# T05 – Human‑Centered Design & Simulation Planning: K–8 Skill List (Draft v1)

Topic reference: `T05 Human-Centered Design & Simulation Planning` in `domains_topics_overview.md`
Domain: Algorithms & Design (D1) · CSTA focus: ALG‑HD, DAA‑DI (with links to ALG‑IM, ALG‑AF, PRO‑PF)

Each skill below has:

- a stable **ID** (`T05.G<grade>.<nn>`),
- an IXL‑style **short name**,
- a **description** (what understanding/behavior it targets),
- a **challenge format** (the typical problem type to assess it).

Where relevant, a primary **CSTA code** is noted.

---

## Grade K (PreK–K)

Grade K students begin recognizing that technology helps people and exploring the idea that designs should consider what others need.

### T05.GK.01 – Name a helper in your life

- **Short name:** Who does technology help?
- **Description:** Students identify someone in their immediate environment (family member, teacher, classmate) and name a piece of technology or a tool that helps that person. They articulate a simple reason (e.g., "Mom uses a microwave to cook food faster"). This builds awareness that technology and design are made for people.
- **Challenge format:** Concept, oral or written response. Prompt: "Name someone and one thing that helps them." Students answer with a person and a technology/tool. Simple pictorial or text options provide scaffolding. Auto‑grading accepts varied answers that match the person-technology pairing and show understanding.
- **CSTA:** EK‑ALG‑HD‑02 (Identify ways that technology might help others).

### T05.GK.02 – Spot what's easy or hard to use

- **Short name:** Easy or hard to use?
- **Description:** Students handle or observe simple everyday tools (physical objects or software buttons) and describe whether each is "easy" or "hard" to use for a typical person. They may explain why in simple terms (e.g., "The big button is easy; the tiny button is hard"). This introduces the idea of usability without formal terminology.
- **Challenge format:** Concept, interactive activity or multiple choice. Show pictures or short animations of tools (a big/small button, large/small text, a simple/complex menu). Students choose "easy" or "hard" for each. Auto‑grading compares to a reasonable rubric of accessibility (size, clarity, simplicity).
- **CSTA:** EK‑ALG‑HD‑02.

### T05.GK.03 – What would help someone?

- **Short name:** Design an idea to help someone
- **Description:** Given a simple scenario (e.g., "Your friend always loses their toy"), students suggest a simple design or tool idea to solve the problem (e.g., "A special box with a picture on it so he knows where to look"). This is informal design thinking—recognizing a need and imagining a solution.
- **Challenge format:** Concept, open response with a drawing or choice of suggestions. Prompt: "How could we help someone?" Students select or describe an idea. Auto‑grading accepts reasonable, age‑appropriate solutions that address the stated problem.
- **CSTA:** EK‑ALG‑HD‑02.

---

## Grade 1

Grade 1 students deepen their understanding of user needs and design improvements by thinking about how technology can solve problems for others.

### T05.G1.01 – Ask what someone needs

- **Short name:** What does someone need?
- **Description:** Students are given a brief story about a person facing a problem (e.g., "Priya wants to remember her favorite foods"). They identify or articulate what the person needs (in this case, a way to remember foods). This teaches observation and empathy as the first step in human‑centered design.
- **Challenge format:** Concept, multiple choice or short response. Prompt: "What does [person] need?" Options range from related to unrelated; students pick the real need. Auto‑grading checks for correct identification of the user's need.
- **CSTA:** E1‑ALG‑HD‑02 (Design an improvement to a technology to solve a problem for someone else).

### T05.G1.02 – Improve a tool for someone

- **Short name:** Make it better for someone else
- **Description:** Students are shown a simple tool or program (e.g., a sprite that asks yes/no questions, or a drawing tool). They propose a small improvement that would help a specific person use it better (e.g., "Add bigger buttons for my little sister"). This connects user needs to design choices.
- **Challenge format:** Concept, open response with scaffolding. Prompt: "How could you change [tool] to help [person]?" Students sketch or describe a change. Auto‑grading accepts reasonable improvements tied to the stated person and their needs.
- **CSTA:** E1‑ALG‑HD‑02.

### T05.G1.03 – Spot differences in how people do things

- **Short name:** Do people solve problems differently?
- **Description:** Students observe or hear about two people solving the same problem in different ways (e.g., one person uses a map, another asks for directions). They notice and articulate that people have different approaches and preferences. This introduces the idea of diverse user needs.
- **Challenge format:** Concept, multiple choice or short answer. Show two short scenarios; ask "How are these different?" or "Which person solved the problem a different way?" Auto‑grading checks recognition of difference in approach or preference.
- **CSTA:** E1‑ALG‑HD‑02.

### T05.G1.04 – Design a simple app idea for someone

- **Short name:** App idea for a friend
- **Description:** Students propose a very simple app or program idea that would help someone they know (e.g., "An app to help my friend remember his soccer games"). They describe what the app would do and whom it would help. This is informal design documentation.
- **Challenge format:** Coding or concept, project description. Prompt: "Design an app idea for someone. What does it do? Who does it help?" Students create a one-paragraph description or label a simple drawing. Auto‑grading checks for (1) a clear idea, (2) identification of a user/helper, and (3) a basic purpose/function.
- **CSTA:** E1‑ALG‑HD‑02.

---

## Grade 2

Grade 2 students formalize the link between human problems and algorithmic or programmatic solutions, discussing how algorithms can help.

### T05.G2.01 – Name the problem and the solution

- **Short name:** What's the problem? What's the solution?
- **Description:** Given a scenario (e.g., "Marcus wants to organize his stamps"), students identify the problem (disorganized stamps) and propose a solution approach (a list, a sorting rule). This develops the habit of framing user needs as problems and algorithm/program design as solutions.
- **Challenge format:** Concept, fill-in-the-blank or structured response. Prompt: "Problem: ___. Solution: ___." Students complete both blanks. Auto‑grading checks that the problem and solution are related and reasonable.
- **CSTA:** E2‑ALG‑HD‑02 (Discuss how human problems might be solved with the assistance of algorithms or programs).

### T05.G2.02 – Trace a program and say who it helps

- **Short name:** What does this program do for people?
- **Description:** Students read or trace a short CreatiCode program (e.g., a sprite that keeps a count of button presses) and explain what task it accomplishes and who it might help (e.g., "It counts votes for a class election"). This connects code to human purpose.
- **Challenge format:** Concept, code‑reading with explanation. Show a short script; prompt: "What does this program do? Who does it help?" Students provide short written or oral answers. Auto‑grading checks that the answer reflects the program's behavior and identifies a plausible user.
- **CSTA:** E2‑ALG‑HD‑02.

### T05.G2.03 – Identify what makes something easy or hard to use

- **Short name:** Why is it easy or hard to use?
- **Description:** Students examine a simple program (in CreatiCode or conceptually) and identify one feature that makes it easy or hard to use (e.g., "Big buttons are easy to click," "Too many options are confusing"). They articulate a reason.
- **Challenge format:** Concept, observation and explanation. Show a program or sketch of an interface; ask "What makes this easy (or hard) to use?" Students point out one feature and explain. Auto‑grading checks for identification of a real feature and a reasonable explanation.
- **CSTA:** E2‑ALG‑HD‑02.

### T05.G2.04 – Pitch an improvement to a program

- **Short name:** Suggest one way to improve it
- **Description:** Students suggest a small, concrete change to an existing simple program (in words or pictures) that would make it more helpful or easier to use (e.g., "Add a 'quit' button," "Make the text bigger"). This is early refactoring with user feedback in mind.
- **Challenge format:** Concept, design proposal or sketch. Prompt: "How would you improve [program] to help the user?" Students describe or draw one change. Auto‑grading accepts improvements that are (1) simple, (2) relevant to usability or function, and (3) achievable in a block-based system.
- **CSTA:** E2‑ALG‑HD‑02.

---

## Grade 3

Grade 3 students design algorithms and programs that solve problems for and meet the needs of someone else, introducing simple user research and feedback.

### T05.G3.01 – Plan a program with a user in mind

- **Short name:** Design for someone specific
- **Description:** Students brainstorm and plan a simple program (e.g., a quiz game, a story, a tool) by first identifying who will use it and what they need. They create a simple one-page design document that names the user and describes the program's features to meet that person's needs.
- **Challenge format:** Concept, design document. Prompt: "Design a program for [a specific friend/user]. What would it do? Why would it help them?" Students write/draw a brief plan. Auto‑grading checks for (1) identification of a user, (2) a named feature or function, and (3) a stated connection between feature and user need.
- **CSTA:** E3‑ALG‑HD‑02 (Design an algorithm or program that solves a problem for and meets the needs of someone else).

### T05.G3.02 – Create a simple user story

- **Short name:** User story for a program
- **Description:** Students write or act out a very simple user story (e.g., "Aisha wants to remember her favorite songs, so she will add them to a list"). This reinforces the problem-solution frame and introduces the idea of documenting user needs.
- **Challenge format:** Concept, template-guided writing. Provide a sentence frame: "_____ wants to _____, so they will _____." Students complete it. Auto‑grading checks for coherent logic (want → action) and a realistic scenario.
- **CSTA:** E3‑ALG‑HD‑02.

### T05.G3.03 – Make a UX flow diagram for a simple app

- **Short name:** Draw the steps in an app
- **Description:** Students sketch or arrange cards to show the steps a user takes to accomplish a task in a program (e.g., "Start → Click New Game → Choose Difficulty → Play → See Score → Restart"). This is an informal UX flow or storyboard.
- **Challenge format:** Concept, interactive card ordering or drawing. Prompt: "Put these steps in order for someone using [app]." Or: "Draw the steps." Students arrange items or create a simple diagram. Auto‑grading checks logical order and coverage of main interactions.
- **CSTA:** E3‑ALG‑HD‑02.

### T05.G3.04 – Test a program and give feedback

- **Short name:** Use a program and say what works
- **Description:** Students use a simple CreatiCode program, then describe one thing that works well and one thing that could be better. This introduces the concept of user testing and gathering feedback to improve design.
- **Challenge format:** Concept, interactive testing and response. Students run a provided program, then answer prompts like "What was easy?" and "What was hard?" Auto‑grading accepts observations tied to actual program behavior.
- **CSTA:** E3‑ALG‑HD‑02.

---

## Grade 4

Grade 4 students modify programs and algorithms based on feedback and begin considering diverse user needs and accessibility.

### T05.G4.01 – Gather feedback and plan improvements

- **Short name:** What did testers say? Improve it.
- **Description:** Students are given feedback from hypothetical or real users (e.g., "The buttons are too small," "It's too easy"). They identify the feedback, the problem it points to, and propose a design change to address it.
- **Challenge format:** Concept, structured analysis. Prompt: "Here's what a user said. What is the problem? How would you fix it?" Students analyze feedback and propose a change. Auto‑grading checks that the proposed change addresses the stated feedback.
- **CSTA:** E4‑ALG‑HD‑02 (Modify an algorithm or program, based on feedback, to better meet the needs and requirements of others).

### T05.G4.02 – Code a program improvement based on feedback

- **Short name:** Improve your program
- **Description:** Students have a simple CreatiCode program and receive one piece of concrete feedback (e.g., "Add a sound when the player wins"). They modify the code to address the feedback, practicing the iterative design process in a real codebase.
- **Challenge format:** Coding, refactor and feedback response. Starter project includes a program and a feedback card. Students modify the code to address the feedback. Auto‑grading checks that the modification is present and functional.
- **CSTA:** E4‑ALG‑HD‑02.

### T05.G4.03 – Design for different users (accessibility)

- **Short name:** Design for someone with different needs
- **Description:** Given a scenario (e.g., "Design a game for a classmate who is deaf," "Design an interface for someone with low vision"), students identify one design change that would make a program accessible or usable for that person (e.g., "Add text labels to all sounds," "Use a big, easy-to-read font").
- **Challenge format:** Concept, design proposal. Prompt: "How would you change [program] so [person with specific need] could use it?" Students describe a change. Auto‑grading checks that the change is relevant to the stated need and achievable.
- **CSTA:** E4‑ALG‑HD‑02.

### T05.G4.04 – Evaluate a program for different user groups

- **Short name:** Does it work for everyone?
- **Description:** Students examine a program and consider how different people might use it (e.g., young children, English learners, people with slow internet). They identify potential barriers or improvements for each group. This develops awareness of diverse user needs.
- **Challenge format:** Concept, analysis worksheet. Show a program; list several user groups (with characteristics). Students check "works well" or "needs improvement" for each and explain briefly. Auto‑grading checks that reasons tie to the program's design and the group's characteristics.
- **CSTA:** E4‑ALG‑HD‑02.

---

## Grade 5

Grade 5 students develop algorithms and programs using a structured process that considers user needs, requirements, and feedback from the outset.

### T05.G5.01 – Create a simple design document

- **Short name:** Full design plan for a program
- **Description:** Students create a one- to two-page design document for a simple program, including (1) who the user is, (2) what problem it solves, (3) key features, (4) how the user will interact with it. This formalizes user-centered design thinking.
- **Challenge format:** Concept, design document. Prompt: "Design a program. Include: user, problem, features, and how they use it." Students write and/or sketch a plan. Auto‑grading checks for all four required elements and internal consistency.
- **CSTA:** E5‑ALG‑HD‑02 (Develop an algorithm to solve a problem, using a process that considers the needs, requirements, and feedback of others).

### T05.G5.02 – Develop personas for your program

- **Short name:** Create user personas
- **Description:** Students create 2–3 simple personas (fictional users) for a program they're designing, describing each person's goal, background, and needs. Example: "Maya is 7 years old and wants to learn to draw; she needs big, colorful buttons." This deepens empathy and helps design decisions.
- **Challenge format:** Concept, persona template. Provide a frame: "Name, Age, Goal, Needs." Students fill out 2–3 for their program idea. Auto‑grading checks that each persona is distinct, realistic, and relevant to the program.
- **CSTA:** E5‑ALG‑HD‑02.

### T05.G5.03 – Create a detailed UX flow or storyboard

- **Short name:** Detailed user journey in your app
- **Description:** Students map out a user's path through a program in detail (e.g., "Start screen → Enter name → Choose level → Play → Win → See score → Return to menu"). Each step shows interaction points and decisions. This is a more mature version of Grade 3's simple flow.
- **Challenge format:** Concept, diagram or card sequence. Students create a storyboard or flowchart with 5–7 steps. Auto‑grading checks for logical flow, clarity of steps, and realism.
- **CSTA:** E5‑ALG‑HD‑02.

### T05.G5.04 – Plan what to model and what to simplify

- **Short name:** Simplify reality for a simulation
- **Description:** Students plan a simple simulation (e.g., "A game where a ball falls and bounces"). They identify aspects of real life they will model (gravity, bouncing) and aspects they will leave out or simplify (air resistance, friction). This teaches the core skill of simulation design: knowing what to include and what to ignore for a specific purpose.
- **Challenge format:** Concept, planning document. Prompt: "Plan a simulation. What real things will you model? What will you simplify or ignore? Why?" Students create a list or table. Auto‑grading checks for (1) at least one modeled aspect, (2) at least one simplified aspect, and (3) reasonable justifications.
- **CSTA:** E5‑DAA‑DI (Use data investigation and interpretation skills; recognize patterns).

---

## Grade 6

In middle school, students design algorithms using human-centered design principles such as empathy, user needs, and accessibility, and begin iteratively refining based on feedback.

### T05.G6.01 – Apply HCD principles to a project

- **Short name:** Use HCD: empathy, needs, accessibility
- **Description:** Students apply explicit human-centered design principles (empathy mapping, needs analysis, accessibility checklist) to design or evaluate a program or game. They document how each principle was applied.
- **Challenge format:** Concept, design analysis or project document. Prompt: "Design a program using empathy, user needs, and accessibility. Show how you used each." Students provide evidence of considering all three. Auto‑grading checks for explicit mention and evidence of each principle.
- **CSTA:** MS‑ALG‑HD‑03 (Design algorithms, using human-centered design principles such as empathy, user needs and requirements, and accessibility).

### T05.G6.02 – Conduct user research and interviews

- **Short name:** Interview users to understand needs
- **Description:** Students design and conduct 1–2 short user interviews (with classmates or family) to understand needs for a program idea. They document responses and identify patterns or key requirements. This is formalized user research.
- **Challenge format:** Concept, research document. Prompt: "Interview 1–2 people. Ask: What problem do you want to solve? Students document answers and identify common needs. Auto‑grading checks for (1) at least 2 interviews, (2) clear questions, and (3) summary of findings.
- **CSTA:** MS‑ALG‑HD‑03.

### T05.G6.03 – Iterate on a design based on user feedback

- **Short name:** Refine design through feedback cycles
- **Description:** Students present a program or design to users, gather feedback, analyze it, and make targeted improvements. They document the feedback loop (feedback → issue identified → change made → tested). This is iterative design in practice.
- **Challenge format:** Coding and concept, iteration project. Students implement a program, show it to 2–3 testers, gather notes, make 1–2 code changes, and document the cycle. Auto‑grading checks for (1) documented feedback, (2) at least one code change, (3) evidence of improvement.
- **CSTA:** MS‑ALG‑HD‑04 (Refine algorithms iteratively through user feedback to improve usability, accessibility, and user experience).

### T05.G6.04 – Plan a simulation and defend design choices

- **Short name:** Simulation design and justification
- **Description:** Students design a simple educational simulation (e.g., "Simulate predator-prey population," "Model a water cycle"). They document what aspects of reality they model and what they simplify, and justify each choice based on educational purpose or computational feasibility.
- **Challenge format:** Concept, design document with justification. Prompt: "Plan a simulation. What will you model? What will you simplify? Justify each choice." Students create a table or narrative. Auto‑grading checks for at least 2 modeled aspects and 2 simplified aspects, each with a brief justification.
- **CSTA:** MS‑DAA‑DI (Data investigation; understand patterns and design data experiments).

---

## Grade 7

Grade 7 students deepen iteration and accessibility practices, and begin evaluating potential harms or unintended consequences of their designs for diverse audiences.

### T05.G7.01 – Accessibility audit and remediation

- **Short name:** Audit a program for accessibility
- **Description:** Students audit an existing program (CreatiCode project or a web app) against an accessibility checklist (readable text, keyboard navigation, color contrast, alt text for images, clear instructions). They identify gaps and propose or implement fixes.
- **Challenge format:** Concept and coding, audit report plus fixes. Prompt: "Check [program] against this checklist. What's missing? Fix at least two issues." Students provide a report and code changes. Auto‑grading checks for (1) identification of real accessibility issues, (2) relevant fixes.
- **CSTA:** MS‑ALG‑HD‑04.

### T05.G7.02 – Identify and mitigate potential harms in a design

- **Short name:** What could go wrong? Prevent harms.
- **Description:** Students brainstorm potential negative impacts or unintended consequences of a program they've designed (e.g., "My game is addictive and kids might play too long," "My chatbot gives wrong answers"). They identify one harm and propose a mitigation strategy (e.g., add a play-time limit, add a disclaimer, verify sources).
- **Challenge format:** Concept, risk analysis and mitigation plan. Prompt: "What unintended consequences could [program] have? Propose one mitigation." Students identify a harm and a solution. Auto‑grading checks for reasonable harm identification and relevant mitigation proposal.
- **CSTA:** MS‑ALG‑HD‑04 (by extension; also touches on ALG‑IM: Impacts of Algorithms).

### T05.G7.03 – Gather iterative feedback across multiple rounds

- **Short name:** Multi-round user testing and refinement
- **Description:** Students conduct 2–3 rounds of user testing on a program they're developing. After each round, they analyze feedback, make changes, and test again. They document how the program evolves and reflect on insights gained.
- **Challenge format:** Coding and concept, testing report. Students create a program, test with users (round 1), document changes, test again (round 2), document results. Auto‑grading checks for (1) at least 2 testing rounds, (2) documented feedback and changes, (3) evidence of improvement.
- **CSTA:** MS‑ALG‑HD‑04.

### T05.G7.04 – Design a simulation for a real-world question

- **Short name:** Simulation to answer a research question
- **Description:** Students design and build a simulation to answer a real-world or classroom question (e.g., "How does population grow if there's limited food?" or "What happens to a virus spreading in a population?"). They define what to model, run the simulation, and interpret results.
- **Challenge format:** Coding, simulation project. Prompt: "Design a simulation to answer [question]. Model key variables. Run it and describe what you learn." Students build code, document design choices, and report findings. Auto‑grading checks for (1) clear simulation logic, (2) at least 2 variables being modeled, (3) coherent interpretation of results.
- **CSTA:** MS‑DAA‑DI (Data investigation: design and run simulations to test hypotheses or answer questions).

---

## Grade 8

Grade 8 students evaluate potential harms, biases, and unintended consequences in algorithm and program design across diverse user groups, and design and refine simulations for complex real-world scenarios.

### T05.G8.01 – Analyze potential biases in an algorithm or design

- **Short name:** Find and fix biases in your design
- **Description:** Students examine an algorithm or program they've designed and identify potential biases (e.g., does it work equally well for all genders, abilities, or backgrounds?). They propose and implement changes to mitigate bias (e.g., diverse imagery, inclusive language, accessible features).
- **Challenge format:** Concept and coding, bias analysis and remediation. Prompt: "Does your program work fairly for everyone? Identify one bias and fix it." Students document the bias, explain its impact, and code a fix. Auto‑grading checks for identification of a plausible bias and a reasonable, implemented solution.
- **CSTA:** MS‑ALG‑HD‑04 (by extension; evaluating fairness and accessibility).

### T05.G8.02 – Design for diverse audiences with conflicting needs

- **Short name:** Serve multiple user groups with different needs
- **Description:** Students design a program or algorithm that must satisfy two or more distinct user groups with potentially conflicting needs (e.g., "A math game for 2nd graders AND their parents," "A website for English learners AND native speakers"). They document trade-offs and design decisions that balance needs.
- **Challenge format:** Concept, design document with trade-off analysis. Prompt: "Design for [two groups with different needs]. What trade-offs did you make?" Students document design choices and justify them. Auto‑grading checks for (1) identification of real conflicts, (2) evidence of design trade-offs, (3) reasonable justifications.
- **CSTA:** MS‑ALG‑HD‑03, MS‑ALG‑HD‑04.

### T05.G8.03 – Run a controlled simulation experiment

- **Short name:** Experiment with a simulation model
- **Description:** Students build a simulation, then systematically vary one parameter at a time (e.g., starting population, food availability) and observe effects on outcomes. They document hypotheses, results, and conclusions. This teaches simulation as a tool for experimentation and evidence-based reasoning.
- **Challenge format:** Coding and concept, simulation experiment report. Prompt: "Build a simulation. Change one variable at a time. Record results. What patterns do you see?" Students create a simulation, complete a data table of results, and write conclusions. Auto‑grading checks for (1) systematic variation of variables, (2) documented results, (3) coherent conclusions.
- **CSTA:** MS‑DAA‑DI (Design and run simulations to explore questions and test hypotheses).

### T05.G8.04 – Evaluate realism and limitations in a simulation

- **Short name:** How realistic is your simulation?
- **Description:** Students critically examine a simulation they've built or studied and evaluate its realism and limitations. They identify simplifications, assumptions, and edge cases not covered. They articulate how limitations might affect conclusions drawn from the simulation.
- **Challenge format:** Concept, reflection and analysis. Prompt: "What did you simplify in your simulation? How might that change your conclusions?" Students write a brief analysis identifying 2–3 simplifications and discussing impact. Auto‑grading checks for (1) identification of real simplifications, (2) reasoning about impact on conclusions.
- **CSTA:** MS‑DAA‑DI (Reflect on limitations and validity of simulations).

---
