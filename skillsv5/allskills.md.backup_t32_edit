# T01 - Everyday Algorithms (Phase 9 Optimized - November 2025)
# PHASE 9 MAJOR OVERHAUL - Bold Changes for Excellence
#
# PHILOSOPHY SHIFT: Algorithms are about THINKING, not just DOING
# - Every skill now emphasizes WHY algorithms work, not just HOW
# - Added "Defend your reasoning" and "Critique" components throughout
# - Integrated AI-era skills: verifying AI suggestions, collaborative design
#
# NEW SKILL CATEGORIES ADDED:
# 1. ALGORITHM COMMUNICATION (explaining algorithms to others)
#    - GK.10: Explain your sequence choice to a partner using picture cards
#    - G1.12: Explain why one algorithm is better than another
#    - G3.18: Describe algorithm behavior to a partner who can't see the code
#    - G5.14: Document algorithm design decisions for future readers
#    - G7.12: Present algorithm trade-offs to stakeholders
#
# 2. ALGORITHM VERIFICATION & CRITIQUE
#    - G2.21: Spot the flaw in a friend's algorithm
#    - G4.17: Critique a peer's algorithm and suggest improvements
#    - G6.14: Verify AI-generated algorithm suggestions
#    - G8.14: Lead code review for peer's algorithm implementation
#
# 3. REAL-WORLD ALGORITHM RECOGNITION
#    - GK.11: Find algorithms in everyday activities (video examples)
#    - G2.22: Connect everyday decisions to if/then rules
#    - G4.18: Recognize algorithms in apps and games you use
#    - G6.15: Analyze algorithms behind recommendation systems
#
# 4. COLLABORATIVE ALGORITHM DESIGN
#    - G3.19: Build an algorithm together with a partner (pair programming intro)
#    - G5.15: Merge two partial algorithms into a complete solution
#    - G7.13: Design algorithm as a team with role assignments
#    - G8.15: Coordinate multi-person algorithm development
#
# 5. ALGORITHM ADAPTATION & MODIFICATION
#    - G2.23: Change one rule to make an algorithm work differently
#    - G4.19: Adapt an algorithm to solve a similar but different problem
#    - G6.16: Extend an algorithm to handle new requirements
#    - G8.16: Refactor legacy algorithm to meet new constraints
#
# CONSOLIDATED SKILLS (reduced redundancy):
# - G4.03.01-03 merged into G4.03 (pattern identification at multiple scales)
# - G4.05.01-02 merged into G4.05 (loop comparison with reasoning)
# - G4.06.01-02 merged into G4.06 (variable understanding)
#
# VERB UPGRADES (active, measurable):
# - "Match" → "Connect and justify", "Pair with explanation"
# - "Identify" → "Locate and mark", "Detect and highlight"
# - "Compare" → "Analyze and defend choice", "Evaluate with criteria"
# - Added "Construct", "Defend", "Critique", "Propose", "Verify"
#
# DEPENDENCY IMPROVEMENTS:
# - Stronger K→G1→G2 picture-based progression
# - Added alternative dependency paths for key skills
# - All intra-topic dependencies validated for X-2 rule
#
# Total: ~175 skills (added 23 new skills for communication, verification,
# collaboration, and real-world connections while consolidating 8 redundant skills)

ID: T01.GK.01
Topic: T01 – Everyday Algorithms
Skill: Sequence three picture cards for a bedtime routine
Description: **Student task:** Drag 3 picture cards showing bedtime actions into the correct order from first to last. **Visual scenario:** Picture cards show: (A) child putting on pajamas, (B) child brushing teeth at sink, (C) child getting into bed with stuffed animal. **Correct order:** A → B → C. _Implementation note: Drag‑drop sequence with large, colorful picture cards; audio support reads card labels on hover. Auto-graded by final sequence position. CSTA: EK‑ALG‑AF‑01._






ID: T01.GK.02
Topic: T01 – Everyday Algorithms
Skill: Sequence four picture cards for a classroom arrival routine
Description: **Student task:** Drag 4 picture cards showing classroom arrival steps into the correct order. **Visual scenario:** Picture cards show: (A) child walking through door, (B) child hanging backpack on hook, (C) child sitting at desk, (D) child looking at teacher with hand raised. **Correct order:** A → B → C → D. _Implementation note: Drag‑drop sequence with 4 large picture cards; extends GK.01 by adding one more step. Auto-graded by final sequence. CSTA: EK‑ALG‑AF‑01._







ID: T01.GK.03
Topic: T01 – Everyday Algorithms
Skill: Tap the first and last picture cards in a sequence
Description: **Student task:** Look at 4-5 picture cards already arranged in order. Tap the card that shows what happens FIRST. Then tap the card that shows what happens LAST. **Visual scenario:** Cards show a sandwich-making sequence: get bread, spread peanut butter, add jelly, put bread on top, eat sandwich. **Correct answers:** "get bread" is FIRST, "eat sandwich" is LAST. _Implementation note: Two-tap selection task; audio prompt "Which happens first?" and "Which happens last?" Auto-graded by correct selections. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T01.GK.02: Sequence four picture cards for a classroom arrival routine





ID: T01.GK.04
Topic: T01 – Everyday Algorithms
Skill: Select the picture sequence that makes sense
Description: **Student task:** Look at two rows of picture cards. Tap the row that shows the correct order. **Visual scenario:** Row A shows: wash hands → dry hands → eat food. Row B shows: eat food → wash hands → dry hands. **Correct answer:** Row A (you wash before eating). _Implementation note: Binary choice between two pre-arranged sequences; audio asks "Which row shows the right order?" Auto-graded by selection. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑IM‑04._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine





ID: T01.GK.05
Topic: T01 – Everyday Algorithms
Skill: Drag the misplaced picture card to its correct position
Description: **Student task:** Look at 4 picture cards in a row. One card is in the wrong spot. Drag it to where it belongs. **Visual scenario:** Cards show plant-growing steps with "water the plant" incorrectly placed before "put seed in soil." Student drags "water the plant" to after "put seed in soil." _Implementation note: Single card drag-and-drop to fix sequence; visual highlight shows the "wrong" card wobbling. Auto-graded by final arrangement. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑PS‑03._

Dependencies:
* T01.GK.03: Tap the first and last picture cards in a sequence







ID: T01.GK.06
Topic: T01 – Everyday Algorithms
Skill: Predict the next picture card in a sequence
Description: **Student task:** Look at 2 picture cards showing the start of a routine. Tap the picture card that shows what comes next. **Visual scenario:** Shows "put on socks" → "put on shoes" → [?]. Answer choices: (A) tie shoelaces, (B) take off shirt, (C) brush hair. **Correct answer:** (A) tie shoelaces. _Implementation note: MCQ with 3 picture options; audio reads "What comes next?" Auto-graded by selection. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine





ID: T01.GK.07
Topic: T01 – Everyday Algorithms
Skill: Find the repeating pattern in an animation
Description: **Student task:** Watch a short animation showing repeated actions. Tap the picture cards that show what repeats. **Visual scenario:** Animation shows character: hop → clap → hop → clap → hop → clap. Answer choices show different action pairs. **Correct answer:** hop-clap pattern. _Implementation note: Animation (3-4 seconds) + MCQ with 3 pattern options shown as picture card pairs. Auto-graded by selection. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑PS‑03._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine







ID: T01.GK.08
Topic: T01 – Everyday Algorithms
Skill: Count how many times an action repeats in an animation
Description: **Student task:** Watch a character do the same action multiple times. Tap the number that shows how many times. **Visual scenario:** Animation shows bunny jumping 3 times. Answer choices: picture cards showing 1, 2, 3, or 4 bunny jumps. **Correct answer:** 3. _Implementation note: Short animation (2-4 seconds) + picture-based count choices (1-4); audio asks "How many times did bunny jump?" Auto-graded by selection. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T01.GK.07: Identify the repeating pattern in an animation




ID: T01.GK.09
Topic: T01 – Everyday Algorithms
Skill: Compare two picture sequences that achieve the same goal
Description: **Student task:** Look at two rows of picture cards that both show how to do the same thing (like getting ready for school). Tap YES if both ways work, or tap NO if one way is broken. **Visual scenario:** Row A shows: wake up → get dressed → eat breakfast → go to school. Row B shows: wake up → eat breakfast → get dressed → go to school. Question: "Do both ways get you ready for school?" **Correct answer:** YES (both sequences achieve the goal, even though steps are in different order). _Implementation note: Side-by-side comparison with YES/NO buttons; introduces concept that multiple algorithms can solve same problem. Audio support. Auto-graded by selection. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑IM‑04._

Dependencies:
* T01.GK.04: Select the picture sequence that makes sense



ID: T01.GK.10
Topic: T01 – Everyday Algorithms
Skill: Explain your sequence choice to a partner using picture cards
Description: **Student task:** After arranging picture cards, explain WHY you put them in that order. Point to each card and say what happens and why it must come before/after. **Visual scenario:** Student arranges 3 cards for "washing hands." Then records or says aloud: "First I turn on water because I need wet hands. Then I add soap because soap needs water to work. Then I scrub because that's how soap cleans." **Assessment:** Teacher/AI evaluates explanation for logical cause-effect reasoning. _Implementation note: Voice recording or partner listening; introduces algorithm COMMUNICATION - a critical skill for collaborative work. Audio prompt guides explanation. Rubric-graded for completeness and logic. CSTA: EK‑ALG‑AF‑01, EK‑CS‑PC‑01._

Dependencies:
* T01.GK.02: Sequence four picture cards for a classroom arrival routine
* T01.GK.04: Select the picture sequence that makes sense



ID: T01.GK.11
Topic: T01 – Everyday Algorithms
Skill: Find algorithms in everyday activities (video examples)
Description: **Student task:** Watch a short video of everyday activities. Tap when you see someone following steps in order (an algorithm!). **Visual scenario:** Video shows: child tying shoes (algorithm!), bird flying (not an algorithm), person making a sandwich step-by-step (algorithm!), leaves blowing (not an algorithm). Students tap "Yes, algorithm!" or "No, not algorithm" for each clip. **Key insight:** Algorithms are step-by-step instructions that people (or computers) follow. _Implementation note: 4-6 short video clips (5-10 seconds each); introduces recognition that algorithms exist everywhere, not just in computers. Audio explains "An algorithm is steps in order to do something." Auto-graded by selection. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine





ID: T01.G1.01
Topic: T01 – Everyday Algorithms
Skill: Sequence four picture cards for planting a seed
Description: **Student task:** Drag 4 picture cards into the correct order to plant a seed. **Visual scenario:** Cards show: (A) get a pot, (B) add soil to pot, (C) put seed in soil, (D) water the seed. Students arrange A → B → C → D. _Implementation note: Drag‑drop with 4 cards; builds on GK sequencing with nature/science context. Auto-graded by final arrangement. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T01.GK.02: Sequence four picture cards for a classroom arrival routine





ID: T01.G1.02
Topic: T01 – Everyday Algorithms
Skill: Sequence five picture cards for making breakfast
Description: **Student task:** Drag 5 picture cards into the correct order to make cereal for breakfast. **Visual scenario:** Cards show: (A) get bowl from cabinet, (B) pour cereal into bowl, (C) pour milk, (D) eat cereal with spoon, (E) put bowl in sink. Students arrange A → B → C → D → E. _Implementation note: Drag‑drop with 5 cards; extends G1.01 by adding one more step. Auto-graded by final arrangement. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T01.G1.01: Sequence four picture cards for planting a seed





ID: T01.G1.03
Topic: T01 – Everyday Algorithms
Skill: Select the missing last step in a routine
Description: **Student task:** Look at 3 picture cards showing an incomplete routine. Select the picture that shows the correct last step. **Visual scenario:** Cards show: get bread → add peanut butter → add jelly → [?]. Answer choices: (A) eat sandwich, (B) turn on TV, (C) go outside. **Correct answer:** (A) eat sandwich. _Implementation note: MCQ with 3-4 picture options; extends GK.06 prediction with completion framing. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T01.GK.06: Predict the next picture card in a sequence





ID: T01.G1.04
Topic: T01 – Everyday Algorithms
Skill: Predict the next panel in a story sequence
Description: **Student task:** Look at 3 story panels showing a cause-and-effect sequence. Select the picture that shows what happens next. **Visual scenario:** Panels show: (1) dog sees ball, (2) dog runs toward ball, (3) dog reaches for ball. Answer choices: (A) dog catches ball, (B) dog sleeps, (C) dog eats food. **Correct answer:** (A) dog catches ball. _Implementation note: MCQ with 3 picture options; focuses on narrative cause-effect rather than procedural routines. Auto-graded. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T01.GK.06: Predict the next picture card in a sequence





ID: T01.G1.05
Topic: T01 – Everyday Algorithms
Skill: Select the missing middle step in an algorithm
Description: **Student task:** Look at 4 picture cards with one blank in the MIDDLE (not the end). Select the picture that fills the gap. **Visual scenario:** Cards show: get cup → [?] → pour milk → drink. Answer choices: (A) open refrigerator, (B) wash hands, (C) sit down. **Correct answer:** (A) open refrigerator. _Implementation note: MCQ with 3-4 picture options; extends G1.03 by placing gap in middle instead of end. Auto-graded. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T01.G1.03: Select the missing last step in a routine





ID: T01.G1.06
Topic: T01 – Everyday Algorithms
Skill: Find and replace the wrong step in a routine
Description: **Student task:** Look at 4 picture cards. One card shows a completely WRONG action (not just out of order). Tap the wrong card, then select the correct replacement. **Visual scenario:** Cards show: get pan → eat food → cook egg → put on plate. "Eat food" is wrong because you can't eat before cooking. Replace with "crack egg into pan." _Implementation note: Two-step task: (1) tap wrong card, (2) select replacement from 3 options. Auto-graded. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T01.GK.05: Drag the misplaced picture card to its correct position





ID: T01.G1.07
Topic: T01 – Everyday Algorithms
Skill: Compare two algorithms to check if they achieve the same result
Description: **Student task:** Look at two rows of picture cards showing different routines. Do both routines end with the same result? **Visual scenario:** Row A: get bread → add butter → add jam. Row B: get bread → add jam → add butter. Question: "Do both make the same thing?" **Correct answer:** Yes (both make bread with butter and jam). _Implementation note: Side-by-side comparison + Yes/No question. Auto-graded. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T01.GK.04: Select the picture sequence that makes sense





ID: T01.G1.08
Topic: T01 – Everyday Algorithms
Skill: Select the shorter algorithm that achieves the same goal
Description: **Student task:** Look at two correct routines that both achieve the same goal. Select the one that uses FEWER steps. **Visual scenario:** Row A (5 cards): get sponge → wet sponge → add soap → scrub dish → rinse dish. Row B (4 cards): get soapy sponge → scrub dish → rinse dish → done. Question: "Which uses fewer steps?" **Correct answer:** Row B (4 steps vs 5 steps). _Implementation note: Count-and-compare task + selection. Auto-graded. CSTA: E1‑ALG‑IM‑04._

Dependencies:
* T01.G1.07: Compare two algorithms to check if they achieve the same result





ID: T01.G1.09
Topic: T01 – Everyday Algorithms
Skill: Connect picture-based routines to their goals
Description: **Student task:** Draw lines connecting 3 picture-card routines to their matching goal labels. Distractors include similar-sounding goals. **Visual scenario:** Routine 1: water can → soil → seed → water. Routine 2: brush → paste → mouth → rinse. Routine 3: paper → crayons → draw → show. Goals: "Plant a seed", "Brush teeth", "Make a drawing", "Cook food", "Build a tower". _Implementation note: Line-matching exercise; auto-graded by correct pairings. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T01.G1.02: Sequence five picture cards for making breakfast





ID: T01.G1.10
Topic: T01 – Everyday Algorithms
Skill: Match situation pictures to if/then rules
Description: **Student task:** Match picture cards showing situations to "If... then..." sentences. **Visual scenario:** Picture A shows rain clouds. Picture B shows sunny sky. Sentences: "If it rains, then use umbrella", "If it's sunny, then wear sunglasses". Match rain picture → umbrella rule, sunny picture → sunglasses rule. _Implementation note: Line-matching or MCQ; introduces conditional thinking with pictures. Auto-graded. CSTA: E1‑ALG‑AF‑01 (conceptual branching)._

Dependencies:
* T01.GK.04: Select the picture sequence that makes sense




ID: T01.G1.11
Topic: T01 – Everyday Algorithms
Skill: Identify which step would break the routine if removed
Description: **Student task:** Look at 4-5 picture cards showing a complete routine. If we REMOVE one card, the routine won't work anymore. Tap the card that CANNOT be removed. **Visual scenario:** Cards show "brushing teeth": (A) pick up toothbrush, (B) add toothpaste, (C) brush teeth, (D) rinse mouth, (E) put toothbrush away. Question: "Which step can't be skipped, or your teeth won't get clean?" **Correct answer:** (C) brush teeth - this is the essential step. _Implementation note: MCQ identifying critical vs optional steps; introduces algorithm analysis at picture level. Distractor cards are "nice to have" steps that could be skipped. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T01.G1.02: Sequence five picture cards for making breakfast



ID: T01.G1.12
Topic: T01 – Everyday Algorithms
Skill: Explain why one algorithm is better using picture reasoning
Description: **Student task:** Look at two picture-card algorithms that both work. Tap the BETTER one, then choose WHY from picture-based reasons. **Visual scenario:** Algorithm A for "clean room": pick up 1 toy → put away → pick up 1 toy → put away → ... (6 cards). Algorithm B: pick up all toys → put all away (2 cards). Question 1: "Which is better?" (tap B). Question 2: "Why?" Choices: (A) picture of fewer cards with happy face, (B) picture of more work with tired face, (C) picture of faster clock. **Correct reason:** (A) fewer steps/cards. _Implementation note: Two-step MCQ with picture-based reasoning; builds algorithm evaluation skills early. Introduces concept that algorithms can be compared for quality. Auto-graded. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑IM‑04._

Dependencies:
* T01.G1.08: Select the shorter algorithm that achieves the same goal
* T01.GK.10: Explain your sequence choice to a partner using picture cards



ID: T01.G2.01
Topic: T01 – Everyday Algorithms
Skill: Identify the repeating action in an everyday task
Description: **Student task:** Look at picture cards showing an everyday task being done multiple times. Select which action repeats. **Visual scenario:** Cards show: pick up toy → put in box → pick up toy → put in box → pick up toy → put in box. Question: "Which action repeats?" Answer choices: (A) pick up toy, (B) open door, (C) eat snack. **Correct answer:** (A) pick up toy. _Implementation note: MCQ identifying repeated action; extends GK.07 to real-world task context. Auto-graded. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.GK.07: Identify the repeating pattern in an animation
* T04.G1.03: Find repeated steps in an instruction list





ID: T01.G2.02
Topic: T01 – Everyday Algorithms
Skill: Select the shorter "repeat" version of directions
Description: **Student task:** Compare two ways to write the same directions. Select the shorter version that uses "repeat ___ times". **Visual scenario:** Version A: "clap, clap, clap, clap" (4 separate cards). Version B: "repeat 'clap' 4 times" (1 card with repeat symbol). Question: "Which says the same thing with fewer cards?" **Correct answer:** Version B. _Implementation note: MCQ comparing explicit vs compressed versions. Auto-graded. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.01: Identify the repeating action in an everyday task





ID: T01.G2.03
Topic: T01 – Everyday Algorithms
Skill: Rewrite repeated steps using a "repeat" instruction
Description: **Student task:** Look at a long list of repeated picture cards (5-6 repeating actions). Drag and arrange cards to create the equivalent "repeat ___ times" version. **Visual scenario:** Given: jump → jump → jump → jump → jump (5 cards). Create: "repeat 'jump' 5 times" by selecting the action card and the number 5. _Implementation note: Assembly/drag task to build compressed form; auto-graded by matching result. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.02: Select the shorter "repeat" version of directions





ID: T01.G2.04
Topic: T01 – Everyday Algorithms
Skill: Match if/then rules to pictures
Description: **Student task:** Draw lines connecting if/then rule cards to matching picture cards. **Visual scenario:** Rule cards show: "If it is raining, then use umbrella" and "If door is open, then close it." Picture cards show: (A) rain clouds with person holding umbrella, (B) sunny sky with sunglasses, (C) open door with arrow pointing to closed door, (D) closed window. Students match: rain rule → picture A, door rule → picture C. _Implementation note: Line-matching with 3-4 rules and 4-5 pictures (includes distractors). Auto-graded by correct pairings. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G1.10: Match pictures to "if/then" rules





ID: T01.G2.05
Topic: T01 – Everyday Algorithms
Skill: Complete a simple if/then algorithm
Description: **Student task:** Look at an incomplete if/then rule card. Drag the correct picture card to fill in the blank. **Visual scenario:** Rule card shows: "If it is cold outside, then ___." Blank space for action. Answer choices: (A) wear a jacket, (B) eat ice cream, (C) go swimming. **Correct answer:** (A) wear a jacket. _Implementation note: Fill-in-the-blank with picture cards for condition OR action; 3-4 answer choices. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.04: Match if/then rules to pictures





ID: T01.G2.06
Topic: T01 – Everyday Algorithms
Skill: Choose the best if/then rule for a situation
Description: **Student task:** Look at a 2-3 panel picture story. Select which if/then rule best describes what should happen. **Visual scenario:** Story panels show: (1) child at crosswalk, (2) walk signal turns green, (3) [what happens next?]. Rule choices: (A) "If signal is green, then walk across," (B) "If signal is red, then run across," (C) "If signal is green, then sit down." **Correct answer:** (A). _Implementation note: Picture story + MCQ with 3-4 if/then rule choices. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.05: Complete a simple if/then algorithm





ID: T01.G2.07
Topic: T01 – Everyday Algorithms
Skill: Trace an algorithm that uses an if/then choice
Description: **Student task:** Look at a picture algorithm with an if/then decision branch. Follow the path based on the given starting condition and select the final outcome. **Visual scenario:** Algorithm shows: START → check weather picture → IF sunny THEN "go to park" → IF rainy THEN "stay home" → END. Given condition: rainy cloud picture. Question: "Where does the character end up?" **Correct answer:** stay home. _Implementation note: Branching picture algorithm with 2-3 conditions; students trace the correct path. Auto-graded by final outcome selection. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.06: Choose the best if/then rule for a situation





ID: T01.G2.08
Topic: T01 – Everyday Algorithms
Skill: Trace an algorithm that uses "repeat ___ times"
Description: **Student task:** Look at a picture algorithm with a "repeat ___ times" loop. Count the total actions or find the final position. **Visual scenario:** Algorithm shows: START at position 0 → "repeat 3 times: hop forward 2 spaces" → END. Number line from 0-10 shown. Question: "Where does the bunny end up?" **Correct answer:** position 6 (hopped 2 spaces, 3 times = 6 total). _Implementation note: Picture-based loop tracing with visual number line or grid; 3-5 total steps. Auto-graded by final position/count. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.03: Replace repeated steps with a repeat instruction





ID: T01.G2.09
Topic: T01 – Everyday Algorithms
Skill: Fix a wrong repeat count in an algorithm
Description: **Student task:** Look at a picture algorithm where the repeat count is wrong. The character ends up in the wrong place. Change the number to fix it. **Visual scenario:** Goal: bunny should reach the carrot at position 8. Algorithm shows: START at 0 → "repeat 3 times: hop 2 spaces." Current result: bunny at position 6 (too short!). Fix: change 3 to 4. Question: "What number should go in the repeat box?" **Correct answer:** 4. _Implementation note: Number adjustment task with visual before/after; auto-graded by correct repeat count. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.08: Trace an algorithm that uses "repeat ___ times"





ID: T01.G2.10
Topic: T01 – Everyday Algorithms
Skill: Fix a wrong or missing if/then branch
Description: **Student task:** Look at a picture algorithm where an if/then branch has the wrong action or is missing. Fix it by selecting the correct action. **Visual scenario:** Algorithm shows: "If touching hot stove, then ___" with wrong action "keep touching." Story shows child getting hurt. Fix by selecting "pull hand away" from choices: (A) pull hand away, (B) touch again, (C) sit down. **Correct answer:** (A) pull hand away. _Implementation note: Error-correction MCQ with 3-4 action choices; visual story shows consequence of bug. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.07: Trace an algorithm that uses an if/then choice





ID: T01.G2.11
Topic: T01 – Everyday Algorithms
Skill: Trace maze directions on a simple grid
Description: **Student task:** Look at a character on a 3×3 grid and a sequence of arrow cards. Trace the path and tap where the character ends up. **Visual scenario:** Grid shows: robot starting at bottom-left corner facing right. Arrow sequence: → → ↑ → (forward, forward, turn up, forward). Grid has cells labeled A1-C3. Question: "Where does the robot end up?" Answer choices show different grid cells highlighted. **Correct answer:** cell C2. _Implementation note: Visual grid with path tracing; 3-5 arrow cards. Auto-graded by final position selection. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._





ID: T01.G2.12
Topic: T01 – Everyday Algorithms
Skill: Choose directions that reach the goal
Description: **Student task:** Look at a 3×3 grid with START (mouse), GOAL (cheese), and one wall block. Select which arrow sequence reaches the goal without hitting the wall. **Visual scenario:** Grid shows: mouse at A1, cheese at C3, wall at B2. Arrow sequence options: (A) →→↑↑ (hits wall), (B) ↑↑→→ (reaches goal), (C) →↑→↑ (reaches goal). Question: "Which path gets the mouse to the cheese?" _Implementation note: MCQ with 3 arrow sequences; visual shows wall obstacle. Auto-graded by simulation. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.11: Trace maze directions on a simple grid





ID: T01.G2.13
Topic: T01 – Everyday Algorithms
Skill: Write directions to navigate a simple grid
Description: **Student task:** Drag arrow cards from a card bank to create a path from START to GOAL on a 3×3 or 4×4 grid. **Visual scenario:** Grid shows: cat at A1 (START), fish at C2 (GOAL), wall at B1. Available arrow cards: →, ↑, ←, ↓ (multiple of each). Students drag arrows to build sequence: ↑ → → ↓ to navigate around wall to fish. _Implementation note: Drag-and-drop arrow card assembly; grid shows path preview as cards are placed. Auto-graded by successful path simulation. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.12: Choose directions that reach the goal





ID: T01.G2.14
Topic: T01 – Everyday Algorithms
Skill: Fix maze directions that miss the goal
Description: **Student task:** Look at a grid path that doesn't work. Find and fix the wrong arrow card to make the character reach the goal. **Visual scenario:** Grid shows: dog at A1 (START), bone at B3 (GOAL). Given sequence: → ↑ → (ends at C2, misses goal!). Visual shows dog ending at wrong cell with "X". Students must change the last → to ↑ so sequence becomes: → ↑ ↑. Question: "Which arrow needs to change?" **Correct answer:** Replace third arrow (→) with (↑). _Implementation note: Single card replacement; shows before/after path preview. Auto-graded by correct path simulation. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.13: Write directions to navigate a simple grid





ID: T01.G2.15
Topic: T01 – Everyday Algorithms
Skill: Match picture instructions to visual block commands
Description: Students match simple picture‑based instruction sequences (e.g., arrow cards showing "forward, forward, turn right") to equivalent visual block images, recognizing that pictures and blocks can represent the same algorithm. **Progression note:** This skill focuses on SEQUENCE-level matching (3-4 step sequences), building on the grid navigation skills to connect familiar direction sequences to code block representations. _Implementation note: Picture-based matching ONLY - no code writing or block arrangement. Drag‑and‑drop matching with 3–4 sequence pairs; auto‑graded. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.13: Write directions to navigate a simple grid





ID: T01.G2.16
Topic: T01 – Everyday Algorithms
Skill: Match code block images to picture sequences
Description: Students look at a picture sequence showing actions (e.g., 3 pictures of a character moving and turning). Then they choose which set of code block IMAGES does the same thing from 3-4 options. **Progression note:** This skill REVERSES the direction from T01.G2.15 - students start with pictures and find matching blocks, and introduces "repeat" block images (building on T01.G2.03). This tests the same concept bidirectionally. _Implementation note: Picture-based MCQ ONLY - students select from pre-drawn block images, no code writing. Auto‑graded. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.03: Replace repeated steps with a repeat instruction
* T01.G2.15: Match picture instructions to visual block commands





ID: T01.G2.17
Topic: T01 – Everyday Algorithms
Skill: Identify the action each code block performs
Description: Students look at simple code block IMAGES (move, turn, say) and identify what action each SINGLE block performs by matching block images to picture-based behaviors (character moving, turning, speaking). **Progression note:** This skill focuses on INDIVIDUAL BLOCK recognition (unlike T01.G2.15-16 which focus on sequences), building vocabulary of what each block type does before combining them. _Implementation note: Picture-based MCQ matching block images to action pictures - no code writing. Auto‑graded. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.02: Use "repeat" to make directions shorter
* T01.G2.15: Match picture instructions to visual block commands





ID: T01.G2.18.01
Topic: T01 – Everyday Algorithms
Skill: Find the mistake in a broken algorithm
Description: Students look at a picture-based algorithm that doesn't work correctly and identify which step is wrong by selecting from picture-based answer choices. Focus is on IDENTIFICATION only - no explanation required at this stage. _Implementation note: MCQ with picture options identifying which step is wrong; auto‑graded. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.14: Fix maze directions that miss the goal





ID: T01.G2.18.02
Topic: T01 – Everyday Algorithms
Skill: Choose why an algorithm doesn't work
Description: After identifying a mistake in an algorithm, students choose from simple picture-based explanations WHY the algorithm doesn't work. Example: "It goes the wrong way" vs "It misses a step" vs "It does steps in wrong order." _Implementation note: MCQ with simple picture+text explanations; auto-graded. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.18.01: Find the mistake in a broken algorithm





ID: T01.G2.19
Topic: T01 – Everyday Algorithms
Skill: Read a simple 3-block script and match to pictures
Description: Students see a simple 3-block script (like: move forward, turn right, move forward) and match it to a picture sequence showing the same actions. **Progression note:** This is the CAPSTONE skill for G2 code reading - students read actual block script format (vertically stacked, like real code) rather than just block images. This bridges picture-based understanding to reading code structure, preparing for Grade 3 coding. _Implementation note: MCQ matching code to pictures; auto-graded. Picture-based matching only - no code writing required. CSTA: E2-ALG-AF-01._

Dependencies:
* T01.G2.17: Identify the action each code block performs
* T01.G2.15: Match picture instructions to visual block commands




ID: T01.G2.20
Topic: T01 – Everyday Algorithms
Skill: Predict what changes if one step is modified
Description: **Student task:** Look at a picture algorithm that works. If we CHANGE one step, predict what will happen differently. **Visual scenario:** Original algorithm: robot at position 1 → "move forward 3 spaces" → ends at position 4. Modified algorithm: robot at position 1 → "move forward 5 spaces" → [?]. Question: "Where will the robot end up now?" Answer choices show positions 4, 5, 6, 7 on a number line. **Correct answer:** position 6. _Implementation note: Side-by-side original/modified comparison with MCQ prediction; builds "what-if" reasoning about algorithms. Picture-based with simple number line. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.08: Trace an algorithm that uses "repeat ___ times"
* T01.G2.11: Trace maze directions on a simple grid



ID: T01.G2.21
Topic: T01 – Everyday Algorithms
Skill: Spot the flaw in a friend's algorithm and explain it
Description: **Student task:** Look at a picture algorithm that a "friend" made. Find the mistake and choose the picture that explains what's wrong. **Visual scenario:** Friend's algorithm for "get ready for bed": put on pajamas → brush teeth → get in bed → turn off light → brush teeth (duplicate!). Students tap the repeated step and choose explanation: (A) "Brushing teeth twice is extra work", (B) "Missing a step", (C) "Wrong order". **Correct answer:** (A). **Skill focus:** CRITIQUE - analyzing others' work to find errors. Builds collaborative debugging mindset. _Implementation note: Error-spotting with explanation MCQ; picture-based throughout. Auto-graded. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.18.02: Choose why an algorithm doesn't work
* T01.G1.12: Explain why one algorithm is better using picture reasoning



ID: T01.G2.22
Topic: T01 – Everyday Algorithms
Skill: Connect everyday decisions to if/then rules
Description: **Student task:** Watch video clips of everyday decisions and match them to if/then rules. **Visual scenario:** Video 1: Person sees red traffic light and stops. Video 2: Child feels rain and opens umbrella. Video 3: Dog hears doorbell and runs to door. Match to rules: "If light is red, then stop", "If it rains, then use umbrella", "If doorbell rings, then go to door". **Skill focus:** Recognizing algorithms in REAL LIFE, not just puzzles. _Implementation note: Video-to-rule matching; shows algorithms exist everywhere. Auto-graded. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T01.G2.06: Choose the best if/then rule for a situation
* T01.GK.11: Find algorithms in everyday activities (video examples)



ID: T01.G2.23
Topic: T01 – Everyday Algorithms
Skill: Change one rule to make an algorithm work differently
Description: **Student task:** Look at a working picture algorithm. Change ONE step to make it do something different (but still work). **Visual scenario:** Original: make orange juice → pour in cup → drink. If we change "orange juice" to "apple juice", we get a different drink! Students select which step to change and what to change it to from options. **Goal:** Get apple juice instead of orange juice. **Skill focus:** ALGORITHM ADAPTATION - understanding that small changes create different outcomes. _Implementation note: Step-selection + replacement MCQ; teaches modification thinking. Auto-graded. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T01.G2.20: Predict what changes if one step is modified
* T01.G2.14: Fix maze directions that miss the goal



ID: T01.G3.00
Topic: T01 – Everyday Algorithms
Skill: Arrange given blocks to match a picture sequence (bridge skill)
Description: **Student task:** Look at a 4-picture sequence showing actions (move, turn, say). Drag 4 given code blocks into the correct order to match the pictures. **This is a BRIDGE skill:** Students don't write new code yet - they only arrange pre-made blocks. **Visual scenario:** Pictures show: (1) cat facing right, (2) cat moves forward, (3) cat turns, (4) cat says "Meow!". Block bank shows: [move 10], [turn 90], [say "Meow!"], [when green flag clicked]. Students arrange: green flag → move → turn → say. _Implementation note: Drag-drop block arrangement from bank; blocks are visual (no typing). Critical bridge from G2 picture-reading to G3 script completion. Auto-graded by sequence match. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T01.G2.19: Read a simple 3-block script and match to pictures
* T01.G2.17: Identify the action each code block performs




ID: T01.G3.01
Topic: T01 – Everyday Algorithms
Skill: Complete a simple script with missing blocks
Description: **Student task:** Look at a script that's almost finished. Add 1 or 2 missing blocks to make it work. **Context:** Start with a mostly built project. Script should do 3-5 simple actions (e.g., move forward twice, turn, say something). _Implementation note: Guided coding in a starter project (mostly pre‑built); auto‑graded via final behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T01.G3.00: Arrange given blocks to match a picture sequence (bridge skill)
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T01.G3.02
Topic: T01 – Everyday Algorithms
Skill: Match a story description to a code sequence
Description: Students choose which of several scripts matches a natural‑language description. _Implementation note: MCQ, code snippets. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T01.G2.17: Identify the action each code block performs





ID: T01.G3.03
Topic: T01 – Everyday Algorithms
Skill: Highlight repeated blocks in a script (no loops)
Description: **Student task:** Examine a short script and highlight which blocks repeat in sequence. The script hasn't been refactored yet (same blocks appear multiple times before being converted to loops). **Visual scenario:** A script drawing a square has "move 50, turn 90" repeated 4 times. Students highlight one occurrence of "move 50, turn 90" to mark the repeating pattern. _Implementation note: Highlight or click region in code; project examples include geometric drawing (square, triangle), simple animation (repeated dance moves), basic movement patterns (zigzag, staircase). CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T04.G2.01: Identify the repeating unit in a longer pattern





ID: T01.G3.04
Topic: T01 – Everyday Algorithms
Skill: Predict how many times repeated blocks run
Description: Students count how many times an action happens based on repeated blocks (e.g., 4× `move 10`) in a concrete behavior (like a character walking), connecting T04's abstract repeat units to meaningful movement or actions. _Implementation note: MCQ; auto‑graded. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T04.G2.01: Identify the repeating unit in a longer pattern





ID: T01.G3.05
Topic: T01 – Everyday Algorithms
Skill: Replace repeated blocks with a repeat loop
Description: Students refactor repeated blocks into a `repeat` loop with the correct count in a small project script (10-15 blocks), using loop patterns first explored in T04.G3.01–G3.02 to improve a real algorithm. _Implementation note: Coding refactor; auto‑graded by structure + behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks





ID: T01.G3.06
Topic: T01 – Everyday Algorithms
Skill: Trace a repeat loop to find total movement
Description: Students trace a script with a `repeat` loop to determine how far a sprite moves or how many actions occur, calculating total distance or rotation. _Implementation note: Tracing + MCQ. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T01.G2.08: Trace an algorithm that uses "repeat ___ times"
* T04.G3.03: Match a "repeat N" loop to repeated behavior
* T07.G3.01: Use a counted repeat loop





ID: T01.G3.07
Topic: T01 – Everyday Algorithms
Skill: Adjust a repeat count to match a pattern
Description: Students change the repeat number so a pattern (e.g., a square, a full spin) completes exactly. _Implementation note: Edit loop count; auto‑graded via final orientation/pattern. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T04.G3.03: Match a "repeat N" loop to repeated behavior
* T07.G3.01: Use a counted repeat loop





ID: T01.G3.08
Topic: T01 – Everyday Algorithms
Skill: Add a simple if/then to a script
Description: Students insert an `if touching [color/sprite]` block to trigger an action. _Implementation note: Coding, scaffolded; auto‑graded by behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T08.G3.04: Use a simple if in a script





ID: T01.G3.09
Topic: T01 – Everyday Algorithms
Skill: Match an if/then script to a behavior description
Description: Students pick which script with if/then matches a described behavior ("When you touch the goal, say 'Yay!'."). _Implementation note: MCQ; auto‑graded. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T08.G3.04: Use a simple if in a script





ID: T01.G3.10
Topic: T01 – Everyday Algorithms
Skill: Trace a script with a single if/then
Description: Students predict whether the if/then block will run in a given situation (with 2-3 possible conditions). _Implementation note: Tracing scenario + MCQ. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T01.G2.07: Trace an algorithm that uses an if/then choice
* T08.G3.04: Use a simple if in a script





ID: T01.G3.11
Topic: T01 – Everyday Algorithms
Skill: Choose the best description of what a short program does
Description: Students read a short script (5-8 blocks) and select the best one-sentence description from 4 options that explains what the script achieves (its goal) and how it achieves it (the key actions). _Implementation note: MCQ with 4 description options; auto-graded. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T07.G3.02: Trace a script with a simple loop





ID: T01.G3.12
Topic: T01 – Everyday Algorithms
Skill: Predict the final state of a simple algorithm
Description: Students trace a script (possibly with a loop) to predict final position or direction. _Implementation note: Grid/orientation MCQ. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T01.G3.13
Topic: T01 – Everyday Algorithms
Skill: Debug a program with steps in the wrong order
Description: Students rearrange blocks in a sequence script to match a given intended behavior. _Implementation note: Coding re‑order; auto‑graded via behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑TR‑03._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T01.G3.14
Topic: T01 – Everyday Algorithms
Skill: Debug a loop that repeats the wrong number of times
Description: Students fix a `repeat` loop that runs too many or too few times by adjusting the loop count so the behavior matches the description. _Implementation note: Coding edit (loop count); auto‑graded via final behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑TR‑03._

Dependencies:
* T01.G2.09: Fix a wrong repeat count in an algorithm
* T07.G3.01: Use a counted repeat loop





ID: T01.G3.15
Topic: T01 – Everyday Algorithms
Skill: Debug an if/then that doesn't trigger when it should
Description: Students fix a simple if/then condition so an action (like saying "Yay!" at the goal) happens at the right time. _Implementation note: Coding edits; auto‑graded with multiple tests. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑TR‑03._

Dependencies:
* T08.G3.04: Use a simple if in a script





ID: T01.G3.16
Topic: T01 – Everyday Algorithms
Skill: Select when to use 'repeat forever' vs 'repeat N times'
Description: **Student task:** Analyze two scripts and select the appropriate loop type for each. **Visual scenario:** Script A needs to run forever (like checking if a key is pressed). Script B needs to run a specific number of times (like drawing a square). Students select which loop type each script should use. _Implementation note: MCQ matching scenarios to loop types; auto‑graded. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T07.G3.02: Trace a script with a simple loop




ID: T01.G3.17
Topic: T01 – Everyday Algorithms
Skill: Form hypothesis about why a program behaves unexpectedly
Description: **Student task:** Watch a program run and observe unexpected behavior. Form a hypothesis about what might be wrong from 3-4 options. **Visual scenario:** A sprite should draw a square but draws a triangle instead. Options: (A) "The repeat count is wrong", (B) "The turn angle is wrong", (C) "The move distance is wrong", (D) "The pen color is wrong". Students select the most likely hypothesis. **Correct answer:** (A) The repeat count is wrong (should be 4, not 3). _Implementation note: First step of debugging - forming a hypothesis before checking code. Builds scientific thinking about programs. MCQ; auto-graded. CSTA: E3‑ALG‑PS‑03, E3‑PRO‑TR‑03._

Dependencies:
* T01.G3.14: Debug a loop that repeats the wrong number of times
* T01.G3.15: Debug an if/then that doesn't trigger when it should



ID: T01.G3.18
Topic: T01 – Everyday Algorithms
Skill: Describe algorithm behavior to someone who can't see the code
Description: **Student task:** Look at a short script (5-8 blocks). Describe what it does in simple sentences WITHOUT showing the code - like explaining to a friend on the phone. **Example:** Script draws a square. Student says/types: "The cat starts in the middle. It moves forward, then turns right. It does this 4 times and draws a square." **Assessment criteria:** (1) mentions key actions, (2) mentions loop/repetition, (3) describes the result. **Skill focus:** ALGORITHM COMMUNICATION - essential for collaboration and code review. _Implementation note: Voice recording or text entry; rubric-graded for completeness and clarity. Uses CreatiCode's speech recognition for voice input. CSTA: E3‑ALG‑AF‑01, E3‑CS‑PC‑01._

Dependencies:
* T01.G3.11: Choose the best description of what a short program does
* T01.GK.10: Explain your sequence choice to a partner using picture cards



ID: T01.G3.19
Topic: T01 – Everyday Algorithms
Skill: Build an algorithm together with a partner (pair programming intro)
Description: **Student task:** Work with a partner to build a simple algorithm. One person is the "Navigator" (gives directions) and one is the "Driver" (places blocks). Switch roles halfway. Build a script that makes a sprite draw a triangle. **Roles:** Round 1: Student A navigates ("Now add a move block"), Student B drives. Round 2: Switch. **Assessment:** Both students complete reflection: "What worked well? What was hard?" **Skill focus:** COLLABORATIVE ALGORITHM DESIGN - introduces pair programming concept. _Implementation note: Partner activity with role cards and reflection prompts; requires two students or can be done with AI partner (CreatiCode XO). Rubric-graded. CSTA: E3‑ALG‑AF‑01, E3‑CS‑PC‑01._

Dependencies:
* T01.G3.01: Complete a simple script with missing blocks
* T01.G3.18: Describe algorithm behavior to someone who can't see the code



ID: T01.G4.00
Topic: T01 – Everyday Algorithms
Skill: Design algorithm steps before writing code
Description: **Student task:** Given a goal description, design the algorithm steps BEFORE opening the code editor. Write 5-8 steps in plain English describing what the program should do. This is a "design-first" skill that separates planning from coding. **Example:** Goal: "Make a sprite walk to a coin, collect it, and celebrate." Student writes: "1. Start at left side of stage. 2. Point toward the coin. 3. Move toward coin until touching it. 4. When touching coin, hide the coin. 5. Say 'Got it!' 6. Do a celebration dance (spin around)." _Implementation note: Text-based planning exercise; emphasizes thinking before coding. Rubric-graded for completeness and logical order. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T01.G3.11: Choose the best description of what a short program does
* T01.G2.13: Write directions to navigate a simple grid




ID: T01.G4.01
Topic: T01 – Everyday Algorithms
Skill: Plan steps for a coded maze or goal‑reach task
Description: **Student task:** Write a numbered list of 5-8 steps in simple sentences (not code) describing what the program should do to reach the flag without touching red walls. **Example:** "1. Start at the green arrow. 2. Move forward 3 squares. 3. Turn right. 4. Move forward 2 squares. 5. Reach the flag." _Implementation note: Extends G4.00 to maze context; arrange/choose steps. Auto-graded or rubric. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T01.G4.00: Design algorithm steps before writing code
* T01.G2.11: Trace maze directions on a simple grid
* T01.G2.12: Choose directions that reach the goal





ID: T01.G4.02.01
Topic: T01 – Everyday Algorithms
Skill: Convert first 2-3 plan steps into code blocks
Description: **Student task:** Given a 5-8 step written plan, implement ONLY the first 2-3 steps as code blocks. Focus on basic movement/action blocks without loops or conditions. **Example:** Plan says "1. Go to start position 2. Move forward 50 steps 3. Turn right 90 degrees". Students build: [go to x:0 y:0] → [move 50] → [turn 90]. _Implementation note: First checkpoint of capstone; auto-graded by position/direction after running first few blocks. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T01.G4.01: Plan steps for a coded maze or goal‑reach task
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




ID: T01.G4.02.02
Topic: T01 – Everyday Algorithms
Skill: Add loop structures to implement repeated plan steps
Description: **Student task:** Extend the code from G4.02.01 by adding loop structures for plan steps that mention repetition. **Example:** Plan step "4. Repeat the move-turn sequence 4 times to draw a square" becomes [repeat 4 [move 50, turn 90]]. _Implementation note: Second checkpoint; focuses on recognizing when plan implies repetition and choosing correct loop count. Auto-graded by behavior. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T01.G4.02.01: Convert first 2-3 plan steps into code blocks
* T07.G3.01: Use a counted repeat loop




ID: T01.G4.02.03
Topic: T01 – Everyday Algorithms
Skill: Add conditional logic to implement plan decision points
Description: **Student task:** Extend the code by adding if/then blocks for plan steps that describe conditions. **Example:** Plan step "5. If touching the goal, say 'You win!'" becomes [if touching Goal then say "You win!"]. _Implementation note: Third checkpoint; focuses on translating "if" language in plans to conditional blocks. Auto-graded by testing both condition paths. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T01.G4.02.02: Add loop structures to implement repeated plan steps
* T08.G3.04: Use a simple if in a script




ID: T01.G4.02.04
Topic: T01 – Everyday Algorithms
Skill: Test and verify complete plan implementation (Capstone)
Description: **CAPSTONE SKILL** - Students complete and test the full plan implementation, verifying that all plan steps work together correctly. Run the program, check if behavior matches the original plan, and fix any mismatches. _Implementation note: Final checkpoint; requires G4.02.01-03 sub-skills completed first. Schedule in Q3-Q4 of Grade 4. Auto-grading checks full behavior matches plan. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T01.G4.02.03: Add conditional logic to implement plan decision points
* T12.G3.01: Test and trace simple block-based scripts





ID: T01.G4.03
Topic: T01 – Everyday Algorithms
Skill: Detect and mark repeating patterns of varying lengths in scripts
Description: **Student task:** Examine scripts of increasing complexity and identify ALL repeating patterns. **Progression within skill:** (1) Find 2-block patterns in 8-10 block scripts, (2) Find 3-block patterns in 12-15 block scripts, (3) Find MULTIPLE different patterns in 15-20 block scripts. **Example progression:** Script 1: "move, turn, move, turn, move, turn" → mark "move, turn". Script 2: "move, turn, color, move, turn, color" → mark "move, turn, color". Script 3: Drawing script with both "move-turn" pattern AND separate "color change" pattern → mark both. **Skill focus:** Pattern recognition at multiple scales - essential for refactoring. _Implementation note: Progressive difficulty within single skill; block highlight selection. Each sub-task auto-graded by region match. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T01.G3.03: Highlight repeated blocks in a script (no loops)
* T07.G3.01: Use a counted repeat loop





ID: T01.G4.04
Topic: T01 – Everyday Algorithms
Skill: Refactor repeated patterns into loops
Description: **Student task:** Take a script with repeated 2-3 block sequences and refactor it to use a repeat loop. The refactored version should produce identical behavior with fewer blocks. **Example:** Convert "move 10, turn 90" repeated 4 times into "repeat 4 [move 10, turn 90]". _Implementation note: Coding refactor task; auto-graded by behavior match AND reduced block count. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T01.G4.03: Detect and mark repeating patterns of varying lengths in scripts
* T07.G3.01: Use a counted repeat loop





ID: T01.G4.05
Topic: T01 – Everyday Algorithms
Skill: Analyze and defend why loop versions are better than explicit repetition
Description: **Student task:** Compare two equivalent scripts side-by-side and build an argument for why one is better. **Part 1 (Analyze):** Identify 3+ differences between loop and no-loop versions: block count, repetition visibility, modifiability. **Part 2 (Defend):** Select and JUSTIFY the best reason why loops are better. Choose from: (A) fewer blocks = less typing, (B) easier to see the pattern, (C) easier to change repeat count, (D) all of the above, with explanation. **Example:** "The loop version is better because if I want to draw a hexagon instead of a square, I only change ONE number (4→6), not FOUR blocks." **Skill focus:** Building ARGUMENTS about code quality, not just identifying differences. _Implementation note: Two-part MCQ with justification; auto-graded. CSTA: E4‑ALG‑IM‑04._

Dependencies:
* T01.G4.04: Refactor repeated patterns into loops
* T07.G3.01: Use a counted repeat loop



## [REMOVED in Phase 9 - G4.05.02 consolidated into G4.05]



ID: T01.G4.06
Topic: T01 – Everyday Algorithms
Skill: Identify and explain the purpose of variables in scripts
Description: **Student task:** Look at a script with sprites, blocks, and variables. Highlight or select which names are variables (not sprite names or block names). **Example:** In a game script, identify "score", "lives", "speed" as variables vs "Cat" (sprite) or "move" (block). _Implementation note: Code-reading with highlight/MCQ selection. Auto-graded. CSTA: E4‑PRO‑DH‑02._

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T01.G4.06.02
Topic: T01 – Everyday Algorithms
Skill: Match variables to their purpose descriptions
Description: **Student task:** Look at a script with 2-3 variables. Match each variable name to a description of what it stores. **Example:** Match "score" → "number of coins collected", "lives" → "how many tries remaining", "speed" → "how fast character moves". _Implementation note: Matching exercise or MCQ; auto-graded. CSTA: E4‑PRO‑DH‑02._

Dependencies:
* T01.G4.06.01: Identify variable names in a script





ID: T01.G4.07
Topic: T01 – Everyday Algorithms
Skill: Trace a counter variable through loop iterations
Description: **Student task:** Follow a script with a counter variable inside a repeat loop. Track the counter value through each iteration and predict its final value. **Example:** "set count to 0, repeat 4 [change count by 1]" → final count = 4. _Implementation note: Tracing table showing value after each iteration + MCQ for final value. Auto-graded. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑DH‑02._

Dependencies:
* T01.G4.06.02: Match variables to their purpose descriptions
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T01.G4.08
Topic: T01 – Everyday Algorithms
Skill: Add a counter variable to an existing program
Description: **Student task:** Add a new variable (e.g., "steps" or "coins") to an existing script and place "change [variable] by 1" in the right location to count events. **Example:** Add a "jumps" counter that increases each time the character jumps. _Implementation note: Coding task in starter project; auto-graded by variable display and correct increment placement. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑DH‑02._

Dependencies:
* T01.G4.07: Trace a counter variable through loop iterations
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T01.G4.09
Topic: T01 – Everyday Algorithms
Skill: Track game state with lives or score variables
Description: **Student task:** Extend a simple game to track lives or score. Add variable that increases when collecting items OR decreases when hitting obstacles. **Example:** "score" starts at 0, increases by 10 when touching coin; "lives" starts at 3, decreases by 1 when touching enemy. _Implementation note: Coding in game starter project; auto-graded by variable updates under test scenarios. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑DH‑02._

Dependencies:
* T01.G4.08: Add a counter variable to an existing program
* T08.G3.04: Use a simple if in a script





ID: T01.G4.10.01
Topic: T01 – Everyday Algorithms
Skill: Trace two variables changing in a loop
Description: **Student task:** Follow a script with TWO variables being updated inside a loop. Track both values through each iteration. **Example:** "repeat 3 [change x by 2, change y by 5]" with x=0, y=0 initially → after loop: x=6, y=15. _Implementation note: Dual-column tracing table + MCQ for final values. Auto-graded. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T01.G4.07: Trace a counter variable through loop iterations
* T07.G3.01: Use a counted repeat loop




ID: T01.G4.10.02
Topic: T01 – Everyday Algorithms
Skill: Trace variables with position and direction changes
Description: **Student task:** Follow a script where variables control sprite position and direction. Trace values through iterations to predict final position. **Example:** "repeat 4 [move x by 10, turn 90]" → predict ending position and direction. _Implementation note: Tracing with visual grid showing position + MCQ. Auto-graded. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T01.G4.10.01: Trace two variables changing in a loop
* T12.G3.01: Test and trace simple block-based scripts





ID: T01.G4.11
Topic: T01 – Everyday Algorithms
Skill: Debug an off-by-one counting error
Description: **Student task:** Fix a counter variable that ends one too high or one too low. Diagnose whether the bug is in (a) initialization (start at 0 vs 1) or (b) loop count (repeat 9 vs 10). **Example:** Counter should end at 10 but ends at 9 - fix by changing "set count to 1" to "set count to 0" OR changing "repeat 9" to "repeat 10". _Implementation note: Coding debug task; auto-graded with test cases checking final counter value. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑TR‑03._

Dependencies:
* T01.G4.10.01: Trace two variables changing in a loop
* T07.G3.01: Use a counted repeat loop
* T12.G3.01: Test and trace simple block-based scripts





ID: T01.G4.12
Topic: T01 – Everyday Algorithms
Skill: Select the better algorithm and explain why
Description: **Student task:** Compare two working algorithms that achieve the same goal. Select which is better and choose the reason from options: (a) fewer blocks/shorter, (b) clearer/easier to understand, (c) uses better structures like loops. _Implementation note: Two-part MCQ: (1) select best algorithm, (2) select explanation. Auto-graded. CSTA: E4‑ALG‑IM‑04._

Dependencies:
* T01.G4.05.02: Select reasons why the loop version is better
* T01.G3.11: Choose the best description of what a short program does





ID: T01.G4.13
Topic: T01 – Everyday Algorithms
Skill: Compare counted loops with condition-based loops
Description: **Student task:** Compare two scripts that achieve similar results. One uses "repeat 10 times" (counted), one uses "repeat until touching edge" (condition-based). Identify when each type is better: counted when you know exact repetitions, condition-based when you need to stop based on a situation. _Implementation note: Side-by-side comparison + MCQ on when to use each type. Auto-graded. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T07.G4.01: Create a forever game loop for controls





ID: T01.G4.14
Topic: T01 – Everyday Algorithms
Skill: Identify inner and outer loops in nested loop scripts
Description: **Student task:** Look at a script with one repeat loop inside another. Identify which is the OUTER loop (runs fewer times, wraps around) and which is the INNER loop (runs more total times, nested inside). **Example:** "repeat 3 [repeat 4 [move 10]]" - outer loop runs 3 times, inner loop runs 12 times total (4×3). _Implementation note: Code reading with highlight selection + MCQ. Auto-graded. CSTA: E4-ALG-AF-01, E4-ALG-PS-03._

Dependencies:
* T01.G4.04: Refactor repeated patterns into loops
* T07.G3.01: Use a counted repeat loop





ID: T01.G4.15
Topic: T01 – Everyday Algorithms
Skill: Add conditional logic based on variable values
Description: **Student task:** Add an if/then block that checks a variable value and triggers an action. **Example:** "if score > 10 then say 'You win!'" or "if lives = 0 then broadcast game-over". _Implementation note: Coding task; auto-graded by testing behavior with different variable values. CSTA: E4-ALG-AF-01, E4-PRO-PF-01._

Dependencies:
* T01.G4.09: Track game state with lives or score variables
* T08.G3.04: Use a simple if in a script





ID: T01.G4.16
Topic: T01 – Everyday Algorithms
Skill: Use console logging to trace algorithm execution
Description: **Student task:** Add console.log statements (using CreatiCode's console panel) to track variable values as an algorithm runs. Predict what the console will show before running, then verify. **Example:** In a counting loop, add "log 'counter is' + counter" inside the loop. Student predicts: "counter is 1, counter is 2, counter is 3..." then runs to verify. **CreatiCode feature:** Uses the Console Panel for logging output. _Implementation note: Introduces systematic tracing with logging; bridges to G7.10 hypothesis testing. Auto-graded by log output matching expected pattern. CSTA: E4‑ALG‑PS‑03, E4‑PRO‑TR‑03._

Dependencies:
* T01.G4.07: Trace a counter variable through loop iterations
* T01.G3.17: Form hypothesis about why a program behaves unexpectedly



ID: T01.G4.17
Topic: T01 – Everyday Algorithms
Skill: Critique a peer's algorithm and suggest improvements
Description: **Student task:** Review a peer's (or sample) algorithm and provide constructive feedback. **Part 1 (Find issues):** Identify 2+ things that could be improved (inefficiency, unclear naming, missing edge case, etc.). **Part 2 (Suggest fixes):** For each issue, suggest a specific improvement. **Example:** Peer's algorithm draws a square with 8 blocks. Critique: "1. You repeat 'move, turn' 4 times separately - use a loop instead. 2. Variable name 'x' doesn't explain what it stores - rename to 'sideLength'." **Skill focus:** CODE REVIEW - essential for collaborative development and learning from others. _Implementation note: Two-part structured response; rubric-graded for constructive criticism and actionable suggestions. CSTA: E4‑ALG‑AF‑01, E4‑CS‑PC‑01._

Dependencies:
* T01.G4.05: Analyze and defend why loop versions are better than explicit repetition
* T01.G3.18: Describe algorithm behavior to someone who can't see the code



ID: T01.G4.18
Topic: T01 – Everyday Algorithms
Skill: Recognize algorithms in apps and games you use
Description: **Student task:** Identify algorithms in familiar apps and games. **Part 1 (Find):** List 3 algorithms you interact with daily (e.g., YouTube recommendations, game enemy movement, calculator operations). **Part 2 (Describe):** For one algorithm, describe what inputs it uses and what outputs it produces. **Example:** "The YouTube recommendation algorithm takes inputs: videos I watched, how long I watched, what I liked. It outputs: a list of suggested videos." **Skill focus:** REAL-WORLD CONNECTION - understanding that algorithms are everywhere, not just in coding class. _Implementation note: Reflection + structured response; rubric-graded. CSTA: E4‑ALG‑IM‑04, E4‑CS‑PC‑01._

Dependencies:
* T01.G2.22: Connect everyday decisions to if/then rules
* T01.G4.00: Design algorithm steps before writing code



ID: T01.G4.19
Topic: T01 – Everyday Algorithms
Skill: Adapt an algorithm to solve a similar but different problem
Description: **Student task:** Take a working algorithm and modify it to solve a related problem. **Example:** Given: algorithm that draws a square (repeat 4: move 50, turn 90). Task: Adapt it to draw a triangle. Student modifies: change "repeat 4" to "repeat 3", change "turn 90" to "turn 120". **Assessment:** (1) Identify what to change, (2) Make correct changes, (3) Verify it works. **Skill focus:** ALGORITHM TRANSFER - applying patterns to new contexts, not just following instructions. _Implementation note: Coding modification task; auto-graded by new behavior matching target. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T01.G4.04: Refactor repeated patterns into loops
* T01.G2.23: Change one rule to make an algorithm work differently


ID: T01.G5.00
Topic: T01 – Everyday Algorithms
Skill: Write algorithm in plain English before flowchart
Description: **Student task:** Given a problem description, write the algorithm in plain English sentences BEFORE creating a flowchart or pseudocode. Focus on clarity and completeness. **Example:** Problem: "Find the largest number in a list." Student writes: "1. Remember the first number as the largest so far. 2. Look at each other number one by one. 3. If the number is bigger than the largest so far, remember it as the new largest. 4. After checking all numbers, the one we remember is the largest." _Implementation note: Emphasizes natural language algorithm design before formal notation. Rubric-graded for logical completeness. CSTA: E5‑ALG‑AF‑01._

Dependencies:
* T01.G4.00: Design algorithm steps before writing code
* T01.G3.11: Choose the best description of what a short program does




ID: T01.G5.01
Topic: T01 – Everyday Algorithms
Skill: Connect a word description to a flowchart
Description: **Student task:** Match everyday‑language descriptions of algorithms to flowcharts. Connect each description to the correct flowchart. **Visual scenario:** 3-4 algorithm descriptions paired with 3-4 flowcharts (with distractors). _Implementation note: MCQ matching applying flowchart symbols from T02. Auto-graded. CSTA: E5‑ALG‑AF‑01._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T02.G3.01: Identify flowchart symbols (start/end, process, decision)
* T02.G4.01: Read a simple flowchart with loops


## T01.G5.02 CONSOLIDATED Structure (Phase 5 Optimization)
## Reduced from 8 sub-skills to 4 focused skills:
## - Two foundation skills (sequential flowchart, sequential pseudocode)
## - Two capstone skills (complex flowchart, complex pseudocode)




ID: T01.G5.02.01
Topic: T01 – Everyday Algorithms
Skill: Convert a sequential flowchart into code
Description: **Student task:** Implement a simple sequential flowchart (5-7 steps, no loops or conditionals) as block-based code. Focus on mapping flowchart rectangles to action blocks. **Example:** Flowchart shows: START → "set score to 0" → "move 50 steps" → "say Hello" → END. Students build matching CreatiCode script. _Implementation note: Foundation skill for flowchart-to-code; auto-graded on behavior matching flowchart. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T01.G5.01: Match a word description to a flowchart
* T06.G3.01: Build a green‑flag script
* T09.G3.03: Use variables in expressions





ID: T01.G5.02.02
Topic: T01 – Everyday Algorithms
Skill: Convert a complex flowchart into code
Description: **Student task:** Implement a flowchart with loops AND conditionals as block-based code for a CreatiCode project. **Example:** Flowchart shows: START → "set lives to 3" → loop diamond "repeat until lives=0" → decision diamond "if touching enemy?" → yes: "change lives by -1" → no: "move 10" → END. Students build matching game loop with conditional logic. _Implementation note: Capstone skill for flowchart-to-code; auto-graded on behavior matching flowchart logic. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T01.G5.02.01: Convert a sequential flowchart into code
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if in a script
* T07.G5.01: Simulate repeated experiments with a loop





## [REMOVED - Consolidated into T01.G5.02.02]





## [REMOVED - Consolidated into T01.G5.02.02]





ID: T01.G5.02.03
Topic: T01 – Everyday Algorithms
Skill: Convert sequential pseudocode into code
Description: **Student task:** Implement simple sequential pseudocode (structured text with action statements) as block-based code. **Example:** Pseudocode shows: "SET x TO 100, MOVE TO x, SAY 'Done!'". Students build: set x to 100, go to x, say "Done!". _Implementation note: Foundation skill for pseudocode-to-code; auto-graded on behavior. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T06.G3.01: Build a green‑flag script
* T02.G4.02: Read pseudocode notation
* T09.G3.03: Use variables in expressions





ID: T01.G5.02.04
Topic: T01 – Everyday Algorithms
Skill: Convert complex pseudocode into code
Description: **Student task:** Implement pseudocode with loops, conditionals, AND variables as block-based code for a CreatiCode project. **Example:** Pseudocode: "SET score TO 0; REPEAT 5 TIMES { IF touching coin THEN SET score TO score + 10; MOVE 20 }". Students build matching script with all three structures. _Implementation note: Capstone skill for pseudocode-to-code; auto-graded on behavior. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T01.G5.02.03: Convert sequential pseudocode into code
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage





## [REMOVED - Consolidated into T01.G5.02.04]





## [REMOVED - Consolidated into T01.G5.02.04]





## T01.G5.03 CONSOLIDATED (Phase 5 Optimization)
## Reduced from 4 sub-skills to 1 focused skill

ID: T01.G5.03
Topic: T01 – Everyday Algorithms
Skill: Convert a program into pseudocode
Description: **Student task:** Rewrite a short CreatiCode program containing loops, conditionals, and variables as structured pseudocode. Use notation: REPEAT N TIMES, IF...THEN...ELSE, SET variable TO value. **Example:** Given script with "repeat 4 [if touching edge then bounce, move 10]", write pseudocode: "REPEAT 4 TIMES { IF touching edge THEN bounce; MOVE 10 }". Focus on clarity for human readers. _Implementation note: Reverse skill from code-reading; builds algorithm documentation skills. Auto-graded for structure and faithfulness to behavior. CSTA: E5‑ALG‑AF‑01, E5‑ALG‑PS‑03._

Dependencies:
* T01.G5.02.04: Convert complex pseudocode into code
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage




## [REMOVED - T01.G5.03.02, T01.G5.03.03, T01.G5.03.04 consolidated into T01.G5.03]





ID: T01.G5.04.01
Topic: T01 – Everyday Algorithms
Skill: Trace a "find the largest" algorithm
Description: Students trace a simple "find the largest value in a list" algorithm and track how the "max" variable changes through the loop. _Implementation note: Tracing table; auto‑graded. CSTA: E5‑ALG‑PS‑03, E5‑PRO‑DH‑02._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T10.G5.01: Understand table structure (rows, columns, cells)
* T02.G5.01: Trace a script with nested loops using debug print





ID: T01.G5.04.02
Topic: T01 – Everyday Algorithms
Skill: Trace a "count matches" algorithm
Description: Students trace a simple "count items that match a condition" algorithm and track how the counter variable changes. _Implementation note: Tracing table; auto‑graded. CSTA: E5‑ALG‑PS‑03, E5‑PRO‑DH‑02._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T10.G5.01: Understand table structure (rows, columns, cells)
* T04.G5.01: Identify and classify counter update patterns in code
* T02.G5.01: Trace a script with nested loops using debug print





ID: T01.G5.05
Topic: T01 – Everyday Algorithms
Skill: Determine whether an algorithm is correct for all inputs
Description: Students apply test cases (including common cases and edge cases) to decide if an algorithm always gives the right answer. _Implementation note: Choose "always works" vs "fails sometimes" with evidence. CSTA: E5‑ALG‑PS‑03._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T08.G3.04: Use a simple if in a script
* T02.G5.01: Trace a script with nested loops using debug print





ID: T01.G5.06
Topic: T01 – Everyday Algorithms
Skill: Compare two algorithms for step counts (efficiency)
Description: Students estimate or count loop iterations and compare efficiency. _Implementation note: Tables + MCQ; auto‑graded. CSTA: E5‑ALG‑PS‑03, E5‑ALG‑IM‑04._

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor





## T01.G5.07 Sub-Skills Structure (Phase 8)
## Debugging edge cases broken into identification + fix

ID: T01.G5.07.01
Topic: T01 – Everyday Algorithms
Skill: Locate why an algorithm fails on an edge case
Description: **Student task:** Given an algorithm that fails on certain inputs, trace through the algorithm with the failing input to locate WHICH step causes the problem. **Example:** A "find maximum" algorithm returns wrong answer for single-item lists. Students trace with input [5] and identify that the loop never runs because it starts at index 1, so the "max" variable keeps its initial value of 0 instead of 5. _Implementation note: Tracing task; auto-graded by identifying correct failing step. CSTA: E5‑ALG‑PS‑03, E5‑PRO‑TR‑03._

Dependencies:
* T01.G5.05: Determine whether an algorithm is correct for all inputs
* T01.G4.16: Use console logging to trace algorithm execution
* T02.G5.01: Trace a script with nested loops using debug print




ID: T01.G5.07.02
Topic: T01 – Everyday Algorithms
Skill: Fix an algorithm's edge case bug
Description: **Student task:** After identifying where an algorithm fails on an edge case, modify the code to handle that case correctly. **Example:** The "find maximum" algorithm fails on single-item lists. Fix by initializing "max" to the first item instead of 0, OR add a special case "if list has 1 item, return that item". _Implementation note: Coding edits; auto-graded with edge case tests. CSTA: E5‑ALG‑PS‑03, E5‑PRO‑TR‑03._

Dependencies:
* T01.G5.07.01: Locate why an algorithm fails on an edge case
* T08.G3.04: Use a simple if in a script





ID: T01.G5.08
Topic: T01 – Everyday Algorithms
Skill: Add checks to handle edge cases proactively
Description: **Student task:** Extend an algorithm to include extra if/then checks for invalid or special inputs PROACTIVELY (before bugs occur). **Example:** Before processing a list, add "if list is empty, say 'No items' and stop". _Implementation note: Coding; test both regular and edge cases. CSTA: E5‑ALG‑PS‑03._

Dependencies:
* T01.G5.07.02: Fix an algorithm's edge case bug
* T08.G3.04: Use a simple if in a script





ID: T01.G5.09
Topic: T01 – Everyday Algorithms
Skill: Explain why algorithm components maintain correctness
Description: **Student task:** Explain why algorithm components (loops and variable updates) ensure the algorithm produces the correct result. **Part 1 (loops):** Explain why a loop is guaranteed to check every item needed (e.g., "The loop starts at the first item and moves through each one until it reaches the end"). **Part 2 (variables):** Explain why variable updates ensure the correct answer (e.g., "The 'max' variable always holds the largest value seen so far, so when the loop ends, it holds the largest of all values"). _Implementation note: Two-part MCQ/structured explanation combining loop completeness and variable invariants. Auto-graded patterns. CSTA: E5‑ALG‑PS‑03._

Dependencies:
* T01.G5.04.01: Trace a "find the largest" algorithm
* T01.G5.04.02: Trace a "count matches" algorithm
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T04.G5.01: Identify and classify counter update patterns in code





## [REMOVED - T01.G5.09.02 consolidated into T01.G5.09]





ID: T01.G5.10
Topic: T01 – Everyday Algorithms
Skill: Rewrite a long algorithm using loops
Description: Students reduce a long, repetitive algorithm to a shorter one using loops to reduce repetition, without changing behavior. _Implementation note: Pseudocode/code refactor; rubric/auto‑graded. CSTA: E5‑ALG‑AF‑01, E5‑ALG‑PS‑03._

Dependencies:
* T06.G3.01
* T07.G3.01
* T10.G3.05
* T10.G4.18





ID: T01.G5.11
Topic: T01 – Everyday Algorithms
Skill: Choose appropriate test cases for an algorithm
Description: Students choose test cases to verify an algorithm works correctly, selecting from options that include normal cases, edge cases, and boundary conditions. _Implementation note: MCQ selecting test cases; auto‑graded for coverage. CSTA: E5‑ALG‑PS‑03._

Dependencies:
* T01.G5.05: Determine whether an algorithm is correct for all inputs
* T02.G5.01: Trace a script with nested loops using debug print





ID: T01.G5.12
Topic: T01 – Everyday Algorithms
Skill: Distinguish between algorithm correctness and efficiency
Description: Students look at two correct algorithms that solve the same problem. Both are correct, but one is faster. Why do we care about efficiency if both work? _Implementation note: MCQ + explanation; auto‑graded. CSTA: E5‑ALG‑IM‑04._

Dependencies:
* T01.G4.12: Explain why one algorithm solution is better than another
* T01.G5.06: Compare two algorithms for step counts (efficiency)
* T03.G5.01: Write a feature list with subtasks for each feature







ID: T01.G5.13
Topic: T01 – Everyday Algorithms
Skill: Identify hidden assumptions in an algorithm
Description: **Student task:** Analyze an algorithm and identify what it ASSUMES to be true that might not always be true. **Example:** A "find winner" algorithm assumes there will always be exactly one highest score. Students identify: "This assumes no ties. What happens if two players have the same score?" Choose from options: (A) algorithm assumes all scores are different, (B) algorithm assumes scores are already sorted, (C) algorithm assumes there's only one player. _Implementation note: MCQ identifying unstated assumptions; builds critical thinking about algorithm limitations. Auto-graded. CSTA: E5‑ALG‑PS‑03, E5‑ALG‑IM‑04._

Dependencies:
* T01.G5.05: Determine whether an algorithm is correct for all inputs
* T01.G5.07: Debug an algorithm that mis-handles a simple edge case



ID: T01.G5.14
Topic: T01 – Everyday Algorithms
Skill: Document algorithm design decisions for future readers
Description: **Student task:** Write documentation explaining WHY an algorithm is designed the way it is, not just WHAT it does. **Required sections:** (1) Purpose - what problem does it solve, (2) Approach - why this method was chosen over alternatives, (3) Limitations - what it doesn't handle, (4) Examples - sample inputs and expected outputs. **Example:** For a "find maximum" algorithm, document: "Purpose: Find largest value in a list. Approach: We compare each item to the current max because this works for any list without sorting first. Limitation: Doesn't handle ties - returns first max if duplicates exist. Example: [3,7,2] returns 7." **Skill focus:** ALGORITHM DOCUMENTATION - essential for professional work and collaboration. _Implementation note: Structured writing task; rubric-graded for completeness and clarity. CSTA: E5‑ALG‑AF‑01, E5‑CS‑PC‑01._

Dependencies:
* T01.G5.00: Write algorithm in plain English before flowchart
* T01.G5.13: Identify hidden assumptions in an algorithm



ID: T01.G5.15
Topic: T01 – Everyday Algorithms
Skill: Merge two partial algorithms into a complete solution
Description: **Student task:** Given two partial algorithms that each solve part of a problem, combine them into a complete solution. **Example:** Algorithm A finds the largest number. Algorithm B counts how many times a value appears. Task: Combine them to find how many times the largest number appears. **Steps:** (1) Run A to find max, (2) Use max as input to B, (3) Return B's count. **Skill focus:** ALGORITHM COMPOSITION - building complex solutions from simpler parts. _Implementation note: Algorithm integration task; auto-graded by correct output for test cases. CSTA: E5‑ALG‑AF‑01, E5‑ALG‑PS‑03._

Dependencies:
* T01.G5.04.01: Trace a "find the largest" algorithm
* T01.G5.04.02: Trace a "count matches" algorithm
* T01.G3.19: Build an algorithm together with a partner (pair programming intro)


ID: T01.G6.01
Topic: T01 – Everyday Algorithms
Skill: Compare efficiency of linear and binary search
Description: Students qualitatively compare linear and binary search on small sorted lists, identifying that binary search uses fewer comparisons by eliminating half the remaining options with each step. _Implementation note: Table showing step-by-step comparisons; auto‑graded. CSTA: MS‑ALG‑AF‑02._

Dependencies:
* T01.G5.04.01: Trace a "find the largest" algorithm





ID: T01.G6.02
Topic: T01 – Everyday Algorithms
Skill: Compare how step counts grow with input size
Description: Students interpret tables/graphs to see which algorithm scales better. _Implementation note: MCQ + explanation. CSTA: MS‑ALG‑AF‑02, MS‑ALG‑PS‑05._

Dependencies:
* T01.G5.06: Compare two algorithms for step counts (efficiency)





ID: T01.G6.03
Topic: T01 – Everyday Algorithms
Skill: Spot unnecessary work in an algorithm
Description: Students highlight lines where an algorithm keeps working after the result is found. _Implementation note: Code highlight; auto‑graded. CSTA: MS‑ALG‑AF‑01._

Dependencies:
* T06.G5.01: Build a green‑flag script that runs a 3–5 block sequence
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)





ID: T01.G6.04
Topic: T01 – Everyday Algorithms
Skill: Revise an algorithm to do less work
Description: Students remove redundant checks/loops without changing output. _Implementation note: Pseudocode/coding edit; auto‑graded on correctness + fewer steps. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑05._

Dependencies:
* T01.G6.03: Spot unnecessary work in an algorithm
* T07.G5.01: Use a counted repeat loop
* T08.G5.02: Use a simple if in a script





## T01.G6.05 Sub-Skills Structure (Phase 8)
## Algorithm fairness broken into identification + impact analysis

ID: T01.G6.05.01
Topic: T01 – Everyday Algorithms
Skill: Identify which groups a decision algorithm affects differently
Description: **Student task:** Analyze a decision algorithm and identify which groups of people might be treated differently. **Example:** A "homework helper recommendation" algorithm uses past grades. Students identify: Group A (students with high past grades) get more recommendations, Group B (students with low past grades, possibly due to past illness) get fewer. _Implementation note: Scenario MCQ identifying affected groups. CSTA: MS‑ALG‑IM‑08. AI4K12: Ethical design (D)._

Dependencies:
* T01.G5.13: Identify hidden assumptions in an algorithm




ID: T01.G6.05.02
Topic: T01 – Everyday Algorithms
Skill: Analyze the impact of algorithmic bias on different groups
Description: **Student task:** After identifying groups affected differently, analyze whether the different treatment is fair or harmful. **Example:** The homework helper algorithm helps students who are already doing well, but doesn't help struggling students who might need it most. Is this fair? Students select and justify. _Implementation note: MCQ with justification; builds on G6.05.01 identification. CSTA: MS‑ALG‑IM‑08. AI4K12: Societal impacts (E)._

Dependencies:
* T01.G6.05.01: Identify which groups a decision algorithm affects differently





ID: T01.G6.06
Topic: T01 – Everyday Algorithms
Skill: Propose changes to make a decision algorithm more fair
Description: **Student task:** After analyzing algorithmic bias, propose specific changes to make the algorithm more fair. **Example:** For a homework helper algorithm that favors high-performing students, propose: "Include recent improvement as a factor, not just past grades" or "Give extra recommendations to students with declining grades." _Implementation note: Structured response; auto‑graded by alignment with identified issue. CSTA: MS‑ALG‑IM‑09. AI4K12: Ethical design (D), Societal impacts (E)._

Dependencies:
* T01.G6.05.02: Analyze the impact of algorithmic bias on different groups





ID: T01.G6.07
Topic: T01 – Everyday Algorithms
Skill: Design a flowchart for a multi‑step program
Description: Students design a flowchart for a game turn (ask, check, update score, continue/stop), building on the flowchart symbols, loops, and decisions practiced in T02 up through Grade 6. _Implementation note: Flowchart design tied to a concrete game scenario; rubric. CSTA: MS‑ALG‑AF‑01._

Dependencies:
* T01.G5.01: Match a word description to a flowchart
* T07.G5.01: Use a counted repeat loop
* T08.G5.02: Use a simple if in a script
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)





ID: T01.G6.08
Topic: T01 – Everyday Algorithms
Skill: Implement code from a detailed flowchart
Description: **Student task:** Implement a detailed flowchart with 3+ decision points and nested loops as working CreatiCode code. This extends the simpler flowchart-to-code skills from Grade 5 to more complex, multi-path algorithms typical of complete game turns. **Example:** Flowchart shows game loop with health checks, enemy collision detection, score updates, and win/lose conditions. Students translate each flowchart element into corresponding blocks. _Implementation note: Coding; auto‑graded structure + tests, assumes prior diagram‑to‑code practice from T02.G6.05. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑PF‑01._

Dependencies:
* T01.G5.02.02: Convert a complex flowchart into code
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)







ID: T01.G6.09
Topic: T01 – Everyday Algorithms
Skill: Trace algorithm with early exit optimization
Description: **Student task:** Trace an algorithm that includes an "early exit" (stops searching once the answer is found instead of checking everything). Compare step counts with and without early exit. **Example:** Linear search that returns immediately when target is found vs. search that always checks all items. Students trace both versions with target at position 3 of 10 items. Early exit: 3 steps. Full search: 10 steps. _Implementation note: Side-by-side tracing with step counter; MCQ on which is more efficient. Auto-graded. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑05._

Dependencies:
* T01.G6.03: Spot unnecessary work in an algorithm
* T01.G6.04: Revise an algorithm to do less work




ID: T01.G6.10
Topic: T01 – Everyday Algorithms
Skill: Design test suite covering normal, edge, and boundary cases
Description: **Student task:** Given an algorithm description, design a complete test suite that includes: (1) normal/typical inputs, (2) edge cases (empty, single item, maximum size), (3) boundary conditions (values at limits). **Example:** For a "find largest" algorithm, design tests: normal: [5,2,8,1], edge: [], [7], boundary: [0,0,0], [-999, 999]. Students select or write test cases that provide good coverage. _Implementation note: Test suite design with checklist for coverage types. Auto-graded for inclusion of each category. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11._

Dependencies:
* T01.G5.11: Choose appropriate test cases for an algorithm
* T01.G5.13: Identify hidden assumptions in an algorithm




ID: T01.G6.11
Topic: T01 – Everyday Algorithms
Skill: Analyze algorithm transparency (can users understand decisions?)
Description: **Student task:** Evaluate whether an algorithm's decisions can be explained to the people affected by it. **Example:** A "recommend homework help" algorithm uses 5 hidden factors to suggest tutoring. Students analyze: Can a student understand WHY they were recommended tutoring? What information would make the decision clearer? Select from options describing transparency improvements. _Implementation note: Scenario-based MCQ with transparency evaluation rubric. Auto-graded. CSTA: MS‑ALG‑IM‑08, MS‑ALG‑IM‑09. AI4K12: Societal impacts (E)._

Dependencies:
* T01.G6.05: Identify who is favored or harmed by a decision algorithm
* T01.G6.06: Suggest a change to make a decision algorithm more fair




ID: T01.G6.12
Topic: T01 – Everyday Algorithms
Skill: Classify algorithms into pattern families (vocabulary building)
Description: **Student task:** Learn to name and recognize the four main algorithm pattern families: (1) **Search** - finding items that match criteria, (2) **Sort** - arranging items in order, (3) **Accumulation** - collecting/counting/summing through data, (4) **Simulation** - modeling real-world processes over time. Match algorithm descriptions to their family. **Example:** "Find the oldest student" → Search. "Put names in alphabetical order" → Sort. "Count red items" → Accumulation. "Model a bouncing ball" → Simulation. _Implementation note: Vocabulary-building MCQ with 8-10 algorithm examples; prepares for G7.01 pattern identification in code. Auto-graded. CSTA: MS‑ALG‑AF‑01._

Dependencies:
* T01.G5.04.01: Trace a "find the largest" algorithm
* T01.G5.04.02: Trace a "count matches" algorithm
* T01.G6.02: Compare how step counts grow with input size




ID: T01.G6.13
Topic: T01 – Everyday Algorithms
Skill: Build algorithm visualization using stage display
Description: **Student task:** Create a visual representation of an algorithm running using CreatiCode's stage display features. Display variable values, show loop iterations with sprites, or animate data movement. **Example:** For a "find maximum" algorithm, create sprites representing list items, highlight the current item being checked in yellow, highlight the current maximum in green. As the algorithm runs, students see the comparison happening visually. **CreatiCode features:** Uses variable monitors, sprite movement, costume changes, and say blocks to visualize algorithm state. _Implementation note: Coding task combining algorithm understanding with visualization design. Auto-graded by visual correctness + algorithm behavior. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑PF‑02._

Dependencies:
* T01.G6.09: Trace algorithm with early exit optimization
* T01.G5.04.01: Trace a "find the largest" algorithm
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)



ID: T01.G6.14
Topic: T01 – Everyday Algorithms
Skill: Verify AI-generated algorithm suggestions before using them
Description: **Student task:** Given an algorithm suggestion from an AI assistant (like CreatiCode XO), verify it works correctly before adopting it. **Steps:** (1) Read the suggested algorithm carefully, (2) Trace through it with 2-3 test cases (including edge cases), (3) Identify any bugs or issues, (4) Decide: use as-is, modify, or reject. **Example:** AI suggests a sorting algorithm. Student tests with: empty list (works), one item (works), items with duplicates (fails - duplicates disappear!). Student rejects or modifies the suggestion. **Skill focus:** AI VERIFICATION - critical skill as AI tools become common. Never blindly trust AI output! _Implementation note: Multi-step verification task; auto-graded by correct identification of AI errors. Uses CreatiCode XO for realistic AI suggestions. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11. AI4K12: Human-AI partnership._

Dependencies:
* T01.G6.10: Design test suite covering normal, edge, and boundary cases
* T01.G5.07.01: Locate why an algorithm fails on an edge case
* T01.G4.17: Critique a peer's algorithm and suggest improvements



ID: T01.G6.15
Topic: T01 – Everyday Algorithms
Skill: Analyze algorithms behind recommendation systems
Description: **Student task:** Understand how recommendation algorithms work in systems you use daily. **Part 1 (Deconstruct):** For a given recommendation system (YouTube, Spotify, Amazon), identify: what inputs does it use? what outputs does it produce? **Part 2 (Analyze):** Trace how changing one input might change recommendations. **Example:** "If I watch 5 cooking videos, YouTube will recommend more cooking videos because its algorithm assumes I like what I watch recently." **Part 3 (Evaluate):** Discuss one benefit and one concern about recommendation algorithms. **Skill focus:** UNDERSTANDING REAL-WORLD ALGORITHMS that affect daily life. _Implementation note: Structured analysis with scenario exploration; rubric-graded. CSTA: MS‑ALG‑IM‑08. AI4K12: Societal impacts (E)._

Dependencies:
* T01.G6.11: Analyze algorithm transparency (can users understand decisions?)
* T01.G4.18: Recognize algorithms in apps and games you use



ID: T01.G6.16
Topic: T01 – Everyday Algorithms
Skill: Extend an algorithm to handle new requirements
Description: **Student task:** Take a working algorithm and extend it to handle a new requirement WITHOUT breaking existing functionality. **Example:** Given: algorithm that finds largest number in a list. New requirement: also return WHERE the largest number is (its position). Student extends algorithm to track position while finding maximum. **Assessment:** (1) Original tests still pass, (2) New tests for position work, (3) Code is clean (not duplicated). **Skill focus:** ALGORITHM EXTENSION - modifying existing code safely, a key professional skill. _Implementation note: Coding extension task; auto-graded by both original and new test cases. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑TR‑11._

Dependencies:
* T01.G6.09: Trace algorithm with early exit optimization
* T01.G4.19: Adapt an algorithm to solve a similar but different problem


ID: T01.G7.01
Topic: T01 – Everyday Algorithms
Skill: Identify the pattern family in a given program
Description: **Student task:** Look at code and categorize it as search, sort, accumulation, or simulation based on its structure and purpose. **Example:** Code with "for each item, if item > max, set max = item" → Search (finding max). Code with "for each item, add item to total" → Accumulation. _Implementation note: MCQ; builds on G6.12 vocabulary by applying to actual code. Auto‑graded. CSTA: MS‑ALG‑AF‑01._

Dependencies:
* T01.G6.12: Classify algorithms into pattern families (vocabulary building)
* T01.G6.02: Compare how step counts grow with input size
* T08.G5.02: Use conditional logic to analyze different cases in pattern identification





ID: T01.G7.02
Topic: T01 – Everyday Algorithms
Skill: Choose a pattern to solve a problem
Description: Students pick which algorithm pattern is best for a described task. _Implementation note: MCQ; auto‑graded. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑06._

Dependencies:
* T01.G7.01: Identify the pattern in a given program





ID: T01.G7.03.01
Topic: T01 – Everyday Algorithms
Skill: Write pseudocode for a "find max" search algorithm
Description: Students write structured pseudocode for "find the largest value in a list." _Implementation note: Guided pseudocode; auto‑graded structure. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑PF‑02._

Dependencies:
* T01.G5.04.01: Trace a "find the largest" algorithm
* T04.G5.03: Identify linear search patterns in code
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T10.G5.03: Finding max requires searching through a list or collection of values.





ID: T01.G7.03.02
Topic: T01 – Everyday Algorithms
Skill: Write pseudocode for a "count matches" accumulation algorithm
Description: Students write structured pseudocode for "count items that match a condition." _Implementation note: Guided pseudocode; auto‑graded structure. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑PF‑02._

Dependencies:
* T01.G5.04.02: Trace a "count matches" algorithm
* T04.G5.03: Identify linear search patterns in code
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T08.G5.02: Counting matches requires conditional logic to determine what counts as a match.





ID: T01.G7.04
Topic: T01 – Everyday Algorithms
Skill: Compare efficiency of two algorithms qualitatively
Description: Students reason which algorithm scales better as inputs grow. _Implementation note: Scenario + MCQ + explanation. CSTA: MS‑ALG‑AF‑02, MS‑ALG‑PS‑05._

Dependencies:
* T01.G5.06: Compare two algorithms for step counts (efficiency)
* T01.G6.02: Compare how step counts grow with input size
* T08.G5.02: Algorithm comparison requires conditional reasoning about different scenarios.





ID: T01.G7.05
Topic: T01 – Everyday Algorithms
Skill: Design a set of edge‑case tests for an algorithm
Description: Students pick tests (including edge cases) that give high confidence the algorithm works. _Implementation note: Choose tests from list; auto‑graded for coverage. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11._

Dependencies:
* T01.G5.11: Choose appropriate test cases for an algorithm
* T10.G5.01: Test sets are organized as lists of test cases.





ID: T01.G7.06
Topic: T01 – Everyday Algorithms
Skill: Run an algorithm on edge cases and find failures
Description: Students test algorithms on tricky inputs and flag those that fail. _Implementation note: MCQ/interactive; auto‑graded. CSTA: MS‑ALG‑PS‑05._

Dependencies:
* T01.G7.05: Design a set of edge‑case tests for an algorithm





ID: T01.G7.07
Topic: T01 – Everyday Algorithms
Skill: Explain why an algorithm fails on a specific edge case
Description: Students explain which step causes the failure and why. _Implementation note: Structured explanation; auto‑graded patterns. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11._

Dependencies:
* T01.G7.06: Run an algorithm on edge cases and find failures
* T08.G5.02: Apply conditional logic to understand boundary conditions and logic failures in edge cases





ID: T01.G7.08
Topic: T01 – Everyday Algorithms
Skill: Rewrite a naive algorithm using a better pattern
Description: Students replace repeated naive logic with a cleaner pattern (single loop, flag, etc.). _Implementation note: Pseudocode/coding refactor; rubric. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑06._

Dependencies:
* T01.G7.02: Choose a pattern to solve a problem
* T04.G5.03: Identify linear search patterns in code
* T07.G5.01: Use a counted repeat loop







ID: T01.G7.09
Topic: T01 – Everyday Algorithms
Skill: Analyze algorithm scalability with data tables
Description: **Student task:** Given step count data for different input sizes, determine how an algorithm scales. Fill in a table predicting step counts for larger inputs. **Example:** Algorithm A: size 10→100 steps, size 20→200 steps, size 40→? Algorithm B: size 10→100 steps, size 20→400 steps, size 40→? Students identify A as linear (400 steps) and B as quadratic (1600 steps). _Implementation note: Table completion with pattern recognition; introduces informal Big-O thinking. Auto-graded. CSTA: MS‑ALG‑AF‑02, MS‑ALG‑PS‑05._

Dependencies:
* T01.G6.02: Compare how step counts grow with input size
* T01.G7.04: Compare efficiency of two algorithms qualitatively




ID: T01.G7.10
Topic: T01 – Everyday Algorithms
Skill: Debug algorithm with systematic hypothesis testing
Description: **Student task:** Debug an algorithm using systematic hypothesis testing: (1) form hypothesis about the bug, (2) design a test to confirm/reject, (3) run test, (4) refine hypothesis. **Example:** A sorting algorithm fails on some inputs. Students test hypotheses: "fails on empty lists" (test: [] → works), "fails on duplicates" (test: [3,3,1] → fails!), then fix the duplicate-handling bug. _Implementation note: Multi-step debugging with hypothesis-test-refine cycle; builds scientific debugging mindset. Auto-graded through test case selection and fix verification. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11._

Dependencies:
* T01.G7.06: Run an algorithm on edge cases and find failures
* T01.G7.07: Explain why an algorithm fails on a specific edge case




ID: T01.G7.11
Topic: T01 – Everyday Algorithms
Skill: Trace state changes in a multi-variable update loop (simulation precursor)
Description: **Student task:** Trace a loop that updates multiple related variables each iteration, predicting values after N steps. This is the foundation for simulation thinking. **Example:** A simple "bouncing ball" simulation loop: each step, position += velocity, and if position > boundary then velocity = -velocity. Students trace 5 steps showing position and velocity values, identifying when the "bounce" happens. _Implementation note: Tracing table with 2-3 variables; bridges G6 nested loops to G8 simulation design. Critical prereq for G8.01. Auto-graded. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑05._

Dependencies:
* T01.G6.12: Classify algorithms into pattern families (vocabulary building)
* T07.G6.01: Trace nested loops with variable bounds
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)



ID: T01.G7.12
Topic: T01 – Everyday Algorithms
Skill: Present algorithm trade-offs to stakeholders
Description: **Student task:** Prepare and deliver a presentation comparing 2-3 algorithm options for a given problem, explaining trade-offs in terms stakeholders can understand. **Scenario:** You're helping the school decide on a fair way to assign lunch tables. Present 3 algorithms: (A) random assignment, (B) rotating schedule, (C) student preference matching. For each, explain: speed to implement, fairness, student satisfaction, complexity. **Deliverable:** Slide deck or oral presentation with recommendation. **Skill focus:** ALGORITHM COMMUNICATION TO NON-PROGRAMMERS - essential for real-world impact. _Implementation note: Presentation task with rubric for clarity, completeness, and audience-appropriate language. Uses CreatiCode's text-to-speech for practice. CSTA: MS‑ALG‑IM‑04, MS‑CS‑PC‑01._

Dependencies:
* T01.G7.04: Compare efficiency of two algorithms qualitatively
* T01.G5.14: Document algorithm design decisions for future readers



ID: T01.G7.13
Topic: T01 – Everyday Algorithms
Skill: Design algorithm as a team with role assignments
Description: **Student task:** Work in a team of 3-4 to design an algorithm, with each person taking a specific role. **Roles:** (1) Requirements - defines what problem to solve and constraints, (2) Designer - creates algorithm structure, (3) Implementer - writes the code, (4) Tester - creates test cases and verifies. **Process:** Rotate through roles for different problems. Reflect on how roles work together. **Example project:** Build a "fair team picker" algorithm. **Skill focus:** COLLABORATIVE ALGORITHM DEVELOPMENT - mimics real software teams. _Implementation note: Group project with role rotation; requires 3-4 students or simulated with AI partners. Rubric-graded for collaboration and deliverables. CSTA: MS‑ALG‑AF‑01, MS‑CS‑PC‑01._

Dependencies:
* T01.G5.15: Merge two partial algorithms into a complete solution
* T01.G6.14: Verify AI-generated algorithm suggestions before using them


ID: T01.G8.01
Topic: T01 – Everyday Algorithms
Skill: Design one‑step update rules for a simple simulation
Description: **Student task:** Specify how state variables change in one timestep of a simulation. Given a description of what should happen (e.g., "ball falls due to gravity, bounces off floor"), write the update rules. **Example:** "Each step: velocity += gravity, position += velocity, if position < 0 then position = 0 and velocity = -velocity * 0.8". _Implementation note: Code/pseudocode blanks; builds on G7.11 tracing. Auto‑graded. CSTA: MS‑ALG‑AF‑01, DAA‑DI. AI4K12: Modeling (B)._

Dependencies:
* T01.G7.11: Trace state changes in a multi-variable update loop (simulation precursor)
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds





ID: T01.G8.02
Topic: T01 – Everyday Algorithms
Skill: Interpret the behavior of a simulation algorithm over time
Description: Students explain what happens to variables after several steps. _Implementation note: Code + graph reading; MCQ/short answer. CSTA: MS‑ALG‑AF‑02, DAA‑DI. AI4K12: Modeling (B)._

Dependencies:
* T01.G8.01: Design one‑step update rules for a simple simulation
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T07.G6.01: Trace nested loops with variable bounds
* T12.G6.01: Trace complex code with multiple variables





ID: T01.G8.03
Topic: T01 – Everyday Algorithms
Skill: Compare two simulations with slightly different rules
Description: Students explain how changed rules affect outcomes. _Implementation note: Side‑by‑side comparison + explanation. CSTA: MS‑ALG‑AF‑02, DAA‑DI. AI4K12: Modeling (B)._

Dependencies:
* T01.G8.02: Interpret the behavior of a simulation algorithm over time
* T07.G6.01: Trace nested loops with variable bounds





ID: T01.G8.04
Topic: T01 – Everyday Algorithms
Skill: Identify base case and recursive step in an algorithm description
Description: Students highlight base case and recursive step in a **natural‑language** description of a recursive process, keeping recursion **concept‑only** (no code blocks). **Concrete example:** Students see a story about counting nested boxes: "To count all boxes: if there are no boxes inside, count is 1 (base case). Otherwise, count this box plus count all boxes inside (recursive step)." Students identify which sentence is the base case and which is the recursive step. _Implementation note: MCQ/highlight; auto‑graded. CSTA: MS‑ALG‑PS‑07._

Dependencies:
* T01.G7.11: Trace state changes in a multi-variable update loop (simulation precursor)
* T03.G6.01: Propose a module hierarchy for a medium project





ID: T01.G8.05
Topic: T01 – Everyday Algorithms
Skill: Trace a conceptual recursive algorithm on small inputs
Description: Students step through a **diagram or story version** of recursion for small inputs, marking each call/return to show how the answer is built, without writing or reading recursive code. **Concrete example:** Given "To find the sum of numbers 1 to N: if N=1, sum is 1; otherwise, sum is N plus sum(1 to N-1)." Trace sum(3): sum(3)=3+sum(2), sum(2)=2+sum(1), sum(1)=1, then return: 1→3→6. Students fill in a visual call/return diagram. _Implementation note: Tracing table with call stack visualization; auto‑graded. CSTA: MS‑ALG‑PS‑07._

Dependencies:
* T01.G8.04: Identify base case and recursive step in an algorithm description
* T01.G7.11: Trace state changes in a multi-variable update loop (simulation precursor)





ID: T01.G8.06
Topic: T01 – Everyday Algorithms
Skill: Analyze who is helped or harmed by a real‑world algorithm
Description: Students identify stakeholders and impacts of a real‑world algorithm. _Implementation note: Scenario with MCQ + short answers. CSTA: MS‑ALG‑IM‑08. AI4K12: Ethical design (D), Societal impacts (E)._

Dependencies:
* T32.G6.04: Apply ethics lenses (beneficence, fairness, autonomy)





ID: T01.G8.07
Topic: T01 – Everyday Algorithms
Skill: Propose changes to make a real‑world algorithm more fair
Description: Students propose specific mitigations based on identified harms. _Implementation note: Structured responses; auto‑graded alignment. CSTA: MS‑ALG‑IM‑09. AI4K12: Ethical design (D), Societal impacts (E)._

Dependencies:
* T01.G8.06: Analyze who is helped or harmed by a real‑world algorithm
* T07.G6.01: Trace nested loops with variable bounds





## T01.G8.08 Sub-Skills Structure
## Refactoring for clarity broken into focused sub-skills:
## .01 - Extract helper blocks (modularization)
## .02 - Remove duplicate code
## .03 - Apply meaningful names

ID: T01.G8.08.01
Topic: T01 – Everyday Algorithms
Skill: Extract helper blocks from a medium-sized program
Description: Students identify repeated or complex code sections and reorganize them into named helper blocks (custom blocks/procedures), improving code organization and reusability. _Implementation note: Coding refactor; auto-graded via behavior preservation + structure check for helper block usage. CSTA: MS‑PRO‑TR‑11._

Dependencies:
* T01.G7.08: Rewrite a naive algorithm using a better pattern
* T03.G6.01: Propose a module hierarchy for a medium project




ID: T01.G8.08.02
Topic: T01 – Everyday Algorithms
Skill: Remove duplicate code in a medium-sized program
Description: Students identify code that appears multiple times and consolidate it using loops or helper blocks, ensuring the program does the same thing with less repetition. _Implementation note: Coding refactor; auto-graded via behavior preservation + reduced block count. CSTA: MS‑PRO‑TR‑11._

Dependencies:
* T01.G8.08.01: Extract helper blocks from a medium-sized program
* T07.G3.01: Use a counted repeat loop




ID: T01.G8.08.03
Topic: T01 – Everyday Algorithms
Skill: Apply meaningful names to variables and blocks
Description: Students rename variables and custom blocks to use clear, descriptive names that explain their purpose (e.g., "playerScore" instead of "x", "moveToGoal" instead of "myBlock1"). _Implementation note: Coding refactor; auto-graded via behavior preservation + naming rubric. CSTA: MS‑PRO‑TR‑11._

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T03.G6.01: Propose a module hierarchy for a medium project




ID: T01.G8.08.04
Topic: T01 – Everyday Algorithms
Skill: Refactor a medium-sized program for overall clarity
Description: Students apply all three clarity refactoring techniques (helper blocks, removing duplication, meaningful names) to improve a medium-sized program's readability and maintainability. This is the culminating skill for clarity refactoring. _Implementation note: Coding refactor; auto‑graded via behavior + structure. CSTA: MS‑PRO‑TR‑11._

Dependencies:
* T01.G8.08.01: Extract helper blocks from a medium-sized program
* T01.G8.08.02: Remove duplicate code in a medium-sized program
* T01.G8.08.03: Apply meaningful names to variables and blocks
* T02.G6.01: Use the pseudocode generation block
* T08.G6.01: Use conditionals in physics simulations





ID: T01.G8.09
Topic: T01 – Everyday Algorithms
Skill: Refactor a medium‑sized program for efficiency
Description: Students make local changes (e.g., break loops early, avoid unnecessary recomputation) to reduce work. _Implementation note: Coding edits; auto‑graded for unchanged outputs and fewer steps. CSTA: MS‑ALG‑PS‑05, MS‑PRO‑TR‑11._

Dependencies:
* T01.G6.04: Revise an algorithm to do less work
* T07.G3.01: Use a counted repeat loop
* T03.G6.01: Propose a module hierarchy for a medium project
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds





ID: T01.G8.10
Topic: T01 – Everyday Algorithms
Skill: Use logging/probes to analyze algorithm behavior
Description: Students insert logs or display statements at key points and use them to answer questions about an algorithm's internal behavior. _Implementation note: Coding + reading logs; auto‑graded. CSTA: MS‑ALG‑PS‑07, MS‑PRO‑TR‑11._

Dependencies:
* T01.G7.08: Rewrite a naive algorithm using a better pattern
* T04.G6.01: Group snippets by underlying algorithm pattern



ID: T01.G8.11
Topic: T01 – Everyday Algorithms
Skill: Design algorithm for ambiguous real-world problem
Description: **Student task:** Given an ambiguous real-world problem description, identify what clarifications are needed before designing an algorithm, then create a solution. **Example:** "Make a fair team picker." Students identify ambiguities: "What makes it 'fair'? Equal team sizes? Balanced skill levels? Random?" Then design algorithm for their chosen interpretation. _Implementation note: Two-part task: (1) identify 3+ ambiguities, (2) design algorithm for clarified problem. Rubric-graded for completeness. CSTA: MS‑ALG‑AF‑01, MS‑ALG‑PS‑06. AI4K12: Problem framing._

Dependencies:
* T01.G8.01: Design one-step update rules for a simple simulation
* T01.G8.06: Analyze who is helped or harmed by a real-world algorithm




ID: T01.G8.12
Topic: T01 – Everyday Algorithms
Skill: Evaluate algorithm trade-offs (speed vs memory vs clarity)
Description: **Student task:** Compare algorithms along multiple dimensions (speed, memory usage, code clarity) and justify which is best for a given context. **Example:** Three sorting algorithms: A is fast but uses extra memory, B is slow but in-place, C is moderate speed and clear code. For a phone app with limited memory, which is best? Students analyze trade-offs and justify choice. _Implementation note: Multi-criteria comparison with context-dependent best answer. MCQ + justification. CSTA: MS‑ALG‑AF‑02, MS‑ALG‑PS‑05._

Dependencies:
* T01.G7.04: Compare efficiency of two algorithms qualitatively
* T01.G8.09: Refactor a medium-sized program for efficiency




ID: T01.G8.13
Topic: T01 – Everyday Algorithms
Skill: Decompose complex problem into sub-algorithms
Description: **Student task:** Break down a complex problem into 3-5 sub-problems, each requiring its own algorithm. Describe the inputs/outputs of each sub-algorithm and how they connect. **Example:** "Build a multiplayer quiz game" decomposes into: (1) generate questions, (2) handle player input, (3) score answers, (4) track turns, (5) determine winner. Students create a dependency diagram showing data flow between sub-algorithms. _Implementation note: Problem decomposition with sub-algorithm interface design. Rubric-graded. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑PF‑02. Prepares for modular design._

Dependencies:
* T01.G8.08.04: Refactor a medium-sized program for overall clarity
* T03.G6.01: Propose a module hierarchy for a medium project



ID: T01.G8.14
Topic: T01 – Everyday Algorithms
Skill: Lead code review for peer's algorithm implementation
Description: **Student task:** Conduct a structured code review of a peer's algorithm implementation, providing actionable feedback. **Review checklist:** (1) Does it solve the stated problem? (2) Are there edge cases it misses? (3) Is the code readable and well-named? (4) Could efficiency be improved? (5) Are there potential bugs? **Deliverable:** Written review with 3+ specific suggestions and at least 1 positive observation. **Skill focus:** CODE REVIEW LEADERSHIP - giving constructive feedback that helps others improve. _Implementation note: Peer review activity; can use sample code if no peer available. Rubric-graded for thoroughness and constructiveness. CSTA: MS‑ALG‑PS‑05, MS‑CS‑PC‑01._

Dependencies:
* T01.G6.14: Verify AI-generated algorithm suggestions before using them
* T01.G4.17: Critique a peer's algorithm and suggest improvements



ID: T01.G8.15
Topic: T01 – Everyday Algorithms
Skill: Coordinate multi-person algorithm development
Description: **Student task:** Lead a team developing a complex algorithm, coordinating work across multiple contributors. **Responsibilities:** (1) Divide algorithm into independent pieces, (2) Assign pieces to team members, (3) Define interfaces between pieces, (4) Integrate and test combined solution, (5) Resolve conflicts when pieces don't fit. **Example project:** Build a multiplayer game with separate algorithms for: player movement, collision detection, scoring, game state. Each team member builds one piece; leader coordinates integration. **Skill focus:** PROJECT COORDINATION - essential for larger software projects. _Implementation note: Team project requiring 3-4 students; can simulate with role-play. Rubric-graded for coordination quality. CSTA: MS‑ALG‑AF‑01, MS‑CS‑PC‑01._

Dependencies:
* T01.G7.13: Design algorithm as a team with role assignments
* T01.G8.13: Decompose complex problem into sub-algorithms



ID: T01.G8.16
Topic: T01 – Everyday Algorithms
Skill: Refactor legacy algorithm to meet new constraints
Description: **Student task:** Take an old, working algorithm and refactor it to meet new constraints (e.g., must run faster, use less memory, handle new input types) while preserving correct behavior. **Example:** Legacy search algorithm works but is slow for large lists. New constraint: must work 10x faster for lists over 1000 items. Student analyzes bottleneck, applies binary search pattern (requires sorted data), adds sorting step if needed. **Assessment:** (1) All old tests pass, (2) New constraint is met, (3) Code remains readable. **Skill focus:** LEGACY CODE MAINTENANCE - dealing with existing code is most of real programming work. _Implementation note: Refactoring task with before/after comparison; auto-graded by test cases + performance metrics. CSTA: MS‑ALG‑AF‑01, MS‑PRO‑TR‑11._

Dependencies:
* T01.G8.09: Refactor a medium-sized program for efficiency
* T01.G6.16: Extend an algorithm to handle new requirements


# T02 - Algorithm Diagrams (Phase 9 Optimized - November 2025)
# Applied Phase 9 comprehensive optimizations:
# MAJOR CHANGES FROM PHASE 8 → PHASE 9:
# 1. NEW SKILLS ADDED (18 new skills for depth, visual programming, AI-era thinking):
#    K-2 NEW SKILLS (picture-based):
#    - T02.GK.07: Sort picture cards by step size (big steps vs small steps)
#    - T02.G1.09: Predict which path a character takes through a branching diagram
#    - T02.G2.12: Compare two diagrams and tap the one with more steps
#    G3-5 NEW SKILLS (block-based):
#    - T02.G3.12: Draw a flowchart programmatically using drawing blocks
#    - T02.G4.10: Build a decision table for a multi-condition algorithm
#    - T02.G4.11: Create an animated flowchart that highlights current step during execution
#    - T02.G5.11: Design a flowchart for error handling with try/catch patterns
#    G6-8 NEW SKILLS (advanced):
#    - T02.G6.12: Draw a recursive algorithm diagram showing call stack
#    - T02.G6.13: Build an interactive flowchart editor using sprites and clicks
#    - T02.G7.10: Design a sequence diagram for multi-sprite message passing
#    - T02.G7.11: Trace parallel algorithms showing concurrent execution paths
#    - T02.G8.12: Draw a system architecture diagram showing component interactions
#    - T02.G8.13: Use AI to generate flowcharts from natural language descriptions
#    - T02.G8.14: Create algorithm diagrams for scalable systems (millions of data points)
#    - T02.G8.15: Build a diagram version control system tracking changes over time
#    - T02.G8.16: Design a formal specification from a flowchart for verification
#    - T02.G8.17: Critique AI-generated diagrams and improve them systematically
#    - T02.G8.18: Draw a pipeline diagram for data processing workflows
# 2. SKILLS ENHANCED for better active verbs and granularity:
#    - All "Identify" → "Locate and tap" or "Find and highlight"
#    - All "Understand" → "Explain" or "Demonstrate"
#    - Added prediction-verification cycles throughout
# 3. DEPENDENCY REFINEMENTS:
#    - All X-2 rule validations confirmed
#    - Strengthened visual → code progression
#    - Added cross-skill connections for deeper learning paths
# 4. ENHANCED AI INTEGRATION:
#    - AI-generated diagram verification skills
#    - Human-AI collaboration for complex diagrams
#    - Critical thinking about AI diagram outputs
# 5. REAL-WORLD DIAGRAM TYPES ADDED:
#    - Decision tables, sequence diagrams, architecture diagrams
#    - Pipeline diagrams, recursive call diagrams
#    - Version control for diagrams
# Previous Phase 8 optimizations preserved
# Total: 119 skills (K:7, G1:9, G2:12, G3:13, G4:14, G5:11, G6:15, G7:16, G8:22 + sub-skills)

## KINDERGARTEN (7 skills - added T02.GK.07 for comparing step sizes)




ID: T02.GK.01
Topic: T02 – Algorithm Diagrams
Skill: Tap the arrow showing "what comes next" in a picture strip
Description: **Student task:** Look at a picture strip with 3 pictures connected by arrows (→). Tap the arrow that shows "what comes next" after brushing teeth. **Visual scenario:** Strip shows: [get toothbrush] →₁ [add toothpaste] →₂ [brush teeth]. Students tap arrow₁ or arrow₂ based on the question "Which arrow shows what happens after 'get toothbrush'?" **Correct answer:** Arrow₁. _Implementation note: Introduces arrows as directional symbols in diagrams; focuses on arrow meaning rather than sequencing. Large colorful arrows with highlight on tap. Auto-graded by selection. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine






ID: T02.GK.02
Topic: T02 – Algorithm Diagrams
Skill: Place pictures into a diagram strip with numbered boxes
Description: **Student task:** Drag 3–4 scrambled picture cards into a pre-made diagram strip with numbered boxes (Box 1 → Box 2 → Box 3 → Box 4) connected by arrows. **Visual scenario:** Empty diagram strip shows: [1] → [2] → [3] → [4]. Cards show "robot getting dressed": (A) robot in pajamas, (B) robot putting on shirt, (C) robot putting on pants, (D) robot with backpack ready. Students drag cards into boxes: A in Box 1, B in Box 2, C in Box 3, D in Box 4. _Implementation note: Focuses on filling a diagram structure (not creating sequence); arrows are fixed in the diagram. Auto-graded by final arrangement. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T02.GK.01: Identify arrows showing "what comes next" in a picture strip






ID: T02.GK.03
Topic: T02 – Algorithm Diagrams
Skill: Label START and END boxes in a picture diagram
Description: **Student task:** Look at a 3-box diagram strip. Drag the "START" label to the first box and "END" label to the last box. **Visual scenario:** Diagram shows 3 boxes connected by arrows: [?] → [add soap] → [?]. Labels available: "START: turn on water" and "END: dry hands." Students drag START label to first box, END label to last box. _Implementation note: Introduces START/END as diagram conventions; foundational for flowcharts. Audio support reads labels. Auto-graded by correct label placement. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T02.GK.02: Place pictures into a diagram strip with numbered boxes





ID: T02.GK.04
Topic: T02 – Algorithm Diagrams
Skill: Fix a diagram by moving one misplaced picture box
Description: **Student task:** Look at a 3-box diagram where one picture box is in the wrong position. Drag that box to fix the diagram. **Visual scenario:** Diagram shows "watering a plant": [water plant] → [get watering can] → [watch plant grow]. The first box is wrong—"water plant" should come after "get watering can." Student drags "water plant" box to the middle position. _Implementation note: Emphasizes fixing a diagram structure; wobbling animation highlights misplaced box. Auto-graded by final arrangement. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑PS‑03._

Dependencies:
* T02.GK.03: Label START and END boxes in a picture diagram




ID: T02.GK.05
Topic: T02 – Algorithm Diagrams
Skill: Tap the "question box" in a simple picture diagram
Description: **Student task:** Look at a picture diagram with regular boxes and one special "question box" (shown with a question mark or different color). Tap the question box. **Visual scenario:** Diagram shows: [START: wake up] → [?Is it raining?] → [get umbrella OR wear hat]. The question box has a "?" symbol and different shape/color. Students tap the question box. _Implementation note: Pre-cursor to flowchart decision diamonds; introduces concept that some boxes ask questions. Auto-graded by selection. CSTA: EK‑ALG‑AF‑01._

Dependencies:
* T02.GK.03: Label START and END boxes in a picture diagram


ID: T02.GK.06
Topic: T02 – Algorithm Diagrams
Skill: Tap the picture box that does NOT belong in a diagram
Description: **Student task:** Look at a 4-box diagram strip where one picture box does not belong with the others. Tap the picture box that should be removed. **Visual scenario:** Diagram shows "brushing teeth": [get toothbrush] → [eat pizza] → [add toothpaste] → [brush]. The "eat pizza" box doesn't belong—it's unrelated to the task! Student taps "eat pizza" to identify the wrong box. _Implementation note: Develops error-detection in diagrams; precursor to debugging. Large picture cards with audio support: "Which box doesn't belong?" Auto-graded by selection. CSTA: EK‑ALG‑AF‑01, EK‑ALG‑PS‑03._

Dependencies:
* T02.GK.02: Place pictures into a diagram strip with numbered boxes


ID: T02.GK.07
Topic: T02 – Algorithm Diagrams
Skill: Sort picture cards by step size (big steps vs small steps)
Description: **Student task:** Look at picture cards showing steps of different sizes (e.g., "make a sandwich" vs "put peanut butter on bread"). Sort cards into two piles: "BIG steps" and "small steps." **Visual scenario:** Cards show: (A) "Make lunch" (BIG—many actions inside), (B) "Open jar" (small—one action), (C) "Get dressed" (BIG), (D) "Put on left sock" (small). Students drag each card to the correct pile. Discussion: "Why is 'Make lunch' a BIG step?" **Answer:** It has many smaller steps inside! _Implementation note: Introduces granularity concept visually; precursor to decomposition. Large picture cards with clear visuals. Audio support: "Is this a BIG step or a small step?" Auto-graded by correct pile placement. CSTA: EK‑ALG‑AF‑01, EK‑DEC‑01._

Dependencies:
* T02.GK.04: Fix a diagram by moving one misplaced picture box


---

## GRADE 1 (9 skills - added T02.G1.09 for path prediction)




ID: T02.G1.01
Topic: T02 – Algorithm Diagrams
Skill: Build a 4-box diagram strip for a given task
Description: **Student task:** Given a task description, drag 4 picture cards into empty diagram boxes connected by arrows to create an algorithm diagram. **Visual scenario:** Task: "Feed the class fish." Empty diagram: [1] → [2] → [3] → [4]. Available picture cards: (A) sprinkle food, (B) open food container, (C) look at fish tank, (D) close container. Students build diagram: [C: look at tank] → [B: open container] → [A: sprinkle food] → [D: close container]. _Implementation note: Emphasizes building a diagram structure from scratch; arrows are pre-drawn. Auto-graded by valid sequence. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T02.GK.02: Place pictures into a diagram strip with numbered boxes





ID: T02.G1.02
Topic: T02 – Algorithm Diagrams
Skill: Fill the missing box in a diagram strip
Description: **Student task:** Look at a diagram strip with one empty box marked "?". Select the correct picture card to fill the missing box. **Visual scenario:** Diagram shows "making lemonade": [get cup] → [?] → [stir] → [drink]. Answer choices: (A) add water and lemon, (B) wash hands, (C) put on hat. **Correct answer:** (A) add water and lemon fills the empty box. _Implementation note: MCQ with 3 picture options to complete diagram; emphasizes diagram completeness. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T02.G1.01: Build a 4-box diagram strip for a given task





ID: T02.G1.03
Topic: T02 – Algorithm Diagrams
Skill: Trace a diagram and predict the final result
Description: **Student task:** Follow a 4-box diagram strip from START to END. Predict what the result will be after all steps complete. **Visual scenario:** Diagram shows "planting a seed": [START: get pot] → [add soil] → [plant seed] → [water] → END. Question: "What will happen after following this diagram?" Answer choices: (A) plant grows, (B) pot breaks, (C) seed disappears. **Correct answer:** (A) plant grows. _Implementation note: Introduces tracing as following arrows through a diagram; MCQ with 3 picture outcomes. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01._

Dependencies:
* T02.G1.01: Build a 4-box diagram strip for a given task





ID: T02.G1.04
Topic: T02 – Algorithm Diagrams
Skill: Compare two diagrams and identify the broken one
Description: **Student task:** Compare two diagram strips for the same task. One diagram is correct, one has a missing or wrong box. Tap the broken diagram. **Visual scenario:** Task: "Wash hands." Diagram A: [turn on water] → [add soap] → [rub hands] → [dry hands]. Diagram B: [turn on water] → [rub hands] → [dry hands] (missing soap box). Question: "Which diagram is broken?" **Correct answer:** Diagram B (missing a box). _Implementation note: Side-by-side diagram comparison; focuses on diagram structure integrity. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T02.G1.01: Build a 4-box diagram strip for a given task





ID: T02.G1.05
Topic: T02 – Algorithm Diagrams
Skill: Debug a diagram by replacing the wrong box
Description: **Student task:** Look at a diagram strip with one clearly wrong picture in a box. Tap the wrong box, then select the correct picture to replace it. **Visual scenario:** Diagram shows "make a sandwich": [eat sandwich] → [add peanut butter] → [add jelly] → [put bread on top]. The first box "eat sandwich" is wrong—you can't eat before making! Student taps it and selects "get bread slices" from 3 options. _Implementation note: Two-step debug: (1) identify wrong box, (2) select replacement. Emphasizes diagram debugging. Auto-graded by correct replacement. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T02.G1.04: Compare two diagrams and identify the broken one


ID: T02.G1.06
Topic: T02 – Algorithm Diagrams
Skill: Trace a diagram with a Yes/No question box
Description: **Student task:** Follow a diagram that has a "question box" with Yes and No arrows leading to different picture boxes. Answer what happens for a given scenario. **Visual scenario:** Diagram shows: [START: Is it cold?] with two arrows: "Yes" → [wear jacket] → END, "No" → [wear t-shirt] → END. Question: "It IS cold today. What do you wear?" **Correct answer:** wear jacket (follow the Yes arrow). _Implementation note: First branching diagram; introduces conditional paths visually. MCQ with 2 picture options. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T02.GK.05: Identify the "question box" in a simple picture diagram
* T02.G1.03: Trace a diagram and predict the final result


ID: T02.G1.07
Topic: T02 – Algorithm Diagrams
Skill: Trace a two-step decision diagram with multiple question boxes
Description: **Student task:** Follow a diagram with TWO question boxes in sequence. Answer what happens based on two conditions. **Visual scenario:** Diagram shows: [START] → ◇Is it morning?◇ "Yes" → ◇Hungry?◇ "Yes" → [Eat breakfast] → END, "No" → [Play] → END. "No" (not morning) → [Go to bed] → END. Question: "It IS morning and you ARE hungry. What do you do?" **Correct answer:** Eat breakfast (follow Yes→Yes path). _Implementation note: Two-level decision tree; extends G1.06 with chained decisions. Picture-based with clear arrow paths. Auto-graded by selection. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T02.G1.06: Trace a diagram with a Yes/No question box


ID: T02.G1.08
Topic: T02 – Algorithm Diagrams
Skill: Build two different diagrams that achieve the same goal
Description: **Student task:** Create TWO different diagram strips that both accomplish the same task, showing that problems can have multiple solutions. **Visual scenario:** Task: "Get ready for bed." Students build Diagram A: [brush teeth] → [put on pajamas] → [get in bed]. Then build Diagram B: [put on pajamas] → [brush teeth] → [get in bed]. Both achieve the goal! Students drag pictures to build both versions. Question: "Do both diagrams work?" **Answer:** Yes—different order, same result. _Implementation note: Introduces algorithm alternatives; foundational for efficiency comparisons later. Two side-by-side diagram builders. Audio support. Auto-graded by both diagrams achieving goal. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑IM‑04._

Dependencies:
* T02.G1.01: Build a 4-box diagram strip for a given task


ID: T02.G1.09
Topic: T02 – Algorithm Diagrams
Skill: Predict which path a character takes through a branching diagram
Description: **Student task:** Look at a branching diagram with multiple paths. Given information about the character, predict which path they will follow and what they will do. **Visual scenario:** Diagram shows: [START: Robot at home] → ◇Is it sunny?◇ → "Yes" → [go to park] → ◇Has ball?◇ → "Yes" → [play catch] → END, "No" → [play on swings] → END. "No" (not sunny) → [stay inside] → [read book] → END. Question: "It IS sunny and the robot HAS a ball. What will the robot do?" Students trace the Yes→Yes path and select: "Play catch." _Implementation note: Multi-step prediction through branching structure; extends G1.07 with concrete scenarios. Picture-based with clear character and path highlighting. Auto-graded by correct final action selection. CSTA: E1‑ALG‑AF‑01, E1‑ALG‑PS‑03._

Dependencies:
* T02.G1.07: Trace a two-step decision diagram with multiple question boxes


---

## GRADE 2 (12 skills - added T02.G2.12 for comparing diagram complexity)




ID: T02.G2.01
Topic: T02 – Algorithm Diagrams
Skill: Convert a picture diagram into a text-label diagram
Description: **Student task:** Look at a 4-box picture diagram. Create an equivalent text-label diagram by dragging word labels into matching boxes. **Visual scenario:** Picture diagram shows "getting ready for school": [🌅wake up] → [👕get dressed] → [🍳eat breakfast] → [🎒grab backpack]. Empty text diagram: [___] → [___] → [___] → [___]. Students drag text labels: "Wake up" → "Get dressed" → "Eat" → "Get bag" to match the picture diagram. _Implementation note: Introduces text-based diagrams as abstraction from pictures; same structure, different representation. Auto-graded by label placement. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T02.G1.01: Build a 4-box diagram strip for a given task





ID: T02.G2.02
Topic: T02 – Algorithm Diagrams
Skill: Match a text-label diagram to its picture diagram
Description: **Student task:** Look at a text-label diagram. Select which picture diagram shows the same algorithm from 2-3 options. **Visual scenario:** Text diagram: [Get ball] → [Throw ball] → [Catch ball]. Picture diagram options: (A) [🏀get] → [🤾throw] → [🙌catch], (B) [⚽kick] → [🏃run] → [🪑sit], (C) [🍕eat] → [😴sleep] → [🎮play]. **Correct answer:** (A). _Implementation note: Reverses G2.01 direction; tests understanding that diagrams can use different representations. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T02.G2.01: Convert a picture diagram into a text-label diagram





ID: T02.G2.03
Topic: T02 – Algorithm Diagrams
Skill: Trace a text-label diagram on a number line
Description: **Student task:** Follow a text-label diagram with movement instructions. Track position on a number line and predict the final result. **Visual scenario:** Diagram: [START at 0] → [Move right 2] → [Move right 3] → [Say number]. Number line 0-10 shown below. Students trace: 0 → 2 → 5 → say "5". Question: "What number does the character say?" Answer choices: 3, 5, 7. **Correct answer:** 5. _Implementation note: Introduces tracing as stepping through diagram boxes while tracking state. Auto-graded by final answer. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G2.02: Match a text-label diagram to its picture diagram





ID: T02.G2.04
Topic: T02 – Algorithm Diagrams
Skill: Build a trace table for a diagram step-by-step
Description: **Student task:** As each box in a diagram is revealed, mark the character's position in a trace table. **Visual scenario:** Diagram boxes revealed one at a time: [Start at 2] → write "2" in table, [Move right 3] → write "5", [Move left 1] → write "4", [Move right 2] → write "6". Trace table has columns: Step | Position. Students fill in each row. _Implementation note: First trace table experience; builds systematic tracking. Auto-graded by position sequence in table. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G2.03: Trace a text-label diagram on a number line





ID: T02.G2.05
Topic: T02 – Algorithm Diagrams
Skill: Trace a diagram with a Yes/No decision box
Description: **Student task:** Follow a text-label diagram that includes a decision box (shown as diamond shape) with Yes/No paths. Predict the result for a given condition. **Visual scenario:** Diagram: [START: x=7] → ◇Is x > 5?◇ with "Yes" → [Say "Big!"] → END, "No" → [Say "Small!"] → END. Question: "What does the character say?" **Correct answer:** "Big!" (since 7 > 5, follow Yes path). _Implementation note: Introduces diamond decision shape; builds on G1.06 Yes/No boxes with formal notation. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G1.06: Trace a diagram with a Yes/No question box
* T02.G2.03: Trace a text-label diagram on a number line





ID: T02.G2.06
Topic: T02 – Algorithm Diagrams
Skill: Debug a diagram by reordering misplaced boxes
Description: **Student task:** Look at a diagram where boxes are in the wrong order. Drag boxes to reorder them to match the target algorithm. **Visual scenario:** Target: "Get paint" → "Dip brush" → "Paint picture." Given broken diagram: [Paint picture] → [Get paint] → [Dip brush]. Students drag boxes to fix: [Get paint] → [Dip brush] → [Paint picture]. _Implementation note: Multi-step diagram debugging; reorder multiple boxes. Auto-graded by final arrangement. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G2.04: Build a trace table for a diagram step-by-step





ID: T02.G2.07
Topic: T02 – Algorithm Diagrams
Skill: Explore the CreatiCode workspace and run a pre-made block script
Description: **Student task:** Open CreatiCode, locate the block workspace, sprite stage, and green flag button. Run a pre-made script by clicking the green flag. **Visual scenario:** Students see CreatiCode with a simple 3-block script already built. They locate and tap: (1) block palette on left, (2) script area in middle, (3) stage on right, (4) green flag at top. Click green flag to run and watch sprite move. _Implementation note: Guided exploration; prepares for understanding blocks as executable diagrams. Auto-graded by correct hotspot selections + script execution. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T02.G2.06: Debug a diagram by reordering misplaced boxes




ID: T02.G2.08
Topic: T02 – Algorithm Diagrams
Skill: Match a text-label diagram to a block script (bridging skill)
Description: **Student task:** Look at a text-label diagram. Select which block script (shown as images of stacked blocks) implements the same algorithm. **Visual scenario:** Text diagram: [Move forward] → [Turn right] → [Move forward] → [Say hello]. Block options show 3 different block stacks. Students select the one with: move → turn right → move → say blocks matching the diagram. _Implementation note: CRITICAL BRIDGING SKILL from diagrams to blocks; shows blocks as executable versions of diagrams. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T02.G2.07: Identify CreatiCode workspace and run a pre-made block script
* T02.G2.03: Trace a text-label diagram on a number line


ID: T02.G2.09
Topic: T02 – Algorithm Diagrams
Skill: Tap the repeat symbol (loop arrow) and predict how many times it runs
Description: **Student task:** Look at a diagram that has a "repeat" symbol (curved arrow going back to an earlier box). Tap the repeat symbol and predict how many times the loop runs. **Visual scenario:** Diagram shows: [START] → [Jump] → [Clap] with a curved arrow labeled "×3" going from [Clap] back to [Jump] → [END]. Question: "What does the curved arrow mean?" Answer choices: (A) Do Jump-Clap 3 times, (B) Skip Jump, (C) Go backwards. **Correct answer:** (A). _Implementation note: Introduces loop notation in diagrams; precursor to repeat blocks. Auto-graded by selection. CSTA: E2‑ALG‑AF‑01._

Dependencies:
* T02.G2.04: Build a trace table for a diagram step-by-step
* T04.G2.01: Identify the repeating unit in a longer pattern


ID: T02.G2.10
Topic: T02 – Algorithm Diagrams
Skill: Trace a repeat diagram step-by-step showing each iteration
Description: **Student task:** Follow a diagram with a repeat symbol (loop arrow "×3"). Show what happens each time through the loop by filling in a simple trace strip. **Visual scenario:** Diagram: [START at step 0] → [Step forward] with curved "×3" arrow → [END]. Trace strip shows: Step 0 → Step 1 (iteration 1) → Step 2 (iteration 2) → Step 3 (iteration 3) → END. Students fill in step counts: 0, 1, 2, 3. Question: "What step number at the END?" **Answer:** 3. _Implementation note: Explicit loop iteration tracing; builds foundation for loop trace tables. Picture-based with number-line visual. Auto-graded by trace strip values. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G2.09: Identify a repeat symbol (loop arrow) in a diagram
* T02.G2.04: Build a trace table for a diagram step-by-step


ID: T02.G2.11
Topic: T02 – Algorithm Diagrams
Skill: Debug a diagram by adding a missing arrow connection
Description: **Student task:** Look at a diagram where boxes are disconnected—an arrow is missing between two boxes. Drag an arrow to connect the broken diagram. **Visual scenario:** Diagram shows "making a card": [fold paper] [GAP—no arrow] [draw picture] → [give to friend]. Student sees that "fold paper" and "draw picture" are not connected. Drag an arrow from "fold paper" to "draw picture" to fix the diagram. _Implementation note: Introduces arrow/connection as critical diagram element; different from wrong box content. Drag-drop arrow tool. Auto-graded by correct arrow placement. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑PS‑03._

Dependencies:
* T02.G2.06: Debug a diagram by reordering misplaced boxes
* T02.GK.01: Identify arrows showing "what comes next" in a picture strip


ID: T02.G2.12
Topic: T02 – Algorithm Diagrams
Skill: Compare two diagrams and tap the one with more steps
Description: **Student task:** Look at two diagrams side by side. Count the steps in each diagram and tap the one that has more steps. Explain why one might be more detailed than the other. **Visual scenario:** Diagram A shows "making a bed": [pull up blanket] → [fluff pillow] → [done] (3 steps). Diagram B shows: [remove old sheets] → [put on fitted sheet] → [put on flat sheet] → [add blanket] → [fluff pillow] → [done] (6 steps). Question: "Which diagram has more steps? Tap it." **Answer:** Diagram B. Follow-up: "Why might someone use more steps?" **Answer:** More detail, clearer instructions. _Implementation note: Introduces diagram complexity comparison; connects to granularity concept from GK.07. Side-by-side visual comparison with counting support. Auto-graded by correct selection. CSTA: E2‑ALG‑AF‑01, E2‑ALG‑IM‑04._

Dependencies:
* T02.G2.04: Build a trace table for a diagram step-by-step
* T02.GK.07: Sort picture cards by step size (big steps vs small steps)


---

## GRADE 3 (13 skills - added T02.G3.12 for programmatic flowchart drawing)




ID: T02.G3.00
Topic: T02 – Algorithm Diagrams
Skill: Arrange provided blocks in the order shown by a diagram
Description: **Student task:** Look at a simple 4-box diagram and arrange pre-made blocks to match the diagram order. Blocks are already provided; students only need to drag them into correct sequence. **Visual scenario:** Diagram: [set x to 0] → [move 50] → [turn 90] → [say "done"]. Four loose blocks are shown scrambled. Students drag blocks into the correct top-to-bottom order matching the diagram left-to-right. _Implementation note: Bridge between reading diagrams (G2) and building code (G3); scaffolds coding entry. Auto-graded by block arrangement. CSTA: E3-ALG-AF-01._

Dependencies:
* T02.G2.08: Match a text-label diagram to a block script (bridging skill)




ID: T02.G3.01
Topic: T02 – Algorithm Diagrams
Skill: Build and run a 4-block sequence in CreatiCode
Description: **Student task:** Build a simple 4-block sequence in CreatiCode by snapping blocks together, then run it with the green flag. **Visual scenario:** Students create: [move 50 steps] → [turn 90°] → [move 50 steps] → [say "Hello!"]. They observe blocks execute top-to-bottom, just like diagram boxes execute left-to-right. _Implementation note: First block-building task; emphasizes blocks as executable diagram boxes. Auto-graded by sprite position + message. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T02.G2.08: Match a text-label diagram to a block script (bridging skill)





ID: T02.G3.02
Topic: T02 – Algorithm Diagrams
Skill: Predict the outcome of a block sequence without running it
Description: **Student task:** Look at a 5-block script WITHOUT running it. Predict what the sprite will do and where it ends up. **Visual scenario:** Script: [move 100] → [turn 90°] → [move 50] → [turn 90°] → [say "Done!"]. Grid shows starting position. Students predict: (1) sprite's final position on grid, (2) sprite says "Done!". _Implementation note: Mental tracing without execution; same skill as tracing a diagram. Auto-graded by position and message selection. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T02.G3.01: Build and run a 4-block sequence in CreatiCode





ID: T02.G3.03
Topic: T02 – Algorithm Diagrams
Skill: Build a block script to implement a given algorithm
Description: **Student task:** Given a task description, create a 4–6 block script that implements the algorithm. **Visual scenario:** Task: "Make the sprite draw a short line, then say 'Done!'" Students build: [pen down] → [move 100] → [pen up] → [say "Done!"]. This is the executable version of a diagram. _Implementation note: Task specification → block implementation; auto-graded by behavior. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T02.G3.02: Predict the outcome of a block sequence without running it





ID: T02.G3.04
Topic: T02 – Algorithm Diagrams
Skill: Trace a block script with one if/else decision
Description: **Student task:** Follow a block script with one if/else block. Given a starting value, trace which branch executes and predict the outcome. **Visual scenario:** Script: [if x > 50 then] → [say "Big!"] [else] → [say "Small!"]. Given: x = 30. Students trace: condition 30 > 50 is FALSE → follow "else" branch → sprite says "Small!". _Implementation note: Single if/else tracing; mirrors tracing a decision diamond in a diagram. Auto-graded by path and outcome. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T02.G3.03: Build a block script to implement a given algorithm
* T02.G2.05: Trace a diagram with a Yes/No decision box





ID: T02.G3.05
Topic: T02 – Algorithm Diagrams
Skill: Build a block script with one if/else decision
Description: **Student task:** Build a block script with one if/else block to handle a simple decision. **Visual scenario:** Task: "If the sprite is touching the edge, say 'Stop!' Otherwise, move forward 10 steps." Students build: [if touching edge?] → [say "Stop!"] [else] → [move 10]. _Implementation note: First conditional building; implements a decision diagram as executable code. Auto-graded by testing both branches. CSTA: E3‑ALG‑AF‑01, E3‑PRO‑PF‑01._

Dependencies:
* T02.G3.04: Trace a block script with one if/else decision





ID: T02.G3.06
Topic: T02 – Algorithm Diagrams
Skill: Compare two block scripts for the same task
Description: **Student task:** Look at two block scripts that both accomplish the same goal. Identify which uses fewer blocks or is clearer. **Visual scenario:** Task: "Move sprite to (100, 100)." Script A: [go to x:0 y:0] → [glide to x:100 y:100] (2 blocks). Script B: [set x to 100] → [set y to 100] → [wait 1 sec] (3 blocks). Question: "Which script is simpler?" **Answer:** Script A (fewer blocks, same result). _Implementation note: Algorithm comparison; introduces efficiency thinking. Auto-graded by selection. CSTA: E3‑ALG‑IM‑04._

Dependencies:
* T02.G3.03: Build a block script to implement a given algorithm




ID: T02.G3.07
Topic: T02 – Algorithm Diagrams
Skill: Determine when an algorithm diagram needs a loop symbol
Description: **Student task:** Look at a task description and determine whether the algorithm diagram would need a repeat/loop symbol. **Visual scenario:** Task A: "Draw a square (4 equal sides)" – needs [move-turn] repeated 4×. Task B: "Say hello once" – no repetition. Question: "Which task needs a loop in its diagram?" **Answer:** Task A (same steps repeat). _Implementation note: Connects loop concept to diagram notation (repeat symbols). Auto-graded by selection. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T02.G2.09: Tap the repeat symbol (loop arrow) and predict how many times it runs
* T02.G3.03: Build a block script to implement a given algorithm




ID: T02.G3.08
Topic: T02 – Algorithm Diagrams
Skill: Trace a repeat block script and predict the final result
Description: **Student task:** Follow a block script with a "repeat N times" block. Predict what happens after all repetitions. **Visual scenario:** Script: [repeat 4] → [move 50] → [turn 90°]. Trace table: Iteration 1: move+turn, Iteration 2: move+turn, Iteration 3: move+turn, Iteration 4: move+turn. Result: sprite draws a square, ends at start. _Implementation note: First loop tracing in blocks; connects to diagram repeat symbols. Auto-graded by final position/pattern. CSTA: E3‑ALG‑AF‑01, E3‑ALG‑PS‑03._

Dependencies:
* T02.G3.07: Identify when an algorithm diagram needs a loop symbol
* T07.G2.01: Identify when to use "repeat" vs "do once"


ID: T02.G3.09
Topic: T02 – Algorithm Diagrams
Skill: Draw a simple flowchart for a block script
Description: **Student task:** Given a simple 4-5 block script, draw a matching flowchart using START/END ovals, action rectangles, and arrows. **Visual scenario:** Script: [move 50] → [turn 90°] → [say "Done!"]. Students draw: (START oval) → [move 50 rect] → [turn 90° rect] → [say "Done!" rect] → (END oval). Drag flowchart shapes and connect with arrows. _Implementation note: First flowchart creation; introduces standard symbols. Auto-graded by shape sequence and connections. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T02.G3.01: Build and run a 4-block sequence in CreatiCode
* T02.GK.03: Label START and END boxes in a picture diagram


ID: T02.G3.10
Topic: T02 – Algorithm Diagrams
Skill: Match flowchart symbols to their meanings and demonstrate understanding
Description: **Student task:** Match flowchart symbols to their meanings by dragging labels, then demonstrate understanding by answering questions about each symbol's purpose. **Visual scenario:** Show 4 symbols: (1) oval, (2) rectangle, (3) diamond, (4) arrow. Labels: "Start/End", "Process/Action", "Decision/Question", "Flow direction". Students drag: oval="Start/End", rectangle="Process", diamond="Decision", arrow="Flow". Follow-up question: "Which symbol asks a question?" **Answer:** Diamond. "When would you use a rectangle?" **Answer:** For an action step. _Implementation note: Explicit symbol vocabulary with active demonstration; foundational for flowchart literacy. Drag-drop matching + MCQ verification. Auto-graded by correct matches and answers. CSTA: E3‑ALG‑AF‑01._

Dependencies:
* T02.G3.09: Draw a simple flowchart for a block script
* T02.G2.05: Trace a diagram with a Yes/No decision box


ID: T02.G3.11
Topic: T02 – Algorithm Diagrams
Skill: Plan an algorithm using the diagram editor before building blocks
Description: **Student task:** Before coding, use the CreatiCode diagram editor to create a visual plan showing the steps of your algorithm. Include START/END ovals, action boxes, and arrows. Then build the matching blocks. **Visual scenario:** Task: "Make sprite draw a triangle." Students first create diagram in diagram editor: (START) → [pen down] → [move 100] → [turn 120] → [repeat back arrow ×3] → (END). Then build blocks to match their diagram. Compare diagram to final code. _Implementation note: Pre-coding visual planning tool; connects diagram skills to coding workflow. Auto-graded by diagram completeness + block implementation match. CSTA: E3-ALG-AF-01, E3-PRO-PF-01._

Dependencies:
* T02.G3.09: Draw a simple flowchart for a block script
* T02.G3.03: Build a block script to implement a given algorithm


ID: T02.G3.12
Topic: T02 – Algorithm Diagrams
Skill: Draw a flowchart programmatically using drawing blocks
Description: **Student task:** Use CreatiCode's drawing blocks (draw rectangle, draw oval, draw line) to create a flowchart on the stage. Program your sprite to draw START/END ovals, action rectangles, and connecting arrows. **Visual scenario:** Students build a script: [draw oval at x:-150 y:100 (START)] → [draw line from START to first action] → [draw rectangle at x:-150 y:0 (action: move 50)] → [draw line to next] → [draw rectangle at x:-150 y:-100 (action: turn 90)] → [draw oval at x:-150 y:-200 (END)]. Result: a programmatically-generated flowchart appears on stage! Compare to hand-drawn version. _Implementation note: First programmatic diagram creation; connects drawing skills to algorithm visualization. Uses draw_rectangle, draw_oval, draw_line blocks. Auto-graded by shape positions and connections. CSTA: E3-ALG-AF-01, E3-PRO-PF-01._

Dependencies:
* T02.G3.09: Draw a simple flowchart for a block script
* T02.G3.01: Build and run a 4-block sequence in CreatiCode


---

## GRADE 4 (14 skills - added T02.G4.10 decision tables, T02.G4.11 animated flowcharts)




ID: T02.G4.01
Topic: T02 – Algorithm Diagrams
Skill: Predict and trace loop variable changes in a trace table
Description: **Student task:** BEFORE running a loop script, fill in a trace table predicting variable values for each iteration. Then run the script and verify your predictions match actual output. **Visual scenario:** Script: [set count to 0] → [repeat 5] → [change count by 2]. Prediction trace table: Iteration | count: 1 | 2, 2 | 4, 3 | 6, 4 | 8, 5 | 10. Students fill predictions FIRST, then run script and add print blocks to verify. Match predictions to actual console output. _Implementation note: Prediction-first tracing builds mental model before execution; combines loop tracing with formal trace tables. Auto-graded by prediction accuracy against actual execution. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T02.G3.08: Trace a repeat block script and predict the final result
* T02.G2.04: Build a trace table for a diagram step-by-step





ID: T02.G4.02
Topic: T02 – Algorithm Diagrams
Skill: Build a block script with a repeat loop for a pattern
Description: **Student task:** Create a block script using a repeat block to draw a geometric pattern. **Visual scenario:** Task: "Draw a square (4 sides, each 100 steps, turn 90° after each)." Students build: [repeat 4] → [move 100] → [turn 90°]. Result: sprite draws a square. _Implementation note: First loop building; implements repetitive algorithm. Auto-graded by drawn shape. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T02.G4.01: Trace a repeat loop with variable tracking in a trace table
* T02.G3.03: Build a block script to implement a given algorithm





ID: T02.G4.03.01
Topic: T02 – Algorithm Diagrams
Skill: Trace a script with sequential if/else decisions
Description: **Student task:** Trace a block script with 2 if/else blocks that run one after another (sequential, not nested). Track which conditions are true. **Visual scenario:** Script: [if x > 50 say "Big" else say "Small"] → [if y > 50 say "High" else say "Low"]. Given: x=60, y=30. Trace: first if: 60>50=TRUE → "Big"; second if: 30>50=FALSE → "Low". Result: "Big" then "Low". _Implementation note: Sequential conditionals; each decision independent. Auto-graded by both outputs. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T02.G3.05: Build a block script with one if/else decision
* T12.G3.01: Test and trace simple block-based scripts




ID: T02.G4.03.02
Topic: T02 – Algorithm Diagrams
Skill: Trace a script with nested if/else decisions
Description: **Student task:** Trace a block script where one if/else is INSIDE another if/else (nested). Track the path through nested structure. **Visual scenario:** Script: [if x > 50] → [if y > 50 say "Big & High" else say "Big & Low"] [else say "Small"]. Given: x=60, y=30. Trace: outer if: 60>50=TRUE → enter inner; inner if: 30>50=FALSE → "Big & Low". _Implementation note: Nested conditionals; requires tracking depth level. Auto-graded by final output. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T02.G4.03.01: Trace a script with sequential if/else decisions





ID: T02.G4.04.01
Topic: T02 – Algorithm Diagrams
Skill: Build a script with loop followed by decision (sequential)
Description: **Student task:** Build a block script with a repeat loop FOLLOWED BY an if/else block (sequential, not nested). **Visual scenario:** Task: "Move 4 times (10 steps each), then check if you've gone far." Students build: [repeat 4] → [move 10] → [if x > 100 say "Far!" else say "Close!"]. Loop runs first, then decision checks result. _Implementation note: Sequential combination of structures. Auto-graded by position + message. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T02.G4.02: Build a block script with a repeat loop for a pattern
* T02.G3.05: Build a block script with one if/else decision





ID: T02.G4.04.02
Topic: T02 – Algorithm Diagrams
Skill: Build a script with decision inside a loop (nested)
Description: **Student task:** Build a block script with an if/else block INSIDE a repeat loop (decision made each iteration). **Visual scenario:** Task: "Repeat 10 times: if touching blue, turn; otherwise move." Students build: [repeat 10] → [if touching blue? turn 90° else move 10]. Decision runs each iteration—behavior depends on environment. _Implementation note: Nested combination; decision affects each iteration. Auto-graded by final path. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑PF‑01._

Dependencies:
* T02.G4.04.01: Build a script with loop followed by decision (sequential)
* T02.G4.03.02: Trace a script with nested if/else decisions





ID: T02.G4.04.03
Topic: T02 – Algorithm Diagrams
Skill: Draw a flowchart with a decision diamond
Description: **Student task:** Draw a flowchart for a block script that includes an if/else decision, using diamond shape for the decision. **Visual scenario:** Script: [if score > 10] → [say "Winner!"] [else] → [say "Try again"]. Students draw: (START) → ◇score > 10?◇ with "Yes" → [say "Winner!"] → (END), "No" → [say "Try again"] → (END). _Implementation note: Introduces diamond decision symbol in flowcharts. Auto-graded by shape types and connections. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T02.G3.09: Draw a simple flowchart for a block script
* T02.G3.05: Build a block script with one if/else decision





ID: T02.G4.05.01
Topic: T02 – Algorithm Diagrams
Skill: Locate and use the print block to display a message in console
Description: **Student task:** Find the "print [MESSAGE] in [console]" block in the Operators category. Add it to a script and run to see output in the console panel. **Visual scenario:** Students locate the print block, add it with message "Hello from console!", run the script, and find the Console panel (click Console tab at bottom). See "Hello from console!" appear. Verify you can clear and rerun. _Implementation note: Tool discovery—console panel orientation is critical foundation. Auto-graded by console output. CSTA: E4‑PRO‑TR‑03._

Dependencies:
* T02.G4.01: Predict and trace loop variable changes in a trace table
* T12.G3.01: Test and trace simple block-based scripts


ID: T02.G4.05.02
Topic: T02 – Algorithm Diagrams
Skill: Add strategic print blocks inside a loop to trace variable changes
Description: **Student task:** Add print blocks at strategic points inside a repeat loop to display variable changes. Compare console output to trace table predictions. **Visual scenario:** Script: [set count to 0] → [repeat 5] → [change count by 3, print "count = " + count]. Console shows: count = 3, count = 6, count = 9, count = 12, count = 15. Students verify their trace table predictions match console output. Identify where to place prints: AFTER the variable changes, not before. _Implementation note: Strategic print placement; builds debugging intuition. Auto-graded by trace table matching console output. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑TR‑03._

Dependencies:
* T02.G4.05.01: Locate and use the print block to display a message in console






ID: T02.G4.06
Topic: T02 – Algorithm Diagrams
Skill: Debug a script by adding print blocks to find the error
Description: **Student task:** Given a buggy script, add "print" blocks to display variable values. Use console output to identify and fix the error. **Visual scenario:** Buggy script supposed to count 0-10 by 2s, but outputs 2,4,6,8,10,12. Students add print blocks, discover initialization error (starts at 2 not 0). Fix: change "set x to 2" to "set x to 0". _Implementation note: Print-based debugging workflow. Auto-graded by corrected script behavior. CSTA: E4‑ALG‑AF‑01, E4‑PRO‑TR‑03._

Dependencies:
* T02.G4.05.02: Add strategic print blocks inside a loop to trace variable changes






ID: T02.G4.07
Topic: T02 – Algorithm Diagrams
Skill: Draw a flowchart with a loop symbol
Description: **Student task:** Draw a flowchart for a block script with a repeat loop, using proper loop notation (back-arrow or loop box). **Visual scenario:** Script: [repeat 4] → [move 50] → [turn 90°]. Students draw: (START) → [Loop: 4 times] → [move 50] → [turn 90°] → (back to loop check) → (END when done). _Implementation note: Introduces loop representation in flowcharts. Auto-graded by structure and connections. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T02.G4.04.03: Draw a flowchart with a decision diamond
* T02.G4.02: Build a block script with a repeat loop for a pattern


ID: T02.G4.08
Topic: T02 – Algorithm Diagrams
Skill: Display algorithm state using a table variable monitor on stage
Description: **Student task:** Create a table variable to display algorithm state visually on stage. Add columns for "Step", "Variable", and "Value". Update the table during loop execution so viewers can watch the algorithm progress. **Visual scenario:** Counting algorithm: table shows rows like [Step 1 | count | 2], [Step 2 | count | 4], etc. Students use "add row to table [table]" block inside the loop to log each state change. Watch the table grow as the algorithm runs—visual trace on stage! _Implementation note: Visual algorithm tracing using CreatiCode table variables; connects to T10 data skills. Auto-graded by table content accuracy. CSTA: E4-ALG-AF-01, E4-ALG-PS-03._

Dependencies:
* T02.G4.05.02: Add strategic print blocks inside a loop to trace variable changes
* T10.G3.01: Create a table variable with named columns


ID: T02.G4.09
Topic: T02 – Algorithm Diagrams
Skill: Draw a data flow diagram showing input, process, and output
Description: **Student task:** Create a data flow diagram that shows where data comes from (input), what happens to it (process), and where it goes (output). Use rounded rectangles for processes, arrows for data flow. **Visual scenario:** Task: "Calculate a tip." Students draw: [User enters bill amount] → [Calculate 15% of bill] → [Display tip amount]. Data flows along arrows: "billAmount" flows into process, "tipAmount" flows out. Students label each arrow with the data name. _Implementation note: Introduces data flow notation; different from control flow (flowcharts). Foundation for system design. Auto-graded by correct input/process/output structure. CSTA: E4‑ALG‑AF‑01._

Dependencies:
* T02.G4.04.03: Draw a flowchart with a decision diamond
* T02.G4.01: Predict and trace loop variable changes in a trace table


ID: T02.G4.10
Topic: T02 – Algorithm Diagrams
Skill: Build a decision table for a multi-condition algorithm
Description: **Student task:** Create a decision table that lists all combinations of conditions and their corresponding actions. Use the table to verify your algorithm handles all cases. **Visual scenario:** Task: "What to wear based on weather." Conditions: Is it cold? (Y/N), Is it raining? (Y/N). Decision table with 4 rows: Cold+Rain→jacket+umbrella, Cold+NoRain→jacket, NotCold+Rain→umbrella, NotCold+NoRain→t-shirt. Students fill in table, then build matching if/else blocks. Verify all 4 combinations work. _Implementation note: Decision tables as algorithm planning tool; alternative to flowcharts for multi-condition logic. Table variable display on stage. Auto-graded by table completeness + code matching all cases. CSTA: E4‑ALG‑AF‑01, E4‑ALG‑PS‑03._

Dependencies:
* T02.G4.03.02: Trace a script with nested if/else decisions
* T02.G4.08: Display algorithm state using a table variable monitor on stage


ID: T02.G4.11
Topic: T02 – Algorithm Diagrams
Skill: Create an animated flowchart that highlights current step during execution
Description: **Student task:** Build a visual flowchart on stage using drawing blocks. As your algorithm runs, highlight the current step by changing its color. Create a "live" flowchart that shows execution progress. **Visual scenario:** Students draw a 4-step flowchart. Script runs: draw all boxes in gray → start algorithm → change box 1 to green (current) → execute step 1 → change box 1 back to gray, box 2 to green → continue. Viewers see the flowchart "light up" step by step! Add wait blocks for visibility. _Implementation note: Self-illustrating algorithm; advanced diagram-code integration. Uses draw_rectangle with color changes. Auto-graded by correct highlighting sequence matching execution. CSTA: E4-ALG-AF-01, E4-PRO-PF-01._

Dependencies:
* T02.G3.12: Draw a flowchart programmatically using drawing blocks
* T02.G4.05.02: Add strategic print blocks inside a loop to trace variable changes


---

## GRADE 5 (11 skills - added T02.G5.11 error handling flowcharts)




ID: T02.G5.01
Topic: T02 – Algorithm Diagrams
Skill: Trace nested loops using print blocks and a trace table
Description: **Student task:** Trace a script with nested repeat blocks by adding print blocks inside both loops. Record console output in a trace table showing outer and inner loop iterations. **Visual scenario:** Script: [repeat 3 (outer)] → [repeat 2 (inner)] → [print "outer: " + i + " inner: " + j]. Trace table: outer=1,inner=1 | outer=1,inner=2 | outer=2,inner=1 | outer=2,inner=2 | outer=3,inner=1 | outer=3,inner=2. _Implementation note: Multi-level loop tracing. Auto-graded by trace table accuracy. CSTA: E5‑ALG‑AF‑01, E5‑ALG‑PS‑03._

Dependencies:
* T02.G4.05.02: Add strategic print blocks inside a loop to trace variable changes
* T02.G4.07: Draw a flowchart with a loop symbol





ID: T02.G5.02
Topic: T02 – Algorithm Diagrams
Skill: Build a nested loop script to create a 2D pattern
Description: **Student task:** Create a script using nested repeat blocks to generate a 2D grid pattern (outer loop for rows, inner loop for columns). **Visual scenario:** Task: "Create a 4×3 grid of stamps." Students build: [repeat 3 (rows)] → [repeat 4 (cols)] → [stamp, move right 50], [move to next row]. Result: 3 rows of 4 stamps each. _Implementation note: Nested loop construction for 2D patterns. Auto-graded by visual grid output. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T02.G5.01: Trace nested loops using print blocks and a trace table





ID: T02.G5.03
Topic: T02 – Algorithm Diagrams
Skill: Trace multiple variables including accumulators in custom trace tables
Description: **Student task:** Trace a script with multiple changing values, designing your own trace table format. Include accumulator patterns (running totals, growing values). Predict values before running, then verify with print output. **Visual scenario:** Script: running total adds position each step. Student designs table: Iteration | x | total | change. Predict: 1|50|50|+50, 2|100|150|+100, 3|150|300|+150. Verify with console output. Tracks both regular variables AND accumulators. _Implementation note: Combines multi-variable tracing with student-designed tables and accumulator patterns. Auto-graded by prediction accuracy. CSTA: E5-ALG-AF-01, E5-ALG-PS-03._

Dependencies:
* T02.G4.05.02: Add strategic print blocks inside a loop to trace variable changes
* T09.G5.01: Use multiple variables together in a single expression


ID: T02.G5.04
Topic: T02 – Algorithm Diagrams
Skill: Trace an algorithm with multiple exit points and predict which exit is taken
Description: **Student task:** Trace a script that has multiple possible exit points (early returns, different stop conditions). Predict which exit path executes for a given input. **Visual scenario:** Search algorithm with 3 exits: (1) item found → return position, (2) end of list → return "not found", (3) invalid input → return "error". Students trace with inputs: [5,3,8], target=3 → exits at position 2 (found). [5,3,8], target=9 → exits at end (not found). [], target=5 → exits immediately (error). Draw flowchart showing all exit paths. _Implementation note: Multiple exit point analysis; critical for understanding algorithm termination. Auto-graded by correct exit prediction. CSTA: E5‑ALG‑AF‑01, E5‑ALG‑PS‑03._

Dependencies:
* T02.G5.03: Trace multiple variables including accumulators in custom trace tables
* T02.G4.04.02: Build a script with decision inside a loop (nested)







ID: T02.G5.05
Topic: T02 – Algorithm Diagrams
Skill: Analyze two algorithms by counting operations to determine efficiency
Description: **Student task:** Compare two block scripts that solve the same problem. Count blocks and trace execution steps to identify which is more efficient. **Visual scenario:** Task: "Move sprite 200 steps." Algorithm A: [repeat 4] → [move 50] (4 iterations). Algorithm B: [move 200] (1 operation). Students count: A=4 move operations, B=1 move operation. B is more efficient. _Implementation note: Efficiency analysis by operation counting. Auto-graded by efficiency identification. CSTA: E5‑ALG‑IM‑04._

Dependencies:
* T02.G3.06: Compare two block scripts for the same task
* T02.G5.01: Trace nested loops using print blocks and a trace table





ID: T02.G5.06
Topic: T02 – Algorithm Diagrams
Skill: Optimize an algorithm by removing redundant blocks
Description: **Student task:** Given a working script with unnecessary blocks, identify and remove redundant operations while keeping the same output behavior. **Visual scenario:** Script with redundant steps: [move 50] → [move -50] → [move 50] → [turn 90°]. Redundant: first two moves cancel out. Optimized: [move 50] → [turn 90°]. Students identify and remove waste. _Implementation note: Algorithm optimization; same behavior, fewer blocks. Auto-graded by output matching + block count reduction. CSTA: E5‑ALG‑IM‑04._

Dependencies:
* T02.G5.05: Compare two algorithms by counting operations


ID: T02.G5.07
Topic: T02 – Algorithm Diagrams
Skill: Draw a flowchart with nested structures
Description: **Student task:** Draw a flowchart for a block script that has a loop containing a decision (or vice versa). Show proper nesting in the diagram. **Visual scenario:** Script: [repeat 5] → [if touching edge, turn 180°, else move 10]. Flowchart shows: loop box containing a decision diamond inside, with both branches returning to loop check. _Implementation note: Advanced flowchart with nested control structures. Auto-graded by structure and nesting accuracy. CSTA: E5‑ALG‑AF‑01._

Dependencies:
* T02.G4.07: Draw a flowchart with a loop symbol
* T02.G4.04.02: Build a script with decision inside a loop (nested)


ID: T02.G5.08
Topic: T02 – Algorithm Diagrams
Skill: Convert a flowchart to a block script
Description: **Student task:** Given a flowchart diagram, build the equivalent block script in CreatiCode. **Visual scenario:** Flowchart shows: (START) → ◇x > 0?◇ → "Yes" → [move x] → (END), "No" → [turn 180°] → (END). Students build: [if x > 0] → [move x] [else] → [turn 180°]. _Implementation note: Flowchart-to-code translation. Auto-graded by script behavior matching flowchart logic. CSTA: E5‑ALG‑AF‑01, E5‑PRO‑PF‑01._

Dependencies:
* T02.G5.07: Draw a flowchart with nested structures
* T02.G4.04.02: Build a script with decision inside a loop (nested)


ID: T02.G5.09
Topic: T02 – Algorithm Diagrams
Skill: Build an interactive algorithm stepper using button and label widgets
Description: **Student task:** Create an interactive algorithm visualization using widgets: a "Step" button that executes one algorithm step per click, a label widget showing current state, and a "Reset" button. **Visual scenario:** Sorting visualizer: 5 numbers displayed. Click "Step" button → one comparison happens, label shows "Comparing 5 and 3", swapped elements highlight. Click again → next comparison. Students control algorithm pace and observe each step. _Implementation note: Widget-based algorithm stepper; combines UI skills (T15) with algorithm tracing. Auto-graded by correct step-by-step behavior. CSTA: E5-ALG-AF-01, E5-PRO-PF-01._

Dependencies:
* T02.G5.03: Trace multiple variables including accumulators in custom trace tables
* T15.G4.01: Add a button widget to the stage


ID: T02.G5.10
Topic: T02 – Algorithm Diagrams
Skill: Export trace table data to a stage display for visual debugging
Description: **Student task:** Build a trace table during algorithm execution and display it on stage using table variable monitor. Add a "Show Trace" button that reveals the complete execution history. **Visual scenario:** After running a search algorithm, click "Show Trace" button. Table appears on stage showing: [Step 1 | index=1 | value=5 | not match], [Step 2 | index=2 | value=12 | FOUND!]. Students can scroll through trace history. _Implementation note: Persistent visual trace for algorithm analysis. Auto-graded by trace table content + display functionality. CSTA: E5-ALG-AF-01, E5-PRO-TR-03._

Dependencies:
* T02.G5.03: Trace multiple variables including accumulators in custom trace tables
* T02.G4.08: Display algorithm state using a table variable monitor on stage


ID: T02.G5.11
Topic: T02 – Algorithm Diagrams
Skill: Design a flowchart for error handling with try/catch patterns
Description: **Student task:** Draw a flowchart that includes error handling paths. Show what happens when things go right AND what happens when errors occur. Use a special "error path" notation. **Visual scenario:** Task: "Load a file and display contents." Flowchart: START → [Try: Open file] → ◇Success?◇ → Yes → [Read contents] → [Display on stage] → END. No → [Error path: Show "File not found"] → [Ask user to try again] → (back to Open file). Students draw both the "happy path" and the error recovery path. Color-code error paths in red. _Implementation note: Error handling in algorithm design; critical for robust programs. Introduces try/catch thinking at diagram level. Auto-graded by correct error path structure. CSTA: E5-ALG-AF-01, E5-PRO-TR-03._

Dependencies:
* T02.G5.07: Draw a flowchart with nested structures
* T02.G5.04: Trace an algorithm with multiple exit points and predict which exit is taken


---

## GRADE 6 (15 skills - added T02.G6.12 recursive diagrams, T02.G6.13 interactive editor)




ID: T02.G6.00
Topic: T02 – Algorithm Diagrams
Skill: Classify algorithms into families: search, sort, accumulate, transform
Description: **Student task:** Given 4-5 code snippets, classify each into an algorithm family: Search (find item), Sort (arrange order), Accumulate (combine values), Transform (change each item). Explain your classification. **Visual scenario:** Snippet A: loops finding maximum → "Accumulate" (combines values to find result). Snippet B: compares adjacent items and swaps → "Sort". Snippet C: looks for target value → "Search". Snippet D: doubles each item → "Transform". Match each to its family and explain why. _Implementation note: Algorithm pattern vocabulary; foundational for G7 pattern recognition. Auto-graded by correct classification + brief explanation. CSTA: E6-ALG-AF-01._

Dependencies:
* T02.G5.05: Analyze two algorithms by counting operations to determine efficiency
* T02.G5.03: Trace multiple variables including accumulators in custom trace tables


ID: T02.G6.01.01
Topic: T02 – Algorithm Diagrams
Skill: Find and use the pseudocode generation block
Description: **Student task:** Locate the "get scripts for all blocks from sprite [SPRITE] into list [LIST]" block in the Data category. Add it to your script and run it to generate pseudocode. Confirm the list contains text. **Visual scenario:** Students find the block in Data palette, connect it to a simple 3-block script, and run. They see item 1 of the list contains text description of their code. _Implementation note: Tool discovery skill. Auto-graded by successful block execution and list populated. CSTA: E6-ALG-AF-01._

Dependencies:
* T02.G5.08: Convert a flowchart to a block script


ID: T02.G6.01.02
Topic: T02 – Algorithm Diagrams
Skill: Read and interpret generated pseudocode text
Description: **Student task:** After generating pseudocode, read item 1 of the list and identify how each block translates to text. Match phrases in pseudocode back to their original blocks. **Visual scenario:** Script: [move 50] → [turn 90] → [say "Hello"]. Generated pseudocode: "move 50 steps, turn 90 degrees, say Hello". Students match each phrase: "move 50 steps" ↔ [move 50], "turn 90 degrees" ↔ [turn 90], etc. _Implementation note: Comprehension of generated pseudocode. Auto-graded by correct matching. CSTA: E6-ALG-AF-01._

Dependencies:
* T02.G6.01.01: Find and use the pseudocode generation block





ID: T02.G6.02
Topic: T02 – Algorithm Diagrams
Skill: Match block structures to their pseudocode representation
Description: **Student task:** Build scripts with different structures (sequence, loop, if/else), generate pseudocode for each, and identify how each structure appears in text form. **Visual scenario:** Students build 3 scripts: (1) sequence only, (2) with loop, (3) with if/else. Generate pseudocode for each. Match: "if...then...else" appears for conditionals, "repeat N times" for loops. _Implementation note: Structure recognition in pseudocode. Auto-graded by correct structure-to-text matching. CSTA: E6‑ALG‑AF‑01._

Dependencies:
* T02.G6.01.02: Read and interpret generated pseudocode text





ID: T02.G6.03
Topic: T02 – Algorithm Diagrams
Skill: Analyze representation differences between block script and generated pseudocode
Description: **Student task:** Compare a block script to its generated pseudocode. Identify what information is preserved vs. lost in translation. **Visual scenario:** Script uses specific block names; pseudocode uses generic terms. Script: [glide 1 secs to x:100 y:100]. Pseudocode: "glide to position (100,100) over 1 second". Students note: exact block name differs, but meaning preserved. _Implementation note: Critical analysis of representation differences. Auto-graded by correct identification. CSTA: E6‑ALG‑AF‑01._

Dependencies:
* T02.G6.02: Match block structures to their pseudocode representation





ID: T02.G6.04
Topic: T02 – Algorithm Diagrams
Skill: Write pseudocode first, then implement as blocks
Description: **Student task:** Write pseudocode on paper for a given task BEFORE coding. Then build the matching block script. Compare your pseudocode to the generated pseudocode. **Visual scenario:** Task: "Draw a triangle." Student writes: "repeat 3: move 100, turn 120". Then builds: [repeat 3] → [move 100] → [turn 120°]. Generate pseudocode to verify match. _Implementation note: Pseudocode-first planning workflow. Auto-graded by script behavior + pseudocode similarity. CSTA: E6‑ALG‑AF‑01, E6‑PRO‑PF‑01._

Dependencies:
* T02.G6.03: Identify differences between block script and its pseudocode





ID: T02.G6.05
Topic: T02 – Algorithm Diagrams
Skill: Debug by comparing actual pseudocode to intended algorithm
Description: **Student task:** Generate pseudocode from a buggy script. Compare to the intended algorithm description. Identify the mismatch and fix the blocks. **Visual scenario:** Task was "draw a square" but sprite draws a line. Generate pseudocode, see "repeat 4: move 100" (missing turn!). Compare to correct: "repeat 4: move 100, turn 90". Fix: add [turn 90°] inside loop. _Implementation note: Pseudocode-based debugging. Auto-graded by corrected script output. CSTA: E6‑ALG‑AF‑01, E6‑PRO‑TR‑03._

Dependencies:
* T02.G6.03: Identify differences between block script and its pseudocode





ID: T02.G6.06
Topic: T02 – Algorithm Diagrams
Skill: Trace a list-processing algorithm with print blocks
Description: **Student task:** Trace a script that processes a list (e.g., finding the largest value). Add print blocks to show each item examined and how the result variable updates. **Visual scenario:** Script: [set max to item 1] → [repeat for each item] → [if item > max, set max to item, print "new max: " + max]. Console shows progression: "checking 5... checking 12, new max: 12... checking 8..." _Implementation note: List traversal tracing. Auto-graded by trace accuracy. CSTA: E6‑ALG‑AF‑01, E6‑ALG‑PS‑03._

Dependencies:
* T02.G5.03: Trace multiple variables including accumulators in custom trace tables
* T10.G5.03: Work with list data structures





ID: T02.G6.07.01
Topic: T02 – Algorithm Diagrams
Skill: Build a find-maximum algorithm with trace output
Description: **Student task:** Create a script that finds the maximum value in a list. Track the "max so far" variable and print when it changes. **Visual scenario:** List: [5, 12, 8, 3, 15, 7]. Students build: [set max to item 1] → [repeat for items 2-6] → [if item > max, set max to item, print "new max found: " + max]. Console: "new max: 12... new max: 15". Final max = 15. _Implementation note: Classic find-max algorithm with tracing. Auto-graded by correct max + trace log. CSTA: E6‑ALG‑AF‑01, E6‑PRO‑PF‑01._

Dependencies:
* T02.G6.06: Trace a list-processing algorithm with print blocks


ID: T02.G6.07.02
Topic: T02 – Algorithm Diagrams
Skill: Adapt find-maximum to find-minimum and trace the difference
Description: **Student task:** Modify your find-maximum algorithm to find the minimum value instead. Trace both algorithms on the same list and compare their behavior. **Visual scenario:** List: [5, 12, 8, 3, 15, 7]. Find-max trace: starts 5, updates to 12, updates to 15. Find-min trace: starts 5, updates to 3, done. Students identify: (1) only the comparison operator changes (> becomes <), (2) update patterns differ. Question: "What's the minimum change needed to convert max to min?" **Answer:** Change > to <. _Implementation note: Algorithm adaptation skill; shows how small changes create different behaviors. Auto-graded by correct min + comparison to max trace. CSTA: E6‑ALG‑AF‑01, E6‑ALG‑IM‑04._

Dependencies:
* T02.G6.07.01: Build a find-maximum algorithm with trace output




ID: T02.G6.08
Topic: T02 – Algorithm Diagrams
Skill: Test an algorithm with normal, edge, and boundary inputs
Description: **Student task:** Test your find-max algorithm with different categories of inputs. Document results for each category. **Visual scenario:** Test categories: (1) Normal: [5, 12, 8] → max=12 ✓. (2) Edge - empty list: [] → should handle gracefully. (3) Edge - one item: [7] → max=7 ✓. (4) Boundary: all same [5,5,5] → max=5 ✓. Students test each and record pass/fail. _Implementation note: Systematic testing categories. Auto-graded by correct handling of all cases. CSTA: E6‑ALG‑AF‑01, E6‑PRO‑TR‑03._

Dependencies:
* T02.G6.07.02: Adapt find-maximum to find-minimum and trace the difference


ID: T02.G6.09
Topic: T02 – Algorithm Diagrams
Skill: Convert a flowchart diagram directly to pseudocode text
Description: **Student task:** Given a flowchart with sequence, decision, and loop structures, write equivalent pseudocode that captures the same logic. **Visual scenario:** Flowchart shows: (START) → [set sum to 0] → [repeat 5 times] → [add i to sum] → (loop back) → ◇sum > 10?◇ → "Yes" → [print "Big"] → (END), "No" → [print "Small"] → (END). Students write: "SET sum TO 0; FOR i FROM 1 TO 5: sum = sum + i; IF sum > 10 THEN PRINT 'Big' ELSE PRINT 'Small'". _Implementation note: Bridges visual flowchart to text pseudocode; critical translation skill. Auto-graded by pseudocode structure matching flowchart logic. CSTA: E6‑ALG‑AF‑01._

Dependencies:
* T02.G5.07: Draw a flowchart with nested structures
* T02.G6.02: Match block structures to their pseudocode representation


ID: T02.G6.10
Topic: T02 – Algorithm Diagrams
Skill: Create animated algorithm visualization using sprite movements
Description: **Student task:** Build an animated visualization where sprites physically demonstrate algorithm behavior. Create sprite clones or multiple sprites that move, change color, or swap positions to show algorithm steps. **Visual scenario:** Bubble sort visualization: 5 "bar" sprites of different heights. Each comparison step: two bars glow yellow, if out of order they slide and swap positions. Animation continues until sorted (all bars in ascending order left to right). Students see sorting happen step-by-step visually. _Implementation note: Animated algorithm demonstration; advanced visual tracing. Auto-graded by correct final state + animation sequence. CSTA: E6-ALG-AF-01, E6-PRO-PF-01._

Dependencies:
* T02.G6.06: Trace a list-processing algorithm with print blocks
* T06.G5.02: Broadcast a message and wait for all receivers to finish


ID: T02.G6.11
Topic: T02 – Algorithm Diagrams
Skill: Design a flowchart template for reuse across similar problems
Description: **Student task:** Create a reusable flowchart template that can be adapted for multiple similar problems. Identify which parts are fixed (structure) and which are variable (can be customized). **Visual scenario:** Template: "Process each item in a collection." Fixed structure: START → [Initialize] → [Loop through items] → ◇More items?◇ → Yes → [Process item] → (back to loop) → No → [Finalize] → END. Variable slots marked: "Initialize what?", "Process how?", "Finalize how?". Students apply template to 2 problems: (1) find sum, (2) count matches. Same structure, different slot values. _Implementation note: Template-based design thinking; introduces abstraction over algorithm patterns. Auto-graded by correct template application. CSTA: E6-ALG-AF-01, E6-ALG-IM-04._

Dependencies:
* T02.G6.09: Convert a flowchart diagram directly to pseudocode text
* T02.G6.00: Classify algorithms into families: search, sort, accumulate, transform


ID: T02.G6.12
Topic: T02 – Algorithm Diagrams
Skill: Draw a recursive algorithm diagram showing call stack
Description: **Student task:** Create a diagram that visualizes a recursive algorithm. Show the "call stack" as nested boxes or a vertical stack, with each recursive call as a new layer. Draw arrows showing how values pass down and results return up. **Visual scenario:** Task: "Diagram for factorial(4)." Students draw: [factorial(4)] calls → [factorial(3)] calls → [factorial(2)] calls → [factorial(1)] returns 1 → returns 2 → returns 6 → returns 24. Stack visualization shows 4 layers deep. Label each layer with: input value, calculation, return value. Show "going down" (calls) and "coming back up" (returns) phases. _Implementation note: Recursive call visualization; critical for understanding recursion. Uses either nested boxes or vertical stack notation. Auto-graded by correct call sequence and return values. CSTA: E6-ALG-AF-01, E6-ALG-PS-03._

Dependencies:
* T02.G6.09: Convert a flowchart diagram directly to pseudocode text
* T02.G5.07: Draw a flowchart with nested structures


ID: T02.G6.13
Topic: T02 – Algorithm Diagrams
Skill: Build an interactive flowchart editor using sprites and clicks
Description: **Student task:** Create a simple flowchart editor where users can click to place flowchart symbols on the stage, then click to connect them. Use sprites for symbols and click detection for user interaction. **Visual scenario:** Students build: (1) Toolbar with symbol sprites (rectangle, diamond, oval, arrow), (2) When user clicks a symbol, it creates a clone at the mouse position, (3) When user clicks two symbols in sequence, draw a line connecting them. Users can build their own flowcharts! Add a "Clear" button to reset. _Implementation note: Advanced project combining sprites, cloning, click detection, and drawing. Introduces tool-building mindset. Auto-graded by editor functionality: can create symbols + can connect them. CSTA: E6-PRO-PF-01, E6-ALG-AF-01._

Dependencies:
* T02.G6.10: Create animated algorithm visualization using sprite movements
* T02.G4.11: Create an animated flowchart that highlights current step during execution


---

## GRADE 7 (16 skills - added T02.G7.10 sequence diagrams, T02.G7.11 parallel algorithms)




ID: T02.G7.01.01
Topic: T02 – Algorithm Diagrams
Skill: Trace a simulation with counter/accumulator patterns
Description: **Student task:** Trace a script that simulates change over time using counters (e.g., score increasing, population growing). Print state after each iteration and predict future values. **Visual scenario:** Simulation: bank balance grows by 10% each year. Script: [set balance to 100] → [repeat 5] → [change balance by balance * 0.1, print balance]. Trace: 110, 121, 133.1... Students predict year 6 value. _Implementation note: Simulation tracing with growth patterns. Auto-graded by prediction accuracy. CSTA: E7‑ALG‑AF‑01, E7‑ALG‑PS‑03._

Dependencies:
* T02.G6.06: Trace a list-processing algorithm with print blocks





ID: T02.G7.01.02
Topic: T02 – Algorithm Diagrams
Skill: Trace a physics simulation with position and velocity
Description: **Student task:** Trace a physics simulation where velocity affects position each frame. Track multiple state variables (position, velocity, acceleration) in a trace table. **Visual scenario:** Falling ball: [set y to 200, velocity to 0] → [repeat] → [change velocity by -2 (gravity), change y by velocity, print "y=" + y + " v=" + velocity]. Trace: y=200,v=0 | y=198,v=-2 | y=194,v=-4... _Implementation note: Physics simulation with multiple coupled variables. Auto-graded by trace table accuracy. CSTA: E7‑ALG‑AF‑01, E7‑ALG‑PS‑03._

Dependencies:
* T02.G7.01.01: Trace a simulation with counter/accumulator patterns





ID: T02.G7.02.01
Topic: T02 – Algorithm Diagrams
Skill: Add a breakpoint block to pause execution at a specific line
Description: **Student task:** Add the "breakpoint" block from Control category at a strategic point in a script. Run in Debug Mode (blue arrow) to pause execution there. **Visual scenario:** Script: [set x to 0] → [repeat 5] → [change x by 10] → [BREAKPOINT] → [say x]. Run in Debug Mode. Execution pauses after the loop. Students see x=50 before the say block runs. _Implementation note: Introduces breakpoint debugging tool. Auto-graded by correct breakpoint placement and pause observation. CSTA: E7‑PRO‑TR‑03._

Dependencies:
* T02.G6.05: Debug by comparing actual pseudocode to intended algorithm





ID: T02.G7.02.02
Topic: T02 – Algorithm Diagrams
Skill: Inspect variable values and compare to predictions at a breakpoint
Description: **Student task:** Pause at a breakpoint in Debug Mode. Examine the current values of all variables in the variable panel. Compare actual values to your predictions. **Visual scenario:** Script paused at breakpoint mid-loop. Variable panel shows: x=30, count=3. Student predicted x=40 at this point—there's a bug! The mismatch reveals the loop started counting from 1 instead of 0. _Implementation note: Variable inspection during pause. Auto-graded by prediction vs actual comparison. CSTA: E7‑PRO‑TR‑03._

Dependencies:
* T02.G7.02.01: Add a breakpoint block to pause execution at a specific line





ID: T02.G7.02.03
Topic: T02 – Algorithm Diagrams
Skill: Step through code block-by-block using Debug Mode controls
Description: **Student task:** After pausing at a breakpoint, use Debug Mode's step controls to execute one block at a time. Watch variables and sprite state change after each step. **Visual scenario:** Paused at breakpoint. Click "Step Over" → one block executes → x changes from 10 to 20 → click again → another block → sprite moves. Students trace execution manually, block by block. _Implementation note: Step-through debugging. Auto-graded by accurate step-by-step trace. CSTA: E7‑PRO‑TR‑03._

Dependencies:
* T02.G7.02.02: Examine variable values in the variable panel at a breakpoint





ID: T02.G7.03.01
Topic: T02 – Algorithm Diagrams
Skill: Build a linear search algorithm to find a target value
Description: **Student task:** Create a script that searches through a list sequentially to find a specific target value. Return the position where it's found (or "not found"). **Visual scenario:** List: [4, 8, 2, 7, 5]. Target: 7. Students build: [repeat for each item] → [if item = target, say "Found at position " + i]. Script checks 4, 8, 2, 7 → "Found at position 4". _Implementation note: Basic linear search algorithm. Auto-graded by correct position returned. CSTA: E7‑ALG‑AF‑01, E7‑PRO‑PF‑01._

Dependencies:
* T02.G6.07: Build a find-maximum algorithm with trace output
* T10.G5.03: Work with list data structures





ID: T02.G7.03.02
Topic: T02 – Algorithm Diagrams
Skill: Add trace output to visualize search algorithm steps
Description: **Student task:** Add print blocks to your search algorithm to show each comparison in the console. Make the search process visible step-by-step. **Visual scenario:** Searching for 7 in [4, 8, 2, 7, 5]. Console output: "Checking item 1: 4 - no match", "Checking item 2: 8 - no match", "Checking item 3: 2 - no match", "Checking item 4: 7 - FOUND!" _Implementation note: Search algorithm tracing. Auto-graded by correct trace sequence. CSTA: E7‑ALG‑AF‑01, E7‑PRO‑TR‑03._

Dependencies:
* T02.G7.03.01: Build a linear search algorithm to find a target value





ID: T02.G7.03.03
Topic: T02 – Algorithm Diagrams
Skill: Optimize search with early exit when target is found
Description: **Student task:** Modify your search algorithm to stop immediately when the target is found instead of checking all remaining items. Use "stop this script" or a flag variable. **Visual scenario:** List: [4, 8, 7, 2, 5]. Target: 7. Without early exit: checks all 5 items. With early exit: stops after item 3. Console shows only 3 checks instead of 5. Compare efficiency. _Implementation note: Early exit optimization. Auto-graded by reduced comparison count. CSTA: E7‑ALG‑IM‑04, E7‑PRO‑PF‑01._

Dependencies:
* T02.G7.03.02: Add trace output to visualize search algorithm steps





ID: T02.G7.04
Topic: T02 – Algorithm Diagrams
Skill: Generate and analyze pseudocode for a search algorithm
Description: **Student task:** Generate pseudocode from your search algorithm. Analyze how the pseudocode represents the search logic (iteration, comparison, early exit). **Visual scenario:** Block script for linear search with early exit. Generated pseudocode: "for each item in list: if item equals target: return position; stop searching; return not found". Students identify: loop structure, conditional check, early exit pattern. _Implementation note: Pseudocode analysis of search algorithms. Auto-graded by structure identification. CSTA: E7‑ALG‑AF‑01._

Dependencies:
* T02.G7.03.03: Optimize search with early exit when target is found
* T02.G6.02: Match block structures to their pseudocode representation





ID: T02.G7.05
Topic: T02 – Algorithm Diagrams
Skill: Compare search algorithm efficiency by counting comparisons
Description: **Student task:** Compare two search algorithms on the same input. Count comparisons each makes using a counter variable and print blocks. **Visual scenario:** List: [4, 8, 2, 7, 5, 9, 1, 3]. Target: 7. Algorithm A (no early exit): 8 comparisons. Algorithm B (early exit): 4 comparisons. Students add [change comparisons by 1] inside loop and print final count. _Implementation note: Algorithm efficiency comparison. Auto-graded by correct counts. CSTA: E7‑ALG‑IM‑04._

Dependencies:
* T02.G7.03.03: Optimize search with early exit when target is found
* T02.G5.05: Compare two algorithms by counting operations





ID: T02.G7.06
Topic: T02 – Algorithm Diagrams
Skill: Debug edge case failures using breakpoints and trace output
Description: **Student task:** Test your search algorithm with edge cases. Use breakpoints and print blocks to identify where/why it fails. **Visual scenario:** Edge cases: (1) empty list [] → should return "not found" without error. (2) single item [7] → should find it. (3) target not in list [1,2,3] target=9 → should return "not found". Students step through with breakpoints to find bugs. _Implementation note: Edge case debugging. Auto-graded by all edge cases handled. CSTA: E7‑PRO‑TR‑03._

Dependencies:
* T02.G7.02.03: Step through code block-by-block using Debug Mode controls
* T02.G7.03.02: Add trace output to visualize search algorithm steps
* T02.G6.08: Test an algorithm with normal, edge, and boundary inputs


ID: T02.G7.07.01
Topic: T02 – Algorithm Diagrams
Skill: Explain the split-the-list strategy for efficient search
Description: **Student task:** Given a sorted list, explain why checking the middle element first is faster than checking from the start. Compare linear vs binary approach. **Visual scenario:** Sorted list [2,5,8,11,14,17,20]. Target: 17. Compare: Linear search checks 2,5,8,11,14,17 (6 comparisons). Binary: check 11 (too small, go right), check 17 (found!) (2 comparisons). Students explain why splitting eliminates half the list each time. _Implementation note: Conceptual understanding before tracing; builds intuition for logarithmic efficiency. Auto-graded by explanation of elimination reasoning. CSTA: E7-ALG-AF-01._

Dependencies:
* T02.G7.05: Compare search algorithm efficiency by counting comparisons


ID: T02.G7.07.02
Topic: T02 – Algorithm Diagrams
Skill: Trace binary search showing search space reduction at each step
Description: **Student task:** Trace a binary search algorithm on a sorted list. Record after each step: the range being searched, the middle element checked, and the decision (go left/right/found). **Visual scenario:** Sorted list: [2, 5, 8, 11, 14, 17, 20]. Target: 14. Trace table: Step 1: Range [0-6], mid=11, 14>11 → go right. Step 2: Range [4-6], mid=17, 14<17 → go left. Step 3: Range [4-4], mid=14, FOUND! Students fill detailed trace showing each split decision. _Implementation note: Detailed binary search tracing; O(log n) efficiency demonstrated. Auto-graded by trace table accuracy. CSTA: E7-ALG-AF-01, E7-ALG-PS-03._

Dependencies:
* T02.G7.07.01: Explain the split-the-list strategy for efficient search
* T02.G7.03.03: Optimize search with early exit when target is found


ID: T02.G7.08
Topic: T02 – Algorithm Diagrams
Skill: Design a flowchart showing multi-sprite algorithm coordination
Description: **Student task:** Create a flowchart that shows how multiple sprites coordinate to execute an algorithm together. Use swim lanes (parallel columns) for each sprite, with arrows showing broadcasts between them. **Visual scenario:** Turn-based game flowchart: Player sprite column shows "wait for turn → make move → broadcast 'done'". Enemy sprite column shows "wait for 'done' → calculate move → execute move → broadcast 'player-turn'". Draw synchronization arrows between lanes showing message passing. _Implementation note: Multi-actor flowchart with swim lanes; connects to T06 events. Auto-graded by correct swim lane structure and broadcast arrows. CSTA: E7-ALG-AF-01._

Dependencies:
* T02.G6.09: Convert a flowchart diagram directly to pseudocode text
* T06.G5.03: Build a level-start/level-end broadcast sequence coordinating 3 sprites


ID: T02.G7.09
Topic: T02 – Algorithm Diagrams
Skill: Build an algorithm visualization that animates execution with user controls
Description: **Student task:** Create an interactive algorithm visualization where users can control playback: play, pause, step forward, step backward, and adjust speed. Display current step, variable values, and highlight active code. **Visual scenario:** Binary search visualization: sorted list of numbers displayed. User clicks "Step" → middle element highlights, comparison shown, half of list grays out. User clicks "Step" again → next middle highlights. "Speed" slider adjusts animation timing. "Reset" button restarts. Students build controls using button widgets and implement animation logic. _Implementation note: Full-featured algorithm animator; combines T15 widgets with algorithm tracing. Auto-graded by control functionality + correct algorithm animation. CSTA: E7-ALG-AF-01, E7-PRO-PF-01._

Dependencies:
* T02.G6.10: Create animated algorithm visualization using sprite movements
* T02.G5.09: Build an interactive algorithm stepper using button and label widgets


ID: T02.G7.10
Topic: T02 – Algorithm Diagrams
Skill: Design a sequence diagram for multi-sprite message passing
Description: **Student task:** Create a sequence diagram showing how multiple sprites communicate over time. Draw vertical "lifelines" for each sprite, with horizontal arrows showing broadcasts and responses. Time flows downward. **Visual scenario:** Three sprites: Player, Enemy, GameManager. Sequence diagram shows: Player→GameManager: "I moved" | GameManager→Enemy: "Check collision" | Enemy→GameManager: "Collision detected" | GameManager→Player: "Take damage". Students draw lifelines, arrows with message labels, and show the order of communication. Compare to actual broadcast/receive blocks in code. _Implementation note: UML-lite sequence diagrams; visualizes event-driven programming. Connects to T06 broadcast skills. Auto-graded by correct message order and sprite identification. CSTA: E7-ALG-AF-01, E7-PRO-PF-01._

Dependencies:
* T02.G7.08: Design a flowchart showing multi-sprite algorithm coordination
* T02.G6.10: Create animated algorithm visualization using sprite movements


ID: T02.G7.11
Topic: T02 – Algorithm Diagrams
Skill: Trace parallel algorithms showing concurrent execution paths
Description: **Student task:** Trace an algorithm where multiple scripts run simultaneously on different sprites. Create a timeline diagram showing what each sprite is doing at each moment, and identify points where they interact. **Visual scenario:** Two sprites both running "forever" loops. Sprite A: move, check collision. Sprite B: move, check collision. Timeline shows: t=0: both start | t=1: A moves, B moves | t=2: A checks, B checks | t=3: COLLISION—both respond. Students trace parallel paths, mark synchronization points, identify race conditions (what if A checks before B moves?). _Implementation note: Parallel execution tracing; critical for understanding concurrent programs and multiplayer games. Auto-graded by correct timeline + interaction point identification. CSTA: E7-ALG-AF-01, E7-ALG-PS-03._

Dependencies:
* T02.G7.10: Design a sequence diagram for multi-sprite message passing
* T02.G7.01.02: Trace a physics simulation with position and velocity


---

## GRADE 8 (22 skills - added 7 advanced skills for AI-era, scalability, formal methods)




ID: T02.G8.01.01
Topic: T02 – Algorithm Diagrams
Skill: Write pseudocode for a multi-step calculation algorithm
Description: **Student task:** Write pseudocode on paper for an algorithm that performs multiple sequential calculations. Use clear variable names and proper structure. **Visual scenario:** Task: "Calculate the average of a list of numbers." Student writes: "SET sum to 0; FOR each number in list: ADD number to sum; SET average to sum / count; RETURN average". Then implement and verify. _Implementation note: Pseudocode writing for calculations. Auto-graded by pseudocode structure + implementation match. CSTA: E8‑ALG‑AF‑01._

Dependencies:
* T02.G6.04: Write pseudocode first, then implement as blocks





ID: T02.G8.01.02
Topic: T02 – Algorithm Diagrams
Skill: Write pseudocode for input validation with error handling
Description: **Student task:** Write pseudocode for an algorithm that validates user input and handles invalid cases. Use loops for re-prompting and conditionals for validation. **Visual scenario:** Task: "Get a number between 1-100 from user." Student writes: "REPEAT: ASK user for number; IF number < 1 OR number > 100: PRINT 'Invalid, try again'; UNTIL number is valid; RETURN number". _Implementation note: Validation loop pattern. Auto-graded by handling invalid inputs correctly. CSTA: E8‑ALG‑AF‑01._

Dependencies:
* T02.G8.01.01: Write pseudocode for a multi-step calculation algorithm





ID: T02.G8.01.03
Topic: T02 – Algorithm Diagrams
Skill: Write pseudocode for a data processing algorithm
Description: **Student task:** Write pseudocode for an algorithm that processes a collection of data to produce a result. Include loops, conditionals, and helper steps. **Visual scenario:** Task: "Find the median of a list." Student writes: "SORT the list; SET middle to length / 2; IF length is odd: RETURN item at middle; ELSE: RETURN average of items at middle and middle+1". _Implementation note: Complex data processing pseudocode. Auto-graded by algorithm correctness. CSTA: E8‑ALG‑AF‑01._

Dependencies:
* T02.G8.01.01: Write pseudocode for a multi-step calculation algorithm
* T10.G6.01: Sort a table by a column





ID: T02.G8.02
Topic: T02 – Algorithm Diagrams
Skill: Implement pseudocode as blocks and verify with generated pseudocode
Description: **Student task:** Take written pseudocode and implement it as a CreatiCode block script. Generate pseudocode from your blocks and compare to verify your implementation matches the plan. **Visual scenario:** Given pseudocode for average calculation. Students build blocks. Generate pseudocode. Compare: original says "divide by count", generated says "divide by length of list" — equivalent! Implementation verified. _Implementation note: Pseudocode → code → verification cycle. Auto-graded by behavior match. CSTA: E8‑ALG‑AF‑01, E8‑PRO‑PF‑01._

Dependencies:
* T02.G8.01.01: Write pseudocode for a multi-step calculation algorithm
* T02.G6.01: Use the pseudocode generation block to export algorithm text





ID: T02.G8.03.01
Topic: T02 – Algorithm Diagrams
Skill: Design a comprehensive test plan for an algorithm
Description: **Student task:** Create a test plan document listing test cases by category: normal cases (typical inputs), edge cases (empty, single item, extremes), boundary cases (at limits). Write expected output for each. **Visual scenario:** For median algorithm, students create: Normal: [1,2,3,4,5]→expected 3. Edge: []→error, [5]→5. Boundary: [1,1,1,1]→1, all same values. Even length: [1,2,3,4]→2.5. List 8+ test cases with expected outputs before running any code. _Implementation note: Test planning skill; design before execution. Auto-graded by test case coverage + correct expected outputs. CSTA: E8-ALG-AF-01, E8-PRO-TR-03._

Dependencies:
* T02.G8.02: Implement pseudocode as blocks and verify with generated pseudocode
* T02.G7.06: Debug edge case failures using breakpoints and trace output


ID: T02.G8.03.02
Topic: T02 – Algorithm Diagrams
Skill: Execute test plan and document results
Description: **Student task:** Run each test case from your test plan, record actual output, compare to expected, mark pass/fail. Document any failures with details about what went wrong. **Visual scenario:** Test matrix with columns: Test | Input | Expected | Actual | Pass/Fail. Students fill in actual outputs: [1,2,3,4,5]→3 ✓Pass. []→crash ✗Fail (expected error message, got crash). Document failure details: "Empty list causes division by zero". _Implementation note: Test execution and documentation; systematic verification. Auto-graded by accuracy of pass/fail determination. CSTA: E8-PRO-TR-03._

Dependencies:
* T02.G8.03.01: Design a comprehensive test plan for an algorithm





ID: T02.G8.04
Topic: T02 – Algorithm Diagrams
Skill: Refactor algorithms by identifying and removing redundancy
Description: **Student task:** Analyze a complex algorithm to find redundant operations. Remove them and verify the simplified version still works. **Visual scenario:** Original: calculates sum twice, stores intermediate values never used. Pseudocode shows: "sum = 0; for each x: sum += x; total = sum; average = total / count". Redundant: "total" variable. Simplified: "sum = 0; for each x: sum += x; average = sum / count". Test to verify same behavior. _Implementation note: Algorithm refactoring. Auto-graded by behavior preservation + reduced complexity. CSTA: E8‑ALG‑IM‑04._

Dependencies:
* T02.G8.03.02: Execute test plan and document results
* T02.G5.06: Optimize an algorithm by removing redundant blocks






ID: T02.G8.05
Topic: T02 – Algorithm Diagrams
Skill: Compare deterministic vs probabilistic algorithm outputs
Description: **Student task:** Build two versions of an algorithm—one deterministic (same input → same output) and one probabilistic (uses randomness). Run each multiple times and compare outputs. **Visual scenario:** Task: "Select an item from a list." Deterministic: always return first item. Probabilistic: return random item using [pick random]. Run 5 times each. Deterministic: A,A,A,A,A. Probabilistic: C,A,D,B,A. Discuss when each is appropriate. _Implementation note: Algorithm behavior comparison. Auto-graded by correct identification of patterns. CSTA: E8‑ALG‑AF‑01._

Dependencies:
* T02.G8.03.02: Execute test plan and document results
* T02.G7.01.02: Trace a physics simulation with position and velocity








ID: T02.G8.06.01
Topic: T02 – Algorithm Diagrams
Skill: Draw a state diagram for a multi-state algorithm
Description: **Student task:** Create a state diagram showing states (circles) and transitions (arrows with labels) for an algorithm with multiple modes. **Visual scenario:** Task: "Draw a state diagram for a traffic light controller." States: Red, Yellow, Green (shown as circles). Transitions: Red→Green (after 30s), Green→Yellow (after 25s), Yellow→Red (after 5s). Students draw circles for each state, arrows with timing labels. Question: "If currently Green for 20s, what's next state after 10s?" **Answer:** Yellow. _Implementation note: State diagram notation; useful for game states, UI modes, simulations. Auto-graded by correct states and transitions. CSTA: E8‑ALG‑AF‑01._

Dependencies:
* T02.G7.01.02: Trace a physics simulation with position and velocity
* T02.G6.09: Convert a flowchart diagram directly to pseudocode text


ID: T02.G8.06.02
Topic: T02 – Algorithm Diagrams
Skill: Implement a state machine from a state diagram using variables and conditionals
Description: **Student task:** Take a state diagram and implement it as a working CreatiCode script. Use a variable to track current state, conditionals to handle transitions. **Visual scenario:** Implement the traffic light state diagram. Students build: [set state to "red"] → [forever loop] → [if state = "red" and timer > 30: set state to "green", reset timer] → [if state = "green" and timer > 25: set state to "yellow", reset timer] → [if state = "yellow" and timer > 5: set state to "red", reset timer]. Light sprite changes color based on state variable. _Implementation note: State machine implementation; connects diagram representation to executable code. Auto-graded by correct state transitions. CSTA: E8‑ALG‑AF‑01, E8‑PRO‑PF‑01._

Dependencies:
* T02.G8.06.01: Draw a state diagram for a multi-state algorithm


ID: T02.G8.07
Topic: T02 – Algorithm Diagrams
Skill: Analyze algorithm complexity by counting operations at different scales
Description: **Student task:** Compare two algorithms by counting operations for small and large inputs. Recognize which algorithm scales better. **Visual scenario:** Task: "Count comparisons for linear search vs binary search." List sizes: 8 items, 64 items, 1024 items. Linear search (worst): 8, 64, 1024 comparisons. Binary search (worst): 3, 6, 10 comparisons. Students fill in table, observe: linear grows with N, binary grows slowly (log N). Question: "For 1 million items, which is faster?" **Answer:** Binary search (by far). _Implementation note: Intuitive complexity comparison; lays foundation for Big-O thinking. Auto-graded by correct operation counts and comparison. CSTA: E8‑ALG‑IM‑04._

Dependencies:
* T02.G7.07.02: Trace binary search showing search space reduction at each step
* T02.G7.05: Compare search algorithm efficiency by counting comparisons


ID: T02.G8.08
Topic: T02 – Algorithm Diagrams
Skill: Use AI to generate and verify pseudocode for a complex algorithm
Description: **Student task:** Use the ChatGPT block to request pseudocode for a given task. Verify the AI-generated pseudocode by tracing through test cases, then implement and compare. **Visual scenario:** Task: "Get pseudocode for finding the second-largest number in a list." Prompt ChatGPT: "Write pseudocode to find the second largest number." AI returns pseudocode. Students: (1) trace pseudocode with [5,9,3,9,7], (2) identify if it handles duplicates correctly, (3) implement in blocks, (4) test edge cases. If AI made errors, debug and fix. _Implementation note: AI-assisted algorithm design with human verification; critical skill for AI-augmented programming. Auto-graded by correct implementation handling all test cases. CSTA: E8‑ALG‑AF‑01, E8‑AI‑INT‑04._

Dependencies:
* T02.G8.01.03: Write pseudocode for a data processing algorithm
* T02.G8.03.02: Execute test plan and document results


ID: T02.G8.09
Topic: T02 – Algorithm Diagrams
Skill: Document an algorithm with structured comments explaining each section
Description: **Student task:** Add comprehensive documentation to a complex algorithm: (1) Header comment explaining algorithm purpose and inputs/outputs, (2) Section comments marking major phases (initialize, process, output), (3) Inline comments explaining non-obvious logic. **Visual scenario:** Document a find-median algorithm: "-- PURPOSE: Find median of list, handles odd/even lengths --", "-- PHASE 1: Sort the list --", "-- PHASE 2: Find middle --", "-- Note: for even length, average two middle values --". Students create self-documenting code with clear structure. _Implementation note: Algorithm documentation standards; prepares for collaborative coding and code review. Auto-graded by comment structure + coverage of key sections. CSTA: E8-PRO-PF-01._

Dependencies:
* T02.G8.04: Refactor algorithms by identifying and removing redundancy
* T02.G6.04: Write pseudocode first, then implement as blocks


ID: T02.G8.10
Topic: T02 – Algorithm Diagrams
Skill: Verify AI-generated algorithm against test cases to identify and correct errors
Description: **Student task:** Given AI-generated pseudocode for a task, systematically verify it by: (1) tracing through 3+ test cases (normal, edge, boundary), (2) identifying any errors in the AI output, (3) correcting the pseudocode. **Visual scenario:** AI generates pseudocode for "find second smallest". Students trace: [5,3,8]→works. [5,5,5]→fails (duplicates not handled). [5]→fails (not enough items). Students identify bugs: "AI assumed all unique values" and "AI didn't check list length". Propose corrections: add duplicate handling, add length check. _Implementation note: Critical AI verification skill; human oversight of AI tools. Auto-graded by error identification + correction quality. CSTA: E8-ALG-AF-01, E8-AI-INT-04._

Dependencies:
* T02.G8.08: Use AI to generate and verify pseudocode for a complex algorithm
* T02.G8.03.02: Execute test plan and document results


ID: T02.G8.11
Topic: T02 – Algorithm Diagrams
Skill: Compare and reconcile algorithm diagrams from multiple team members
Description: **Student task:** Given two different flowcharts created by different team members for the same problem, compare them systematically: identify structural differences, determine which elements are equivalent but expressed differently, find genuine disagreements, and propose a reconciled version. **Visual scenario:** Team member A's flowchart for "validate password": checks length first, then special characters. Team member B's flowchart: checks special characters first, then length. Students analyze: (1) Both check the same things, (2) Order differs—does it matter? (3) A has more detailed error messages, (4) B handles empty input explicitly. Reconcile: combine A's detail with B's edge case handling. Propose merged flowchart. _Implementation note: Collaborative algorithm design; critical for team projects. Prepares for code review skills. Auto-graded by identification of differences + quality of reconciliation. CSTA: E8-ALG-AF-01, E8-PRO-PF-01._

Dependencies:
* T02.G8.09: Document an algorithm with structured comments explaining each section
* T02.G7.08: Design a flowchart showing multi-sprite algorithm coordination


ID: T02.G8.12
Topic: T02 – Algorithm Diagrams
Skill: Draw a system architecture diagram showing component interactions
Description: **Student task:** Create a system architecture diagram for a multi-component project. Show components as boxes, data flows as arrows, and external systems (user input, databases, APIs) with special notation. **Visual scenario:** Project: "Multiplayer quiz game." Architecture diagram shows: [User Interface] ↔ [Game Logic] ↔ [Score Manager] | [Game Logic] ↔ [Cloud Database] | [Game Logic] ↔ [Timer] | [Multiple Players] ↔ [Sync Manager]. Students identify: (1) Which components talk to each other, (2) Data flowing between them, (3) External dependencies. Label each arrow with what data flows (e.g., "quiz question", "player answer", "score update"). _Implementation note: System-level design thinking; prepares for large project architecture. Similar to professional architecture diagrams. Auto-graded by correct component relationships. CSTA: E8-ALG-AF-01, E8-SYS-02._

Dependencies:
* T02.G8.06.02: Implement a state machine from a state diagram using variables and conditionals
* T02.G7.10: Design a sequence diagram for multi-sprite message passing


ID: T02.G8.13
Topic: T02 – Algorithm Diagrams
Skill: Use AI to generate flowcharts from natural language descriptions
Description: **Student task:** Use the ChatGPT block to request a flowchart description from a natural language algorithm description. Parse the AI response into actual flowchart elements and draw the diagram. Verify the AI-generated structure is correct. **Visual scenario:** Task: "I want to check if a number is prime." Students prompt ChatGPT: "Describe a flowchart for checking if a number is prime. List each shape and connection." AI responds with text description. Students: (1) Parse response into shapes/connections, (2) Draw the flowchart, (3) Trace through examples to verify correctness, (4) Fix any AI errors. _Implementation note: AI-assisted diagram generation with human verification; critical skill for AI-augmented development. Auto-graded by correct final flowchart + verification documentation. CSTA: E8-ALG-AF-01, E8-AI-INT-04._

Dependencies:
* T02.G8.08: Use AI to generate and verify pseudocode for a complex algorithm
* T02.G6.09: Convert a flowchart diagram directly to pseudocode text


ID: T02.G8.14
Topic: T02 – Algorithm Diagrams
Skill: Create algorithm diagrams for scalable systems (millions of data points)
Description: **Student task:** Design algorithm diagrams that work at scale. Show how your algorithm handles 10 items vs 1,000,000 items. Identify bottlenecks and show optimization strategies in the diagram. **Visual scenario:** Task: "Search algorithm at scale." Diagram 1: Linear search on 10 items (simple loop). Diagram 2: Same algorithm on 1,000,000 items—add annotations showing "1M comparisons needed!" Diagram 3: Binary search alternative with annotations "only 20 comparisons needed at 1M scale". Students annotate diagrams with operation counts at different scales. Question: "At what scale does the difference matter?" _Implementation note: Scalability thinking in algorithm design; critical for real-world applications. Connects to G8.07 complexity analysis. Auto-graded by correct scale annotations + bottleneck identification. CSTA: E8-ALG-IM-04, E8-ALG-AF-01._

Dependencies:
* T02.G8.07: Analyze algorithm complexity by counting operations at different scales
* T02.G7.07.02: Trace binary search showing search space reduction at each step


ID: T02.G8.15
Topic: T02 – Algorithm Diagrams
Skill: Build a diagram version control system tracking changes over time
Description: **Student task:** Create a system that saves multiple versions of a diagram and allows comparing versions. Use list variables to store diagram states, add "Save Version" and "Load Version" buttons, and show what changed between versions. **Visual scenario:** Students build: (1) "Save Version" button that stores current diagram state to a list, (2) Version selector showing v1, v2, v3, (3) "Load Version" to restore a previous state, (4) "Compare Versions" that highlights differences (boxes added/removed/moved). Test by making changes, saving, making more changes, then comparing. _Implementation note: Version control concepts applied to diagrams; prepares for git/collaboration workflows. Advanced project using lists + widgets. Auto-graded by save/load functionality + version comparison. CSTA: E8-PRO-PF-01, E8-COL-02._

Dependencies:
* T02.G8.11: Compare and reconcile algorithm diagrams from multiple team members
* T02.G6.13: Build an interactive flowchart editor using sprites and clicks


ID: T02.G8.16
Topic: T02 – Algorithm Diagrams
Skill: Design a formal specification from a flowchart for verification
Description: **Student task:** Convert a flowchart into a formal specification that can be verified. Write preconditions (what must be true before), postconditions (what must be true after), and invariants (what stays true during). Use these to prove the algorithm is correct. **Visual scenario:** Flowchart for "find maximum in list." Formal specification: PRECONDITION: list has ≥1 item. POSTCONDITION: result equals the largest value in list. INVARIANT: maxSoFar is always ≥ all items seen so far. Students annotate flowchart with these formal statements. Trace through to verify invariant holds at each step. _Implementation note: Formal methods introduction; prepares for software verification and correctness proofs. Advanced theoretical concept. Auto-graded by correct specification statements + verification trace. CSTA: E8-ALG-AF-01, E8-PRO-TR-03._

Dependencies:
* T02.G8.04: Refactor algorithms by identifying and removing redundancy
* T02.G8.03.02: Execute test plan and document results


ID: T02.G8.17
Topic: T02 – Algorithm Diagrams
Skill: Critique AI-generated diagrams and improve them systematically
Description: **Student task:** Given an AI-generated flowchart (with intentional flaws), systematically critique it: identify structural issues, missing edge cases, unclear labels, and incorrect logic. Then improve the diagram with specific fixes. **Visual scenario:** AI generated a flowchart for "password validation." Flaws: (1) Missing edge case for empty password, (2) Unclear label "check stuff", (3) Wrong order—checks length after checking characters, (4) No error messages shown. Students: (1) List all flaws found, (2) Explain why each is a problem, (3) Draw improved version fixing all issues. Compare original to improved. _Implementation note: Critical evaluation of AI outputs; essential skill for AI-augmented work. Develops systematic critique methodology. Auto-graded by flaw identification + quality of improvements. CSTA: E8-AI-INT-04, E8-ALG-AF-01._

Dependencies:
* T02.G8.13: Use AI to generate flowcharts from natural language descriptions
* T02.G8.10: Verify AI-generated algorithm against test cases to identify and correct errors


ID: T02.G8.18
Topic: T02 – Algorithm Diagrams
Skill: Draw a pipeline diagram for data processing workflows
Description: **Student task:** Create a pipeline diagram showing how data flows through multiple processing stages. Each stage transforms the data and passes it to the next. Show intermediate data states between stages. **Visual scenario:** Task: "Image processing pipeline." Diagram: [Raw image] → Stage 1: [Resize to 256x256] → [256x256 image] → Stage 2: [Convert to grayscale] → [grayscale image] → Stage 3: [Detect edges] → [edge map] → Stage 4: [Find shapes] → [shape list] → OUTPUT. Label each arrow with the data format at that point. Question: "What happens if Stage 2 fails?" Add error handling branches. _Implementation note: Pipeline architecture; common in data science, ML, and modern applications. Shows data transformation focus vs control flow focus. Auto-graded by correct stage sequence + data labels. CSTA: E8-ALG-AF-01, E8-DATA-02._

Dependencies:
* T02.G8.12: Draw a system architecture diagram showing component interactions
* T02.G4.09: Draw a data flow diagram showing input, process, and output


# T03 - Problem Decomposition (Phase 7 Optimized - November 2025)
# Applied Phase 7 comprehensive optimizations:
# MAJOR CHANGES FROM PHASE 6:
# 1. NEW SKILLS ADDED (18 new skills for depth, AI-era thinking, and team collaboration):
#    - T03.G2.11: Debug a project plan with steps in wrong order
#    - T03.G3.00.01: Match picture-based task steps to block code equivalents
#    - T03.G3.00.02: Translate a picture step into multiple code blocks
#    - T03.G4.14: Apply chosen decomposition strategy to implement a project
#    - T03.G5.02.01: Label diagram connections with navigation conditions
#    - T03.G5.11: Decompose a voice-controlled project into recognition/processing/response phases
#    - T03.G6.11: Separate components suitable for AI assistance from those requiring human judgment
#    - T03.G6.12: Design module isolation for independent AI vs deterministic testing
#    - T03.G7.13: Identify which modules can be built independently vs sequentially for team work
#    - T03.G7.14: Design module interfaces for clean team handoffs
#    - T03.G8.17: Design iterative human-AI feedback loops in project architecture
#    - T03.G8.18: Decompose for AI oversight with human checkpoints at critical decisions
#    - T03.G8.19: Decompose privacy-sensitive projects separating public/private data components
#    - T03.G8.20: Detect and mitigate AI bias in AI-assisted decomposition suggestions
# 2. STRENGTHENED G2→G3 BRIDGE:
#    - Added sub-skills T03.G3.00.01 and T03.G3.00.02 to ease picture-to-code transition
#    - Added G2.11 for debugging order-based issues before coding
# 3. TEAM COLLABORATION PROGRESSION:
#    - Added G7.13 and G7.14 to prepare for G8.15 team development skill
# 4. ENHANCED AI-ERA SKILLS:
#    - Prompt engineering decomposition (G5)
#    - AI vs human task separation (G6)
#    - Human-AI feedback loops and oversight (G8)
#    - Privacy-aware decomposition (G8)
#    - AI bias detection in decomposition (G8)
# 5. IMPROVED ACTIVE VERBS:
#    - Changed "Evaluate" → "Compare and analyze" or "Critique"
#    - Changed "Identify" → "Locate", "Find", or "Detect"
# 6. ENHANCED DEPTH AT UPPER GRADES:
#    - G6-G8 skills now address AI oversight, privacy, and bias
#    - More sophisticated architectural thinking
# Previous Phase 6 optimizations preserved
# Total: 123 skills (was 109, added 14 new skills)

ID: T03.GK.01
Topic: T03 – Problem Decomposition
Skill: Locate and tap picture cards showing parts of a whole object
Description: **Student task:** Locate and tap on picture cards showing individual parts that belong to a whole object. **Visual scenario:** See a picture card of a playground. Locate and tap on picture cards of parts: slide, swings, sandbox, bench. Distractors include unrelated items like a book or cup. PICTURE-BASED visual recognition activity with audio support for pre-readers.






ID: T03.GK.02
Topic: T03 – Problem Decomposition
Skill: Drag picture cards of parts to match their whole objects
Description: **Student task:** Drag picture cards of close-up parts to the whole objects they belong to. **Visual scenario:** Drag "wheel" to "car," drag "keyboard" to "computer," drag "door handle" to "refrigerator." 4-5 matching pairs with clear visual cues. PICTURE-BASED drag-and-drop matching activity.

Dependencies:
* T03.GK.01: Tap picture cards to identify parts of a whole object







ID: T03.GK.03
Topic: T03 – Problem Decomposition
Skill: Arrange 3–4 picture cards to plan steps in a routine
Description: **Student task:** Drag and arrange 3–4 picture cards to show the steps of a routine as a plan. **Visual scenario:** "Plan how to wash hands": arrange cards for "turn on water" → "add soap" → "scrub hands" → "dry hands." Audio narration guides students through the planning activity. PICTURE-BASED sequencing activity.

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed







ID: T03.GK.04
Topic: T03 – Problem Decomposition
Skill: Select the missing middle step in a routine plan
Description: **Student task:** Given the first and last steps, tap to select the picture card that fits in the middle. **Visual scenario:** First card: "get soap." Last card: "dry hands." Middle card is missing. Choose from: "scrub hands" (correct), "eat lunch" (wrong), "read book" (wrong). PICTURE-BASED logical completion activity.

Dependencies:
* T03.GK.03: Arrange 3–4 picture cards to plan steps in a routine






ID: T03.GK.05
Topic: T03 – Problem Decomposition
Skill: Match each step to what it accomplishes
Description: **Student task:** Match picture cards of steps to picture cards of their results. **Visual scenario:** Drag "scrub hands" to "clean hands," drag "put on shoes" to "feet ready," drag "brush teeth" to "clean teeth." Helps students understand why each step matters in a plan. PICTURE-BASED cause-and-effect matching activity.

Dependencies:
* T03.GK.03: Arrange 3–4 picture cards to plan steps in a routine




ID: T03.GK.06
Topic: T03 – Problem Decomposition
Skill: Match picture cards of problems to their helper tools
Description: **Student task:** Match picture cards showing problems with picture cards of tools that help. **Visual scenario:** Match "dirty dishes" to "sponge," match "tall shelf" to "step stool," match "dark room" to "flashlight." Introduces the idea that big problems need the right helpers (tools). PICTURE-BASED matching activity with audio support.

Dependencies:
* T03.GK.02: Drag picture cards of parts to match their whole objects




ID: T03.GK.07
Topic: T03 – Problem Decomposition
Skill: Sort picture cards of a project into "do first" and "do last" piles
Description: **Student task:** Drag picture cards showing project steps into two piles: "do first" and "do last." **Visual scenario:** Making a sandwich: drag "get bread" to "do first" pile, drag "eat sandwich" to "do last" pile, drag "add peanut butter" to middle (either pile is partially correct). Introduces concept that some tasks must happen before others. PICTURE-BASED sorting activity with audio support.

Dependencies:
* T03.GK.03: Arrange 3–4 picture cards to plan steps in a routine
* T03.GK.05: Match each step to what it accomplishes




ID: T03.GK.08
Topic: T03 – Problem Decomposition
Skill: Predict which picture card must come before another
Description: **Student task:** See two picture cards and tap on which one MUST happen first for the plan to work. **Visual scenario:** Card A shows "pour water in cup," Card B shows "get cup from shelf." Question: "Which must happen first?" Correct answer: Card B (get cup). Distractor pairs include steps that can happen in either order. Builds understanding that some steps have required ordering while others are flexible. PICTURE-BASED prediction activity with audio support for pre-readers.

Dependencies:
* T03.GK.07: Sort picture cards of a project into "do first" and "do last" piles




ID: T03.G1.01
Topic: T03 – Problem Decomposition
Skill: Match parts to their functions using picture and word cards
Description: **Student task:** Tap on a part picture card, then select the word card describing what it does. **Visual scenario:** Match "wheels" to "helps it roll," match "door" to "lets people in," match "button" to "turns it on." 4-5 matching pairs with audio support. PICTURE-BASED matching activity with simple word cards.

Dependencies:
* T03.GK.01: Tap picture cards to identify parts of a whole object





ID: T03.G1.02
Topic: T03 – Problem Decomposition
Skill: Sort parts into function-based groups
Description: **Student task:** Drag picture cards of parts into labeled category boxes based on function. **Visual scenario:** Sort robot parts: drag "wheels" to "things that help it move," drag "camera" to "things that help it see," drag "paint" to "things that make it look nice." 6-8 parts across 3 categories. PICTURE-BASED sorting activity.

Dependencies:
* T03.G1.01: Match parts to their functions using picture and word cards





ID: T03.G1.03
Topic: T03 – Problem Decomposition
Skill: Arrange 4–5 step cards to plan a longer routine
Description: **Student task:** Drag and arrange 4–5 picture/word cards to build a step-by-step plan. **Visual scenario:** "Plan how to line up for recess": arrange "put away work" → "push in chair" → "stand up" → "walk to door" → "wait quietly." Mix of picture cards (for pre-readers) and simple word cards. PICTURE-BASED sequencing activity.

Dependencies:
* T03.GK.03: Arrange 3–4 picture cards to plan steps in a routine





ID: T03.G1.04
Topic: T03 – Problem Decomposition
Skill: Match steps to characters in a simple story plan
Description: **Student task:** See a story idea and drag word cards to match steps with characters. **Visual scenario:** Story: "A cat says hello, then dances." Drag "says hello" to the cat picture, drag "music plays" to the background. Introduces idea that different parts of a project have different jobs. PICTURE-BASED matching activity for early project planning.

Dependencies:
* T03.G1.03: Arrange 4–5 step cards to plan a longer routine




ID: T03.G1.05
Topic: T03 – Problem Decomposition
Skill: Select which part of a task a tool helps with
Description: **Student task:** See a big task and tap on which part of the task a specific tool helps complete. **Visual scenario:** Task: "Make a sandwich." Tool: "Knife." Select from: "cut the bread" ✓, "get the plate" ✗, "wash hands" ✗. Shows that tools help with specific parts of bigger tasks. PICTURE-BASED selection activity with audio support.

Dependencies:
* T03.GK.06: Match picture cards of problems to their helper tools
* T03.G1.01: Match parts to their functions using picture and word cards




ID: T03.G1.06
Topic: T03 – Problem Decomposition
Skill: Debug a broken routine plan by finding the missing step
Description: **Student task:** See a routine plan with picture cards that doesn't work because one step is missing. Find where the gap is and drag the correct card to fix it. **Visual scenario:** Plan shows: "get toothbrush" → "put toothpaste on" → [missing] → "rinse mouth." The plan won't work because "brush teeth" is missing. Drag "brush teeth" card from options (including distractors like "comb hair" and "eat breakfast") to the gap. Introduces debugging as finding what's missing in a decomposed plan. PICTURE-BASED debugging activity with audio support.

Dependencies:
* T03.G1.03: Arrange 4–5 step cards to plan a longer routine
* T03.GK.08: Predict which picture card must come before another





ID: T03.G2.01
Topic: T03 – Problem Decomposition
Skill: Select subtasks needed for a small project
Description: **Student task:** Read/hear a project idea and tap to select word cards showing needed subtasks. **Visual scenario:** Project: "Make a greeting card." Select from: "draw background" ✓, "add message" ✓, "add sound" ✓, "make it fly" ✗, "cook dinner" ✗. 5-6 options with 3-4 correct answers. PICTURE-BASED selection activity with word cards and audio support.

Dependencies:
* T03.G1.03: Arrange 4–5 step cards to plan a longer routine





ID: T03.G2.02
Topic: T03 – Problem Decomposition
Skill: Sort subtasks into category boxes by work type
Description: **Student task:** Drag subtask word cards into labeled category boxes. **Visual scenario:** Sort subtasks for a game project: drag "draw character" to "Art," drag "write story" to "Writing," drag "add music" to "Sound." 6-8 subtasks across 3 categories. PICTURE-BASED sorting activity organizing work by type.

Dependencies:
* T03.G2.01: Select subtasks needed for a small project





ID: T03.G2.03
Topic: T03 – Problem Decomposition
Skill: Arrange subtasks in logical sequence
Description: **Student task:** Drag 4–5 subtask word cards and arrange them in the order they should be done. **Visual scenario:** Arrange: "plan the game" → "draw the pictures" → "make it work" → "try it out" → "fix problems." Introduces concept that order matters when building something. PICTURE-BASED sequencing activity with word cards.

Dependencies:
* T03.G2.02: Sort subtasks into category boxes by work type





ID: T03.G2.04
Topic: T03 – Problem Decomposition
Skill: Track progress by marking completed subtasks
Description: **Student task:** Read what's been done and tap checkmarks on completed subtasks. **Visual scenario:** "We already drew the characters and added sounds." Checklist shows: "draw characters" ✓, "add sounds" ✓, "write story" □, "test game" □. Introduces progress tracking. PICTURE-BASED checklist activity.

Dependencies:
* T03.G2.03: Arrange subtasks in logical sequence





ID: T03.G2.05
Topic: T03 – Problem Decomposition
Skill: Identify features by watching a project demo
Description: **Student task:** Watch a short project video and select word cards describing its features. **Visual scenario:** Watch: cat walks, clicks make it jump, music plays. Select from: "the cat can walk" ✓, "you can click to make it jump" ✓, "it plays music" ✓, "it flies" ✗. Introduces observing and naming project features. PICTURE-BASED observation activity.

Dependencies:
* T03.G2.02: Sort subtasks into category boxes by work type





ID: T03.G2.06
Topic: T03 – Problem Decomposition
Skill: Distinguish whole projects from single features
Description: **Student task:** Drag word cards into "Whole Project" vs "Single Feature" columns. **Visual scenario:** "Whole Project" column: "make a jumping game." "Single Feature" column: "sprite jumps when clicked," "score increases," "game over when falling." Shows that projects are made of many features. PICTURE-BASED sorting activity.

Dependencies:
* T03.G2.05: Identify features by watching a project demo
* T02.G2.05: Create a 3-step flowchart





ID: T03.G2.07
Topic: T03 – Problem Decomposition
Skill: Group subtasks that work together for one feature
Description: **Student task:** Drag subtask cards into groups that create a single feature. **Visual scenario:** "Player Movement" group: "draw player sprite," "add arrow key controls," "make player move." "Scoring" group: "create score variable," "add points when hit." Shows how subtasks combine into features. PICTURE-BASED grouping activity.

Dependencies:
* T03.G2.06: Distinguish whole projects from single features




ID: T03.G2.08
Topic: T03 – Problem Decomposition
Skill: Predict which subtasks take longest
Description: **Student task:** Look at subtasks for a project and tap on which ones would take the longest time. **Visual scenario:** Project: "Make a birthday card." Subtasks: "draw a picture" (long - tap), "write 'Happy Birthday'" (short), "add sparkle" (medium), "pick colors" (short). Introduces idea that different subtasks take different amounts of effort. PICTURE-BASED prediction activity with visual size cues.

Dependencies:
* T03.G2.03: Arrange subtasks in logical sequence
* T03.G2.04: Track progress by marking completed subtasks




ID: T03.G2.09
Topic: T03 – Problem Decomposition
Skill: Predict what breaks if a subtask is skipped
Description: **Student task:** Look at a project plan and predict what goes wrong if a specific subtask is skipped. **Visual scenario:** Project: "Make a card with music." Subtasks: 1) draw picture, 2) add text, 3) add music button, 4) connect button to sound. Question: "What if we skip step 3?" Select: "The music won't play because there's no button to click" ✓. Introduces dependency thinking. PICTURE-BASED prediction activity with word cards.

Dependencies:
* T03.G2.03: Arrange subtasks in logical sequence
* T03.G2.07: Group subtasks that work together for one feature



ID: T03.G2.10
Topic: T03 – Problem Decomposition
Skill: Build a project plan from scattered subtask cards
Description: **Student task:** Given a project goal and 8-10 scattered subtask word cards (some relevant, some distractors), build a complete project plan by selecting the right cards and arranging them in order. **Visual scenario:** Goal: "Make a game where a cat chases a mouse." Cards include: "draw cat sprite" ✓, "make cat move with arrows" ✓, "draw mouse sprite" ✓, "make mouse run away" ✓, "add score" ✓, "cook dinner" ✗, "do homework" ✗, "add win message" ✓. Select 6 correct cards and arrange: draw sprites → add movement → add chase logic → add score → add win. Capstone G2 skill synthesizing selection, ordering, and grouping. PICTURE-BASED planning activity with word cards.

Dependencies:
* T03.G2.09: Predict what breaks if a subtask is skipped
* T03.G2.08: Predict which subtasks take longest
* T03.G2.06: Distinguish whole projects from single features



ID: T03.G2.11
Topic: T03 – Problem Decomposition
Skill: Debug a project plan by finding steps in the wrong order
Description: **Student task:** See a project plan where some steps are out of order and won't work. Find and fix the ordering problems. **Visual scenario:** Plan shows: "Test the game" → "Draw the character" → "Make it move" → "Add sounds." Problem: can't test before building! Drag "Test the game" to the end. Find 2 ordering mistakes in a 6-step plan and fix them by reordering cards. Builds debugging skills before coding by finding logical order errors in visual plans. PICTURE-BASED debugging activity with word cards.

Dependencies:
* T03.G2.10: Build a project plan from scattered subtask cards
* T03.G2.09: Predict what breaks if a subtask is skipped



ID: T03.G3.00
Topic: T03 – Problem Decomposition
Skill: Decompose a picture-based task description into code-ready steps
Description: **Student task:** Read a simple task description and convert picture-based thinking into coding steps. **Coding scenario:** Task: "Make a cat walk across the screen." Convert to code steps: "1. Add cat sprite," "2. Use green flag event," "3. Add repeat loop," "4. Add move block inside loop." Bridge skill connecting G2 picture-thinking to G3 code-thinking. Auto-graded by step identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G2.07: Group subtasks that work together for one feature
* T03.G2.09: Predict what breaks if a subtask is skipped


ID: T03.G3.00.01
Topic: T03 – Problem Decomposition
Skill: Match picture-based task steps to their block code equivalents
Description: **Student task:** See picture cards showing task steps and match each to the correct code block. **Coding scenario:** Picture card "cat moves forward" matches to [move 10 steps] block. Picture card "cat turns around" matches to [turn 180 degrees] block. Picture card "wait a moment" matches to [wait 1 second] block. 4-5 matching pairs connecting visual thinking to code blocks. Auto-graded by correct matches. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.00: Decompose a picture-based task description into code-ready steps
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence


ID: T03.G3.00.02
Topic: T03 – Problem Decomposition
Skill: Translate a single picture step into multiple code blocks
Description: **Student task:** Take one picture-based task step and expand it into the 2-3 code blocks needed to implement it. **Coding scenario:** Picture: "Cat walks and says hello." Expand to: "[move 50 steps], [say 'Hello!' for 2 seconds]." Another: "Cat spins around three times." Expand to: "[repeat 3], [turn 120 degrees], [wait 0.1 seconds]." Demonstrates that one visual idea often requires multiple blocks. Auto-graded by block sequence correctness. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.00.01: Match picture-based task steps to block code equivalents
* T07.G3.01: Use a counted repeat loop


ID: T03.G3.01
Topic: T03 – Problem Decomposition
Skill: List distinct features needed for a game
Description: **Student task:** Read a game description and list 3-5 distinct features the game needs. **Coding scenario:** Game: "Catch falling apples to score points." List features: "player moves left/right," "apples fall from top," "score increases when caught," "game ends after time." Auto-graded by matching required features. _CSTA: 1B-AP-11._

Dependencies:
* T03.G2.07: Group subtasks that work together for one feature
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




ID: T03.G3.01.01
Topic: T03 – Problem Decomposition
Skill: Describe why each feature is needed for the game
Description: **Student task:** For each listed feature, write one sentence explaining why the game needs it. **Coding scenario:** Apple game features: "Player moves: so player can catch apples," "Apples fall: to give player something to catch," "Score: so player knows how well they did," "Timer: so the game has an ending." Auto-graded by purpose explanation coverage. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.01: List distinct features needed for a game


ID: T03.G3.01.02
Topic: T03 – Problem Decomposition
Skill: Prioritize features by user impact
Description: **Student task:** Rank listed features from most important to least important based on user experience impact. **Coding scenario:** Apple game features to rank: "player can move" (high - core gameplay), "score display" (high - feedback), "background music" (medium - atmosphere), "particle effects on catch" (low - polish). Explain ranking: "Movement is #1 because without it there's no game." Auto-graded by ranking logic. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.01.01: Describe why each feature is needed for the game



ID: T03.G3.02
Topic: T03 – Problem Decomposition
Skill: Categorize features as "must-have" or "nice-to-have"
Description: **Student task:** Sort features into "Must-Have" (game won't work without) vs "Nice-to-Have" (extras). **Coding scenario:** Apple catching game. Must-Have: "player moves," "apples fall," "score tracking." Nice-to-Have: "sound effects," "high score," "different apple colors." Auto-graded by correct categorization. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.01: List distinct features needed for a game
* T07.G3.01: Use a counted repeat loop





ID: T03.G3.03
Topic: T03 – Problem Decomposition
Skill: Create a storyboard for a coding project
Description: **Student task:** Arrange 3-4 panels showing key moments of a project. **Coding scenario:** Create storyboard for a space game: Panel 1 (Start): rocket at bottom. Panel 2 (Play): rocket moves, asteroids fall. Panel 3 (End): explosion or "You Win!" Use CreatiCode diagram editor. Auto-graded by panel completeness. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.02: Categorize features as "must-have" or "nice-to-have"





ID: T03.G3.04
Topic: T03 – Problem Decomposition
Skill: Label storyboard panels with scene names
Description: **Student task:** Label each storyboard panel with a scene name matching project structure. **Coding scenario:** Space game storyboard: Label Panel 1 as "Title Screen," Panel 2 as "Gameplay," Panel 3 as "Game Over Screen." Connects visual plan to how code will be organized. Auto-graded by matching labels. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.03: Create a storyboard for a coding project





ID: T03.G3.05
Topic: T03 – Problem Decomposition
Skill: List main components of a coding project
Description: **Student task:** Open a simple project and list its main components with their purposes. **Coding scenario:** Open a maze game project. List: "Player sprite: moves with arrow keys," "Wall sprites: block movement," "Goal sprite: triggers win message," "Score variable: tracks attempts." 3-5 components required. Auto-graded by component identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.04: Label storyboard panels with scene names





ID: T03.G3.06
Topic: T03 – Problem Decomposition
Skill: Compare project plans and select the best sequence
Description: **Student task:** Compare 2-3 project plans and select the one with the best logical sequence. **Coding scenario:** Plan A: "test → build → design." Plan B: "design → build → test." Plan C: "build → design → test." Select Plan B and explain why design must come before building. Auto-graded by selection. _CSTA: 1B-AP-12._

Dependencies:
* T03.G3.05: List main components of a coding project





ID: T03.G3.07
Topic: T03 – Problem Decomposition
Skill: Trace and explain how two components interact in a project
Description: **Student task:** Examine a project, trace how two components work together, and explain the interaction. **Coding scenario:** In maze game: "When player sprite touches goal sprite, the score variable increases and say block shows 'You Win!'" Trace and explain the interaction: player position → collision detection → variable update → display. Auto-graded by identifying both components and explaining their interaction. _CSTA: 1B-AP-10._

Dependencies:
* T03.G3.05: List main components of a coding project
* T09.G3.02: Use a variable in a conditional (if block)





ID: T03.G3.08
Topic: T03 – Problem Decomposition
Skill: Identify different work types needed for a project
Description: **Student task:** Examine a completed project and list the different types of work involved. **Coding scenario:** Story animation project. List work types: "Art: drew backgrounds and characters," "Writing: wrote the story dialogue," "Sound: recorded voice and music," "Coding: made animations work." Introduces roles in project creation. Auto-graded by category coverage. _CSTA: 1B-IC-20._

Dependencies:
* T03.G3.02: Categorize features as "must-have" or "nice-to-have"





ID: T03.G3.09
Topic: T03 – Problem Decomposition
Skill: Find and group sprites that need similar code
Description: **Student task:** Find sprites in a project that need similar actions and group them as candidates for shared code. **Coding scenario:** Space invader game: "Enemy1, Enemy2, Enemy3 all need: move down slowly, check if touching player, disappear when hit." Find and group these sprites as "Enemies" that share behavior. Introduces reusable code concept. Auto-graded by correct grouping. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.05: List main components of a coding project
* T01.G3.06: Execute a simple sequence (green flag with 3+ blocks)




ID: T03.G3.10
Topic: T03 – Problem Decomposition
Skill: Trace data flow between components in a simple project
Description: **Student task:** Draw arrows showing how information flows between components. **Coding scenario:** Apple game: "Player sprite sends position → Collision checker reads position → Collision triggers score update → Score variable displays on screen." Draw 3-4 arrows showing the flow. Auto-graded by correct data flow identification. _CSTA: 1B-AP-10._

Dependencies:
* T03.G3.07: Trace how two components interact in a project
* T03.G3.05: List main components of a coding project


ID: T03.G3.11
Topic: T03 – Problem Decomposition
Skill: Decompose a bug report into investigation steps
Description: **Student task:** Read a bug report and list 3-4 steps to investigate the problem. **Coding scenario:** Bug: "Score doesn't increase when player catches apple." Investigation steps: "1. Check if collision detection is working (add say block)," "2. Check if score variable exists," "3. Check if change score block is inside collision code," "4. Check if score display is connected to variable." Introduces debugging decomposition. Auto-graded by step coverage. _CSTA: 1B-AP-15._

Dependencies:
* T03.G3.07: Trace how two components interact in a project
* T03.G3.10: Trace data flow between components in a simple project



ID: T03.G3.12
Topic: T03 – Problem Decomposition
Skill: Build and test ONE feature before adding the next
Description: **Student task:** Given a multi-feature project plan, implement and verify one feature works completely before starting the next. **Coding scenario:** Project: "Cat chases mouse game." Feature 1: "Cat moves with arrow keys." Build it, test it works, then move to Feature 2: "Mouse moves randomly." Test Feature 2 works without breaking Feature 1. Then Feature 3: "Score increases when cat touches mouse." Demonstrates incremental building strategy where each piece is verified before adding complexity. Auto-graded by feature completion order and testing. _CSTA: 1B-AP-15._

Dependencies:
* T03.G3.11: Decompose a bug report into investigation steps
* T03.G3.07: Trace how two components interact in a project



ID: T03.G4.01
Topic: T03 – Problem Decomposition
Skill: Break down a multi-feature project into subtasks
Description: **Student task:** Read a project description and list 4-6 subtasks needed to build it. **Coding scenario:** Project: "Quiz game with levels." Subtasks: "create question list," "show one question at a time," "check answer and update score," "track which level player is on," "show results at end." Auto-graded by subtask coverage. _CSTA: 1B-AP-11._

Dependencies:
* T03.G3.07: Trace how two components interact in a project
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T08.G3.04: Use a simple if in a script





ID: T03.G4.02
Topic: T03 – Problem Decomposition
Skill: Arrange subtasks in logical build order
Description: **Student task:** Arrange subtasks in the order they should be built, with prerequisites first. **Coding scenario:** Quiz game subtasks: 1. "create question list" (first - data needed), 2. "set up score variable" (before using it), 3. "show questions" (needs list), 4. "check answers" (needs score), 5. "show results" (last). Auto-graded by correct ordering. _CSTA: 1B-AP-12._

Dependencies:
* T03.G4.01: Break down a multi-feature project into subtasks





ID: T03.G4.03
Topic: T03 – Problem Decomposition
Skill: Assign subtasks to team roles
Description: **Student task:** Match subtasks to team members based on roles/skills. **Coding scenario:** Quiz game team: "Alice (artist): design question cards," "Bob (coder): write score logic," "Claire (writer): create questions," "Dan (tester): try the game." For solo projects, categorize tasks by type. Auto-graded by role-task matching. _CSTA: 1B-IC-20._

Dependencies:
* T03.G4.02: Arrange subtasks in logical build order
* T03.G3.08: Identify different work types needed for a project





ID: T03.G4.04
Topic: T03 – Problem Decomposition
Skill: Track progress using a task checklist
Description: **Student task:** Use a checklist to mark subtasks as "not started," "in progress," or "done." **Coding scenario:** Quiz game tracker: "create questions ✓ done," "score logic ◐ in progress," "show results □ not started." Identify blocking task: "can't test until score logic is done." Auto-graded by correct status assignment. _CSTA: 1B-AP-15._

Dependencies:
* T03.G4.03: Assign subtasks to team roles





ID: T03.G4.05
Topic: T03 – Problem Decomposition
Skill: Trace and evaluate how modules organize project components
Description: **Student task:** Examine a project organized into modules, trace how grouping works, and evaluate why it helps. **Coding scenario:** Platformer game modules: "Player Module: player sprite + movement scripts + jump code," "Enemy Module: enemy sprites + patrol code + collision." Trace the organization and evaluate why grouping helps: "easier to find player code, can copy Enemy Module for new enemies." Auto-graded by identifying module benefits. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.04: Track progress using a task checklist
* T03.G3.09: Identify sprites that need similar code




ID: T03.G4.05.01
Topic: T03 – Problem Decomposition
Skill: List three benefits of organizing code into modules
Description: **Student task:** List three specific benefits of using modules to organize code. **Coding scenario:** After examining the platformer game modules, list benefits: "1. Easier to find code (all player code in one place)," "2. Easier to fix bugs (only look in one module)," "3. Can reuse modules (copy Enemy Module for new game)." Auto-graded by benefit identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.05: Trace how modules organize project components


ID: T03.G4.05.02
Topic: T03 – Problem Decomposition
Skill: Identify coupling between modules
Description: **Student task:** Examine modules and identify where they depend on each other (coupling). **Coding scenario:** Platformer game: "Player Module depends on Input Module (reads keys)," "Enemy Module depends on Player Module (needs player position)," "Score Module depends on nothing (independent)." Rate coupling: tight (must change together) vs loose (can change independently). Auto-graded by coupling identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.05.01: List three benefits of organizing code into modules
* T03.G4.06: Sort components into logical modules



ID: T03.G4.06
Topic: T03 – Problem Decomposition
Skill: Sort components into logical modules
Description: **Student task:** Sort project components into logical modules by shared purpose or data. **Coding scenario:** Racing game components: Sort "car sprite," "speed variable," "acceleration code" into "Car Module." Sort "timer display," "lap counter," "finish line check" into "Race Logic Module." Sort "background," "track sprites" into "Graphics Module." Auto-graded by correct groupings. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.05: Trace how modules organize project components





ID: T03.G4.07
Topic: T03 – Problem Decomposition
Skill: Identify which task must complete before another
Description: **Student task:** Examine pairs of tasks and identify which must complete first. **Coding scenario:** Quiz game: "create questions" must finish before "display questions." "Set up score variable" must finish before "update score on correct answer." Draw arrows showing dependencies. Auto-graded by correct dependency identification. _CSTA: 1B-AP-12._

Dependencies:
* T03.G4.02: Arrange subtasks in logical build order
* T12.G3.01: Test and trace simple block-based scripts





ID: T03.G4.08
Topic: T03 – Problem Decomposition
Skill: Find missing or unnecessary tasks in a project plan
Description: **Student task:** Review a project plan and find missing critical tasks or unnecessary duplicates. **Coding scenario:** Quiz game plan missing "test the game" — identify it's needed. Plan has "draw background" twice — identify duplicate. Plan has "cook dinner" — identify it's unrelated. Auto-graded by correct identification. _CSTA: 1B-AP-15._

Dependencies:
* T03.G4.07: Identify which task must complete before another
* T12.G3.01: Test and trace simple block-based scripts





ID: T03.G4.09
Topic: T03 – Problem Decomposition
Skill: Find repeated code patterns across sprites
Description: **Student task:** Examine code across multiple sprites and find patterns that repeat. **Coding scenario:** Platform game: "Enemy1, Enemy2, Enemy3 all have same patrol code: forever [move 50 steps, wait 1 sec, turn 180 degrees]." Identify this pattern repeats 3 times. List opportunities for creating a custom block. Auto-graded by pattern identification. _CSTA: 1B-AP-13._

Dependencies:
* T03.G3.09: Identify sprites that need similar code
* T04.G3.04.01: Identify repeated code segments that could be simplified with templates
* T07.G3.01: Use a counted repeat loop





ID: T03.G4.10
Topic: T03 – Problem Decomposition
Skill: Design custom block names and inputs for repeated patterns
Description: **Student task:** Design custom blocks for repeated code patterns, specifying name and inputs. **Coding scenario:** Patrol pattern repeats in 3 enemies. Design: "patrol [steps] [wait_time]" custom block that takes steps to move and wait time as inputs. Each enemy calls it with different values. Auto-graded by block design completeness. _CSTA: 1B-AP-14._

Dependencies:
* T03.G4.09: Find repeated code patterns across sprites
* T11.G4.01: Recognize when similar code appears in multiple places




ID: T03.G4.11
Topic: T03 – Problem Decomposition
Skill: Decompose a project with widgets into UI and logic tasks
Description: **Student task:** Break down a widget-based project into separate UI tasks and logic tasks. **Coding scenario:** Score display project: UI tasks: "create label widget," "position label," "style font size." Logic tasks: "track score variable," "update label when score changes," "reset on new game." Uses CreatiCode widget blocks. Auto-graded by correct task categorization. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.06: Sort components into logical modules
* T03.G3.08: Identify different work types needed for a project


ID: T03.G4.12
Topic: T03 – Problem Decomposition
Skill: Decompose a scientific simulation into input/process/output
Description: **Student task:** Break down a scientific simulation project into input, processing, and output stages. **Coding scenario:** Plant growth simulation: "Input: sun slider (0-100), water slider (0-100)," "Process: calculate growth rate based on inputs, update plant height variable," "Output: animate plant sprite size, display growth status." Uses CreatiCode 2D physics or animation blocks. Auto-graded by stage identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.06: Sort components into logical modules
* T03.G4.11: Decompose a project with widgets into UI and logic tasks



ID: T03.G4.13
Topic: T03 – Problem Decomposition
Skill: Choose decomposition strategy (by data vs by action vs by user story)
Description: **Student task:** Given a project, evaluate and choose the best decomposition strategy from three options: by data (what information is stored/processed), by action (what behaviors/operations happen), or by user story (what the user wants to accomplish). **Coding scenario:** Project: "Pet care game." Option A (by data): "Pet stats module, Food inventory module, Money module." Option B (by action): "Feeding module, Playing module, Shopping module." Option C (by user story): "Keep pet happy feature, Earn coins feature, Buy items feature." Evaluate: "Option C best for planning because it matches what players want to do; Option A best for implementation because it organizes shared data." Choose and justify. Auto-graded by justification quality. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.12: Decompose a scientific simulation into input/process/output
* T03.G4.06: Sort components into logical modules
* T03.G3.08: Identify different work types needed for a project


ID: T03.G4.14
Topic: T03 – Problem Decomposition
Skill: Apply chosen decomposition strategy to implement a project
Description: **Student task:** Choose a decomposition strategy (by data, by action, or by user story) and apply it to plan and build a small project. **Coding scenario:** Project: "Virtual pet that needs feeding and playing." Student chooses: "by user story" approach. Plan: "Feature 1: Feed the pet (hunger decreases when food clicked). Feature 2: Play with pet (happiness increases when toy clicked). Feature 3: Pet mood display (shows hungry/happy/sad based on stats)." Build each feature following the plan. Document why this strategy was chosen over alternatives. Auto-graded by strategy consistency and implementation completeness. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.13: Choose decomposition strategy (by data vs by action vs by user story)
* T03.G4.02: Arrange subtasks in logical build order



ID: T03.G5.01
Topic: T03 – Problem Decomposition
Skill: Write a feature list with subtasks for each feature
Description: **Student task:** Create a structured document listing main features with 2-3 subtasks each. **Coding scenario:** Adventure game pitch: "Scoring feature: 1. create score variable, 2. add points on coin pickup, 3. display score on screen." "Movement feature: 1. arrow key detection, 2. change position, 3. animate walking." Auto-graded by structure and coverage. _CSTA: 1B-AP-11._

Dependencies:
* T03.G4.04: Track progress using a task checklist
* T03.G4.06: Sort components into logical modules
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T03.G5.02
Topic: T03 – Problem Decomposition
Skill: Draw a screen/level flow diagram
Description: **Student task:** Create a diagram showing how screens or levels connect in a project. **Coding scenario:** Adventure game flow: "Title Screen → Level 1 → Level 2 → Boss Level → Win Screen." Add "Game Over Screen" branching from any level. Use arrows showing navigation. Use CreatiCode diagram editor. Auto-graded by completeness and logical flow. _CSTA: 1B-AP-12._

Dependencies:
* T03.G4.06: Sort components into logical modules
* T02.G4.01: Add a loop to an existing flowchart





ID: T03.G5.02.01
Topic: T03 – Problem Decomposition
Skill: Label diagram connections with navigation conditions
Description: **Student task:** Add condition labels to arrows in a screen/level flow diagram showing what triggers each transition. **Coding scenario:** Adventure game flow diagram: Label "Title Screen → Level 1" with "when 'Start' button clicked." Label "Level 1 → Game Over Screen" with "when player health = 0." Label "Level 1 → Level 2" with "when player reaches exit AND has key." Add 4-5 condition labels explaining why transitions happen. Auto-graded by condition label completeness and logic. _CSTA: 1B-AP-12._

Dependencies:
* T03.G5.02: Draw a screen/level flow diagram
* T08.G4.03: Use nested if statements



ID: T03.G5.03
Topic: T03 – Problem Decomposition
Skill: Create a complete dependency graph for all tasks in a project plan
Description: **Student task:** Examine all tasks in a project plan and create a complete dependency graph with arrows showing all prerequisite relationships. **Coding scenario:** Tasks: "A: create player sprite," "B: add movement code," "C: create score variable," "D: update score on collision," "E: test collision detection," "F: display score on screen." Create graph: A→B (movement needs sprite), C→D (update needs variable), B→E (test needs movement), D→E (test needs scoring), C→F (display needs variable), D→F (display after update). Show all dependencies, not just pairs. Auto-graded by graph completeness. _CSTA: 1B-AP-12._

Dependencies:
* T03.G4.07: Identify which task must complete before another
* T03.G4.08: Find missing or unnecessary tasks in a project plan
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T03.G5.04
Topic: T03 – Problem Decomposition
Skill: Decompose vague tasks into specific testable sub-tasks
Description: **Student task:** Take vague tasks and break them into specific, testable sub-tasks. **Coding scenario:** Vague: "make AI for enemies." Specific sub-tasks: "1. enemy moves toward player when within 100 steps (test: measure distance)," "2. enemy turns at walls (test: check direction change)," "3. enemy speeds up after 30 seconds (test: check speed variable)." Auto-graded by specificity and testability. _CSTA: 1B-AP-15._

Dependencies:
* T03.G4.08: Find missing or unnecessary tasks in a project plan
* T03.G4.10: Design custom block names and inputs for repeated patterns
* T02.G5.01: Trace a script with nested loops using debug print




ID: T03.G5.04.01
Topic: T03 – Problem Decomposition
Skill: Write acceptance criteria for each sub-task
Description: **Student task:** For each sub-task, write specific acceptance criteria that define "done." **Coding scenario:** Sub-task: "enemy moves toward player when within 100 steps." Acceptance criteria: "1. Enemy faces player direction when distance < 100," "2. Enemy moves at speed 3 toward player," "3. Enemy stops pursuing when distance > 150." Auto-graded by criteria specificity. _CSTA: 1B-AP-15._

Dependencies:
* T03.G5.04: Decompose vague tasks into specific testable sub-tasks


ID: T03.G5.04.02
Topic: T03 – Problem Decomposition
Skill: Estimate effort for each sub-task
Description: **Student task:** For each sub-task, estimate relative effort (small/medium/large) with justification. **Coding scenario:** Sub-tasks for enemy AI: "enemy moves toward player" = medium (needs distance calculation + movement), "enemy changes color when close" = small (just costume change), "enemy finds path around obstacles" = large (needs pathfinding algorithm). Justify each estimate by listing what code is needed. Auto-graded by estimation reasoning. _CSTA: 1B-AP-15._

Dependencies:
* T03.G5.04.01: Write acceptance criteria for each sub-task
* T03.G5.03: Mark dependencies between tasks in a project plan



ID: T03.G5.05
Topic: T03 – Problem Decomposition
Skill: Compare and rank two project plans with justified criteria
Description: **Student task:** Compare two project plans, rank them by quality, and explain the ranking with specific criteria. **Coding scenario:** Plan A: tasks in random order, no dependencies marked, missing "test game." Plan B: logical order, dependencies shown, includes testing. Rank: "Plan B is better (score: 8/10) vs Plan A (score: 4/10)." Criteria: "1. Logical ordering (B: yes, A: no), 2. Dependencies shown (B: yes, A: no), 3. Testing included (B: yes, A: no), 4. Completeness (B: complete, A: missing step)." Auto-graded by criteria completeness and ranking logic. _CSTA: 1B-AP-15._

Dependencies:
* T03.G5.03: Mark dependencies between tasks in a project plan
* T03.G4.08: Find missing or unnecessary tasks in a project plan





ID: T03.G5.06
Topic: T03 – Problem Decomposition
Skill: Label modules in an example project
Description: **Student task:** Examine a project and label its logical modules with their responsibilities. **Coding scenario:** Platform game project: Label "Player Control Module: handles keyboard input and sprite movement." Label "Enemy AI Module: controls enemy patrol and chase behavior." Label "Scoring Module: tracks and displays points." Auto-graded by correct module identification. _CSTA: 1B-AP-14._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature
* T03.G4.06: Sort components into logical modules
* T11.G5.01: Decompose a problem into logical custom block boundaries





ID: T03.G5.07
Topic: T03 – Problem Decomposition
Skill: Decompose a 2D physics simulation into components
Description: **Student task:** Break down a 2D physics project into its key components. **Coding scenario:** Ball bounce simulation: "Physics world setup: initialize 2D physics with gravity," "Ball component: sprite + physics body + restitution," "Walls: static bodies at edges," "Interactions: collision detection and bounce." Uses CreatiCode 2D Physics blocks. Auto-graded by component identification. _CSTA: 1B-AP-11._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature
* T03.G4.05: Trace how modules organize project components




ID: T03.G5.08
Topic: T03 – Problem Decomposition
Skill: Identify shared state between modules
Description: **Student task:** Examine modules and identify which variables or data are shared between them. **Coding scenario:** Platform game: "Player Module and Enemy Module both need: player position variable." "Score Module and UI Module both need: current score variable." "Level Module and all others need: game state (playing/paused/over)." List 3+ shared states. Auto-graded by shared state identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G5.06: Label modules in an example project
* T03.G4.05.01: List three benefits of organizing code into modules


ID: T03.G5.09
Topic: T03 – Problem Decomposition
Skill: Apply divide-and-conquer to break a large task into halves
Description: **Student task:** Take a large task and repeatedly split it in half until each piece is manageable. **Coding scenario:** Task: "Build a 100-question quiz game." Split 1: "Build first 50 questions" + "Build last 50 questions." Split 2: "Build questions 1-25" + "Build questions 26-50." Continue until each piece is ~5-10 questions. Explain why this approach helps: "Each small piece can be tested independently." Auto-graded by split logic and justification. _CSTA: 2-AP-13._

Dependencies:
* T03.G5.03: Mark dependencies between tasks in a project plan
* T03.G5.04.02: Estimate effort for each sub-task



ID: T03.G5.10
Topic: T03 – Problem Decomposition
Skill: Decompose an AI prompt into context/instruction/constraint parts
Description: **Student task:** Break down an effective AI prompt (for ChatGPT block) into three parts: context (background information), instruction (what to do), and constraints (rules/limits). **Coding scenario:** Prompt for story generator: "Context: 'You are a friendly storyteller for kids aged 5-7.' Instruction: 'Write a short story about a brave rabbit.' Constraints: 'Keep it under 100 words, use simple vocabulary, end with a lesson.'" Practice decomposing prompts, then compose a new one for a math tutor chatbot. Uses CreatiCode ChatGPT blocks. Auto-graded by component identification and composition. _CSTA: 2-AP-13, 2-IC-23._

Dependencies:
* T03.G5.04: Decompose vague tasks into specific testable sub-tasks
* T03.G5.01: Write a feature list with subtasks for each feature


ID: T03.G5.11
Topic: T03 – Problem Decomposition
Skill: Decompose a voice-controlled project into recognition/processing/response phases
Description: **Student task:** Break down a voice-controlled project into three phases: recognition (capturing and transcribing speech), processing (understanding and acting on input), and response (providing feedback via speech or visuals). **Coding scenario:** Voice calculator project: "Recognition phase: use speech recognition block, store transcribed text in variable." "Processing phase: parse spoken numbers and operation, perform calculation." "Response phase: use text-to-speech to speak result, display in label widget." Each phase handles specific blocks: recognition uses AI Speaker start/stop blocks, processing uses operators and conditionals, response uses AI Speaker and widgets. Uses CreatiCode speech recognition and text-to-speech blocks. Auto-graded by phase identification and block mapping. _CSTA: 2-AP-13._

Dependencies:
* T03.G5.10: Decompose an AI prompt into context/instruction/constraint parts
* T03.G5.07: Decompose a 2D physics simulation into components



ID: T03.G6.01
Topic: T03 – Problem Decomposition
Skill: Propose a module hierarchy for a medium-sized project
Description: **Student task:** Read a project description and propose a hierarchy of modules with sub-modules. **Coding scenario:** Racing game: "Top-level: Car Module (sub: car sprite, controls, physics), Track Module (sub: background, checkpoints, finish line), UI Module (sub: timer, lap counter, results)." Show which modules contain others. Auto-graded by hierarchy structure. _CSTA: 2-AP-13._

Dependencies:
* T03.G5.06: Label modules in an example project
* T06.G5.01: Build a green‑flag script that runs a 3–5 block sequence
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)





ID: T03.G6.02
Topic: T03 – Problem Decomposition
Skill: Identify reusable components across projects
Description: **Student task:** Examine components from multiple projects and identify which could be reused. **Coding scenario:** Compare 3 games. Reusable: "collision detection custom block (used in all 3)," "score display widget (same in 2 games)," "sound manager (plays sounds in all)." Name each, describe purpose and parameters. Auto-graded by reusability identification. _CSTA: 2-AP-14._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature
* T03.G4.10: Design custom block names and inputs for repeated patterns





ID: T03.G6.03
Topic: T03 – Problem Decomposition
Skill: Organize features into v1/v2/v3 milestones
Description: **Student task:** Sort features into milestone columns: v1 (working prototype), v2 (improvements), v3 (stretch goals). **Coding scenario:** Adventure game: v1 (player moves, basic enemies, one level), v2 (score system, multiple levels, sound effects), v3 (boss battles, leaderboard, multiplayer). Explain why v1 choices are essential. Auto-graded by milestone organization. _CSTA: 2-AP-15._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature
* T03.G5.03: Mark dependencies between tasks in a project plan


ID: T03.G6.03.01
Topic: T03 – Problem Decomposition
Skill: Define success criteria for each milestone
Description: **Student task:** For each milestone (v1/v2/v3), write specific success criteria that define when it's complete. **Coding scenario:** Adventure game v1 criteria: "1. Player can move in all 4 directions," "2. At least 2 enemies patrol," "3. Player can reach goal to win," "4. Game can be restarted." v2 criteria: "1. Score increases by 10 per coin," "2. 3+ levels load in sequence," "3. Background music plays." Auto-graded by criteria specificity and completeness. _CSTA: 2-AP-15._

Dependencies:
* T03.G6.03: Organize features into v1/v2/v3 milestones
* T03.G5.04.01: Write acceptance criteria for each sub-task



ID: T03.G6.04
Topic: T03 – Problem Decomposition
Skill: Revise milestones when constraints are discovered
Description: **Student task:** Respond to a discovered constraint by moving features between milestones. **Coding scenario:** Original v1 included multiplayer. Discovery: "multiplayer requires server setup we can't do." Revision: move multiplayer to v3, add "local 2-player on same keyboard" to v1 instead. Explain trade-offs. Auto-graded by logical revision. _CSTA: 2-AP-15._

Dependencies:
* T03.G6.03: Organize features into v1/v2/v3 milestones
* T03.G5.03: Mark dependencies between tasks in a project plan





ID: T03.G6.05
Topic: T03 – Problem Decomposition
Skill: Decompose an AI chatbot project into components
Description: **Student task:** Break down an AI chatbot project into its pipeline components. **Coding scenario:** Quiz helper chatbot: "Input component: text input widget or speech recognition," "AI component: ChatGPT request with quiz context," "Output component: text-to-speech response," "State: track conversation history." Uses CreatiCode AI/widget blocks. Auto-graded by component coverage. _CSTA: 2-AP-13._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature
* T03.G6.01: Propose a module hierarchy for a medium-sized project





ID: T03.G6.06
Topic: T03 – Problem Decomposition
Skill: Use XO to generate subtasks, then critique and refine suggestions
Description: **Student task:** Prompt XO with a project idea, then critique its suggested subtasks and refine them into an improved plan. **Coding scenario:** Prompt: "Help me plan a maze game." XO suggests 8 tasks. Critique each with reasoning: "Keep 'create player sprite' (essential, well-defined)." "Refine 'add walls' → 'add wall sprites and position them to form maze layout' (more specific, testable)." "Discard 'add online leaderboard' (too complex for v1, move to v2)." "Add missing task: 'add collision detection between player and walls' (XO overlooked this)." Final improved plan shows all refinements with justifications. Auto-graded by critique depth and refinement quality. _CSTA: 2-IC-23._

Dependencies:
* T03.G5.01: Write a feature list with subtasks for each feature




ID: T03.G6.07
Topic: T03 – Problem Decomposition
Skill: Decompose a data pipeline project into stages
Description: **Student task:** Break down a data-processing project into input, processing, and output stages. **Coding scenario:** Quiz score tracker: "Input stage: read scores from table variable," "Processing stage: calculate average, find highest/lowest," "Output stage: display results in label widget, save summary to cloud." Show data transformations at each stage. Uses CreatiCode table and widget blocks. Auto-graded by stage identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G5.08: Identify shared state between modules


ID: T03.G6.08
Topic: T03 – Problem Decomposition
Skill: Decompose an educational tool into learner-facing and admin components
Description: **Student task:** Break down an educational tool project into components for learners vs administrators. **Coding scenario:** Math practice app: "Learner components: problem display widget, answer input, feedback animation, progress bar." "Admin components: question editor (table variable), difficulty settings, progress viewer." Identify which components share data: "Both need progress table." Uses CreatiCode widget and table blocks. Auto-graded by component separation and data sharing identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G6.05: Decompose an AI chatbot project into components


ID: T03.G6.09
Topic: T03 – Problem Decomposition
Skill: Identify when to use AI vs custom code for a subtask
Description: **Student task:** For each subtask in a project, decide whether AI (ChatGPT) or custom code is more appropriate. **Coding scenario:** Story game subtasks: "Generate creative story text" → AI (ChatGPT can write stories), "Check if player clicked button" → custom code (simple event), "Calculate score" → custom code (math formula), "Suggest plot twists" → AI (creative generation). Justify each choice by citing: "AI for creative/open-ended, custom code for precise/deterministic." Auto-graded by justification quality. _CSTA: 2-IC-23._

Dependencies:
* T03.G6.05: Decompose an AI chatbot project into components
* T03.G6.06: Use XO to generate subtasks and evaluate suggestions



ID: T03.G6.10
Topic: T03 – Problem Decomposition
Skill: Decide when to decompose vs keep integrated
Description: **Student task:** Analyze scenarios where decomposition helps versus hurts, and justify when to keep code integrated. **Coding scenario:** Scenario A: "10-line script that moves sprite and plays sound" → Keep integrated (too small to split, splitting adds overhead). Scenario B: "200-line script with player controls, enemy AI, scoring, and sound" → Decompose (too complex, hard to debug). Scenario C: "Two sprites that MUST change together or both break" → Keep integrated (tight coupling makes separation risky). Identify criteria: "Decompose when: >50 lines, multiple concerns, independent testing needed. Keep integrated when: <20 lines, single concern, tightly coupled." Auto-graded by criteria identification and scenario analysis. _CSTA: 2-AP-13._

Dependencies:
* T03.G6.09: Identify when to use AI vs custom code for a subtask
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G5.08: Identify shared state between modules


ID: T03.G6.11
Topic: T03 – Problem Decomposition
Skill: Separate components suitable for AI assistance from those requiring human judgment
Description: **Student task:** Analyze a project and categorize each component as "AI-suitable" (can be delegated to AI tools) or "human-required" (needs human creativity, ethics, or domain expertise). **Coding scenario:** Educational game project components: "AI-suitable: generate practice problems (ChatGPT), create varied feedback messages, suggest difficulty adjustments." "Human-required: design learning progression (pedagogical expertise), set appropriate difficulty levels for age group, ensure content is culturally appropriate." "Shared: content review (AI generates, human validates)." Justify each categorization by identifying what makes tasks suitable for AI (pattern-based, well-defined) vs human (creative, ethical, contextual). Auto-graded by justification quality and completeness. _CSTA: 2-IC-23._

Dependencies:
* T03.G6.09: Identify when to use AI vs custom code for a subtask
* T03.G6.05: Decompose an AI chatbot project into components


ID: T03.G6.12
Topic: T03 – Problem Decomposition
Skill: Design module isolation for independent AI vs deterministic testing
Description: **Student task:** Restructure a project decomposition so AI-powered components can be tested separately from deterministic logic components. **Coding scenario:** Story game with AI: Original design mixes AI text generation with game logic. Improved design: "AI Module: isolated text generation with mock inputs for testing (can test with sample prompts without game running)." "Game Logic Module: isolated scoring and state management with mock story content (can test with placeholder text)." "Integration Module: connects the two (tested last)." Design test stubs for each module showing how each can be verified independently. Auto-graded by isolation completeness and test stub design. _CSTA: 2-AP-17._

Dependencies:
* T03.G6.11: Separate components suitable for AI assistance from those requiring human judgment
* T03.G6.10: Decide when to decompose vs keep integrated



ID: T03.G7.01
Topic: T03 – Problem Decomposition
Skill: Trace how architecture organizes a complex project
Description: **Student task:** Examine a complex project and trace how its architecture organizes components. **Coding scenario:** Multiplayer racing game architecture: "Trace how Game State Manager coordinates Car Module, Track Module, and Network Module. Show data flow: user input → Car → position update → Network → other players." Explain why this organization helps testing. Auto-graded by tracing accuracy. _CSTA: 2-AP-13._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T02.G5.01: Trace a script with nested loops using debug print





ID: T03.G7.02
Topic: T03 – Problem Decomposition
Skill: List architectural components with responsibility statements
Description: **Student task:** List main architectural components and write a responsibility statement for each. **Coding scenario:** RPG game: "Player System: handles character stats, inventory, and movement." "Combat System: manages battles, damage calculation, and animations." "World System: controls maps, NPCs, and quests." Each statement defines clear boundaries. Auto-graded by component coverage and clarity. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.01: Trace how architecture organizes a complex project
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T03.G7.02.01
Topic: T03 – Problem Decomposition
Skill: Define clear boundaries between component responsibilities
Description: **Student task:** Identify what each component should NOT do to maintain clear boundaries. **Coding scenario:** RPG game: "Player System should NOT: calculate enemy damage (that's Combat)," "Combat System should NOT: move the player (that's Player)," "World System should NOT: modify player stats directly (use Combat)." List 2-3 "should NOT" rules per component. Auto-graded by boundary clarity. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.02: List architectural components with responsibility statements


ID: T03.G7.02.02
Topic: T03 – Problem Decomposition
Skill: Identify interface contracts between components
Description: **Student task:** For each pair of communicating components, define the interface contract (what data is sent, format, when). **Coding scenario:** RPG game interfaces: "Player → Combat: sends {attackType: string, power: number} when attack button pressed," "Combat → Player: sends {damage: number, source: string} when hit detected," "World → Player: sends {canMove: boolean} before each movement." Specify data types and trigger conditions. Auto-graded by interface completeness. _CSTA: 2-AP-14._

Dependencies:
* T03.G7.02.01: Define clear boundaries between component responsibilities
* T03.G7.03: Draw component interaction diagrams



ID: T03.G7.03
Topic: T03 – Problem Decomposition
Skill: Draw component interaction diagrams
Description: **Student task:** Create diagrams showing how components communicate and share data. **Coding scenario:** RPG game diagram: Draw arrows: "Player System → position → World System," "Combat System → damage → Player System," "World System → NPC data → Combat System." Label each arrow with what data flows. Use CreatiCode diagram editor. Auto-graded by diagram completeness. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.02: List architectural components with responsibility statements





ID: T03.G7.04
Topic: T03 – Problem Decomposition
Skill: Compare and analyze trade-offs between two architecture designs
Description: **Student task:** Compare two architecture designs side-by-side and analyze their trade-offs across multiple criteria. **Coding scenario:** Design A: all code in one sprite (simple but hard to maintain). Design B: separate sprites for each system (more files but easier to test and modify). Trade-off analysis table: "Simplicity: A wins (one file). Maintainability: B wins (isolated changes). Testability: B wins (test modules separately). Communication overhead: A wins (no broadcasts needed)." Weighted recommendation: "For a small project, A is acceptable. For a growing project, B is better because maintainability matters more over time." Auto-graded by trade-off completeness and context-aware recommendation. _CSTA: 2-AP-17._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G5.05: Compare and rank two project plans with justified criteria





ID: T03.G7.05
Topic: T03 – Problem Decomposition
Skill: Propose a restructured design to fix problems
Description: **Student task:** Given a project with structural problems, propose a new module breakdown to fix them. **Coding scenario:** Problem: "collision code duplicated in 5 sprites, score updates happen in 3 different places." Solution: "Create Collision Manager sprite to handle all collisions," "Create Score Manager to centralize all score updates." Explain how each change fixes a problem. Auto-graded by solution relevance. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.04: Evaluate trade-offs between two architecture designs
* T03.G6.02: Identify reusable components across projects





ID: T03.G7.06
Topic: T03 – Problem Decomposition
Skill: Write test cases for each module
Description: **Student task:** List specific test cases for each module in a project breakdown. **Coding scenario:** Platform game modules: "Player Module: test jump height is exactly 100 pixels, test can't move through walls." "Enemy Module: test patrol reverses at edges, test damage reduces player health." "Score Module: test coin adds 10 points, test score displays correctly." Auto-graded by test coverage. _CSTA: 2-AP-17._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G5.02: Draw a screen/level flow diagram
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T03.G7.07
Topic: T03 – Problem Decomposition
Skill: Insert bug-fix tasks into a project plan
Description: **Student task:** Read test results with failures and insert bug-fix tasks at appropriate positions. **Coding scenario:** Test results: "Player falls through floor (FAIL)," "Score doesn't reset on new game (FAIL)." Insert: "Fix floor collision check" after "Create floor sprites" and before "Add enemies." "Fix score reset" in "Game State Manager" section. Maintain dependencies. Auto-graded by insertion logic. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.06: Write test cases for each module
* T03.G5.03: Mark dependencies between tasks in a project plan





ID: T03.G7.08
Topic: T03 – Problem Decomposition
Skill: Decompose a 3D scene project into components
Description: **Student task:** Break down a 3D project into its key components using CreatiCode 3D blocks. **Coding scenario:** 3D racing game: "Scene Setup: initialize 3D scene + camera follow," "Car Component: 3D model + physics body + controls," "Track Component: 3D terrain + checkpoints + boundaries," "UI Overlay: speedometer widget attached to viewport." Auto-graded by component identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium-sized project
* T03.G5.07: Decompose a 2D physics simulation into components




ID: T03.G7.09
Topic: T03 – Problem Decomposition
Skill: Identify cross-cutting concerns in architecture
Description: **Student task:** Identify features that affect multiple modules and need special handling. **Coding scenario:** RPG game cross-cutting concerns: "Logging: all modules need to log errors to console," "Sound: Player, Combat, and World all play sounds," "Save/Load: all modules need to save and restore state." Propose solution: "Sound Manager sprite that all modules broadcast to." Auto-graded by concern identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.02.01: Define clear boundaries between component responsibilities
* T03.G6.02: Identify reusable components across projects


ID: T03.G7.10
Topic: T03 – Problem Decomposition
Skill: Decompose using recursive structure (base case + recursive case)
Description: **Student task:** Break down a problem that has recursive structure into base case and recursive case. **Coding scenario:** Draw a fractal tree: "Base case: if branch length < 5, stop drawing." "Recursive case: draw branch, then at tip spawn two smaller branches at angles." Another example - file browser: "Base case: if item is file, display name." "Recursive case: if item is folder, display name and apply same process to contents." Identify when recursive decomposition is appropriate (self-similar structures). Auto-graded by base/recursive identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.04: Evaluate trade-offs between two architecture designs
* T03.G5.09: Apply divide-and-conquer to break a large task into halves


ID: T03.G7.11
Topic: T03 – Problem Decomposition
Skill: Trace how a complex bug spans multiple modules
Description: **Student task:** Given a bug report, trace which modules might be involved and in what order to investigate. **Coding scenario:** Bug: "Player score doesn't save between sessions." Trace: "1. Check Score Module - is score variable correct? 2. Check Save/Load Module - is save being called? 3. Check Data Storage - is cloud variable being set? 4. Check Game Flow - when is save triggered?" For each step, list what to check and how. Auto-graded by trace completeness and logical order. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.09: Identify cross-cutting concerns in architecture
* T03.G3.11: Decompose a bug report into investigation steps



ID: T03.G7.12
Topic: T03 – Problem Decomposition
Skill: Decompose for testability (each piece independently verifiable)
Description: **Student task:** Restructure a decomposition plan so each piece can be tested independently without requiring other pieces to work. **Coding scenario:** Original plan: "Build movement, then collision, then scoring" – problem: can't test scoring without movement and collision working. Improved plan: "1. Build scoring module with test button that simulates adding points (testable alone). 2. Build collision module with test sprite that always reports 'hit' (testable alone). 3. Build movement with mock boundaries (testable alone). 4. Connect all pieces." Each module includes its own test harness. Auto-graded by independent testability of each piece. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.11: Trace how a complex bug spans multiple modules
* T03.G7.06: Write test cases for each module


ID: T03.G7.13
Topic: T03 – Problem Decomposition
Skill: Identify which modules can be built independently vs sequentially for team work
Description: **Student task:** Analyze a project decomposition and categorize modules as "independent" (can be built in parallel by different team members) or "sequential" (must wait for another module). **Coding scenario:** Multiplayer game modules: "Player Module: INDEPENDENT - can start immediately, no dependencies." "Network Module: INDEPENDENT - can start immediately with mock data." "Game Logic Module: SEQUENTIAL - needs Player and Network interfaces defined first." "UI Module: PARTIALLY INDEPENDENT - menu can start now, HUD needs Game Logic interface." Create a parallelization diagram showing which modules can proceed simultaneously and where bottlenecks occur. Auto-graded by correct categorization and bottleneck identification. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.12: Decompose for testability (each piece independently verifiable)
* T03.G7.02.02: Identify interface contracts between components


ID: T03.G7.14
Topic: T03 – Problem Decomposition
Skill: Design module interfaces for clean team handoffs
Description: **Student task:** Design clear interface specifications that allow team members to work independently and integrate later without conflicts. **Coding scenario:** Team project with 3 developers: "Developer A (Player): exports {getPosition(), getHealth(), takeDamage(amount)} - all return types and behaviors documented." "Developer B (Enemy): imports Player interface, exports {spawn(), attack(), getPosition()} - documents what Player methods it calls." "Developer C (Game): imports both, coordinates overall logic." Write interface contracts specifying: method names, input types, output types, when methods are called, and what happens on errors. Create mock implementations so each developer can test without waiting for others. Auto-graded by interface completeness and mock implementation quality. _CSTA: 2-AP-14._

Dependencies:
* T03.G7.13: Identify which modules can be built independently vs sequentially for team work
* T03.G7.02.02: Identify interface contracts between components



ID: T03.G8.01
Topic: T03 – Problem Decomposition
Skill: Distinguish feature-level vs system-level decomposition
Description: **Student task:** Analyze project breakdowns and identify whether they use feature-level (what it does) or system-level (how it's organized) decomposition. **Coding scenario:** Breakdown A: "jumping feature, scoring feature, level feature" = feature-level. Breakdown B: "input handler, game state manager, renderer" = system-level. Explain when each is appropriate: feature-level for planning, system-level for implementation. Auto-graded by correct identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.03: Draw component interaction diagrams
* T02.G6.01: Use the pseudocode generation block





ID: T03.G8.02
Topic: T03 – Problem Decomposition
Skill: Extract user requirements from a project specification
Description: **Student task:** Read a project specification and extract key user requirements with priorities. **Coding scenario:** Spec: "Educational math game for elementary students. Must track progress, show animations, include sound. Nice to have: multiplayer, leaderboard." Extract: "Must: progress tracking (P1), animations (P1), sound (P2). Optional: multiplayer (P3), leaderboard (P3)." Auto-graded by requirement extraction. _CSTA: 2-AP-13._

Dependencies:
* T03.G8.01: Distinguish feature-level vs system-level decomposition
* T10.G6.01: Sort a table by a column





ID: T03.G8.03
Topic: T03 – Problem Decomposition
Skill: List technical constraints from a specification
Description: **Student task:** Examine a specification and extract technical constraints by category. **Coding scenario:** Spec: "Must run on school tablets, no network required, all data local, max 5 sprites for performance." Constraints: "Platform: tablet-compatible (touch controls)," "Network: offline-only," "Performance: max 5 sprites," "Storage: local only (use cloud variable simulation)." Auto-graded by constraint identification. _CSTA: 2-AP-13._

Dependencies:
* T03.G8.02: Extract user requirements from a project specification






ID: T03.G8.04
Topic: T03 – Problem Decomposition
Skill: Propose technical modules from requirements and constraints
Description: **Student task:** Take requirements and constraints and propose a technical module breakdown. **Coding scenario:** Requirements: progress tracking, animations, sound. Constraints: offline, max 5 sprites. Modules: "Progress Manager (1 sprite): saves to local storage," "Animation Controller (1 sprite): manages all character animations," "Sound Manager (1 sprite): handles all audio," "Game Logic (2 sprites): player + level." Total: 5 sprites. Auto-graded by constraint satisfaction. _CSTA: 2-AP-13._

Dependencies:
* T03.G8.03: List technical constraints from a specification




ID: T03.G8.04.01
Topic: T03 – Problem Decomposition
Skill: Justify module boundary decisions with trade-off analysis
Description: **Student task:** Explain why you drew module boundaries where you did, with trade-offs. **Coding scenario:** "Why separate Sound Manager? Trade-off: adds broadcast overhead BUT centralizes audio control, easier to add mute feature, all sounds in one place." "Why combine player+level in Game Logic? Trade-off: tighter coupling BUT saves sprite count for constraint." Justify each boundary. Auto-graded by trade-off reasoning. _CSTA: 2-AP-17._

Dependencies:
* T03.G8.04: Propose technical modules from requirements and constraints
* T03.G7.04: Evaluate trade-offs between two architecture designs


ID: T03.G8.04.02
Topic: T03 – Problem Decomposition
Skill: Validate module design against constraints checklist
Description: **Student task:** Create a checklist of constraints and validate your module design against each one. **Coding scenario:** Constraints checklist: "[ ] Max 5 sprites" → check module count, "[ ] Offline only" → verify no network blocks used, "[ ] Touch-friendly" → verify UI modules use appropriate widgets, "[ ] Performance" → verify no heavy loops in main thread. For each constraint, explain how design satisfies it or what trade-off was made. Auto-graded by validation completeness. _CSTA: 2-AP-17._

Dependencies:
* T03.G8.04.01: Justify module boundary decisions with trade-off analysis
* T03.G8.03: List technical constraints from a specification



ID: T03.G8.05
Topic: T03 – Problem Decomposition
Skill: Specify module interfaces and data flows
Description: **Student task:** Specify how modules communicate with clear interfaces. **Coding scenario:** Math game interfaces: "Progress Manager receives: {level: number, score: number} via broadcast 'save-progress'." "Animation Controller receives: {action: string, sprite: string} via broadcast 'animate'." "Game Logic sends: score updates to Progress Manager, animation requests to Animation Controller." Define input/output for each. Auto-graded by interface clarity. _CSTA: 2-AP-14._

Dependencies:
* T03.G8.04: Propose technical modules from requirements and constraints





ID: T03.G8.06
Topic: T03 – Problem Decomposition
Skill: Use XO to review a specification and apply feedback
Description: **Student task:** Provide a draft specification to XO and critically evaluate its feedback. **Coding scenario:** Draft spec for puzzle game. XO feedback: "Missing: how levels increase difficulty," "Risk: no save system mentioned," "Suggestion: add tutorial level." Evaluate each: integrate "difficulty progression," add "auto-save after each level," defer tutorial to v2. Explain reasoning for each decision. Auto-graded by feedback integration. _CSTA: 2-IC-23._

Dependencies:
* T03.G8.05: Specify module interfaces and data flows
* T03.G6.06: Use XO to generate subtasks and evaluate suggestions





ID: T03.G8.07
Topic: T03 – Problem Decomposition
Skill: Rank project ideas by complexity with justification
Description: **Student task:** Compare project ideas and rank them by complexity with specific justification. **Coding scenario:** Ideas: A) Single-player quiz, B) Two-player racing, C) Multiplayer RPG. Rank: A (simplest: no real-time sync), B (medium: needs timing, two inputs), C (complex: network, persistent state, multiple systems). Justify each ranking citing: feature count, dependencies, unknowns. Auto-graded by justification quality. _CSTA: 2-AP-15._

Dependencies:
* T03.G7.04: Evaluate trade-offs between two architecture designs
* T10.G6.01: Sort a table by a column





ID: T03.G8.08
Topic: T03 – Problem Decomposition
Skill: Cut scope from over-ambitious plans with trade-off analysis
Description: **Student task:** Analyze an over-ambitious plan and propose scope reductions with trade-offs. **Coding scenario:** Plan has 15 features for 2-week project. Cut to 6 for v1: keep "core gameplay" (essential), keep "basic UI" (usable), cut "voice commands" (complex, not essential), move "leaderboard" to v2 (nice but not critical). Trade-off: "cutting voice saves 3 days but reduces accessibility." Auto-graded by trade-off analysis. _CSTA: 2-AP-15._

Dependencies:
* T03.G8.07: Rank project ideas by complexity with justification
* T03.G6.03: Organize features into v1/v2/v3 milestones
* T03.G6.04: Revise milestones when constraints are discovered






ID: T03.G8.09
Topic: T03 – Problem Decomposition
Skill: Write a refactoring plan for a complex project
Description: **Student task:** Review a project with structural problems and write a step-by-step refactoring plan. **Coding scenario:** Problems: "1. Collision code duplicated in 5 sprites, 2. Score variable updated in 3 places, 3. No clear game state management." Plan: "Step 1 (high impact): Create Collision Manager sprite, Step 2: Centralize score in Score Manager, Step 3: Add Game State Manager for level/game-over." Prioritize by impact. Auto-graded by plan completeness. _CSTA: 2-AP-17._

Dependencies:
* T03.G7.05: Propose a restructured design to fix problems
* T03.G8.04: Propose technical modules from requirements and constraints





ID: T03.G8.10
Topic: T03 – Problem Decomposition
Skill: Assign refactoring tasks to release milestones
Description: **Student task:** Take refactoring tasks and assign them to release milestones by priority. **Coding scenario:** Tasks: "Create Collision Manager, Centralize score, Add Game State Manager, Split large sprite into modules, Add unit tests." Assign: "v1.1 (bug fix): Collision Manager (blocks bugs)," "v1.2 (cleanup): Centralize score, Game State Manager," "v2.0 (architecture): Split sprite, Add tests." Respect dependencies. Auto-graded by milestone logic. _CSTA: 2-AP-17._

Dependencies:
* T03.G8.09: Write a refactoring plan for a complex project
* T03.G6.04: Revise milestones when constraints are discovered





ID: T03.G8.11
Topic: T03 – Problem Decomposition
Skill: Decompose a multiplayer project into components
Description: **Student task:** Break down a multiplayer project using CreatiCode multiplayer blocks. **Coding scenario:** Multiplayer racing game: "Room Management: create/join game room, list players," "State Sync: broadcast position updates to all players," "Host Logic: host tracks race progress, declares winner," "Client Logic: receives updates, renders other players." Identify what runs on host vs all clients. Auto-graded by component coverage. _CSTA: 2-AP-13._

Dependencies:
* T03.G7.08: Decompose a 3D scene project into components
* T03.G8.04: Propose technical modules from requirements and constraints




ID: T03.G8.12
Topic: T03 – Problem Decomposition
Skill: Decompose an AI-assisted project with human-AI task division
Description: **Student task:** Break down a project that uses AI, clearly separating human tasks from AI tasks. **Coding scenario:** AI story generator: "Human tasks: design UI, write prompts, validate AI output quality." "AI tasks: generate story text via ChatGPT, suggest plot twists." "Shared handoff: human provides context → AI generates → human reviews → AI refines." Uses CreatiCode ChatGPT blocks. Auto-graded by task division clarity. _CSTA: 2-IC-23._

Dependencies:
* T03.G8.04.01: Justify module boundary decisions with trade-off analysis
* T03.G6.05: Decompose an AI chatbot project into components


ID: T03.G8.13
Topic: T03 – Problem Decomposition
Skill: Decompose a data dashboard project into query/transform/display layers
Description: **Student task:** Break down a data dashboard project into distinct layers: query (getting data), transform (processing data), display (showing results). **Coding scenario:** Class survey dashboard: "Query layer: read responses from table variable, fetch from cloud storage," "Transform layer: count responses per option, calculate percentages, sort by frequency," "Display layer: create bar chart with widgets, add labels, color-code by category." Identify which CreatiCode blocks belong to each layer. Auto-graded by layer identification and block mapping. _CSTA: 2-AP-13._

Dependencies:
* T03.G8.05: Specify module interfaces and data flows
* T03.G6.07: Decompose a data pipeline project into stages


ID: T03.G8.14
Topic: T03 – Problem Decomposition
Skill: Propose decomposition strategies for unknown problem domains
Description: **Student task:** Given an unfamiliar problem domain, propose multiple decomposition strategies and evaluate which is most appropriate. **Coding scenario:** New domain: "Build an accessibility tool for vision-impaired users." Propose strategies: "Strategy A: Decompose by user task (navigation, reading, input)," "Strategy B: Decompose by assistive technology (screen reader, voice commands, haptic feedback)," "Strategy C: Decompose by platform component (input handler, output renderer, settings manager)." Evaluate: "Strategy A best for user-centered design, Strategy C best for technical implementation." Choose and justify. Auto-graded by strategy variety and justification. _CSTA: 2-AP-17._

Dependencies:
* T03.G8.01: Distinguish feature-level vs system-level decomposition
* T03.G8.07: Rank project ideas by complexity with justification
* T03.G7.10: Decompose using recursive structure (base case + recursive case)



ID: T03.G8.15
Topic: T03 – Problem Decomposition
Skill: Decompose a large codebase for team parallel development
Description: **Student task:** Given a large project with 10+ features, decompose it into work streams that 3-4 team members can build in parallel with minimal blocking. **Coding scenario:** Multiplayer game project: "Team member 1: Player Module (movement, controls, animation) - NO dependencies. Team member 2: Network Module (room creation, messaging, sync) - NO dependencies. Team member 3: Game Logic Module (scoring, win conditions, timer) - depends on interfaces from 1 & 2. Team member 4: UI Module (menus, HUD, results) - depends on interfaces from 3." Define clear interfaces between streams: "Player → Game Logic: {position, action} via broadcast." Identify bottlenecks: "Game Logic must wait for Player and Network interfaces." Auto-graded by parallel-work analysis and interface definition. _CSTA: 2-AP-17, 2-AP-13._

Dependencies:
* T03.G8.14: Propose decomposition strategies for unknown problem domains
* T03.G8.11: Decompose a multiplayer project into components
* T03.G7.14: Design module interfaces for clean team handoffs



ID: T03.G8.16
Topic: T03 – Problem Decomposition
Skill: Critique and improve a peer's decomposition plan
Description: **Student task:** Review another student's decomposition plan and provide structured feedback with specific improvements. **Coding scenario:** Peer's plan for quiz game: "1. Make questions, 2. Make buttons, 3. Make scoring, 4. Make sounds, 5. Make it look nice." Critique: "Problem 1: Steps are too vague - what exactly does 'make questions' include? Problem 2: No dependencies shown - does scoring need buttons to work first? Problem 3: Missing testing step. Problem 4: 'Make it look nice' is too broad - split into specific UI tasks." Improved plan: "1. Create question data in list variable (testable: verify list has 10 items), 2. Build answer buttons with click detection (testable: buttons respond), 3. Connect buttons to question checking and score update (needs 1+2), 4. Add sound effects for correct/wrong (needs 3), 5. Style: add background, animate correct answers, format score display." Auto-graded by critique specificity and improvement quality. _CSTA: 2-AP-17._

Dependencies:
* T03.G8.15: Decompose a large codebase for team parallel development
* T03.G7.12: Decompose for testability (each piece independently verifiable)
* T03.G8.06: Use XO to review a specification and apply feedback


ID: T03.G8.17
Topic: T03 – Problem Decomposition
Skill: Design iterative human-AI feedback loops in project architecture
Description: **Student task:** Design a project architecture where AI and human work in iterative cycles, with each improving the other's output. **Coding scenario:** AI writing assistant project: "Cycle 1: Human provides topic outline → AI generates first draft → Human reviews and marks issues. Cycle 2: Human feedback fed back to AI → AI revises → Human approves or continues cycles." Decompose into components: "Input Collector (human outlines/feedback), AI Generator (ChatGPT requests), Human Review Interface (highlighting, commenting), Feedback Processor (formats human input for AI), Iteration Manager (tracks cycles, stores history)." Define when cycles should stop: "Stop when human approves OR 3 cycles reached OR no new feedback." Auto-graded by loop design completeness and stopping criteria. _CSTA: 2-IC-23, 2-AP-17._

Dependencies:
* T03.G8.12: Decompose an AI-assisted project with human-AI task division
* T03.G8.06: Use XO to review a specification and apply feedback


ID: T03.G8.18
Topic: T03 – Problem Decomposition
Skill: Decompose for AI oversight with human checkpoints at critical decisions
Description: **Student task:** Design a decomposition that places human review checkpoints at critical decision points where AI actions could have significant consequences. **Coding scenario:** AI-powered student feedback system: "Critical checkpoints: BEFORE AI sends negative feedback (human reviews tone), BEFORE final grade is assigned (human verifies), BEFORE any message mentions student's personal situation (privacy check)." "Non-critical (AI can proceed): generating practice problems, providing hints, explaining concepts." Decompose into: "AI Draft Module: generates all content," "Checkpoint Router: identifies critical vs non-critical," "Human Review Queue: holds critical items for approval," "Override Handler: allows human to modify before sending." Design escalation paths: "If human rejects 3 times, flag for curriculum team review." Auto-graded by checkpoint placement rationale and escalation design. _CSTA: 2-IC-23, 2-AP-17._

Dependencies:
* T03.G8.17: Design iterative human-AI feedback loops in project architecture
* T03.G6.11: Separate components suitable for AI assistance from those requiring human judgment


ID: T03.G8.19
Topic: T03 – Problem Decomposition
Skill: Decompose privacy-sensitive projects separating public and private data components
Description: **Student task:** Design a decomposition that clearly separates components handling private/sensitive data from those handling public data, minimizing data exposure. **Coding scenario:** Classroom progress tracker: "Private data components (restricted access): student names, individual scores, learning difficulties, parent contact info – stored encrypted, accessed only by authenticated teachers." "Public data components (open access): class averages (anonymized), general lesson content, achievement badges (opt-in display)." "Separation boundaries: Private Data Store (encrypted), Access Controller (verifies permissions), Anonymizer (strips identifying info before analytics), Public Display (only receives anonymized data)." Design data flow: "Never pass raw student data to public components – always go through Anonymizer first." Auto-graded by separation clarity and data flow safety. _CSTA: 2-IC-20, 2-AP-17._

Dependencies:
* T03.G8.18: Decompose for AI oversight with human checkpoints at critical decisions
* T03.G8.04: Propose technical modules from requirements and constraints


ID: T03.G8.20
Topic: T03 – Problem Decomposition
Skill: Detect and mitigate AI bias in AI-assisted decomposition suggestions
Description: **Student task:** Critically analyze AI-generated decomposition suggestions for potential biases, then design mitigation strategies. **Coding scenario:** XO suggests decomposition for "accessibility app for elderly users": Original AI suggestion: "Simple large buttons, basic features only, limited customization." Bias detection: "Assumes elderly users want/need simplicity – some may want full features." "Assumes all elderly users have same needs – ignores diversity in abilities." Mitigated decomposition: "User Profile Module: stores individual preferences and abilities," "Adaptive Interface: adjusts based on user feedback, not assumptions," "Full Feature Set: available to all, with optional simplification mode," "Accessibility Options: customizable per user (text size, contrast, audio)." Document: what biases were detected, why they're problematic, how the mitigation addresses them. Auto-graded by bias identification depth and mitigation effectiveness. _CSTA: 2-IC-23, 2-AP-17._

Dependencies:
* T03.G8.06: Use XO to review a specification and apply feedback
* T03.G6.11: Separate components suitable for AI assistance from those requiring human judgment



# T04 - Algorithm Patterns (Phase 9 Optimized - November 2025)
# PHASE 9 MAJOR OVERHAUL - Bold Changes for Excellence
#
# PHILOSOPHY SHIFT: Algorithm Patterns are about PROBLEM-SOLVING STRATEGIES
# - Every skill emphasizes WHY patterns exist and WHEN to apply them
# - Added "Explain your reasoning" and "Critique" components throughout
# - Integrated AI-era skills across more grades (not just G7-G8)
# - Strengthened connections to real-world problem solving
#
# MAJOR CHANGES FROM PHASE 8:
#
# 1. FIXED DUPLICATE: Removed duplicate T04.G5.02.02 (was at two locations)
#
# 2. NEW SKILL CATEGORIES ADDED:
#    a) PATTERN COMMUNICATION (explaining pattern choices):
#       - GK.06: Explain why your pattern choice works using picture cards
#       - G1.07: Explain the difference between two patterns to a partner
#       - G3.11: Describe a pattern's purpose without showing the code
#       - G5.09: Document why a specific pattern was chosen
#       - G7.13: Present pattern trade-offs to stakeholders
#
#    b) PATTERN CRITIQUE & VERIFICATION:
#       - G2.06: Spot a pattern that doesn't fit the sequence
#       - G4.10: Critique a peer's pattern choice and suggest improvements
#       - G6.09: Verify that code matches the intended pattern
#       - G8.19: Lead code review for pattern implementation quality
#
#    c) REAL-WORLD PATTERN RECOGNITION:
#       - GK.07: Find repeating patterns in everyday life (video examples)
#       - G2.07: Connect daily routines to repeat patterns
#       - G4.11: Recognize algorithm patterns in apps and games
#       - G6.10: Analyze patterns in data processing pipelines
#
#    d) COLLABORATIVE PATTERN DESIGN:
#       - G3.12: Build a pattern solution with a partner
#       - G5.10: Merge two partial pattern implementations
#       - G7.14: Design composite patterns as a team
#
#    e) AI-ASSISTED PATTERN WORK (expanded to earlier grades):
#       - G5.11: Use AI to explain unfamiliar patterns
#       - G6.11: Evaluate AI suggestions for pattern improvements
#       - G7.12: Evaluate when AI-generated code matches standard patterns
#       - G8.17-18: Advanced AI collaboration for pattern development
#
# 3. ENHANCED DEBUGGING PROGRESSION:
#    - GK.04.01, G1.06 (multi-error debugging)
#    - G3.07.01 (off-by-one), G4.10.01 (nested loop bugs)
#    - G5.04.02 (filter condition bugs), G6.04.01 (parameterized block bugs)
#    - G7.05.01 (data flow bugs), G8.09 (multi-pattern bugs)
#    - NEW: G8.20: Systematic debugging methodology for complex patterns
#
# 4. STRENGTHENED K-2 COMPUTATIONAL THINKING:
#    - More emphasis on WHY patterns work, not just recognition
#    - Added prediction and reasoning skills
#    - Connected patterns to everyday decision-making
#
# 5. ADVANCED G8 SKILLS FOR AI ERA:
#    - Pattern composition at scale
#    - Performance analysis and optimization
#    - AI collaboration and validation
#    - Team-based pattern library development
#
# 6. DEPENDENCY IMPROVEMENTS:
#    - Fixed incorrect dependency references
#    - Stronger K→G1→G2→G3 progression for pattern thinking
#    - Added alternative dependency paths for flexibility
#    - All intra-topic dependencies validated for X-2 rule
#
# Total: 142 skills (20 new skills added for communication, verification,
# real-world connections, AI collaboration, and advanced debugging)

ID: T04.GK.01
Topic: T04 – Algorithm Patterns
Skill: Select a row of picture cards showing a repeating pattern
Description: Students look at rows of picture cards (colored shapes, animals, or objects) and click on the row that shows a clear repeating pattern (ABAB, AABB, ABCABC), distinguishing it from broken or random rows. PICTURE-BASED visual scenario activity.






ID: T04.GK.02
Topic: T04 – Algorithm Patterns
Skill: Drag the next picture card to extend a repeating pattern
Description: Students see a short pattern of picture cards (e.g., red circle, blue square, red circle, blue square, ?) and drag-and-drop the correct picture card to extend the pattern by one. PICTURE-BASED drag-and-drop activity.

Dependencies:
* T04.GK.01: Select a row of picture cards showing a repeating pattern







ID: T04.GK.03
Topic: T04 – Algorithm Patterns
Skill: Match a picture pattern to its spoken description
Description: Students see a pattern of picture cards (shapes, colors, or objects) and click on the audio button that matches the pattern description (e.g., "circle, square, circle, square"). PICTURE-BASED audio-supported matching activity for pre-readers.

Dependencies:
* T04.GK.02: Drag the next picture card to extend a repeating pattern







ID: T04.GK.04
Topic: T04 – Algorithm Patterns
Skill: Debug a broken pattern by replacing the wrong picture card
Description: Students see a row of picture cards with one wrong picture (highlighted or marked) and drag-and-drop the correct picture card to fix the broken repeating pattern. PICTURE-BASED debugging activity.

Dependencies:
* T04.GK.02: Drag the next picture card to extend a repeating pattern




ID: T04.GK.04.01
Topic: T04 – Algorithm Patterns
Skill: Debug a pattern by identifying and replacing TWO wrong cards
Description: Students see a row of picture cards with TWO wrong pictures (not highlighted) and must find and replace both cards to fix the broken repeating pattern. This extends debugging from single errors to multiple errors. PICTURE-BASED multi-step debugging activity.

Dependencies:
* T04.GK.04: Debug a broken pattern by replacing the wrong picture card







ID: T04.GK.05
Topic: T04 – Algorithm Patterns
Skill: Compare two patterns and select the one with more repetitions
Description: Students see two rows of picture cards showing patterns and click on the row that has more repetitions of the pattern unit (e.g., ABAB vs ABABAB). Focus is on counting how many times a pattern repeats. PICTURE-BASED counting and comparison activity.

Dependencies:
* T04.GK.04: Debug a broken pattern by replacing the wrong picture card




ID: T04.GK.05.01
Topic: T04 – Algorithm Patterns
Skill: Classify patterns by their repeating unit length
Description: Students sort picture card patterns into groups based on how many cards are in the repeating unit (2-card patterns like AB vs 3-card patterns like ABC). They drag patterns into labeled bins: "2-card unit" or "3-card unit." Focus is on analyzing pattern structure, not just recognizing repetition. PICTURE-BASED classification activity.

Dependencies:
* T04.GK.05: Compare two patterns and select the one with more repetitions




ID: T04.GK.06
Topic: T04 – Algorithm Patterns
Skill: Explain why your pattern choice works using picture cards
Description: **Student task:** After arranging picture cards into a repeating pattern, explain WHY the pattern works. Point to each card and say what repeats and why it makes a good pattern. **Visual scenario:** Student arranges red-blue-red-blue pattern, then records or says: "First red, then blue, then red again, then blue again. Red-blue keeps repeating!" **Assessment:** Teacher/AI evaluates explanation for identifying the repeating unit and explaining the repetition. _Implementation note: Voice recording or partner listening; introduces pattern COMMUNICATION - a critical skill. Audio prompt guides explanation. Rubric-graded for completeness. PICTURE-BASED explanation activity. CSTA: EK-ALG-AF-01, EK-CS-PC-01._

Dependencies:
* T04.GK.02: Drag the next picture card to extend a repeating pattern
* T04.GK.05: Compare two patterns and select the one with more repetitions




ID: T04.GK.07
Topic: T04 – Algorithm Patterns
Skill: Find repeating patterns in everyday life (video examples)
Description: **Student task:** Watch short video clips of everyday activities. Tap when you see a repeating pattern! **Visual scenario:** Videos show: clock ticking (tick-tock-tick-tock - pattern!), car driving straight (not a pattern), person walking (left-right-left-right - pattern!), dog barking once (not a pattern), traffic light changing (green-yellow-red-green - pattern!). Students tap "Yes, pattern!" or "No, not a pattern" for each clip. **Key insight:** Patterns are everywhere in our world, not just in pictures. _Implementation note: 4-6 short video clips (5-10 seconds each); connects pattern recognition to real life. Audio explains "A pattern is something that repeats." Auto-graded by selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T04.GK.01: Select a row of picture cards showing a repeating pattern




ID: T04.G1.01
Topic: T04 – Algorithm Patterns
Skill: Match picture cards of actions to a character's repeated movements
Description: Students see picture cards showing action sequences (e.g., hop, clap, hop, clap) and match them to a short animation showing a character performing those same repeated movements. PICTURE-BASED matching activity with simple animations.

Dependencies:
* T04.GK.02: Drag the next picture card to extend a repeating pattern





ID: T04.G1.02
Topic: T04 – Algorithm Patterns
Skill: Arrange action picture cards to create a repeating dance plan
Description: Students drag-and-drop 3-4 action picture cards (e.g., spin, jump, spin, jump) into a sequence to create a repeating "dance" plan that matches a target animation. UNPLUGGED visual planning activity with picture cards.

Dependencies:
* T04.G1.01: Match picture cards of actions to a character's repeated movements





ID: T04.G1.03
Topic: T04 – Algorithm Patterns
Skill: Highlight the repeated steps in a row of picture cards
Description: Students examine a row of picture-based instruction cards (e.g., move forward, move forward, move forward, turn) and click to highlight which cards repeat (e.g., three identical "move forward" cards). PICTURE-BASED selection activity.

Dependencies:
* T01.GK.07: Find the pattern that repeats




ID: T04.G1.03.01
Topic: T04 – Algorithm Patterns
Skill: Predict output for a sequence of repeated actions
Description: Students see a character at a starting position and a row of action picture cards (e.g., step forward, step forward, turn right). They predict where the character ends up by selecting from 3-4 position pictures. Focus is on mental execution of sequential actions. PICTURE-BASED prediction activity that builds tracing skills.

Dependencies:
* T04.G1.03: Highlight the repeated steps in a row of picture cards




ID: T04.G1.04
Topic: T04 – Algorithm Patterns
Skill: Match a picture story to a step-by-step action card sequence
Description: Students see a simple picture story (comic strip) showing a character repeating actions and match it to the correct row of step-by-step action cards that represent the same repeated sequence. PICTURE-BASED visual matching activity.

Dependencies:
* T04.G1.03: Highlight the repeated steps in a row of picture cards





ID: T04.G1.05
Topic: T04 – Algorithm Patterns
Skill: Predict the next action in a repeating picture sequence
Description: Students see an incomplete pattern of action picture cards (e.g., clap, stomp, clap, stomp, clap, ?) and select which action card comes next. Focus is on predicting pattern continuation. PICTURE-BASED prediction activity.

Dependencies:
* T04.G1.04: Match a picture story to a step-by-step action card sequence




ID: T04.G1.06
Topic: T04 – Algorithm Patterns
Skill: Debug a picture sequence by identifying the missing step
Description: Students see a picture sequence showing actions (e.g., hop, clap, hop, ___, hop, clap) with one card missing or showing a blank placeholder. Students select from 3-4 picture options which card completes the pattern correctly. Focus is on recognizing what should come next based on the established pattern. PICTURE-BASED debugging activity that builds on prediction skills.

Dependencies:
* T04.G1.05: Predict the next action in a repeating picture sequence




ID: T04.G1.06.01
Topic: T04 – Algorithm Patterns
Skill: Create a new pattern from given picture cards
Description: Students are given 4-6 different picture cards and must arrange them to create a NEW repeating pattern (not copy an existing one). They demonstrate understanding by creating valid patterns like ABAB, AABB, or ABCABC from the available cards. PICTURE-BASED creative pattern construction activity.

Dependencies:
* T04.G1.06: Debug a picture sequence by identifying the missing step
* T04.G1.02: Arrange action picture cards to create a repeating dance plan




ID: T04.G1.07
Topic: T04 – Algorithm Patterns
Skill: Explain the difference between two patterns to a partner
Description: **Student task:** Look at two different picture card patterns and explain to a partner HOW they are different. **Visual scenario:** Pattern A: red-red-blue (AAB), Pattern B: red-blue-red-blue (ABAB). Student says: "In the first pattern, red comes twice then blue once. In the second pattern, red and blue take turns." **Assessment:** Teacher/AI evaluates for correctly identifying the structural difference between patterns. _Implementation note: Pair activity with voice recording; builds communication skills. Large picture cards, audio support. PICTURE-BASED comparison activity. CSTA: E1-ALG-AF-01, E1-CS-PC-01._

Dependencies:
* T04.G1.05: Predict the next action in a repeating picture sequence
* T04.GK.06: Explain why your pattern choice works using picture cards




ID: T04.G2.01
Topic: T04 – Algorithm Patterns
Skill: Select the repeating unit from a longer picture pattern
Description: Students see a longer pattern of picture cards (e.g., star-moon-sun-star-moon-sun-star-moon-sun) and click on the group of cards that forms the repeating "unit" (e.g., star-moon-sun). PICTURE-BASED pattern recognition activity.

Dependencies:
* T04.G1.02: Arrange action picture cards to create a repeating dance plan
* T04.G1.03: Highlight the repeated steps in a row of picture cards





ID: T04.G2.02
Topic: T04 – Algorithm Patterns
Skill: Highlight the repeated steps in an everyday routine shown with picture cards
Description: Students see picture cards showing an everyday routine (e.g., brush teeth, rinse, brush teeth, rinse, brush teeth, rinse) and click to highlight the step sequence that repeats. Focus is on identifying the pattern unit in familiar activities. PICTURE-BASED selection activity.

Dependencies:
* T04.G2.01: Select the repeating unit from a longer picture pattern





ID: T04.G2.03
Topic: T04 – Algorithm Patterns
Skill: Compare expanded vs compressed representations of a repeating pattern
Description: Students see two visual representations of the same pattern using picture cards: one showing all steps explicitly (three star cards in a row) vs one using a "repeat 3" label with a single star card. They click on which representation is shorter and clearer. UNPLUGGED visual comparison activity.

Dependencies:
* T01.G2.02: Use "repeat" to make directions shorter





ID: T04.G2.04
Topic: T04 – Algorithm Patterns
Skill: Create a "repeat ___ times" label for a row of repeated picture cards
Description: Students see a row of repeated picture cards (e.g., four jump cards) and select or type the correct number to create a "repeat 4: [jump]" compressed representation. Focus is on expressing repetition concisely using visual notation. UNPLUGGED activity preparing for loop concepts.

Dependencies:
* T04.G2.03: Compare expanded vs compressed representations of a repeating pattern





ID: T04.G2.04.01
Topic: T04 – Algorithm Patterns
Skill: Debug a repeat label with wrong count
Description: Students see a "repeat N" label next to a row of repeated picture cards where N is incorrect (e.g., "repeat 3" with 5 jump cards). They identify the error and select the correct number. Focus is on verifying that compressed notation matches expanded form. UNPLUGGED debugging activity.

Dependencies:
* T04.G2.04: Create a "repeat ___ times" label for a row of repeated picture cards





ID: T04.G2.05
Topic: T04 – Algorithm Patterns
Skill: Match a "repeat box" diagram to its expanded picture card sequence
Description: Students see a visual "repeat box" (a box drawn around picture cards with "repeat 3 times" label) and match it to the equivalent expanded sequence showing all three repetitions. UNPLUGGED visual matching activity preparing students for code blocks in Grade 3.

Dependencies:
* T04.G2.04: Create a "repeat ___ times" label for a row of repeated picture cards




ID: T04.G2.05.01
Topic: T04 – Algorithm Patterns
Skill: Predict how many actions result from a repeat box
Description: Students see a "repeat box" diagram with multiple action cards inside (e.g., "repeat 3: [jump, clap]") and calculate the total number of actions that will happen. They predict: 3 × 2 = 6 actions. UNPLUGGED multiplication-based prediction activity preparing students for nested loops.

Dependencies:
* T04.G2.05: Match a "repeat box" diagram to its expanded picture card sequence
* T04.G2.03: Compare expanded vs compressed representations of a repeating pattern




ID: T04.G2.06
Topic: T04 – Algorithm Patterns
Skill: Spot a pattern that doesn't fit the sequence
Description: **Student task:** Look at 4 rows of picture card patterns. Three rows show correct repeating patterns, but one row has a mistake where the pattern breaks. Tap the row that has the broken pattern. **Visual scenario:** Row A: star-moon-star-moon (correct), Row B: red-blue-red-GREEN (broken!), Row C: cat-dog-cat-dog (correct), Row D: 1-2-3-1-2-3 (correct). **Assessment:** Students identify Row B as having the pattern error. _Implementation note: Visual critique activity; develops critical analysis skills. Auto-graded by selection. PICTURE-BASED pattern verification. CSTA: E1-ALG-AF-01._

Dependencies:
* T04.G2.01: Select the repeating unit from a longer picture pattern
* T04.G1.07: Explain the difference between two patterns to a partner




ID: T04.G2.07
Topic: T04 – Algorithm Patterns
Skill: Connect daily routines to repeat patterns
Description: **Student task:** Match everyday routines to their pattern type. **Visual scenario:** Students see routine cards: "brush teeth morning and night" (repeat 2 times daily), "days of the week" (repeat every 7 days), "school bell rings every hour" (repeat pattern). They connect each routine to a "repeat box" showing how many times it repeats. **Key insight:** Repetition patterns are everywhere in daily life—schedules, habits, natural cycles. _Implementation note: Matching activity connecting real-world to pattern notation. Auto-graded by matching accuracy. PICTURE-BASED real-world connection. CSTA: E1-ALG-AF-01._

Dependencies:
* T04.G2.02: Highlight the repeated steps in an everyday routine shown with picture cards
* T04.GK.07: Find repeating patterns in everyday life (video examples)




ID: T04.G3.01
Topic: T04 – Algorithm Patterns
Skill: Identify and match repeat box diagrams to actual code blocks
Description: Students match visual "repeat box" diagrams (showing a box around pictures with "repeat 3" label) to actual code snippets using repeat blocks, creating an explicit bridge from G2's unplugged visual notation to G3 coding with real code blocks.

Dependencies:
* T04.G2.05: Match a "repeat box" diagram to its expanded picture card sequence
* T07.G3.01: Use a counted repeat loop





ID: T04.G3.02
Topic: T04 – Algorithm Patterns
Skill: Identify where a loop could replace repeated blocks
Description: Students see a short script with copy-pasted blocks and choose which part can be replaced by a loop, focusing on recognizing the loop pattern shape.

Dependencies:
* T04.G3.01: Identify and match repeat box diagrams to actual code blocks
* T07.G3.01: Use a counted repeat loop




ID: T04.G3.02.01
Topic: T04 – Algorithm Patterns
Skill: Refactor repeated blocks into a loop
Description: Students take a script with 3-5 identical repeated blocks and refactor it into a loop with the correct repeat count. They verify the refactored code produces the same behavior as the original. Focus is on active transformation, not just identification.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks
* T07.G3.01: Use a counted repeat loop




ID: T04.G3.03
Topic: T04 – Algorithm Patterns
Skill: Match a "repeat N" loop to repeated behavior
Description: Students match a `repeat N` loop script (e.g., `repeat 4 { move 10 }`) to an animation or path with the same repeated behavior, treating it as a generic "N‑times pattern" that will later appear inside real T01/T07 projects.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks





ID: T04.G3.03.01
Topic: T04 – Algorithm Patterns
Skill: Predict loop output given initial state
Description: Students see a simple loop script with a starting variable value (e.g., "set x to 5, repeat 3 {change x by 2}") and predict the final value by tracing mentally. They show work: "Start: 5, After 1st: 7, After 2nd: 9, After 3rd: 11." Focus is on accurate mental simulation of loop execution.

Dependencies:
* T04.G3.03: Match a "repeat N" loop to repeated behavior





ID: T04.G3.04
Topic: T04 – Algorithm Patterns
Skill: Explain how custom blocks improve code readability
Description: Students compare code snippets before and after refactoring into custom blocks. They explain specific benefits: reduced duplication, clearer naming, and easier modification. Assessment: Given two versions of code, students identify which is more readable and explain why.

Dependencies:
* T04.G3.03: Match a "repeat N" loop to repeated behavior
* T11.G3.01: Use a pre-built custom block in a project





ID: T04.G3.05
Topic: T04 – Algorithm Patterns
Skill: Customize a template by changing repeated elements (small-scale)
Description: Students modify a simple template by adjusting small-scale elements (e.g., one loop's color pattern, repeat count, or individual sounds) while preserving the template structure. Focus is on localized, small-scale customization within a single loop or block sequence.

Dependencies:
* T04.G3.04: Explain how custom blocks improve code readability
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T04.G3.06
Topic: T04 – Algorithm Patterns
Skill: Fix a loop that repeats too many or too few times
Description: Students adjust the `repeat` count to match a target pattern or path in a small, self‑contained example, so they can later use the same adjustment skill inside larger T01 algorithms.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks





ID: T04.G3.07
Topic: T04 – Algorithm Patterns
Skill: Debug a loop where one action block is incorrect
Description: Students examine a loop or repeated sequence where one action block differs from the intended pattern and edit that block to fix the error. Focus is on identifying and correcting single-step pattern errors.

Dependencies:
* T04.G3.06: Fix a loop that repeats too many or too few times
* T07.G3.03: Build a forever loop for simple animation





ID: T04.G3.07.01
Topic: T04 – Algorithm Patterns
Skill: Debug a loop with off-by-one error
Description: Students examine a loop that produces slightly wrong output (e.g., draws 3 sides instead of 4, or moves 9 steps instead of 10). They identify whether the error is in the repeat count or the loop body and fix the off-by-one bug. Focus is on precise counting in loop control.

Dependencies:
* T04.G3.07: Debug a loop where one action block is incorrect





ID: T04.G3.08
Topic: T04 – Algorithm Patterns
Skill: Identify which code structure matches an algorithm description
Description: Students see simple algorithm descriptions (e.g., "check each item," "repeat an action") and identify which generic code structures (loop, conditional) match each description. This bridges pattern recognition from descriptions to code, focusing on loop and conditional patterns at the G3 level.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks
* T04.G3.01: Identify and match repeat box diagrams to actual code blocks
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence





ID: T04.G3.09
Topic: T04 – Algorithm Patterns
Skill: Label inner and outer patterns in nested visual structures
Description: Students examine VISUAL nested patterns (3 rows of 4 stars, 2 groups of 3 circles) and label which part is the "outer" pattern (rows/groups) and which is the "inner" pattern (items within each row/group). Students write labels like: "Outer: 3 rows, Inner: 4 stars per row." This prepares for nested loop code analysis. Assessment shows 3-4 visual patterns and students label outer/inner components for each.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks
* T07.G3.01: Use a counted repeat loop





ID: T04.G3.10
Topic: T04 – Algorithm Patterns
Skill: Implement a counter variable to track loop iterations
Description: Students create a variable, set it to 0, and increment it by 1 each time through a simple loop. They observe how the variable tracks the count and display it to see the progression (1, 2, 3...). This introduces the foundational concept of counters before pattern recognition.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.04: Display variable value on stage using the variable monitor




ID: T04.G3.11
Topic: T04 – Algorithm Patterns
Skill: Describe a pattern's purpose without showing the code
Description: Students examine code that uses a pattern (like a counting loop or bounce-on-edge conditional) and write or record a description of what the pattern DOES without mentioning the specific blocks. For example: "This pattern makes the sprite bounce back when it hits the wall" rather than "This uses an if-then with touching-edge." Focus is on explaining PURPOSE and BEHAVIOR, not syntax. Assessment: Given 3 code snippets, students write purpose descriptions that another student could use to identify the pattern.

Dependencies:
* T04.G3.04: Explain how custom blocks improve code readability
* T04.G3.08: Identify which code structure matches an algorithm description




ID: T04.G3.12
Topic: T04 – Algorithm Patterns
Skill: Build a pattern solution with a partner
Description: **Student task:** Work with a partner to build a simple pattern-based solution. One student identifies the pattern needed, the other implements it, then switch roles. **Scenario:** Given a problem like "make a sprite draw a square," partners discuss: "We need a repeat-4 pattern for the sides." Partner A identifies the pattern, Partner B codes it. Then reverse for a new problem. **Assessment:** Both students must contribute to discussion; teacher observes pair collaboration. Focus is on COLLABORATIVE problem decomposition and pattern selection.

Dependencies:
* T04.G3.02.01: Refactor repeated blocks into a loop
* T04.G3.06: Fix a loop that repeats too many or too few times







ID: T04.G4.01
Topic: T04 – Algorithm Patterns
Skill: Trace a loop that creates a visual pattern
Description: Students trace code that draws shapes or patterns and match it to one of several images.

Dependencies:
* T04.G3.02: Identify where a loop could replace repeated blocks
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T12.G3.01: Test and trace simple block-based scripts





ID: T04.G4.01.01
Topic: T04 – Algorithm Patterns
Skill: Identify problems that require tracking a count
Description: Students examine problem scenarios (like "count how many red items", "track number of jumps", "tally correct answers") and identify which problems need a counter variable to track a count, distinguishing these from problems that don't require counting. Focus is on problem analysis, not yet on code patterns.

Dependencies:
* T04.G3.10: Implement a counter variable to track loop iterations
* T04.G4.01: Trace a loop that creates a visual pattern





ID: T04.G4.01.02
Topic: T04 – Algorithm Patterns
Skill: Distinguish and label nested loop structures in simple code
Description: Students identify nested loops in simple code examples and label which is the outer loop and which is the inner loop, without yet analyzing what each controls. Focus is on recognizing the structural pattern of nesting before understanding the roles of each loop.

Dependencies:
* T04.G3.09: Analyze nested repetition in visual patterns
* T04.G4.01: Trace a loop that creates a visual pattern





ID: T04.G4.02
Topic: T04 – Algorithm Patterns
Skill: Analyze nested loop code structure (outer vs inner loop)
Description: Students read nested loop CODE and analyze which loop controls what aspect of the output (e.g., which controls rows vs columns in a grid pattern). Focus is on understanding code structure: identifying the outer loop, inner loop, and determining the role each plays in creating the pattern.

Dependencies:
* T04.G4.01.02: Distinguish and label nested loop structures in simple code
* T07.G3.01: Use a counted repeat loop
* T12.G3.01: Test and trace simple block-based scripts





ID: T04.G4.02.01
Topic: T04 – Algorithm Patterns
Skill: Trace nested loop output step by step
Description: Students trace through nested loop code and write down what happens at each step. Given code that creates a 3x4 grid, they record: "Outer loop 1: Inner draws 4 dots, move down. Outer loop 2: Inner draws 4 dots, move down..." They predict the final visual output by tracking both loop counters.

Dependencies:
* T04.G4.02: Analyze nested loop code structure (outer vs inner loop)





ID: T04.G4.03
Topic: T04 – Algorithm Patterns
Skill: Identify and classify conditional patterns that handle boundary cases
Description: Students identify code patterns like "bounce on edge" or "wrap around screen" as standard conditional patterns that handle boundary or edge cases. They classify these as boundary-handling patterns.

Dependencies:
* T04.G3.05: Customize a template by changing repeated elements (small-scale)
* T08.G3.04: Use a simple if in a script





ID: T04.G4.04
Topic: T04 – Algorithm Patterns
Skill: Identify template patterns in example projects
Description: Students examine 2-3 simple example projects and identify which elements form the reusable template pattern (the structure that stays the same) versus customization points (values that change). This bridges from creating templates (G3.04) to understanding how templates work as reusable patterns.

Dependencies:
* T04.G3.04: Explain how custom blocks improve code readability
* T04.G3.05: Customize a template by changing repeated elements (small-scale)





ID: T04.G4.05
Topic: T04 – Algorithm Patterns
Skill: Group code snippets that share the same algorithm pattern
Description: Students identify 2-3 code snippets that implement the same algorithm pattern (e.g., boundary-check-and-adjust, loop-and-count, test-and-respond) and select which snippets belong together based on their underlying logic structure.

Dependencies:
* T04.G3.08: Identify which code structure matches an algorithm description
* T12.G3.01: Test and trace simple block-based scripts





ID: T04.G4.05.01
Topic: T04 – Algorithm Patterns
Skill: Determine when a pattern approach is inappropriate
Description: Students examine problem scenarios and identify cases where applying a standard pattern would be inefficient or overly complex. They explain why a simpler, direct approach is better for some problems, developing critical judgment about pattern selection.

Dependencies:
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T04.G4.03: Identify and classify conditional patterns that handle boundary cases




ID: T04.G4.06
Topic: T04 – Algorithm Patterns
Skill: Select the appropriate pattern to solve a new problem
Description: Students see a new problem description and choose which known pattern (e.g., loop over list, counter pattern, conditional check) would help solve it. Focus is on pattern selection based on problem characteristics.

Dependencies:
* T04.G4.01: Trace a loop that creates a visual pattern
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T07.G3.01: Use a counted repeat loop





ID: T04.G4.06.01
Topic: T04 – Algorithm Patterns
Skill: Justify pattern selection with reasoning
Description: Students not only select a pattern to solve a problem but also write 2-3 sentences explaining why that pattern fits. They identify specific problem features (e.g., "need to check each item" → search pattern, "need to count matches" → counter pattern) that match pattern characteristics.

Dependencies:
* T04.G4.06: Select the appropriate pattern to solve a new problem





ID: T04.G4.07
Topic: T04 – Algorithm Patterns
Skill: Evaluate the benefits of reusing algorithm patterns
Description: Students answer multiple-choice questions distinguishing true benefits of reusing patterns (e.g., "less code to write," "fewer bugs," "easier to understand") from incorrect claims (e.g., "makes code run faster," "uses less memory"). Focus is on reasoning about code quality tradeoffs.

Dependencies:
* T04.G3.08: Identify which code structure matches an algorithm description
* T06.G2.03: Design a simple "if-then" game rule





ID: T04.G4.08
Topic: T04 – Algorithm Patterns
Skill: Use a template to create a customized project (project-level)
Description: Students start with a provided template project and modify multiple marked elements across different parts of the project (colors, sounds, repeat counts, sprite behaviors) to create their own version while preserving the template structure. Focus is on PROJECT-LEVEL customization affecting multiple elements throughout the project.

Dependencies:
* T04.G4.04: Identify template patterns in example projects





ID: T04.G4.09
Topic: T04 – Algorithm Patterns
Skill: Use loops to iterate through all items in a list
Description: Students write or complete code that uses a loop to process each item in a list one by one, understanding the basic pattern of list iteration that underlies many algorithm patterns.

Dependencies:
* T04.G4.01: Trace a loop that creates a visual pattern
* T07.G3.01: Use a counted repeat loop
* T10.G4.01: Use list blocks to add, remove, and access items




ID: T04.G4.09.01
Topic: T04 – Algorithm Patterns
Skill: Trace list iteration to predict final state
Description: Students trace through code that iterates over a list, tracking variable values at each step to predict the final output. They show intermediate states (e.g., "After item 1: count=1, total=5; After item 2: count=2, total=12"). Focus is on detailed step-by-step tracing.

Dependencies:
* T04.G4.09: Use loops to iterate through all items in a list
* T04.G4.01: Trace a loop that creates a visual pattern





ID: T04.G4.10
Topic: T04 – Algorithm Patterns
Skill: Critique a peer's pattern choice and suggest improvements
Description: **Student task:** Review a partner's code that uses a pattern and provide constructive feedback. Identify: (1) Is the pattern correct for the problem? (2) Is it implemented correctly? (3) Could it be improved? **Scenario:** Partner A shows code using a repeat loop to draw 5 squares. Partner B reviews: "The pattern is good, but you could add a variable to change the size each time." **Assessment:** Teacher evaluates feedback quality using rubric: identifies pattern correctly, gives specific suggestion, explains reasoning. Focus is on CONSTRUCTIVE CRITIQUE skills.

Dependencies:
* T04.G4.06.01: Justify pattern selection with reasoning
* T04.G3.12: Build a pattern solution with a partner




ID: T04.G4.10.01
Topic: T04 – Algorithm Patterns
Skill: Debug nested loop bugs with tracing
Description: Students examine nested loop code that produces incorrect output (e.g., draws wrong number of rows or columns, or items appear in wrong positions). They trace the outer and inner loop counters step-by-step to identify where the bug occurs. They fix the bug and verify the output matches expectations. Focus is on systematic debugging of nested structures.

Dependencies:
* T04.G4.02.01: Trace nested loop output step by step
* T04.G3.07.01: Debug a loop with off-by-one error




ID: T04.G4.11
Topic: T04 – Algorithm Patterns
Skill: Recognize algorithm patterns in apps and games
Description: **Student task:** Analyze familiar apps or games and identify the algorithm patterns they use. **Scenario:** Students examine: a timer app (uses counter pattern), a shopping list (uses add-to-list pattern), a score tracker in a game (uses accumulator pattern), a "find matching cards" game (uses search pattern). **Assessment:** Students match 4-5 app features to their underlying algorithm patterns and explain why. Focus is on connecting REAL-WORLD applications to pattern knowledge.

Dependencies:
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T04.G3.11: Describe a pattern's purpose without showing the code





ID: T04.G5.01
Topic: T04 – Algorithm Patterns
Skill: Identify and classify counter update patterns in code
Description: Students identify code where a variable counts events (`set count to 0; change count by 1`) across different contexts and classify them as counter patterns.

Dependencies:
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T06.G5.01: Identify standard event patterns in a small game





ID: T04.G5.01.01
Topic: T04 – Algorithm Patterns
Skill: Implement a basic accumulator pattern
Description: Students create code that accumulates a running total by adding values in a loop (set total to 0, then add each item's value to the total). Focus is on implementing the accumulator pattern from scratch before recognizing it in others' code.

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T04.G5.02
Topic: T04 – Algorithm Patterns
Skill: Identify accumulator patterns in code (sum/concatenate)
Description: Students identify code where a variable accumulates totals or builds strings, classifying these as accumulator patterns.

Dependencies:
* T04.G5.01.01: Implement a basic accumulator pattern
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T04.G5.02.01
Topic: T04 – Algorithm Patterns
Skill: Compare counter and accumulator patterns and choose appropriately
Description: Students examine problems and scenarios to determine whether a counter pattern (count occurrences) or accumulator pattern (sum values) is more appropriate, understanding the distinction between counting items versus adding their values.

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T04.G5.02.02
Topic: T04 – Algorithm Patterns
Skill: Implement accumulator with conditional inclusion
Description: Students create code that accumulates values only when a condition is met (e.g., "sum only the even numbers" or "total only scores above 50"). They combine the accumulator pattern with conditional logic to selectively add values. Focus is on integrating two pattern components.

Dependencies:
* T04.G5.02.01: Compare counter and accumulator patterns and choose appropriately
* T04.G5.01.01: Implement a basic accumulator pattern





ID: T04.G5.03
Topic: T04 – Algorithm Patterns
Skill: Identify linear search patterns in code
Description: Students identify the "look at each item and compare" pattern in code that searches for a match. Focus is on the search pattern: iterating through items to find one that matches a condition.

Dependencies:
* T04.G4.09: Use loops to iterate through all items in a list
* T08.G3.04: Use a simple if in a script
* T10.G5.01: Understand table structure (rows, columns, cells)


ID: T04.G5.03.02
Topic: T04 – Algorithm Patterns
Skill: Implement a linear search pattern with conditional matching
Description: Students write code that implements the linear search pattern: iterate through a list, compare each item to a target condition, and stop when a match is found. Focus is on implementing the pattern from scratch.

Dependencies:
* T04.G5.03: Identify linear search patterns in code
* T04.G4.09: Use loops to iterate through all items in a list




ID: T04.G5.03.01
Topic: T04 – Algorithm Patterns
Skill: Identify the filter-collect pattern structure
Description: Students identify code that implements the filter-collect pattern: loop through items, test each against a condition (filter), and add matching items to a result list (collect). They understand this extends search (which finds ONE match) to collect ALL matches.

Dependencies:
* T04.G5.03: Identify linear search patterns in code
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T08.G3.04: Use a simple if in a script





ID: T04.G5.03.03
Topic: T04 – Algorithm Patterns
Skill: Implement early-exit pattern in search
Description: Students modify a linear search to stop as soon as a match is found, using a flag variable or "stop this script" block. They explain why early-exit improves efficiency compared to always checking every item. Assessment: Given a search that checks all items, students refactor it to exit early when the target is found.

Dependencies:
* T04.G5.03.02: Implement a linear search pattern with conditional matching
* T08.G4.03: Use nested conditionals (if inside if)




ID: T04.G5.03.04
Topic: T04 – Algorithm Patterns
Skill: Compare search efficiency with and without early-exit
Description: Students run two versions of search code (with and without early-exit) on lists of different sizes and compare how many comparisons each makes. They explain when early-exit provides the biggest benefit (target found early) vs minimal benefit (target at end or not found).

Dependencies:
* T04.G5.03.03: Implement early-exit pattern in search
* T04.G5.05: Compare solutions that use a pattern vs those that don't




ID: T04.G5.04
Topic: T04 – Algorithm Patterns
Skill: Apply the filter-collect pattern to gather matching items
Description: Students implement or complete code that uses the filter-collect pattern: loop through items, test each against criteria, and add matching items to a new list. They practice writing the pattern from scratch or completing partial implementations.

Dependencies:
* T04.G5.03.01: Recognize the filter-collect pattern structure
* T07.G5.01: Simulate repeated experiments with a loop
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T04.G5.04.01
Topic: T04 – Algorithm Patterns
Skill: Identify map/transform pattern structure
Description: Students identify the map/transform pattern in code: loop through a list and apply a transformation to each item, creating a new list with transformed values. Examples include doubling all numbers, converting strings to uppercase, or scaling sprite sizes. Students distinguish map (transform each item) from filter (select some items).

Dependencies:
* T04.G5.04: Apply the filter-collect pattern to gather matching items
* T04.G4.09: Use loops to iterate through all items in a list




ID: T04.G5.04.02
Topic: T04 – Algorithm Patterns
Skill: Debug filter pattern with incorrect condition
Description: Students examine filter code that produces wrong results (e.g., includes items that shouldn't match, or misses valid items). They trace through the condition logic to identify the bug, fix the condition, and verify with test cases. Focus is on condition debugging in filter patterns.

Dependencies:
* T04.G5.04.01: Identify map/transform pattern structure
* T04.G5.04: Apply the filter-collect pattern to gather matching items





ID: T04.G5.05
Topic: T04 – Algorithm Patterns
Skill: Compare solutions that use a pattern vs those that don't
Description: Students compare two snippets solving the same task, one using a standard pattern (loop + counter) and one using ad‑hoc code, and choose which is better and why.

Dependencies:
* T04.G4.06: Select the appropriate pattern to solve a new problem
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T07.G5.01: Simulate repeated experiments with a loop





ID: T04.G5.06
Topic: T04 – Algorithm Patterns
Skill: Identify changeable vs fixed parts in a template
Description: Students look at a simple template project (e.g., a basic animation or greeting card) and mark which parts are placeholders (meant to be changed, like colors or messages) vs structural elements (meant to stay the same, like loop structure or event handlers). Focus is on binary classification: changeable or fixed.

Dependencies:
* T04.G4.08: Use a template to create a customized project (project-level)
* T04.G4.03: Identify and classify conditional patterns that handle boundary cases





ID: T04.G5.07
Topic: T04 – Algorithm Patterns
Skill: Apply a counter pattern to solve a counting problem
Description: Students implement code using the counter pattern (set count to 0, change count by 1 when condition met) to solve a simple counting task like tallying matching items.

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T04.G5.07.01
Topic: T04 – Algorithm Patterns
Skill: Identify where a hard-coded value could become a parameter
Description: Students examine custom blocks with hard-coded values and identify which values would benefit from becoming parameters to make the block more reusable. They explain why making specific values into parameters improves flexibility and reusability.

Dependencies:
* T04.G5.06: Identify changeable vs fixed parts in a template
* T04.G4.04: Identify template patterns in example projects





ID: T04.G5.08
Topic: T04 – Algorithm Patterns
Skill: Create a custom block with one parameter for reusable patterns
Description: Students create a custom block that takes one parameter, replacing a hard-coded value with the parameter. They understand how parameters make blocks reusable with different values (e.g., a "draw square" block that takes size as a parameter).

Dependencies:
* T04.G5.07.01: Identify where a hard-coded value could become a parameter
* T11.G4.10: Define a custom block with one parameter





ID: T04.G5.09
Topic: T04 – Algorithm Patterns
Skill: Document why a specific pattern was chosen
Description: **Student task:** After implementing a pattern-based solution, write documentation explaining WHY you chose that specific pattern. **Scenario:** Student builds a "count red items" solution using counter pattern. Documentation: "I used the counter pattern because the problem asks 'how many' which means counting. The accumulator pattern wouldn't work because I'm counting occurrences, not summing values." **Assessment:** Documentation must (1) name the pattern, (2) explain why it fits the problem, (3) mention at least one alternative that wouldn't work. Focus is on JUSTIFYING design decisions.

Dependencies:
* T04.G5.02.01: Compare counter and accumulator patterns and choose appropriately
* T04.G4.06.01: Justify pattern selection with reasoning




ID: T04.G5.10
Topic: T04 – Algorithm Patterns
Skill: Merge two partial pattern implementations
Description: **Student task:** Given two incomplete pattern implementations that solve different parts of a problem, combine them into a complete solution. **Scenario:** Part A: Code that filters items by color (filter pattern). Part B: Code that counts items (counter pattern). Problem: "Count only red items." Students merge A and B, connecting the filter output to the counter input. **Assessment:** Combined code must work correctly; students explain how the patterns connect. Focus is on PATTERN COMPOSITION skills.

Dependencies:
* T04.G5.04: Apply the filter-collect pattern to gather matching items
* T04.G5.07: Apply a counter pattern to solve a counting problem




ID: T04.G5.11
Topic: T04 – Algorithm Patterns
Skill: Use AI to explain unfamiliar patterns
Description: **Student task:** When encountering unfamiliar code patterns, use CreatiCode's AI assistant (XO) to get explanations. Practice asking good questions like "What pattern is this code using?" and "Why would someone use this pattern here?" **Scenario:** Students see code they don't recognize (e.g., a toggle pattern or clamp-value pattern). They ask the AI: "What does this code pattern do?" Then verify the AI's explanation by tracing the code themselves. **Assessment:** Students must (1) ask a clear question to AI, (2) verify the answer by tracing, (3) summarize what they learned. Focus is on AI-ASSISTED LEARNING with verification.

Dependencies:
* T04.G5.05: Compare solutions that use a pattern vs those that don't
* T04.G4.11: Recognize algorithm patterns in apps and games






ID: T04.G6.01
Topic: T04 – Algorithm Patterns
Skill: Group snippets by underlying algorithm pattern
Description: Students classify 5+ diverse code snippets into groups based on their underlying algorithm pattern (counter, accumulator, search, filter), distinguishing between similar-looking but functionally different patterns.

Dependencies:
* T04.G4.05: Group code snippets that share the same algorithm pattern
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)





ID: T04.G6.02
Topic: T04 – Algorithm Patterns
Skill: Identify pattern variants that look different but behave the same
Description: Students identify code snippets that use different syntax or structure but achieve the same result—for example, counting with a `repeat N` loop versus iterating through a list, or accumulating with `set` + `change` versus a single `set to sum` block.

Dependencies:
* T04.G4.05: Group code snippets that share the same algorithm pattern





ID: T04.G6.02.01
Topic: T04 – Algorithm Patterns
Skill: Apply filter pattern with two AND criteria
Description: Students filter a list using two conditions that must both be true (AND logic). For example, "find items that are both red AND large" or "select sprites that are both moving AND visible." Focus is on combining exactly two conditions with AND.

Dependencies:
* T04.G5.04: Apply the filter-collect pattern to gather matching items
* T08.G5.02: Use a simple if in a script





ID: T04.G6.02.02
Topic: T04 – Algorithm Patterns
Skill: Apply map/transform pattern to create transformed lists
Description: Students implement the map/transform pattern: loop through a list, apply a transformation to each item, and build a new list with the results. Examples: doubling all scores, adding prefixes to names, scaling coordinates. Assessment: Given a list and transformation rule, students create the mapped output list.

Dependencies:
* T04.G5.04.01: Identify map/transform pattern structure
* T04.G6.02.01: Apply filter pattern with two AND criteria




ID: T04.G6.03.01
Topic: T04 – Algorithm Patterns
Skill: Apply filter pattern with OR criteria
Description: Students filter a list using two conditions where either can be true (OR logic). For example, "find items that are red OR large" or "select sprites that are moving OR visible." Focus is on combining two conditions with OR to broaden matching criteria.

Dependencies:
* T04.G6.02.01: Apply filter pattern with two AND criteria
* T08.G5.02: Use a simple if in a script





ID: T04.G6.03.02
Topic: T04 – Algorithm Patterns
Skill: Apply filter pattern combining AND and OR logic
Description: Students extend the filter pattern to handle complex multi-criteria logic using nested conditions with both AND and OR operators. They combine multiple conditions to select items matching complex requirements (e.g., "items that are (red AND large) OR (blue AND small)").

Dependencies:
* T04.G6.03.01: Apply filter pattern with OR criteria
* T04.G6.01: Group snippets by underlying algorithm pattern





ID: T04.G6.04
Topic: T04 – Algorithm Patterns
Skill: Refactor repeated code into a custom block with multiple parameters
Description: Students refactor repeated code sequences into a parameterized custom block that can be reused with different values. They identify multiple varying elements, add parameters to the custom block (e.g., number of steps, color, speed), and replace repeated code with calls to the custom block.

Dependencies:
* T04.G5.08: Create a custom block with one parameter for reusable patterns
* T11.G5.01: Define a custom block with multiple parameters
* T08.G5.02: Use a simple if in a script




ID: T04.G6.04.01
Topic: T04 – Algorithm Patterns
Skill: Debug a parameterized custom block
Description: Students examine a custom block with parameters that produces incorrect output and identify whether the bug is in the block definition (wrong formula, missing condition) or in the call site (wrong parameter values). They fix the bug and verify the block works correctly with multiple test cases.

Dependencies:
* T04.G6.04: Refactor repeated code into a custom block with multiple parameters
* T04.G4.05.01: Determine when a pattern approach is inappropriate




ID: T04.G6.05
Topic: T04 – Algorithm Patterns
Skill: Identify and categorize customization points in a complex template
Description: Students inspect a complex template project (quiz, platformer, etc.) and identify which elements are customization points versus structural code. They categorize each customization point by what aspect it controls (appearance, behavior, difficulty, content, etc.).

Dependencies:
* T04.G5.06: Identify changeable vs fixed parts in a template





ID: T04.G6.05.01
Topic: T04 – Algorithm Patterns
Skill: Analyze safe modification constraints for template parameters
Description: Students examine customization points in a template and determine: what values are safe to change, what ranges are acceptable (e.g., speed between 1-10), and which changes would break the template's functionality. They explain the constraints and reasoning for each parameter.

Dependencies:
* T04.G6.05: Identify and categorize customization points in a complex template





ID: T04.G6.06
Topic: T04 – Algorithm Patterns
Skill: Compare two pattern‑based solutions for efficiency and code clarity
Description: Students compare two pattern-based solutions and select which is better based on efficiency (fewer operations, faster execution) and clarity (easier to read, fewer lines of code). Example: comparing nested loops versus a single loop with index math.

Dependencies:
* T04.G5.05: Compare solutions that use a pattern vs those that don't
* T07.G5.01: Use a counted repeat loop
* T08.G5.02: Use a simple if in a script





ID: T04.G6.07
Topic: T04 – Algorithm Patterns
Skill: Implement a pattern-based solution from a description
Description: Students read a problem description that fits a standard pattern (counter, accumulator, or search) and implement a solution using that pattern.

Dependencies:
* T04.G5.07: Apply a counter pattern to solve a counting problem
* T04.G6.01: Group snippets by underlying algorithm pattern





ID: T04.G6.07.01
Topic: T04 – Algorithm Patterns
Skill: Decompose a problem into pattern components
Description: Students analyze a multi-step problem and break it down into distinct pattern components. Given "find the average of passing scores," they identify: (1) filter pattern to get passing scores, (2) accumulator to sum them, (3) counter to count them, (4) division for average. They create a component diagram.

Dependencies:
* T04.G6.07: Implement a pattern-based solution from a description
* T04.G6.01: Group snippets by underlying algorithm pattern





ID: T04.G6.08
Topic: T04 – Algorithm Patterns
Skill: Apply 2D indexing patterns to access grid elements
Description: Students work with grid or table data structures and use nested loops or 2D indexing patterns (row, column) to access, modify, or analyze grid elements systematically.

Dependencies:
* T04.G4.02: Analyze nested loop code structure (outer vs inner loop)
* T04.G6.07: Implement a pattern-based solution from a description





ID: T04.G6.09
Topic: T04 – Algorithm Patterns
Skill: Verify that code matches the intended pattern
Description: **Student task:** Given code and a description of what pattern it SHOULD use, verify if the implementation matches. **Scenario:** Description: "This code should use the filter pattern to find all scores above 80." Code: [shows code that counts scores instead of filtering]. Students identify: "This uses counter pattern, not filter pattern. It should collect matching items, not just count them." **Assessment:** Students must (1) identify what pattern the code actually uses, (2) explain the mismatch, (3) describe how to fix it. Focus is on CODE REVIEW and VERIFICATION skills.

Dependencies:
* T04.G6.02: Identify pattern variants that look different but behave the same
* T04.G5.09: Document why a specific pattern was chosen




ID: T04.G6.10
Topic: T04 – Algorithm Patterns
Skill: Analyze patterns in data processing pipelines
Description: **Student task:** Analyze a multi-step data processing flow and identify the pattern used at each stage. **Scenario:** Given a pipeline: "Load scores from table → Filter scores above 50 → Calculate average → Display result." Students label: Stage 1 (data access), Stage 2 (filter pattern), Stage 3 (accumulator + counter for average), Stage 4 (output). **Assessment:** Students correctly identify patterns at each stage and explain how data flows between them. Focus is on PIPELINE ANALYSIS for real-world data processing.

Dependencies:
* T04.G6.07.01: Decompose a problem into pattern components
* T04.G6.02.02: Apply map/transform pattern to create transformed lists




ID: T04.G6.11
Topic: T04 – Algorithm Patterns
Skill: Evaluate AI suggestions for pattern improvements
Description: **Student task:** Use AI assistant to get suggestions for improving pattern-based code, then critically evaluate those suggestions. **Scenario:** Student shows code using a search pattern that checks every item. AI suggests: "You could use early-exit to stop when found." Student evaluates: "Good suggestion because it makes the search faster when item is found early." OR AI suggests something incorrect and student identifies the error. **Assessment:** Students must (1) ask AI for improvement suggestions, (2) evaluate each suggestion's validity, (3) explain why they accept or reject it. Focus is on CRITICAL EVALUATION of AI assistance.

Dependencies:
* T04.G5.11: Use AI to explain unfamiliar patterns
* T04.G6.06: Compare two pattern-based solutions for efficiency and code clarity






ID: T04.G7.01
Topic: T04 – Algorithm Patterns
Skill: Identify the main loop patterns in a simulation or game
Description: Students analyze a game/simulation and identify loops like "update each frame," "process each object," "check each pair."

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T07.G5.01: Use a counted repeat loop
* T08.G5.02: Use a simple if in a script





ID: T04.G7.02
Topic: T04 – Algorithm Patterns
Skill: Identify data structure patterns (lists, grids) in use
Description: Students recognize when code uses a list or grid pattern (e.g., iterating over a list of enemies or cells).

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T08.G5.02: Use a simple if in a script
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T04.G7.02.01
Topic: T04 – Algorithm Patterns
Skill: Identify state machine patterns in game code
Description: Students identify state machine patterns in game code where a variable tracks the current state (e.g., "idle", "running", "jumping") and conditionals determine behavior and state transitions. They trace how events trigger state changes and explain the role of each state. Assessment: Given game code with states, students label the states, transitions, and triggering events.

Dependencies:
* T04.G7.02: Identify data structure patterns (lists, grids) in use
* T04.G7.01: Identify the main loop patterns in a simulation or game
* T13.G6.01: Track game state with variables




ID: T04.G7.03
Topic: T04 – Algorithm Patterns
Skill: Identify problems that require multiple patterns
Description: Students examine problem descriptions and identify which ones need more than one algorithm pattern (like counter + filter, or search + accumulator).

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T04.G6.01: Group snippets by underlying algorithm pattern
* T08.G5.02: Use a simple if in a script





ID: T04.G7.04
Topic: T04 – Algorithm Patterns
Skill: Outline a solution combining two patterns
Description: Students create a written or block-diagram outline showing how two patterns work together to solve a problem.

Dependencies:
* T04.G7.03: Identify problems that require multiple patterns




ID: T04.G7.04.01
Topic: T04 – Algorithm Patterns
Skill: Implement pattern composition with shared variables
Description: Students implement a solution where two patterns (e.g., filter then accumulate) share variables to pass data between them. They design the data flow: one pattern produces output that becomes input for the next pattern. Focus is on variable coordination between patterns.

Dependencies:
* T04.G7.04: Outline a solution combining two patterns
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)




ID: T04.G7.05
Topic: T04 – Algorithm Patterns
Skill: Implement a combined pattern solution
Description: Students code a solution that uses two patterns together (e.g., loop through list with counter + filter matching items).

Dependencies:
* T04.G7.04: Outline a solution combining two patterns
* T06.G5.01: Identify standard event patterns in a small game
* T09.G5.01: Use multiple variables together in a single expression
* T07.G5.01: Simulate repeated experiments with a loop





ID: T04.G7.05.01
Topic: T04 – Algorithm Patterns
Skill: Debug combined pattern with data flow error
Description: Students debug code where two patterns are combined but data passes incorrectly between them (e.g., filter outputs to wrong variable, accumulator reads wrong list). They trace data flow between pattern stages to identify where the connection breaks and fix the variable references.

Dependencies:
* T04.G7.05: Implement a combined pattern solution
* T04.G7.04.01: Implement pattern composition with shared variables





ID: T04.G7.06
Topic: T04 – Algorithm Patterns
Skill: Trace a composite pattern and identify each pattern used
Description: Students trace code that combines multiple patterns and label which parts use counter, accumulator, search, or filter patterns.

Dependencies:
* T04.G7.03: Identify problems that require multiple patterns
* T06.G5.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T04.G7.07
Topic: T04 – Algorithm Patterns
Skill: Explain the role of each pattern in a composite solution
Description: Students write or select explanations describing what each pattern contributes to the overall solution.

Dependencies:
* T04.G7.06: Trace a composite pattern and identify each pattern used





ID: T04.G7.08.01
Topic: T04 – Algorithm Patterns
Skill: Identify initialization errors in algorithm patterns
Description: Students examine code examples with initialization problems such as using a counter without setting it to 0 first, or using an accumulator without resetting it. They identify why the missing initialization causes problems and explain how to fix it.

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T04.G7.03: Identify problems that require multiple patterns





ID: T04.G7.08.02
Topic: T04 – Algorithm Patterns
Skill: Identify termination errors in algorithm patterns
Description: Students examine code examples with termination problems such as searching without a found flag to stop the search, or infinite loops that never exit. They identify why each example fails to terminate correctly and suggest fixes.

Dependencies:
* T04.G7.08.01: Identify initialization errors in algorithm patterns
* T04.G5.03: Identify linear search patterns in code





ID: T04.G7.08.03
Topic: T04 – Algorithm Patterns
Skill: Identify pattern mismatch errors
Description: Students examine problem descriptions and code solutions, identifying cases where the wrong pattern was applied (like using a counter when an accumulator is needed, or using search when filter-collect is appropriate). They explain why the pattern doesn't match the problem and suggest the correct pattern.

Dependencies:
* T04.G7.08.01: Identify initialization errors in algorithm patterns
* T04.G5.02.01: Compare counter and accumulator patterns and choose appropriately





ID: T04.G7.09
Topic: T04 – Algorithm Patterns
Skill: Simplify code by merging repeated patterns
Description: Students refactor code that has repeated pattern blocks into a more compact form (e.g., use a function applied twice).

Dependencies:
* T04.G6.02: Identify pattern variants that look different but behave the same
* T07.G5.01: Simulate repeated experiments with a loop
* T11.G5.01: Define a custom block with multiple parameters





ID: T04.G7.10
Topic: T04 – Algorithm Patterns
Skill: Compare pattern‑based implementations for long‑term maintainability
Description: Students compare two implementations and decide which will be easier to modify or extend later, considering factors like: where changes would need to be made, how many places would need updating, and whether the pattern isolates what might change.

Dependencies:
* T04.G6.06: Compare two pattern‑based solutions for efficiency and clarity





ID: T04.G7.11
Topic: T04 – Algorithm Patterns
Skill: Identify and classify utility helper patterns in code
Description: Students identify common utility patterns like clamp-value (keep number in range), random-choice (pick from list), and toggle (flip between two states). Focus is on recognizing these as reusable helpers distinct from algorithm patterns like search, counter, and accumulator.

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T04.G5.01: Identify and classify counter update patterns in code





ID: T04.G7.12
Topic: T04 – Algorithm Patterns
Skill: Evaluate when AI-generated code matches standard patterns
Description: Students examine code snippets that could be human-written or AI-generated and identify whether they follow standard algorithm patterns. They evaluate: Does this code use a recognizable pattern? Is it correctly implemented? Would a human write it differently? Focus is on pattern recognition as a code review skill.

Dependencies:
* T04.G7.11: Identify and classify utility helper patterns in code
* T04.G6.02: Identify pattern variants that look different but behave the same





ID: T04.G7.13
Topic: T04 – Algorithm Patterns
Skill: Present pattern trade-offs to stakeholders
Description: **Student task:** Prepare and deliver a brief presentation explaining pattern choices to non-technical stakeholders (classmates, teachers). **Scenario:** Student presents: "We chose the filter-then-count pattern instead of checking each item individually. This makes our code easier to change if requirements change, and it's what professional programmers do." **Assessment:** Presentation must (1) explain what the pattern does in non-technical terms, (2) describe the trade-off (why this pattern instead of alternatives), (3) answer follow-up questions. Focus is on COMMUNICATING technical decisions.

Dependencies:
* T04.G7.07: Explain the role of each pattern in a composite solution
* T04.G7.10: Compare pattern-based implementations for long-term maintainability




ID: T04.G7.14
Topic: T04 – Algorithm Patterns
Skill: Design composite patterns as a team
Description: **Student task:** Work in a team of 3-4 to design a multi-pattern solution. Each team member takes responsibility for one pattern component. **Scenario:** Problem: "Build a quiz game that tracks scores and shows high scores." Team divides: Member A (accumulator for scores), Member B (filter for high scores), Member C (search for current player), Member D (state machine for game flow). Team coordinates how patterns connect. **Assessment:** Team produces working solution where each member can explain their pattern and how it connects to others. Focus is on COLLABORATIVE DESIGN at scale.

Dependencies:
* T04.G7.05: Implement a combined pattern solution
* T04.G6.09: Verify that code matches the intended pattern






ID: T04.G8.00
Topic: T04 – Algorithm Patterns
Skill: Distinguish between algorithm patterns and utility patterns
Description: Students examine code patterns and classify them as either algorithm patterns (solving computational problems like search, count, accumulate) or utility patterns (helper functions like clamp-value, random-choice, state-update). They understand that algorithm patterns focus on problem-solving logic while utility patterns provide reusable helper functionality.

Dependencies:
* T04.G7.11: Identify and classify utility helper patterns in code
* T04.G7.01: Identify the main loop patterns in a simulation or game
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column

* T13.G6.01: Track game state with variables





ID: T04.G8.01
Topic: T04 – Algorithm Patterns
Skill: Identify and classify reusable patterns in a code library
Description: Students inspect a small library of utility blocks and identify familiar reusable patterns such as: clamp-value (keep number in range), random-choice (pick from options), and state-update (change state based on input).

Dependencies:
* T04.G8.00: Distinguish between algorithm patterns and utility patterns
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column

* T13.G6.01: Track game state with variables





ID: T04.G8.01.01
Topic: T04 – Algorithm Patterns
Skill: Identify and trace pipeline patterns
Description: Students identify pipeline patterns where data flows through multiple processing stages (e.g., load → filter → transform → display). They trace how data changes at each stage and explain the purpose of each step. Assessment: Given a multi-stage processing flow, students label each stage's function and predict intermediate outputs.

Dependencies:
* T04.G8.01: Identify and classify reusable patterns in a code library
* T04.G6.02.02: Apply map/transform pattern to create transformed lists




ID: T04.G8.02
Topic: T04 – Algorithm Patterns
Skill: Adapt a library function to a new context
Description: Students take an existing utility block and adapt parameters or logic to a new but related use. They identify which parts of the block can be modified for the new context while preserving the core pattern logic. Assessment: Given a utility block and new requirements, students modify the block and explain their changes.

Dependencies:
* T04.G8.01: Identify and classify reusable patterns in a code library
* T04.G6.04: Refactor repeated code into a custom block with multiple parameters




ID: T04.G8.02.01
Topic: T04 – Algorithm Patterns
Skill: Implement a solution using library patterns
Description: Students write a complete solution that uses multiple library patterns together. They select appropriate patterns from a library, compose them into a working solution, and verify the solution handles edge cases correctly.

Dependencies:
* T04.G8.02: Adapt a library function to a new context
* T04.G7.05: Implement a combined pattern solution





ID: T04.G8.03
Topic: T04 – Algorithm Patterns
Skill: Choose between alternative patterns for a problem
Description: Students evaluate several candidate approaches (e.g., polling vs event‑driven; nested loops vs index lists) and choose which pattern fits given constraints.

Dependencies:
* T04.G7.01: Identify the main loop patterns in a simulation or game
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T06.G6.02: Identify parallel vs sequential event behaviors
* T08.G6.01: Use conditionals in physics simulations





ID: T04.G8.03.01
Topic: T04 – Algorithm Patterns
Skill: Evaluate pattern scalability for large datasets
Description: Students analyze how different pattern choices scale with data size. Given two solutions (e.g., nested loops O(n²) vs hash lookup O(n)), they predict which performs better with 10, 100, and 1000 items. They justify pattern selection based on expected data volume and performance requirements.

Dependencies:
* T04.G8.03: Choose between alternative patterns for a problem
* T04.G6.06: Compare two pattern-based solutions for efficiency and code clarity





ID: T04.G8.04
Topic: T04 – Algorithm Patterns
Skill: Analyze tradeoffs in using a standard pattern vs custom code
Description: Students reason about pros/cons of relying on a standard pattern or library vs writing one‑off code.

Dependencies:
* T04.G7.10: Compare pattern‑based implementations for long‑term maintainability
* T06.G6.01: Trace event execution paths in a multi‑event program
* T09.G6.01: Model real-world quantities using variables and formulas





ID: T04.G8.05
Topic: T04 – Algorithm Patterns
Skill: Complete a "pattern card" describing a reusable solution
Description: Students fill in a structured pattern card template with four fields: (1) pattern name, (2) problem it solves, (3) solution structure using blocks, and (4) example use case. Assessment checks completeness and accuracy of each field.

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern





ID: T04.G8.06
Topic: T04 – Algorithm Patterns
Skill: Match pattern usage instructions to project scenarios
Description: Students match structured pattern-usage instructions (identifying what to customize, what to keep the same, and common pitfalls) to specific project scenarios where the pattern would apply.

Dependencies:
* T04.G8.05: Complete a "pattern card" describing a reusable solution
* T10.G6.01: Sort a table by a column



ID: T04.G8.07
Topic: T04 – Algorithm Patterns
Skill: Design a pattern-based solution architecture for a complex problem
Description: Students decompose a complex problem (e.g., multiplayer game score tracking, data visualization dashboard) into components, identify which algorithm patterns apply to each component, and create a design document showing how patterns connect. Assessment: Students create a visual diagram showing 3+ patterns and their interactions.

Dependencies:
* T04.G8.06: Match pattern usage instructions to project scenarios
* T04.G7.05: Implement a combined pattern solution




ID: T04.G8.08
Topic: T04 – Algorithm Patterns
Skill: Refactor legacy code to use standard patterns
Description: Students examine existing code that uses ad-hoc solutions and refactor it to use standard algorithm patterns (counter, accumulator, filter, map). They explain how the refactored version is more readable, maintainable, and testable. Assessment: Given messy code, students identify the pattern it approximates and rewrite it cleanly.

Dependencies:
* T04.G8.04: Analyze tradeoffs in using a standard pattern vs custom code
* T04.G7.09: Simplify code by merging repeated patterns




ID: T04.G8.09
Topic: T04 – Algorithm Patterns
Skill: Debug complex multi-pattern algorithm errors
Description: Students debug code that combines 3+ patterns where the bug could be in any pattern or in the interaction between patterns. They use systematic debugging: isolate each pattern, test independently, then test interactions. They document the debugging process and explain the root cause.

Dependencies:
* T04.G8.08: Refactor legacy code to use standard patterns
* T04.G7.08.01: Identify initialization errors in algorithm patterns
* T04.G7.08.03: Identify pattern mismatch errors




ID: T04.G8.10
Topic: T04 – Algorithm Patterns
Skill: Implement reduce pattern to aggregate data
Description: Students implement the reduce pattern: iterate through a collection, combining elements into a single result using an accumulator and a combining function. Examples: finding max/min, joining strings, computing product. They distinguish reduce from map (single output vs list output) and filter (all items processed vs some selected).

Dependencies:
* T04.G8.01.01: Identify and trace pipeline patterns
* T04.G6.02.02: Apply map/transform pattern to create transformed lists




ID: T04.G8.11
Topic: T04 – Algorithm Patterns
Skill: Trace and implement recursive patterns
Description: Students trace recursive algorithms (factorial, countdown, tree traversal) by tracking the call stack and return values. They implement simple recursive patterns with clear base cases and recursive steps. They compare recursive vs iterative solutions for the same problem.

Dependencies:
* T04.G8.01.01: Identify and trace pipeline patterns
* T04.G7.08.02: Identify termination errors in algorithm patterns




ID: T04.G8.12
Topic: T04 – Algorithm Patterns
Skill: Design AI data processing pipelines using CreatiCode AI blocks
Description: Students design multi-stage data processing pipelines using CreatiCode AI blocks: get AI response → parse JSON → extract fields → transform data → display results. They handle AI response formats (text, lists, structured data) and implement error handling for failed requests.

Dependencies:
* T04.G8.01.01: Identify and trace pipeline patterns
* T04.G8.07: Design pattern-based solution architecture for complex problems




ID: T04.G8.13
Topic: T04 – Algorithm Patterns
Skill: Implement real-time sensor data patterns (hand/body tracking)
Description: Students implement patterns for processing real-time sensor data from CreatiCode hand/body tracking blocks. They use table variables to store landmark positions, implement smoothing patterns (averaging recent values), and create gesture recognition patterns (detecting specific hand shapes or movements).

Dependencies:
* T04.G8.12: Design AI data processing pipelines using CreatiCode AI blocks
* T04.G6.08: Apply 2D indexing patterns to access grid elements




ID: T04.G8.14
Topic: T04 – Algorithm Patterns
Skill: Analyze algorithm efficiency using Big-O reasoning
Description: Students analyze code to determine if it runs in O(1), O(n), O(n²) time based on loop structure. They predict how execution time changes as input size grows (10 items vs 100 items vs 1000 items). They identify which pattern choice affects efficiency (nested loops vs single loop with index).

Dependencies:
* T04.G8.09: Debug complex multi-pattern algorithm errors
* T04.G6.06: Compare two pattern-based solutions for efficiency and code clarity




ID: T04.G8.15
Topic: T04 – Algorithm Patterns
Skill: Design pattern-based multiplayer game architecture
Description: Students design algorithm patterns for multiplayer games using CreatiCode multiplayer blocks: state synchronization patterns (broadcasting updates), conflict resolution patterns (handling simultaneous actions), and event distribution patterns (routing messages to correct players). They create a design document showing how patterns interact.

Dependencies:
* T04.G8.07: Design pattern-based solution architecture for complex problems
* T04.G7.02.01: Identify state machine patterns in game code




ID: T04.G8.16
Topic: T04 – Algorithm Patterns
Skill: Create reusable pattern libraries for team projects
Description: Students create a documented library of 3+ reusable pattern blocks that teammates can use. They write usage documentation including: when to use each pattern, parameter descriptions, example use cases, and common pitfalls. They demonstrate the library by building a project that uses all patterns.

Dependencies:
* T04.G8.08: Refactor legacy code to use standard patterns
* T04.G8.05: Complete a "pattern card" describing a reusable solution




ID: T04.G8.17
Topic: T04 – Algorithm Patterns
Skill: Design prompt strategies for AI to generate pattern-based solutions
Description: Students learn to write effective prompts that guide AI code generators (like ChatGPT) to produce clean, pattern-based solutions. They compare results from vague prompts ("write code to process this list") vs specific prompts ("write a filter-then-accumulate pattern to sum values above threshold"). Focus is on prompt engineering for code generation.

Dependencies:
* T04.G8.16: Create reusable pattern libraries for team projects
* T04.G7.12: Evaluate when AI-generated code matches standard patterns




ID: T04.G8.18
Topic: T04 – Algorithm Patterns
Skill: Validate and refactor AI-generated algorithm implementations
Description: Students receive AI-generated code and systematically validate it: Does it use appropriate patterns? Are edge cases handled? Is the code maintainable? They refactor AI output to use cleaner patterns, add missing error handling, and improve readability. Focus is on critical evaluation and improvement of AI-assisted code.

Dependencies:
* T04.G8.17: Design prompt strategies for AI to generate pattern-based solutions
* T04.G8.08: Refactor legacy code to use standard patterns








ID: T04.G8.19
Topic: T04 – Algorithm Patterns
Skill: Lead code review for pattern implementation quality
Description: **Student task:** Lead a code review session evaluating a classmate's pattern implementations. Use a structured review checklist covering: (1) Is the pattern correctly identified and named? (2) Is it implemented correctly? (3) Are edge cases handled? (4) Is it readable and maintainable? (5) Are there opportunities for improvement? **Assessment:** Review must provide specific, actionable feedback with evidence from the code. Student demonstrates LEADERSHIP in technical review process.

Dependencies:
* T04.G8.09: Debug complex multi-pattern algorithm errors
* T04.G7.13: Present pattern trade-offs to stakeholders




ID: T04.G8.20
Topic: T04 – Algorithm Patterns
Skill: Apply systematic debugging methodology for complex patterns
Description: **Student task:** Apply a systematic debugging methodology when facing complex pattern bugs. Steps: (1) Reproduce the bug consistently, (2) Isolate which pattern component has the bug, (3) Add logging to track data flow, (4) Form hypothesis about root cause, (5) Test hypothesis with minimal change, (6) Verify fix doesn't break other patterns. **Assessment:** Students document their debugging process, showing each step taken. Focus is on METHODICAL problem-solving skills essential for professional development.

Dependencies:
* T04.G8.09: Debug complex multi-pattern algorithm errors
* T04.G8.14: Analyze algorithm efficiency using Big-O reasoning




ID: T04.G8.21
Topic: T04 – Algorithm Patterns
Skill: Design pattern-based solutions for emerging technologies
Description: **Student task:** Apply pattern knowledge to emerging technology contexts: AI/ML data pipelines, IoT sensor processing, real-time collaboration systems. **Scenario:** Given a new technology context (e.g., "process streaming data from multiple sensors"), students identify which classic patterns apply (filter for anomaly detection, accumulator for averages, state machine for device status) and design the solution architecture. **Assessment:** Students produce a design document showing pattern selection and justification for a novel context. Focus is on TRANSFERRING pattern knowledge to new domains.

Dependencies:
* T04.G8.07: Design a pattern-based solution architecture for a complex problem
* T04.G8.12: Design AI data processing pipelines using CreatiCode AI blocks



# T05 - Human-Centered Design (Phase 7 Major Revision - November 2025)
# MAJOR RESTRUCTURING from Phase 6:
#
# PHILOSOPHY SHIFT:
# This revision refocuses T05 on CORE Human-Centered Design principles:
# - Empathy & User Research (understanding users deeply)
# - Ideation & Prototyping (designing solutions)
# - Testing & Iteration (validating with real users)
# - Accessibility & Inclusion (designing for all)
# - Modern UX Patterns (AI-era interfaces)
#
# KEY CHANGES:
# 1. REDUCED SIMULATION FOCUS: Simulation is computational modeling (better in T04/T12).
#    Kept only skills where simulation relates to user behavior modeling.
#
# 2. STRENGTHENED EMPATHY STRAND (K-5):
#    - Added emotion recognition in K-2
#    - Added observation-based research skills
#    - Added empathy mapping at G4
#    - Added user journey mapping at G5
#
# 3. ENHANCED PROTOTYPING STRAND (G3-8):
#    - Paper prototyping at G3
#    - Wireframing at G4-5
#    - CreatiCode widget implementation at G5-6
#    - Interactive prototyping at G6-7
#    - Full app prototyping at G8
#
# 4. ADDED MODERN UX PATTERNS (G5-8):
#    - Micro-interactions and feedback design
#    - Progressive disclosure
#    - Voice UI design (with CreatiCode speech blocks)
#    - Gesture-based interaction (with CreatiCode hand tracking)
#    - Conversational UX (chatbot design with ChatGPT blocks)
#
# 5. STRENGTHENED ACCESSIBILITY (all grades):
#    - Visual accessibility (contrast, size, color-blindness)
#    - Motor accessibility (keyboard nav, large targets)
#    - Auditory accessibility (captions, visual alerts)
#    - Cognitive accessibility (clear language, consistent layout)
#    - Multimodal input (speech, gesture, touch fallbacks)
#
# 6. ADDED AI-AUGMENTED DESIGN (G6-8):
#    - AI as design partner (XO for brainstorming)
#    - Chatbot personality design
#    - AI safety and moderation
#    - AI content personalization
#    - Critical evaluation of AI suggestions
#
# VERB IMPROVEMENTS:
# All skills use active, measurable verbs: Recognize, Match, Select, Predict,
# Extract, Compose, Build, Test, Debug, Evaluate, Critique, Design, Implement
#
# TOTAL: 143 skills across K-8
# Distribution: GK=5, G1=6, G2=8, G3=12, G4=18, G5=18, G6=17, G7=18, G8=25
# (Note: Some simulation skills preserved for user behavior modeling context)

# === KINDERGARTEN (5 skills) ===
# Focus: Recognizing helpers, simple usability, emotions in pictures

ID: T05.GK.01
Topic: T05 – Human‑Centered Design
Skill: Recognize who a tool helps from picture cards
Description: Students see a picture card of a person and a tool (e.g., grandparent + smartphone, child + step stool) and click on "Who does this help?" from picture options. Picture-based selection activity with visual scenarios only. Builds foundation for thinking about users.




ID: T05.GK.02
Topic: T05 – Human‑Centered Design
Skill: Match problem pictures to helpful tool pictures
Description: Students drag-and-drop to match picture cards showing simple everyday problems (e.g., picture of dark room) to picture cards showing tools that help (e.g., flashlight). Picture-based matching activity with visual scenarios only.

Dependencies:
* T05.GK.01: Recognize who a tool helps from picture cards




ID: T05.GK.03
Topic: T05 – Human‑Centered Design
Skill: Select the easier-to-use version from two pictures
Description: Students compare two picture cards of an interface/tool (big vs tiny button, clear vs cluttered screen) and click on which is easier to use. Picture-based comparison activity with visual scenarios only. Introduces usability thinking.

Dependencies:
* T05.GK.02: Match problem pictures to helpful tool pictures




ID: T05.GK.04
Topic: T05 – Human‑Centered Design
Skill: Recognize happy and frustrated faces when using tools
Description: Students see picture cards showing faces of people using tools (child smiling while using big buttons, adult frowning at tiny text) and sort them into "happy" and "frustrated" piles. Introduces emotional response to design. Picture-based sorting activity.

Dependencies:
* T05.GK.03: Select the easier-to-use version from two pictures




ID: T05.GK.05
Topic: T05 – Human‑Centered Design
Skill: Select a change picture that makes a device easier to use
Description: Students see picture cards showing possible changes (bigger button, clearer text, speaker icon for sound) and click on which change would help a pictured character use a device. Picture-based selection activity with visual scenarios only.

Dependencies:
* T05.GK.04: Recognize happy and frustrated faces when using tools




# === GRADE 1 (6 skills) ===
# Focus: Deeper empathy, matching users to designs, predicting struggles

ID: T05.G1.01
Topic: T05 – Human‑Centered Design
Skill: Recognize what a character needs from a picture story
Description: Students see a 2-3 panel picture story showing a character with a problem (e.g., child can't reach a shelf, person squinting at small text, someone lost in a building) and choose from picture options what the character needs (a step stool, bigger text, a map sign). Picture-based activity using visual scenarios only.

Dependencies:
* T05.GK.02: Match problem pictures to helpful tool pictures




ID: T05.G1.02
Topic: T05 – Human‑Centered Design
Skill: Match a need picture to a design solution picture
Description: Students match picture cards showing problems (person squinting at screen, person in wheelchair at stairs, child confused by many buttons) to picture cards showing solutions (larger screen, ramp, fewer bigger buttons). Drag-and-drop picture matching activity.

Dependencies:
* T05.G1.01: Recognize what a character needs from a picture story




ID: T05.G1.03
Topic: T05 – Human‑Centered Design
Skill: Choose a better screen version for a pictured user
Description: Students see a picture of a user (young child, elderly person with glasses, person using one hand) and two screen versions side by side, then click on which screen version would work better for that pictured user. Picture-based comparison activity.

Dependencies:
* T05.GK.03: Select the easier-to-use version from two pictures




ID: T05.G1.04
Topic: T05 – Human‑Centered Design
Skill: Choose one change picture that helps a pictured user
Description: Students see a picture of a user with a specific need and a device/screen, then choose from 3-4 picture options showing possible changes (bigger buttons, added pictures, speaker icon, brighter colors) which change would help that user most. Picture-based selection activity.

Dependencies:
* T05.G1.02: Match a need picture to a design solution picture




ID: T05.G1.05
Topic: T05 – Human‑Centered Design
Skill: Predict which user will struggle with a pictured tool
Description: Students see a picture of a tool (e.g., tablet with small buttons, toy with complicated instructions) and three user pictures (young child, teenager, elderly person). They predict which user might have the most trouble using the tool by clicking on their picture. Builds predictive thinking about user-tool fit. Picture-based selection activity.

Dependencies:
* T05.G1.03: Choose a better screen version for a pictured user
* T05.G1.04: Choose one change picture that helps a pictured user




ID: T05.G1.06
Topic: T05 – Human‑Centered Design
Skill: Sort emotion faces by how good the design made users feel
Description: Students see 4 face pictures showing different emotions (very happy, okay, sad, confused) and drag them to match different design scenarios shown in pictures (easy app vs confusing app vs broken app). Builds understanding that design affects emotions. Picture-based sorting activity.

Dependencies:
* T05.GK.04: Recognize happy and frustrated faces when using tools
* T05.G1.01: Recognize what a character needs from a picture story




# === GRADE 2 (8 skills) ===
# Focus: User preferences, accessibility features, design cycles, bridging to text

ID: T05.G2.01
Topic: T05 – Human‑Centered Design
Skill: Match user pictures to preferred design pictures
Description: Students see three picture cards of users (e.g., kid, adult, person with glasses) and drag-and-drop to match each to a preferred design picture (colorful icons, simple layout, high contrast). Picture-based matching activity with visual scenarios only.

Dependencies:
* T05.G1.03: Choose a better screen version for a pictured user




ID: T05.G2.02
Topic: T05 – Human‑Centered Design
Skill: Circle accessibility features in a picture
Description: Students see interface screenshots and circle or click on accessibility features they can identify (large buttons, speaker icons for sound, picture labels, high contrast colors). Picture-based feature identification activity where students recognize helpful design elements.

Dependencies:
* T05.G1.04: Choose one change picture that helps a pictured user




ID: T05.G2.03
Topic: T05 – Human‑Centered Design
Skill: Match real situations to pretend computer versions
Description: Students see picture pairs showing real things and their "pretend computer versions" (e.g., real traffic light vs animated traffic light on screen, real weather vs weather animation). They drag and drop to match which real situations have a computer pretend version, then choose which would be safer to try on computer first. Picture-based matching activity without written explanation.

Dependencies:
* T05.G1.01: Recognize what a character needs from a picture story




ID: T05.G2.04
Topic: T05 – Human‑Centered Design
Skill: Choose what to include in a very simple simulation
Description: Students see a picture of a situation (e.g., garden with sun, rain, flowers, bugs, fence). They drag and drop 2-3 pictures of important things to include in a "computer pretend version" to answer a question like "What helps the plant grow?" while leaving out unimportant details.

Dependencies:
* T05.G2.03: Match real situations to pretend computer versions




ID: T05.G2.05
Topic: T05 – Human‑Centered Design
Skill: Drag picture labels to match needs shown in a picture story
Description: Students see a 3-panel picture story of a user struggling with something (e.g., child squinting at tiny phone screen, grandparent confused by many buttons). They drag picture labels (magnifying glass for "bigger", fewer buttons icon for "simpler") to match each need. Picture-based labeling bridges to text-based work in G3.

Dependencies:
* T05.G2.01: Match user pictures to preferred design pictures
* T05.G2.02: Circle accessibility features in a picture




ID: T05.G2.06
Topic: T05 – Human‑Centered Design
Skill: Read a one-sentence need and choose the matching solution picture
Description: Students read a simple sentence describing a user need (e.g., "Maria has trouble seeing small words") and choose from 3 picture options showing solutions (bigger text, louder sound, faster loading). Introduces reading comprehension for user needs while keeping response picture-based.

Dependencies:
* T05.G2.05: Drag picture labels to match needs shown in a picture story




ID: T05.G2.07
Topic: T05 – Human‑Centered Design
Skill: Sequence 4 pictures showing design-test-improve cycle
Description: Students see 4 scrambled pictures showing: (1) person thinking about an idea, (2) person building/drawing something, (3) another person trying it and looking confused, (4) first person making changes. They drag pictures into correct order to show the design cycle. Prepares for G3.01 sequencing with more steps. Picture-based sequencing activity.

Dependencies:
* T05.G2.05: Drag picture labels to match needs shown in a picture story
* T05.G2.06: Read a one-sentence need and choose the matching solution picture




ID: T05.G2.08
Topic: T05 – Human‑Centered Design
Skill: Watch a picture story and spot what made a user confused
Description: Students see a 3-4 panel picture story showing someone using a device and getting confused at one step (e.g., clicking wrong button, looking lost at a menu). They click on the panel where confusion happened. Introduces observation-based research. Picture-based selection activity.

Dependencies:
* T05.G1.06: Sort emotion faces by how good the design made users feel
* T05.G2.02: Circle accessibility features in a picture




# === GRADE 3 (12 skills) ===
# Focus: HCD process, user research basics, paper prototyping, accessibility matching

ID: T05.G3.01
Topic: T05 – Human‑Centered Design
Skill: Arrange human-centered design steps into correct sequence
Description: Students drag-and-drop cards showing HCD cycle phases ("learn about users," "plan design," "build prototype," "test with users," "improve") into correct order. Activity shows why iterative design matters - after testing, designers return to earlier steps to make improvements.

Dependencies:
* T05.G2.06: Read a one-sentence need and choose the matching solution picture
* T05.G2.07: Sequence 4 pictures showing design-test-improve cycle




ID: T05.G3.01.01
Topic: T05 – Human‑Centered Design
Skill: Locate the "learn about users" phase in a design story
Description: Students read a short story about someone creating an app and select which part shows "learning about users" (e.g., asking friends what games they like, watching how someone uses a tablet). Multiple choice with 3-4 options.

Dependencies:
* T05.G3.01: Arrange human-centered design steps into correct sequence




ID: T05.G3.01.02
Topic: T05 – Human‑Centered Design
Skill: Locate the "test and improve" phase in a design story
Description: Students read a short story about creating an app and select which part shows "testing and improving" (e.g., letting a friend try the app and then fixing the confusing button). Distinguishes testing from building or planning.

Dependencies:
* T05.G3.01: Arrange human-centered design steps into correct sequence




ID: T05.G3.02
Topic: T05 – Human‑Centered Design
Skill: Distinguish user needs from wants in an interview transcript
Description: Students read 3-4 lines of a mock user interview (e.g., "I always forget my homework assignments. My teacher writes them on the board but I can't see well from the back row. I wish the app had cool animations.") and sort statements into "needs" (essential problems to solve) vs "wants" (nice-to-have preferences). Multiple choice format.

Dependencies:
* T05.G2.06: Read a one-sentence need and choose the matching solution picture
* T05.G1.01: Identify what a character needs from pictures




ID: T05.G3.02.01
Topic: T05 – Human‑Centered Design
Skill: Extract user constraints from an interview transcript
Description: Students read interview quotes and extract constraints the user cannot change (e.g., "I can only use one hand," "I don't have internet at home," "I have 5 minutes between classes"). Distinguishes constraints from preferences. Builds toward G4 persona work.

Dependencies:
* T05.G3.02: Distinguish user needs from wants in an interview transcript




ID: T05.G3.02.02
Topic: T05 – Human‑Centered Design
Skill: Summarize user's main problem in one sentence
Description: After reading a short interview transcript, students write or select a one-sentence summary of the user's core problem (e.g., "Sam needs a way to remember homework because he can't see the board from his seat"). Practices distilling verbose input into actionable insight.

Dependencies:
* T05.G3.02: Distinguish user needs from wants in an interview transcript
* T05.G3.02.01: Identify user constraints from an interview transcript




ID: T05.G3.03
Topic: T05 – Human‑Centered Design
Skill: Select design improvements based on user feedback
Description: Students read 1-2 short feedback comments from a mock user test (e.g., "The buttons are too small for me to tap" or "I couldn't find where to save my work") and select from 3-4 options which design change would best address the feedback. Multiple choice format with clear correct answer.

Dependencies:
* T05.G2.02: Circle accessibility features in a picture




ID: T05.G3.04
Topic: T05 – Human‑Centered Design
Skill: Select the main variable a simple simulation should display
Description: Students select what the main "thing that changes" is in a simple simulation (e.g., plant height, number of cars) from multiple choice options, considering what question they want the simulation to help answer.

Dependencies:
* T05.G2.04: Choose what to include in a very simple simulation




ID: T05.G3.05
Topic: T05 – Human‑Centered Design
Skill: Select simple rules for a simulation
Description: Students pick rules such as "if it rains, plant grows taller" from options to define simulation behavior, keeping each rule small and focused on one cause/effect.

Dependencies:
* T05.G2.04: Choose what to include in a very simple simulation




ID: T05.G3.06
Topic: T05 – Human‑Centered Design
Skill: Match accessibility features to users who benefit
Description: Students see accessibility features (captions, large text, high contrast, keyboard shortcuts, voice control) and match each to which user types benefit most (deaf/hard of hearing, low vision, motor difficulty, prefer keyboard). Bridges feature identification to issue recognition.

Dependencies:
* T05.G2.02: Circle accessibility features in a picture
* T05.G2.01: Match user pictures to preferred design pictures




ID: T05.G3.07
Topic: T05 – Human‑Centered Design
Skill: Classify which questions a simulation can answer
Description: Students see a list of questions about a real-world situation (e.g., "How many birds will there be next year?", "What color are the birds?", "What happens if we plant more trees?") and sort them into "simulation can help answer" vs "need other ways to find out." Builds understanding of what simulations are useful for.

Dependencies:
* T05.G3.04: Select the main variable a simple simulation should display
* T05.G3.05: Select simple rules for a simulation




ID: T05.G3.08
Topic: T05 – Human‑Centered Design
Skill: Identify which accessibility features are present in a design
Description: Students look at an interface screenshot and identify which accessibility features it already has (e.g., large buttons, high contrast, captions) and which are missing. Creates a checklist of features present vs absent. Bridges G3.06 (matching features to users) to G4.03 (recognizing issues).

Dependencies:
* T05.G3.06: Match accessibility features to users who benefit




ID: T05.G3.09
Topic: T05 – Human‑Centered Design
Skill: Sketch a paper prototype for a simple app screen
Description: Students draw a basic paper prototype for one app screen given a user need (e.g., "timer for homework breaks"). They include at least 3 UI elements (button, text, image area) and label each. Introduces rapid prototyping before digital tools.

Dependencies:
* T05.G3.03: Select design improvements based on user feedback
* T05.G3.01: Arrange human-centered design steps into correct sequence




ID: T05.G3.10
Topic: T05 – Human‑Centered Design
Skill: Test a paper prototype by role-playing as user and designer
Description: Students work in pairs: one pretends to use a paper prototype by pointing at elements, the other moves paper pieces to simulate the app's response. They note one thing that worked and one thing that confused the "user." Introduces low-fidelity testing.

Dependencies:
* T05.G3.09: Sketch a paper prototype for a simple app screen
* T05.G2.08: Watch a picture story and spot what made a user confused




# === GRADE 4 (16 skills) ===
# Focus: Personas, empathy mapping, accessibility barriers, user stories, interview skills

ID: T05.G4.01
Topic: T05 – Human‑Centered Design
Skill: Extract design-relevant details from a user persona
Description: Students read a short persona card (3-4 sentences covering age, context, goals, constraints) and highlight or select which details would most influence design decisions. For example, from "Maya is 10, uses a tablet for homework, struggles to read small text, prefers colorful apps," students extract "struggles to read small text" as a key detail for design.

Dependencies:
* T05.G3.01: Arrange human-centered design steps into correct sequence
* T05.G3.02.02: Summarize user's main problem in one sentence




ID: T05.G4.01.01
Topic: T05 – Human‑Centered Design
Skill: Distinguish user constraints from preferences in a persona
Description: Students read a persona and sort details into "constraints" (things the user cannot change, like vision difficulty) vs "preferences" (things the user likes but could adapt, like colorful apps). Helps students prioritize which persona details are essential to address.

Dependencies:
* T05.G4.01: Extract design-relevant details from a user persona


ID: T05.G4.01.02
Topic: T05 – Human‑Centered Design
Skill: Prioritize persona details by design impact
Description: Students rank 4-5 details from a persona by how much each affects design decisions. They drag details into high/medium/low impact tiers and justify their top choice. Builds systematic prioritization before design begins.

Dependencies:
* T05.G4.01.01: Distinguish user constraints from preferences in a persona




ID: T05.G4.02
Topic: T05 – Human‑Centered Design
Skill: Match app design variants to user personas
Description: Students see a persona description and two different app design screenshots, then select which design better matches the persona's needs. They also select from multiple choice options why that design is better suited (e.g., "Design A has larger buttons which helps Maya who struggles with small text").

Dependencies:
* T05.G3.02: Distinguish user needs from wants in an interview transcript
* T05.G4.01: Extract design-relevant details from a user persona




ID: T05.G4.03
Topic: T05 – Human‑Centered Design
Skill: Spot accessibility barriers in interface screenshots
Description: Students view an interface screenshot containing accessibility issues and click on or circle specific problems: tiny text (hard to read), low contrast (text blends into background), missing captions (video has no subtitles), cluttered layout (too many elements). Activity requires locating at least 2 issues from the screenshot.

Dependencies:
* T05.G3.08: Identify which accessibility features are present in a design
* T05.G3.06: Match accessibility features to users who benefit




ID: T05.G4.03.01
Topic: T05 – Human‑Centered Design
Skill: Categorize accessibility barriers by type
Description: Students see 4-5 accessibility issues and sort them into categories: visual barriers (text size, contrast, color-only indicators), motor barriers (small click targets, no keyboard access), auditory barriers (no captions, no visual alerts), or cognitive barriers (complex language, confusing layout). Builds systematic thinking about accessibility.

Dependencies:
* T05.G4.03: Spot accessibility barriers in interface screenshots




ID: T05.G4.04
Topic: T05 – Human‑Centered Design
Skill: Select fixes for identified accessibility issues
Description: Students see a specific accessibility issue (e.g., "Users with low vision can't read the small text") and select from 3-4 options which fix best addresses it (e.g., increase font size to 16px+, add text-to-speech, improve contrast, add magnification). Focus is matching the right solution to the right problem.

Dependencies:
* T05.G4.03: Spot accessibility barriers in interface screenshots
* T05.G3.03: Select design improvements based on user feedback




ID: T05.G4.04a
Topic: T05 – Human‑Centered Design
Skill: Compose a user story in standard format
Description: Given a short user scenario (e.g., "Sam is 8 and wants to track homework but often forgets due dates"), students complete a structured user story: "As a [user type], I need [feature] so that [benefit]." Students fill in blanks from dropdown menus or type short answers. Example completion: "As a student, I need reminders for due dates so that I don't forget my homework."

Dependencies:
* T05.G4.01: Identify design-relevant details in a user persona
* T05.G4.02: Match app design variants to user personas




ID: T05.G4.05
Topic: T05 – Human‑Centered Design
Skill: Categorize factors as included or ignored in a simulation
Description: Students see a real-world situation and categorize factors by dragging them into "include" (2-3 important factors) and "ignore" (1-2 unimportant details) columns for the simulation.

Dependencies:
* T05.G3.04: Select the main variable a simple simulation should display
* T05.G3.05: Select simple rules for a simulation




ID: T05.G4.05a
Topic: T05 – Human‑Centered Design
Skill: Formulate questions a simulation should answer
Description: Students see a real-world situation and write 2-3 specific questions that a simulation could help answer (e.g., "How will the population change if we add more food?", "What happens if we double the starting number?"). Builds on G3.07 by having students generate their own questions.

Dependencies:
* T05.G3.07: Classify which questions a simulation can answer
* T05.G4.05: Categorize factors as included or ignored in a simulation




ID: T05.G4.06
Topic: T05 – Human‑Centered Design
Skill: Select the best justification for a simulation simplification
Description: Students select the best reason from multiple choice options for why a given factor can be ignored in a simulation (e.g., too complex, not needed for the question, minimal impact on results).

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T05.G3.07: Classify which questions a simulation can answer




ID: T05.G4.06.01
Topic: T05 – Human‑Centered Design
Skill: Predict simulation behavior from a simple rule set
Description: Students see a simulation scenario with starting values (e.g., 10 rabbits, 20 carrots) and simple rules (e.g., "each step: rabbits eat 2 carrots, rabbits increase by 1"). They predict the values after 3 steps by applying rules mentally. Builds understanding of how simulation rules affect outcomes before coding.

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T05.G4.06: Select the best justification for a simulation simplification




ID: T05.G4.06.02
Topic: T05 – Human‑Centered Design
Skill: Connect simulation factors to user personas
Description: Given a user persona with a goal (e.g., farmer wanting to plan crop planting), students select which factors from a list would be most relevant to include in a simulation for that user. Connects HCD persona thinking to simulation design decisions.

Dependencies:
* T05.G4.01: Identify design-relevant details in a user persona
* T05.G4.05: Categorize factors as included or ignored in a simulation




ID: T05.G4.06.03
Topic: T05 – Human‑Centered Design
Skill: Debug a mental simulation by finding rule conflict
Description: Students see simulation rules that produce unexpected results (e.g., "rabbits increase by 5" and "rabbits decrease by 3 when food is low" both triggering). They identify the conflicting rules and explain why the result is confusing. Introduces debugging thinking for simulations.

Dependencies:
* T05.G4.06.01: Predict simulation behavior from a simple rule set




ID: T05.G4.07
Topic: T05 – Human‑Centered Design
Skill: Select test tasks that reveal specific design problems
Description: Students see a suspected design problem (e.g., "Users can't find the save button") and select from 3-4 options which test task would best reveal it (e.g., "Ask user to save their work and observe" vs "Ask user to change colors" vs "Ask user about their favorite feature"). Multiple choice format introduces usability testing logic.

Dependencies:
* T05.G3.03: Select design improvements based on user feedback
* T05.G4.02: Match app design variants to user personas
* T05.G3.01.02: Identify the "test and improve" phase in a design story




ID: T05.G4.08
Topic: T05 – Human‑Centered Design
Skill: Write an open-ended interview question
Description: Students write 1 interview question to learn about user needs for a given topic (e.g., homework tracking). Question must be open-ended (not yes/no). Good example: "What challenges do you face with homework?" Activity provides sentence starters and evaluates question quality.

Dependencies:
* T05.G3.02: Distinguish user needs from wants in an interview transcript
* T05.G4.01: Identify design-relevant details in a user persona




ID: T05.G4.08.01
Topic: T05 – Human‑Centered Design
Skill: Detect leading questions in user research
Description: Students see 4-5 interview questions and detect which are "leading" (suggest an answer, like "Don't you think the buttons are too small?") vs "neutral" (like "How do you feel about the button size?"). Teaches unbiased question design.

Dependencies:
* T05.G4.08: Write an open-ended interview question




ID: T05.G4.08.02
Topic: T05 – Human‑Centered Design
Skill: Rewrite a leading question to be neutral
Description: Students see a leading question (e.g., "Wouldn't it be great if the app had notifications?") and rewrite it as a neutral question (e.g., "How do you currently remember important tasks?"). Practices transforming biased to unbiased questions.

Dependencies:
* T05.G4.08.01: Detect leading questions in user research




ID: T05.G4.09
Topic: T05 – Human‑Centered Design
Skill: Create a simple empathy map for a user persona
Description: Students complete an empathy map template with 4 quadrants (Says, Thinks, Does, Feels) based on a user scenario. For example, for a student struggling with homework: Says "I don't have time", Thinks "This is too hard", Does "Opens phone instead", Feels "Stressed". Deepens understanding of user experience.

Dependencies:
* T05.G4.01: Extract design-relevant details from a user persona
* T05.G4.01.01: Distinguish user constraints from preferences in a persona




ID: T05.G4.10
Topic: T05 – Human‑Centered Design
Skill: Trace a user's steps through a simple app flow
Description: Students see a 3-screen app mockup and trace the steps a user would take to complete a task (e.g., "Add a new reminder"). They number each action (tap button 1, type text 2, tap save 3) and identify any confusing steps. Introduces user flow analysis.

Dependencies:
* T05.G4.02: Match app design variants to user personas
* T05.G3.10: Test a paper prototype by role-playing as user and designer




# === GRADE 5 (20 skills) ===
# Focus: Requirements, wireframing, user journeys, CreatiCode widget mapping, accessibility specs

ID: T05.G5.01
Topic: T05 – Human‑Centered Design
Skill: Write a requirements document with multiple user stories
Description: Students complete a requirements document containing 3-4 user stories (using "As a... I need... so that..." format) for a simple app idea (e.g., pet care tracker, homework helper). Each user story addresses a different user need. Document also lists 2-3 app features that address these needs.

Dependencies:
* T05.G4.04a: Compose a user story in standard format




ID: T05.G5.01.01
Topic: T05 – Human‑Centered Design
Skill: Map user stories to app features
Description: Students see 3-4 user stories and 4-5 potential app features, then draw lines to match each user story to the feature(s) that would address it. Some features may address multiple stories; some stories may need multiple features. Practices connecting user needs to implementation.

Dependencies:
* T05.G5.01: Write a requirements document with multiple user stories




ID: T05.G5.01.02
Topic: T05 – Human‑Centered Design
Skill: Prioritize user stories by importance
Description: Students rank 4-5 user stories by importance using criteria: How many users does it affect? Is it essential or nice-to-have? Does it block other functionality? Students drag stories into priority order and write one sentence justifying their top choice.

Dependencies:
* T05.G5.01: Write a requirements document with multiple user stories




ID: T05.G5.01.03
Topic: T05 – Human‑Centered Design
Skill: Detect conflicting user needs across stories
Description: Students read 4-5 user stories and detect pairs that conflict (e.g., "As a child, I want lots of colors" vs "As a user with sensitivity, I want muted colors"). They explain why these conflict and which user group is larger or more critical.

Dependencies:
* T05.G5.01.02: Prioritize user stories by importance




ID: T05.G5.01.04
Topic: T05 – Human‑Centered Design
Skill: Propose a compromise for conflicting user needs
Description: Given conflicting user stories (from G5.01.03), students propose a design solution that addresses both (e.g., "Add a theme toggle so users can choose colorful or muted"). Practices negotiating competing requirements.

Dependencies:
* T05.G5.01.03: Identify conflicting user needs across stories




ID: T05.G5.02
Topic: T05 – Human‑Centered Design
Skill: Arrange UI elements to create a basic wireframe
Description: Students drag and drop basic UI elements (buttons, text areas, images, navigation bars) onto a screen template to create a simple wireframe layout for a given user story. Focus is on spatial arrangement and visual hierarchy - placing important elements prominently, grouping related items, ensuring logical flow.

Dependencies:
* T05.G5.01: Write a requirements document with multiple user stories




ID: T05.G5.02a
Topic: T05 – Human‑Centered Design
Skill: Label wireframe elements with their purpose
Description: Students add labels to a wireframe explaining what each UI element does (e.g., "Submit button," "User input field," "Help icon"). This practices connecting visual elements to their functional purpose.

Dependencies:
* T05.G5.02: Arrange UI elements to create a basic wireframe




ID: T05.G5.02b
Topic: T05 – Human‑Centered Design
Skill: Explain how wireframe elements support user tasks
Description: Students write a brief explanation for 2-3 wireframe elements, connecting each to a specific user task from the requirements (e.g., "The large 'Add' button helps users quickly add new items as stated in requirement #2").

Dependencies:
* T05.G5.02a: Label wireframe elements with their purpose




ID: T05.G5.02c
Topic: T05 – Human‑Centered Design
Skill: Create two design alternatives for the same user need
Description: Students sketch two different UI layout approaches for the same user story, then identify one advantage and one disadvantage of each. Introduces design tradeoffs and exploring alternatives before committing to one approach.

Dependencies:
* T05.G5.02b: Explain how wireframe elements support user tasks




ID: T05.G5.03
Topic: T05 – Human‑Centered Design
Skill: Identify variables and initial values for a simulation
Description: Students list or select variables (e.g., "number of rabbits") and their starting values from a story, as a planning step before building the simulation in CreatiCode using the variable blocks (e.g., T17/T25-T27).

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T05.G4.05a: Formulate questions a simulation should answer
* T09.G3.03: Create a variable and display its value
* T10.G5.01: Understand table structure (rows, columns, cells)
* T03.G5.01: Write a feature list with subtasks for each feature




ID: T05.G5.03.01
Topic: T05 – Human‑Centered Design
Skill: Distinguish state variables from parameters in a simulation
Description: Students categorize simulation factors into "state variables" (things that change during simulation, like population count) vs "parameters" (things set at the start and stay constant, like growth rate). Builds understanding of simulation structure.

Dependencies:
* T05.G5.03: Identify variables and initial values for a simulation




ID: T05.G5.04
Topic: T05 – Human‑Centered Design
Skill: Draft simple update rules for a simulation
Description: Students choose or write rules for how variables change each step (e.g., "each month, rabbits double"), keeping each rule small and unambiguous so it can be implemented later in code using loops and conditionals.

Dependencies:
* T05.G3.05: Select simple rules for a simulation
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T07.G5.01: Simulate repeated experiments with a loop
* T08.G5.01: Draw decision tree flowchart
* T09.G5.01: Use multiple variables together in a single expression




ID: T05.G5.05
Topic: T05 – Human‑Centered Design
Skill: Create a usability test plan with tasks and success criteria
Description: Students create a usability test plan with 3-4 specific tasks for a tester to try (e.g., "Find the start button," "Add an item to cart," "Change your profile picture"). For each task, students define what success looks like (e.g., "User finds button within 10 seconds without asking for help"). Plan includes task descriptions and measurable success criteria.

Dependencies:
* T05.G3.01: Arrange human-centered design steps into correct sequence
* T05.G4.07: Select test tasks that reveal specific design problems
* T09.G3.03: Create a variable and display its value
* T10.G5.01: Understand table structure (rows, columns, cells)
* T02.G5.01: Trace a script with nested loops using debug print
* T03.G5.01: Write a feature list with subtasks for each feature




ID: T05.G5.05a
Topic: T05 – Human‑Centered Design
Skill: Specify accessibility features for a target user group
Description: Given a user persona with a specific need (e.g., low vision, motor difficulty, hearing impairment), students select which accessibility features from a checklist should be included: high contrast colors, larger click targets, captions for audio, keyboard navigation, screen reader compatibility. They write 1 sentence explaining why each selected feature helps that user.

Dependencies:
* T05.G4.04: Select fixes for identified accessibility issues




ID: T05.G5.06
Topic: T05 – Human‑Centered Design
Skill: Plan what to measure in a simulation experiment
Description: Students choose what data to record when running a simulation (e.g., population at each step), planning to use tables for data logging and charts for visualization.

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T03.G5.01: Write a feature list with subtasks for each feature




ID: T05.G5.07
Topic: T05 – Human‑Centered Design
Skill: Select design questions that can be tested with simulation
Description: Given a list of design questions about an app idea (e.g., "Will users like the colors?", "How long until the character runs out of energy?", "Can users find the button?"), students sort them into "test with simulation" vs "test with real users." Builds understanding of when simulation is the right validation tool.

Dependencies:
* T05.G5.03: Identify variables and initial values for a simulation
* T05.G5.05: Create a usability test plan with tasks and success criteria




ID: T05.G5.08
Topic: T05 – Human‑Centered Design
Skill: Plan CreatiCode widget layout for simulation controls
Description: Students plan the UI for a simulation by selecting and positioning CreatiCode widgets: sliders for parameters (starting values), buttons for start/reset, labels for displaying current values, and chart areas for results. Connects HCD wireframing skills to simulation implementation.

Dependencies:
* T05.G5.02: Arrange UI elements to create a basic wireframe
* T05.G5.03: Identify variables and initial values for a simulation




ID: T05.G5.09
Topic: T05 – Human‑Centered Design
Skill: Debug a wireframe for missing user flow
Description: Students review a wireframe and identify missing steps in the user flow (e.g., "There's no way to go back from this screen," "How does the user confirm their choice?"). They mark the gaps and propose additions. Introduces debugging thinking for design artifacts.

Dependencies:
* T05.G5.02b: Explain how wireframe elements support user tasks
* T05.G5.05: Create a usability test plan with tasks and success criteria


ID: T05.G5.10
Topic: T05 – Human‑Centered Design
Skill: Map wireframe elements to CreatiCode widgets
Description: Students take a wireframe design and map each UI element to the appropriate CreatiCode widget type: buttons (Button widget), text displays (Label widget), user input fields (Text Input widget), choice menus (Dropdown widget). They list each wireframe element and its matching CreatiCode widget, preparing for implementation.

Dependencies:
* T05.G5.02a: Label wireframe elements with their purpose
* T05.G5.08: Plan CreatiCode widget layout for simulation controls


ID: T05.G5.11
Topic: T05 – Human‑Centered Design
Skill: Specify widget properties for accessibility
Description: Students configure CreatiCode widget properties to meet accessibility needs: large font sizes for Label widgets, high-contrast colors for Button widgets, clear placeholder text for Text Input widgets. They complete a checklist connecting each widget to its accessibility settings.

Dependencies:
* T05.G5.10: Map wireframe elements to CreatiCode widgets
* T05.G5.05a: Specify accessibility features for a target user group




ID: T05.G5.12
Topic: T05 – Human‑Centered Design
Skill: Create a user journey map for a simple task
Description: Students create a journey map showing the steps, emotions, and pain points a user experiences while completing a task in an app. Map includes: steps (what user does), emotions (happy/neutral/frustrated at each step), and opportunities (where design could help). Visualizes the user experience over time.

Dependencies:
* T05.G4.10: Trace a user's steps through a simple app flow
* T05.G4.09: Create a simple empathy map for a user persona




ID: T05.G5.13
Topic: T05 – Human‑Centered Design
Skill: Design feedback for user actions in a prototype
Description: Students specify what feedback users should receive for key actions: button press (color change, sound), form submission (success message), error (helpful error text). They list 3-4 user actions and the corresponding feedback. Introduces micro-interaction design.

Dependencies:
* T05.G5.02: Arrange UI elements to create a basic wireframe
* T05.G5.10: Map wireframe elements to CreatiCode widgets




ID: T05.G5.14
Topic: T05 – Human‑Centered Design
Skill: Build a clickable prototype in CreatiCode with buttons and labels
Description: Students create a working prototype in CreatiCode with at least 3 button widgets that trigger actions (show/hide labels, change text, play sound). They test that clicking each button produces expected feedback. First hands-on implementation of HCD wireframe.

Dependencies:
* T05.G5.10: Map wireframe elements to CreatiCode widgets
* T05.G5.11: Specify widget properties for accessibility




# === GRADE 6 (18 skills) ===
# Focus: HCD evaluation, user research synthesis, prototype implementation, voice UI

ID: T05.G6.01
Topic: T05 – Human‑Centered Design
Skill: Evaluate a design using HCD principle checklist
Description: Students review a small app design using a structured checklist with three HCD principles: (1) Empathy - does the design show understanding of users' context and feelings? (2) Needs - does it solve real user problems? (3) Accessibility - is it usable by people with different abilities? Students mark pass/fail for each item and identify 1-2 gaps.

Dependencies:
* T05.G4.02: Match app design variants to user personas
* T05.G4.04: Select fixes for identified accessibility issues




ID: T05.G6.01.01
Topic: T05 – Human‑Centered Design
Skill: Rate a design on empathy criteria
Description: Students evaluate a design specifically on empathy criteria: Does it acknowledge user frustrations? Does it use language appropriate for the target audience? Does it consider the user's context (time-pressed, distracted, stressed)? Students mark each criterion pass/fail and cite specific evidence from the design.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G6.01.02
Topic: T05 – Human‑Centered Design
Skill: Rate a design on user needs criteria
Description: Students evaluate a design specifically on whether it addresses user needs: Does each main feature solve a stated user problem? Are the most important tasks easy to complete? Does it avoid unnecessary features that distract from core needs? Students mark each criterion and explain their reasoning.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G6.01.03
Topic: T05 – Human‑Centered Design
Skill: Rate a design on accessibility criteria
Description: Students evaluate a design specifically on accessibility: Is text readable (size, contrast)? Are interactive elements large enough? Does it work without color alone? Can it be used with keyboard only? Students mark each criterion pass/fail and note specific accessibility barriers found.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G6.02
Topic: T05 – Human‑Centered Design
Skill: Propose targeted design changes for HCD gaps
Description: Given a design with identified HCD gaps (from checklist evaluation), students propose 2-3 specific changes. Each change must address one principle and be actionable: empathy (e.g., "add onboarding tutorial for new users"), needs (e.g., "add quick-access button for the most common task"), or accessibility (e.g., "add keyboard shortcuts for all main actions"). Changes must be specific, not vague.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G6.03
Topic: T05 – Human‑Centered Design
Skill: Group user interview quotes by common theme
Description: Students read 5-6 short user responses (mock interview quotes or survey answers about an app idea) and drag-and-drop quotes into 2-3 theme buckets they create (e.g., "speed concerns," "navigation confusion"). They label each theme with a short title.

Dependencies:
* T05.G4.08: Write an open-ended interview question




ID: T05.G6.03.01
Topic: T05 – Human‑Centered Design
Skill: Flag outlier feedback that doesn't fit common themes
Description: Given grouped feedback themes (from G6.03), students flag 1-2 quotes that don't fit any theme and decide whether to create a new theme or note them as edge cases. Builds nuanced analysis skills.

Dependencies:
* T05.G6.03: Group user interview quotes by common theme




ID: T05.G6.03.02
Topic: T05 – Human‑Centered Design
Skill: Weight themes by frequency and importance
Description: Students count how many quotes support each theme and rank themes by (1) frequency and (2) impact on core functionality. They identify which theme should be addressed first and justify their choice.

Dependencies:
* T05.G6.03: Group user interview quotes by common theme
* T05.G6.03.01: Identify outlier feedback that doesn't fit common themes




ID: T05.G6.04
Topic: T05 – Human‑Centered Design
Skill: Map user feedback to specific design changes
Description: Students read 3-4 specific feedback items from user testing (e.g., "I couldn't find the save button," "The font is too small to read," "I got confused by too many options") and drag-and-drop to match each feedback to an appropriate design fix from a list (e.g., "Make save button larger and more prominent," "Increase font size," "Simplify menu structure").

Dependencies:
* T05.G6.03: Group user interview quotes by common theme




ID: T05.G6.05
Topic: T05 – Human‑Centered Design
Skill: Plan a simple CreatiCode simulation with variables, rules, and UI
Description: Students complete a planning template listing variables, rules, and simple UI widgets (sliders for parameters, labels for displays, buttons for controls, charts for results) for a simulation idea, as a bridge from paper planning (T05/T03) to actual CreatiCode simulations (e.g., physics/data topics).

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T05.G4.06: Select the best justification for a simulation simplification




ID: T05.G6.06
Topic: T05 – Human‑Centered Design
Skill: Write justifications for simulation modeling choices
Description: Students write brief reasons (1-2 sentences each) explaining why specific aspects of reality are included or simplified in a simulation design, connecting choices to the simulation's purpose.

Dependencies:
* T05.G4.05: Categorize factors as included or ignored in a simulation
* T05.G4.06: Select the best justification for a simulation simplification




ID: T05.G6.07
Topic: T05 – Human‑Centered Design
Skill: Interpret bar chart data about user preferences
Description: Students view a bar chart showing user preference data (e.g., "Which feature do you use most?") and answer factual questions: Which option is most popular? Which is least used? How many more users prefer A over B? Activity builds data literacy needed for evidence-based design decisions.

Dependencies:
* T05.G5.05: Create a usability test plan with tasks and success criteria




ID: T05.G6.08
Topic: T05 – Human‑Centered Design
Skill: Classify which user questions suit simulation vs other methods
Description: Students read a user scenario with 4-5 questions and sort them into "best answered by simulation" (e.g., "What happens to the population over time?", "How do changes in X affect Y?") vs "needs other methods" (e.g., "What color do users prefer?", "How do users feel about the design?"). Builds understanding of when simulations are the right tool.

Dependencies:
* T05.G4.05a: Formulate questions a simulation should answer
* T05.G5.06: Plan what to measure in a simulation experiment
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G6.09
Topic: T05 – Human‑Centered Design
Skill: Compare simulation predictions to actual user testing results
Description: Students run a simulation to make predictions (e.g., "Users will need 5 clicks to complete the task"), then review actual user testing data. They identify where simulation matched reality and where it differed, writing one sentence explaining each difference (e.g., "Simulation predicted 5 clicks but users took 8 because they missed the hidden menu").

Dependencies:
* T05.G6.05: Plan a simple CreatiCode simulation with variables, rules, and UI
* T05.G6.07: Interpret bar chart data about user preferences




ID: T05.G6.10
Topic: T05 – Human‑Centered Design
Skill: Debug a simulation by comparing expected vs actual behavior
Description: Students run a simulation and observe results that differ from expected (e.g., population grows too fast). They trace through rules step-by-step to find the error (e.g., growth rate was 2x instead of 1.2x). Introduces systematic debugging for simulations.

Dependencies:
* T05.G6.05: Plan a simple CreatiCode simulation with variables, rules, and UI
* T05.G6.09: Compare simulation predictions to actual user testing results




ID: T05.G6.11
Topic: T05 – Human‑Centered Design
Skill: Trace user research bias in interview questions
Description: Students review a set of 5-6 interview questions and identify which contain bias: leading questions, loaded language, or assumptions. For each biased question, they explain the bias and rewrite it neutrally. Advances skills from G4.08.01-02.

Dependencies:
* T05.G4.08.02: Rewrite a leading question to be neutral
* T05.G6.03: Group user interview quotes by common theme


ID: T05.G6.12
Topic: T05 – Human‑Centered Design
Skill: Build a CreatiCode prototype with text-to-speech accessibility
Description: Students implement text-to-speech in a CreatiCode project to make instructions and feedback accessible to visually impaired users. They configure the AI Speaker block to read labels, button confirmations, and error messages aloud, testing with eyes closed.

Dependencies:
* T05.G5.11: Specify widget properties for accessibility
* T05.G6.01.03: Rate a design on accessibility criteria


ID: T05.G6.13
Topic: T05 – Human‑Centered Design
Skill: Validate design against multiple personas
Description: Students take a single design and evaluate it against 3 different user personas, identifying which persona needs are well-served and which are underserved. They create a matrix showing design elements vs persona needs with pass/partial/fail ratings.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist
* T05.G4.02: Match app design variants to user personas




ID: T05.G6.14
Topic: T05 – Human‑Centered Design
Skill: Design a simple voice command flow for an app feature
Description: Students plan voice commands for one app feature (e.g., "add reminder" flow). They list: trigger phrases users might say, system responses, error cases ("I didn't understand"). Introduces voice UI design before implementation in G7.

Dependencies:
* T05.G6.12: Build a CreatiCode prototype with text-to-speech accessibility
* T05.G6.04: Map user feedback to specific design changes




ID: T05.G6.15
Topic: T05 – Human‑Centered Design
Skill: Create a dropdown menu for user choices in CreatiCode
Description: Students implement a CreatiCode dropdown widget that presents user choices and responds to selection changes. They test that selecting different options produces correct results. Expands widget implementation skills.

Dependencies:
* T05.G5.14: Build a clickable prototype in CreatiCode with buttons and labels
* T05.G6.01: Evaluate a design using HCD principle checklist




# === GRADE 7 (22 skills) ===
# Focus: Accessibility auditing, harm assessment, data-driven design, multimodal input testing

ID: T05.G7.01
Topic: T05 – Human‑Centered Design
Skill: Audit color contrast and text readability in a CreatiCode project
Description: Students evaluate a CreatiCode project for visual accessibility: (1) Color contrast - is text readable against its background? (2) Font size - is text large enough to read easily? (3) Spacing - is there enough white space? They document at least 2 specific issues with evidence (element name, issue description, suggested fix).

Dependencies:
* T05.G5.05a: Specify accessibility features for a target user group
* T08.G5.02: Use nested conditionals to handle multiple outcomes




ID: T05.G7.01a
Topic: T05 – Human‑Centered Design
Skill: Test keyboard navigation and timing controls in a project
Description: Students test a CreatiCode project without using a mouse: Can all buttons be reached with Tab key? Can all actions be triggered with Enter/Space? Can animations be paused? They complete a pass/fail checklist with specific evidence for each item (e.g., "Tab key skips the Settings button - FAIL").

Dependencies:
* T05.G7.01: Audit color contrast and text readability in a CreatiCode project
* T07.G5.01: Simulate repeated experiments with a loop




ID: T05.G7.01b
Topic: T05 – Human‑Centered Design
Skill: Evaluate captions and alt-text in a project
Description: Students check a CreatiCode project for media accessibility: Do videos/audio have captions? Do images have descriptive alt-text? They list each media element, mark whether accessibility text exists, and rate its quality (adequate/inadequate). For inadequate items, they write improved text.

Dependencies:
* T05.G7.01a: Test keyboard navigation and timing controls in a project




ID: T05.G7.01c
Topic: T05 – Human‑Centered Design
Skill: Compile a comprehensive accessibility report
Description: Students combine results from previous accessibility checks (visual, keyboard, media) into a structured report. Report includes: summary of pass/fail counts, prioritized list of issues by severity, and 2-3 recommended fixes with rationale. Format: table with columns for Issue, Category, Severity (High/Medium/Low), and Recommended Fix.

Dependencies:
* T05.G7.01b: Evaluate captions and alt-text in a project
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.02
Topic: T05 – Human‑Centered Design
Skill: Prioritize accessibility issues by impact and effort
Description: Students see 5-6 identified accessibility issues and drag-and-drop to rank them by priority. Ranking criteria: (1) How many users are affected? (2) Does it block core functionality? (3) How difficult is the fix? High-impact, easy-fix issues rank highest. Students justify their top 2 rankings in one sentence each.

Dependencies:
* T05.G7.01c: Compile a comprehensive accessibility report
* T08.G5.02: Use nested conditionals to handle multiple outcomes
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.03
Topic: T05 – Human‑Centered Design
Skill: Categorize potential design harms by severity
Description: Students read a project description (e.g., social app, data collection tool) and categorize potential harms by severity: critical (safety, privacy breach), major (exclusion, addiction), minor (frustration, inefficiency). They identify 3-4 potential harms from a checklist and assign severity.

Dependencies:
* T05.G5.01: Write a requirements document with multiple user stories
* T05.G5.05: Create a usability test plan with tasks and success criteria
* T08.G5.02: Use nested conditionals to handle multiple outcomes
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.03.01
Topic: T05 – Human‑Centered Design
Skill: Map potential harms to affected user groups
Description: For each identified harm (from G7.03), students identify which user groups would be most affected (e.g., "privacy risk affects users who share personal info," "addictive features affect younger users"). Builds empathy and targeted mitigation thinking.

Dependencies:
* T05.G7.03: Categorize potential design harms by severity




ID: T05.G7.03.02
Topic: T05 – Human‑Centered Design
Skill: Prioritize harms for mitigation based on severity and reach
Description: Students rank 4-5 identified harms by priority for addressing, considering both severity and how many users are affected. They create a 2x2 matrix (high/low severity x high/low reach) and place each harm, then identify top 2 for immediate action.

Dependencies:
* T05.G7.03.01: Map potential harms to affected user groups




ID: T05.G7.04
Topic: T05 – Human‑Centered Design
Skill: Match potential harms to mitigation strategies
Description: Students drag-and-drop to match each identified potential harm (privacy risk, addictive feature, exclusion) to an appropriate mitigation strategy from a provided list.

Dependencies:
* T05.G7.03: Categorize potential design harms by severity




ID: T05.G7.05
Topic: T05 – Human‑Centered Design
Skill: Interpret usage or feedback data to find UX problems
Description: Students analyze a simple data visualization (bar chart of feature usage, pie chart of user complaints, or table of task completion times) to identify patterns indicating UX problems, such as features users avoid or tasks that take too long.

Dependencies:
* T05.G5.05: Create a usability test plan with tasks and success criteria
* T05.G6.04: Map user feedback to specific design changes
* T08.G5.02: Use nested conditionals to handle multiple outcomes
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.06
Topic: T05 – Human‑Centered Design
Skill: Select design changes that address identified data patterns
Description: Students select from multiple choice options which design changes correspond logically to the identified data issues (e.g., if data shows users skip a feature, choose to make it more visible or simplify access).

Dependencies:
* T05.G7.05: Interpret usage or feedback data to find UX problems
* T08.G5.02: Use nested conditionals to handle multiple outcomes
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.07
Topic: T05 – Human‑Centered Design
Skill: Write one sentence connecting a design decision to user feedback
Description: Students complete sentence stems to connect design decisions to evidence (e.g., "We changed [X] because users said [Y]" or "Based on the data showing [A], we decided to [B]"). Activity provides 3-4 sentence starters and students fill in specific details from given user feedback or test results. Scaffolds the multi-sentence justifications required in G8.05.

Dependencies:
* T05.G7.06: Select design changes that address identified data patterns




ID: T05.G7.08
Topic: T05 – Human‑Centered Design
Skill: Test and refine a simple simulation design
Description: Students implement a simple simulation they planned (or are given a design), run it, observe behavior, and identify one improvement to make it more realistic or useful.

Dependencies:
* T05.G6.05: Plan a simple CreatiCode simulation with variables, rules, and UI
* T05.G6.08: Classify which user questions suit simulation vs other methods
* T08.G5.02: Use nested conditionals to handle multiple outcomes
* T10.G5.01: Understand table structure (rows, columns, cells)




ID: T05.G7.08.01
Topic: T05 – Human‑Centered Design
Skill: Debug a simulation by isolating faulty rule
Description: Students test a simulation producing wrong results by disabling rules one at a time to find which rule causes the error. They document their debugging process: hypothesis, test, result, conclusion. Systematic debugging for complex simulations.

Dependencies:
* T05.G7.08: Test and refine a simple simulation design
* T05.G6.10: Debug a simulation by comparing expected vs actual behavior




ID: T05.G7.09
Topic: T05 – Human‑Centered Design
Skill: Evaluate voice interface accessibility using CreatiCode speech blocks
Description: Students test a CreatiCode project's speech recognition feature with different speaking speeds, accents (if available), and background noise scenarios. They document which voice commands work reliably and which fail, identifying accessibility barriers for users with different speech patterns.

Dependencies:
* T05.G7.01c: Compile a comprehensive accessibility report
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G7.10
Topic: T05 – Human‑Centered Design
Skill: Debug hand gesture controls for accessibility
Description: Students test a CreatiCode project using hand tracking and identify usability issues: Are gestures easy to perform? Do they work at different distances from the camera? Can users with limited mobility perform them? They propose at least 2 alternative gestures or fallback controls.

Dependencies:
* T05.G7.01a: Test keyboard navigation and timing controls in a project
* T05.G7.09: Evaluate voice interface accessibility using CreatiCode speech blocks




ID: T05.G7.11
Topic: T05 – Human‑Centered Design
Skill: Design an A/B test plan for comparing two interface variants
Description: Students create a plan to compare two design variants: define what to measure (clicks, time, errors), how many users to test, how to assign users to variants randomly, and what result would indicate a "winner." Introduces controlled comparison testing.

Dependencies:
* T05.G6.07: Interpret bar chart data about user preferences
* T05.G7.05: Interpret usage or feedback data to find UX problems




ID: T05.G7.12
Topic: T05 – Human‑Centered Design
Skill: Analyze heatmap data to identify usability hotspots
Description: Students view a click heatmap from user testing and identify: (1) areas users clicked most (hotspots), (2) areas users expected to click but couldn't (rage clicks), (3) areas users ignored. They propose one design change based on the heatmap analysis.

Dependencies:
* T05.G7.05: Interpret usage or feedback data to find UX problems
* T05.G7.06: Select design changes that address identified data patterns


ID: T05.G7.13
Topic: T05 – Human‑Centered Design
Skill: Design error recovery flows for user mistakes
Description: Students map common user errors in an interface (wrong button, invalid input, accidental deletion) and design recovery paths: undo options, confirmation dialogs, helpful error messages. They sketch the error-recovery flow and explain how it preserves user confidence.

Dependencies:
* T05.G7.05: Interpret usage or feedback data to find UX problems
* T05.G7.08: Test and refine a simple simulation design


ID: T05.G7.14
Topic: T05 – Human‑Centered Design
Skill: Build adaptive UI that responds to user preferences
Description: Students implement a CreatiCode project that adjusts its interface based on stored user preferences: font size slider that persists via cloud variable, color theme toggle (light/dark), simplified vs advanced mode switch. They test that preferences persist across sessions.

Dependencies:
* T05.G7.01: Audit color contrast and text readability in a CreatiCode project
* T05.G6.12: Build a CreatiCode prototype with text-to-speech accessibility




ID: T05.G7.15
Topic: T05 – Human‑Centered Design
Skill: Implement voice input in CreatiCode using speech recognition
Description: Students build a CreatiCode prototype that accepts voice commands using the speech recognition block. They configure trigger phrases, handle recognition results, and display transcribed text. First implementation of voice-controlled interface.

Dependencies:
* T05.G6.14: Design a simple voice command flow for an app feature
* T05.G7.09: Evaluate voice interface accessibility using CreatiCode speech blocks




ID: T05.G7.16
Topic: T05 – Human‑Centered Design
Skill: Design progressive disclosure for complex features
Description: Students redesign a cluttered interface using progressive disclosure: show basic options first, reveal advanced options on demand. They identify which features are "basic" vs "advanced" and design the reveal mechanism (expand button, tabs, wizard).

Dependencies:
* T05.G7.01c: Compile a comprehensive accessibility report
* T05.G7.05: Interpret usage or feedback data to find UX problems




# === GRADE 8 (23 skills) ===
# Focus: Design briefs, AI-augmented design, chatbot design, multimodal interfaces, scalability

ID: T05.G8.01
Topic: T05 – Human‑Centered Design
Skill: Define and describe target users for a design
Description: Students write a clear description of the target user(s) for a design project, including age, experience level, needs, and context of use. They define 1-2 primary user groups and explain why they are the focus.

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G8.01a
Topic: T05 – Human‑Centered Design
Skill: Define specific design goals for a project
Description: Students write 2-3 specific, measurable design goals for a project (e.g., "Users can complete the main task in under 2 minutes," "95% of users can find the help feature"). Goals should connect to identified user needs.

Dependencies:
* T05.G8.01: Identify and describe target users for a design




ID: T05.G8.01b
Topic: T05 – Human‑Centered Design
Skill: List design constraints for a project
Description: Students identify and document constraints that will affect their design choices, including device constraints (mobile vs desktop), time constraints (deadline), accessibility requirements, and technical limitations.

Dependencies:
* T05.G8.01a: Define specific design goals for a project
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T29.G6.01: Analyze sensor specifications for CreatiCode projects




ID: T05.G8.01c
Topic: T05 – Human‑Centered Design
Skill: Combine users, goals, and constraints into a design brief
Description: Students assemble a complete design brief document that integrates target users, design goals, and constraints into a cohesive project plan. The brief serves as a reference for all subsequent design decisions.

Dependencies:
* T05.G8.01b: List design constraints for a project
* T21.G6.01.01: Make a basic ChatGPT request with one parameter




ID: T05.G8.02
Topic: T05 – Human‑Centered Design
Skill: Use XO to critique and refine a design brief
Description: Students send their brief to XO, collect critique, and incorporate at least two specific refinements.

Dependencies:
* T05.G8.01c: Combine users, goals, and constraints into a design brief
* T10.G6.01: Sort a table by a column
* T32.G6.04: Apply ethics lenses (beneficence, fairness, autonomy)




ID: T05.G8.03
Topic: T05 – Human‑Centered Design
Skill: Plan controlled simulation experiments (change one variable)
Description: Students design a simulation experiment by identifying one variable to change (independent variable, adjustable via slider), variables to keep constant (controls), and what to measure (dependent variable, logged in table). Example: "Change initial population from 10 to 50, keep food constant, measure time to reach 100."

Dependencies:
* T05.G6.05: Plan a simple CreatiCode simulation with variables, rules, and UI
* T05.G6.06: Write justifications for simulation modeling choices
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T12.G6.01: Trace complex code with multiple variables




ID: T05.G8.04
Topic: T05 – Human‑Centered Design
Skill: Draw valid conclusions from simulation results
Description: Students view a set of simulation results (tables, charts) and select appropriate conclusions from multiple choice options, identifying which conclusions are supported by data and which represent over-generalization.

Dependencies:
* T05.G8.03: Plan controlled simulation experiments (change one variable)
* T07.G6.01: Trace nested loops with variable bounds




ID: T05.G8.05
Topic: T05 – Human‑Centered Design
Skill: Explain key design decisions in terms of user needs and data
Description: Students write 2-3 sentence justifications for design choices, explicitly connecting each decision to evidence: user feedback quotes, survey data, or usability test results. Example: "We added larger buttons because 3 of 5 testers missed the small tap targets."

Dependencies:
* T05.G6.01: Evaluate a design using HCD principle checklist
* T05.G7.06: Select design changes that address identified data patterns
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals in physics simulations
* T10.G6.01: Sort a table by a column




ID: T05.G8.06
Topic: T05 – Human‑Centered Design
Skill: Evaluate a design brief for HCD principles and simulation quality
Description: Students read a sample design brief and complete a structured evaluation checklist, identifying 2-3 strengths and 2-3 gaps in user focus (empathy, needs, accessibility) and simulation planning (variables, rules, questions).

Dependencies:
* T05.G8.01c: Combine users, goals, and constraints into a design brief
* T05.G8.03: Plan controlled simulation experiments (change one variable)
* T10.G6.01: Sort a table by a column
* T32.G6.04: Apply ethics lenses (beneficence, fairness, autonomy)




ID: T05.G8.07
Topic: T05 – Human‑Centered Design
Skill: Design for multimodal input using CreatiCode speech and gesture blocks
Description: Students plan a project that supports multiple input methods (keyboard, voice via speech recognition, hand gestures via hand detection). They specify which user groups benefit from each input mode and map input types to CreatiCode blocks (speech-to-text block, hand landmark detection).

Dependencies:
* T05.G8.01c: Combine users, goals, and constraints into a design brief
* T05.G7.01c: Compile a comprehensive accessibility report




ID: T05.G8.08
Topic: T05 – Human‑Centered Design
Skill: Trace user flow through a multi-screen CreatiCode project
Description: Students draw or describe the path a user takes through a CreatiCode project with multiple scenes/screens. They identify decision points (buttons, menu choices), label what happens at each step, and predict where users might get confused or stuck.

Dependencies:
* T05.G8.01: Identify and describe target users for a design
* T05.G7.07: Write one sentence connecting a design decision to user feedback




ID: T05.G8.09
Topic: T05 – Human‑Centered Design
Skill: Compare AI-generated design suggestions to human-centered criteria
Description: Students use XO to generate design suggestions for a project idea, then evaluate each suggestion against HCD criteria (empathy, needs, accessibility). They identify which AI suggestions align with user needs and which need modification, practicing critical evaluation of AI assistance.

Dependencies:
* T05.G8.02: Use XO to critique and refine a design brief
* T05.G6.01: Evaluate a design using HCD principle checklist




ID: T05.G8.10
Topic: T05 – Human‑Centered Design
Skill: Critique AI-generated personas for bias and stereotyping
Description: Students ask XO to generate 3 user personas, then analyze each for: stereotypical assumptions, missing diversity dimensions, and unrealistic constraints. They revise one persona to be more realistic and inclusive.

Dependencies:
* T05.G8.09: Compare AI-generated design suggestions to human-centered criteria
* T05.G4.01.01: Distinguish user constraints from preferences in a persona




ID: T05.G8.11
Topic: T05 – Human‑Centered Design
Skill: Design fail-safe fallbacks for AI input methods
Description: Students plan fallback controls for when AI input methods fail: What happens if speech recognition doesn't understand? If hand tracking loses the user? They design graceful degradation (e.g., show click buttons when voice fails) and inform-user strategies.

Dependencies:
* T05.G8.07: Design for multimodal input using CreatiCode speech and gesture blocks
* T05.G7.10: Debug hand gesture controls for accessibility




ID: T05.G8.12
Topic: T05 – Human‑Centered Design
Skill: Conduct comparative analysis of HCD vs non-HCD design approaches
Description: Students see two versions of the same app: one designed with HCD process (user research, testing, iteration) and one designed without (developer assumptions only). They compare outcomes (usability scores, user satisfaction) and explain why HCD produced better results. Synthesizes topic learning.

Dependencies:
* T05.G8.06: Evaluate a design brief for HCD principles and simulation quality
* T05.G8.05: Explain key design decisions in terms of user needs and data


ID: T05.G8.13
Topic: T05 – Human‑Centered Design
Skill: Design inclusive onboarding for diverse users
Description: Students design an onboarding flow that accommodates users with different abilities, experience levels, and learning styles. They include: skip options for experienced users, audio alternatives for visual content, progress indicators, and allow-pause features. They map each onboarding element to the user group it serves.

Dependencies:
* T05.G8.07: Design for multimodal input using CreatiCode speech and gesture blocks
* T05.G8.01c: Combine users, goals, and constraints into a design brief


ID: T05.G8.14
Topic: T05 – Human‑Centered Design
Skill: Critique AI assistant responses for user context awareness
Description: Students test ChatGPT block responses in a CreatiCode chatbot and evaluate whether the AI: understands user context from previous messages, maintains appropriate conversation memory, handles ambiguous requests gracefully, and provides responses suited to the user's stated expertise level. They document gaps and propose prompt improvements.

Dependencies:
* T05.G8.09: Compare AI-generated design suggestions to human-centered criteria
* T05.G8.02: Use XO to critique and refine a design brief


ID: T05.G8.15
Topic: T05 – Human‑Centered Design
Skill: Plan scalable design systems for growing user bases
Description: Students analyze how a design should evolve as user base grows from 10 to 1000 users. They identify: which current design patterns won't scale (e.g., manual moderation), which new user segments might emerge, and which accessibility requirements become critical at scale. They create a design evolution roadmap.

Dependencies:
* T05.G8.12: Conduct comparative analysis of HCD vs non-HCD design approaches
* T05.G8.06: Evaluate a design brief for HCD principles and simulation quality




ID: T05.G8.16
Topic: T05 – Human‑Centered Design
Skill: Design a chatbot personality for a target audience
Description: Students define a chatbot's personality traits for their target users: tone (formal/casual), vocabulary level, response length, humor style. They write 3-4 sample responses showing consistent personality and explain why these traits match the audience.

Dependencies:
* T05.G8.01c: Combine users, goals, and constraints into a design brief
* T05.G8.02: Use XO to critique and refine a design brief




ID: T05.G8.17
Topic: T05 – Human‑Centered Design
Skill: Build a simple chatbot in CreatiCode using ChatGPT blocks
Description: Students implement a basic chatbot using CreatiCode's ChatGPT block. They configure system instructions to set personality, handle user input via text widget, and display AI responses. They test conversation flow and adjust for user experience.

Dependencies:
* T05.G8.16: Design a chatbot personality for a target audience
* T05.G8.14: Critique AI assistant responses for user context awareness




ID: T05.G8.18
Topic: T05 – Human‑Centered Design
Skill: Design conversation recovery for chatbot errors
Description: Students plan how their chatbot should handle misunderstandings: clarifying questions ("Did you mean...?"), graceful fallbacks ("I can help with X, Y, or Z"), and human escalation options. They write sample dialogues showing error recovery.

Dependencies:
* T05.G8.17: Build a simple chatbot in CreatiCode using ChatGPT blocks
* T05.G7.13: Design error recovery flows for user mistakes




ID: T05.G8.19
Topic: T05 – Human‑Centered Design
Skill: Test and iterate a chatbot based on user feedback
Description: Students test their chatbot with 2-3 peers, collect feedback on confusion points, and make at least 2 improvements to prompts or response handling. They document what changed and why. Completes the HCD cycle for AI interfaces.

Dependencies:
* T05.G8.18: Design conversation recovery for chatbot errors
* T05.G8.12: Conduct comparative analysis of HCD vs non-HCD design approaches




ID: T05.G8.20
Topic: T05 – Human‑Centered Design
Skill: Design an AI content moderation strategy for user safety
Description: Students plan how AI should moderate user-generated content in their app: what content to flag, block, or allow; how to inform users of violations; appeals process. They use CreatiCode's moderation block concept and design user-facing messaging.

Dependencies:
* T05.G8.17: Build a simple chatbot in CreatiCode using ChatGPT blocks
* T05.G7.03.02: Prioritize harms for mitigation based on severity and reach


# T06 - Events & Sequences (Phase 10 Optimized - November 2025)
# PHASE 10 MAJOR OVERHAUL - Bold Changes for Excellence
#
# PHILOSOPHY SHIFT: Events are about REACTIVE THINKING and CAUSE-EFFECT
# - K-2 skills now distinctly focus on TRIGGERS and WHEN-THEN thinking
#   (differentiated from T01 which covers basic sequencing)
# - Emphasis on understanding that programs WAIT for and RESPOND to events
# - Added "prediction" and "debugging" components throughout
#
# MAJOR STRUCTURAL CHANGES:
# 1. K-2 SKILLS REFOCUSED on triggers/events (not generic sequencing):
#    - GK.01: Now about WAITING for a trigger (alarm clock wakes child)
#    - GK.02-06: Strengthened trigger-action vocabulary
#    - Added GK.07-08: "Wait for" concept, multiple triggers for same action
#    - G1 skills enhanced with "WHEN...THEN" game rule thinking
#    - G2 skills bridge to code with visual event blocks
#
# 2. NEW SKILL CATEGORIES ADDED:
#    a) EVENT PRIORITY & CONFLICT (G5-G8):
#       - G5.17: Predict which event fires first when conditions overlap
#       - G6.24: Build event priority system for input handling
#       - G7.15: Resolve conflicting events with priority queues
#       - G8.17: Design event arbitration for complex multi-input systems
#
#    b) EVENT LIFECYCLE & CANCELLATION:
#       - G4.17: Stop a running script when new event arrives
#       - G5.18: Cancel pending broadcasts before they complete
#       - G6.25: Build interruptible action sequences
#
#    c) CUSTOM EVENTS & EVENT TYPES:
#       - G6.26: Create custom event types with semantic naming
#       - G7.16: Design domain-specific event vocabularies
#       - G8.18: Implement event taxonomy for large projects
#
#    d) MODERN EVENT PATTERNS:
#       - G7.17: Build observer pattern with subscription lists
#       - G8.19: Implement event sourcing for replay/undo
#       - G8.20: Build command pattern for event queueing
#
# 3. ENHANCED AI-ERA SKILLS:
#    - G5.13: Speech recognition with confidence thresholds
#    - G5.14: Hand gesture with multi-gesture recognition
#    - G7.18: Coordinate AI streaming responses with UI updates
#    - G8.21: Build adaptive event systems that learn from AI
#
# 4. SKILL QUALITY IMPROVEMENTS:
#    - All skills now have active verbs (Build, Trace, Predict, Debug)
#    - K-2 explicitly reference picture scenarios
#    - Clear auto-grading criteria for every skill
#    - Added depth through sub-skills (e.g., T06.G4.15.01, T06.G5.11.01)
#
# 5. DEPENDENCY IMPROVEMENTS:
#    - All intra-topic dependencies verified for X-2 rule
#    - Added alternative paths for key skills
#    - Stronger progression chains within each grade
#
# Previous optimizations preserved:
# - Gateway skill T06.G3.01 (foundational events)
# - Broadcast/messaging skill chain with parameters
# - Widget and UI event coverage (click, change, hover, tabs, drag)
# - 3D event coverage for G8 (collision, picking, drag, proximity)
# - Timer/clock events for timed actions
# - Event throttling and debouncing patterns
# - Event bus architecture for large-scale projects
#
# Total: 145 skills (+20 new skills for event priority, cancellation,
# custom events, modern patterns, and AI coordination)

ID: T06.GK.01
Topic: T06 – Events & Sequences
Skill: Tap the trigger that starts a chain of events in a picture story
Description: **Student task:** Look at a 3-panel picture story. Tap the picture that shows the TRIGGER - the thing that made everything else happen. **Visual scenario:** Panel 1: Alarm clock ringing loudly. Panel 2: Child waking up and stretching. Panel 3: Child getting dressed. Audio asks "What started it all? Tap the trigger!" **Correct answer:** The alarm clock (Panel 1) - this is the EVENT that triggered the actions. **Key concept:** Something has to START the action - that's the trigger/event. _Implementation note: Hot-spot click on one of 3 panels; audio explains "The trigger is what makes things happen!" Different from T01 sequencing - here we identify WHAT CAUSES the sequence, not just order. Auto-graded by panel selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine





ID: T06.GK.02
Topic: T06 – Events & Sequences
Skill: Match triggers to their actions using "WHEN...THEN" cards
Description: **Student task:** Draw lines connecting TRIGGER picture cards to matching ACTION picture cards. **Visual scenario:** Left side (WHEN triggers): (A) doorbell ringing, (B) traffic light turns red, (C) lunch bell rings. Right side (THEN actions): (1) person opens door, (2) cars stop, (3) children line up. Students draw lines: A-1, B-2, C-3. **Key concept:** WHEN the trigger happens, THEN the action follows. _Implementation note: Line-matching with 3 pairs; audio says "When the doorbell rings, then..." as hint. Different from T01 - focuses on trigger-response relationships, not just ordering. Auto-graded by correct pairings. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.01: Tap the trigger that starts a chain of events in a picture story





ID: T06.GK.03
Topic: T06 – Events & Sequences
Skill: Predict what action happens WHEN a specific trigger occurs
Description: **Student task:** See a trigger picture card, then predict which action will happen from 3 choices. **Visual scenario:** TRIGGER shown: teacher clapping hands. Answer choices: (A) children stop talking and look, (B) children keep playing, (C) children fall asleep. Audio asks "WHEN teacher claps, what happens?" **Correct answer:** (A) children stop and look. **Key concept:** Different triggers cause different actions - we can predict what happens! _Implementation note: MCQ with 3 picture choices; prediction skill using trigger-action logic. Auto-graded by selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.02: Match triggers to their actions using "WHEN...THEN" cards





ID: T06.GK.04
Topic: T06 – Events & Sequences
Skill: Identify what is WAITING for a trigger to happen
Description: **Student task:** Look at picture cards showing things that are WAITING for a trigger. Tap the picture that shows something waiting. **Visual scenario:** Cards show: (A) cat sitting by door looking at door handle - WAITING for door to open, (B) bird already flying in sky, (C) ball rolling down hill. Audio asks "Who is WAITING for something to happen?" **Correct answer:** (A) cat waiting. **Key concept:** Before an event happens, things WAIT for the trigger. Programs also wait! _Implementation note: MCQ identifying "waiting" state; introduces concept that programs wait for events. Auto-graded by selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.03: Predict what action happens WHEN a specific trigger occurs


ID: T06.GK.05
Topic: T06 – Events & Sequences
Skill: Predict what happens when a trigger is missing
Description: **Student task:** Look at a situation where the trigger does NOT happen. Predict what DOESN'T happen. **Visual scenario:** Shows: crossed-out alarm clock (alarm doesn't ring) → child in bed → [?]. Question: "The alarm didn't ring. What happens?" Choices: (A) child wakes up anyway, (B) child keeps sleeping, (C) child goes to school. **Correct answer:** (B) - without the trigger, the action doesn't happen. **Key concept:** No trigger = no action! This is why triggers are important. _Implementation note: Counterfactual reasoning; audio explains "Without the trigger, nothing happens!" Auto-graded by selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.04: Identify what is WAITING for a trigger to happen


ID: T06.GK.06
Topic: T06 – Events & Sequences
Skill: Tap which trigger does NOT match the action picture
Description: **Student task:** Look at an action picture, then find the trigger that does NOT cause this action. **Visual scenario:** Action: Children running inside the classroom. Triggers: (A) recess bell ringing - YES causes this, (B) teacher waving "come in" - YES causes this, (C) sunny day outside - NO, doesn't cause running inside. **Correct answer:** (C) sunny day. **Key concept:** Not every event triggers every action - triggers and actions must match! _Implementation note: Inverse matching MCQ with 3 trigger options; builds negative reasoning. Auto-graded by selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.05: Predict what happens when a trigger is missing


ID: T06.GK.07
Topic: T06 – Events & Sequences
Skill: Identify that the SAME action can have DIFFERENT triggers
Description: **Student task:** Look at one action picture, then select TWO different triggers that could both cause this action. **Visual scenario:** Action: Child waking up. Triggers: (A) alarm clock ringing, (B) mom calling "wake up!", (C) cat sleeping. Select TWO that wake the child. **Correct answers:** (A) and (B) - both can wake a child! **Key concept:** Many different events can cause the same thing to happen. _Implementation note: Multi-select MCQ (pick 2 from 3); introduces concept that multiple events can trigger same action. Auto-graded by both correct. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.06: Tap which trigger does NOT match the action picture


ID: T06.GK.08
Topic: T06 – Events & Sequences
Skill: Match computer game triggers to picture block representations
Description: **Student task:** Match 3 game triggers to their picture representations of event blocks. **Visual scenario:** Left (game actions): (1) Game starts = green flag picture, (2) Press space key = keyboard picture, (3) Click on character = mouse clicking picture. Right (illustrated blocks with matching colors). Students draw lines to match. **Key concept:** In computer programs, we use special blocks to say "WHEN this happens, do something." _Implementation note: Line-matching bridging to code concepts; prepares for G3 coding. Auto-graded by correct pairings. CSTA: EK-ALG-AF-01._

Dependencies:
* T06.GK.07: Identify that the SAME action can have DIFFERENT triggers


ID: T06.G1.01
Topic: T06 – Events & Sequences
Skill: Complete "WHEN...THEN" game rules by matching triggers to actions
Description: **Student task:** Complete 4 game rules by matching trigger pictures to action pictures. Rules are shown as "WHEN [?] → THEN [?]" templates. **Visual scenario:** Rule templates with trigger and action slots. Triggers: (A) player lands on star space, (B) player rolls a 6, (C) player draws red card, (D) timer buzzes. Actions: (1) take extra turn, (2) get bonus points, (3) go back 2 spaces, (4) game ends. Students create valid rules: A→2, B→1, C→3, D→4. **Key concept:** Games have RULES that say "WHEN this happens, THEN do that" - just like computer programs! _Implementation note: Drag triggers/actions into rule templates; introduces game-rule thinking. Auto-graded by valid rule creation. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.GK.08: Match computer game triggers to picture block representations





ID: T06.G1.02
Topic: T06 – Events & Sequences
Skill: Predict what happens when TWO triggers occur in order
Description: **Student task:** See 2 triggers happen in sequence, predict the combined result. **Visual scenario:** Trigger 1: Child presses elevator button (door opens). Trigger 2: Child presses floor 5 button. Question: "What happens after BOTH triggers?" Choices: (A) elevator goes to floor 5, (B) door stays open, (C) nothing happens. **Correct answer:** (A) - the triggers together cause the elevator ride. **Key concept:** Sometimes we need MULTIPLE events in the right order to make something happen. _Implementation note: MCQ with sequential trigger reasoning; introduces concept of event ordering. Auto-graded by selection. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.G1.01: Complete "WHEN...THEN" game rules by matching triggers to actions





ID: T06.G1.03
Topic: T06 – Events & Sequences
Skill: Identify ONE trigger that causes MULTIPLE actions at the same time
Description: **Student task:** See one trigger, select ALL the actions that happen together from it. **Visual scenario:** TRIGGER: Fire alarm goes off in school. Actions: (A) lights start flashing - YES, (B) children line up - YES, (C) teacher reads book - NO, (D) children walk outside - YES (shortly after). Select all that happen BECAUSE of the alarm. **Correct answers:** A, B, D. **Key concept:** One trigger can cause MANY things to happen at once - like pressing one button starting a whole program! _Implementation note: Multi-select MCQ (pick 3 from 4); introduces parallel/multiple actions from single event. Auto-graded by all correct. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.G1.02: Predict what happens when TWO triggers occur in order





ID: T06.G1.04
Topic: T06 – Events & Sequences
Skill: Debug a broken game rule by fixing the wrong trigger
Description: **Student task:** A game rule isn't working right. Find and fix the wrong trigger. **Visual scenario:** Rule card shows: "WHEN player touches monster, THEN get a point." But picture shows player getting hurt, not getting points! Students identify the trigger is wrong - touching monsters should hurt, not help. Fix: change trigger to "touches coin" OR change action to "lose a life". **Key concept:** When things don't work right, check if the trigger matches the action! _Implementation note: Debugging task with picture-based reasoning; introduces "debugging" at K-2 level. Auto-graded by valid fix. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.G1.03: Identify ONE trigger that causes MULTIPLE actions at the same time


ID: T06.G1.05
Topic: T06 – Events & Sequences
Skill: Design your own 3-rule game using trigger-action pairs
Description: **Student task:** Create 3 game rules by dragging triggers and actions to make a complete mini-game. **Visual scenario:** Rule slots 1-3 with empty "WHEN [?] THEN [?]" templates. Trigger options: start flag, touch star, timer ends, press button. Action options: get point, lose life, game over, character jumps. Students create 3 valid rules. Example: "WHEN start flag → character appears", "WHEN touch star → get point", "WHEN timer ends → game over". **Key concept:** Games are made of MANY trigger-action rules working together! _Implementation note: Creative design task with multiple valid solutions; validates each rule is logical. Auto-graded by 3 valid rules. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.G1.04: Debug a broken game rule by fixing the wrong trigger


ID: T06.G1.06
Topic: T06 – Events & Sequences
Skill: Put 4 game events in the order they should happen
Description: **Student task:** Drag 4 game event cards into the correct order for a game to work. **Visual scenario:** Cards (out of order): (A) Player touches goal - GAME WIN, (B) Player presses start - GAME BEGINS, (C) Player collects 3 coins - SCORE SHOWN, (D) Game asks for player name - SETUP. Correct order: D → B → C → A. **Key concept:** Game events have a logical order - some must happen before others! _Implementation note: Drag-drop ordering with 4 cards; introduces event sequencing in game context. Auto-graded by final order. CSTA: E1-ALG-AF-01._

Dependencies:
* T06.G1.05: Design your own 3-rule game using trigger-action pairs


ID: T06.G2.01
Topic: T06 – Events & Sequences
Skill: Build a chain where each event TRIGGERS the next event
Description: **Student task:** Drag 4 picture cards into a chain where each event becomes the TRIGGER for the next. **Visual scenario:** Cards show: (A) button pressed, (B) bell rings, (C) dog hears bell, (D) dog runs to door. Correct chain: A → B → C → D. Arrow labels show: "triggers" between each card. Audio explains "Each event becomes the trigger for the next!" **Key concept:** Events can CHAIN together - one event's action becomes another event's trigger. _Implementation note: Drag-drop chain building with "triggers" arrows appearing; introduces cascading/chained events. Auto-graded by chain order. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G1.06: Put 4 game events in the order they should happen





ID: T06.G2.02
Topic: T06 – Events & Sequences
Skill: Draw lines connecting multiple triggers to ONE shared action
Description: **Student task:** Draw lines from 4 different trigger cards to the ONE action they all cause. **Visual scenario:** Action card in center: "Character jumps" (in a game). Trigger cards around it: (A) press spacebar, (B) click mouse, (C) say "jump!", (D) tap screen. ALL 4 triggers → same action! **Key concept:** In games and programs, MANY different events can trigger the same action. This lets different players use different controls! _Implementation note: Multi-to-one line matching with 4 triggers; demonstrates event flexibility. Auto-graded by all 4 connections correct. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.01: Build a chain where each event TRIGGERS the next event





ID: T06.G2.03
Topic: T06 – Events & Sequences
Skill: Complete an "If ___ then ___" game rule by selecting pictures
Description: **Student task:** Complete a game rule by choosing the correct trigger and action from picture options. **Visual scenario:** Rule template: "IF [?] THEN [?]". Trigger choices: (A) landing on star space, (B) rolling dice, (C) picking up card. Action choices: (1) move forward 2, (2) skip turn, (3) draw card. Example correct rule: IF (A) THEN (1) - "If you land on star, move forward 2." _Implementation note: Two-part MCQ to build if-then rule; drag trigger and action pictures into template. Auto-graded by valid rule creation. Bridges to event-based game coding. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.02: Draw lines from 3 different triggers to 1 shared action card


ID: T06.G2.04
Topic: T06 – Events & Sequences
Skill: Sort 4 event cards into "trigger" and "action" categories
Description: **Student task:** Drag 4 picture cards into two category boxes: "TRIGGERS" (things that start something) and "ACTIONS" (things that happen). **Visual scenario:** Cards: (A) pressing doorbell button = trigger, (B) door opening = action, (C) fire alarm going off = trigger, (D) people running outside = action. _Implementation note: Category sorting with 2 boxes; reinforces trigger vs action distinction. Audio explains "Triggers START things. Actions are what HAPPENS." Auto-graded by correct categorization. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.01: Drag 4 picture cards to build a cause-effect chain


ID: T06.G2.05
Topic: T06 – Events & Sequences
Skill: Identify TWO different actions that can happen from one trigger
Description: **Student task:** Look at one trigger picture and choose TWO action pictures that could both happen from that trigger. **Visual scenario:** Trigger: teacher clapping hands. Action choices: (A) students stop talking, (B) students look at teacher, (C) fish swims in tank, (D) bird flies away. **Correct answers:** A AND B - both happen when teacher claps. _Implementation note: Multi-select MCQ (pick 2 from 4); introduces concept that one trigger can cause multiple simultaneous actions. Audio says "Pick TWO things that happen!" Auto-graded by both correct selections. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.04: Sort 4 event cards into "trigger" and "action" categories


ID: T06.G2.06
Topic: T06 – Events & Sequences
Skill: Match picture if-then rules to illustrated event block types
Description: **Student task:** Match 4 picture-based if-then rules to illustrations of Scratch-style event blocks. **Visual scenario:** Left side shows picture rules: (1) "If game starts → show cat" matches illustrated green flag block, (2) "If spacebar pressed → cat jumps" matches illustrated key block, (3) "If cat is clicked → cat says meow" matches illustrated sprite-click block, (4) "If touching wall → cat bounces" matches illustrated touch-sensing block. **Activity:** Drag lines connecting picture rules to block illustrations. _Implementation note: Bridge activity from picture-based K-2 to code-based G3; uses simple block illustrations (not actual code). Audio reads rules aloud. Auto-graded by correct matches. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.05: Identify TWO different actions that can happen from one trigger
* T06.G2.03: Complete an "If ___ then ___" game rule by selecting pictures


ID: T06.G2.07
Topic: T06 – Events & Sequences
Skill: Identify that one trigger starts multiple actions happening at the same time
Description: **Student task:** Look at a picture showing one trigger causing TWO things to happen at once (not in sequence). Tap which picture shows "both at the same time." **Visual scenario:** Trigger: Teacher claps hands. Options: (A) First students stop talking, THEN students look at teacher (sequential - shown with 1,2 numbers), (B) Students stop talking AND look at teacher at the same time (parallel - shown with both actions circled together), (C) Only students stop talking (incomplete). **Correct answer:** (B) - both actions start immediately when teacher claps. _Implementation note: Introduces the concept that one event can trigger multiple responses running together (parallel execution). This bridges to G3's multi-script sprites where clicking green flag runs multiple scripts simultaneously. Audio explains "Both happen at once!" Auto-graded by selection. CSTA: E2-ALG-AF-01._

Dependencies:
* T06.G2.05: Identify TWO different actions that can happen from one trigger
* T06.G2.06: Match picture if-then rules to illustrated event block types


ID: T06.G3.01
Topic: T06 – Events & Sequences
Skill: Build a 3-block "when green flag clicked" script that makes a sprite move and speak
Description: Students create their first event-driven program using the "when green flag clicked" block followed by 2-3 action blocks (e.g., move 50 steps → say "Hello!" for 2 seconds → change costume). **Gateway skill:** This introduces the foundational concept that all programs start with event blocks and execute actions in sequence. Students observe that clicking the green flag triggers their code. _Auto-graded: Check script has green flag hat + at least 2 motion/looks blocks. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G2.03: Complete an "If ___ then ___" game rule by selecting pictures
* T01.G2.02: Select the shorter "repeat" version of directions





ID: T06.G3.02
Topic: T06 – Events & Sequences
Skill: Use "prepare for green flag click" to set starting position before main script runs
Description: Students use the "prepare for green flag click" block to reset a sprite's position and appearance before the main green flag script runs. Example: In "prepare for green flag click" set x to -200, y to 0, switch costume to "idle". This runs BEFORE regular "when green flag clicked" scripts. Students compare behavior with and without initialization to understand why setup matters. _Auto-graded: Check prepare block sets position or costume. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.01: Build a 3-block "when green flag clicked" script that makes a sprite move and speak





ID: T06.G3.03
Topic: T06 – Events & Sequences
Skill: Build a "when [right arrow] key pressed" script to move a sprite right
Description: Students create a "when [right arrow] key pressed" script containing "change x by 10" to move a sprite to the right when the key is pressed. This introduces keyboard events as a second event type beyond green flag. Students test by pressing the key multiple times and observing the sprite move. _Auto-graded: Check "when key pressed" hat block exists with motion block inside. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.01: Build a 3-block "when green flag clicked" script that makes a sprite move and speak





ID: T06.G3.04
Topic: T06 – Events & Sequences
Skill: Build a "when this sprite clicked" script to make a sprite react to clicks
Description: Students create a "when this sprite clicked" script that triggers an action when the sprite is clicked (e.g., say "Ouch!" → change costume → play "pop" sound). This completes the trio of basic event types: green flag, key press, and sprite click. Students click the sprite during runtime to test. _Auto-graded: Check "when this sprite clicked" hat exists with at least one looks/sound block. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.03: Build a "when [right arrow] key pressed" script to move a sprite right





ID: T06.G3.05
Topic: T06 – Events & Sequences
Skill: Build a "when backdrop switches to [scene2]" script to respond to scene changes
Description: Students create a "when backdrop switches to [scene2]" script that triggers actions when the backdrop changes (e.g., hide sprite, play different music, move to new position). Students use "switch backdrop to [scene2]" in another script to test. This introduces scene-based events for multi-scene stories. _Auto-graded: Check "when backdrop switches to" hat exists with action blocks. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.04: Build a "when this sprite clicked" script to make a sprite react to clicks





ID: T06.G3.06
Topic: T06 – Events & Sequences
Skill: Build a "when I start as a clone" script to initialize cloned sprites differently
Description: Students create a "when I start as a clone" script that runs only for cloned sprites, not the original (e.g., go to random position, set size to 50%, glide for 2 seconds, delete this clone). Use "create clone of myself" to spawn clones. This shows that clones can have different initialization than the original sprite. _Auto-graded: Check "when I start as a clone" hat exists with setup blocks; project creates clones. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.04: Build a "when this sprite clicked" script to make a sprite react to clicks





ID: T06.G3.07
Topic: T06 – Events & Sequences
Skill: Match 5 code snippets to descriptions of when they run
Description: Students read 5 short scripts with different event hat blocks (green flag, key pressed, sprite clicked, backdrop switches, clone start) and match each to the correct plain-language description. Example matches: "when green flag clicked → move 10" matches "This runs when the game starts"; "when space key pressed → jump" matches "This runs when you press space." _Auto-graded: MCQ matching with 5 pairs. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.06: Build a "when I start as a clone" script to initialize cloned sprites differently





ID: T06.G3.08
Topic: T06 – Events & Sequences
Skill: Select the correct event type for 5 different game behaviors
Description: Given 5 game behaviors, students select the appropriate event type from a list. Examples: "Initialize game" → green flag; "Player jumps" → key pressed; "Coin collected" → sprite clicked; "Enter new level" → backdrop switches; "Bullet spawns" → when I start as a clone. _Auto-graded: MCQ with 5 behavior-to-event matches. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.07: Match 5 code snippets to descriptions of when they run





ID: T06.G3.09
Topic: T06 – Events & Sequences
Skill: Trace a 4-block green flag script and predict the sprite's final position
Description: Given a "when green flag clicked" script with 4 blocks (e.g., go to x:0 y:0 → move 50 steps → turn 90 degrees → move 30 steps), students trace the execution and predict the sprite's final x,y position. _Auto-graded: MCQ asking final position from 4 choices. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.08: Select the correct event type for 5 different game behaviors
* T07.G3.02: Trace a script with a simple loop





ID: T06.G3.10
Topic: T06 – Events & Sequences
Skill: Trace a project with 2 events and predict what happens for each trigger
Description: Given a sprite with two scripts ("when green flag clicked → say 'Ready!'" and "when space key pressed → move 50 steps"), students answer: (1) What happens when you click green flag only? (2) What happens when you press space only? This tests understanding that different events trigger different scripts independently. _Auto-graded: Two MCQ questions about separate behaviors. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.09: Trace a 4-block green flag script and predict the sprite's final position





ID: T06.G3.11
Topic: T06 – Events & Sequences
Skill: Debug a script by adding the missing event hat block
Description: Given an orphaned script without a hat block (e.g., "move 50 steps → say 'Go!'"), students identify that it won't run and add the correct event block based on the intended behavior described (e.g., "This should run when the game starts" → add "when green flag clicked"). _Auto-graded: Check added event hat matches specification. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.10: Trace a project with 2 events and predict what happens for each trigger





ID: T06.G3.12
Topic: T06 – Events & Sequences
Skill: Debug a script by changing the wrong event type to the correct one
Description: Given a buggy script where the event type doesn't match the intended behavior (e.g., "when green flag clicked → change x by 10" but description says "move right when pressing right arrow"), students identify the mismatch and replace the event block with the correct one. _Auto-graded: Check correct event hat is used. CSTA: E3-PRO-PF-01._

Dependencies:
* T06.G3.11: Debug a script by adding the missing event hat block






ID: T06.G3.13
Topic: T06 – Events & Sequences
Skill: Identify which sprite should own which event handler in a 2-sprite game
Description: Given a simple 2-sprite game description (Cat sprite collects Fish sprite), students identify where each event handler belongs. **Scenario:** "When the game starts, the cat should go to the left side. When the fish is clicked, it should disappear." Students select: (1) "when green flag clicked → go to x:-200" belongs to Cat sprite, (2) "when this sprite clicked → hide" belongs to Fish sprite. **Why important:** Prepares for G4's broadcast communication by establishing that sprites own their own behaviors. _Auto-graded: MCQ matching handlers to sprites. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.10: Trace a project with 2 events and predict what happens for each trigger
* T06.G3.04: Build a "when this sprite clicked" script to make a sprite react to clicks

ID: T06.G4.01
Topic: T06 – Events & Sequences
Skill: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements
Description: Students create a sprite with 5 separate event scripts: (1) "when green flag clicked" → reset position to center; (2-5) "when [up/down/left/right] arrow key pressed" → move in that direction. This demonstrates a sprite with multiple event handlers working together. _Auto-graded: Check sprite has green flag + 4 arrow key event scripts. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G3.12: Debug a script by changing the wrong event type to the correct one





ID: T06.G4.02
Topic: T06 – Events & Sequences
Skill: Trace a multi-script sprite and list which scripts run for each input
Description: Given a sprite with 4 event scripts (green flag, space key, sprite click, left arrow), students answer questions like: "Which scripts run when you click green flag then press left arrow?" Students list the script execution sequence. _Auto-graded: MCQ identifying correct script(s) that fire for given input sequence. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.01: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements





ID: T06.G4.03
Topic: T06 – Events & Sequences
Skill: Explain why broadcast is needed for inter-sprite communication
Description: Given a scenario where one sprite needs to tell another sprite to act (e.g., "when player touches goal, the door sprite should open"), students select "broadcast" as the correct communication method from options: (A) just use variables, (B) broadcast a message, (C) use a loop. Students explain that broadcasts let sprites send signals to each other. _Auto-graded: MCQ + short answer explaining broadcast purpose. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.02: Trace a multi-script sprite and list which scripts run for each input





ID: T06.G4.04
Topic: T06 – Events & Sequences
Skill: Build a broadcast sender in one sprite and a receiver in another sprite
Description: Students create a two-sprite communication: Sprite A has "when this sprite clicked → broadcast 'go'" and Sprite B has "when I receive 'go' → say 'Moving!' → glide to x:100 y:0". Clicking Sprite A causes Sprite B to move. _Auto-graded: Check broadcast block in one sprite and matching receive block in another. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.03: Explain why broadcast is needed for inter-sprite communication





ID: T06.G4.05
Topic: T06 – Events & Sequences
Skill: Use "broadcast and wait" to ensure actions happen in sequence
Description: Students replace "broadcast [message]" with "broadcast [message] and wait" to make the sender sprite wait until all receivers finish before continuing. Example: Sprite A says "Ready?" → broadcasts 'action' and waits → says "Done!" vs regular broadcast where "Done!" appears immediately. Students compare both behaviors to understand sequencing. _Auto-graded: Check "broadcast and wait" block is used with sequential actions after it. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.04: Build a broadcast sender in one sprite and a receiver in another sprite





ID: T06.G4.06
Topic: T06 – Events & Sequences
Skill: Draw lines matching 3 broadcast blocks to their receiver scripts across sprites
Description: Given a project diagram showing 3 sprites with broadcast and receive blocks, students draw lines connecting each "broadcast [X]" to all "when I receive [X]" scripts that respond. Example: broadcast 'start' connects to 2 receivers (sprite B and sprite C both have 'when I receive start'). _Auto-graded: Line matching with multiple senders and receivers. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.04: Build a broadcast sender in one sprite and a receiver in another sprite





ID: T06.G4.07
Topic: T06 – Events & Sequences
Skill: Debug a sprite by fixing the wrong key in a "when key pressed" event
Description: Given a buggy project where pressing 'space' should make the sprite jump but nothing happens, students examine the script and find the event says "when [a] key pressed" instead of "when [space] key pressed". Students change the key parameter to fix the bug. This builds on G3.12 with focus on parameter errors in multi-script contexts. _Auto-graded: Check event parameter matches intended key. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.02: Trace a multi-script sprite and list which scripts run for each input





ID: T06.G4.08
Topic: T06 – Events & Sequences
Skill: Debug a project by adding the missing "when I receive" script
Description: Given a project where Sprite A broadcasts 'explode' but Sprite B doesn't respond, students add a "when I receive 'explode'" script to Sprite B with appropriate actions (e.g., switch costume to 'explosion', play sound, hide). This fixes the missing receiver bug. _Auto-graded: Check Sprite B has receive block matching Sprite A's broadcast. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.06: Draw lines matching 3 broadcast blocks to their receiver scripts across sprites





ID: T06.G4.09
Topic: T06 – Events & Sequences
Skill: Build a "when touching [coin]" script that plays a sound and hides the coin
Description: Students create a collision event using "when touching [player]" on the coin sprite that triggers: play 'collect' sound → hide. When the player sprite moves to touch the coin, the coin responds automatically. This introduces collision events as a trigger type. _Auto-graded: Check "when touching sprite" event with hide or effect. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.01: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements





ID: T06.G4.10
Topic: T06 – Events & Sequences
Skill: Build a "when touching [edge]" script to bounce a sprite off walls
Description: Students create a "when touching [edge]" script on a moving sprite that triggers: turn 180 degrees (or if on edge, bounce). This makes sprites bounce off stage boundaries automatically. Students test by making the sprite move continuously and watching it bounce. _Auto-graded: Check "when touching edge" event with turn or bounce block. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.09: Build a "when touching [coin]" script that plays a sound and hides the coin





ID: T06.G4.11
Topic: T06 – Events & Sequences
Skill: Build a "when touching color [red]" script to detect lava and lose a life
Description: Students create a "when touching color [red]" script that triggers when the sprite touches red areas of the backdrop (representing lava/danger): say "Ouch!" → change lives by -1 → go to start position. This introduces color-based collision for environment interactions. _Auto-graded: Check "when touching color" event with consequence actions. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.09: Build a "when touching [coin]" script that plays a sound and hides the coin





ID: T06.G4.12
Topic: T06 – Events & Sequences
Skill: Build a green flag initialization script that resets all game variables
Description: Students create a comprehensive "when green flag clicked" initialization: set score to 0 → set lives to 3 → go to x:-200 y:0 → show → switch costume to 'idle'. Students compare a game with proper initialization vs without (where score accumulates across runs) to understand why reset matters. _Auto-graded: Check green flag script sets at least 2 variables to initial values. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.01: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements
* T09.G3.01.01: Create a new variable with a descriptive name





ID: T06.G4.13
Topic: T06 – Events & Sequences
Skill: Build paired "when key pressed" and "when key released" scripts for hold actions
Description: Students create both "when [right arrow] key pressed → set moving to 1" and "when [right arrow] key released → set moving to 0". In a forever loop, check: if moving = 1, change x by 5. This creates smooth movement that continues while key is held. Students compare tap vs hold behavior. _Auto-graded: Check both key pressed and key released events for same key. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.01: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements
* T09.G4.01: Use addition (+) in variable expressions





ID: T06.G4.14
Topic: T06 – Events & Sequences
Skill: Build a key binding system using variable-based key events
Description: Students create customizable controls using "when key [jumpKey] pressed" where jumpKey is a variable. At start, set jumpKey to 'space'. Add a settings option where clicking a button asks for input and sets jumpKey to the user's choice. This enables players to customize their controls. _Auto-graded: Check event uses variable for key name, not hardcoded value. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.13: Build paired "when key pressed" and "when key released" scripts for hold actions


ID: T06.G4.15
Topic: T06 – Events & Sequences
Skill: Build a "when <condition>" event that triggers when a threshold is crossed
Description: Students create their first condition-based event using "when <(score) > [10]>" that triggers automatically when the score exceeds 10: say "Level up!" → change backdrop. **Key concept:** Unlike polling with "forever if score > 10", this event fires exactly once when the condition becomes true (not every frame). Students test by incrementing score and observing the event triggers at 11, not continuously. Compare: condition event fires once on transition vs forever-if fires every frame while true. _Auto-graded: Check "when <condition>" event exists with comparison; event fires once on threshold crossing. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.12: Build a green flag initialization script that resets all game variables
* T06.G4.11: Build a "when touching color [red]" script to detect lava and lose a life


ID: T06.G4.16
Topic: T06 – Events & Sequences
Skill: Add "say" logging to event handlers to trace which events fire and in what order
Description: Students add temporary "say [event name]" blocks at the start of each event handler to see when they fire: "say 'green flag fired'" in green flag script, "say 'space pressed'" in key event, etc. Given a project with 4 events, students add logging, run the project with specific inputs, and record the order events appeared. **Example:** Click green flag then press space twice → should see "green flag fired" then "space pressed" twice. This introduces systematic debugging of event timing. _Auto-graded: Logging added to 4 events + correct execution order recorded. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.02: Trace a multi-script sprite and list which scripts run for each input
* T06.G4.07: Debug a sprite by fixing the wrong key in a "when key pressed" event


ID: T06.G4.17
Topic: T06 – Events & Sequences
Skill: Use "stop other scripts in sprite" to cancel running actions when new event arrives
Description: Students create an interruptible animation: one key starts a long animation (say "1" → wait 1 → say "2" → wait 1 → say "3"), another key adds "stop other scripts in sprite" at start to cancel any running animation before starting its own. **Scenario:** Press A to count 1-2-3, press B anytime to interrupt and start over. **Key concept:** Sometimes a new event should STOP what's currently happening. This prevents overlapping animations and conflicting states. _Auto-graded: "stop other scripts in sprite" used in at least one event handler; observable interruption behavior. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.02: Trace a multi-script sprite and list which scripts run for each input
* T06.G4.01: Build a sprite with 5 event handlers: green flag setup + 4 arrow key movements


ID: T06.G4.15.01
Topic: T06 – Events & Sequences
Skill: Compare "when <condition>" event vs "forever if <condition>" polling
Description: Students build the SAME behavior two ways: (1) Using "when <score > 10>" event (fires once), (2) Using "forever: if score > 10 then..." (fires every frame while true). **Observation task:** Run both versions, increment score to 11, 12, 13. Event version: shows "Level up!" once. Polling version: keeps showing message every frame. Students write 2-3 sentences explaining when each approach is better. **Key insight:** Events are cleaner for "when something changes" while polling is for continuous checking. _Auto-graded: Both versions implemented + written comparison of one-time vs repeated firing. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.15: Build a "when <condition>" event that triggers when a threshold is crossed


ID: T06.G5.01
Topic: T06 – Events & Sequences
Skill: Identify and add a comment labeling the game-start initialization pattern
Description: Given an existing game project, students find the green flag initialization script (the one that sets score=0, lives=3, positions sprites) and add a comment: "-- GAME START: Initialize all game state --". Students explain in 1-2 sentences why this pattern must run before other scripts. _Auto-graded: Check comment added to correct script + explanation provided. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.12: Build a green flag initialization script that resets all game variables
* T09.G3.03: Use variables in expressions


ID: T06.G5.01.01
Topic: T06 – Events & Sequences
Skill: Trace the reset-level broadcast pattern and draw sender-receiver arrows
Description: Given a game with a "reset-level" broadcast, students trace the flow: (1) Find the sprite that broadcasts 'reset-level', (2) Find all sprites with "when I receive 'reset-level'" scripts, (3) Draw arrows from sender to each receiver, (4) Label each receiver's action (e.g., "enemy: go to start", "player: reset position"). _Auto-graded: Diagram with correct arrows + labels for 3+ sprites. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G5.01: Identify and add a comment labeling the game-start initialization pattern
* T06.G4.06: Draw lines matching 3 broadcast blocks to their receiver scripts across sprites


ID: T06.G5.01.02
Topic: T06 – Events & Sequences
Skill: Identify collision event patterns and explain their game logic purpose
Description: Students find all collision events in a game ("when touching sprite", "when touching color", "when touching edge") and create a table with columns: Trigger Sprite, Collision Type, Target, Game Effect. Example row: "Player | touching sprite | Coin | Score +10, coin hides". Students explain one collision's cause-effect chain. _Auto-graded: Table with 3+ collision events + one explanation. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G5.01.01: Trace the reset-level broadcast pattern and draw sender-receiver arrows
* T06.G4.09: Build a "when touching [coin]" script that plays a sound and hides the coin


ID: T06.G5.01.03
Topic: T06 – Events & Sequences
Skill: Identify "when <condition>" state-change patterns and explain when they fire
Description: Students find "when <condition>" blocks in a game (e.g., "when <score > 100>", "when <lives = 0>") and explain: (1) What state is being watched? (2) When does this fire? (3) What action happens? Example: "when <lives = 0>" watches the lives variable; fires when lives reaches zero; shows game over screen. _Auto-graded: Identify 2+ condition events with correct explanations. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G5.01.02: Identify collision event patterns and explain their game logic purpose
* T06.G4.15: Build a "when <condition>" event that triggers when a threshold is crossed





ID: T06.G5.02
Topic: T06 – Events & Sequences
Skill: Add a new "when [p] key pressed" pause feature to an existing game
Description: Given a working game, students add a new event handler: "when [p] key pressed → toggle paused variable (if paused=0 set to 1, else set to 0)". Existing game loops check "if paused = 0" before moving. This adds a pause feature without breaking existing functionality. _Auto-graded: Check new key event added + pause toggle logic works. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.07: Debug a sprite by fixing the wrong key in a "when key pressed" event
* T06.G4.08: Debug a project by adding the missing "when I receive" script





ID: T06.G5.03
Topic: T06 – Events & Sequences
Skill: Build a level-start/level-end broadcast sequence coordinating 3 sprites
Description: Students create a level transition system: (1) Controller sprite broadcasts 'level-start' when level begins, (2) Player/Enemy/UI sprites each have "when I receive 'level-start'" scripts that reset positions/show themselves, (3) When level ends, broadcast 'level-end' hides enemies and shows victory. _Auto-graded: Check level-start and level-end broadcasts with 3+ receivers. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.08: Debug a project by adding the missing "when I receive" script





ID: T06.G5.04
Topic: T06 – Events & Sequences
Skill: Trace execution order when player clicks green flag then presses space twice
Description: Given a project with green flag init, space key event, and broadcasts, students trace what happens when: (1) Click green flag, (2) Press space, (3) Press space again. List all scripts that run in order, noting when broadcasts trigger receivers. Example: "1. Green flag: init → 2. Space: broadcast 'jump' → 3. Receive 'jump': player jumps..." _Auto-graded: Correct sequence of 6+ script executions. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G4.07: Debug a sprite by fixing the wrong key in a "when key pressed" event
* T06.G5.03: Build a level-start/level-end broadcast sequence coordinating 3 sprites





ID: T06.G5.05
Topic: T06 – Events & Sequences
Skill: Debug and fix two event handlers that conflict with each other
Description: Given a buggy project where pressing space both jumps AND shoots (two separate "when space pressed" scripts interfere), students diagnose the conflict and fix it by: (A) changing one key to a different key, OR (B) combining into one handler with mode checking. Students explain why two handlers for the same event can cause issues. _Auto-graded: Conflict resolved + explanation provided. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.07: Debug a sprite by fixing the wrong key in a "when key pressed" event
* T06.G5.04: Trace execution order when player clicks green flag then presses space twice





ID: T06.G5.06
Topic: T06 – Events & Sequences
Skill: Add structured comments to 4 event handlers following a template
Description: Students add comments to 4 different event scripts using template: "-- TRIGGER: [what causes this] / ACTION: [what it does] / PURPOSE: [why needed]". Example: "-- TRIGGER: Player touches coin / ACTION: Score +10, hide coin / PURPOSE: Reward collection". This creates self-documenting event code. _Auto-graded: 4 event handlers with structured comments. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.01.03: Identify "when <condition>" state-change patterns and explain when they fire
* T03.G5.01: Write a feature list with subtasks for each feature





ID: T06.G5.07
Topic: T06 – Events & Sequences
Skill: Build a "when <lives = 0>" event that triggers game over automatically
Description: Students create a "when <(lives) = [0]>" event script that triggers automatically when the lives variable reaches zero: broadcast 'game-over' → show game over sprite → stop all. Compare to polling approach (forever if lives=0) to understand reactive vs polling design. _Auto-graded: Check "when <condition>" event exists with lives=0 check. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.01.03: Identify "when <condition>" state-change patterns and explain when they fire
* T09.G4.01: Use addition (+) in variable expressions





ID: T06.G5.08
Topic: T06 – Events & Sequences
Skill: Build a "broadcast with parameter" to send damage amount to player
Description: Students use "broadcast 'take-damage' with parameter [damageAmount]" where damageAmount varies (5 for small enemy, 20 for boss). The receiver uses the parameter to reduce health by the correct amount. This introduces parameterized messaging for flexible event communication. _Auto-graded: Check broadcast with parameter used; parameter value affects receiver behavior. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.03: Build a level-start/level-end broadcast sequence coordinating 3 sprites
* T09.G4.01: Use addition (+) in variable expressions





ID: T06.G5.09
Topic: T06 – Events & Sequences
Skill: Build a receiver that captures broadcast parameter and uses it in calculations
Description: Students create "when I receive 'take-damage' with parameter [damage]" script that: say "Ouch!" → change health by (0 - damage). The damage variable captures whatever value was sent. Students test with different damage amounts to verify the parameter is correctly received. _Auto-graded: Check receive-with-parameter block; parameter variable used in script. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.08: Build a "broadcast with parameter" to send damage amount to player





ID: T06.G5.10
Topic: T06 – Events & Sequences
Skill: Use "broadcast with parameter and wait" for sequenced dialogue with speaker names
Description: Students create a dialogue system: broadcast 'speak' with parameter 'Hero: Hello!' and wait → broadcast 'speak' with parameter 'Villain: We meet again!' and wait. The receiver displays each message in sequence. The "and wait" ensures lines appear one after another. _Auto-graded: Check broadcast-with-parameter-and-wait used; messages display in sequence. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.09: Build a receiver that captures broadcast parameter and uses it in calculations
* T06.G4.05: Use "broadcast and wait" to ensure actions happen in sequence





ID: T06.G5.11
Topic: T06 – Events & Sequences
Skill: Build 3 reactive "when <condition>" events for different game state thresholds
Description: Students create three condition-based events: (1) "when <score > 50>" → show 'Level 2!' message, (2) "when <score > 100>" → show 'Level 3!' message, (3) "when <health < 20>" → show 'Low Health!' warning. These fire automatically as variables change during gameplay. _Auto-graded: Check 3 distinct when-condition events with different thresholds. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.07: Build a "when <lives = 0>" event that triggers game over automatically





ID: T06.G5.12
Topic: T06 – Events & Sequences
Skill: Build 2D physics collision events that broadcast on collision start and end
Description: Students use physics collision events: "broadcast 'hit' when colliding with [ball]" triggers when physics collision begins; "broadcast 'separated' when finish colliding" triggers when objects separate. Compare to regular "when touching" (continuous) vs physics collision (start/end events). Build a bouncing ball that plays sound on each collision. _Auto-graded: Check physics collision broadcast events used. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.09: Build a "when touching [coin]" script that plays a sound and hides the coin
* T16.G5.01: Apply gravity to a sprite using 2D physics


ID: T06.G5.17
Topic: T06 – Events & Sequences
Skill: Predict which event fires first when multiple conditions become true simultaneously
Description: Students analyze a scenario where two "when <condition>" events could fire at the same moment: "when <score > 100>" and "when <level = 2>" both become true on the same frame. Students predict and test: which message appears first? **Key concept:** When multiple condition events fire together, they execute in the ORDER they appear in the sprite's script list (top to bottom). Students document the firing order and explain why event order matters for game logic. _Auto-graded: Correct prediction of firing order + explanation of why order matters. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G5.11: Build 3 reactive "when <condition>" events for different game state thresholds
* T06.G4.16: Add "say" logging to event handlers to trace which events fire and in what order


ID: T06.G5.18
Topic: T06 – Events & Sequences
Skill: Cancel a pending "broadcast and wait" by using stop scripts strategically
Description: Students create an interruptible dialogue system: one broadcast starts a long conversation ("broadcast 'talk' and wait" where receiver says 5 lines with waits). Add a "skip" button that stops the current script, canceling the wait. **Pattern:** Skip button → stop this script → broadcast 'skip-dialogue' to receiver → receiver also stops. **Key concept:** "broadcast and wait" can be interrupted, but you need to stop BOTH sender and receiver to fully cancel. _Auto-graded: Skip functionality works; dialogue is interruptible. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G4.05: Use "broadcast and wait" to ensure actions happen in sequence
* T06.G4.17: Use "stop other scripts in sprite" to cancel running actions when new event arrives


ID: T06.G5.11.01
Topic: T06 – Events & Sequences
Skill: Build overlapping condition events with non-conflicting ranges
Description: Students create condition events for game levels that DON'T overlap: Level 1 is score 0-49, Level 2 is score 50-99, Level 3 is 100+. **Issue to solve:** If using "when score > 50" and "when score > 100", score 101 triggers BOTH events! **Solution:** Use guards: "when score > 50" → only act if level is still 1. Students identify the overlap problem and implement guards. _Auto-graded: Level transitions work correctly without double-firing. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.11: Build 3 reactive "when <condition>" events for different game state thresholds

ID: T06.G6.01
Topic: T06 – Events & Sequences
Skill: Create an event flow diagram showing all execution paths for a game scenario
Description: Given a game with 6+ event scripts and broadcasts, students draw a flow diagram showing: (1) All event entry points (green flag, keys, clicks, conditions), (2) Broadcast connections between sprites, (3) Execution paths for scenario "player starts game, collects 3 coins, dies". Label each path with script names and order. _Auto-graded: Diagram with 6+ scripts, correct flow arrows, scenario path highlighted. CSTA: E6-ALG-AF-01._

Dependencies:
* T06.G5.04: Trace execution order when player clicks green flag then presses space twice
* T06.G5.05: Debug and fix two event handlers that conflict with each other





ID: T06.G6.02
Topic: T06 – Events & Sequences
Skill: Label 6 scripts as "parallel" or "sequential" and explain the execution model
Description: Given a project with 6 scripts, students label each as PARALLEL (runs simultaneously with others from same trigger) or SEQUENTIAL (uses broadcast-and-wait to ensure order). Example: Two "when green flag" scripts = PARALLEL (both start at once); broadcast-and-wait chain = SEQUENTIAL. Students write 2-3 sentences explaining Scratch's threading model. _Auto-graded: Correct labels + explanation of concurrency concept. CSTA: E6-ALG-AF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario
* T06.G4.05: Use "broadcast and wait" to ensure actions happen in sequence





ID: T06.G6.03
Topic: T06 – Events & Sequences
Skill: Organize 8+ event handlers into 4 labeled categories with section comments
Description: Given a sprite with 8+ disorganized event handlers, students group them into categories: MOVEMENT (arrow keys), COMBAT (attack/damage), UI (click handlers), LIFECYCLE (green flag, game over). Add section comments: "-- MOVEMENT HANDLERS --" etc. Visually arrange scripts so related handlers are adjacent. _Auto-graded: 4 section comments + logical grouping verified. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.05: Debug and fix two event handlers that conflict with each other
* T06.G5.06: Add structured comments to 4 event handlers following a template





ID: T06.G6.04
Topic: T06 – Events & Sequences
Skill: Refactor 3 event handlers by extracting shared code into a custom block
Description: Given 3 event handlers with identical 4-block code sequences (e.g., all three play sound → change costume → wait → reset costume), students extract the shared sequence into a custom block "playHitAnimation" and replace duplicates with calls to the custom block. Count lines before/after to show reduction. _Auto-graded: Custom block created + used in 3 event handlers. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.03: Organize 8+ event handlers into 4 labeled categories with section comments
* T11.G5.17: Extract repeated code into reusable blocks





ID: T06.G6.05
Topic: T06 – Events & Sequences
Skill: Consolidate 4 similar key event handlers into 1 handler with conditionals
Description: Students refactor 4 separate "when [arrow] key pressed" handlers (up/down/left/right each with similar logic) into ONE "when any key pressed" handler with if-else chain checking which key was pressed. Compare before (4 scripts, 20 blocks) vs after (1 script, ~10 blocks). Verify behavior is identical. _Auto-graded: Single handler with conditionals replaces 4 handlers; same behavior. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.04: Refactor 3 event handlers by extracting shared code into a custom block
* T08.G5.02: Use multi-way conditionals (if-else chains)





ID: T06.G6.06
Topic: T06 – Events & Sequences
Skill: Rename 5 generic broadcasts to semantic names and create an event dictionary
Description: Students rename generic broadcasts (message1 → 'player-died', message2 → 'level-complete', etc.) and create an "Event Dictionary" table with columns: Broadcast Name, Sender, Receiver(s), When Triggered, What Happens. Document all 5 renamed broadcasts with complete entries. _Auto-graded: 5 semantic broadcast names + complete dictionary table. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.03: Build a level-start/level-end broadcast sequence coordinating 3 sprites
* T06.G5.06: Add structured comments to 4 event handlers following a template





ID: T06.G6.07
Topic: T06 – Events & Sequences
Skill: Build a menu with 3 button widgets that respond to click events
Description: Students create a main menu with 3 button widgets (Start, Settings, Quit). Each button has a "when widget [buttonName] clicked" event that performs different actions: Start → broadcast 'start-game', Settings → show settings panel, Quit → stop all. This introduces app-style UI event handling. _Auto-graded: 3 button widgets + 3 click event handlers. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario
* T15.G3.02: Create a widget and change its properties





ID: T06.G6.08
Topic: T06 – Events & Sequences
Skill: Build a settings panel with slider and checkbox change events
Description: Students create settings with: (1) Volume slider → "when widget [volumeSlider] changes" → set volume to slider value, (2) Music checkbox → "when widget [musicToggle] changes" → if checked play music, else stop music. Changes take effect immediately as user adjusts controls. _Auto-graded: Slider + checkbox with change event handlers that update live. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.07: Build a menu with 3 button widgets that respond to click events
* T15.G4.01: Use sliders and text inputs for user input





ID: T06.G6.09
Topic: T06 – Events & Sequences
Skill: Build video-synchronized captions using video time events
Description: Students create an interactive video with captions: "when video time is [5] seconds" → show caption 'Introduction', "when video time is [15] seconds" → show caption 'Key point 1', etc. Add "when video paused" → show pause overlay. This synchronizes actions to video playback timing. _Auto-graded: 3+ video time events with captions + pause event. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.07: Build a menu with 3 button widgets that respond to click events
* T15.G5.01: Add video widgets and control playback





ID: T06.G6.10
Topic: T06 – Events & Sequences
Skill: Build button hover effects using pointer enter/leave events
Description: Students create button hover effects: "when pointer enters widget [button1]" → change button color to highlight → show tooltip 'Click to start', "when pointer leaves widget [button1]" → restore original color → hide tooltip. Apply to 3 buttons for consistent hover feedback. _Auto-graded: 3 buttons with enter/leave events changing appearance. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.07: Build a menu with 3 button widgets that respond to click events





ID: T06.G6.11
Topic: T06 – Events & Sequences
Skill: Build a 3-tab settings interface with tab selection events
Description: Students create a tabbed settings panel with 3 tabs (Audio, Video, Controls). Each "when tab [tabName] selected" event shows the appropriate content panel and hides others: select Audio tab → show audio settings, hide video/controls. Use broadcasts to coordinate panel visibility. _Auto-graded: 3 tab selection events with correct show/hide logic. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.07: Build a menu with 3 button widgets that respond to click events
* T15.G5.02: Create tabbed interfaces





ID: T06.G6.12
Topic: T06 – Events & Sequences
Skill: Handle multiple delete buttons with a single "any button named" event
Description: Students create a list with 5 items, each having a delete button named 'deleteBtn'. Instead of 5 separate handlers, use ONE "when any button named [deleteBtn] clicked" event that identifies which item to delete using button's parent info. This pattern scales to any number of items. _Auto-graded: Single any-button-named event handling multiple buttons. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.07: Build a menu with 3 button widgets that respond to click events
* T15.G5.03: Create lists of widgets dynamically





ID: T06.G6.13
Topic: T06 – Events & Sequences
Skill: Use "send message to sprite" for targeted communication to one specific enemy
Description: Students use "send 'take-damage' to sprite [enemyName]" to damage only one specific enemy while leaving others unaffected. Compare to broadcast (all enemies would respond). The target sprite receives via normal "when I receive" block. This enables precise one-to-one sprite communication. _Auto-graded: Send-to-sprite used; only targeted sprite responds. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.06: Rename 5 generic broadcasts to semantic names and create an event dictionary





ID: T06.G6.14
Topic: T06 – Events & Sequences
Skill: Send targeted message with damage parameter to a specific enemy sprite
Description: Students combine targeted messaging with parameters: "send 'take-damage' with parameter [15] to sprite [boss]" damages only the boss for 15 HP while other enemies ignore it. The boss receives both the message AND the damage amount. Compare to broadcast-with-parameter (all would receive). _Auto-graded: Send-with-parameter-to-sprite used; target receives correct value. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.13: Use "send message to sprite" for targeted communication to one specific enemy
* T06.G5.08: Build a "broadcast with parameter" to send damage amount to player





ID: T06.G6.15
Topic: T06 – Events & Sequences
Skill: Build a turn-based attack sequence using "send and wait" for ordered actions
Description: Students create turn-based combat: player attacks → "send 'attack' to sprite [enemy] and wait" → (waits for enemy damage animation) → enemy counterattacks → "send 'attack' to sprite [player] and wait". The "and wait" ensures each action completes before the next begins, creating proper turn order. _Auto-graded: Send-and-wait creates observable sequential behavior. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.14: Send targeted message with damage parameter to a specific enemy sprite





ID: T06.G6.16
Topic: T06 – Events & Sequences
Skill: Build a drag-start handler that changes sprite appearance when picked up
Description: Students create "when dragging starts" event that: play 'pickup' sound → set ghost effect to 30 → set size to 120% → bring to front. This gives visual feedback that the sprite is being dragged. The event fires once when drag begins. _Auto-graded: Drag-starts event with visual/audio feedback. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario





ID: T06.G6.17
Topic: T06 – Events & Sequences
Skill: Build a being-dragged handler that draws a trail while sprite moves
Description: Students create "when being dragged" event that fires continuously during drag: pen down → (sprite follows mouse, leaving line) → check if touching drop zone → if yes, change drop zone color. This enables real-time feedback during drag operations. _Auto-graded: Being-dragged event with continuous action (trail or detection). CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.16: Build a drag-start handler that changes sprite appearance when picked up





ID: T06.G6.18
Topic: T06 – Events & Sequences
Skill: Build complete drag-and-drop using all 3 drag events: start, dragging, stop
Description: Students create a puzzle piece with all three drag events: (1) drag-starts → enlarge + play pickup, (2) being-dragged → highlight valid drop zones, (3) drag-stops → if near slot, snap to position + play click + check if puzzle complete, else return to original position. Combine for complete drag-drop UX. _Auto-graded: All 3 drag events create cohesive interaction. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.17: Build a being-dragged handler that draws a trail while sprite moves





ID: T06.G6.19
Topic: T06 – Events & Sequences
Skill: Create a game-state variable with 3 states and conditional logic per state
Description: Students create a 'gameState' variable with values 0=menu, 1=playing, 2=gameover. In relevant event handlers, add "if gameState = 1" checks so game logic only runs during playing state. Add transitions: clicking Start sets gameState=1, dying sets gameState=2. This introduces state-based program organization. _Auto-graded: State variable with 3 values + conditionals checking state. CSTA: E6-PRO-PF-01._

Dependencies:
* T09.G4.01: Use addition (+) in variable expressions
* T08.G4.03: Use nested if/else for multi-way decisions


ID: T06.G6.24
Topic: T06 – Events & Sequences
Skill: Build an input priority system that handles keyboard, mouse, and touch events
Description: Students create a game that accepts input from multiple sources but prioritizes them correctly: (1) Keyboard arrows are highest priority, (2) Mouse clicks are medium priority, (3) Screen touch is lowest. When multiple inputs occur, the highest priority wins. **Implementation:** Use a 'lastInputSource' variable; each handler sets it and checks if it should override. Students test: pressing arrow while clicking mouse → keyboard wins. _Auto-graded: Priority system correctly handles simultaneous inputs from 3 sources. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.05: Consolidate 4 similar key event handlers into 1 handler with conditionals
* T06.G5.17: Predict which event fires first when multiple conditions become true simultaneously


ID: T06.G6.25
Topic: T06 – Events & Sequences
Skill: Build interruptible action sequences using state flags
Description: Students create a multi-step action (character does combo attack: hit1 → wait → hit2 → wait → hit3) that can be interrupted by pressing escape. **Pattern:** Use 'actionInProgress' flag; each step checks if flag is still true before continuing. Pressing ESC sets flag to false, which causes remaining steps to exit early. **Key concept:** Long-running sequences need cancellation points to be responsive. _Auto-graded: ESC interrupts multi-step action at any point. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.18: Cancel a pending "broadcast and wait" by using stop scripts strategically
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state


ID: T06.G6.26
Topic: T06 – Events & Sequences
Skill: Create custom event types by defining a broadcast naming convention
Description: Students design a broadcast naming system for their game: player events start with 'player-' (player-jump, player-hit), enemy events start with 'enemy-' (enemy-spawn, enemy-die), system events start with 'sys-' (sys-pause, sys-level-up). Document the convention and refactor 10+ existing broadcasts to follow it. **Key concept:** Consistent naming makes large projects manageable. _Auto-graded: 10+ broadcasts follow documented convention; no generic names. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G6.06: Rename 5 generic broadcasts to semantic names and create an event dictionary
* T06.G6.03: Organize 8+ event handlers into 4 labeled categories with section comments






ID: T06.G7.01
Topic: T06 – Events & Sequences
Skill: Build a 4-state game state machine with broadcast-triggered transitions
Description: Students implement a state machine with 4 states: MENU→PLAYING→PAUSED→GAMEOVER. Each state change triggers a broadcast ('enter-playing', 'enter-paused', etc.) that sprites receive to update their behavior. Create a state diagram showing all states and transitions. Implement transitions: Start button→PLAYING, P key→toggle PAUSED, death→GAMEOVER. _Auto-graded: 4 states + transition broadcasts + correct behavior per state. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G6.03: Organize 8+ event handlers into 4 labeled categories with section comments
* T06.G6.06: Rename 5 generic broadcasts to semantic names and create an event dictionary
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state





ID: T06.G7.02
Topic: T06 – Events & Sequences
Skill: Complete a state-transition table and predict final state for an input sequence
Description: Given a state machine implementation, students fill in a transition table with columns: Current State | Event | New State | Actions. Then given input sequence "Start, Space, Space, P, Collision", predict the final state by tracing through the table. Example: MENU→(Start)→PLAYING→(Space)→PLAYING→(P)→PAUSED→(Collision)→still PAUSED (collisions ignored when paused). _Auto-graded: Correct transition table + final state prediction. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions





ID: T06.G7.03
Topic: T06 – Events & Sequences
Skill: Design and document a broadcast protocol connecting 4 game subsystems
Description: Students design a broadcast protocol for a game with 4 subsystems: Player, Enemies, UI, ScoreManager. Create a protocol document listing: (1) All broadcasts between subsystems, (2) Direction of each (who sends, who receives), (3) Parameters passed. Example: 'player-hit' sent by Enemy, received by Player+UI+ScoreManager, parameter: damage. Implement the protocol. _Auto-graded: Protocol document + working implementation with 6+ broadcasts. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G6.03: Organize 8+ event handlers into 4 labeled categories with section comments
* T06.G6.06: Rename 5 generic broadcasts to semantic names and create an event dictionary





ID: T06.G7.04
Topic: T06 – Events & Sequences
Skill: Compare two designs and explain why broadcast-based is more modular
Description: Given two implementations of the same feature: (A) Tightly coupled (Player directly calls Enemy.takeDamage), (B) Broadcast-based (Player broadcasts 'attack', Enemy receives). Students analyze both and write 3-4 sentences explaining: Why is B more modular? What happens if we add a new enemy type in each design? Which is easier to change? _Auto-graded: Correct identification + valid modularity explanation. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G6.03: Organize 8+ event handlers into 4 labeled categories with section comments
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems





ID: T06.G7.05
Topic: T06 – Events & Sequences
Skill: Build a drawing tool that captures mouse press position to start lines
Description: Students use "when [left] mouse button is pressed at x [startX] y [startY]" to capture where drawing begins. Store startX, startY as the line's starting point. Combine with mouse release event to draw line from start to end position. This enables position-aware mouse interactions. _Auto-graded: Mouse-press-at-xy event captures coordinates into variables. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions





ID: T06.G7.06
Topic: T06 – Events & Sequences
Skill: Complete the drawing tool with mouse release to finish lines
Description: Students add "when [left] mouse button is released at x [endX] y [endY]" to complete the drawing tool. On release, draw line from (startX, startY) to (endX, endY). The combination of press + release events enables drag-to-draw behavior. _Auto-graded: Mouse-release-at-xy captures end coordinates; line drawn between start/end. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.05: Build a drawing tool that captures mouse press position to start lines





ID: T06.G7.07
Topic: T06 – Events & Sequences
Skill: Build a freehand drawing tool using continuous mouse drag events
Description: Students use "when [left] mouse pointer is dragged to x [currX] y [currY]" to track position continuously during drag. Draw point at (currX, currY) each time event fires to create freehand drawing. This event fires repeatedly (many times per second) while dragging. Compare to press/release (line) vs drag (freehand). _Auto-graded: Drag-to-xy event creates continuous marks. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.05: Build a drawing tool that captures mouse press position to start lines





ID: T06.G7.08
Topic: T06 – Events & Sequences
Skill: Build zoom controls using mouse wheel scroll events
Description: Students use "when mouse wheel scroll by [scrollAmount]" to implement zoom: if scrollAmount > 0 (scroll up) → increase zoom/size, if scrollAmount < 0 (scroll down) → decrease zoom/size. Apply to a canvas or sprite that scales based on scroll direction. Clamp values to min/max zoom levels. _Auto-graded: Scroll event changes size/zoom in correct direction. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions





ID: T06.G7.09
Topic: T06 – Events & Sequences
Skill: Build complex auto-updating UI using multiple "when variable changed" events
Description: Building on G6.23's basic reactive UI, students create a comprehensive reactive dashboard with multiple interconnected displays: (1) "when variable [health] changed" → resize healthBar + change color (green→yellow→red based on value), (2) "when variable [score] changed" → update score text + trigger milestone animations, (3) "when variable [level] changed" → update level display + play level-up sound. Students implement cross-variable effects: health < 20 AND score milestone triggers special "critical bonus" UI effect. This demonstrates complex reactive systems with multiple coordinated variable-changed events. _Auto-graded: 3+ variable-changed events with interconnected display updates + cross-variable coordination. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G6.23: Build "when variable changed" event for reactive data displays
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions





ID: T06.G7.10
Topic: T06 – Events & Sequences
Skill: Build a multi-sprite cutscene using coordinated broadcast sequences
Description: Students create a 30-second intro cutscene with 4 sprites using broadcast coordination: 'intro-start' → sprite1 walks in (broadcast 'intro-part2' and wait) → sprite2 speaks (broadcast 'intro-part3' and wait) → sprite3 reacts → sprite4 exits. Document the sequence timeline. The "and wait" blocks ensure proper timing. _Auto-graded: 4+ broadcast sequence with observable correct ordering. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G6.02: Label 6 scripts as "parallel" or "sequential" and explain the execution model
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems





ID: T06.G8.01
Topic: T06 – Events & Sequences
Skill: Debug a race condition by adding logging and converting to broadcast-and-wait
Description: Given a buggy game where score sometimes doesn't update (race condition between scoring and display), students: (1) Add "say [event name + timestamp]" logging to each handler to identify firing order, (2) Identify the race condition from logs, (3) Fix by converting "broadcast" to "broadcast and wait" where order matters. Document the bug cause and fix. _Auto-graded: Logging added + race condition fixed + explanation provided. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G7.04: Compare two designs and explain why broadcast-based is more modular





ID: T06.G8.02
Topic: T06 – Events & Sequences
Skill: Implement a debounce pattern using a processing flag variable
Description: Students fix double-click issues by adding a 'processing' flag: at start of handler check "if processing = 0" → set processing to 1 → run action → set processing to 0. Without this, rapid clicks cause duplicate actions. Apply to purchase button (prevent buying twice) and attack button (prevent attack spam). **Builds on G7.13 throttling:** Throttling limits rate of continuous events; debouncing prevents duplicate discrete events. Students compare: throttling for continuous input (mouse move), debouncing for discrete input (button clicks). _Auto-graded: Processing flag prevents duplicate handler execution on rapid clicks. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G7.13: Implement event throttling pattern for performance
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G7.04: Compare two designs and explain why broadcast-based is more modular


ID: T06.G8.02.01
Topic: T06 – Events & Sequences
Skill: Add defensive initialization checks at the start of event handlers
Description: Students add guard conditions to event handlers: "if health = 0 or health = '' then set health to 100" at start of handlers that use health. This handles cases where initialization was skipped (user jumped directly into game from a link). Apply to 3 key handlers ensuring they work even without green flag init. _Auto-graded: 3 handlers with default value guards work without prior initialization. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.02: Implement a debounce pattern using a processing flag variable





ID: T06.G8.03
Topic: T06 – Events & Sequences
Skill: Document a complete event protocol table with 8+ broadcasts
Description: Students create a comprehensive protocol table for a complex game with columns: Broadcast Name | Sender | Receiver(s) | Parameter | Trigger Condition | Actions Performed. Document all 8+ broadcasts including gameplay events, UI events, and state transitions. Include a flow diagram showing broadcast relationships between all sprites. _Auto-graded: Table with 8+ complete entries + accurate flow diagram. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G7.04: Compare two designs and explain why broadcast-based is more modular





ID: T06.G8.04
Topic: T06 – Events & Sequences
Skill: Perform an event architecture review using a 5-point checklist
Description: Students review a peer's project using checklist: (1) Descriptive broadcast names? (2) Unused broadcasts? (3) Overloaded receivers (>5 handlers)? (4) Combinable broadcasts? (5) Missing receivers? Rate each 1-3 stars, identify 3+ specific issues, propose fixes for each. Write 1-paragraph summary of event architecture quality and key recommendations. _Auto-graded: Checklist completed + 3 issues identified + fixes proposed. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.01: Create an event flow diagram showing all execution paths for a game scenario
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G7.04: Compare two designs and explain why broadcast-based is more modular





ID: T06.G8.05
Topic: T06 – Events & Sequences
Skill: Build multiplayer join handling using "when added to game" event
Description: Students create "when added to game" event for multiplayer initialization: set position to spawn point → display player name above sprite → broadcast 'player-joined' to notify others → show join animation. This fires after successful server registration, ensuring network is ready. Compare to green flag init (local) vs added-to-game (networked). _Auto-graded: Added-to-game event with multiplayer-specific initialization. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems





ID: T06.G8.06
Topic: T06 – Events & Sequences
Skill: Coordinate multiplayer actions using "broadcast to all players"
Description: Students use "broadcast 'game-event' to all players" for multiplayer coordination: (1) 'round-start' reaches all players simultaneously, (2) 'player-scored' with parameter announces scorer to everyone, (3) Choose mode: include replicates (all copies) vs exclude (original only). Build a synchronized countdown that all players see together. _Auto-graded: Broadcast-to-all-players used for cross-player coordination. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.05: Build multiplayer join handling using "when added to game" event





ID: T06.G6.20
Topic: T06 – Events & Sequences
Skill: Design a collision response table and implement 5 different collision behaviors
Description: Students create a collision response table with columns: Collision Pair | Detection Method | Response Actions | Sound/Visual Effect. Document 5 collision types (player-enemy, player-coin, bullet-enemy, player-powerup, player-hazard). Implement each with appropriate event handlers. This systematizes collision design before advancing to 3D. _Auto-graded: Table with 5 collision types + all 5 implemented and working. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.12: Build 2D physics collision events that broadcast on collision start and end
* T06.G5.01.02: Identify collision event patterns and explain their game logic purpose


ID: T06.G8.07
Topic: T06 – Events & Sequences
Skill: Build 3D collision detection using "when colliding with" for 3D objects
Description: Students use "when colliding with [sprite]" in 3D mode to detect 3D object collisions: player touches 3D coin → collect, 3D projectile hits 3D enemy → damage. Compare 2D (touching sprite based on costumes) vs 3D (based on mesh boundaries). Handle collision response with appropriate 3D effects. _Auto-graded: 3D collision events working in 3D scene. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.20: Design a collision response table and implement 5 different collision behaviors
* T17.G6.02: Add and position 3D objects





ID: T06.G8.08
Topic: T06 – Events & Sequences
Skill: Build 3D object selection using picking events to highlight clicked objects
Description: Students use "when an object from this sprite is picked" to detect clicks on 3D objects in 3D space. On pick: highlight object (glow effect) → show info panel → set as selected. "Picking" is how 3D engines identify which 3D object the user clicked by casting a ray from camera through click point. _Auto-graded: 3D picking event highlights/selects clicked 3D object. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.07: Build 3D collision detection using "when colliding with" for 3D objects
* T06.G7.05: Build a drawing tool that captures mouse press position to start lines





ID: T06.G8.09
Topic: T06 – Events & Sequences
Skill: Build 3D object manipulation using all three 3D drag events
Description: Students implement 3D drag-and-drop: "when 3D object starts being dragged" → show placement preview, "when 3D object being dragged" → update preview position along drag plane, "when 3D object stops being dragged" → place object at final 3D position or snap to grid. This enables 3D building/placement mechanics. _Auto-graded: All 3 drag events create working 3D object placement. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.08: Build 3D object selection using picking events to highlight clicked objects
* T06.G6.16: Build a drag-start handler that changes sprite appearance when picked up





ID: T06.G8.10
Topic: T06 – Events & Sequences
Skill: Build proximity-based triggers using 3D distance and overlap events
Description: Students use "broadcast 'enemy-near' when distance <= [50]" to trigger when player approaches enemy (for aggro/detection), and "broadcast 'in-zone' when objects overlap" for area triggers (entering room, checkpoint zones). These enable spatial awareness without constant polling. Build enemy that chases when player is within detection range. _Auto-graded: Distance/overlap events trigger appropriate behaviors. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.07: Build 3D collision detection using "when colliding with" for 3D objects
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems





ID: T06.G8.11
Topic: T06 – Events & Sequences
Skill: Build 3D scene initialization using "when 3D scene is initialized"
Description: Students use "when 3D scene is initialized" for 3D-specific setup: position camera → set lighting parameters → load 3D models → initialize physics engine → set gravity. This event fires when 3D engine is ready (after resources load), not at green flag. Compare timing: green flag (immediate) vs 3D-init (after 3D ready). _Auto-graded: 3D-scene-init event with camera/lighting/physics setup. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state
* T17.G6.01: Build a simple 3D scene with camera controls


ID: T06.G3.03.01
Topic: T06 – Events & Sequences
Skill: Compare key pressed (single tap) vs key held (continuous) behaviors
Description: Students create two versions of right-arrow movement: (1) Single tap version with "when right arrow key pressed" moves once per press, (2) Continuous version using forever loop checking "key right arrow pressed?" moves while held. Students compare behaviors and explain when each is appropriate (typing game vs character walking). _Auto-graded: Both versions implemented; written comparison of behaviors. CSTA: E3-ALG-AF-01._

Dependencies:
* T06.G3.03: Build a "when [right arrow] key pressed" script to move a sprite right


ID: T06.G4.04.01
Topic: T06 – Events & Sequences
Skill: Trace broadcast flow between sender and multiple receivers
Description: Given a project with one "broadcast 'reset'" and three receivers (Player sprite resets position, Enemy sprite resets position, Score display resets to 0), students trace the complete flow by drawing a diagram with sender → all receivers and predicting the order of actions. They explain that all receivers run simultaneously (not sequentially). _Auto-graded: Correct diagram + explanation of parallel receiver execution. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.04: Build a broadcast sender in one sprite and a receiver in another sprite


ID: T06.G4.07.01
Topic: T06 – Events & Sequences
Skill: Debug by tracing unexpected event trigger
Description: Given a buggy game where jumping happens when clicking the sprite instead of pressing space (symptoms described), students add "say [event triggered]" logging to each event handler, run the game, observe which events fire when, and identify that "when this sprite clicked" is triggering instead of "when space key pressed". They fix by checking control binding. _Auto-graded: Bug identified via logging + correct fix applied. CSTA: E4-PRO-PF-01._

Dependencies:
* T06.G4.07: Debug a sprite by fixing the wrong key in a "when key pressed" event


ID: T06.G4.09.01
Topic: T06 – Events & Sequences
Skill: Compare sprite collision vs color collision detection
Description: Students build both collision types side by side: (1) "when touching [coin]" for sprite-based collection, (2) "when touching color [red]" for lava detection. They compare: sprite collision requires specific sprite names, color collision works with any painted area. Students explain when each is more appropriate (collectible items vs painted hazard zones). _Auto-graded: Both types implemented + written comparison. CSTA: E4-ALG-AF-01._

Dependencies:
* T06.G4.09: Build a "when touching [coin]" script that plays a sound and hides the coin


ID: T06.G5.05.01
Topic: T06 – Events & Sequences
Skill: Debug infinite event loop by identifying broadcast cycle
Description: Given a buggy project where the game freezes, students trace broadcast flow and find: Handler A broadcasts 'update' → Handler B receives 'update' and broadcasts 'refresh' → Handler C receives 'refresh' and broadcasts 'update' (cycle back to A). Students identify the loop, explain why it causes freeze, and fix by breaking the cycle. _Auto-graded: Cycle identified + explanation + fix that breaks the loop. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.05: Debug and fix two event handlers that conflict with each other


ID: T06.G5.13
Topic: T06 – Events & Sequences
Skill: Build speech recognition event handler using start/end recognition pattern
Description: Students implement voice control using CreatiCode's speech recognition pattern: (1) "start recognizing speech in [English]" begins listening, (2) Store recognized text in a variable when recognition completes, (3) Check the variable value to trigger actions: if recognized text = "jump" → make sprite jump, if recognized text = "stop" → stop all motion. Students handle: enabling microphone permissions, setting language, and checking for empty/unrecognized results. **Pattern:** Start recognition → wait for result → check text → perform action. _Auto-graded: Speech recognition started + result checked + at least 2 different voice commands handled. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.03: Build a level-start/level-end broadcast sequence coordinating 3 sprites
* T06.G4.15: Build a "when <condition>" event that triggers when a threshold is crossed


ID: T06.G5.14
Topic: T06 – Events & Sequences
Skill: Build hand gesture detection using hand tracking and condition events
Description: Students implement gesture control using CreatiCode's hand tracking pattern: (1) "run hand detection table [handData]" continuously updates hand position/gesture data, (2) Use "when <condition>" event to react to gestures: "when <(item 1 of handData) = 'thumbs_up'>" → add heart effect, "when <(item 1 of handData) = 'open_palm'>" → pause game. Students understand: camera access requirement, detection latency, and that hand tracking writes to a table continuously while condition events fire on state changes. _Auto-graded: Hand detection running + at least 2 condition events for different gestures. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.13: Build speech recognition event handler using start/end recognition pattern



ID: T06.G5.15
Topic: T06 – Events & Sequences
Skill: Build "when timer reaches X" events for timed game actions
Description: Students use "when timer equals [X]" or "when timer > [X]" events to trigger actions at specific times. **Example 1:** Power-up expires after 10 seconds: "when timer > 10" → remove power-up effect → reset timer. **Example 2:** Countdown warning: "when timer = 5" → play warning sound → say "5 seconds left!". Students reset the timer in green flag script and observe that the event fires at the specified time. Compare to using "wait" blocks which block other code. _Auto-graded: Timer event triggers at correct time + timer is reset properly. CSTA: E5-PRO-PF-01._

Dependencies:
* T06.G5.11: Build 3 reactive "when <condition>" events for different game state thresholds
* T06.G4.12: Build a green flag initialization script that resets all game variables


ID: T06.G5.16
Topic: T06 – Events & Sequences
Skill: Compare timer-event vs wait-block timing approaches
Description: Students build the same timed behavior two ways: (1) Using "when timer = 10" event (non-blocking), (2) Using "wait 10 seconds" in a script (blocking). **Scenario:** After 10 seconds, play a sound. Students observe: Version 1 allows other scripts to run during the wait, Version 2 blocks that script from doing anything else. Students write 2-3 sentences explaining when each approach is better (timer events for background timing, wait blocks for sequential actions). _Auto-graded: Both versions implemented + written comparison. CSTA: E5-ALG-AF-01._

Dependencies:
* T06.G5.15: Build "when timer reaches X" events for timed game actions
* T07.G4.01: Use a forever loop with keyboard sensing


ID: T06.G6.21
Topic: T06 – Events & Sequences
Skill: Build AI chatbot response event handler
Description: Students create "when AI response received" event that captures the ChatGPT response and displays it: send question to AI → wait → when response received → say response. They handle the asynchronous nature (response doesn't come immediately) and implement a "thinking..." indicator while waiting. CreatiCode-specific: Uses ChatGPT blocks. _Auto-graded: AI question sent + response event handler displays result + waiting indicator shown. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.13: Build speech recognition event handler using start/end recognition pattern
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state



ID: T06.G6.23
Topic: T06 – Events & Sequences
Skill: Build "when variable changed" event for reactive data displays
Description: Students use "when variable [score] changed" event to automatically update UI when data changes: score changes → update score display sprite size/text, health changes → update health bar width. **Key benefit:** No need to manually call update functions after every score change; the event fires automatically whenever ANY code changes the variable. Students compare: (A) Manual approach - add "broadcast update-display" after every "change score by" block, (B) Reactive approach - single "when variable changed" event handles all cases. Students implement reactive health bar that resizes automatically when health changes from any source (enemy hit, healing item, time damage). _Auto-graded: Variable-changed event updates display; display reflects changes from multiple sources. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.11: Build 3 reactive "when <condition>" events for different game state thresholds
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state


ID: T06.G6.22
Topic: T06 – Events & Sequences
Skill: Build periodic event triggers using timer reset patterns
Description: Students create events that fire repeatedly at intervals by resetting the timer. **Pattern:** "when timer > 2" → spawn enemy → reset timer (creates enemy every 2 seconds). **Example game:** Asteroids spawn every 3 seconds, power-ups spawn every 15 seconds. Students implement 2 different periodic spawners with different intervals running simultaneously. This introduces the concept of scheduled/recurring events. _Auto-graded: 2 periodic events with different intervals working simultaneously. CSTA: E6-PRO-PF-01._

Dependencies:
* T06.G5.15: Build "when timer reaches X" events for timed game actions
* T06.G5.16: Compare timer-event vs wait-block timing approaches


ID: T06.G7.11
Topic: T06 – Events & Sequences
Skill: Design event flow for AI-assisted game with voice commands
Description: Students design a complete voice-controlled game flow: (1) Game starts in "listening" state, (2) Voice commands trigger actions ("move left", "jump", "attack"), (3) AI responses provide hints on request, (4) Visual feedback shows current voice recognition status. Create state diagram showing voice → action mappings and handle unrecognized commands gracefully. _Auto-graded: State diagram + 3+ voice commands implemented + error handling. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G5.13: Build speech recognition event handler using start/end recognition pattern
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions


ID: T06.G7.12
Topic: T06 – Events & Sequences
Skill: Build body tracking event handler for motion-based interaction
Description: Students use "when body pose is [pose]" for full-body interaction: "when body pose is [arms raised]" → character jumps, "when body pose is [leaning left]" → character moves left. They implement a fitness game or dance-along that responds to body movement. Handle calibration and provide visual skeleton overlay for feedback. CreatiCode-specific: Uses TensorFlow body tracking. _Auto-graded: 3+ body pose events with game responses + visual feedback. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G5.14: Build hand gesture detection using hand tracking and condition events
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions


ID: T06.G7.13
Topic: T06 – Events & Sequences
Skill: Implement event throttling pattern for performance
Description: Students implement throttling to limit how often an event handler runs: store lastRunTime variable, in handler check "if timer - lastRunTime > 0.1 then run logic and update lastRunTime". Apply to mouse move events (prevent 60 updates/second) or collision checks. Compare performance with and without throttling using frame rate display. **Difference from debouncing (G8):** Throttling ensures regular execution at max rate (e.g., every 100ms), while debouncing waits until activity stops. _Auto-graded: Throttling implemented + performance comparison documented. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions
* T06.G6.19: Create a game-state variable with 3 states and conditional logic per state



ID: T06.G7.14
Topic: T06 – Events & Sequences
Skill: Predict when race conditions can occur in multi-event programs
Description: Students analyze event flow diagrams and identify where race conditions MIGHT occur before running the code. **Scenario:** Two sprites both respond to 'score-changed' broadcast: Sprite A updates score display, Sprite B checks if score > 100 for level-up. Students predict: "If both run at once, level-up check might see old score value." Students identify 3 race condition patterns: (1) Read-after-write with shared variables, (2) Unordered broadcast receivers, (3) Parallel handlers modifying same state. _Auto-graded: Identify 3 potential race conditions in given diagrams + explain why each is risky. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G6.02: Label 6 scripts as "parallel" or "sequential" and explain the execution model



ID: T06.G8.12


ID: T06.G7.15
Topic: T06 – Events & Sequences
Skill: Resolve conflicting events using an event priority queue
Description: Students build a system where events are queued with priorities instead of firing immediately: (1) Create an 'eventQueue' list variable, (2) Event handlers add events to queue with priority number, (3) A main loop processes queue in priority order. **Example:** Movement events (priority 2), combat events (priority 1 - higher), UI events (priority 3). Students implement 3+ event types with observable priority ordering. _Auto-graded: Queue system processes events in correct priority order. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.14: Predict when race conditions can occur in multi-event programs
* T06.G6.24: Build an input priority system that handles keyboard, mouse, and touch events


ID: T06.G7.16
Topic: T06 – Events & Sequences
Skill: Design a domain-specific event vocabulary for a game genre
Description: Students create a comprehensive event vocabulary for a specific game genre (platformer, RPG, puzzle). Document 15+ events organized by category: player actions (player-jump, player-attack), world events (level-start, level-complete), system events (pause, save, settings-changed). Each event has defined parameters and receivers. Compare your vocabulary to a different genre to show how event design reflects game type. _Auto-graded: 15+ documented events + implementation + comparison. CSTA: E7-ALG-AF-01._

Dependencies:
* T06.G6.26: Create custom event types by defining a broadcast naming convention
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems


ID: T06.G7.17
Topic: T06 – Events & Sequences
Skill: Build an observer pattern with subscription and unsubscription
Description: Students implement observer pattern: (1) Create 'scoreObservers' list, (2) Sprites call 'add-observer' broadcast to subscribe, (3) When score changes, iterate through observers and send message to each. (4) Implement 'remove-observer' for unsubscription. **Use case:** UI elements subscribe to score changes; when UI is hidden, it unsubscribes. Compare to always-broadcast approach. _Auto-graded: Subscription/unsubscription working; only subscribed sprites receive updates. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G7.03: Design and document a broadcast protocol connecting 4 game subsystems
* T06.G6.13: Use "send message to sprite" for targeted communication to one specific enemy


ID: T06.G7.18
Topic: T06 – Events & Sequences
Skill: Coordinate AI streaming responses with progressive UI updates
Description: Students handle AI responses that arrive in chunks (streaming mode): (1) Start AI request with "ChatGPT ask streaming", (2) Use "when AI response chunk received" to get each piece, (3) Append chunks to display progressively, (4) Use "when AI response complete" for final cleanup. **Key pattern:** Show "..." loading, update display as chunks arrive, remove loading when complete. Handle partial responses gracefully. _Auto-graded: Streaming response displays progressively + loading indicator works. CSTA: E7-PRO-PF-01._

Dependencies:
* T06.G6.21: Build AI chatbot response event handler
* T06.G7.01: Build a 4-state game state machine with broadcast-triggered transitions

Topic: T06 – Events & Sequences
Skill: Orchestrate multiple AI input events with priority handling
Description: Students build a system handling voice, hand gesture, and keyboard input simultaneously: define priority order (keyboard > hand > voice), implement arbitration when multiple inputs occur at once, handle conflicts (voice says "jump" while hand shows "stop"). Create a priority table and implement queue/override logic. _Auto-graded: 3 input types + priority system + conflict resolution working. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G7.11: Design event flow for AI-assisted game with voice commands
* T06.G7.12: Build body tracking event handler for motion-based interaction


ID: T06.G8.13
Topic: T06 – Events & Sequences
Skill: Debug timing issues in AI event handlers with latency handling
Description: Students debug issues caused by AI response latency: (1) Add timestamp logging to track when events fire and when AI responds, (2) Identify race conditions where user acts before AI response arrives, (3) Implement timeout handling for slow/failed AI responses, (4) Add graceful degradation if AI is unavailable. Document latency measurements and mitigation strategies. _Auto-graded: Logging shows timing + timeout implemented + fallback behavior works. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G6.21: Build AI chatbot response event handler
* T06.G8.01: Debug a race condition by adding logging and converting to broadcast-and-wait


ID: T06.G8.14
Topic: T06 – Events & Sequences
Skill: Design event bus architecture for large-scale projects
Description: Students implement a centralized event bus pattern: (1) Create EventBus sprite that all broadcasts go through, (2) Implement event registration (sprites register what events they care about), (3) Add event logging for debugging, (4) Create event priority queue for ordered processing. Compare direct broadcast vs event bus approaches for maintainability. Document the architecture with diagram. _Auto-graded: EventBus sprite + registration system + logging + comparison document. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.03: Document a complete event protocol table with 8+ broadcasts
* T06.G8.04: Perform an event architecture review using a 5-point checklist





ID: T06.G8.15
Topic: T06 – Events & Sequences
Skill: Design fallback event handlers when sensors fail
Description: Students implement graceful degradation when AI sensors (speech, gesture, body tracking) fail or are unavailable. **Pattern:** Primary handler uses speech recognition; fallback handler uses keyboard. **Implementation:** Check if sensor available → if yes, use speech events → if no, broadcast 'use-keyboard-mode'. Students build a game that works with voice commands but falls back to keyboard when microphone is unavailable or speech recognition fails repeatedly. _Auto-graded: Primary + fallback handlers implemented; game playable in both modes. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.13: Debug timing issues in AI event handlers with latency handling
* T06.G5.13: Build speech recognition event handler using start/end recognition pattern


ID: T06.G8.16
Topic: T06 – Events & Sequences
Skill: Implement graceful degradation for AI event timeouts
Description: Students add timeout handling to AI-dependent features. **Pattern:** When asking AI a question, start a 10-second timer → if AI responds before timeout, handle normally → if timeout fires first, show default response and offer retry. **Implementation:** Use "when timer > 10" as timeout event, cancel timer when AI responds successfully. Students handle 3 failure modes: (1) Slow response, (2) No response, (3) Error response. _Auto-graded: Timeout implemented + default fallback behavior + retry option working. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.15: Design fallback event handlers when sensors fail
* T06.G6.22: Build periodic event triggers using timer reset patterns


ID: T06.G8.17
Topic: T06 – Events & Sequences
Skill: Design event arbitration for complex multi-modal input systems
Description: Students build a comprehensive input arbitration system handling 4+ input types (keyboard, mouse, voice, gesture, touch). Design rules for: (1) Which inputs can work simultaneously, (2) Which inputs block others, (3) Priority when conflicts occur, (4) Timeout/fallback handling. Create a decision matrix and implement the full system. Document edge cases and how they're handled. _Auto-graded: 4+ input types + decision matrix + edge cases documented + implementation. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.12: Orchestrate multiple AI input events with priority handling
* T06.G7.15: Resolve conflicting events using an event priority queue


ID: T06.G8.18
Topic: T06 – Events & Sequences
Skill: Implement event taxonomy for organizing 20+ broadcasts in a large project
Description: Students create a formal event taxonomy for a project with 20+ broadcasts: (1) Define event categories (lifecycle, input, gameplay, ui, network), (2) Define naming patterns for each category, (3) Document event flow between categories, (4) Implement automated validation that new events follow taxonomy. Create an event reference document that new team members could use. _Auto-graded: 20+ events organized + taxonomy document + flow diagram. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G7.16: Design a domain-specific event vocabulary for a game genre
* T06.G8.03: Document a complete event protocol table with 8+ broadcasts


ID: T06.G8.19
Topic: T06 – Events & Sequences
Skill: Implement event sourcing pattern for replay and undo functionality
Description: Students implement event sourcing: (1) Record every event that changes game state to an 'eventHistory' list with timestamps, (2) Build replay system that plays events from history at original timing, (3) Build undo that reverses the last N events. **Use case:** Replay feature for puzzle game; undo button for strategy game. Students compare: state-based save vs event-sourcing save. _Auto-graded: Event recording + replay + undo working. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.14: Design event bus architecture for large-scale projects
* T06.G7.17: Build an observer pattern with subscription and unsubscription


ID: T06.G8.20
Topic: T06 – Events & Sequences
Skill: Build command pattern for event queueing and batching
Description: Students implement command pattern: (1) Events don't execute immediately but add "commands" to a queue, (2) Commands can be batched (execute 10 at once), delayed (execute after 5 seconds), or cancelled before execution. **Use case:** Undo/redo system, network game sync (queue commands until server confirms). Build a command queue with add, execute, cancel, and batch operations. _Auto-graded: Command queue with delayed execution + cancellation + batching. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.19: Implement event sourcing pattern for replay and undo functionality
* T06.G7.15: Resolve conflicting events using an event priority queue


ID: T06.G8.21
Topic: T06 – Events & Sequences
Skill: Build adaptive event handling that adjusts based on AI feedback
Description: Students create an event system that learns from AI: (1) Track which events user triggers most frequently, (2) Use AI to suggest event optimizations (e.g., "player often uses voice after keyboard fails"), (3) Dynamically adjust event priorities based on usage patterns. **Implementation:** Log events, periodically send to AI for analysis, apply suggestions. Build a self-optimizing input system. _Auto-graded: Usage tracking + AI analysis integration + adaptive priority adjustment. CSTA: E8-PRO-PF-01._

Dependencies:
* T06.G8.17: Design event arbitration for complex multi-modal input systems
* T06.G8.13: Debug timing issues in AI event handlers with latency handling



# T07 - Loops (Phase 8 Major Redesign - November 2025)
# PHASE 8 MAJOR REDESIGN - Bold improvements for high-quality skill progression:
#
# MAJOR CHANGES:
# 1. CONSOLIDATED DUPLICATES:
#    - Merged T07.G4.07.01 and T07.G5.04.01 (both were "build nested loop for grid")
#    - Kept G4.07.01 as first construction, removed G5.04.01, renumbered G5 skills
#
# 2. ADDED CRITICAL MISSING SKILLS:
#    - T07.G3.02.02: Debug by adding say blocks inside loops (visualization)
#    - T07.G4.04.01: Identify the repeating unit in sequential code (prerequisite to refactoring)
#    - T07.G5.07: Transform list items in place using a loop (map pattern)
#    - T07.G5.08: Count items matching a condition (count pattern)
#    - T07.G6.04.01: Debug nested loops with incorrect bounds
#    - T07.G6.12: Iterate over table variable rows (for AI vision/hand tracking data)
#    - T07.G7.09: Compare recursion vs iteration for repeated tasks
#    - T07.G7.10: Implement loops with multiple exit conditions
#    - T07.G8.12: Design loops for paginated API responses
#    - T07.G8.13: Implement asynchronous processing patterns with loops
#
# 3. IMPROVED SKILL VERBS (active, specific):
#    - Changed "Use" to "Construct", "Implement", "Debug", "Trace", "Predict" throughout
#    - Added explicit task descriptions with clear success criteria
#
# 4. ENHANCED GRADE PROGRESSION:
#    - G3: Added visualization/debugging scaffolding before complex loops
#    - G4: Added pattern identification before refactoring
#    - G5-G6: Smoother transition with intermediate skills
#    - G7-G8: Added modern data science and async patterns
#
# 5. CREATICODE-SPECIFIC ADDITIONS:
#    - T07.G6.12: Table variable iteration (hand/body tracking)
#    - T07.G8.13: Asynchronous loop patterns (AI API callbacks)
#
# 6. PRESERVED AND ENHANCED:
#    - All K-2 picture-based activities
#    - Grade 3 gateway skills with prediction sub-skills
#    - All cross-topic dependencies unchanged
#    - Sorting algorithms (bubble, selection)
#    - AI streaming and batch processing
#
# Total: 98 skills (net +11 skills after removing 1 duplicate and adding 12 new skills)

ID: T07.K.01
Topic: T07 – Loops
Skill: Complete a repeating pattern
Description: **Student task:** Drag the correct picture to fill in the missing item in a simple repeating pattern. **Visual scenario:** Show 4-5 items in a row with the last item missing. Example: red apple → green apple → red apple → green apple → [?]. Students select from 3 picture choices (red apple, banana, orange) to complete the AB pattern. Use simple AB patterns only at this level. **Visual themes:** animals (cat-dog), colors (red-blue), shapes (circle-square), or food (apple-banana). _Implementation note: Single drag-drop with 3 picture options; audio prompt "What comes next?" Auto-graded by correct selection. CSTA: EK-ALG-PS-03._

Dependencies:



ID: T07.K.01.01
Topic: T07 – Loops
Skill: Predict the next TWO items in an AB pattern
Description: **Student task:** Look at a repeating pattern (AB AB AB). Predict what the next TWO items should be, then verify by revealing them. **Visual scenario:** Show: star → moon → star → moon → star → moon → [?] → [?]. Students first select their prediction from choices showing pairs: (A) star-moon, (B) moon-star, (C) star-star. After selecting, animation reveals the correct answer. **Correct answer:** star-moon. _Implementation note: Prediction-then-verify format builds metacognition; students commit to an answer before seeing confirmation. Audio asks "What do you think comes next?" CSTA: EK-ALG-PS-03._

Dependencies:
* T07.K.01: Complete a repeating pattern



ID: T07.K.02
Topic: T07 – Loops
Skill: Extend an AAB repeating pattern
Description: **Student task:** Drag pictures to complete a more complex AAB pattern (two same, then one different). **Visual scenario:** Show pattern: jump → jump → clap → jump → jump → [?]. Students select from 3 picture choices (clap, jump, sit) to continue the AAB pattern. **Correct answer:** clap. **Visual themes:** actions (clap-clap-jump), animals (dog-dog-cat), shapes (circle-circle-star). _Implementation note: Extends K.01 by introducing AAB patterns; audio asks "What comes next in the pattern?" Auto-graded. CSTA: EK-ALG-PS-03._

Dependencies:
* T07.K.01.01: Predict the next TWO items in an AB pattern




ID: T07.G1.01
Topic: T07 – Loops
Skill: Count repetitions in a pattern
Description: **Student task:** Count how many times a pattern unit repeats and select the correct number. **Visual scenario:** Show a visual sequence with clear groupings: "star-moon | star-moon | star-moon" (6 picture cards with visual separators showing 3 groups). Students count that the pattern repeats 3 times and select "3" from choices (2, 3, 4). Use 2-4 repetitions with concrete, observable actions or objects. **Visual themes:** hand motions, animal movements, stacking objects. _Implementation note: MCQ with 3 number choices; visual separators help students identify pattern units. Audio asks "How many times does the pattern repeat?" Auto-graded. CSTA: E1-ALG-PS-03._

Dependencies:
* T07.K.02: Extend an AAB repeating pattern





ID: T07.G1.02
Topic: T07 – Loops
Skill: Match "do N times" instructions to outcomes
Description: **Student task:** Match a simple "do N times" instruction to the correct visual outcome. **Visual scenario:** Show an instruction card with a number and action (e.g., speech bubble showing "Jump 3 times" with number "3" prominently displayed). Present 3 picture choices showing different counts: (A) 2 jumping figures, (B) 3 jumping figures, (C) 4 jumping figures. Students select the picture that matches the instruction. **Actions:** clapping, jumping, stacking blocks, drawing stars. **Numbers:** 2-5 only. _Implementation note: MCQ with picture choices showing different quantities; audio reads the instruction aloud. Connects "repeat N times" to concrete visual results, preparing for `repeat N` block. Auto-graded. CSTA: E1-ALG-PS-03._

Dependencies:
* T07.G1.01: Count repetitions in a pattern


ID: T07.G1.03
Topic: T07 – Loops
Skill: Predict how many steps to reach a goal
Description: **Student task:** Look at a picture showing a character and a goal with a path between them. Count how many steps (jumps, hops) the character needs to repeat to reach the goal. **Visual scenario:** Show a frog on lily pad 1, with the goal flower on lily pad 4. Lily pads are numbered 1-4. Students count: the frog needs to jump 3 times to reach the flower. Select from choices: 2, 3, or 4 jumps. **Visual themes:** frog on lily pads, bunny on stepping stones, car on road segments. _Implementation note: MCQ with 3 number choices; counting visible spaces between start and goal. Audio asks "How many jumps to reach the flower?" Auto-graded. Introduces the concept of repeat-until (keep going until you reach the goal). CSTA: E1-ALG-PS-03._

Dependencies:
* T07.G1.02: Match "do N times" instructions to outcomes



ID: T07.G1.03.01
Topic: T07 – Loops
Skill: Predict the outcome of a "do N times" instruction
Description: **Student task:** Given an instruction card "Jump 4 times starting from square 2", predict where the character will end up BEFORE seeing the animation. **Visual scenario:** Number line squares 1-8. Character starts on square 2. Instruction shows "Jump 4 times (each jump = 1 square)". Students predict: 2 + 4 = square 6. Select from choices: square 5, 6, or 7. After selecting, animation plays to verify. **Correct answer:** square 6. _Implementation note: Prediction-before-verification format; stronger focus on mental calculation than G1.03 which focuses on counting visible spaces. Audio asks "Where will the bunny end up?" CSTA: E1-ALG-PS-03._

Dependencies:
* T07.G1.03: Predict how many steps to reach a goal





ID: T07.G2.01
Topic: T07 – Loops
Skill: Sort tasks into "repeat many times" vs "do once"
Description: **Student task:** Drag picture task cards into two labeled bins: "Do many times" vs "Do only once." **Visual scenario:** Two bins with clear labels and icons (loop arrow vs single arrow). **Picture cards for "Do many times" bin:** brushing all teeth (many teeth icon), coloring all 5 stars on a page (stars icon), watering all 4 plants (pots icon), sweeping entire floor. **Cards for "Do only once" bin:** putting on ONE hat, opening THE door, flipping light switch ON, sitting in chair. _Implementation note: 6-8 drag-drop cards into 2 bins; emphasizes recognizing when a task requires repetition vs single action. Audio reads card labels. Auto-graded by bin placement. CSTA: E2-ALG-PS-03._

Dependencies:
* T07.G1.03.01: Predict the outcome of a "do N times" instruction


ID: T07.G2.02
Topic: T07 – Loops
Skill: Trace a pictorial "repeat" instruction step by step
Description: **Student task:** Watch an animation of a character following a "repeat 3 times: step forward" instruction. After each step, tap to confirm the character's position. Count along: "Step 1... Step 2... Step 3... Done!" **Visual scenario:** Robot starts at position 0, moves right one square per step on a number line (0-5). After "repeat 3" the robot should be at position 3. Students verify the final position by selecting from choices (2, 3, 4). **Visual themes:** robot on grid, bunny on path, car on road. _Implementation note: Animated sequence with pause-and-confirm; introduces step-by-step tracing concept. Audio counts each repetition. Auto-graded. CSTA: E2-ALG-PS-03._

Dependencies:
* T07.G2.01: Sort tasks into "repeat many times" vs "do once"



ID: T07.G2.02.01
Topic: T07 – Loops
Skill: Predict final position before tracing animation
Description: **Student task:** Look at a pictorial repeat instruction ("repeat 4 times: move right 1 square") and the starting position. Predict the final position BEFORE watching the animation, then watch to verify. **Visual scenario:** Robot at square 2. Instruction card shows "Repeat 4: move right." Students predict: 2 + 4 = square 6. MCQ choices: 5, 6, 7. After prediction, animation plays step-by-step so students can verify their thinking. **Correct answer:** 6. _Implementation note: Prediction-first format develops mental simulation skills; animation provides immediate feedback. Builds on G2.02 by adding prediction before tracing. Audio: "Where do you THINK the robot will end up? Let's check!" CSTA: E2-ALG-PS-03._

Dependencies:
* T07.G2.02: Trace a pictorial "repeat" instruction step by step


ID: T07.G2.03
Topic: T07 – Loops
Skill: Identify when a repeat loop should stop
Description: **Student task:** Look at a picture showing a character repeating an action toward a goal. The goal has a flag or marker. Tap the picture that shows when the character should STOP repeating. **Visual scenario:** 4 panels showing a snail moving toward a lettuce leaf: (A) snail at start, (B) snail halfway, (C) snail at lettuce, (D) snail past lettuce. Students select panel C - the snail stops when it reaches the goal. **Correct answer:** Panel C. _Implementation note: MCQ with 4 picture panels; introduces the concept of stopping condition (until). Audio asks "When should the snail stop?" Auto-graded. Prepares for repeat-until loops. CSTA: E2-ALG-PS-03._

Dependencies:
* T07.G2.02.01: Predict final position before tracing animation


ID: T07.G2.04
Topic: T07 – Loops
Skill: Build a repeating picture sequence from instructions
Description: **Student task:** Given a "repeat 3 times: [action]" instruction card, drag pictures in order to build the complete sequence. **Visual scenario:** Instruction says "Repeat 3 times: clap → stomp". Students drag 6 picture cards in order: clap, stomp, clap, stomp, clap, stomp. **Correct sequence:** alternating clap-stomp repeated 3 times. **Visual themes:** dance moves, robot actions, building blocks. _Implementation note: 6-8 drag-drop cards into numbered slots; students actively construct the repeated sequence rather than just identifying it. Audio reads "Build what happens when we repeat this 3 times." Auto-graded by sequence order. Bridges pattern recognition to loop construction. CSTA: E2-ALG-PS-03._

Dependencies:
* T07.G2.03: Identify when a repeat loop should stop




ID: T07.G3.01
Topic: T07 – Loops
Skill: Use a counted repeat loop (GATEWAY)
Description: Students use their first `repeat N` block to run a simple action multiple times. **Task:** Make a sprite say "Hello!" 3 times using `repeat 3 [say "Hello!" for 1 second]`. Students drag the `repeat` C-block from Control, set N=3, and place the `say` block inside. **Key insight:** `repeat 3` means "do this 3 times" - directly applying K-2 pattern knowledge to code. Start with N=2-3 and single action inside. Students run the code and observe the sprite saying hello 3 times in sequence.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.04: Build a repeating picture sequence from instructions



ID: T07.G3.01.01
Topic: T07 – Loops
Skill: Predict the outcome of a repeat block before running
Description: Students read a script with `repeat N` and predict what will happen BEFORE clicking the green flag. **Task:** Given `when green flag clicked, repeat 4 [stamp]`, students predict: "The sprite will stamp 4 copies of itself." MCQ: (A) 3 stamps, (B) 4 stamps, (C) 5 stamps. After selecting, students run the code to verify. **Focus:** Building the habit of mental execution before running code. This prediction skill is essential for debugging - you must know what SHOULD happen to identify when something goes wrong.

Dependencies:
* T07.G3.01: Use a counted repeat loop (GATEWAY)



ID: T07.G3.01.02
Topic: T07 – Loops
Skill: Modify repeat count to achieve a target outcome
Description: Students change the repeat count to produce a specified result. **Task:** Given `repeat 3 [move 20 steps]` that moves the sprite 60 steps, modify the code so the sprite moves exactly 100 steps. Students calculate: 100 ÷ 20 = 5, so change to `repeat 5`. **Variations:** (1) "Make the sprite turn exactly 360 degrees" with `repeat ? [turn 45]` → answer: 8, (2) "Play the drum 6 times" with `repeat ? [play drum]` → answer: 6. This reverse-engineering skill builds number sense with loops.

Dependencies:
* T07.G3.01.01: Predict the outcome of a repeat block before running





ID: T07.G3.02
Topic: T07 – Loops
Skill: Trace a script with a simple repeat loop
Description: Students read a script with a single `repeat N` loop (N = 2-4) and predict the outcome. Example: `repeat 3 [move 10 steps]` - students predict the sprite moves 30 steps total (3 × 10). Use concrete, visual actions like moving, stamping, or changing costume. Focus is on "multiply the action by the count" understanding. Students trace on paper or mentally before running the code.

Dependencies:
* T07.G3.01.02: Modify repeat count to achieve a target outcome
* T04.G3.03: Match a "repeat N" loop to repeated behavior


ID: T07.G3.02.01
Topic: T07 – Loops
Skill: Predict the final position after a repeat loop
Description: Students predict where a sprite ends up after a `repeat N [move X steps]` loop. Given: sprite starts at x=0, code is `repeat 4 [move 25 steps]`. Students calculate: 4 × 25 = 100, so sprite ends at x=100. This skill focuses specifically on spatial/position outcomes rather than general tracing, building intuition for how loops accumulate effects.

Dependencies:
* T07.G3.02: Trace a script with a simple repeat loop



ID: T07.G3.02.02
Topic: T07 – Loops
Skill: Debug loops by adding say blocks to visualize execution
Description: Students learn to debug loops by inserting `say` blocks to display the loop counter or variable values during execution. **Task:** Given a buggy loop `repeat 5 [move 10, turn 30]` that doesn't draw the expected pentagon, students add `say (counter)` inside the loop to watch each iteration. They observe: counter shows 1,2,3,4,5 and realize 30° is wrong (should be 72° for pentagon). **Key insight:** Visualizing what happens inside the loop helps identify where the logic fails. This is the first formal debugging technique for loops - "print debugging" - that students will use throughout their programming careers. This skill teaches the technique; T07.G3.05 applies it to fix specific bugs.

Dependencies:
* T07.G3.02.01: Predict the final position after a repeat loop



ID: T07.G3.03
Topic: T07 – Loops
Skill: Build a forever loop for continuous animation
Description: Students create their first `forever` loop with a simple action inside (e.g., `forever [turn 15 degrees]` or `forever [next costume, wait 0.2 seconds]`) to create continuous animation. Students understand that `forever` means "keep repeating until the program stops" - there is no count. Compare with `repeat N` which stops after N times. Key insight: forever loops never end on their own.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T04.G3.04.01: Identify repeated code segments that could be simplified with templates


ID: T07.G3.03.02
Topic: T07 – Loops
Skill: Use wait until to pause execution
Description: Students use the `wait until <condition>` block to pause script execution until a condition becomes true. **Task:** Create a program where a sprite says "Click me!" and then uses `wait until <mouse down?>` before saying "Thanks!" **Key difference from repeat until:** `wait until` does nothing while waiting (just pauses), while `repeat until` runs actions each iteration. **Applications:** Wait for user input, wait for another sprite to reach a position, wait for timer to reach a value. Students trace execution to see the script pauses at the wait block until condition is true.

Dependencies:
* T07.G3.03: Build a forever loop for continuous animation
* T08.G3.04: Use a simple if in a script


ID: T07.G3.03.01
Topic: T07 – Loops
Skill: Compare repeat vs forever loops
Description: Students explain when to use `repeat N` vs `forever`. Given two tasks: (1) "Make the sprite spin 5 times" → use `repeat 5`, (2) "Make the sprite spin continuously" → use `forever`. Students identify that `repeat N` is for a known number of repetitions, while `forever` is for continuous/indefinite repetition. This comparison skill solidifies understanding of both loop types.

Dependencies:
* T07.G3.03: Build a forever loop for continuous animation





ID: T07.G3.04
Topic: T07 – Loops
Skill: Use repeat-until to reach a goal
Description: Students use `repeat until <condition>` to move a sprite toward a goal. Example: `repeat until <touching [goal]> [move 10 steps]`. The sprite moves step by step until it reaches the target. Students understand this as "keep doing until" - combining repetition with a stopping condition. Use simple conditions like `touching [sprite]` or `touching [color]`.

Dependencies:
* T07.G3.02: Trace a script with a simple repeat loop
* T07.G3.03.01: Compare repeat vs forever loops
* T08.G3.04: Use a simple if in a script





ID: T07.G3.04.01
Topic: T07 – Loops
Skill: Trace a repeat-until loop step by step
Description: Students trace a `repeat until` loop iteration by iteration, predicting when the stopping condition becomes true. Example: sprite at x=0, goal at x=30, code is `repeat until <touching goal> [move 10 steps]`. Trace: iteration 1 → x=10 (not touching), iteration 2 → x=20 (not touching), iteration 3 → x=30 (touching!) → STOP. Students count iterations and identify the final state. Use 3-5 iterations maximum.

Dependencies:
* T07.G3.04: Use repeat-until to reach a goal





ID: T07.G3.05
Topic: T07 – Loops
Skill: Debug a wrong repeat loop count
Description: Students identify and fix a `repeat` loop with the wrong count. Example: task is "draw 4 sides of a square" but code says `repeat 3 [move, turn 90]`. Students use the say-block visualization technique (from T07.G3.02.02) to trace and see only 3 sides are drawn, then fix by changing to `repeat 4`. **Diagnostic process:** (1) read the goal, (2) add say blocks to visualize, (3) trace the code, (4) notice mismatch, (5) fix the count.

Dependencies:
* T07.G3.02.02: Debug loops by adding say blocks to visualize execution



ID: T07.G3.05.01
Topic: T07 – Loops
Skill: Debug a repeat loop with wrong action inside
Description: Students debug a `repeat` loop where the count is correct but the ACTION inside is wrong. **Task:** Goal is "make sprite move 100 steps total using 4 moves." Code shows `repeat 4 [move 30 steps]`. Students trace: 4 × 30 = 120, but goal is 100. Fix: change to `move 25 steps` (100 ÷ 4 = 25). **Key insight:** The bug isn't always in the repeat count - sometimes the action inside needs fixing. This complements G3.05 which focuses on count errors.

Dependencies:
* T07.G3.05: Debug a wrong repeat loop count





ID: T07.G4.01
Topic: T07 – Loops
Skill: Create a forever loop for keyboard controls
Description: Students implement a `forever` loop that continuously checks keyboard input and moves the sprite. Example: `forever [if <key "right arrow" pressed?> [change x by 10]]`. Students understand why this needs to be in a forever loop: checking once wouldn't allow continuous control. This is the standard "game loop" pattern for player controls.

Dependencies:
* T07.G3.03.01: Compare repeat vs forever loops
* T08.G3.04: Use a simple if in a script





ID: T07.G4.02
Topic: T07 – Loops
Skill: Combine a loop with an if statement inside
Description: Students write a loop containing an `if` block to check a condition on each iteration. Example 1: `forever [if <touching edge?> [bounce]]` - check for edge collision every frame. Example 2: `repeat 10 [if <pick random 1 to 2 = 1> [stamp]]` - conditionally stamp on each iteration. Students understand that the if block runs on EVERY iteration, not just once.

Dependencies:
* T07.G3.05.01: Debug a repeat loop with wrong action inside
* T08.G3.04: Use a simple if in a script



ID: T07.G4.02.01
Topic: T07 – Loops
Skill: Identify which iterations trigger a condition
Description: Students trace a loop with an `if` inside and identify WHICH iterations cause the condition to fire. **Task:** Given `for i from 1 to 6 [if (i mod 2 = 0) [stamp]]`, identify which iterations produce a stamp. Students trace: i=1 (1 mod 2=1, no stamp), i=2 (2 mod 2=0, STAMP), i=3 (no), i=4 (STAMP), i=5 (no), i=6 (STAMP). **Answer:** Stamps on iterations 2, 4, 6. This granular tracing builds understanding of conditional behavior within loops.

Dependencies:
* T07.G4.02: Combine a loop with an if statement inside





ID: T07.G4.03
Topic: T07 – Loops
Skill: Use a counter variable inside a loop
Description: Students manually create and increment a counter variable inside a loop. Pattern: (1) initialize before loop: `set counter to 0`, (2) increment inside loop: `change counter by 1`. Example: display "Step 1", "Step 2", etc. using `repeat 5 [change counter by 1, say (join "Step " counter)]`. This manual counter pattern is the foundation for understanding for-loops.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G3.01.01: Create a new variable with a descriptive name
* T09.G3.01.02: Set a variable to an initial value at program start





ID: T07.G4.03.01
Topic: T07 – Loops
Skill: Use a for-loop with automatic counter
Description: Students use CreatiCode's `for [i] from (1) to (10) at step (1)` block. The for-loop automatically: (1) creates the loop variable, (2) initializes it to START, (3) increments by STEP each iteration, (4) stops when it exceeds LIMIT. Compare with manual counter: for-loop is cleaner and less error-prone. Start with step=1 cases: `for i from 1 to 5` runs 5 times with i = 1, 2, 3, 4, 5.

Dependencies:
* T07.G4.03: Use a counter variable inside a loop





ID: T07.G4.03.02
Topic: T07 – Loops
Skill: Use for-loops with step sizes other than 1
Description: Students use for-loops with step=2, 5, 10, etc. to skip values. Examples: `for i from 0 to 20 step 2` generates even numbers (0, 2, 4, ..., 20). `for i from 5 to 50 step 5` counts by fives. Applications: create evenly-spaced stamps, generate number sequences, position objects at regular intervals. Students predict which values the loop variable takes.

Dependencies:
* T07.G4.03.01: Use a for-loop with automatic counter





ID: T07.G4.03.03
Topic: T07 – Loops
Skill: Use for-loops to count backwards
Description: Students use negative step values to count down. Example: `for i from 10 to 1 step -1` counts 10, 9, 8, ..., 1 (countdown timer). Key insight: when step is negative, START must be greater than LIMIT. Applications: countdown displays, reverse animations, processing items from last to first. Students trace the loop to predict all values.

Dependencies:
* T07.G4.03.01: Use a for-loop with automatic counter





ID: T07.G4.03.04
Topic: T07 – Loops
Skill: Identify the repeating unit in sequential code
Description: Students analyze sequential code to identify which blocks repeat and how many times. **Task:** Given code: `move 50, turn 90, move 50, turn 90, move 50, turn 90, move 50, turn 90`, students answer: (1) What blocks repeat? → "move 50, turn 90", (2) How many times? → 4 times. **MCQ format:** "Which sequence repeats?" with choices showing different groupings. **Key insight:** Before refactoring code into a loop, you must first SEE the pattern. This visual pattern recognition skill is a prerequisite for loop refactoring (T07.G4.04). Students practice with 3-5 examples of varying complexity.

Dependencies:
* T07.G3.02: Trace a script with a simple repeat loop
* T07.G4.03.01: Use a for-loop with automatic counter


ID: T07.G4.04
Topic: T07 – Loops
Skill: Refactor repeated code into a loop
Description: Students identify identical repeated blocks and convert them to a loop. **Task:** Given sequential code `move 50, turn 90, move 50, turn 90, move 50, turn 90, move 50, turn 90` (draws a square), refactor it into `repeat 4 [move 50, turn 90]`. **Process:** (1) Identify the repeated pattern (using T07.G4.03.04 skills), (2) Count repetitions, (3) Wrap in repeat block. Students run both versions to verify they produce identical behavior. **Key insight:** Refactoring reduces code length and makes modifications easier—changing the square size requires editing only one number instead of four.

Dependencies:
* T07.G4.03.04: Identify the repeating unit in sequential code
* T07.G3.01: Use a counted repeat loop





ID: T07.G4.05
Topic: T07 – Loops
Skill: Debug off-by-one errors in loops
Description: Students identify and fix off-by-one errors where a loop runs one too many or one too few times. Example bug: `for i from 1 to 5` should run 5 times, but `for i from 0 to 5` runs 6 times. Students trace the loop to count actual iterations vs expected, then adjust start, limit, or condition. Common patterns: fence-post errors, using < vs <=, wrong initial value.

Dependencies:
* T07.G3.04: Use repeat-until to reach a goal
* T07.G4.03: Use a counter variable inside a loop


ID: T07.G4.05.01
Topic: T07 – Loops
Skill: Debug repeat-until condition errors
Description: Students debug `repeat until` loops with faulty stopping conditions. Example bug: `repeat until <x > 100>` never stops because x starts at 200 and increases. Students analyze: (1) what is the condition checking? (2) will it ever become true? (3) how to fix it. Common fixes: change operator direction, use different variable, add proper initialization.

Dependencies:
* T07.G4.05: Debug off-by-one errors in loops
* T07.G3.04.01: Trace a repeat-until loop step by step





ID: T07.G4.06
Topic: T07 – Loops
Skill: Trace a loop containing a conditional
Description: Students trace a loop with an `if` inside, tracking which iterations trigger the condition. Example: `repeat 5 [move 20, if <touching edge?> [bounce]]`. Trace each iteration: iterations 1-3 don't touch edge, iteration 4 touches edge and bounces, iteration 5 continues in new direction. Students predict both the loop's iterations AND which conditionals fire.

Dependencies:
* T07.G4.02: Combine a loop with an if statement inside
* T07.G3.04: Use repeat-until to reach a goal





ID: T07.G4.07
Topic: T07 – Loops
Skill: Trace nested loops with fixed counts
Description: Students trace nested loops (a loop inside a loop) to predict total iterations. Example: `repeat 3 [repeat 2 [stamp]]` - outer runs 3 times, inner runs 2 times EACH outer iteration, total = 3 × 2 = 6 stamps. Students create a trace table: outer iteration 1 → inner runs 2 times; outer iteration 2 → inner runs 2 times; etc. Use small counts (2-3 each) and visual outcomes.

Dependencies:
* T07.G4.03: Use a counter variable inside a loop
* T07.G4.06: Trace a loop containing a conditional



ID: T07.G4.07.01
Topic: T07 – Loops
Skill: Build a nested loop to draw a rectangle grid
Description: Students construct their first nested loop from scratch to create a rectangular pattern. **Task:** Draw a 3×4 grid of stamps (3 rows, 4 columns). Students build: outer loop `for row from 1 to 3`, inner loop `for col from 1 to 4 [go to x=(col*40-80) y=(row*30-60), stamp]`. **Process:** (1) identify that rows need one loop, columns need another, (2) determine which loop is outer vs inner, (3) calculate positions from row/col values. This construction skill follows tracing (G4.07).

Dependencies:
* T07.G4.07: Trace nested loops with fixed counts





ID: T07.G4.08
Topic: T07 – Loops
Skill: Use timed repeat for spaced animations
Description: Students use CreatiCode's `repeat (N) times at intervals of (T) [seconds/milliseconds/frames]` block. This runs the loop body N times with automatic pauses between iterations. Example: `repeat 3 times at intervals of 1 second [say counter]` displays "1", waits 1 second, "2", waits 1 second, "3". Cleaner than `repeat [action, wait]` because timing is built in. Applications: countdown timers, pulsing animations, timed sequences.

Dependencies:
* T07.G4.03: Use a counter variable inside a loop
* T07.G4.01: Create a forever loop for keyboard controls



ID: T07.G4.08.01
Topic: T07 – Loops
Skill: Compare manual wait vs timed repeat for animations
Description: Students compare two approaches to timed animations and identify when each is appropriate. **Approach A (manual):** `repeat 5 [move 10, wait 0.5 secs]` - wait block inside loop. **Approach B (timed):** `repeat 5 times at intervals of 0.5 seconds [move 10]` - built-in timing. **Analysis:** Manual wait: flexible timing per iteration, can vary wait. Timed repeat: cleaner code, guaranteed intervals even if action takes time. Students choose the appropriate approach for different scenarios.

Dependencies:
* T07.G4.08: Use timed repeat for spaced animations





ID: T07.G5.01
Topic: T07 – Loops
Skill: Use a loop to run repeated experiments
Description: Students use loops to repeat a random experiment many times and count outcomes. Pattern: (1) initialize counters to 0, (2) repeat N times: generate random outcome, increment appropriate counter, (3) display results. Example: flip a coin 100 times, count heads vs tails. Students see that more trials → results closer to expected probability. This connects loops to data collection and statistics.

Dependencies:
* T07.G4.08.01: Compare manual wait vs timed repeat for animations
* T07.G4.02.01: Identify which iterations trigger a condition
* T10.G4.18: Use random numbers to model chance or variety



ID: T07.G5.01.01
Topic: T07 – Loops
Skill: Use loops to collect user input repeatedly
Description: Students use loops to gather multiple inputs from the user. **Pattern:** `set names to empty list, repeat 3 [ask "Enter a name", add (answer) to names]`. **Variations:** (1) Collect scores until user enters -1 (sentinel): `repeat until (answer = -1) [ask "Score?", if (answer ≠ -1) [add answer to scores]]`, (2) Collect exactly 5 guesses for a game. **Key insight:** Loops automate repetitive input collection, making programs interactive and data-driven.

Dependencies:
* T07.G5.01: Use a loop to run repeated experiments





ID: T07.G5.02
Topic: T07 – Loops
Skill: Populate a list using a loop
Description: Students use loops to add items to a list programmatically. Patterns: (1) sequential numbers: `for i from 1 to 10 [add i to list]`, (2) user input: `repeat 5 [ask "Enter name", add answer to list]`, (3) calculated values: `for i from 1 to 5 [add (i * i) to list]` creates [1, 4, 9, 16, 25]. Students delete all from list first, then use the loop to populate it.

Dependencies:
* T07.G4.03.01: Use a for-loop with automatic counter
* T10.G5.01: Create and populate a list with items





ID: T07.G5.03
Topic: T07 – Loops
Skill: Compute sum and average using a loop
Description: Students use loops with an accumulator variable to compute aggregates. Sum pattern: `set total to 0, for each item in scores [change total by item]`. Average pattern: add count, then `set average to (total / count)`. Example: given scores [85, 90, 78], total = 253, average = 253/3 = 84.3. Students apply this to calculate totals, averages, or other aggregate statistics from lists.

Dependencies:
* T07.G5.02: Populate a list using a loop
* T07.G5.01.01: Use loops to collect user input repeatedly



ID: T07.G5.03.01
Topic: T07 – Loops
Skill: Compute min and max using a loop with comparisons
Description: Students find minimum and maximum values in a list using the accumulator pattern with comparisons. **Min pattern:** `set minVal to (item 1 of list), for each item in list [if (item < minVal) [set minVal to item]]`. **Max pattern:** similar with `>`. **Task:** Given temperatures [72, 68, 75, 70, 65], find the lowest (65) and highest (75). **Key insight:** Initialize accumulator to first item (not 0 or arbitrary value), then compare each subsequent item. Students trace through to verify correctness.

Dependencies:
* T07.G5.03: Compute sum and average using a loop





ID: T07.G5.04.01
Topic: T07 – Loops
Skill: Predict stamp count before running nested loop
Description: Students read nested loop code and predict the total number of stamps/outputs BEFORE running. **Task:** Given `for row from 1 to 4 [for col from 1 to 5 [stamp]]`, predict stamp count. MCQ: (A) 9 stamps, (B) 20 stamps, (C) 25 stamps. Students calculate: 4 rows × 5 columns = 20. **Verification:** Run code and count stamps to confirm. **Variations:** Different grid sizes, non-square grids. This prediction skill ensures students understand multiplicative relationship before constructing complex patterns.

Dependencies:
* T07.G4.07.01: Build a nested loop to draw a rectangle grid





ID: T07.G5.04
Topic: T07 – Loops
Skill: Create patterns with nested loops
Description: Students use nested loops to create checkerboards, stripes, or color patterns. Example checkerboard: `for row from 1 to 8 [for col from 1 to 8 [if ((row + col) mod 2 = 0) [set color black] else [set color white], stamp]]`. Students modify loop variables and conditions to create different patterns. This combines nested loops with conditionals for visual creativity.

Dependencies:
* T07.G5.04.01: Predict stamp count before running nested loop
* T07.G4.05: Debug off-by-one errors in loops


ID: T07.G5.05
Topic: T07 – Loops
Skill: Iterate over characters in a string using a loop
Description: Students use a for-loop to process each character in a text string one at a time. Pattern: `for i from 1 to (length of text) [set char to (letter i of text), process char]`. Applications: (1) count vowels: `if <char = "a" or char = "e" or ...> [change vowelCount by 1]`, (2) build reversed string: `set reversed to (join char reversed)`, (3) validate input: check each character is a digit. Students apply loop-with-index to text processing.

Dependencies:
* T07.G4.03.01: Use a for-loop with automatic counter
* T07.G5.02: Populate a list using a loop


ID: T07.G5.05.01
Topic: T07 – Loops
Skill: Build a string character by character in a loop
Description: Students construct new strings by building them character by character within a loop. **Task:** Create a program that takes a word and builds a "stretched" version by repeating each letter (e.g., "cat" → "ccaatt"). **Pattern:** `set result to "", for i from 1 to (length of word) [set char to (letter i of word), set result to (join result char char)]`. **Variations:** (1) Build uppercase version, (2) Insert dashes between letters ("c-a-t"), (3) Reverse the string. This skill demonstrates the accumulator pattern applied to string construction.

Dependencies:
* T07.G5.05: Iterate over characters in a string using a loop
* T07.G5.03: Compute sum and average using a loop


ID: T07.G5.06
Topic: T07 – Loops
Skill: Filter list items using a loop with conditional
Description: Students create a new list containing only items that meet a condition. **Task:** Given a list of scores [45, 82, 91, 67, 88, 55], create a new list containing only passing scores (≥70). **Pattern:** `delete all of passingScores, for each item score in allScores [if (score >= 70) [add score to passingScores]]`. **Result:** [82, 91, 88]. **Key insight:** Combining loops with conditionals enables selective processing - a fundamental data processing pattern. Students trace to verify only matching items are added.

Dependencies:
* T07.G5.03: Compute sum and average using a loop
* T07.G4.02.01: Identify which iterations trigger a condition


ID: T07.G5.07
Topic: T07 – Loops
Skill: Transform list items in place using a loop
Description: Students modify each item in a list using a loop (the "map" pattern). **Task:** Given prices [10, 25, 40, 15], apply a 20% discount to each item. **Pattern:** `for i from 1 to (length of prices) [replace item i of prices with (item i of prices * 0.8)]`. **Result:** [8, 20, 32, 12]. **Comparison with filter (G5.06):** Filter creates a NEW list with selected items; transform MODIFIES existing items in place. **Applications:** (1) Convert temperatures F→C, (2) Round all values, (3) Add prefix to all names. Students trace to verify each item is modified correctly.

Dependencies:
* T07.G5.06: Filter list items using a loop with conditional
* T07.G4.03.01: Use a for-loop with automatic counter


ID: T07.G5.08
Topic: T07 – Loops
Skill: Count items matching a condition using a loop
Description: Students count how many list items satisfy a condition (the "count" pattern). **Task:** Given ages [12, 17, 19, 14, 21, 16], count how many are teenagers (13-19). **Pattern:** `set teenCount to 0, for each item age in ages [if (age >= 13 and age <= 19) [change teenCount by 1]]`. **Result:** 4 (17, 19, 14, 16). **Key insight:** The count pattern is similar to filter, but tracks a number instead of building a list. This is more efficient when you only need the count, not the items themselves. **Variations:** Count negative numbers, count items longer than N characters.

Dependencies:
* T07.G5.06: Filter list items using a loop with conditional
* T07.G4.02.01: Identify which iterations trigger a condition


ID: T07.G6.01
Topic: T07 – Loops
Skill: Trace nested loops with variable bounds
Description: Students trace nested loops where inner loop count depends on outer loop variable. Example: `for i from 1 to 4 [repeat (i) times [stamp]]`. Trace: i=1 → 1 stamp, i=2 → 2 stamps, i=3 → 3 stamps, i=4 → 4 stamps, total = 1+2+3+4 = 10 stamps. Students calculate total iterations by summing variable inner counts. This is more complex than fixed nested loops.

Dependencies:
* T07.G5.04: Create patterns with nested loops
* T07.G5.03.01: Compute min and max using a loop with comparisons
* T09.G4.01: Use variables to store and update game state





ID: T07.G6.02
Topic: T07 – Loops
Skill: Refactor varying repetitions into loops with expressions
Description: Students convert code with slight variations into loops using mathematical expressions. Given: `move 10, move 20, move 30, move 40`. Pattern: values are i*10 for i=1,2,3,4. Refactored: `for i from 1 to 4 [move (i * 10)]`. Students identify the mathematical relationship and express it using the loop variable. This is more advanced than G4.04's identical repetitions.

Dependencies:
* T07.G4.04: Refactor repeated code into a loop
* T07.G4.03.02: Use for-loops with step sizes other than 1
* T09.G4.01: Use variables to store and update game state





ID: T07.G6.03
Topic: T07 – Loops
Skill: Implement linear search using a loop
Description: Students search a list for a target value using a loop. Pattern: `set found to false, for each item in list [if (item = target) [set found to true, set result to item]]`. Optionally use break to exit early when found. Example: find first score above 90 in [85, 92, 78, 95] → result is 92. Students understand linear search checks each item one by one.

Dependencies:
* T07.G5.03: Compute sum and average using a loop
* T08.G4.03: Use if-then-else in a project





ID: T07.G6.04
Topic: T07 – Loops
Skill: Identify and fix infinite loops
Description: Students recognize loops that never terminate and fix them. Common causes: (1) `repeat until` with impossible condition (e.g., `repeat until <x = 5>` but x never changes), (2) `forever` with no break or stop. Fixes: ensure the condition CAN become true, add a counter limit, or use `break` when appropriate. Students trace the loop to prove it never ends, then propose fixes.

Dependencies:
* T07.G4.05.01: Debug repeat-until condition errors
* T07.G5.04: Create patterns with nested loops


ID: T07.G6.04.01
Topic: T07 – Loops
Skill: Debug nested loops with incorrect bounds
Description: Students debug nested loops where the inner or outer loop has wrong start/end values. **Task:** Given code to draw a 5×4 grid but it draws 5×5, identify and fix the bug. **Common bugs:** (1) Inner loop uses outer variable instead of its own limit, (2) Off-by-one in both loops compounds (5×5 instead of 4×4), (3) Wrong variable updated in inner loop. **Process:** (1) Trace outer loop iterations, (2) For EACH outer iteration, trace inner loop, (3) Count total outputs, (4) Compare to expected, (5) Fix bounds. **Key insight:** Nested loop bugs are harder to spot because errors multiply—a small mistake in the inner loop happens once per outer iteration.

Dependencies:
* T07.G6.04: Identify and fix infinite loops
* T07.G6.01: Trace nested loops with variable bounds



ID: T07.G6.05
Topic: T07 – Loops
Skill: Use trace tables for nested loop calculations
Description: Students create trace tables to track variables through nested loops. Table columns: outer counter, inner counter, accumulator(s). Rows: one per inner iteration. Example: compute sum of products for `for i from 1 to 3 [for j from 1 to 2 [change sum by (i*j)]]`. Trace: (i=1,j=1)→sum=1, (i=1,j=2)→sum=3, (i=2,j=1)→sum=5, etc. Final sum=18. This systematic approach is essential for competition programming.

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T07.G5.03: Compute sum and average using a loop





ID: T07.G6.06
Topic: T07 – Loops
Skill: Trace nested loops for spatial patterns
Description: Students trace nested loops to predict visual output. Given code that draws shapes at positions based on loop variables, students sketch the expected pattern. Example: `for row from 1 to 3 [for col from 1 to row [stamp at (col*30, row*30)]]` creates a triangle: row 1 → 1 stamp, row 2 → 2 stamps, row 3 → 3 stamps. Students connect loop iteration numbers to x,y coordinates.

Dependencies:
* T07.G6.05: Use trace tables for nested loop calculations
* T07.G5.04: Create patterns with nested loops





ID: T07.G6.07
Topic: T07 – Loops
Skill: Implement iterative update loops
Description: Students build loops where each iteration updates a value based on its previous state. **Task:** Create a compound interest calculator where $100 grows 5% each year: `set balance to 100, repeat 5 [set balance to (balance * 1.05)]`. **Trace:** Year 1: $105, Year 2: $110.25, Year 3: $115.76, Year 4: $121.55, Year 5: $127.63. **Additional examples:** (1) Decay: `repeat 10 [set health to (health * 0.9)]`, (2) Population growth: `repeat years [set population to (population + growthRate)]`. **Key insight:** The NEW value depends on the OLD value—this pattern is fundamental to simulations, physics, and financial modeling.

Dependencies:
* T07.G5.01: Use a loop to run repeated experiments
* T07.G6.05: Use trace tables for nested loop calculations





ID: T07.G6.08.01
Topic: T07 – Loops
Skill: Use break to exit a loop early
Description: Students use CreatiCode's `break` block to exit a loop immediately when a condition is met. Example: `for i from 1 to 100 [if (item i of list = target) [set found to i, break]]` - stops as soon as target is found instead of checking all 100 items. Applications: early exit from search, stop game loop on win/lose, terminate input on sentinel value. Break makes code more efficient.

Dependencies:
* T07.G6.03: Implement linear search using a loop
* T07.G4.03.01: Use a for-loop with automatic counter





ID: T07.G6.08.02
Topic: T07 – Loops
Skill: Use continue to skip loop iterations
Description: Students use CreatiCode's `continue` block to skip the current iteration and move to the next. Example: `for i from 1 to 10 [if (i mod 2 = 0) [continue], say i]` - skips even numbers, only says 1, 3, 5, 7, 9. Use continue for: filtering invalid items, skipping special cases, conditional processing. Compare: continue vs wrapping loop body in if-else (continue is often cleaner).

Dependencies:
* T07.G6.08.01: Use break to exit a loop early



ID: T07.G6.08.03
Topic: T07 – Loops
Skill: Compare break vs flag variable for early exit
Description: Students compare two approaches to early loop termination. **Approach A (break):** `for each item [if (item = target) [set found to true, break]]` - immediately exits. **Approach B (flag):** `set found to false, for each item [if (found = false and item = target) [set found to true]]` - checks flag each iteration. **Analysis:** Break is cleaner and more efficient (fewer iterations after finding). Flag works in languages without break. Students identify when each approach is appropriate.

Dependencies:
* T07.G6.08.02: Use continue to skip loop iterations





ID: T07.G6.09.01
Topic: T07 – Loops
Skill: Use for-each item to iterate over list values
Description: Students use CreatiCode's `for each item [name] in [myList]` block to process each list item by value. Example: `for each item score in highScores [say score]` - the variable `score` takes each value (85, 92, 78...) in turn. Use for-each item when you care about VALUES, not positions. Cleaner than: `for i from 1 to (length of list) [set item to (item i of list)]`.

Dependencies:
* T07.G5.02: Populate a list using a loop
* T10.G5.01: Create and populate a list with items





ID: T07.G6.09.02
Topic: T07 – Loops
Skill: Use for-each index to iterate over list positions
Description: Students use CreatiCode's `for each index [i] in [myList]` block to iterate by position. The variable `i` takes each index (1, 2, 3...) and you access values via `item i of myList`. Use for-each index when you: need both position AND value, want to modify items in place, or work with parallel lists. Example: `for each index i in scores [replace item i of scores with (item i of scores * 2)]` - doubles each score.

Dependencies:
* T07.G6.09.01: Use for-each item to iterate over list values


ID: T07.G6.10
Topic: T07 – Loops
Skill: Iterate over parallel lists using synchronized indices
Description: Students iterate over two or more lists simultaneously using a shared index variable. Pattern: `for i from 1 to (length of names) [set name to (item i of names), set score to (item i of scores), say (join name " scored " score)]`. Applications: (1) display name-score pairs, (2) compare corresponding elements in two lists, (3) merge data from multiple sources. Key insight: parallel lists must have the same length. Students check `length of list1 = length of list2` before iterating.

Dependencies:
* T07.G6.09.02: Use for-each index to iterate over list positions
* T10.G5.01: Create and populate a list with items



ID: T07.G6.11
Topic: T07 – Loops
Skill: Use for-each-3D-object to iterate over scene objects
Description: Students use CreatiCode's `for each 3D object named [variable]` block to process all 3D objects in a scene. **Pattern:** After creating multiple 3D objects (boxes, spheres), use `for each 3D object named [objName] [select sprite object by name (objName), turn 30 degrees around Z axis]` to apply an action to all objects. **Applications:** (1) make all objects spin together, (2) change colors of all objects based on condition, (3) collect positions of all objects for physics simulation. This CreatiCode-specific loop block enables powerful 3D scene manipulation.

Dependencies:
* T07.G6.09.01: Use for-each item to iterate over list values
* T07.G6.08.03: Compare break vs flag variable for early exit


ID: T07.G6.12
Topic: T07 – Loops
Skill: Iterate over table variable rows for structured data
Description: Students use loops to process rows in CreatiCode table variables, which store 2D structured data (like spreadsheets). **Context:** CreatiCode's AI vision blocks (hand detection, body pose) output data to table variables with rows for each landmark and columns for x, y, z coordinates. **Pattern:** `for row from 1 to (row count of handData) [set x to (cell (row, 1) of handData), set y to (cell (row, 2) of handData), draw point at x, y]`. **Applications:** (1) Visualize all 21 hand landmarks from hand tracking, (2) Process body pose data (33 keypoints), (3) Iterate over CSV-imported data. **Key insight:** Table variables extend lists to 2D—loops let you process either all rows (for each landmark) or all columns (for each property). This connects programming to data science workflows.

Dependencies:
* T07.G6.09.02: Use for-each index to iterate over list positions
* T07.G6.10: Iterate over parallel lists using synchronized indices


ID: T07.G7.01
Topic: T07 – Loops
Skill: Simulate physics motion using loops
Description: Students use loops to simulate motion with physics-like rules. Gravity pattern: `forever [change y by velocity, change velocity by -0.5]` - object falls with acceleration. Friction pattern: `forever [change x by speed, set speed to (speed * 0.95)]` - sliding slowdown. Bounce pattern: add `if <touching edge?> [set velocity to (velocity * -0.8)]`. Students see how iterative updates create realistic motion.

Dependencies:
* T07.G6.07: Implement iterative update loops
* T07.G6.11: Use for-each-3D-object to iterate over scene objects





ID: T07.G7.02
Topic: T07 – Loops
Skill: Process 2D grids using nested loops
Description: Students use nested loops to process or generate 2D tile maps. Pattern: `for row from 0 to (gridHeight-1) [for col from 0 to (gridWidth-1) [process tile at (row, col)]]`. Applications: initialize game board, check all cells for conditions, draw tile-based maps. Students understand row-major vs column-major order and calculate 1D index from 2D coordinates if needed: `index = row * width + col`.

Dependencies:
* T07.G6.06: Trace nested loops for spatial patterns
* T07.G6.05: Use trace tables for nested loop calculations
* T08.G6.01: Use conditionals to control simulation steps



ID: T07.G7.02.01
Topic: T07 – Loops
Skill: Calculate 1D index from 2D coordinates
Description: Students convert between 2D grid positions and 1D list indices. **Formula:** `index = row * width + col` (0-indexed) or `index = (row-1) * width + col` (1-indexed). **Task:** Given a 4×5 grid stored in a list, find the index of cell at row 3, col 2. Calculate: (3-1) × 5 + 2 = 12. **Reverse:** Given index 17, find row and col: row = floor(17/5) + 1 = 4, col = 17 mod 5 = 2. This skill is essential for working with grids stored as flat lists (common in game development).

Dependencies:
* T07.G7.02: Process 2D grids using nested loops





ID: T07.G7.03
Topic: T07 – Loops
Skill: Compare loop algorithms by counting iterations
Description: Students compare two solutions to the same problem and count iterations. Example: compute 20 ÷ 3. Method A (repeated subtraction): 20→17→14→11→8→5→2 = 6 iterations. Method B (direct division): 1 operation. For larger numbers (2000 ÷ 3), Method A needs ~666 iterations while Method B still takes 1. Students reason about efficiency: which solution scales better?

Dependencies:
* T07.G6.07: Implement iterative update loops
* T07.G6.05: Use trace tables for nested loop calculations





ID: T07.G7.04
Topic: T07 – Loops
Skill: Recognize and apply accumulator patterns
Description: Students identify common loop patterns: (1) Count: `set count to 0, for each item [if condition [change count by 1]]`, (2) Sum: `set total to 0, for each item [change total by item]`, (3) Min/Max: `set max to (item 1), for each item [if (item > max) [set max to item]]`. Students recognize these patterns in code and apply them to new problems. These are reusable solutions for aggregation.

Dependencies:
* T07.G6.07: Implement iterative update loops
* T07.G5.03.01: Compute min and max using a loop with comparisons
* T08.G6.01: Use conditionals to control simulation steps


ID: T07.G7.05
Topic: T07 – Loops
Skill: Optimize loop performance by reducing redundant operations
Description: Students identify and fix performance issues in loops. Common optimizations: (1) **Cache list length**: `set len to (length of list)` before loop instead of checking each iteration, (2) **Move constant calculations outside**: compute `radius * 2` once before loop, not inside, (3) **Avoid unnecessary operations**: don't update display every iteration when only final result matters. Example: inefficient loop recalculates `(length of scores)` 1000 times; optimized version calculates once. Students profile loops by counting total operations.

Dependencies:
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G7.04: Recognize and apply accumulator patterns



ID: T07.G7.06
Topic: T07 – Loops
Skill: Implement binary search using loops
Description: Students implement iterative binary search to find a value in a SORTED list efficiently. **Pattern:** `set low to 1, set high to (length of list), repeat until (low > high) [set mid to floor((low+high)/2), if (item mid = target) [found at mid, break], if (item mid < target) [set low to mid+1] else [set high to mid-1]]`. **Comparison:** Binary search checks ~log₂(n) items vs linear search checking all n. For 1000 items: binary ≈ 10 checks, linear ≈ 500 average. Students trace through examples and verify O(log n) efficiency.

Dependencies:
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G7.05: Optimize loop performance by reducing redundant operations



ID: T07.G7.07
Topic: T07 – Loops
Skill: Use loops for input validation with retry
Description: Students implement validation loops that keep asking for input until valid. **Pattern:** `repeat until (validInput) [ask "Enter age (1-120)", if (answer > 0 and answer <= 120) [set validInput to true, set age to answer] else [say "Invalid, try again"]]`. **Applications:** (1) Ensure numeric input in range, (2) Validate password format, (3) Confirm user choice (yes/no). **Key insight:** Loops with user input must have achievable exit conditions to avoid infinite loops in interactive programs.

Dependencies:
* T07.G7.04: Recognize and apply accumulator patterns
* T07.G7.05: Optimize loop performance by reducing redundant operations


ID: T07.G7.08
Topic: T07 – Loops
Skill: Implement bubble sort using nested loops
Description: Students implement bubble sort to order a list. **Algorithm:** Compare adjacent pairs and swap if out of order; repeat passes until no swaps needed. **Pattern:** `repeat (length of list - 1) [for i from 1 to (length of list - 1) [if (item i > item (i+1)) [swap items at i and i+1]]]`. **Trace:** For [64, 34, 25]: Pass 1 → [34, 25, 64], Pass 2 → [25, 34, 64]. **Key insight:** Outer loop controls passes, inner loop does comparisons. Students trace through small lists and count total comparisons (n×(n-1)/2 for n items).

Dependencies:
* T07.G7.02: Process 2D grids using nested loops
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G6.03: Implement linear search using a loop


ID: T07.G7.08.01
Topic: T07 – Loops
Skill: Trace a sorting algorithm step by step
Description: Students trace sorting algorithms iteration by iteration, recording the list state after each comparison/swap. **Task:** Given list [5, 2, 8, 1] and bubble sort, trace each step: (1) Compare 5,2 → swap → [2,5,8,1], (2) Compare 5,8 → no swap, (3) Compare 8,1 → swap → [2,5,1,8], etc. **Output:** Students complete a trace table showing: iteration number, comparison made, swap (yes/no), and list state. This detailed tracing skill is essential for understanding algorithm behavior and debugging sorting code.

Dependencies:
* T07.G7.08: Implement bubble sort using nested loops
* T07.G6.05: Use trace tables for nested loop calculations


ID: T07.G7.09
Topic: T07 – Loops
Skill: Compare recursion vs iteration for repeated tasks
Description: Students compare iterative loops to recursive approaches for the same problem. **Example 1 - Factorial:** Iterative: `set result to 1, for i from 1 to n [set result to (result * i)]`. Recursive (via custom blocks): `factorial(n) = if n=1 return 1, else return n * factorial(n-1)`. **Example 2 - Countdown:** Iterative: `for i from 10 to 1 step -1 [say i]`. Recursive: `countdown(n) = say n, if n>1 then countdown(n-1)`. **Analysis:** Iterative is often more efficient (no call stack overhead); recursive is often more intuitive for naturally recursive problems (trees, fractals). Students implement both versions and compare. **Key insight:** The same repeated computation can be expressed as a loop OR as a function calling itself—understanding both expands problem-solving toolkit.

Dependencies:
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G7.04: Recognize and apply accumulator patterns


ID: T07.G7.10
Topic: T07 – Loops
Skill: Implement loops with multiple exit conditions
Description: Students design loops that can exit for multiple different reasons. **Task:** Search a list for a target value, but also stop if you've checked 100 items (timeout) or if you find a negative number (error). **Pattern:** `set found to false, set error to false, set i to 1, repeat until (found or error or i > 100) [if (item i < 0) [set error to true] else [if (item i = target) [set found to true] else [change i by 1]]]`. **After loop:** Check which condition caused exit: `if found [say "Found!"] else [if error [say "Error: negative value"] else [say "Timeout"]]`. **Key insight:** Real-world loops often have multiple exit conditions (success, failure, timeout). Students learn to handle each exit case appropriately.

Dependencies:
* T07.G7.07: Use loops for input validation with retry
* T07.G6.08.01: Use break to exit a loop early


ID: T07.G8.01
Topic: T07 – Loops
Skill: Implement Monte Carlo simulations
Description: Students use loops to estimate probabilities through simulation. Pattern: `set successes to 0, repeat 10000 [run random trial, if (success condition) [change successes by 1]], set probability to (successes / 10000)`. Example: estimate P(sum ≥ 9 with 2 dice) by simulating 10000 rolls. Students compare experimental results to theoretical probability and see convergence with more trials.

Dependencies:
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G7.04: Recognize and apply accumulator patterns
* T07.G7.05: Optimize loop performance by reducing redundant operations





ID: T07.G8.02
Topic: T07 – Loops
Skill: Analyze iterative algorithm structure
Description: Students analyze iterative algorithms to identify three components: (1) **Initialization** - starting state/values, (2) **Update rule** - how values change each iteration, (3) **Termination condition** - when the loop stops. Example (GCD): init: a=48, b=18; update: replace larger with (larger mod smaller); terminate: when a=b. Students label these parts in given algorithms (primality, Fibonacci, binary search).

Dependencies:
* T01.G6.01: Count comparisons in linear and binary search
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G6.01: Trace nested loops with variable bounds





ID: T07.G8.02.01
Topic: T07 – Loops
Skill: Implement GCD using iterative subtraction
Description: Students implement Euclidean algorithm for GCD. Pattern: `repeat until <a = b> [if (a > b) [set a to (a - b)] else [set b to (b - a)]]`. Example: GCD(48, 18): 48→30→12→12; 18→6→6. Result: 6. Students trace the algorithm to verify correctness and understand why it terminates (one value decreases each iteration until equal).

Dependencies:
* T07.G8.02: Analyze iterative algorithm structure
* T09.G6.01: Model real-world quantities using variables and formulas
* T08.G6.01: Use conditionals to control simulation steps





ID: T07.G8.02.02
Topic: T07 – Loops
Skill: Check primality using trial division loop
Description: Students implement primality testing. Pattern: `set isPrime to true, for i from 2 to (sqrt of n) [if (n mod i = 0) [set isPrime to false, break]]`. Optimization: only check up to √n (if n has a factor > √n, it must have one < √n too). Students trace for n=17: check 2,3,4 (4>√17≈4.1), no divisors found → prime.

Dependencies:
* T07.G8.02: Analyze iterative algorithm structure
* T07.G6.08.01: Use break to exit a loop early
* T08.G6.01: Use conditionals to control simulation steps





ID: T07.G8.02.03
Topic: T07 – Loops
Skill: Generate Fibonacci numbers iteratively
Description: Students implement iterative Fibonacci calculation. Pattern: `set prev to 0, set curr to 1, repeat (n-1) [set temp to curr, set curr to (prev + curr), set prev to temp]`. For n=7: sequence is 0,1,1,2,3,5,8 → result is 8. Students maintain two rolling state variables, demonstrating how iterative algorithms track multi-value state across iterations.

Dependencies:
* T07.G8.02: Analyze iterative algorithm structure
* T07.G6.07: Implement iterative update loops



ID: T07.G8.02.04
Topic: T07 – Loops
Skill: Implement Newton-Raphson iteration for square roots
Description: Students implement Newton's method to approximate square roots iteratively. **Pattern:** To find √S: `set guess to S/2, repeat 10 [set guess to ((guess + S/guess) / 2)]`. **Example:** √25: guess starts at 12.5 → 6.25 → 5.125 → 5.002 → 5.0000... **Key insight:** Each iteration improves the estimate. Students trace convergence and learn that iterative refinement is a powerful technique used in numerical computing, graphics, and AI optimization.

Dependencies:
* T07.G8.02.03: Generate Fibonacci numbers iteratively
* T07.G8.02: Analyze iterative algorithm structure





ID: T07.G8.03
Topic: T07 – Loops
Skill: Process 2D data structures with nested loops
Description: Students use nested loops to compute statistics on 2D data. Examples: (1) Row sums: `for row from 1 to rows [set rowSum to 0, for col from 1 to cols [change rowSum by (value at row,col)], add rowSum to results]`. (2) Column averages. (3) Count cells matching condition. Students apply accumulator patterns within nested loop structures.

Dependencies:
* T07.G7.02.01: Calculate 1D index from 2D coordinates
* T07.G7.04: Recognize and apply accumulator patterns





ID: T07.G8.04
Topic: T07 – Loops
Skill: Justify loop design choices
Description: Students compare loop alternatives and justify their choice. Considerations: (1) **Termination** - `repeat N` always terminates vs `repeat until` may not, (2) **Clarity** - for-each is clearer for list iteration than index loops, (3) **Efficiency** - break for early exit vs checking all items, (4) **Edge cases** - what if list is empty? what if condition never true? Students evaluate trade-offs for given problems.

Dependencies:
* T07.G7.03: Compare loop algorithms by counting iterations
* T07.G7.04: Recognize and apply accumulator patterns
* T07.G6.04: Identify and fix infinite loops


ID: T07.G8.05
Topic: T07 – Loops
Skill: Identify loop invariants in iterative algorithms
Description: Students identify loop invariants - properties that remain true before and after each iteration. Example (sum algorithm): invariant is "total equals sum of all items processed so far." For binary search: invariant is "if target exists, it's between low and high." Students state the invariant in words, verify it holds for initialization and each iteration, and explain why it proves correctness. Loop invariants are essential for reasoning about algorithm correctness.

Dependencies:
* T07.G8.02: Analyze iterative algorithm structure
* T07.G8.04: Justify loop design choices


ID: T07.G8.06
Topic: T07 – Loops
Skill: Describe loop requirements to AI coding assistant
Description: Students write clear natural language descriptions of loop behavior for AI code generation (using CreatiCode's ChatGPT blocks or external AI). Effective prompts specify: (1) what data to process, (2) what to do each iteration, (3) when to stop, (4) what result to produce. Example prompt: "Write a loop that goes through the scores list and counts how many are above 80, stopping when count reaches 5 or list ends." Students compare AI-generated code to their own, identifying differences and evaluating correctness.

Dependencies:
* T07.G8.04: Justify loop design choices
* T07.G7.07: Use loops for input validation with retry



ID: T07.G8.07
Topic: T07 – Loops
Skill: Implement game loops with delta time
Description: Students implement game loops that use delta time for frame-rate independent motion. **Pattern:** `set lastTime to (timer), forever [set deltaTime to (timer - lastTime), set lastTime to timer, change x by (speed * deltaTime)]`. **Key insight:** Multiplying movement by deltaTime ensures consistent speed regardless of frame rate - fast computers don't make the game faster. Students compare fixed-timestep vs delta-time approaches and understand why professional games use delta time.

Dependencies:
* T07.G8.01: Implement Monte Carlo simulations
* T07.G8.04: Justify loop design choices



ID: T07.G8.08
Topic: T07 – Loops
Skill: Design loops for batch AI API calls
Description: Students design loops to process multiple items using AI services. **Pattern:** `for each item in inputs [send item to ChatGPT block, wait for response, add response to results, wait 0.5 seconds]`. **Considerations:** (1) Rate limiting - add delays between calls, (2) Error handling - what if one call fails?, (3) Progress feedback - show user which item is processing. **Applications:** Classify multiple images, translate list of sentences, generate summaries for articles. Students balance efficiency with API constraints.

Dependencies:
* T07.G8.06: Describe loop requirements to AI coding assistant
* T07.G8.04: Justify loop design choices



ID: T07.G8.09
Topic: T07 – Loops
Skill: Analyze loop complexity (O(n), O(n²), O(log n))
Description: Students analyze loop structures to determine Big-O complexity. **Single loop** over n items: O(n). **Nested loops** (for i to n [for j to n]): O(n²). **Binary search** halving each time: O(log n). **Task:** Given code, identify the complexity and explain how doubling n affects runtime. Example: nested loop with n=100 runs 10,000 times; with n=200 runs 40,000 times (4× slower, not 2×). Students predict performance for large inputs and choose appropriate algorithms.

Dependencies:
* T07.G7.06: Implement binary search using loops
* T07.G8.02: Analyze iterative algorithm structure


ID: T07.G8.10
Topic: T07 – Loops
Skill: Process streaming AI responses with loops
Description: Students use loops to process streaming responses from ChatGPT in real-time. **Pattern using CreatiCode:** Configure ChatGPT block with streaming=true, then use `repeat until <chatGPT streaming done?> [set chunk to (chatGPT streaming text), append chunk to display, wait 0.05 seconds]`. **Key insight:** Streaming mode returns partial responses incrementally rather than waiting for completion. **Applications:** Display AI responses as they're generated (like typing effect), process long responses progressively, provide responsive user feedback. Students understand the difference between batch and stream processing patterns.

Dependencies:
* T07.G8.08: Design loops for batch AI API calls
* T07.G7.07: Use loops for input validation with retry


ID: T07.G8.11
Topic: T07 – Loops
Skill: Implement selection sort and compare to bubble sort
Description: Students implement selection sort and compare its performance to bubble sort. **Algorithm:** Find minimum in unsorted portion, swap to front, repeat. **Pattern:** `for i from 1 to (length-1) [set minIndex to i, for j from (i+1) to length [if (item j < item minIndex) [set minIndex to j]], swap items at i and minIndex]`. **Comparison:** Both are O(n²), but selection sort does fewer swaps (n vs up to n²). Students trace both algorithms on the same data and count operations. **Key insight:** Different algorithms with same complexity can have different practical performance.

Dependencies:
* T07.G7.08: Implement bubble sort using nested loops
* T07.G8.09: Analyze loop complexity (O(n), O(n²), O(log n))


ID: T07.G8.12
Topic: T07 – Loops
Skill: Design loops for paginated API responses
Description: Students implement loops that handle paginated data from APIs, where results are returned in chunks. **Scenario:** An API returns 10 items per page, and you need to collect all items across multiple pages. **Pattern:** `set allResults to [], set page to 1, set hasMore to true, repeat until (not hasMore) [request API with page number, add items from response to allResults, if (response.nextPage exists) [change page by 1] else [set hasMore to false]]`. **Key considerations:** (1) Detect when there are no more pages (empty response, no nextPage field, or page count reached), (2) Handle rate limits with delays between requests, (3) Set maximum page limit to prevent infinite loops if API misbehaves. **Applications:** Fetch all GitHub repos, retrieve full search results, collect all database records.

Dependencies:
* T07.G8.08: Design loops for batch AI API calls
* T07.G7.10: Implement loops with multiple exit conditions


ID: T07.G8.13
Topic: T07 – Loops
Skill: Implement asynchronous processing patterns with loops
Description: Students design loops that handle asynchronous operations where results arrive later. **Context:** In CreatiCode, AI blocks like ChatGPT and speech recognition operate asynchronously—you start them and results arrive later. **Pattern 1 - Polling loop:** `start speech recognition, repeat until (speech text available) [wait 0.1 seconds], process (speech text)`. **Pattern 2 - Callback accumulation:** Start multiple AI requests, use a forever loop to check for completed responses and process them as they arrive. **Pattern 3 - Sequential async:** `for each item in inputs [start ChatGPT request for item, wait until (response ready), add response to results]`. **Key insight:** Unlike synchronous loops where each iteration completes before the next, async loops must explicitly wait for or poll for completion. This pattern is fundamental to modern programming with APIs, databases, and network requests.

Dependencies:
* T07.G8.10: Process streaming AI responses with loops
* T07.G8.12: Design loops for paginated API responses


# T08 - Conditions & Logic (Phase 9 Optimized - November 2025)
# Phase 9 Major Optimizations Applied:
# 1. STREAMLINED K-2 PROGRESSION WITH OR CONCEPT:
#    - GK.07: NEW - Identify "either works" scenarios (OR foundation)
#    - G1.07: NEW - Sort by "this OR that" rules
#    - G2.10: NEW - Compare AND vs OR in picture scenarios
# 2. REORGANIZED GRADE 3 WITH CLEANER ID PROGRESSION:
#    - Renamed G3.00-pre → G3.01 for cleaner numbering
#    - Fixed all G3 dependencies to use new IDs
# 3. RENUMBERED ALL G4 SKILLS SEQUENTIALLY (G4.01-G4.24):
#    - Removed confusing .00, .00b, .01a, .01b suffixes
#    - All skills now numbered sequentially for clarity
# 4. RENUMBERED ALL G5 SKILLS SEQUENTIALLY (G5.01-G5.20):
#    - Consolidated duplicate ternary skills
#    - Clean progression from flowcharts to advanced patterns
# 5. CREATICODE-SPECIFIC BLOCKS COVERAGE:
#    - G3.10: Use "repeat until" for condition-terminated loops
#    - G4.22: Use "continue" block to skip loop iterations
#    - G4.23: Use "break" block to exit loops early
#    - G5.18: Use ternary if-then-else reporter
#    - G5.19: Use regex conditions for pattern matching
# 6. AI-ERA CONDITIONAL PATTERNS:
#    - G6.05: Use conditionals with AI detection results
#    - G6.08: Build voice command parser with conditional dispatch
#    - G7.07: Design conversation flow with conditional branching
#    - G8.07: Implement confidence-based AI decision making
# 7. PROFESSIONAL SOFTWARE PATTERNS:
#    - G5.20: Implement feature flags using boolean conditionals
#    - G6.09: Design permission and access control conditionals
#    - G7.08: Implement circuit breaker pattern for failing services
#    - G8.08: Design A/B testing conditionals for experiments
# 8. ENHANCED DEBUGGING PROGRESSION:
#    - G3: Wrong comparison operator (single condition)
#    - G4: AND/OR confusion, wrong operator in compound condition
#    - G5: Multi-branch logic errors, unreachable branches
#    - G6: State-dependent bugs, priority order bugs
#    - G7: Coverage gaps, missing edge cases
#    - G8: Formal verification, self-validating systems
# 9. DEPENDENCY FIXES:
#    - All intra-topic dependencies now follow X-2 rule
#    - Cross-topic dependencies preserved unchanged
# Total: 121 skills (was 118: +3 new K-2 skills for OR concept foundation)

ID: T08.GK.01
Topic: T08 – Conditions & Logic
Skill: Match pictures to "if it rains" rules
Description: **Student task:** Look at pictures showing weather (rain, sun, snow) and actions (umbrella, sunglasses, coat). Drag each action picture to match the correct "If [weather], then [action]" sentence. For example, drag umbrella picture to "If it rains, then use an umbrella." This drag-and-drop matching activity with 4 items helps students **recognize that conditions lead to specific actions** using familiar weather scenarios.

CSTA: EK-ALG-AF-01





ID: T08.GK.02
Topic: T08 – Conditions & Logic
Skill: Choose what happens next based on yes/no
Description: **Student task:** Look at a picture showing a situation (traffic light, animal, daily activity) and answer a yes/no question. Then click which of 2 picture choices shows what happens next. For example, "Is the light green?" - click the walking person if yes, or waiting person if no. This multiple-choice activity builds binary decision-making skills.

Dependencies:
* T08.GK.01: Match pictures to "if it rains" rules

CSTA: EK-ALG-AF-01


ID: T08.GK.03
Topic: T08 – Conditions & Logic
Skill: Complete a picture sequence following an if-then rule
Description: **Student task:** Look at a rule card (e.g., "If animal is a bird, then it goes in the sky") and a sequence of pictures with one missing. Drag the correct picture to complete the sequence that follows the if-then rule. This activity with 3-4 pictures and 2 answer choices develops sequential reasoning with conditional rules.

Dependencies:
* T08.GK.02: Choose what happens next based on yes/no

CSTA: EK-ALG-AF-01





ID: T08.GK.04
Topic: T08 – Conditions & Logic
Skill: Trace a picture robot following if-then instruction cards
Description: **Student task:** A picture robot has 3 instruction cards: "If see apple → pick up", "If see banana → wave", "If see nothing → wait". The robot sees different things in each scene. Drag the robot to do the right action for each scene. This unplugged tracing activity with 4-5 scenes develops mental execution of conditional rules, preparing for code tracing in later grades.

Dependencies:
* T08.GK.03: Complete a picture sequence following an if-then rule

CSTA: EK-ALG-AF-01


ID: T08.GK.05
Topic: T08 – Conditions & Logic
Skill: Identify "either-or" choices in picture scenarios
Description: **Student task:** Look at picture cards showing scenarios with two possible outcomes (e.g., "If sunny, play outside OR if rainy, play inside"). Click which action matches the weather shown in the picture. This multiple-choice activity with 3-4 scenarios introduces the concept that conditions can have alternative outcomes (the foundation for OR logic). Students see that different conditions lead to different actions, building awareness of branching decisions before formal programming.

Dependencies:
* T08.GK.04: Trace a picture robot following if-then instruction cards

CSTA: EK-ALG-AF-01


ID: T08.GK.06
Topic: T08 – Conditions & Logic
Skill: Identify conditions in everyday smart devices
Description: **Student task:** Look at pictures of smart devices: automatic door, motion-sensor light, voice assistant, thermostat. For each device, point to what makes it do something. For the automatic door: "What does the door check before opening?" Click the picture showing a person walking toward it (not the car, not the tree). This connects if-then thinking to real technology children encounter daily, building intuition that computers check conditions everywhere. Use 4-5 familiar smart device scenarios with multiple-choice answers showing what each device "checks" before acting.

Dependencies:
* T08.GK.05: Identify "either-or" choices in picture scenarios

CSTA: EK-ALG-AF-01, EK-IC-CT-01


ID: T08.GK.07
Topic: T08 – Conditions & Logic
Skill: Identify "either works" scenarios in pictures
Description: **Student task:** Look at picture cards showing ways to solve a problem. To go to school: walk OR take bus OR ride bike - ANY of these works! To make a sandwich: need bread AND peanut butter - need BOTH! Sort 4-5 scenario cards into two piles: "need ALL of these" vs "ANY of these works." For example: "To play outside: sunny OR cloudy - either works!" goes in "any works" pile. "To bake a cake: flour AND eggs AND sugar - need all!" goes in "need all" pile. This picture-based sorting introduces the foundational difference between AND (need all) and OR (any works) logic that students will formalize in later grades.

Dependencies:
* T08.GK.06: Identify conditions in everyday smart devices

CSTA: EK-ALG-AF-01


ID: T08.G1.01
Topic: T08 – Conditions & Logic
Skill: Sort cards by if-then rules
Description: **Student task:** Look at 6 picture cards (animals, foods, or objects) and drag each into one of 2 labeled bins based on an "if-then" rule. For example, "If the animal has wings, put it in the 'flies' pile; otherwise put it in the 'walks' pile." This drag-and-drop sorting activity develops classification skills based on conditional criteria.

Dependencies:
* T08.GK.07: Identify "either works" scenarios in pictures

CSTA: E1-ALG-AF-01





ID: T08.G1.02
Topic: T08 – Conditions & Logic
Skill: Predict the outcome of an if-then rule
Description: **Student task:** Read a simple "if-then" rule shown with pictures (e.g., "If the cup is full, stop pouring") and look at the starting situation picture. Click which of 3 picture choices shows what happens next. This multiple-choice prediction activity with visual rule cards develops causal reasoning with conditional rules.

Dependencies:
* T08.G1.01: Sort cards by if-then rules

CSTA: E1-ALG-AF-01





ID: T08.G1.03
Topic: T08 – Conditions & Logic
Skill: Choose between two actions based on a condition
Description: **Student task:** Look at a picture showing today's weather or situation, then choose which action to take. The rule shows two options: "If cold, wear a jacket. If hot, wear a t-shirt." Click the correct clothing picture for today's weather. This multiple-choice activity with 2 picture choices reinforces if-then-else decision patterns.

Dependencies:
* T08.G1.02: Predict the outcome of an if-then rule

CSTA: E1-ALG-AF-01


ID: T08.G1.04
Topic: T08 – Conditions & Logic
Skill: Find the mistake in a picture if-then sequence
Description: **Student task:** Look at a picture story that should follow an if-then rule, but one picture is wrong. The rule says "If it's raining, use an umbrella" but the story shows someone using an umbrella when it's sunny. Click the picture that doesn't follow the rule. This error-spotting activity with 4 pictures develops debugging intuition for conditional logic.

Dependencies:
* T08.G1.03: Choose between two actions based on a condition

CSTA: E1-ALG-AF-01


ID: T08.G1.05
Topic: T08 – Conditions & Logic
Skill: Match multiple if-then rules to picture sequences
Description: **Student task:** Look at 3 different if-then rule cards and 3 picture sequences. Drag each rule card to the picture sequence it describes. For example, match "If hungry → eat food" to the sequence showing a hungry character then eating. This advanced matching activity with multiple rules develops pattern recognition across multiple conditional scenarios simultaneously.

Dependencies:
* T08.G1.04: Find the mistake in a picture if-then sequence

CSTA: E1-ALG-AF-01


ID: T08.G1.06
Topic: T08 – Conditions & Logic
Skill: Trace a robot with multiple rules and find which rule fires first
Description: **Student task:** A helper robot has 3 instruction cards checked in order: "1. If see fire → call for help", "2. If see mess → clean up", "3. If see person → wave hello". The robot sees a messy room with a person inside. Which rule does the robot follow FIRST? Click the correct action. This priority-based tracing with 4-5 scenarios introduces the concept that when multiple conditions are true, the order rules are checked matters (foundation for else-if chains). Students learn that the robot stops at the FIRST matching rule.

Dependencies:
* T08.G1.05: Match multiple if-then rules to picture sequences

CSTA: E1-ALG-AF-01


ID: T08.G1.07
Topic: T08 – Conditions & Logic
Skill: Sort items by "this OR that" rules
Description: **Student task:** Sort 6 picture cards using an OR rule. For example: "Put in the 'can eat' pile if it's a fruit OR a vegetable." An apple goes in (it's a fruit), a carrot goes in (it's a vegetable), a rock doesn't (neither). Or: "Put in the 'transportation' pile if it has wheels OR wings." Practice with 2-3 different OR rules. This builds on GK.07's conceptual introduction by having students actively apply OR logic to sorting tasks. Compare to G1.01 which uses single-property rules - here, items can qualify through EITHER path.

Dependencies:
* T08.G1.06: Trace a robot with multiple rules and find which rule fires first
* T08.GK.07: Identify "either works" scenarios in pictures

CSTA: E1-ALG-AF-01


ID: T08.G2.01
Topic: T08 – Conditions & Logic
Skill: Follow branching paths based on yes/no questions
Description: **Student task:** Follow a colorful flowchart path. At each diamond shape, answer a yes/no question to choose which arrow to follow (yes goes one way, no goes another). After 2-3 decisions, click which end picture you reached. This interactive flowchart activity introduces visual representation of conditional logic and sequential decision-making.

Dependencies:
* T08.G1.07: Sort items by "this OR that" rules

CSTA: E2-ALG-AF-01





ID: T08.G2.02
Topic: T08 – Conditions & Logic
Skill: Create a simple if-then-else rule for a scenario
Description: **Student task:** Look at a picture scenario (traffic light, weather, bedtime) and drag words/pictures from a bank to fill in the blanks: "If ___, then ___, else ___". For example, traffic light: "If light is green, then walk, else wait." This fill-in-the-blank activity with 4-6 draggable options develops the ability to construct complete conditional statements.

Dependencies:
* T08.G2.01: Follow branching paths based on yes/no questions

CSTA: E2-ALG-AF-01




ID: T08.G2.03
Topic: T08 – Conditions & Logic
Skill: Identify which rule applies in a situation
Description: **Student task:** Look at 3 "if-then" rule cards and a picture showing a situation. Click which rule card matches the situation shown. For example, rules about what to do when tired, hungry, or bored—which one fits the picture of a yawning child? This multiple-choice rule selection develops pattern matching between situations and conditional rules.

Dependencies:
* T08.G2.02: Create a simple if-then-else rule for a scenario

CSTA: E2-ALG-AF-01




ID: T08.G2.04
Topic: T08 – Conditions & Logic
Skill: Sort items by two-rule logic (AND situations)
Description: **Student task:** Sort 6 picture cards into 2 bins, but this time TWO things must be true. For example, "Put in the 'can fly' bin ONLY if it has wings AND it's not too heavy." A small bird goes in (has wings AND light), but a penguin doesn't (has wings but can't fly). This introduces the concept that sometimes multiple conditions must ALL be true.

Dependencies:
* T08.G2.03: Identify which rule applies in a situation

CSTA: E2-ALG-AF-01


ID: T08.G2.05
Topic: T08 – Conditions & Logic
Skill: Identify one-rule vs two-rule situations
Description: **Student task:** Read 4 scenarios and decide if each needs just one rule or two rules together. For example, "You can have dessert if you finish dinner" needs one rule, but "You can go swimming if it's warm AND sunny" needs two rules together. Click "one rule" or "two rules" for each scenario. This prepares students for AND logic in later grades.

Dependencies:
* T08.G2.04: Sort items by two-rule logic (AND situations)

CSTA: E2-ALG-AF-01


ID: T08.G2.06
Topic: T08 – Conditions & Logic
Skill: Predict branching flowchart outcomes before tracing
Description: **Student task:** Look at a simple flowchart with 2 decision points and read the starting conditions (e.g., "It is sunny. You have an umbrella."). Before tracing the path, predict which ending you will reach. Then trace to check your prediction. This prediction-then-verify activity develops hypothesis-testing thinking and prepares students for predicting code behavior.

Dependencies:
* T08.G2.01: Follow branching paths based on yes/no questions
* T08.G2.05: Identify one-rule vs two-rule situations

CSTA: E2-ALG-AF-01


ID: T08.G2.07
Topic: T08 – Conditions & Logic
Skill: Debug a broken picture rule
Description: **Student task:** A picture machine is supposed to follow a rule but gives wrong outputs. Look at 3 input-output pairs and figure out what's broken: is the condition wrong, or is the action wrong? For example, the rule says "If red → go to box A" but red items go to box B. Identify whether the condition or action needs fixing. This debugging activity develops systematic error analysis skills.

Dependencies:
* T08.G2.06: Predict branching flowchart outcomes before tracing
* T08.G1.04: Find the mistake in a picture if-then sequence

CSTA: E2-ALG-AF-01


ID: T08.G2.08
Topic: T08 – Conditions & Logic
Skill: Create if-then rules for sorting a set of items
Description: **Student task:** Given 6-8 mixed picture cards (shapes, animals, or objects), create your own sorting rule by filling in blanks: "If ___ then put in Box A, else put in Box B." Then sort the cards using your rule. For example, create "If it has 4 legs then put in Box A" and test all cards. This synthesis skill moves beyond following rules to creating them, developing the ability to articulate conditional logic independently. This prepares students for defining their own conditions in block-based programming.

Dependencies:
* T08.G2.07: Debug a broken picture rule

CSTA: E2-ALG-AF-01


ID: T08.G2.09
Topic: T08 – Conditions & Logic
Skill: Design safety rules using if-then logic
Description: **Student task:** Help create safety rules for different situations. Given scenarios (fire drill, crossing street, stranger at door), drag words to complete if-then safety rules: "If you hear the fire alarm, then ___" (choices: run outside, hide under desk, line up quietly). Match the correct safe action to each condition. This applies conditional thinking to real-world safety scenarios that matter to children, showing that if-then rules help keep us safe. Use 4-5 safety scenarios with picture-based drag-and-drop answers. Discuss why these rules work (the condition triggers the safe action).

Dependencies:
* T08.G2.08: Create if-then rules for sorting a set of items

CSTA: E2-ALG-AF-01, E2-IC-SI-01


ID: T08.G2.10
Topic: T08 – Conditions & Logic
Skill: Compare AND vs OR in picture scenarios
Description: **Student task:** Look at 6 rule cards and sort them into two piles: "AND rules" and "OR rules". AND rules: "To ride the roller coaster you must be tall enough AND have a ticket" (need BOTH). OR rules: "You can use the pencil OR the marker to color" (EITHER works). Identify key words ("and", "both", "also" vs "or", "either", "any") that signal which type of logic is needed. After sorting, complete 2-3 fill-in-the-blank sentences choosing between AND/OR. This explicit comparison prepares students for compound conditions in code by building clear mental models of when each operator applies.

Dependencies:
* T08.G2.09: Design safety rules using if-then logic
* T08.G1.07: Sort items by "this OR that" rules
* T08.G2.04: Sort items by two-rule logic (AND situations)

CSTA: E2-ALG-AF-01


ID: T08.G3.01
Topic: T08 – Conditions & Logic
Skill: Match scenarios to if-block descriptions
Description: **Student task:** Match simple unplugged scenarios to descriptions of how an "if block" would work in programming. Drag each scenario card to the matching if-block description (e.g., "If the sprite touches the edge, it turns around" matches to picture of sprite bouncing). This conceptual bridge connects unplugged conditional thinking to block-based conditional structures without coding yet. Drag-and-drop matching with 4-5 scenario pairs prepares students for the transition from picture-based to block-based coding.

Dependencies:
* T08.G2.10: Compare AND vs OR in picture scenarios

CSTA: E3-ALG-AF-01





ID: T08.G3.00
Topic: T08 – Conditions & Logic
Skill: Identify if blocks in existing code
Description: Students look at a short script with mixed control blocks (repeat, if, wait) and identify which blocks are if blocks. This recognition skill helps students distinguish conditional blocks from other control structures before learning to use them. Use visual examples with 3-4 different block types where students click or highlight the if blocks.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.00-pre: Match scenarios to if-block descriptions

CSTA: E3-ALG-AF-01





ID: T08.G3.00b
Topic: T08 – Conditions & Logic
Skill: Complete a partially-built if statement
Description: Students complete an if block by dragging the correct condition into an empty condition slot. The script has the if block structure already, but the condition is missing or needs to be chosen from 2-3 options (e.g., "if <___> then move 10 steps" - choose from "touching edge", "key pressed", "x position > 100"). This scaffolded activity bridges recognition and independent construction.

Dependencies:
* T08.G3.00: Identify if blocks in existing code

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.01a
Topic: T08 – Conditions & Logic
Skill: Use comparison operators in conditions
Description: Students use basic comparison operators (<, >, =) inside if block conditions to compare numbers (e.g., "if score > 10 then say 'Good job!'", "if lives = 0 then game over"). This introduces relational operators and moves beyond simple boolean sensing blocks to numeric comparisons. Students practice choosing the correct operator for different scenarios.

Dependencies:
* T08.G3.04: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage using the variable monitor

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.01b
Topic: T08 – Conditions & Logic
Skill: Use advanced comparison operators (≤, ≥, ≠)
Description: Students use extended comparison operators (≤, ≥, ≠) available in CreatiCode (operator_lte, operator_gte, operator_neq) to express more precise conditions (e.g., "if age ≥ 13 then allow access", "if lives ≠ 3 then show warning"). This extends comparison skills beyond basic <, >, = to the full set of relational operators, enabling more sophisticated conditional logic.

Dependencies:
* T08.G3.01a: Use comparison operators in conditions

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.03b
Topic: T08 – Conditions & Logic
Skill: Build a simple if/else block
Description: Students add their first `if/else` block to handle two distinct outcomes (e.g., "if touching goal, say 'You win!', else say 'Keep going!'"). This introduces the two-branch conditional structure where both paths execute different actions. Use scenarios with clear either/or outcomes that require different responses for each branch.

Dependencies:
* T08.G3.03: Pick the right conditional block for a scenario
* T07.G3.02: Trace a script with a simple loop

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.01
Topic: T08 – Conditions & Logic
Skill: Use a simple if in a script
Description: Students add their first single `if <condition> then ...` block to a very simple script so that an action only happens when an obvious condition is true (e.g., "if touching the green flag, say 'Yay!'"). This gateway skill introduces the fundamental concept of conditional execution in block-based programming. Start with highly visual, binary conditions that are easy to test.

Dependencies:
* T08.G3.00b: Complete a partially-built if statement
* T07.G3.01: Use a counted repeat loop

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.02
Topic: T08 – Conditions & Logic
Skill: Decide when a single if is enough
Description: Students identify simple scenarios where an action should happen only when one condition is true (e.g., "move when space key is pressed" or "say 'Good!' when touching star"). This builds conceptual understanding of when to use a simple if block through concrete, visual examples. Students practice recognizing single-condition situations in game and animation contexts.

Dependencies:
* T08.G3.04: Use a simple if in a script

CSTA: E3-ALG-AF-01





ID: T08.G3.03
Topic: T08 – Conditions & Logic
Skill: Pick the right conditional block for a scenario
Description: Students choose between a simple `if` and an `if/else` block for very basic scenarios (e.g., "if touching star, say 'Good!' but don't do anything else" vs "if touching red, say 'Stop!', otherwise say 'Go!'"). Use clear either/or vs. one-way scenarios. Focus on recognizing the difference between one-branch and two-branch conditionals, not writing complex logic.

Dependencies:
* T08.G3.02: Decide when a single if is enough
* T07.G3.02: Trace a script with a simple loop

CSTA: E3-ALG-AF-01, E3-PRO-PF-01





ID: T08.G3.04
Topic: T08 – Conditions & Logic
Skill: Trace code with a single if/else
Description: **Student task:** Read a short script with one if/else block and given variable values, then predict which branch executes and what output occurs. Trace through the condition evaluation step-by-step. For example, given "if <score > 5> then say 'Win!' else say 'Keep trying'" with score=3, predict "Keep trying". This develops code reading and prediction skills through systematic tracing.

Dependencies:
* T08.G3.03b: Build a simple if/else block
* T07.G3.03: Build a forever loop for simple animation

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.04a
Topic: T08 – Conditions & Logic
Skill: Predict if-block execution before running code
Description: **Student task:** Before clicking the green flag, predict whether an if block will execute based on the current sprite/variable state visible on stage. For example, see a sprite touching the edge, predict whether "if <touching edge>" will be true. Then run the code to verify. This builds hypothesis-testing skills and connects visual state to conditional logic.

Dependencies:
* T08.G3.10: Trace code with a single if/else

CSTA: E3-ALG-AF-01, E3-PRO-PF-01



ID: T08.G3.05
Topic: T08 – Conditions & Logic
Skill: Fix a condition that uses the wrong comparison operator
Description: Students fix a simple script where a single condition uses an obviously wrong comparison operator (e.g., `score > 10` when it should be `score < 10`). The script has only one condition to fix, and the error produces clearly wrong behavior that students can observe. This is an introductory debugging skill focused on comparison operators (<, >, =, ≤, ≥, ≠). CreatiCode supports extended comparison operators beyond standard Scratch.

Dependencies:
* T08.G3.10: Trace code with a single if/else
* T08.G3.01a: Use comparison operators in conditions
* T08.G3.01b: Use advanced comparison operators (≤, ≥, ≠)

CSTA: E3-ALG-AF-01, E3-PRO-PF-02


ID: T08.G3.06
Topic: T08 – Conditions & Logic
Skill: Trace multiple sequential if blocks
Description: Students trace code with 2-3 sequential if blocks (not nested) and predict which blocks execute for given input values. Each if block checks a different condition independently. Given specific variable values, students determine which if blocks trigger and in what order. This prepares for understanding the difference between sequential and nested conditionals in later grades.

Dependencies:
* T08.G3.10: Trace code with a single if/else

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.07
Topic: T08 – Conditions & Logic
Skill: Use sensing blocks as conditions
Description: Students use CreatiCode sensing blocks as conditions in if statements: `<touching [sprite]?>`, `<key [space] pressed?>`, `<mouse down?>`, `<touching color [#ff0000]?>`. Students build simple interactive programs where sprite behavior depends on user input or sprite relationships. This connects conditionals to real interactivity, making coding feel responsive and game-like.

Dependencies:
* T08.G3.04: Use a simple if in a script
* T06.G3.01: Identify event‑driven blocks in a block palette

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.07a
Topic: T08 – Conditions & Logic
Skill: Use conditionals inside loops
Description: **Student task:** Add an if block inside a forever or repeat loop to check conditions repeatedly. For example, in a forever loop: "if <key pressed> then move 10 steps". Students build simple interactive programs where the sprite continuously checks for user input. This combines loops (T07) with conditionals for responsive behavior.

Dependencies:
* T08.G3.14: Use sensing blocks as conditions
* T07.G3.03: Build a forever loop for simple animation

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.08
Topic: T08 – Conditions & Logic
Skill: Use "wait until" block to pause until condition is true
Description: **Student task:** Use CreatiCode's "wait until <condition>" block to make a sprite pause until something specific happens. For example, "wait until <touching goal>" before saying "You win!", or "wait until <answer = 'yes'>" before continuing a quiz. Students build programs where timing depends on game state rather than fixed delays. This introduces event-driven synchronization patterns essential for responsive games and interactive stories.

Dependencies:
* T08.G3.15: Use conditionals inside loops
* T08.G3.10: Trace code with a single if/else

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.09
Topic: T08 – Conditions & Logic
Skill: Distinguish between "if" (check once) vs "forever if" (continuous checking)
Description: **Student task:** Compare two programs: one with a single "if" block that checks once, and another with "if" inside a "forever" loop that checks continuously. Given a scenario (e.g., "sprite should react whenever it touches the wall, not just once"), choose which pattern to use and explain why. Students trace both patterns to understand that "if" alone checks once at that moment, while "forever if" continuously monitors. This prevents a common beginner mistake of expecting single if-blocks to keep checking.

Dependencies:
* T08.G3.15: Use conditionals inside loops
* T08.G3.16: Use "wait until" block to pause until condition is true

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G3.10
Topic: T08 – Conditions & Logic
Skill: Use "repeat until" for condition-terminated loops
Description: **Student task:** Use the `repeat until <condition>` block to make a sprite keep doing something until a condition becomes true. For example, "repeat until <touching goal> [move 5 steps]" makes the sprite walk toward the goal and stop when it arrives. Compare this to forever loops with if-break: "repeat until" is cleaner when you know exactly what ending condition you want. Students build 2-3 programs using repeat-until for different scenarios: collecting all items, reaching a destination, waiting for user input. This foundational condition-terminated loop pattern is essential for game logic where actions continue until a goal is achieved.

Dependencies:
* T08.G3.17: Distinguish between "if" (check once) vs "forever if" (continuous checking)
* T07.G3.03: Build a forever loop for simple animation

CSTA: E3-ALG-AF-01, E3-PRO-PF-01


ID: T08.G4.00
Topic: T08 – Conditions & Logic
Skill: Predict outcomes using AND truth table
Description: Students predict the output of AND operations with various inputs (true AND true, true AND false, false AND true, false AND false). This foundational skill teaches students to reason about logical conjunction before implementing it in code. Use interactive truth table activities where students fill in blanks or match scenarios to outcomes (e.g., "You can play outside if it's sunny AND you finished homework - when can you play?"). Students can use CreatiCode's truth table visualization tool if available.

Dependencies:
* T08.G3.18: Use "repeat until" for condition-terminated loops
* T08.G3.13: Trace multiple sequential if blocks

CSTA: E4-ALG-AF-01





ID: T08.G4.00b
Topic: T08 – Conditions & Logic
Skill: Identify situations requiring AND
Description: Students recognize real-world scenarios that require both conditions to be true before an action occurs (e.g., "You need a ticket AND to be tall enough to ride", "Save file if changes were made AND user clicks save button"). This develops pattern recognition for AND logic in everyday contexts before coding it. Present 4-5 scenarios and students identify which ones need AND vs single conditions.

Dependencies:
* T08.G4.01: Predict outcomes using AND truth table

CSTA: E4-ALG-AF-01





ID: T08.G4.01a
Topic: T08 – Conditions & Logic
Skill: Predict outcomes using OR truth table
Description: Students predict the output of OR operations with various inputs (true OR true, true OR false, false OR true, false OR false). This teaches logical disjunction reasoning before implementation. Use truth table activities similar to AND but emphasizing "at least one" (e.g., "You get dessert if you ate vegetables OR you cleaned your room - when do you get dessert?").

Dependencies:
* T08.G4.03: Combine two conditions with AND

CSTA: E4-ALG-AF-01





ID: T08.G4.01b
Topic: T08 – Conditions & Logic
Skill: Distinguish AND vs OR scenarios
Description: Students are given scenarios and choose whether they require AND (both conditions) or OR (at least one condition). For example, "To enter the club you need to be a member OR pay a fee" (OR) vs "To graduate you need to pass all classes AND complete the project" (AND). This develops critical thinking about boolean logic operator selection. Present 5-6 mixed scenarios.

Dependencies:
* T08.G4.04: Predict outcomes using OR truth table
* T08.G4.02: Identify situations requiring AND

CSTA: E4-ALG-AF-01


ID: T08.G4.01c
Topic: T08 – Conditions & Logic
Skill: Debug simple AND/OR condition errors
Description: **Student task:** Find and fix a bug where AND was used instead of OR (or vice versa). For example, a game ends when "score = 0 AND lives = 0" but should end when "score = 0 OR lives = 0". Students trace through the condition with test values to identify the logical error. This bridges simple comparison debugging (G3.05) to compound logic debugging (G4.08).

Dependencies:
* T08.G4.05: Distinguish AND vs OR scenarios
* T08.G4.03: Combine two conditions with AND

CSTA: E4-ALG-AF-01, E4-PRO-PF-02




ID: T08.G4.03a
Topic: T08 – Conditions & Logic
Skill: Read nested if/else code
Description: Students trace and understand code with nested if/else structures by following the execution path through multiple levels of conditions. Given a simple 2-level nested structure, students answer "what happens if X is true and Y is false?" This reading comprehension skill prepares students to write their own nested conditionals by first understanding how they work.

Dependencies:
* T08.G4.10: Trace code with compound conditionals

CSTA: E4-ALG-AF-01





ID: T08.G4.03b
Topic: T08 – Conditions & Logic
Skill: Identify nesting levels
Description: Students analyze conditional code and count the depth of nested if/else structures (e.g., "this code has 2 levels of nesting"). They identify which blocks are inside which other blocks, developing spatial and structural understanding of code hierarchy. This prepares students to intentionally create nested structures by recognizing nesting patterns.

Dependencies:
* T08.G4.11: Read nested if/else code

CSTA: E4-ALG-AF-01





ID: T08.G4.05a
Topic: T08 – Conditions & Logic
Skill: Predict outcomes using NOT truth table
Description: Students predict the output of NOT operations (NOT true = false, NOT false = true). This foundational skill teaches logical negation reasoning before implementation. Use truth table activities where students fill in "opposite" values and real-world examples (e.g., "if NOT raining, then go outside" - when do you go outside?). Applying negation correctly is essential for compound logic.

Dependencies:
* T08.G4.07: Combine two conditions with OR

CSTA: E4-ALG-AF-01





ID: T08.G4.05b
Topic: T08 – Conditions & Logic
Skill: Use NOT to invert conditions
Description: Students use the NOT block (database_not in CreatiCode) to invert conditions (e.g., "if NOT <touching ground> then falling"). Students reason about when inversion is clearer than checking the opposite directly, comparing "if NOT condition" vs "if opposite condition" patterns. This introduces logical negation and develops code clarity judgment.

Dependencies:
* T08.G4.15: Predict outcomes using NOT truth table

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.01
Topic: T08 – Conditions & Logic
Skill: Combine two conditions with AND
Description: Students use the AND block (database_and in CreatiCode) to check if two things are true at the same time before acting (e.g., "if <key pressed> AND <touching goal> then complete level"). This is their first time writing boolean logic operators in code, introducing logical conjunction. Students must choose appropriate conditions to combine.

Dependencies:
* T08.G4.02: Identify situations requiring AND

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.02
Topic: T08 – Conditions & Logic
Skill: Combine two conditions with OR
Description: Students use the OR block (database_or in CreatiCode) to check if at least one of two conditions is true (e.g., "if <score > 100> OR <lives = 0> then end game"). This introduces logical disjunction. Students compare when to use OR vs AND and practice choosing the right operator for "at least one" scenarios.

Dependencies:
* T08.G4.05: Distinguish AND vs OR scenarios
* T09.G3.01.04: Display variable value on stage using the variable monitor

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.02a
Topic: T08 – Conditions & Logic
Skill: Store and use boolean variables
Description: Students use boolean literals (true/false blocks in CreatiCode) to store and check state. For example, "set gameOver to true" then later "if gameOver then stop all". This skill teaches using variables as flags to track binary states, a fundamental game programming pattern. Students practice setting boolean variables and using them in if conditions.

Dependencies:
* T08.G4.07: Combine two conditions with OR
* T09.G3.01.04: Display variable value on stage using the variable monitor

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.02b
Topic: T08 – Conditions & Logic
Skill: Use string matching conditions
Description: Students use CreatiCode's string condition blocks (operator_include, operator_start, operator_end) to check text content. For example, "if <answer includes 'yes'>" or "if <username starts with 'A'>". This introduces text-based conditional logic beyond numeric comparisons, useful for text adventures, quizzes, and name-based filtering.

Dependencies:
* T08.G4.07: Combine two conditions with OR
* T09.G3.01.04: Display variable value on stage using the variable monitor

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.03
Topic: T08 – Conditions & Logic
Skill: Trace code with compound conditionals
Description: Students read code with compound expressions (AND and/or OR) and predict which branch runs for given inputs. Given specific variable values, students trace through the boolean expression step-by-step to determine the outcome. This builds comfort with compound logic evaluation before debugging or refactoring.

Dependencies:
* T08.G4.09: Use string matching conditions
* T12.G3.01: Test and trace simple block-based scripts

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.04
Topic: T08 – Conditions & Logic
Skill: Nest if/else statements
Description: Students write nested if/else blocks where an else branch contains another if (e.g., checking weather type, then checking temperature). This models multi-step decision-making and introduces hierarchical conditional structures.

Dependencies:
* T08.G4.12: Identify nesting levels

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.05
Topic: T08 – Conditions & Logic
Skill: Use else-if for multiple exclusive conditions
Description: Students use else-if (chained conditionals) when there are more than two mutually exclusive outcomes (e.g., "if score >= 90 then A, else if score >= 80 then B, else if score >= 70 then C, else D"). This introduces the common pattern for handling multiple exclusive cases without deep nesting.

Dependencies:
* T08.G4.13: Nest if/else statements

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.06
Topic: T08 – Conditions & Logic
Skill: Convert nested if to cleaner logic
Description: Students are given deeply nested or redundant if/else code and refactor it using AND, OR, or else-if to make it cleaner and more readable. This skill requires understanding compound conditions and else-if patterns, developing code quality and maintainability awareness.

Dependencies:
* T08.G4.13: Nest if/else statements
* T08.G4.14: Use else-if for multiple exclusive conditions
* T08.G4.16: Use NOT to invert conditions

CSTA: E4-ALG-AF-01, E4-PRO-PF-02





ID: T08.G4.07
Topic: T08 – Conditions & Logic
Skill: Use if to control state changes
Description: Students use conditional logic to manage game states (e.g., "if game over then don't allow movement") or animation states (e.g., "if jumping then use jump costume"). This applies conditionals to tracking and managing program state, a fundamental game programming pattern.

Dependencies:
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T06.G3.02: Build a key‑press script that controls a sprite
* T09.G3.01.04: Display variable value on stage using the variable monitor

CSTA: E4-ALG-AF-01, E4-PRO-PF-01





ID: T08.G4.08
Topic: T08 – Conditions & Logic
Skill: Analyze and fix a compound logic bug
Description: Students debug a script where compound conditions (using AND/OR/NOT) are incorrect or inverted (e.g., using AND when OR was needed, or a missing NOT), causing unexpected behavior. This is more advanced than T08.G3.05 because it involves compound conditions, not just simple comparison operators, developing systematic debugging skills.

Dependencies:
* T08.G4.16: Use NOT to invert conditions
* T08.G4.10: Trace code with compound conditionals
* T12.G3.01: Test and trace simple block-based scripts

CSTA: E4-ALG-AF-01, E4-PRO-PF-02





ID: T08.G4.09
Topic: T08 – Conditions & Logic
Skill: Trace code with a sequence of if/else blocks
Description: **Student task:** Trace code with 2-3 sequential if/else blocks and predict the final output for given variable values. Track how each if/else affects program state before the next one evaluates. For example, trace: "if x>5 then set y to 1, if y=1 then say 'yes'" with x=6. Record intermediate state changes between conditionals. This develops sequential reasoning through multiple decision points.

Dependencies:
* T08.G3.10: Trace code with a single if/else
* T12.G3.01: Test and trace simple block-based scripts

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.09a
Topic: T08 – Conditions & Logic
Skill: Compare sequential vs chained if/else patterns
Description: **Student task:** Given two code versions—one using sequential if blocks and one using chained else-if—compare their behavior for the same inputs. Identify scenarios where they produce different results (e.g., when multiple conditions could be true) and explain why. For example, compare "if x>5... if x>10..." vs "if x>10... else if x>5...". This develops understanding of when order and structure matter.

Dependencies:
* T08.G4.20: Trace code with a sequence of if/else blocks
* T08.G4.14: Use else-if for multiple exclusive conditions

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.10
Topic: T08 – Conditions & Logic
Skill: Use "continue" block to skip loop iteration based on condition
Description: **Student task:** In CreatiCode, use the "continue" block inside a loop to skip the rest of the current iteration when a condition is met. For example, in a repeat loop processing a list: "if <item = 'skip'> then continue" to skip certain items. Students build programs that process collections selectively, like skipping blank entries or filtering out invalid data. This pattern is fundamental for efficient data processing and game logic where not every item needs the same treatment.

Dependencies:
* T08.G4.21: Compare sequential vs chained if/else patterns
* T08.G3.15: Use conditionals inside loops

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.11
Topic: T08 – Conditions & Logic
Skill: Use "break" block to exit loops early when condition is met
Description: **Student task:** Use CreatiCode's `break` block to exit a loop immediately when a specific condition is met, rather than waiting for the loop to finish naturally. For example, searching for an item: "repeat 100 [if <item found> then break, check next position]" stops as soon as the item is found. Students build search programs, validation loops that exit on first error, and games where finding a treasure ends the hunt immediately. Compare break to repeat-until: break can exit from any point in the loop body, while repeat-until only checks at the start. This early-exit pattern is essential for efficient algorithms and responsive programs.

Dependencies:
* T08.G4.22: Use "continue" block to skip loop iteration based on condition
* T08.G3.18: Use "repeat until" for condition-terminated loops

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G4.11b
Topic: T08 – Conditions & Logic
Skill: Analyze condition complexity and identify simplification opportunities
Description: **Student task:** Given a complex conditional expression, count the number of conditions and operators, then identify if it can be simplified. For example, analyze "if <x > 5 AND x > 10>" and recognize that "x > 10" implies "x > 5", so it simplifies to just "if <x > 10>". Students examine 4-5 expressions, identify redundant conditions, recognize tautologies (always true) and contradictions (always false), and propose simpler equivalents. This analytical skill prepares students for optimization and helps them write cleaner code from the start.

Dependencies:
* T08.G4.19: Analyze and fix a compound logic bug
* T08.G4.16: Use NOT to invert conditions

CSTA: E4-ALG-AF-01, E4-PRO-PF-01


ID: T08.G5.01
Topic: T08 – Conditions & Logic
Skill: Draw decision tree flowchart
Description: Students plan multi-branch logic visually by drawing decision tree flowcharts before coding. They map out all possible paths through a decision (e.g., grading system, game state transitions) using diamonds for conditions and rectangles for actions. This design-first approach helps students think through all cases systematically before implementation, reducing bugs and improving code structure.

Dependencies:
* T08.G4.24: Analyze condition complexity and identify simplification opportunities
* T08.G4.14: Use else-if for multiple exclusive conditions
* T08.G4.20: Trace code with a sequence of if/else blocks
* T03.G5.01: Write a feature list with subtasks for each feature

CSTA: E5-ALG-AF-01





ID: T08.G5.02
Topic: T08 – Conditions & Logic
Skill: Design multi-branch decision logic
Description: Students design multi-branch logic (e.g., grading scales, game difficulty tiers) using nested or chained if/else statements. This skill emphasizes planning and designing conditional structures before implementation, developing algorithmic thinking.

Dependencies:
* T08.G5.01: Draw decision tree flowchart
* T08.G4.17: Convert nested if to cleaner logic
* T03.G5.01: Write a feature list with subtasks for each feature

CSTA: E5-ALG-AF-01, E5-PRO-PF-01





ID: T08.G5.03
Topic: T08 – Conditions & Logic
Skill: Implement multi-branch decision logic in code
Description: Students translate their decision tree designs into actual code using nested or chained if/else statements. Given a flowchart or design specification, students build the corresponding conditional structure (e.g., grading system with A/B/C/D/F outcomes, game difficulty selector). This bridges design (T08.G5.02) and complex boolean logic (T08.G5.04).

Dependencies:
* T08.G5.02: Design multi-branch decision logic

CSTA: E5-ALG-AF-01, E5-PRO-PF-01




ID: T08.G5.04
Topic: T08 – Conditions & Logic
Skill: Combine three or more conditions
Description: Students write compound conditions that combine three or more tests using AND/OR/NOT, such as "if <score > 100> AND <lives > 0> AND <has_key> then ...". This extends compound logic skills to more complex scenarios. Students must choose correct operators and understand operator precedence (AND evaluated before OR).

Dependencies:
* T08.G5.03: Implement multi-branch decision logic in code
* T08.G4.19: Analyze and fix a compound logic bug

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.05
Topic: T08 – Conditions & Logic
Skill: Use parentheses to control evaluation order
Description: Students use parentheses to explicitly control the evaluation order of compound boolean expressions. For example, "(A OR B) AND C" behaves differently from "A OR (B AND C)". Students predict outcomes of expressions with and without parentheses, then write parenthesized expressions to achieve specific logic. This prepares students for more complex boolean algebra.

Dependencies:
* T08.G5.04: Combine three or more conditions

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.06
Topic: T08 – Conditions & Logic
Skill: Use type checking in conditions
Description: Students use CreatiCode's operator_isnumber block to check if input is a valid number before performing calculations. For example, "if <answer is a number?> then calculate result, else say 'Please enter a number'". This defensive programming technique prevents errors from invalid input and prepares students for robust input validation in G8.

Dependencies:
* T08.G5.04: Combine three or more conditions
* T09.G3.03: Use a variable in a simple conditional (if block)

CSTA: E5-ALG-AF-01, E5-PRO-PF-01





ID: T08.G5.07
Topic: T08 – Conditions & Logic
Skill: Trace complex decision logic
Description: **Student task:** Trace a decision tree implemented with nested/compound conditionals and determine which path is taken for various inputs. Given 3-4 test cases with different variable values, walk through the conditional structure step-by-step and record the execution path. Use CreatiCode's console panel to log intermediate values during tracing. This develops systematic analysis skills for complex conditional structures.

Dependencies:
* T08.G5.05: Use parentheses to control evaluation order
* T02.G5.01: Trace a script with nested loops using debug print
* T03.G5.01: Write a feature list with subtasks for each feature

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.08
Topic: T08 – Conditions & Logic
Skill: Create test cases for multi-branch conditionals
Description: **Student task:** Given a multi-branch conditional structure (e.g., grading system), design test cases that cover each branch. Create a table with input values and expected outputs. Ensure at least one test per branch, plus boundary values (e.g., score=89, 90 for an A cutoff). Run tests to verify code behavior matches expectations. This bridges tracing (G5.04) to formal testing (G7.02).

Dependencies:
* T08.G5.07: Trace complex decision logic
* T08.G5.03: Implement multi-branch decision logic in code

CSTA: E5-ALG-AF-01, E5-PRO-PF-02



ID: T08.G5.09
Topic: T08 – Conditions & Logic
Skill: Use inline if-then-else expressions to compute conditional values
Description: Students use CreatiCode's inline conditional expression reporter block (`if <condition> then [value1] else [value2]`) to compute values conditionally without using full if/else control blocks. This is useful for setting variables or parameters based on a condition in a single expression (e.g., `set speed to (if fast mode then 10 else 5)`). This introduces the ternary operator concept and promotes more concise code.

Dependencies:
* T08.G5.02: Design multi-branch decision logic
* T09.G3.03: Use a variable in a simple conditional (if block)
* T11.G5.01: Decompose a problem into logical custom block boundaries

CSTA: E5-ALG-AF-01, E5-PRO-PF-01





ID: T08.G5.10
Topic: T08 – Conditions & Logic
Skill: Use condition-triggered events to respond to state changes
Description: Students use CreatiCode's `when <condition>` hat block (event_whenboolean) to trigger scripts when a boolean condition becomes true. For example, `when <score > 100>` triggers a level-up sequence the moment score exceeds 100. Students compare this event-driven pattern to polling with forever loops, understanding when each approach is appropriate.

Dependencies:
* T08.G5.07: Trace complex decision logic
* T08.G4.18: Use if to control state changes
* T06.G4.01: Add conditional logic within an event handler
* T09.G3.03: Use a variable in a simple conditional (if block)
* T07.G5.01: Simulate repeated experiments with a loop

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.11
Topic: T08 – Conditions & Logic
Skill: Identify variables that represent states
Description: Students analyze game or animation code and identify which variables represent discrete states (e.g., gameState = "playing" / "paused" / "gameover", playerMode = "walking" / "jumping" / "falling"). Students distinguish state variables from numeric counters or flags, recognizing that state variables can have multiple distinct values representing different modes of operation.

Dependencies:
* T08.G5.10: Use condition-triggered events to respond to state changes
* T08.G4.18: Use if to control state changes

CSTA: E5-ALG-AF-01


ID: T08.G5.12
Topic: T08 – Conditions & Logic
Skill: Design simple two-state systems
Description: Students design and implement a simple two-state system using a state variable and conditionals. For example, a light switch (on/off), a door (open/closed), or a game character (alive/dead). Students write code that transitions between states based on events and handles each state differently. This prepares students for multi-state machines in G6.

Dependencies:
* T08.G5.11: Identify variables that represent states

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.13
Topic: T08 – Conditions & Logic
Skill: Design three-state systems
Description: **Student task:** Extend a two-state system to three states. For example, a traffic light (red/yellow/green) or a game character (idle/walking/running). Students add a third state variable value, define transitions between all three states, and write code handling all cases. This bridges two-state systems (G5.08) to full state machines (G6.02).

Dependencies:
* T08.G5.12: Design simple two-state systems

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.14
Topic: T08 – Conditions & Logic
Skill: Use guard clauses to exit early from conditions
Description: Students use guard clauses (early returns) to simplify conditional logic by handling exceptional cases first. For example, "if <lives = 0> then [stop this script]" at the start of a damage handler avoids nesting the main logic. Students compare deeply nested if/else structures with flattened guard clause versions and identify when early exit patterns improve readability.

Dependencies:
* T08.G5.03: Implement multi-branch decision logic in code
* T08.G4.17: Convert nested if to cleaner logic

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.15
Topic: T08 – Conditions & Logic
Skill: Apply short-circuit evaluation patterns
Description: Students leverage short-circuit evaluation in compound conditions where the order of checks matters. For example, "if <list length > 0> AND <item 1 of list = 'target'>" prevents errors by checking list length first. Students identify scenarios where condition order affects both correctness and efficiency, and reorder conditions appropriately.

Dependencies:
* T08.G5.04: Combine three or more conditions
* T08.G5.05: Use parentheses to control evaluation order

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.16
Topic: T08 – Conditions & Logic
Skill: Design fallback and default value patterns
Description: Students implement fallback patterns using conditionals: "if <user input = empty> then use default value". Students design systems that gracefully handle missing data, invalid input, or unavailable resources by providing sensible defaults. This defensive programming pattern prepares students for robust application design.

Dependencies:
* T08.G5.09: Use inline if-then-else expressions to compute conditional values
* T08.G5.06: Use type checking in conditions

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.17
Topic: T08 – Conditions & Logic
Skill: Use list/table conditions for data-aware decisions
Description: **Student task:** Create programs that check list or table properties before operating on them. For example: "if <length of inventory = 0> then say 'Inventory empty!'" or "if <length of highScores > 10> then delete item 11". Students build defensive programs that handle edge cases like empty lists, insufficient data, or boundary conditions. This is essential for inventory systems, leaderboards, and any program that processes collections. Students learn to prevent common "index out of bounds" errors through conditional guards.

Dependencies:
* T08.G5.16: Design fallback and default value patterns
* T08.G5.04: Combine three or more conditions

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.18
Topic: T08 – Conditions & Logic
Skill: Use ternary if-then-else reporter for inline conditional values
Description: **Student task:** Use CreatiCode's `if <condition> then [value1] else [value2]` reporter block to compute values conditionally in a single expression. For example, `set speed to (if <running> then [10] else [3])` sets different speeds based on a condition without needing a full if-else control block. Students refactor code that uses if-else to set variables into cleaner ternary expressions. Build programs using inline conditionals for: setting sprite properties, calculating scores, choosing text responses. This concise pattern reduces code complexity and is widely used in professional programming (ternary operator).

Dependencies:
* T08.G5.09: Use inline if-then-else expressions to compute conditional values
* T08.G5.04: Combine three or more conditions

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.19
Topic: T08 – Conditions & Logic
Skill: Use regex conditions for pattern matching in text
Description: **Student task:** Use CreatiCode's `regex [pattern] test [text]` block to check if text matches a pattern. For example, test if user input looks like an email: `if <regex [.*@.*\\..*] test (answer)> then say 'Valid email format!'`. Students learn basic regex patterns: `.` (any character), `*` (zero or more), `+` (one or more), `[]` (character class). Build a username validator that checks: starts with letter, only contains letters/numbers, 3-10 characters long. This powerful pattern-matching skill enables sophisticated text validation beyond simple string comparison.

Dependencies:
* T08.G5.17: Use list/table conditions for data-aware decisions
* T08.G4.09: Use string matching conditions

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G5.20
Topic: T08 – Conditions & Logic
Skill: Implement feature flags using boolean conditionals
Description: **Student task:** Use boolean variables as feature flags to enable/disable features without changing code. For example, "set newScoringSystem to true" then "if <newScoringSystem> then [use new calculation] else [use old calculation]". Students build a program with 2-3 toggleable features (e.g., sound effects on/off, hard mode, show hints). This professional software development pattern allows testing new features safely, A/B testing, and gradual rollouts. Students learn that conditional logic controls not just program behavior but also program configuration.

Dependencies:
* T08.G5.12: Design simple two-state systems
* T08.G4.08: Store and use boolean variables

CSTA: E5-ALG-AF-01, E5-PRO-PF-01


ID: T08.G6.02a
Topic: T08 – Conditions & Logic
Skill: Identify states in a system
Description: Students analyze a system or game mechanic and list all possible states an entity can be in (e.g., player states: idle, walking, jumping, falling; enemy states: patrol, chase, attack, retreat). Given a game description, students enumerate all distinct states and the conditions that distinguish them. This develops system analysis abilities.

Dependencies:
* T08.G5.20: Implement feature flags using boolean conditionals
* T08.G5.14: Use guard clauses to exit early from conditions
* T08.G5.13: Design three-state systems

CSTA: E6-ALG-AF-01





ID: T08.G6.02b
Topic: T08 – Conditions & Logic
Skill: Draw state transition diagram
Description: Students create state transition diagrams showing which states connect to which others and what conditions trigger transitions (e.g., idle → walking when "move key pressed", walking → jumping when "space pressed AND on ground"). This visual planning skill helps students design state machines systematically before coding them.

Dependencies:
* T08.G6.02a: Identify states in a system

CSTA: E6-ALG-AF-01





ID: T08.G6.01
Topic: T08 – Conditions & Logic
Skill: Use conditionals in physics simulations
Description: Students write conditionals that control physics simulation behavior: collision detection ("if <touching wall> then reverse direction"), boundary checking ("if <y position < 0> then set y to 0"), and force application ("if <moving> then apply friction"). Students build a simple physics simulation (bouncing ball, falling object) that uses multiple conditionals to model realistic behavior.

Dependencies:
* T08.G5.07: Trace complex decision logic
* T08.G5.06: Use type checking in conditions

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.01a
Topic: T08 – Conditions & Logic
Skill: Use conditionals in biology simulations
Description: Students write conditionals that model biological systems: population dynamics ("if <population > carrying capacity> then increase death rate"), resource limits ("if <food < threshold> then reduce birth rate"), and ecosystem interactions. Students build a simple ecosystem simulation (predator-prey, population growth) using conditionals to model real-world biological constraints.

Dependencies:
* T08.G6.01: Use conditionals in physics simulations

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.01b
Topic: T08 – Conditions & Logic
Skill: Use conditionals in game logic
Description: Students write conditionals for game mechanics: win/loss conditions ("if <score >= goal> then show 'You win!'"), power-up effects ("if <has shield> then ignore damage"), and level progression ("if <enemies = 0> then next level"). Students implement game logic that responds appropriately to player actions and game state changes.

Dependencies:
* T08.G6.01: Use conditionals in physics simulations

CSTA: E6-ALG-AF-01, E6-PRO-PF-01





ID: T08.G6.02
Topic: T08 – Conditions & Logic
Skill: Implement simple state machines using conditionals
Description: Students implement a state machine using a state variable and conditionals (e.g., playerState: "idle" → "walking" → "jumping" based on inputs). Given a state transition diagram, students write code that checks the current state, evaluates transition conditions, and updates the state variable. This introduces formal state machine implementation patterns.

Dependencies:
* T08.G6.02a: Identify states in a system
* T08.G6.02b: Draw state transition diagram

CSTA: E6-ALG-AF-01, E6-PRO-PF-01





ID: T08.G6.03
Topic: T08 – Conditions & Logic
Skill: Debug multi-condition logic
Description: Students debug scripts where multi-part conditions (AND/OR/NOT) are wrong or mis-parenthesized, leading to incorrect behavior. Given buggy code and expected vs actual behavior, students trace through the boolean expression, identify the logical error (wrong operator, missing NOT, incorrect parentheses), and fix it. This develops systematic debugging for complex boolean expressions.

Dependencies:
* T08.G6.01b: Use conditionals in game logic
* T08.G5.07: Trace complex decision logic

CSTA: E6-ALG-AF-01, E6-PRO-PF-02


ID: T08.G6.04
Topic: T08 – Conditions & Logic
Skill: Implement responsive UI conditionals
Description: Students use conditionals to create responsive interfaces that adapt to different conditions: screen size ("if <stage width < 400> then use mobile layout"), input type ("if <mouse moved recently> then show mouse cursor, else show touch hints"), or device capabilities. Students build UI that gracefully handles different user contexts using CreatiCode's viewport and sensing blocks.

Dependencies:
* T08.G6.02: Implement simple state machines using conditionals
* T08.G5.10: Use condition-triggered events to respond to state changes

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.05
Topic: T08 – Conditions & Logic
Skill: Use conditionals with AI detection results
Description: Students use CreatiCode's AI blocks (hand tracking, body pose, face detection) as conditions in if statements. For example, "if <hand is open> then release object" or "if <body leaning left> then move sprite left". Students build interactive applications that respond to real-time AI detection, learning to handle confidence thresholds and detection failures gracefully.

Dependencies:
* T08.G6.01b: Use conditionals in game logic
* T08.G5.16: Design fallback and default value patterns

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.06
Topic: T08 – Conditions & Logic
Skill: Implement priority-based condition checking
Description: Students design conditional logic where multiple conditions could be true but only the highest-priority action should execute. For example, in a game: check "game over" before "level complete" before "enemy collision" before "coin collection". Students use else-if chains or early returns to ensure proper priority ordering and prevent lower-priority conditions from overriding higher-priority ones.

Dependencies:
* T08.G6.02: Implement simple state machines using conditionals
* T08.G5.14: Use guard clauses to exit early from conditions

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.07
Topic: T08 – Conditions & Logic
Skill: Debug condition timing issues in event handlers
Description: **Student task:** Find and fix timing-related bugs in programs where conditions evaluate at the wrong moment. For example: a broadcast handler checks a variable before another handler has set it, or collision detection happens before position updates. Students use strategies like adding wait blocks, reordering broadcasts, or using flags to synchronize event handlers. This addresses race conditions that occur when multiple scripts run concurrently, a common source of hard-to-find bugs in complex interactive projects.

Dependencies:
* T08.G6.06: Implement priority-based condition checking
* T08.G5.10: Use condition-triggered events to respond to state changes

CSTA: E6-ALG-AF-01, E6-PRO-PF-02


ID: T08.G6.08
Topic: T08 – Conditions & Logic
Skill: Build voice command parser with conditional dispatch
Description: **Student task:** Create a voice-controlled program using CreatiCode's speech recognition that responds to different spoken commands. After getting speech text, use chained conditionals to dispatch to different actions: "if <speech includes 'jump'> then [make sprite jump], else if <speech includes 'run'> then [start running], else if <speech includes 'stop'> then [stop all motion], else [say 'I didn't understand']". Students build a voice-controlled game or assistant with 5+ recognized commands. Handle variations (e.g., "please jump" still triggers jump). This skill is directly applicable to smart speaker development and voice-first interfaces.

Dependencies:
* T08.G6.05: Use conditionals with AI detection results
* T08.G4.14: Use else-if for multiple exclusive conditions

CSTA: E6-ALG-AF-01, E6-PRO-PF-01


ID: T08.G6.09
Topic: T08 – Conditions & Logic
Skill: Design permission and access control conditionals
Description: **Student task:** Implement role-based access control using conditionals. For example, a classroom app: "if <userRole = 'teacher'> then [show edit button], else if <userRole = 'student' AND isOwner> then [show edit button], else [hide edit button]". Students design and implement access rules for 3-4 roles with different permissions. Test that each role sees only what they should. This professional security pattern teaches students that conditionals protect features and data, not just control behavior. Essential for any multi-user application or game with different player types.

Dependencies:
* T08.G6.02: Implement simple state machines using conditionals
* T08.G5.20: Implement feature flags using boolean conditionals

CSTA: E6-ALG-AF-01, E6-PRO-PF-01, E6-IC-CY-01


ID: T08.G7.01
Topic: T08 – Conditions & Logic
Skill: Identify bias in conditional rules
Description: Students analyze conditional rules (e.g., loan approval, college admission, game matchmaking) and identify conditions that may unfairly disadvantage certain groups. For example, "if age < 25 then higher insurance rate" may be age discrimination. Students examine multiple real-world algorithmic decision examples and flag potentially unfair conditions.

Dependencies:
* T08.G6.06: Implement priority-based condition checking
* T08.G6.03: Debug multi-condition logic

CSTA: E7-ALG-AF-01, E7-IC-SI-01


ID: T08.G7.01a
Topic: T08 – Conditions & Logic
Skill: Propose fair alternative conditions
Description: Given conditional rules identified as potentially unfair, students propose alternative conditions that achieve the same goal more fairly. For example, replacing "if ZIP code in [poor areas] then deny loan" with "if income < threshold AND debt > limit then deny loan". Students justify how their alternatives reduce bias while maintaining the system's purpose.

Dependencies:
* T08.G7.01: Identify bias in conditional rules

CSTA: E7-ALG-AF-01, E7-IC-SI-01





ID: T08.G7.02
Topic: T08 – Conditions & Logic
Skill: Design tests for condition-heavy code
Description: Students design test inputs that exercise all branches of condition-heavy code. Given a multi-branch conditional structure (e.g., grading system with A/B/C/D/F), students create test cases that cover: (1) each branch at least once, (2) boundary values (e.g., score = 89, 90, 91), (3) invalid inputs. This introduces branch coverage and boundary testing concepts.

Dependencies:
* T08.G7.01a: Propose fair alternative conditions
* T08.G6.03: Debug multi-condition logic

CSTA: E7-ALG-AF-01, E7-PRO-PF-02





ID: T08.G7.03
Topic: T08 – Conditions & Logic
Skill: Apply De Morgan's laws
Description: Students apply De Morgan's laws to transform boolean expressions: "NOT(A AND B)" = "NOT A OR NOT B" and "NOT(A OR B)" = "NOT A AND NOT B". Given complex negated expressions, students rewrite them using De Morgan's laws to make them clearer or more efficient. This foundational boolean algebra skill prepares students for logical equivalence analysis.

Dependencies:
* T08.G7.02: Design tests for condition-heavy code
* T08.G6.03: Debug multi-condition logic

CSTA: E7-ALG-AF-01


ID: T08.G7.03a
Topic: T08 – Conditions & Logic
Skill: Simplify boolean expressions using algebra
Description: Students apply multiple boolean algebra rules (De Morgan's laws, distributive property, double negation elimination, idempotent law) to simplify complex expressions. For example, simplify "(A AND B) OR (A AND C)" to "A AND (B OR C)" using distribution, or "NOT(NOT A)" to "A". Students practice recognizing which rules apply to given expressions.

Dependencies:
* T08.G7.03: Apply De Morgan's laws

CSTA: E7-ALG-AF-01


ID: T08.G7.04
Topic: T08 – Conditions & Logic
Skill: Analyze decision trees in AI/ML context
Description: Students analyze how AI systems use decision trees to make predictions or classifications. Given a trained decision tree (e.g., loan approval, disease diagnosis, spam detection), students trace inputs through the tree, identify which features are most important (appear near root), and explain how the tree makes decisions. Students discuss limitations and potential biases in decision tree models.

Dependencies:
* T08.G7.01: Identify bias in conditional rules
* T08.G7.02: Design tests for condition-heavy code

CSTA: E7-ALG-AF-01, E7-IC-SI-01


ID: T08.G7.05
Topic: T08 – Conditions & Logic
Skill: Design condition coverage test matrices
Description: Students create systematic test matrices to ensure complete condition coverage. Given a compound condition like "(A AND B) OR C", students generate test cases that cover: each atomic condition true/false, each compound sub-expression true/false, and all critical combinations. Students learn MC/DC (Modified Condition/Decision Coverage) concepts used in safety-critical software testing.

Dependencies:
* T08.G7.02: Design tests for condition-heavy code
* T08.G7.03a: Simplify boolean expressions using algebra

CSTA: E7-ALG-AF-01, E7-PRO-PF-02


ID: T08.G7.06
Topic: T08 – Conditions & Logic
Skill: Implement retry logic with conditional exit
Description: **Student task:** Design and implement retry mechanisms that attempt an operation multiple times with conditions for success or failure exit. For example: "repeat 3 times: try fetching data, if <success> then break, wait 1 second". Students build robust programs that handle temporary failures (network requests, AI responses that don't meet criteria, user input validation). Include counter-based exit conditions to prevent infinite loops. This professional pattern is essential for working with unreliable external services like APIs and AI.

Dependencies:
* T08.G7.05: Design condition coverage test matrices
* T08.G6.07: Debug condition timing issues in event handlers

CSTA: E7-ALG-AF-01, E7-PRO-PF-01


ID: T08.G7.07
Topic: T08 – Conditions & Logic
Skill: Design conversation flow with conditional branching
Description: **Student task:** Create a chatbot or interactive story with branching conversation paths based on user responses. Use conditionals to route the conversation: "if <response includes 'yes'> then [continue story path A], else if <response includes 'no'> then [continue story path B], else [ask for clarification]". Students design a conversation flow diagram first, then implement it with nested/chained conditionals. The chatbot should handle 3+ conversation branches with at least 2 levels of depth. This skill applies directly to designing AI assistants, customer service bots, and interactive narratives.

Dependencies:
* T08.G7.06: Implement retry logic with conditional exit
* T08.G6.08: Build voice command parser with conditional dispatch

CSTA: E7-ALG-AF-01, E7-PRO-PF-01


ID: T08.G7.08
Topic: T08 – Conditions & Logic
Skill: Implement circuit breaker pattern for failing services
Description: **Student task:** Implement the circuit breaker pattern to handle repeated failures gracefully. Track consecutive failures in a counter: "if <failures >= 3> then [circuit open: skip service call, return cached/default], else [try service]". After a timeout, reset to "half-open" and try once. Students build a program that calls an unreliable service (simulated AI or network) and gracefully degrades when it fails repeatedly. This professional resilience pattern prevents cascading failures and improves user experience when external services are down.

Dependencies:
* T08.G7.06: Implement retry logic with conditional exit
* T08.G6.02: Implement simple state machines using conditionals

CSTA: E7-ALG-AF-01, E7-PRO-PF-01


ID: T08.G7.09
Topic: T08 – Conditions & Logic
Skill: Prove condition correctness using loop invariants
Description: **Student task:** Given a loop with conditionals, identify and verify a loop invariant—a condition that is true before the loop, stays true after each iteration, and guarantees the desired result when the loop ends. For example, in a search loop: invariant = "target not found in indices 0 to i-1". Students analyze 3-4 loops, state their invariants, and trace through to verify the invariant holds. This foundational correctness reasoning skill is essential for writing reliable algorithms and understanding why code works, not just that it works.

Dependencies:
* T08.G7.05: Design condition coverage test matrices
* T08.G7.03a: Simplify boolean expressions using algebra

CSTA: E7-ALG-AF-01, E7-PRO-PF-01


ID: T08.G8.01
Topic: T08 – Conditions & Logic
Skill: Prove logical equivalence using truth tables
Description: Students construct truth tables to prove whether two boolean expressions are logically equivalent. Given two expressions (e.g., "NOT(A OR B)" and "(NOT A) AND (NOT B)"), students build a truth table with all input combinations and compare output columns. If outputs match for all rows, expressions are equivalent. This formal verification method complements algebraic simplification.

Dependencies:
* T08.G7.09: Prove condition correctness using loop invariants
* T08.G7.05: Design condition coverage test matrices
* T08.G7.02: Design tests for condition-heavy code

CSTA: E8-ALG-AF-01, E8-PRO-PF-01


ID: T08.G8.01a
Topic: T08 – Conditions & Logic
Skill: Analyze logical equivalence of conditionals in code
Description: Students compare two code implementations with different conditional structures and determine if they produce identical behavior. For example, comparing nested if/else to a flat else-if chain, or a compound condition to separate if statements. Students use truth tables, test cases, or algebraic reasoning to prove or disprove equivalence.

Dependencies:
* T08.G8.01: Prove logical equivalence using truth tables
* T04.G6.01: Group snippets by underlying algorithm pattern

CSTA: E8-ALG-AF-01, E8-PRO-PF-01





ID: T08.G8.02
Topic: T08 – Conditions & Logic
Skill: Design boundary test cases for input validation
Description: Students design comprehensive test cases for input validation, focusing on boundary conditions. For age validation (13-18), test: 12 (below), 13 (lower bound), 15 (middle), 18 (upper bound), 19 (above), non-numeric, empty. Students learn to test edge cases systematically to ensure validation logic handles all scenarios correctly.

Dependencies:
* T08.G8.01a: Analyze logical equivalence of conditionals in code
* T08.G7.02: Design tests for condition-heavy code

CSTA: E8-ALG-AF-01, E8-PRO-PF-02


ID: T08.G8.02a
Topic: T08 – Conditions & Logic
Skill: Implement robust input validation with compound conditions
Description: Students use compound conditions to implement complete input validation. For a password validator: "if <length >= 8> AND <includes number> AND <includes uppercase> then valid". For age: "if <is number> AND <age >= 13> AND <age <= 18> then proceed". Students chain multiple validation checks and provide appropriate error messages for each failure case.

Dependencies:
* T08.G8.02: Design boundary test cases for input validation
* T06.G6.01: Trace event execution paths in a multi‑event program
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design

CSTA: E8-ALG-AF-01, E8-PRO-PF-01, E8-IC-CY-01


ID: T08.G8.03
Topic: T08 – Conditions & Logic
Skill: Implement fuzzy and threshold-based conditions
Description: Students implement conditions that handle uncertainty, confidence scores, or gradual transitions rather than binary true/false. For example, "if <confidence > 0.8> then 'definitely cat', else if <confidence > 0.5> then 'probably cat', else 'uncertain'". Students design conditional logic for AI outputs, sensor readings, or probabilistic data that requires threshold handling rather than exact matching.

Dependencies:
* T08.G8.01a: Analyze logical equivalence of conditionals in code
* T08.G6.05: Use conditionals with AI detection results

CSTA: E8-ALG-AF-01, E8-PRO-PF-01


ID: T08.G8.04
Topic: T08 – Conditions & Logic
Skill: Design conditional logic for multi-agent coordination
Description: Students design conditional logic for scenarios where multiple sprites/agents must coordinate their behavior based on each other's states. For example, in a multi-player game: "if <player1 ready> AND <player2 ready> then start round", or in a simulation: "if <leader moving> AND <distance to leader < 50> then follow". Students learn to handle race conditions and synchronization through careful conditional design.

Dependencies:
* T08.G8.02a: Implement robust input validation with compound conditions
* T08.G6.06: Implement priority-based condition checking

CSTA: E8-ALG-AF-01, E8-PRO-PF-01


ID: T08.G8.05
Topic: T08 – Conditions & Logic
Skill: Optimize condition evaluation order for performance
Description: Students analyze and optimize the order of conditions in compound expressions for performance. For expensive checks (e.g., AI detection, database queries), place cheap failing conditions first: "if <quick check fails> OR <expensive check>" vs "if <expensive check> OR <quick check fails>". Students profile condition evaluation and reorder for efficiency while maintaining correctness.

Dependencies:
* T08.G8.01: Prove logical equivalence using truth tables
* T08.G5.15: Apply short-circuit evaluation patterns

CSTA: E8-ALG-AF-01, E8-PRO-PF-01


ID: T08.G8.06
Topic: T08 – Conditions & Logic
Skill: Design conditional logic for error handling and recovery
Description: **Student task:** Create comprehensive error handling systems using conditional checks for error states, recovery strategies, and graceful degradation. For example: "if <API response = error> then try backup source, if <backup fails> then show cached data, if <no cache> then show user-friendly error message". Students design programs that anticipate failures at each step and provide appropriate fallbacks. This professional-level skill is essential for production-quality software working with AI APIs, network resources, user input, and multiplayer systems.

Dependencies:
* T08.G8.05: Optimize condition evaluation order for performance
* T08.G7.06: Implement retry logic with conditional exit

CSTA: E8-ALG-AF-01, E8-PRO-PF-01


ID: T08.G8.07
Topic: T08 – Conditions & Logic
Skill: Implement confidence-based AI decision making
Description: **Student task:** Design conditional logic that handles AI outputs with varying confidence levels. When using CreatiCode's AI detection (hand tracking, pose detection) or ChatGPT responses, implement tiered decision making: "if <confidence > 0.9> then [take action immediately], else if <confidence > 0.7> then [take action with confirmation], else if <confidence > 0.5> then [show suggestion only], else [say 'unsure, please try again']". Students build AI-powered applications that behave appropriately based on how certain the AI is. This nuanced conditional logic is essential for responsible AI systems that don't overreact to uncertain predictions.

Dependencies:
* T08.G8.03: Implement fuzzy and threshold-based conditions
* T08.G7.07: Design conversation flow with conditional branching

CSTA: E8-ALG-AF-01, E8-PRO-PF-01, E8-IC-AI-01


ID: T08.G8.08
Topic: T08 – Conditions & Logic
Skill: Design A/B testing conditionals for experiments
Description: **Student task:** Implement A/B testing to compare two versions of a feature using conditional random assignment. "set userGroup to (pick random 1 to 2), if <userGroup = 1> then [show version A] else [show version B], log (userGroup) and (user action)". Students design experiments that randomly assign users to groups and track outcomes. Build a simple A/B test for a game feature (e.g., different scoring systems) and analyze which version performs better. This professional experimentation pattern is how real software teams make data-driven decisions about features.

Dependencies:
* T08.G8.06: Design conditional logic for error handling and recovery
* T08.G5.20: Implement feature flags using boolean conditionals

CSTA: E8-ALG-AF-01, E8-PRO-PF-01, E8-DA-IM-01


ID: T08.G8.09
Topic: T08 – Conditions & Logic
Skill: Design self-validating conditional systems
Description: **Student task:** Create conditional systems that validate their own correctness by checking invariants and postconditions. After critical operations, add assertion checks: "if <NOT (score >= 0)> then [log 'ERROR: score went negative!', set score to 0]". Students build programs with self-checking conditionals at key points: after score changes, after state transitions, after data modifications. This defensive programming technique catches bugs early and makes debugging easier. Discuss the trade-off between adding checks (safer but slower) vs trusting the code (faster but riskier).

Dependencies:
* T08.G8.07: Implement confidence-based AI decision making
* T08.G7.09: Prove condition correctness using loop invariants

CSTA: E8-ALG-AF-01, E8-PRO-PF-01, E8-PRO-PF-02


# T09 - Variables & Expressions (Phase 9 Optimized - November 2025)
# Phase 9 Major Optimizations Applied:
# 1. REBALANCED GRADE DISTRIBUTION:
#    - Moved some G4 skills down to G3 (simpler patterns belong earlier)
#    - Added G1 and G2 skills for richer early progression
#    - K: 5 skills (added GK.05 - sort by counter value)
#    - G1: 5 skills (added G1.04-05 - decrement counters, multiple counter tracking)
#    - G2: 6 skills (added G2.05-06 - counter expressions, variable vs constant)
# 2. NEW COMPUTATIONAL THINKING SKILLS:
#    - G3.11: Explain why variable names matter for code readability
#    - G4.21: Use variables to store intermediate calculation results
#    - G5.16: Refactor repeated values into variables
#    - G6.17: Use variables to implement undo functionality
# 3. ENHANCED PROBLEM-SOLVING PROGRESSION:
#    - G4.22: Use boundary checking with variables (min/max guards)
#    - G5.17: Design variable update rules for game mechanics
#    - G6.18: Trace variables through nested conditionals
# 4. NEW AI-ASSISTED PROGRAMMING SKILLS:
#    - G7.21: Use AI to generate variable-based code from natural language
#    - G8.19: Debug variable bugs with AI-assisted analysis
#    - G8.20: Design variable structures for AI training data collection
# 5. IMPROVED INTRA-TOPIC DEPENDENCIES:
#    - Tightened dependency chains within T09
#    - All dependencies verified for X-2 rule compliance
#    - Removed redundant cross-grade dependencies
# 6. STRENGTHENED DEBUGGING PROGRESSION (8 levels now):
#    - G2: Visual debugging (picture-based)
#    - G3: Initialization errors, update errors
#    - G4: Before-use errors, wrong variable, expression errors
#    - G5: Tracing focus, logic errors
#    - G6: Off-by-one, comparison operators, type errors
#    - G7: Scope errors, timing errors, race conditions
#    - G8: Concurrent updates, complex state bugs, AI-assisted debugging
# 7. CREATICODE-SPECIFIC FEATURES:
#    - G3.09: reduce block for young learners
#    - G4.18: for-loop block with automatic variable
#    - G6.13: expression calculator block
#    - G6.16: text validation operators (includes, starts with, ends with)
#    - G7.15: variable-changed event block
#    - G7.20: split/part-of operators for text parsing
#    - G8.12: fast-updating cloud variables
#    - G8.17: noise function for procedural generation
#    - G8.18: solve equation block
# 8. PROFESSIONAL PATTERNS:
#    - G5.13: State machine pattern for animations
#    - G5.15: Constants for maintainable code
#    - G6.17: Undo pattern with variable history
#    - G7.19: Linear interpolation/tweening
#    - G8.15: Memoization and caching
#    - G8.16: Variable schema design
# Logical K-8 Progression:
#   - K: Visual labels (recognition, change, comparison, identification, sorting) - 5 skills
#   - G1: Interactive counters (increment, decrement, tracking, prediction, multiple) - 5 skills
#   - G2: Initialization & goals (starting values, targets, debugging, comparison, expressions, constants) - 6 skills
#   - G3: Core operations (create/init/change/reduce, display, conditionals, copy, trace, debug, predict, naming) - 11 skills
#   - G4: Arithmetic, comparisons, loops, flags, random, pen, timers, debug, boundaries, intermediates - 22 skills
#   - G5: Multiple vars, data types, accumulators, state machines, tracing, swap, constants, refactoring, game design - 17 skills
#   - G6: Real-world modeling, PEMDAS, strings, type conversion, AI prompts, widgets, validation, undo, nested tracing - 18 skills
#   - G7: Dynamic systems, math functions, scope, regex, events, multiplayer, interpolation, parsing, AI code gen - 21 skills
#   - G8: Algorithms, optimization, trig/log, cloud, AI state, memoization, schemas, noise, equations, AI debugging, AI data - 20 skills
# Total: 125 skills (was 110: added 15 new skills for better coverage, rebalanced grades, and AI-era preparation)



ID: T09.GK.01
Topic: T09 – Variables & Expressions
Skill: Recognize that labels can show different numbers
Description: **Student task:** Look at game pictures with labels like "Score: 5", "Lives: 3", "Stars: 2". Point to the label that shows how many stars you have. Then point to the label that shows your score. **Visual scenario:** A colorful game screen with a character, collected stars, and multiple labeled counters at different positions. _Implementation note: Picture-based hot-spot clicking. Show 3-4 labels and ask student to click the correct one. Audio prompt reads labels aloud. CSTA: EK‑PRO‑PF‑02._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine





ID: T09.GK.02
Topic: T09 – Variables & Expressions
Skill: Identify which label changed after collecting something
Description: **Student task:** Look at two game pictures: BEFORE and AFTER catching a star. Which label changed? Tap the label that is different. **Visual scenario:** Side-by-side screenshots: Left shows Score: 2, Stars: 1. Right shows Score: 2, Stars: 2. The Stars label changed! _Implementation note: Side-by-side before/after comparison with tap-to-select. Highlight feedback on correct answer. CSTA: EK‑PRO‑PF‑02._

Dependencies:
* T09.GK.01: Recognize that labels can show different numbers




ID: T09.GK.03
Topic: T09 – Variables & Expressions
Skill: Compare two counters in game pictures to find which is bigger
Description: **Student task:** Look at the game picture. Player 1 has Score: 4. Player 2 has Score: 7. Tap the player who has MORE points! **Visual scenario:** Split-screen showing two game characters with their score labels clearly visible. _Implementation note: Picture comparison task. Audio asks "Who has more points?" Extends GK.02 by comparing values across labels. CSTA: EK‑PRO‑PF‑02._

Dependencies:
* T09.GK.02: Identify which label changed after collecting something




ID: T09.GK.04
Topic: T09 – Variables & Expressions
Skill: Identify what a label is counting in a game picture
Description: **Student task:** Look at the game picture with three labels: "Hearts: 3", "Coins: 5", "Time: 10". The picture shows coins scattered on screen. Tap the label that counts the coins! **Visual scenario:** A colorful game scene with visible coins, heart items, and a timer. Three labeled counters in corners. **Correct answer:** Tap "Coins: 5". _Implementation note: Tests understanding that labels track specific things. Student must match label name to visual items. Audio reads each label. CSTA: EK‑PRO‑PF‑02._

Dependencies:
* T09.GK.03: Compare two counters in game pictures to find which is bigger




ID: T09.GK.05
Topic: T09 – Variables & Expressions
Skill: Sort game characters by their counter values
Description: **Student task:** Three animals finished a race! Duck has Stars: 2, Cat has Stars: 5, Dog has Stars: 3. Drag them onto the podium in order from MOST stars to FEWEST stars. Who gets first place? **Visual scenario:** Three cartoon animals with star counters displayed. A 1st-2nd-3rd podium to drag characters onto. **Correct answer:** Cat (5), Dog (3), Duck (2). _Implementation note: Drag-and-drop sorting activity. Extends GK.03 comparison to ordering three items. Audio celebrates correct ordering. Builds foundation for understanding sorted data. CSTA: EK‑PRO‑PF‑02._

Dependencies:
* T09.GK.03: Compare two counters in game pictures to find which is bigger
* T09.GK.04: Identify what a label is counting in a game picture




ID: T09.G1.01
Topic: T09 – Variables & Expressions
Skill: Change a displayed number by clicking a button
Description: **Student task:** Click the big +1 button to add 1 to the counter. Watch the number go up! Click it 5 times. What number do you see now? **Visual scenario:** Large animated button with counter display starting at 0. Each click shows +1 animation and sound. _Implementation note: Large clickable button (minimum 48x48px) with animated counter. Audio feedback on each click. Final answer verification. CSTA: E1‑PRO‑PF‑02._

Dependencies:
* T09.GK.05: Identify what a label is counting in a game picture
* T03.G1.01: Match a part to its function using picture cards





ID: T09.G1.02
Topic: T09 – Variables & Expressions
Skill: Track items collected using a picture counter
Description: **Student task:** Drag the stars into the basket. Watch the star counter go up each time! How many stars did you collect? **Visual scenario:** 5 scattered stars on screen, a basket in corner, and a "Stars: 0" counter that animates up with each drop. _Implementation note: Drag-and-drop with animated counter increment and celebration at completion. CSTA: E1‑PRO‑PF‑02._

Dependencies:
* T09.G1.01: Change a displayed number by clicking a button




ID: T09.G1.03
Topic: T09 – Variables & Expressions
Skill: Predict counter value after collecting items
Description: **Student task:** The counter shows 2. You are going to drag 3 more stars to the basket. What number will the counter show after? Tap your answer: 3, 4, or 5? **Visual scenario:** Counter at 2 with 3 uncollected stars visible. Multiple choice answers below. _Implementation note: Prediction before action. Student chooses answer, then drags stars to verify. Builds mental math with counters. CSTA: E1‑PRO‑PF‑02._

Dependencies:
* T09.G1.02: Track items collected using a picture counter


ID: T09.G1.04
Topic: T09 – Variables & Expressions
Skill: Decrease a counter by clicking a subtract button
Description: **Student task:** You have 5 cookies. Click the -1 button to eat one cookie. The counter goes DOWN! Click it 3 times. How many cookies are left? **Visual scenario:** Cookie jar with 5 visible cookies and "Cookies: 5" counter. Large -1 button. Each click animates a cookie being eaten and counter decreasing. **Correct answer:** 2 cookies. _Implementation note: Introduces subtraction/decrement concept visually. Mirror of G1.01 for decreasing values. Audio says "Yum!" on each click. CSTA: E1‑PRO‑PF‑02._

Dependencies:
* T09.G1.01: Change a displayed number by clicking a button
* T09.G1.02: Track items collected using a picture counter




ID: T09.G1.05
Topic: T09 – Variables & Expressions
Skill: Track two counters that change independently
Description: **Student task:** Help the bunny collect carrots and apples! Drag carrots to the Carrot basket and apples to the Apple basket. Watch BOTH counters! How many of each did you collect? **Visual scenario:** Two baskets labeled "Carrots: 0" and "Apples: 0", with 3 carrots and 4 apples scattered. Each item only updates its own counter. **Correct answer:** Carrots: 3, Apples: 4. _Implementation note: Introduces multiple independent variables. Drag items to correct baskets, each counter updates separately. Builds foundation for understanding multiple variables. CSTA: E1‑PRO‑PF‑02._

Dependencies:
* T09.G1.02: Track items collected using a picture counter
* T09.G1.05: Track two counters that change independently






ID: T09.G2.01
Topic: T09 – Variables & Expressions
Skill: Set a starting value for a counter before a game begins
Description: **Student task:** Before the race starts, set each racer's starting position. Drag the "Start:" number to 0 for a fair race, or to 5 to give one racer a head start. What happens differently? **Visual scenario:** Two racing characters with editable start position counters. _Implementation note: Picture-based choice of initial values. Shows cause-effect of different starting values. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G1.05: Track two counters that change independently





ID: T09.G2.02
Topic: T09 – Variables & Expressions
Skill: Predict when a counter reaches a target number
Description: **Student task:** The score starts at 2. Each star adds 1 point. The treasure chest opens when score reaches 5. How many stars do you need to collect? **Visual scenario:** Score counter at 2, treasure chest labeled "Opens at 5", and stars to collect. _Implementation note: Animated prediction activity requiring gap calculation (5-2=3). Counter increments toward goal with celebratory reveal when target reached. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G2.01: Set a starting value for a counter before a game begins
* T08.G2.01: Follow branching paths based on yes/no questions




ID: T09.G2.03
Topic: T09 – Variables & Expressions
Skill: Debug why a counter shows a wrong number
Description: **Student task:** Sam collected 4 apples but the counter shows 3. Look at the pictures and find what went wrong! Did Sam miss counting one apple? **Visual scenario:** Four collected apples shown, but counter displays 3. Visual cue highlights the missing count. _Implementation note: Entry-level debugging through picture analysis. Student identifies the discrepancy and taps the missed item. Prepares for G3 debugging skills. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G2.02: Predict when a counter reaches a target number




ID: T09.G2.04
Topic: T09 – Variables & Expressions
Skill: Compare two counters to predict a race winner
Description: **Student task:** Two racers are running! Racer A is at position 6 and moves 2 spaces each turn. Racer B is at position 4 and moves 3 spaces each turn. After 2 more turns, who will be ahead? Tap your prediction! **Visual scenario:** Two race tracks side by side with numbered positions. Racer A at 6, Racer B at 4. Shows "+2 per turn" for A and "+3 per turn" for B. **Correct answer:** Racer B (6+2+2=10 vs 4+3+3=10, tie; or adjust numbers so B wins). _Implementation note: Combines counter tracking with prediction over multiple steps. Builds computational thinking before block-based coding. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G2.03: Debug why a counter shows a wrong number
* T08.G2.01: Follow branching paths based on yes/no questions







ID: T09.G2.05
Topic: T09 – Variables & Expressions
Skill: Predict the result of adding two counters together
Description: **Student task:** Look at the picture! Blue box has 3 toys. Red box has 4 toys. If we put ALL the toys in one BIG box, how many toys will there be? Tap your answer: 5, 6, or 7? **Visual scenario:** Two colorful boxes with visible toys and counters "Blue: 3" and "Red: 4". A large empty box labeled "Total: ?" below. **Correct answer:** 7. _Implementation note: Introduces the concept of combining two values (expression preview). Prepares for arithmetic expressions in G3+. Students learn that counters can be combined. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G2.02: Predict when a counter reaches a target number
* T09.G2.04: Compare two counters to predict a race winner




ID: T09.G2.06
Topic: T09 – Variables & Expressions
Skill: Distinguish between values that change and values that stay the same
Description: **Student task:** In this game, SCORE changes when you collect stars, but MAX_STARS always stays 10 (the goal). Look at the pictures showing SCORE going up: 0, 3, 7, 10. Which number CHANGED and which stayed the SAME? Tap the one that CHANGES. **Visual scenario:** Four sequential game states showing Score increasing from 0 to 10, while "Goal: 10" stays constant. **Correct answer:** Score (it changes). _Implementation note: Introduces variable vs constant concept through visual progression. Prepares for understanding constants in coding. CSTA: E2‑PRO‑PF‑02._

Dependencies:
* T09.G2.01: Set a starting value for a counter before a game begins
* T09.G2.04: Compare two counters to predict a race winner


ID: T09.G3.01
Topic: T09 – Variables & Expressions
Skill: Create, initialize, and increment a variable
Description: Students create their first variable in the block editor by choosing "Make a Variable" with a descriptive name (e.g., "score", "lives"), immediately initialize it with "set [variable] to (value)" at program start, and use "change [variable] by (1)" to increase it by 1 when events occur. They understand that (1) variable names should describe what they store, (2) variables need starting values, and (3) "change by" adds to the current value. This consolidates basic variable creation, initialization, and the increment-by-1 pattern.

Dependencies:
* T09.G2.06: Distinguish between values that change and values that stay the same
* T03.G2.01: Choose subtasks for a simple project idea




ID: T09.G3.02
Topic: T09 – Variables & Expressions
Skill: Change and reduce variables with display monitoring
Description: Students use `change [variable] by (amount)` to increase and `reduce [variable] by (amount)` to decrease variables by arbitrary amounts (e.g., change score by 10, reduce lives by 1). They check the checkbox next to their variable to show its monitor on stage and watch it update in real-time as their code runs. This combines arbitrary increment/decrement operations with real-time visualization.

Dependencies:
* T09.G3.01: Create, initialize, and increment a variable




ID: T09.G3.03
Topic: T09 – Variables & Expressions
Skill: Use variable reporter blocks in other blocks
Description: Students drag the round [variable] reporter block into other blocks to use the variable's value (e.g., "say [score]", "move [speed] steps", or simple conditionals like "if score > 3 then say 'Great!'"). They understand that the variable reporter provides the current value and can be used anywhere a value input is needed. This connects variables to both output (say) and control structures (if).

Dependencies:
* T09.G3.02: Change and reduce variables with display monitoring
* T08.G3.02: Decide when a single if is enough




ID: T09.G3.04
Topic: T09 – Variables & Expressions
Skill: Use a variable in a simple conditional (if block)
Description: Students write conditionals that read a variable's value using simple comparisons (e.g., "if score > 3 then say 'Great!'", "if lives < 1 then say 'Game Over'"). This explicitly connects the variable concept to conditional logic with small, easy-to-test numbers. Focus on understanding that variables can be checked in conditions to control program behavior.

Dependencies:
* T09.G3.03: Use variable reporter blocks in other blocks




ID: T09.G3.05
Topic: T09 – Variables & Expressions
Skill: Debug missing initialization and wrong update values
Description: Students inspect simple scripts (3-5 blocks) where variables don't work because they weren't initialized OR update by the wrong amount. They recognize symptoms (variable starts with wrong value, or changes incorrectly) and find the missing "set [variable] to [initial value]" block or wrong number in "change by [amount]" blocks. This consolidates the two most common beginner variable bugs: missing initialization and wrong literal values.

Dependencies:
* T09.G3.04: Use a variable in a simple conditional (if block)




ID: T09.G3.06
Topic: T09 – Variables & Expressions
Skill: Debug missing change/update block
Description: Students inspect simple scripts (3-5 blocks) where a variable doesn't update as expected during gameplay. Focus on recognizing the symptom (score stays at 0 even after collecting items) and finding the missing "change [variable] by [amount]" or "reduce [variable] by [amount]" block that should appear in the event handler. This builds pattern recognition for update-related bugs.

Dependencies:
* T09.G3.05: Debug missing initialization and wrong update values




ID: T09.G3.07
Topic: T09 – Variables & Expressions
Skill: Trace code with variables to predict outcomes
Description: Students trace a very short script (3-4 steps) where a variable changes in simple ways (set to 0, change by 1, change by 1 again), and predict the final value by reading and following the code. This skill focuses on understanding existing code and predicting outcomes, not creating new variables. Use small numbers and obvious changes.

Dependencies:
* T09.G3.06: Debug missing change/update block
* T08.G3.10: Trace code with a single if/else




ID: T09.G3.08
Topic: T09 – Variables & Expressions
Skill: Copy one variable's value to another variable
Description: Students use "set [variable1] to [variable2]" to copy the value from one variable to another. They understand that this creates an independent copy - changing one variable later doesn't affect the other. Examples: "set backup_score to score", "set player_x to enemy_x". This bridges the gap between basic variable operations and using variables in complex expressions.

Dependencies:
* T09.G3.01: Create, initialize, and increment a variable




ID: T09.G3.09
Topic: T09 – Variables & Expressions
Skill: Use the reduce block for decreasing variables
Description: Students use CreatiCode's `reduce [variable] by (amount)` block as an alternative to `change by` with negative numbers. This block is designed for young learners who may not yet understand negative numbers. Examples: "reduce lives by 1" when hit by enemy, "reduce time by 1" each second. Students understand that reduce decreases while change-by-positive increases.

Dependencies:
* T09.G3.02: Change and reduce variables with display monitoring




ID: T09.G3.10
Topic: T09 – Variables & Expressions
Skill: Predict variable value changes before running code
Description: Students examine a short script (4-6 blocks) with variable operations and predict what value each variable will have after the code runs, WITHOUT actually running the code. They write their prediction, then run the code to verify. This develops computational thinking by mentally simulating code execution. Example: Given "set score to 5, change score by 3, change score by 2", students predict score = 10 before running. This differs from G3.07 (tracing) by requiring prediction BEFORE execution and self-verification AFTER.

Dependencies:
* T09.G3.07: Trace code with variables to predict outcomes




ID: T09.G3.11
Topic: T09 – Variables & Expressions
Skill: Explain why descriptive variable names improve code readability
Description: Students compare code using descriptive variable names (like "score", "playerSpeed", "livesRemaining") versus non-descriptive names (like "x", "n", "thing1"). They identify which version is easier to understand and explain WHY descriptive names help: (1) you can understand what the variable stores without reading the whole program, (2) you make fewer mistakes when updating the right variable, (3) other people (or future you) can read the code more easily. Example: comparing "set s to s + 1" vs "set score to score + 1" - both work, but one is much clearer.

Dependencies:
* T09.G3.01: Create, initialize, and increment a variable
* T09.G3.10: Predict variable value changes before running code




ID: T09.G4.01
Topic: T09 – Variables & Expressions
Skill: Recognize and create arithmetic expressions with variables
Description: Students recognize that expressions combine variables and values using operators, and create their first expression using addition: "set total to score + bonus". They observe that the + operator combines two values into a sum and can be used with variables, literals, or other reporter blocks. They predict the result of simple expressions before running them. This establishes the foundation for all arithmetic operators.

Dependencies:
* T09.G3.07: Trace code with variables to predict outcomes
* T09.G3.08: Copy one variable's value to another variable




ID: T09.G4.02
Topic: T09 – Variables & Expressions
Skill: Use addition (+) in variable expressions
Description: Students use the + operator block to create expressions that add values, such as "set total to score + bonus" or "set sum to a + b". They understand that the + operator combines two values into a sum and can be used with variables, literals, or other expressions. This extends the foundation with practical addition patterns.

Dependencies:
* T09.G4.01: Recognize and create arithmetic expressions with variables




ID: T09.G4.03
Topic: T09 – Variables & Expressions
Skill: Use subtraction (-) in variable expressions
Description: Students use the - operator block to create expressions that subtract values, such as "set remaining to total - used" or "set difference to a - b". They understand that the - operator finds the difference between two values and can compute negative results.

Dependencies:
* T09.G4.01: Recognize and create arithmetic expressions with variables




ID: T09.G4.04
Topic: T09 – Variables & Expressions
Skill: Use multiplication (*) in expressions
Description: Students use the * operator to create expressions that multiply values, such as "set total to lives * 100" or "set area to width * height". They understand that multiplication scales one value by another.

Dependencies:
* T09.G4.01: Recognize and create arithmetic expressions with variables




ID: T09.G4.05
Topic: T09 – Variables & Expressions
Skill: Use division (/) in expressions
Description: Students use the / operator to create expressions that divide values, such as "set average to sum / count" or "set half to total / 2". They understand that division splits one value by another and may produce decimal results.

Dependencies:
* T09.G4.01: Recognize and create arithmetic expressions with variables




ID: T09.G4.06
Topic: T09 – Variables & Expressions
Skill: Combine two arithmetic operators in a single expression
Description: Students write expressions that combine exactly two operators in one statement using the same type of operation, such as "a + b + c" or "x * y * z". They learn to nest operator blocks in Scratch/CreatiCode and read the resulting expression. This is simpler than mixing different operator types and prepares for G6.02 precedence rules.

Dependencies:
* T09.G4.02: Use addition (+) in variable expressions
* T09.G4.03: Use subtraction (-) in variable expressions
* T09.G4.04: Use multiplication (*) in expressions
* T09.G4.05: Use division (/) in expressions




ID: T09.G4.07
Topic: T09 – Variables & Expressions
Skill: Store and use user input in a variable
Description: Students use an "ask and wait" or input block to capture user input (a number or text), store it in a variable, and then use that variable in later blocks or conditionals.

Dependencies:
* T06.G3.02: Build a key‑press script that controls a sprite
* T09.G3.04: Use a variable in a simple conditional (if block)




ID: T09.G4.08
Topic: T09 – Variables & Expressions
Skill: Use a variable as a loop counter
Description: Students create a counter variable (e.g., "i" or "count"), set it to a starting value before a loop, and change it by 1 inside the loop each iteration. They display or use the counter value to see it change (e.g., say the number, or use it to position a sprite). This introduces the for-loop pattern: initialize before loop, update inside loop. Example: set i to 1, repeat 5 times: say i, change i by 1.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G3.02: Change and reduce variables with display monitoring




ID: T09.G4.09
Topic: T09 – Variables & Expressions
Skill: Use equals (=) and less than (<) comparison operators in conditionals
Description: Students use the equals (=) and less than (<) operators in conditionals to compare variable values. Examples: "if score = 10 then say 'You win!'", "if lives < 1 then broadcast game_over". They understand that comparisons evaluate to true/false and control which code runs. These are the foundational comparisons: = checks for exact match, < checks if left value is smaller than right.

Dependencies:
* T09.G3.04: Use a variable in a simple conditional (if block)
* T09.G3.07: Trace code with variables to predict outcomes




ID: T09.G4.10
Topic: T09 – Variables & Expressions
Skill: Use greater than (>) operator in conditionals
Description: Students use the greater than (>) operator to check if one value exceeds another. Examples: "if score > 100 then say 'High score!'", "if health > 0 then keep playing". They understand that > is the opposite of < and when to use each based on what they want to check.

Dependencies:
* T09.G4.09: Use equals (=) and less than (<) comparison operators in conditionals




ID: T09.G4.11
Topic: T09 – Variables & Expressions
Skill: Use not equal (≠) and inclusive comparison (≥, ≤) operators
Description: Students use CreatiCode's extended comparison operators: not equal (≠) to check if values are different, greater-or-equal (≥) for "at least" conditions, and less-or-equal (≤) for "at most" conditions. Examples: "if lives ≠ 0 then keep playing", "if score ≥ 100 then unlock bonus level", "if health ≤ 20 then show warning". They understand that ≥/≤ include the boundary value unlike >/< which exclude it.

Dependencies:
* T09.G4.09: Use equals (=) and less than (<) comparison operators in conditionals
* T09.G4.10: Use greater than (>) operator in conditionals




ID: T09.G4.12
Topic: T09 – Variables & Expressions
Skill: Debug expression evaluation errors
Description: Students identify and fix bugs where expressions produce wrong results due to: (1) wrong operator used (+ instead of *, / instead of -), (2) operands in wrong order (a - b vs b - a matters for subtraction/division), or (3) missing/extra operands. They trace expression evaluation step-by-step to find the error. Example: "set average to sum / count" should be "sum / count" not "count / sum". This introduces debugging of mathematical logic distinct from variable usage bugs.

Dependencies:
* T09.G4.06: Combine two arithmetic operators in a single expression
* T09.G4.09: Use equals (=) and less than (<) comparison operators in conditionals




ID: T09.G4.13
Topic: T09 – Variables & Expressions
Skill: Use a flag variable to track state (0/1 or true/false)
Description: Students create variables (using 0/1 or meaningful names like "game_over") to remember whether an event occurred. They set the flag when the event happens (e.g., "set has_key to 1" when collecting a key) and check it in conditionals to control later behavior (e.g., "if has_key = 1 then open door"). This introduces state tracking, where a variable's value persists and affects future decisions.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.04: Use a variable in a simple conditional (if block)
* T09.G3.05: Debug missing initialization and wrong update values




ID: T09.G4.14
Topic: T09 – Variables & Expressions
Skill: Use random number blocks to set variable values
Description: Students use the "pick random (min) to (max)" block to set variables to random values, enabling games with unpredictable elements like random enemy positions, random prizes, or dice rolls.

Dependencies:
* T09.G3.01: Create, initialize, and increment a variable




ID: T09.G4.15
Topic: T09 – Variables & Expressions
Skill: Choose appropriate variable display modes (normal, large, slider)
Description: Students right-click on a variable monitor and choose between display modes: normal (shows name and value), large (shows only value in big text), or slider (shows value with draggable control). They understand when each mode is useful for different purposes (large for score display, slider for testing/adjusting values).

Dependencies:
* T09.G3.02: Change and reduce variables with display monitoring
* T12.G3.01: Test and trace simple block-based scripts




ID: T09.G4.16
Topic: T09 – Variables & Expressions
Skill: Debug variable used before initialization
Description: Students examine a program where a variable is used in an expression or conditional before being initialized (set to a starting value). They trace through the code to identify that the variable needs to be initialized at program start or before first use. This builds on G3.05 by handling scripts with 6-10 blocks in more complex contexts.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G3.06: Debug missing change/update block
* T09.G4.08: Use a variable as a loop counter
* T12.G3.01: Test and trace simple block-based scripts




ID: T09.G4.17
Topic: T09 – Variables & Expressions
Skill: Debug wrong variable or update frequency errors
Description: Students examine programs where the wrong variable is used in an expression (e.g., using "lives" instead of "score") OR a variable is updated the wrong number of times (often in loops - counter increments on every frame instead of once per event). They trace through the code to identify which variable should be used based on intended logic, or trace loop iterations to identify update frequency problems. This consolidates the two common intermediate debugging patterns.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G4.08: Use a variable as a loop counter
* T09.G4.16: Debug variable used before initialization
* T12.G3.01: Test and trace simple block-based scripts




ID: T09.G4.18
Topic: T09 – Variables & Expressions
Skill: Use CreatiCode's for-loop block with automatic variable
Description: Students use CreatiCode's `for [variable] from (start) to (limit) at step (step)` block which automatically manages a loop counter variable. Examples: "for i from 1 to 10 at step 1" counts 1,2,3...10, or "for i from 0 to 100 at step 10" counts 0,10,20...100. This is more efficient than manually initializing and changing a counter inside a repeat loop. Students compare both approaches and understand when to use each.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G4.08: Use a variable as a loop counter




ID: T09.G4.19
Topic: T09 – Variables & Expressions
Skill: Use variables with pen blocks for drawing patterns
Description: Students use variables to control pen drawing operations, creating patterns based on variable values. They use a counter variable to change pen size, color, or position during drawing. Examples: draw concentric circles where each circle's radius is determined by a counter variable, or draw a spiral where the distance moved increases by a variable amount each iteration. This connects variables to visual output and demonstrates how changing numbers create patterns.

Dependencies:
* T09.G4.08: Use a variable as a loop counter
* T09.G4.18: Use CreatiCode's for-loop block with automatic variable




ID: T09.G4.20
Topic: T09 – Variables & Expressions
Skill: Build a countdown timer using variables
Description: Students create a countdown timer that starts at a value (e.g., 10 seconds) and decreases to 0. They initialize a timer variable, use the `reduce by 1` block inside a loop with a 1-second wait, and display the countdown. They add a conditional to detect when the timer reaches 0 and trigger an action (say "Time's up!", end game). This practical application combines initialization, reduction, display, and conditionals in a common game mechanic.

Dependencies:
* T09.G3.09: Use the reduce block for decreasing variables
* T09.G4.08: Use a variable as a loop counter
* T09.G4.09: Use equals (=) and less than (<) comparison operators in conditionals




ID: T09.G4.21
Topic: T09 – Variables & Expressions
Skill: Store intermediate calculation results in variables
Description: Students break down complex calculations into steps by storing intermediate results in variables. Instead of writing one large expression, they compute each step separately. Example: to calculate area of a border (outer - inner area), first "set outerArea to outerWidth * outerHeight", then "set innerArea to innerWidth * innerHeight", then "set borderArea to outerArea - innerArea". This pattern makes code more readable, easier to debug (can check each step), and prepares for more complex multi-step algorithms.

Dependencies:
* T09.G4.06: Combine two arithmetic operators in a single expression
* T09.G4.12: Debug expression evaluation errors




ID: T09.G4.22
Topic: T09 – Variables & Expressions
Skill: Implement boundary checking with min and max guards
Description: Students use conditionals to keep variable values within valid ranges. They implement patterns like: "if health > maxHealth then set health to maxHealth" and "if x < 0 then set x to 0". They understand that many games and simulations require variables to stay within bounds (health can't exceed max, position can't go off-screen, score can't be negative). This defensive programming pattern prevents bugs and ensures consistent behavior.

Dependencies:
* T09.G4.09: Use equals (=) and less than (<) comparison operators in conditionals
* T09.G4.11: Use not equal (≠) and inclusive comparison (≥, ≤) operators
* T09.G4.13: Use a flag variable to track state (0/1 or true/false)




ID: T09.G5.01
Topic: T09 – Variables & Expressions
Skill: Use multiple variables together in a single expression
Description: Students write expressions that reference 2-3 different variables in one calculation, such as "set area to width * height" or "set total to price * quantity". The focus is on using multiple named variables (not just literals) to compute a result, understanding that variables can reference each other.

Dependencies:
* T09.G4.06: Combine two arithmetic operators in a single expression
* T09.G4.17: Debug wrong variable or update frequency errors




ID: T09.G5.02
Topic: T09 – Variables & Expressions
Skill: Create and use string variables
Description: Students create variables that hold text instead of numbers (e.g., name, message, status). They set string values using "set [myName] to [Alice]" and display them using say blocks or labels.

Dependencies:
* T06.G5.01: Identify standard event patterns in a small game
* T09.G4.07: Store and use user input in a variable




ID: T09.G5.03
Topic: T09 – Variables & Expressions
Skill: Create and use boolean variables with true/false values
Description: Students create variables that hold boolean (true/false) values instead of numbers or text. They set boolean values using logic blocks and use them in conditionals to control program flow. Examples: "set isJumping to true", "if isJumping = true then...". This is more intuitive than using 0/1 for flags.

Dependencies:
* T08.G5.01: Draw decision tree flowchart
* T09.G4.13: Use a flag variable to track state (0/1 or true/false)




ID: T09.G5.04
Topic: T09 – Variables & Expressions
Skill: Identify and choose appropriate variable types for data
Description: Students identify the three main variable types (number, string, boolean) and explain what each can store. They predict what happens when mixing types (e.g., adding a number to a string produces concatenation, not arithmetic). Given a scenario, they choose the appropriate variable type: "score" → number for calculations, "playerName" → string for text, "gameOver" → boolean for true/false state. This skill is essential for avoiding type-related bugs.

Dependencies:
* T09.G5.02: Create and use string variables
* T09.G5.03: Create and use boolean variables with true/false values




ID: T09.G5.05
Topic: T09 – Variables & Expressions
Skill: Join strings using concatenation
Description: Students use the `join` block to combine multiple text values into one string, such as "join [Hello ] [name]" to create personalized messages. They understand that join combines text end-to-end without spaces unless explicitly added.

Dependencies:
* T06.G5.01: Identify standard event patterns in a small game
* T09.G5.02: Create and use string variables




ID: T09.G5.06
Topic: T09 – Variables & Expressions
Skill: Use multi-input join with separator
Description: Students use the advanced join block `join [T1] [T2] [T3] [T4] [T5] [T6] with [SEPARATOR]` to combine multiple strings with a separator between them. They apply this for creating CSV data, formatted lists, or comma-separated values. Example: join names with ", " to create "Alice, Bob, Carol".

Dependencies:
* T09.G5.05: Join strings using concatenation




ID: T09.G5.07
Topic: T09 – Variables & Expressions
Skill: Use variables as settings to control program behavior
Description: Students create variables that control game or program settings (e.g., player_speed, enemy_count, difficulty_level) and use them throughout the code so changing one value updates the entire program's behavior. This demonstrates the power of variables as configurable parameters.

Dependencies:
* T09.G4.17: Debug wrong variable or update frequency errors
* T11.G5.01: Decompose a problem into logical custom block boundaries




ID: T09.G5.08
Topic: T09 – Variables & Expressions
Skill: Use the accumulator pattern to compute running totals
Description: Students implement the accumulator pattern: initialize a variable to 0, then add values to it repeatedly (in a loop or across events) to compute totals. They understand this pattern is essential for sums, averages, and statistics. Example: "set total to 0", then in loop: "change total by (item value)".

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T06.G5.01: Identify standard event patterns in a small game
* T07.G5.01: Simulate repeated experiments with a loop
* T09.G4.08: Use a variable as a loop counter
* T09.G4.17: Debug wrong variable or update frequency errors




ID: T09.G5.09
Topic: T09 – Variables & Expressions
Skill: Trace a counter through loop iterations to predict final value
Description: Students trace a script where a counter variable starts at a value and changes inside a repeat loop, tracking its value at each iteration and predicting the final value. Example: "set i to 0, repeat 5 times: change i by 2" results in i = 10. This extends G3.07 tracing to multi-iteration contexts.

Dependencies:
* T02.G5.01: Trace a script with nested loops using debug print
* T04.G5.01: Identify and classify counter update patterns in code
* T07.G5.01: Simulate repeated experiments with a loop
* T09.G4.08: Use a variable as a loop counter




ID: T09.G5.10
Topic: T09 – Variables & Expressions
Skill: Trace code with multiple interacting variables
Description: Students trace code involving 2-3 variables that interact through expressions, recording each variable's value at each step. Focus on understanding how assignment order affects results (e.g., "set a to b" before vs after "set b to 5").

Dependencies:
* T02.G5.01: Trace a script with nested loops using debug print
* T09.G5.01: Use multiple variables together in a single expression
* T09.G5.09: Trace a counter through loop iterations to predict final value




ID: T09.G5.11
Topic: T09 – Variables & Expressions
Skill: Track high score using variable comparison
Description: Students implement a high score system: compare current score to high_score variable, and if current is greater, update high_score. This combines accumulator tracking with conditional updates and persists the "best so far" value.

Dependencies:
* T04.G5.01: Identify and classify counter update patterns in code
* T08.G5.01: Draw decision tree flowchart
* T09.G4.11: Use not equal (≠) and inclusive comparison (≥, ≤) operators
* T09.G5.08: Use the accumulator pattern to compute running totals




ID: T09.G5.12
Topic: T09 – Variables & Expressions
Skill: Apply basic text formatting using string operations
Description: Students combine string variables and join operations to create formatted output messages. They build messages like "Player: [name] - Score: [score]" by joining text literals with variable values. This prepares them for more advanced string operations in Grade 6 by practicing composition of text from multiple parts.

Dependencies:
* T09.G5.06: Use multi-input join with separator
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G5.13
Topic: T09 – Variables & Expressions
Skill: Use variables for animation state machines
Description: Students create a state variable (e.g., "animation_state" with values like "idle", "walking", "jumping") to control which animation plays and what behaviors are active. They use conditionals to check the state and switch between states based on events. Example: "if animation_state = walking then switch costume to walk1, else if animation_state = jumping then switch costume to jump1". This pattern is essential for character controllers and game entities.

Dependencies:
* T09.G4.13: Use a flag variable to track state (0/1 or true/false)
* T09.G5.02: Create and use string variables
* T09.G5.04: Identify and choose appropriate variable types for data




ID: T09.G5.14
Topic: T09 – Variables & Expressions
Skill: Swap two variable values using a temporary variable
Description: Students implement the classic swap algorithm: create a temporary variable, copy one value to temp, copy second value to first variable, copy temp to second variable. Example: to swap a=3 and b=5, use "set temp to a, set a to b, set b to temp". They understand why a direct swap fails ("set a to b, set b to a" loses the original value of a). This fundamental algorithm pattern is essential for sorting, shuffling, and many other algorithms.

Dependencies:
* T09.G3.08: Copy one variable's value to another variable
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G5.15
Topic: T09 – Variables & Expressions
Skill: Define and use constant variables for configuration
Description: Students create variables intended to be set once and never changed during program execution (constants). They use ALL_CAPS naming convention to indicate constants (e.g., MAX_LIVES, GRAVITY, SCREEN_WIDTH) and set them at program start. They understand constants make code more maintainable—changing one constant updates all places it's used. Example: "set JUMP_HEIGHT to 50" used throughout the code; changing it once changes all jumps. Students contrast constants with variables that change during execution.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G5.16
Topic: T09 – Variables & Expressions
Skill: Refactor repeated literal values into named variables
Description: Students identify code where the same literal value appears multiple times (e.g., "move 50 steps" appears in 5 places) and refactor by creating a named variable (e.g., "set moveDistance to 50") and replacing all occurrences with the variable. They understand benefits: (1) changing the value in one place updates everywhere, (2) the name documents what the value means, (3) reduces chance of inconsistent updates. This "Don't Repeat Yourself" (DRY) principle is fundamental to maintainable code.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior
* T09.G5.15: Define and use constant variables for configuration




ID: T09.G5.17
Topic: T09 – Variables & Expressions
Skill: Design variable update rules for game mechanics
Description: Students design the variable logic for common game mechanics by specifying: (1) what variables are needed, (2) their initial values, (3) when and how they change, and (4) what conditions check them. Examples: health system (health starts at 100, decreases when hit, can't go below 0 or above max, game over when 0), scoring system (score starts at 0, increases on collect, displays on stage), or power-up system (hasPowerUp starts false, becomes true on collect, enables special ability, expires after timer). This design-before-code approach builds planning skills.

Dependencies:
* T09.G5.13: Use variables for animation state machines
* T09.G5.15: Define and use constant variables for configuration
* T09.G4.22: Implement boundary checking with min and max guards




ID: T09.G6.01
Topic: T09 – Variables & Expressions
Skill: Model real-world quantities using variables and formulas
Description: Students create variables representing real-world quantities (e.g., distance, time, money, temperature) and update them using formulas. Examples: total_cost = price × quantity, distance = speed × time. This connects math formulas to programming.

Dependencies:
* T09.G5.08: Use the accumulator pattern to compute running totals
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G6.02
Topic: T09 – Variables & Expressions
Skill: Apply operator precedence rules (PEMDAS) in expressions
Description: Students write and evaluate expressions mixing addition/subtraction with multiplication/division, understanding that * and / are evaluated before + and -. They learn to read and predict evaluation order in expressions like "a + b * c" (multiply first, then add). This focuses on understanding the default order of operations.

Dependencies:
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G6.03
Topic: T09 – Variables & Expressions
Skill: Use parentheses to override operator precedence
Description: Students use parentheses to control evaluation order in expressions, overriding default PEMDAS precedence. They predict and explain different results from "(a + b) * c" vs "a + b * c". This enables them to write expressions that match their intended calculation order.

Dependencies:
* T09.G6.02: Apply operator precedence rules (PEMDAS) in expressions




ID: T09.G6.04
Topic: T09 – Variables & Expressions
Skill: Use exponents (^) and modulo (%) operators
Description: Students use the power operator (^) to compute squares, cubes, and other powers (e.g., "set area to side ^ 2"), and the modulo operator (% or mod) to find remainders from division. They apply modulo to practical tasks like determining odd/even numbers (n mod 2), cycling through values, or creating repeating patterns. Example: "if score mod 10 = 0" to trigger events every 10 points.

Dependencies:
* T09.G6.03: Use parentheses to override operator precedence




ID: T09.G6.05
Topic: T09 – Variables & Expressions
Skill: Use string length and join operations
Description: Students use `length of [string]` to get the character count of text and combine it with join operations for validation and formatting. They apply this to validate input (e.g., check password length) and create formatted output. Example: "if length of [name] > 10".

Dependencies:
* T09.G5.05: Join strings using concatenation




ID: T09.G6.06
Topic: T09 – Variables & Expressions
Skill: Extract characters with letter-of operator
Description: Students use the `letter (position) of [text]` block to extract a single character from a specific position in a string. They apply this for character-by-character text processing, validation, or creating acronyms. Example: "letter 1 of [name]" to get first initial.

Dependencies:
* T09.G6.05: Use string length and join operations




ID: T09.G6.07
Topic: T09 – Variables & Expressions
Skill: Find and extract text with position and substring operators
Description: Students use `position of [search] in [text]` to find where a substring appears (returns position number, or 0 if not found), and `substring of [text] from position (start) to (end)` to extract parts of strings. They apply this for text searching, parsing, and extracting portions like initials or file extensions. Example: check if email contains "@", extract first name from full name.

Dependencies:
* T09.G6.06: Extract characters with letter-of operator




ID: T09.G6.08
Topic: T09 – Variables & Expressions
Skill: Transform text with replace, split, and case operators
Description: Students use `replace [old] with [new] in [text]` to substitute text, `split [text] by [delimiter]` to break strings into lists, and `[CASE v] of text [T]` for uppercase/lowercase conversion. They apply these for text normalization, parsing CSV data, formatting output, and case-insensitive comparisons. Example: replace all spaces with underscores, split "apple,banana,cherry" by ",", convert to uppercase for shouting effects.

Dependencies:
* T09.G6.07: Find and extract text with position and substring operators




ID: T09.G6.09
Topic: T09 – Variables & Expressions
Skill: Use temporary variables for multi-step calculations
Description: Students create temporary variables to hold intermediate results in multi-step calculations. For example, when calculating average: first compute total, then count, then divide total by count. This improves code readability and enables debugging by inspecting intermediate states.

Dependencies:
* T09.G5.08: Use the accumulator pattern to compute running totals
* T09.G6.03: Use parentheses to override operator precedence




ID: T09.G6.10
Topic: T09 – Variables & Expressions
Skill: Trace variable values across multiple event handlers
Description: Students trace how variables maintain their values across different event handlers and broadcasts. They predict the value of a variable after a sequence of events: one script sets a variable and broadcasts a message, another script receiving that broadcast reads the updated value. This demonstrates coordination between different parts of a program through shared variable state.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior




ID: T09.G6.11
Topic: T09 – Variables & Expressions
Skill: Debug off-by-one and comparison operator errors
Description: Students debug scripts where variables control program flow through conditionals and loops. Common bugs include: wrong comparison operator (using > instead of >=), off-by-one errors in loop conditions, or variables not being reset. This extends G4.17 by focusing on control-flow bugs.

Dependencies:
* T09.G4.17: Debug wrong variable or update frequency errors
* T09.G5.10: Trace code with multiple interacting variables




ID: T09.G6.12
Topic: T09 – Variables & Expressions
Skill: Use variables to parameterize AI prompts dynamically
Description: Students create variables to store user preferences, settings, or context information, then use these variables to construct dynamic AI prompts. Examples: "set style to [answer]", then "ask AI to draw [subject] in [style] style", or "set difficulty to [hard]", then "ask AI to generate [difficulty] math problem". This demonstrates how variables enable personalized and adaptive AI interactions.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior
* T09.G5.12: Apply basic text formatting using string operations




ID: T09.G6.13
Topic: T09 – Variables & Expressions
Skill: Use the expression calculator block for complex formulas
Description: Students use CreatiCode's `calculate expression [text]` block to evaluate mathematical expressions written as text strings. This allows for dynamic formula evaluation where the expression itself can be constructed or modified at runtime. Examples: "calculate expression [(1 + 1) * (2^4)]" returns 32, or building a formula string from user input like "calculate expression [join [price] [* 1.08]]" for tax calculation. Students understand when to use this vs regular operator blocks.

Dependencies:
* T09.G5.12: Apply basic text formatting using string operations
* T09.G6.04: Use exponents (^) and modulo (%) operators




ID: T09.G6.14
Topic: T09 – Variables & Expressions
Skill: Build dynamic UI with widget-bound variables
Description: Students connect variables to CreatiCode UI widgets (labels, text inputs, sliders) to create interactive interfaces. They use variables to display values in label widgets, read user input from text fields into variables, and bind slider widgets to control variable values. Example: create a "Speed: [speed]" label that updates automatically, or use a slider widget to let users adjust difficulty level stored in a variable. This pattern is essential for building user-friendly applications.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior
* T09.G6.10: Trace variable values across multiple event handlers




ID: T09.G6.15
Topic: T09 – Variables & Expressions
Skill: Convert between data types explicitly
Description: Students explicitly convert between data types: number to string using join (e.g., "join [] [score]" converts score to text), string to number using arithmetic (e.g., "set num to [textValue] + 0" or explicit conversion blocks), and understand implicit type coercion. They predict and debug type-related errors such as comparing "5" (string) with 5 (number) or concatenating numbers unintentionally. Example: converting user input from text to number before doing calculations.

Dependencies:
* T09.G5.04: Identify and choose appropriate variable types for data
* T09.G6.05: Use string length and join operations




ID: T09.G6.16
Topic: T09 – Variables & Expressions
Skill: Validate text patterns with includes/starts/ends operators
Description: Students use CreatiCode's text validation operators to check string patterns: `[text] includes [search]` to check if text contains a substring, `[text] starts with [prefix]` to check beginning, and `[text] ends with [suffix]` to check ending. They apply these for input validation and filtering. Examples: check if email includes "@", check if filename ends with ".png", check if command starts with "/". These operators support case-insensitive matching with the ignore case option.

Dependencies:
* T09.G5.05: Join strings using concatenation
* T09.G6.07: Find and extract text with position and substring operators




ID: T09.G6.17
Topic: T09 – Variables & Expressions
Skill: Implement undo functionality using variable history
Description: Students implement a simple undo feature by storing the previous value of a variable before changing it. Pattern: "set previousValue to currentValue" before "set currentValue to newValue", then undo restores with "set currentValue to previousValue". They extend this to store multiple previous values in a list for multi-level undo. Example: in a drawing app, store previous x,y positions to undo the last move; in a game editor, store previous object positions. This introduces the concept of state history for reversible actions.

Dependencies:
* T09.G5.14: Swap two variable values using a temporary variable
* T09.G6.09: Use temporary variables for multi-step calculations




ID: T09.G6.18
Topic: T09 – Variables & Expressions
Skill: Trace variables through nested conditional branches
Description: Students trace code with nested if/else structures (2-3 levels deep) to predict variable values. They create a trace table showing the variable's value at each decision point and through each branch. Example: if score > 100 { if hasBonus { multiplier = 3 } else { multiplier = 2 } } else { multiplier = 1 } - trace what multiplier becomes for different score and hasBonus values. This prepares for debugging complex conditional logic.

Dependencies:
* T09.G5.10: Trace code with multiple interacting variables
* T09.G6.11: Debug off-by-one and comparison operator errors




ID: T09.G7.01
Topic: T09 – Variables & Expressions
Skill: Model dynamic systems where variables change over time
Description: Students create simulations where variables represent quantities that change each frame or time step. Examples: position updated by velocity, population growing by percentage, temperature cooling. They set up update rules (e.g., "change position by speed") and observe how repeated updates create realistic animations.

Dependencies:
* T07.G5.01: Dynamic systems require loops to update variables over time steps.
* T09.G6.09: Use temporary variables for multi-step calculations




ID: T09.G7.02
Topic: T09 – Variables & Expressions
Skill: Use rounding and absolute value functions
Description: Students use rounding functions to convert decimals to integers: round() rounds to nearest, floor() rounds down, ceiling() rounds up. They also use abs() to get magnitude without regard to sign. They understand when each is appropriate. Examples: "set rounded_score to round(score)" for display, "set pages to ceiling(items / 10)" for pagination, "set distance to abs(x1 - x2)" for magnitude.

Dependencies:
* T09.G6.04: Use exponents (^) and modulo (%) operators




ID: T09.G7.03
Topic: T09 – Variables & Expressions
Skill: Use square root and distance functions
Description: Students use the sqrt() function to find square roots and distance 2D block to calculate Euclidean distance between points. They apply these for distance formulas (Pythagorean theorem), collision detection ranges, or proximity checks. Examples: "set distance to sqrt((x2-x1)^2 + (y2-y1)^2)" or using the built-in distance block for simplified calculations.

Dependencies:
* T09.G7.02: Use rounding and absolute value functions




ID: T09.G7.04
Topic: T09 – Variables & Expressions
Skill: Use min, max, and direction functions
Description: Students use min() and max() functions to keep variable values within bounds and the direction block to calculate angles between points. Examples: "set x to max(0, min(480, x))" to keep x between 0 and 480, "set health to max(0, health)" to prevent negative health, or calculate angle toward moving target for aiming mechanics. These are essential for game boundaries, clamping values, and trajectory calculations.

Dependencies:
* T09.G7.03: Use square root and distance functions




ID: T09.G7.05
Topic: T09 – Variables & Expressions
Skill: Compute average using sum and count variables
Description: Students implement average calculation: maintain a sum variable (accumulating values) and a count variable (tracking how many), then compute average by dividing sum by count. This combines multiple variable patterns and connects to data analysis.

Dependencies:
* T09.G5.08: Use the accumulator pattern to compute running totals
* T09.G6.09: Use temporary variables for multi-step calculations




ID: T09.G7.06
Topic: T09 – Variables & Expressions
Skill: Use compound conditions (AND, OR, NOT) with variables
Description: Students create conditional expressions using logical operators (AND, OR, NOT) to combine multiple variable comparisons. Example: "if score > 10 AND lives > 0" or "if NOT game_over". This enables more nuanced decision logic.

Dependencies:
* T09.G5.11: Track high score using variable comparison
* T09.G6.11: Debug off-by-one and comparison operator errors




ID: T09.G7.07
Topic: T09 – Variables & Expressions
Skill: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)
Description: Students choose the appropriate scope when creating variables: for-this-sprite for private data each sprite clone needs separately (e.g., individual clone's speed, health), and for-all-sprites for shared data like game score that all sprites can read and update. They debug scope-related bugs where a variable unexpectedly shows the same value across all clones, or where sprites can't access needed data. They demonstrate sharing data between sprites using for-all-sprites variables.

Dependencies:
* T09.G5.07: Use variables as settings to control program behavior
* T09.G6.01: Model real-world quantities using variables and formulas




ID: T09.G7.08
Topic: T09 – Variables & Expressions
Skill: Save and load variables from files (import/export)
Description: Students use file export operations to save variable values to a file and file import operations to load them back. This enables persistent storage of game state, settings, or high scores that survives beyond program execution. They understand how to format data for export/import and create complete save/load functionality.

Dependencies:
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)




ID: T09.G7.09
Topic: T09 – Variables & Expressions
Skill: Predict behavior changes from modifying variable values
Description: Students analyze existing code and predict how behavior changes when variable initialization values, update amounts, or conditions are modified. Example: "If speed changes from 5 to 10, what happens?" This is analytical reasoning about code without running it.

Dependencies:
* T09.G6.11: Debug off-by-one and comparison operator errors
* T09.G7.01: Model dynamic systems where variables change over time




ID: T09.G7.10
Topic: T09 – Variables & Expressions
Skill: Use regex test to validate text patterns
Description: Students use the regex test operation to check if a text string matches a regular expression pattern, returning true or false. They apply this for input validation (e.g., checking if email format is valid, if password meets requirements). Example: test if text matches pattern "^[A-Za-z]+$" for letters only.

Dependencies:
* T09.G6.08: Transform text with replace, split, and case operators




ID: T09.G7.11
Topic: T09 – Variables & Expressions
Skill: Use regex match to find pattern occurrences
Description: Students use the regex match operation to find all occurrences of a pattern in text, returning a list of matches. They apply this for extracting data (e.g., finding all numbers in text, extracting hashtags from messages). Example: match all words starting with capital letters.

Dependencies:
* T09.G7.10: Use regex test to validate text patterns




ID: T09.G7.12
Topic: T09 – Variables & Expressions
Skill: Use regex replace and split for pattern-based text processing
Description: Students use regex replace to substitute text matching a pattern with replacement text, and regex split to break text into parts based on a pattern delimiter (not just fixed strings). They apply these for advanced text processing: removing all digits, normalizing whitespace, flexible parsing. Examples: replace all sequences of spaces with single space, split by any whitespace using pattern "\s+".

Dependencies:
* T09.G7.11: Use regex match to find pattern occurrences




ID: T09.G7.13
Topic: T09 – Variables & Expressions
Skill: Debug variable scope and update timing errors
Description: Students identify and fix bugs related to variable scope (using for-this-sprite when for-all-sprites was needed, or vice versa) and update timing (variable read before being set in another script). They trace variable values across multiple sprites and event handlers to diagnose why a variable has an unexpected value. This prepares them for G8 concurrent update debugging.

Dependencies:
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)
* T09.G7.09: Predict behavior changes from modifying variable values




ID: T09.G7.14
Topic: T09 – Variables & Expressions
Skill: Design variable naming conventions for maintainability
Description: Students establish and follow consistent variable naming conventions (e.g., camelCase, snake_case, descriptive names) for their projects. They understand how good naming improves code readability and maintainability. They refactor existing code to use better variable names and explain why certain names are clearer than others. Examples: "playerSpeed" vs "ps", "highScore" vs "hs", "isGameOver" vs "flag1".

Dependencies:
* T09.G6.10: Trace variable values across multiple event handlers
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)




ID: T09.G7.15
Topic: T09 – Variables & Expressions
Skill: React to variable changes with the variable-changed event
Description: Students use CreatiCode's `when variable [name] changed` event block to trigger scripts automatically whenever a specific variable's value changes. This enables reactive programming patterns where scripts respond to state changes without polling. Examples: update a UI element when score changes, trigger sound when health drops, or sync multiplayer state when position variables update. Students understand this is more efficient than continuously checking variable values in a forever loop.

Dependencies:
* T09.G6.10: Trace variable values across multiple event handlers
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)




ID: T09.G7.16
Topic: T09 – Variables & Expressions
Skill: Store and process AI model outputs in variables
Description: Students use variables to capture outputs from AI blocks (ChatGPT responses, image recognition results, speech-to-text transcriptions) and process them for further use. They understand that AI blocks store their results in specified variables, then use string operations or conditionals to extract meaning from the responses. Example: "ChatGPT request [question] result [aiResponse]", then "if aiResponse includes yes then do action". This connects AI capabilities to programmatic decision-making.

Dependencies:
* T09.G5.12: Apply basic text formatting using string operations
* T09.G6.12: Use variables to parameterize AI prompts dynamically
* T09.G7.10: Use regex test to validate text patterns




ID: T09.G7.17
Topic: T09 – Variables & Expressions
Skill: Create multiplayer game state with shared variables
Description: Students design variable structures for multiplayer games where multiple players need access to shared state. They use for-all-sprites variables for global game state (game_phase, current_turn), and consider how cloud variables can synchronize state across connected players. Example: create turn-based game with "currentPlayer" variable that all sprites check, or shared "gameOver" flag that affects all players. Students plan variable scoping to ensure appropriate data sharing vs privacy.

Dependencies:
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)
* T09.G7.13: Debug variable scope and update timing errors




ID: T09.G7.18
Topic: T09 – Variables & Expressions
Skill: Debug race conditions in concurrent variable updates
Description: Students identify and fix race conditions where multiple scripts attempt to update the same variable simultaneously, causing unpredictable results. They trace scenarios like: two "when I receive" handlers both trying to update score, or collision handler running while another script reads the same variable. They apply fixes such as using flags to prevent concurrent access, ordering operations carefully, or using atomic update patterns. Example: two clones both increment a shared counter at the same time, causing some increments to be lost.

Dependencies:
* T09.G7.13: Debug variable scope and update timing errors
* T09.G7.17: Create multiplayer game state with shared variables




ID: T09.G7.19
Topic: T09 – Variables & Expressions
Skill: Implement linear interpolation for smooth animations (tweening)
Description: Students implement linear interpolation (lerp) to create smooth transitions between values. The lerp formula is: result = start + (end - start) * t, where t goes from 0 to 1. They use this for smooth movement, color fading, size transitions, and easing animations. Example: smoothly move a sprite from position A to position B by updating "set x to startX + (endX - startX) * progress" where progress increases from 0 to 1. Students understand that tweening creates professional-quality animations compared to abrupt changes.

Dependencies:
* T09.G7.01: Model dynamic systems where variables change over time
* T09.G7.04: Use min, max, and direction functions




ID: T09.G7.20
Topic: T09 – Variables & Expressions
Skill: Extract structured data from text using split and part-of operators
Description: Students use the `split [text] by [delimiter]` block to break structured text into parts, and `part (index) of [text] by [separator]` to extract specific fields. They apply this to parse CSV data, extract fields from formatted strings, or process structured input. Examples: split "apple,banana,cherry" by "," to get individual fruits, extract username from "user:password" format, parse coordinates from "x:100,y:200" string. This connects string manipulation to data processing workflows.

Dependencies:
* T09.G6.08: Transform text with replace, split, and case operators
* T09.G7.10: Use regex test to validate text patterns




ID: T09.G7.21
Topic: T09 – Variables & Expressions
Skill: Use AI to generate variable-based code from natural language
Description: Students use CreatiCode's AI assistant (XO) or ChatGPT blocks to generate code snippets involving variables from natural language descriptions. They describe what they want: "Create a score variable that starts at 0 and increases by 10 when touching a coin", then evaluate, test, and potentially modify the AI-generated code. They learn to: (1) write clear prompts that specify variable names and behaviors, (2) verify the generated code works correctly, (3) identify and fix any issues in AI-generated variable logic. This skill prepares students for AI-assisted programming workflows.

Dependencies:
* T09.G6.12: Use variables to parameterize AI prompts dynamically
* T09.G7.16: Store and process AI model outputs in variables




ID: T09.G8.01
Topic: T09 – Variables & Expressions
Skill: Use variables to track index position in linear search
Description: Students implement a linear search algorithm that uses a variable to track the current index position while searching through values. They initialize an index variable, update it in each iteration, and use it to check each position until finding the target value or reaching the end.

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T09.G7.06: Use compound conditions (AND, OR, NOT) with variables
* T09.G7.09: Predict behavior changes from modifying variable values




ID: T09.G8.02
Topic: T09 – Variables & Expressions
Skill: Use flag variables in search algorithms to track found status
Description: Students use a boolean flag variable (e.g., "found") to remember whether a search has succeeded. They set the flag to false initially, update it to true when the target is found, and check it to determine next actions. This pattern helps control loop termination and post-search behavior.

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T09.G8.01: Use variables to track index position in linear search




ID: T09.G8.03
Topic: T09 – Variables & Expressions
Skill: Use variables in iterative approximation algorithms
Description: Students implement iterative approximation algorithms (e.g., Newton's method for square roots, binary search for values) that use variables to track and refine estimates across multiple iterations. They understand convergence criteria and when to stop iterating.

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T09.G8.02: Use flag variables in search algorithms to track found status




ID: T09.G8.04
Topic: T09 – Variables & Expressions
Skill: Simplify and optimize variable expressions
Description: Students identify opportunities to simplify expressions: replacing "x + x + x" with "x * 3", factoring common subexpressions, or replacing a counting loop with a direct formula. They evaluate trade-offs between readability and efficiency.

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.04: Use exponents (^) and modulo (%) operators
* T09.G7.09: Predict behavior changes from modifying variable values
* T10.G6.01: Sort a table by a column




ID: T09.G8.05
Topic: T09 – Variables & Expressions
Skill: Use trigonometric functions in expressions
Description: Students use sine, cosine, tangent, and their inverse functions (asin, acos, atan) to calculate angles and circular motion. They apply these to create circular paths, calculate trajectory angles, or convert between polar and Cartesian coordinates. Examples: "set x to radius * cos(angle)", "set angle to atan2(dy, dx)" for direction to target.

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T07.G6.01: Trace nested loops with variable bounds
* T09.G7.03: Use square root and distance functions
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements




ID: T09.G8.06
Topic: T09 – Variables & Expressions
Skill: Use logarithmic and exponential functions in expressions
Description: Students use natural logarithm (ln), base-10 logarithm (log), and exponential functions (e^x, 10^x) in calculations. They apply these for exponential growth/decay models, compound interest, scientific calculations, or data transformations. Examples: modeling population growth, radioactive decay, pH calculations, or converting between logarithmic and linear scales.

Dependencies:
* T09.G8.05: Use trigonometric functions in expressions




ID: T09.G8.07
Topic: T09 – Variables & Expressions
Skill: Use cloud variables for persistent data storage
Description: Students use cloud variables to save data that persists across sessions and is shared between users. They understand that cloud variables are stored on a server and updated in real-time, enabling high scores, user preferences, or multiplayer data sharing.

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T07.G6.01: Trace nested loops with variable bounds
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)
* T09.G7.08: Save and load variables from files (import/export)
* T15.G6.01: Evaluate an interface for usability




ID: T09.G8.08
Topic: T09 – Variables & Expressions
Skill: Debug variable scope and concurrent update errors
Description: Students identify and fix bugs in programs with multiple sprites sharing variables: scope confusion (for-this-sprite vs for-all-sprites), race conditions when multiple scripts update the same variable, or initialization order dependencies. They trace variable states across concurrent scripts.

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T09.G7.13: Debug variable scope and update timing errors




ID: T09.G8.09
Topic: T09 – Variables & Expressions
Skill: Use variables to manage state in multi-turn AI conversations
Description: Students use variables to track conversation context across multiple AI interactions. Examples: storing user preferences mentioned earlier, tracking conversation topics, maintaining dialogue history, or counting interaction rounds. They understand how variables enable AI systems to "remember" previous interactions and provide contextually relevant responses. Example: "set userFavoriteColor to [answer]", then later "generate poem about [userFavoriteColor]".

Dependencies:
* T09.G6.10: Trace variable values across multiple event handlers
* T09.G6.12: Use variables to parameterize AI prompts dynamically
* T09.G7.07: Choose and apply correct variable scope (for-this-sprite vs for-all-sprites)




ID: T09.G8.10
Topic: T09 – Variables & Expressions
Skill: Analyze variable usage patterns for code optimization
Description: Students analyze their code to identify variable usage patterns and optimization opportunities: variables that are set but never read (dead code), variables updated unnecessarily, or calculations that could be cached in variables instead of recomputed. They refactor code to eliminate redundant variable operations and improve efficiency while maintaining correctness.

Dependencies:
* T09.G7.09: Predict behavior changes from modifying variable values
* T09.G7.14: Design variable naming conventions for maintainability
* T09.G8.04: Simplify and optimize variable expressions




ID: T09.G8.11
Topic: T09 – Variables & Expressions
Skill: Translate mathematical formulas into code expressions
Description: Students translate real-world formulas (distance = speed × time, area = π × r², compound interest) into variable assignments and expressions. They handle operator precedence, multi-step calculations, and unit considerations. This capstone skill demonstrates mastery of variables and expressions.

Dependencies:
* T09.G6.01: Model real-world quantities using variables and formulas
* T09.G6.03: Use parentheses to override operator precedence
* T09.G7.05: Compute average using sum and count variables




ID: T09.G8.12
Topic: T09 – Variables & Expressions
Skill: Use fast-updating cloud variables for real-time synchronization
Description: Students use CreatiCode's cloud variable system to create real-time multiplayer experiences. They join or create cloud sessions with `join cloud session` or `create cloud session named`, then use cloud variables that automatically sync across all connected players. They understand the difference between regular cloud variables (for persistence) and fast-updating cloud variables (for real-time gameplay). Example: sync player positions in a multiplayer racing game, or create a collaborative drawing canvas where strokes appear for all users in real-time.

Dependencies:
* T09.G7.17: Create multiplayer game state with shared variables
* T09.G8.07: Use cloud variables for persistent data storage




ID: T09.G8.13
Topic: T09 – Variables & Expressions
Skill: Use variables with web search and semantic database results
Description: Students use variables to work with CreatiCode's web search and semantic database blocks. They store search results (from `web search [query] store top (K) in table`) and semantic query results in table variables, then extract and process specific fields. Example: search for information about a topic, store results in a table variable, extract the first result's summary, and display it to the user. This connects AI-powered information retrieval to variable-based data processing.

Dependencies:
* T09.G7.16: Store and process AI model outputs in variables
* T09.G8.09: Use variables to manage state in multi-turn AI conversations




ID: T09.G8.14
Topic: T09 – Variables & Expressions
Skill: Build adaptive AI systems using variable-based context
Description: Students design AI interactions that adapt based on accumulated variable state. They track user preferences, interaction history, and conversation context in variables, then use this context to modify AI prompts and responses. Example: build a personalized tutor that tracks which topics the user struggles with (stored in variables), adjusts difficulty based on success rate, and provides targeted help. This represents advanced integration of variables with AI capabilities for intelligent, context-aware applications.

Dependencies:
* T09.G7.16: Store and process AI model outputs in variables
* T09.G8.09: Use variables to manage state in multi-turn AI conversations
* T09.G8.10: Analyze variable usage patterns for code optimization




ID: T09.G8.15
Topic: T09 – Variables & Expressions
Skill: Use variables for memoization and caching
Description: Students implement memoization by storing computed results in variables to avoid redundant calculations. They create cache variables that store previously computed values and check the cache before recalculating. Example: caching Fibonacci numbers, storing collision detection results that are reused in the same frame, or caching expensive AI query results. Students measure performance improvement from caching and understand trade-offs between memory usage and computation time.

Dependencies:
* T09.G8.04: Simplify and optimize variable expressions
* T09.G8.10: Analyze variable usage patterns for code optimization




ID: T09.G8.16
Topic: T09 – Variables & Expressions
Skill: Design variable schemas for complex state management
Description: Students design organized variable naming schemes and structures for managing complex application state. They create variable hierarchies using naming conventions (e.g., player_health, player_x, player_y for player state), document their variable schemas, and plan how different parts of the program will read and update shared state. Example: designing the variable structure for a game with multiple levels, inventory system, and save/load functionality. This capstone skill demonstrates mastery of variables for large-scale applications.

Dependencies:
* T09.G7.14: Design variable naming conventions for maintainability
* T09.G8.10: Analyze variable usage patterns for code optimization
* T09.G8.14: Build adaptive AI systems using variable-based context




ID: T09.G8.17
Topic: T09 – Variables & Expressions
Skill: Generate procedural content using noise functions
Description: Students use CreatiCode's `noise at x (x) y (y) seed (seed)` function to generate smooth, random-looking values for procedural content generation. They understand that noise functions produce consistent values for the same inputs (unlike random), creating coherent patterns. Applications include: terrain generation (height maps), texture variations, natural movement patterns, and organic shapes. Example: use noise to create a rolling hills landscape where y-position varies smoothly based on x-position, or generate random-looking but reproducible tree positions for a forest.

Dependencies:
* T09.G7.01: Model dynamic systems where variables change over time
* T09.G8.05: Use trigonometric functions in expressions




ID: T09.G8.18
Topic: T09 – Variables & Expressions
Skill: Solve equations dynamically with the solve equation block
Description: Students use CreatiCode's `solve equation [equation]` block to solve mathematical equations at runtime. The block takes an equation string and returns variable values (e.g., "solve equation [x + y = 10, x + 2y = 12]" returns "x,8,y,2"). They parse the returned values into separate variables using split operations. Applications include: physics simulations (solving for unknown forces), game mechanics (calculating required speeds to reach targets), and educational tools (checking student equation solutions). This advanced skill combines string handling with mathematical problem-solving.

Dependencies:
* T09.G6.13: Use the expression calculator block for complex formulas
* T09.G7.20: Extract structured data from text using split and part-of operators




ID: T09.G8.19
Topic: T09 – Variables & Expressions
Skill: Debug variable bugs with AI-assisted analysis
Description: Students use AI tools to help diagnose and fix variable-related bugs. They describe the bug symptoms to an AI ("My score variable stays at 0 even when I collect coins") and provide relevant code. They learn to: (1) write effective bug descriptions that include expected vs actual behavior, (2) evaluate AI debugging suggestions critically, (3) verify that suggested fixes actually work, (4) understand WHY the fix works rather than just applying it blindly. This skill develops meta-cognitive debugging abilities enhanced by AI collaboration.

Dependencies:
* T09.G7.13: Debug variable scope and update timing errors
* T09.G7.21: Use AI to generate variable-based code from natural language
* T09.G8.08: Debug variable scope and concurrent update errors




ID: T09.G8.20
Topic: T09 – Variables & Expressions
Skill: Design variable structures for AI training data collection
Description: Students design and implement variable structures to collect training data for AI systems. They create variables and lists to store: user interactions (clicks, answers, times), game play patterns (moves, scores, strategies), or sensor data (positions, velocities). They understand how this data can train AI models to make predictions or adapt behavior. Example: collect player movement patterns in a game to train an AI opponent, or store user preferences to personalize content. This connects variables to machine learning data pipelines.

Dependencies:
* T09.G8.14: Build adaptive AI systems using variable-based context
* T09.G8.16: Design variable schemas for complex state management


# T10 – Lists & Tables (Optimized - November 2025, Revision 3)
# Optimizations (Revision 1):
# 1. Enhanced K-2 skills with Visual scenario format (Student task, Visual scenario, Correct answer, Implementation note)
# 2. Fixed vague verbs: "Look at" → "Read", T10.G5.01 "Understand" → "Identify"
# 3. Split T10.G8.08 into sub-skills: .01 binary search, .02 two-pointer, .03 sliding window
# 4. Verified all X-2 rule compliance for intra-topic dependencies
# 5. Fixed T10.G5.02 dependency name from "Understand table structure" → "Identify table structure"
# 6. Total skills: 113 → 115 (split 1 skill into 3 = +2 skills)
#
# Optimizations (Revision 2 - November 2025):
# 7. Added 4 new essential skills: T10.G4.21 (extract sublist), T10.G6.09 (nested lists/2D arrays), T10.G6.10 (access 2D array elements), T10.G7.15 (stack operations)
# 8. Enhanced descriptions: replaced passive "understand" with observable verbs (observe, verify, note, recognize)
# 9. Added G3 bridging skill T10.G3.11 (predict list changes) for computational thinking
# 10. Added G5 bridging skill T10.G5.19 (manual table filter) to address G6→G3 dependency gap
# 11. Fixed dependency for T10.G6.02 (was violating X-2 rule with G3 dependencies)
# 12. Improved K-2 skills with richer visual scenarios and explicit learning progressions
# 13. Total skills: 115 → 122 (+7 skills for better progression and coverage)
#
# Optimizations (Revision 3 - November 2025):
# MAJOR OVERHAUL - Bold Changes for Data Structure Excellence
#
# PHILOSOPHY SHIFT: Lists & Tables are fundamental for DATA THINKING
# - Every skill emphasizes WHY data structures matter, not just HOW to use them
# - Added "trade-off analysis" and "design justification" components throughout
# - Integrated AI-era skills: processing AI-generated data, validating data pipelines
#
# NEW SKILL CATEGORIES ADDED:
# 1. DATA STRUCTURE COMMUNICATION (explaining choices to others)
#    - GK.09: Explain why we group things together using picture cards
#    - G3.14: Explain to a partner why a list is useful for this problem
#    - G5.22: Compare tables vs parallel lists and justify choice
#    - G7.21: Document data schema decisions for future readers
#
# 2. DATA VERIFICATION & CRITIQUE
#    - G2.08: Trace through a table lookup step by step
#    - G4.25: Debug parallel list synchronization errors
#    - G6.19: Verify data transformation produces correct results
#    - G8.17: Design and test data validation rules for tables
#
# 3. DECISION-MAKING (choosing the right data structure)
#    - G1.07: Choose between one group or two groups based on data
#    - G4.26: Decide when to use a list vs separate variables
#    - G6.20: Choose between filtering vs sorting for a task
#    - G8.18: Compare algorithmic efficiency for list operations
#
# 4. AI-ERA DATA SKILLS
#    - G7.22: Process AI vision detection data stored in tables
#    - G8.16: Parse and analyze AI-generated structured data (NLP, search results)
#    - G8.19: Build a complete AI-enhanced data application
#
# 5. REAL-WORLD DATA CONNECTIONS
#    - GK.10: Find lists and tables in everyday life (picture examples)
#    - G2.09: Connect picture tables to real apps (contacts, calendars)
#    - G5.23: Model a real-world scenario with a table schema
#
# Total skills: 122 → 146 (+24 skills for communication, verification, decision-making, AI integration)

## T10 – Lists & Tables
---

## GRADE K (10 skills)




ID: T10.GK.01
Topic: T10 – Lists & Tables
Skill: Classify picture cards into two groups by attribute
Description: **Student task:** Drag 4-6 picture cards into 2 colored boxes based on a visible attribute (color, shape, or type). **Visual scenario:** Picture cards show: red ball, blue car, red apple, blue block. Two boxes labeled "Red things" and "Blue things." **Correct answer:** Red ball and red apple go in "Red things" box; blue car and blue block go in "Blue things" box. **Why this matters:** Sorting is the first step in organizing data—computers store related items together in lists. _Implementation note: Drag-drop sorting with visual feedback. Auto-graded by final card positions in boxes. CSTA: EK-ALG-AF-01._




ID: T10.GK.02
Topic: T10 – Lists & Tables
Skill: Count items in each sorted group
Description: **Student task:** After sorting picture cards into groups, count how many items are in each group and tap the correct count from picture choices. **Visual scenario:** Two boxes after sorting: "Pets" box has 3 animals (cat, dog, fish), "Wild animals" box has 2 animals (lion, bear). Question: "How many pets?" **Correct answer:** Tap the picture showing 3 dots. **Why this matters:** Counting items in a group is like finding the "length" of a list—a key operation programmers use constantly. _Implementation note: Multi-choice with dot representations (1-4 dots). Audio reads numbers on tap. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute




ID: T10.GK.03
Topic: T10 – Lists & Tables
Skill: Compare group sizes to find which has more
Description: **Student task:** Look at two groups of sorted items and tap the group that has more items. **Visual scenario:** Two boxes after sorting: "Circles" box has 4 shapes, "Triangles" box has 2 shapes. Question: "Which group has more?" **Correct answer:** Tap the "Circles" box. **Why this matters:** Comparing group sizes helps us make decisions about data—like finding which team has more players or which category is most popular. _Implementation note: Visual comparison activity with highlighting on selection. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.02: Count items in each sorted group




ID: T10.GK.04
Topic: T10 – Lists & Tables
Skill: Add a new item to the correct group
Description: **Student task:** Look at two boxes with sorted picture cards. A new picture card appears. Drag it to the correct box. **Visual scenario:** "Animals" box has dog and cat pictures. "Foods" box has apple and banana pictures. New card shows a bird. **Correct answer:** Drag the bird card to the "Animals" box. **Why this matters:** This is like the "add to list" operation—putting a new item where it belongs. _Implementation note: Drag-drop with snap-to-box feedback. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute




ID: T10.GK.05
Topic: T10 – Lists & Tables
Skill: Find the first and last item in a row
Description: **Student task:** Look at a row of 3-5 picture cards arranged from left to right. Tap the first item, then tap the last item. **Visual scenario:** Five picture cards in a row: apple, banana, orange, grape, watermelon. **Correct answer:** Tap apple (first), then tap watermelon (last). _Implementation note: Sequential tap activity with visual order indicators. CSTA: EK-ALG-AF-01._

Dependencies:
* T01.GK.03: Find the first and last pictures




ID: T10.GK.06
Topic: T10 – Lists & Tables
Skill: Read information from a simple picture table
Description: **Student task:** Look at a picture table showing which child likes which fruit. Answer questions by tapping the correct cell. **Visual scenario:** 2x3 table with rows for "Sam" and "Lia", columns for "Fruit" showing apple and banana icons. Question: "What does Sam like?" **Correct answer:** Tap the cell showing Sam's fruit (apple). **Why this matters:** Tables organize information in rows and columns—this is how databases and spreadsheets store data. _Implementation note: Interactive table with cell highlighting on tap. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute




ID: T10.GK.07
Topic: T10 – Lists & Tables
Skill: Match related items by drawing lines
Description: **Student task:** Draw lines or drag to match pairs of related items. **Visual scenario:** Left column shows 3 animals (dog, fish, bird). Right column shows 3 homes (doghouse, fishbowl, nest). **Correct answer:** Dog→doghouse, fish→fishbowl, bird→nest. **Why this matters:** Matching pairs is like a lookup operation—finding related information across two lists. _Implementation note: Line-drawing or drag-drop matching with visual connection feedback. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute




ID: T10.GK.08
Topic: T10 – Lists & Tables
Skill: Filter items by a special mark and count them
Description: **Student task:** Look at a collection of picture cards. Some have a star mark. Tap all cards with stars, then count how many you found. **Visual scenario:** 6 picture cards showing toys. 3 cards have gold stars on them (teddy bear, ball, puzzle). **Correct answer:** Tap the 3 starred cards, then tap "3" from the number choices. **Why this matters:** This is filtering—selecting only the items that match a condition, a core data operation. _Implementation note: Multi-tap selection with counter display. CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.02: Count items in each sorted group




ID: T10.GK.09
Topic: T10 – Lists & Tables
Skill: Explain why we group things together using picture cards
Description: **Student task:** After sorting picture cards into groups, explain WHY you put certain cards together. Point to each group and say what makes those cards belong together. **Visual scenario:** Student has sorted 6 animal cards into "Pets" (dog, cat, fish) and "Farm animals" (cow, pig, chicken). Student records or tells a partner: "I put dog, cat, and fish together because they live in people's homes. I put cow, pig, and chicken together because they live on farms." **Why this matters:** Explaining your grouping helps others understand your thinking and is the first step toward explaining data structure choices in programming. _Implementation note: Voice recording or partner activity. Teacher/AI evaluates explanation for clear reasoning about shared attributes. CSTA: EK-CS-PC-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute
* T10.GK.04: Add a new item to the correct group




ID: T10.GK.10
Topic: T10 – Lists & Tables
Skill: Find lists and tables in everyday life (picture examples)
Description: **Student task:** Look at pictures of real-world items and tap which ones are lists or tables. **Visual scenario:** Four pictures: (A) a grocery shopping list on paper, (B) a single apple, (C) a class schedule showing days and subjects in a grid, (D) a photograph of a dog. **Correct answer:** Tap A (shopping list is a list!) and C (class schedule is a table!). B and D are single items, not collections. **Why this matters:** Lists and tables are everywhere—once you recognize them, you can organize information like a computer does! _Implementation note: Multi-select with picture recognition. Audio explains "A list is a collection of items in order. A table organizes information in rows and columns." CSTA: EK-ALG-AF-01._

Dependencies:
* T10.GK.06: Read information from a simple picture table


---

## GRADE 1 (8 skills)




ID: T10.G1.01
Topic: T10 – Lists & Tables
Skill: Classify items using two combined rules (AND condition)
Description: **Student task:** Drag 6-8 items into groups where each item must match TWO rules (e.g., must be both "big" AND "red"). **Visual scenario:** 8 shape cards: big red circle, small red square, big blue triangle, small blue circle, big red square, small red triangle, big blue square, small blue square. Two boxes: "Big AND Red" and "Other." **Correct answer:** Only big red circle and big red square go in "Big AND Red" box; all others go in "Other" box. **Why this matters:** Filtering data often requires checking multiple conditions at once—this is the AND logic computers use. _Implementation note: Two-attribute classification with visual rule indicators. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.GK.01: Classify picture cards into two groups by attribute
* T10.GK.04: Add a new item to the correct group




ID: T10.G1.02
Topic: T10 – Lists & Tables
Skill: Build a picture tally chart from data
Description: **Student task:** Count items in categories and add tally marks or picture icons to show the count. **Visual scenario:** Picture shows 5 students' snack choices: 2 chose apple, 2 chose banana, 1 chose orange. Empty chart has rows for each snack. **Correct answer:** Add 2 tally marks (or 2 apple icons) in apple row, 2 in banana row, 1 in orange row. **Why this matters:** Tally charts are a simple way to collect and organize data—the foundation of data tables. _Implementation note: Interactive chart builder with drag-drop tally marks or icons. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.GK.02: Count items in each sorted group
* T10.GK.06: Read information from a simple picture table




ID: T10.G1.03
Topic: T10 – Lists & Tables
Skill: Locate specific values in a picture table
Description: **Student task:** Answer questions by finding and tapping specific cells in a picture table with 3-4 rows and 3-4 columns. **Visual scenario:** 3x3 table showing 3 students (rows) and what they have: pencils, crayons, erasers (columns with number icons). Question: "How many pencils does Lia have?" **Correct answer:** Tap the cell at Lia's row, pencils column showing "5." **Why this matters:** Finding a specific value by row and column is exactly how computers look up data in tables. _Implementation note: Interactive table with question-guided cell selection. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.GK.06: Read information from a simple picture table




ID: T10.G1.04
Topic: T10 – Lists & Tables
Skill: Identify the row or column with the maximum value
Description: **Student task:** Look at a picture table and tap the row or column that has the most items in total. **Visual scenario:** 3x2 table showing students and their points. Row 1 (Sam): 5 stars. Row 2 (Lia): 8 stars. Row 3 (Max): 3 stars. Question: "Which student has the most stars?" **Correct answer:** Tap Lia's row (8 stars). **Why this matters:** Finding the maximum is a key aggregation—like finding the high score or the most popular item. _Implementation note: Visual comparison with highlighting on tap. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.G1.03: Locate specific values in a picture table
* T10.GK.03: Compare group sizes to find which has more




ID: T10.G1.05
Topic: T10 – Lists & Tables
Skill: Predict and fill missing values in a table pattern
Description: **Student task:** Look at a table with a pattern in rows or columns. Some cells are empty. Drag the correct picture or number to fill the missing cells. **Visual scenario:** 3x3 table with alternating colors: Red, Blue, ?, Red, Blue, ?, Red, Blue, ?. **Correct answer:** Fill each ? with Red to continue the Red-Blue-Red pattern. **Why this matters:** Recognizing patterns in data helps predict missing values—a common task in data analysis. _Implementation note: Drag-drop pattern completion with visual feedback. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.G1.03: Locate specific values in a picture table
* T01.GK.07: Find the pattern that repeats




ID: T10.G1.06
Topic: T10 – Lists & Tables
Skill: Select items matching multiple conditions (intersection)
Description: **Student task:** Look at a collection of picture cards. Find and tap all items that match TWO conditions at the same time (e.g., items that are both red AND round). **Visual scenario:** 8 cards showing shapes: red circle, blue circle, red square, green triangle, red triangle, blue square, green circle, red oval. Question: "Find all things that are both RED and ROUND." **Correct answer:** Tap only the red circle. **Why this matters:** This is the intersection of two groups—items that are in BOTH groups at once. _Implementation note: Multi-select activity with AND logic indicator. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.G1.01: Classify items using two combined rules (AND condition)




ID: T10.G1.07
Topic: T10 – Lists & Tables
Skill: Select items matching either of two conditions (union)
Description: **Student task:** Look at a collection of picture cards. Find and tap all items that match EITHER one condition OR another (e.g., items that are red OR round). **Visual scenario:** 8 cards showing shapes: red circle, blue circle, red square, green triangle, red triangle, blue square, green circle, red oval. Question: "Find all things that are RED or ROUND (or both)." **Correct answer:** Tap red circle, blue circle, red square, red triangle, green circle, red oval (6 cards total—anything red OR anything round). **Why this matters:** This is the union of two groups—items that are in EITHER group. Sometimes we want anything that matches at least one rule, not both rules. _Implementation note: Multi-select activity with OR logic indicator. Compare to T10.G1.06 to distinguish AND vs OR. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.G1.06: Select items matching multiple conditions (intersection)




ID: T10.G1.08
Topic: T10 – Lists & Tables
Skill: Decide whether to use one group or two groups for sorting
Description: **Student task:** Look at a collection of picture cards and decide: should we sort into ONE group (keep/discard) or TWO groups (category A/category B)? Choose the best sorting strategy. **Visual scenario:** Scenario 1: "We want to find all the red toys." → One group is best (red toys vs. not-red toys). Scenario 2: "We want to organize toys by type." → Two groups make sense (dolls vs. cars). **Correct answer:** Match each scenario to the right sorting approach. **Why this matters:** Choosing the right way to organize data is an important decision programmers make—sometimes one category is enough, sometimes you need multiple categories. _Implementation note: Matching activity connecting scenarios to strategies. CSTA: E1-ALG-AF-01._

Dependencies:
* T10.G1.01: Classify items using two combined rules (AND condition)
* T10.GK.08: Filter items by a special mark and count them


---

## GRADE 2 (10 skills)




ID: T10.G2.01
Topic: T10 – Lists & Tables
Skill: Convert a written list into a structured table
Description: **Student task:** Read a list of information and fill in a table with labeled rows and columns. **Visual scenario:** Text list: "Sam has 3 apples, Lia has 2 oranges, Max has 5 bananas." Empty table with columns: Name, Fruit, Count. **Correct answer:** Fill 3 rows: (Sam, apples, 3), (Lia, oranges, 2), (Max, bananas, 5). **Why this matters:** Converting unstructured information into organized tables is a key data entry skill. _Implementation note: Interactive table builder with drag-drop or type-in fields. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G1.03: Locate specific values in a picture table




ID: T10.G2.02
Topic: T10 – Lists & Tables
Skill: Append a new row to an existing table
Description: **Student task:** Look at an existing picture table. You're given new information for a new student. Add a new row by filling in all the column values. **Visual scenario:** Table has 2 students with columns: Name, Favorite Color. You get: "Add Tom who likes Green." **Correct answer:** Add row 3: (Tom, Green). **Why this matters:** Adding rows is how tables grow—like adding new entries to a database or spreadsheet. _Implementation note: Interactive row addition with column-guided input. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table




ID: T10.G2.03
Topic: T10 – Lists & Tables
Skill: Compare values across two rows in a table
Description: **Student task:** Look at two different rows in a table and answer questions about differences or similarities. **Visual scenario:** Table with columns: Student, Math Score, Reading Score. Row 1: (Sam, 85, 90). Row 2: (Lia, 80, 95). Question: "Who has a higher Math score?" **Correct answer:** Sam. "Who has a higher Reading score?" **Correct answer:** Lia. **Why this matters:** Comparing rows helps answer questions like "who performed better?" or "which product costs more?" _Implementation note: Guided comparison questions with row highlighting. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table




ID: T10.G2.04
Topic: T10 – Lists & Tables
Skill: Reorder table rows by a column value (manual sorting)
Description: **Student task:** Rearrange rows in a simple table to put them in order by one column (e.g., from most to least points). **Visual scenario:** 3-row table: (Sam, 5 points), (Lia, 9 points), (Max, 3 points). Instruction: "Arrange from most to least points." **Correct answer:** Lia (9), Sam (5), Max (3). **Why this matters:** Sorting makes data easier to analyze—finding the top performer or lowest value becomes instant. _Implementation note: Drag-drop row reordering with visual order indicators. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table
* T01.G1.01: Put pictures in order to plant a seed




ID: T10.G2.05
Topic: T10 – Lists & Tables
Skill: Filter table rows by marking those matching a condition
Description: **Student task:** Look at a table and mark all rows where a specific column matches a condition. **Visual scenario:** 5-row table with student scores. Question: "Mark all students with 10 or more points." Rows: (Sam, 8), (Lia, 12), (Max, 15), (Eva, 6), (Tom, 10). **Correct answer:** Mark Lia, Max, and Tom rows. **Why this matters:** Filtering is how we find relevant data—like finding all orders over $100 or all students who passed. _Implementation note: Multi-select row marking with condition indicator. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table




ID: T10.G2.06
Topic: T10 – Lists & Tables
Skill: Count filtered rows that satisfy a condition
Description: **Student task:** Look at a table and count how many rows satisfy a condition. **Visual scenario:** 5-row table with student scores: (Sam, 8), (Lia, 12), (Max, 15), (Eva, 6), (Tom, 10). Question: "How many students scored more than 5?" **Correct answer:** 5 students (all of them: Sam 8, Lia 12, Max 15, Eva 6, Tom 10 are all greater than 5). **Why this matters:** Counting filtered results answers questions like "how many people registered?" or "how many errors occurred?" _Implementation note: Count-focused activity with condition highlighting. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.05: Filter table rows by marking those matching a condition




ID: T10.G2.07
Topic: T10 – Lists & Tables
Skill: Recognize real-world examples of lists and tables
Description: Students transition from picture tables to recognizing that code can have "lists" - ordered collections of items that the computer stores and uses. **Student task:** Look at picture scenarios and tap which ones represent "lists" (ordered collections). **Visual scenario:** Four pictures: (A) shopping list on paper, (B) single ball, (C) music playlist on phone, (D) leaderboard with ranked players. **Correct answer:** Tap A, C, and D (all are ordered collections). **Why this matters:** Lists are everywhere in computing—playlists, contact lists, high scores, search results. Recognizing them prepares you for programming. _Implementation note: Multi-select concept recognition activity. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table




ID: T10.G2.08
Topic: T10 – Lists & Tables
Skill: Trace through a table lookup step by step
Description: **Student task:** Given a picture table and a lookup question, show the step-by-step process to find the answer. **Visual scenario:** Table shows 4 students (rows) with columns: Name, Pet, Favorite Color. Question: "What pet does Sam have?" Step 1: Find the Name column. Step 2: Go down to find "Sam" row. Step 3: Stay in that row, move to Pet column. Step 4: Read the answer: "Dog." Student taps cells in order to show the lookup path. **Correct answer:** Tap Name header → Sam cell → Pet cell in Sam's row → Say "Dog." **Why this matters:** Tracing step-by-step is how we debug and verify our work—an essential computational thinking skill. _Implementation note: Sequential tap activity showing lookup path with visual trail. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.01: Convert a written list into a structured table
* T10.G1.03: Locate specific values in a picture table




ID: T10.G2.09
Topic: T10 – Lists & Tables
Skill: Connect picture tables to real-world apps
Description: **Student task:** Match picture tables to real-world applications that use similar data organization. **Visual scenario:** Three mini-tables: (1) Name-Phone Number table, (2) Day-Subject-Time table, (3) Item-Price table. Three apps: Contacts app, Calendar app, Shopping app. **Correct answer:** Match Name-Phone to Contacts, Day-Subject-Time to Calendar, Item-Price to Shopping. **Why this matters:** The tables you see in apps like contacts and calendars work just like the picture tables you're learning—same rows and columns, just on a screen! _Implementation note: Drag-and-drop matching with real app screenshots. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.07: Recognize real-world examples of lists and tables
* T10.G2.01: Convert a written list into a structured table




ID: T10.G2.10
Topic: T10 – Lists & Tables
Skill: Predict and verify table changes after adding or removing rows
Description: **Student task:** Look at a table, then predict what it will look like after adding or removing a row. Verify your prediction. **Visual scenario:** Table has 3 students: (Sam, 10 points), (Lia, 8 points), (Max, 12 points). Instruction: "We add a new student: Tom with 7 points." Student draws/selects the new table with 4 rows. Then: "Sam leaves the class." Student shows the table now has 3 rows without Sam. **Correct answer:** After add: 4-row table with Tom at bottom. After remove: 3-row table without Sam, others shift up. **Why this matters:** Predicting changes before making them helps catch mistakes—this is how programmers think before they code! _Implementation note: Table prediction with before/after comparison. CSTA: E2-ALG-AF-01._

Dependencies:
* T10.G2.02: Append a new row to an existing table


---

## GRADE 3 (21 skills)




ID: T10.G3.01.01
Topic: T10 – Lists & Tables
Skill: Create a new list variable
Description: Students create a new list variable in the Variables palette by clicking "Make a List" and giving it a descriptive name (e.g., "fruits", "scores", "inventory"). Lists are containers that can hold multiple values, unlike regular variables which hold only one value. Students recognize that this is the first step before any list operations can be performed, and verify the empty list appears in the Variables palette.

Dependencies:
* T09.G3.01.01: Create a new variable




ID: T10.G3.01.02
Topic: T10 – Lists & Tables
Skill: Add an item to the end of a list
Description: Students use the `add [item] to [list]` block to add items one at a time to the end of a list. They observe how each item is added in sequence (1, 2, 3...) and note that lists grow dynamically as items are added. Students practice adding 3-4 items and use the list monitor to verify the growing list.

Dependencies:
* T10.G3.01.01: Create a new list variable




ID: T10.G3.01.03
Topic: T10 – Lists & Tables
Skill: Trace list index access step by step
Description: Before reading items from lists, students practice tracing through the relationship between list positions and items. Given a small list displayed on screen (e.g., ["apple", "banana", "cherry"]), students identify what item is at position 1, position 2, etc., understanding that CreatiCode lists start counting at 1 (not 0 like many programming languages). They predict what `item (2) of [fruits]` will return before running the code, then verify their prediction. This foundational tracing skill prevents common errors like expecting position 0 to work or confusing the item value with its position number. Students practice with 3-4 item lists using the list monitor for visual feedback.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.10: Display a list monitor on the stage




ID: T10.G3.02
Topic: T10 – Lists & Tables
Skill: Read items from a list by position (index starts at 1)
Description: Students use the `item (1) of [list]` block to retrieve specific items from a list by their position number (index). The first item is at position 1, second at position 2, etc. Students practice reading different positions and displaying or using the retrieved values, verifying the correct item is returned.

Dependencies:
* T10.G3.01.03: Trace list index access step by step




ID: T10.G3.03
Topic: T10 – Lists & Tables
Skill: Get the length of a list
Description: Students use the `length of [list]` block to find how many items are in a list. They observe that as items are added or removed, the length changes accordingly. This is essential for knowing the bounds when accessing list items and avoiding out-of-range errors.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list




ID: T10.G3.04.01
Topic: T10 – Lists & Tables
Skill: Delete an item at a specific position
Description: Students use the `delete (position) of [list]` block to remove an item from a specific position in the list. They observe how items after the deleted position shift down (e.g., item 3 becomes item 2) and verify that the list length decreases by 1. Students practice deleting items from different positions (beginning, middle, end) and predict the resulting list state.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T10.G3.03: Get the length of a list




ID: T10.G3.04.02
Topic: T10 – Lists & Tables
Skill: Clear all items from a list
Description: Students use the `delete all of [list]` block to remove every item from a list at once, returning it to empty. Clearing is useful for starting fresh or resetting for a new game. Students observe that after clearing, the list length becomes 0 and verify the list monitor shows an empty list.

Dependencies:
* T10.G3.04.01: Delete an item at a specific position
* T10.G3.03: Get the length of a list




ID: T10.G3.04.03
Topic: T10 – Lists & Tables
Skill: Predict list state after delete operations
Description: Students develop mental models of how lists change when items are deleted. Given a starting list shown in the monitor (e.g., [10, 20, 30, 40, 50]), they predict the resulting list after operations like "delete (2) of list" or "delete (4) of list". They draw or write out the expected result, paying special attention to how items shift positions: when item 2 is deleted, what was item 3 becomes the new item 2. Students verify predictions by running the code and comparing actual vs. expected results. This predictive skill builds debugging ability and prevents confusion about why items "moved" after deletion. Practice includes deleting from beginning (position 1), middle, and end positions.

Dependencies:
* T10.G3.04.01: Delete an item at a specific position
* T10.G3.11: Predict and trace list changes step by step




ID: T10.G3.05
Topic: T10 – Lists & Tables
Skill: Loop through each item in a list
Description: Students use the `for each [item] in [list]` block to automatically visit every item in sequence. Unlike counted repeat loops where you specify a number of repetitions, this block iterates through all items regardless of list length. Students perform simple actions on each item (e.g., say each fruit name) and observe that every item is processed exactly once. Keep the list short (3-4 items) and actions simple.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G3.06
Topic: T10 – Lists & Tables
Skill: Check if a list contains a specific item
Description: Students use the `[list] contains [item]?` block to check whether a value exists in a list. They combine this with conditionals to make decisions based on list membership (e.g., "if my fruits list contains 'apple' then say 'I have an apple!'"). Students test with items that are in the list and items that are not.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T08.G3.04: Use a simple if in a script




ID: T10.G3.07
Topic: T10 – Lists & Tables
Skill: Count items in a list that match a condition
Description: Students loop through a short list and count items that match a simple condition (e.g., "count numbers greater than 5" or "count items equal to 'apple'"). They use a counter variable that increments inside a conditional inside a loop. Students predict the count before running and verify their prediction matches the result.

Dependencies:
* T10.G3.05: Loop through each item in a list
* T08.G3.04: Use a simple if in a script
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G3.08
Topic: T10 – Lists & Tables
Skill: Check if a list is empty before accessing
Description: Students check whether a list is empty (has zero items) before trying to read from it, to avoid errors. They use the `length of [list] = 0` condition in an if-statement to guard list access. This defensive programming pattern prevents crashes when dealing with lists that might be empty.

Dependencies:
* T10.G3.03: Get the length of a list
* T08.G3.04: Use a simple if in a script




ID: T10.G3.08.01
Topic: T10 – Lists & Tables
Skill: Trace empty list edge cases
Description: Students learn to identify and handle the empty list scenario through tracing exercises. They trace through code that attempts to read from an empty list (length = 0) and predict what will happen: trying to access `item (1) of [emptyList]` causes an error because there is no position 1. Students practice checking "is the list empty?" BEFORE accessing items using the pattern: `if <(length of [list]) = (0)> then say "List is empty!" else say (item (1) of [list])`. They trace through programs with different starting conditions (empty list, 1-item list, multi-item list) to understand when guards are necessary. This defensive programming pattern prevents crashes and teaches edge-case thinking early.

Dependencies:
* T10.G3.08: Check if a list is empty before accessing
* T10.G3.11: Predict and trace list changes step by step




ID: T10.G3.09
Topic: T10 – Lists & Tables
Skill: Increment or decrement a list item's value
Description: Students use the `change item (position) of [list] by (amount)` block to modify numeric values in a list arithmetically (e.g., increase a player's score by 10, decrease health by 5). This block changes the value in place without needing to manually get-calculate-replace, making score updates and counters much simpler. For young learners who don't know negative numbers, the `reduce item (position) of [list] by (amount)` block provides a simpler way to decrease values. Students verify the change by reading the item before and after modification.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G3.10
Topic: T10 – Lists & Tables
Skill: Display a list monitor on the stage
Description: Students enable the list monitor by checking the checkbox next to the list name in the Variables palette. The monitor displays all items with their positions (1, 2, 3...) and updates in real-time as items are added, removed, or changed. Students use visual feedback to verify list state and debug their programs by watching the monitor while running code.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list




ID: T10.G3.11
Topic: T10 – Lists & Tables
Skill: Predict and trace list changes step by step
Description: Students trace through a short sequence of list operations (3-5 blocks) and predict the final state of the list. Given blocks like: create list → add "apple" → add "banana" → delete item 1 → add "cherry", students write down what the list contains after each step and predict the final result ["banana", "cherry"]. This builds mental models of how lists work and prepares students for debugging. Students verify predictions by running the code and comparing actual vs expected results.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.04.01: Delete an item at a specific position
* T10.G3.10: Display a list monitor on the stage




ID: T10.G3.12
Topic: T10 – Lists & Tables
Skill: Debug a list program by identifying wrong positions
Description: Students identify and fix bugs in list programs where items are accessed, inserted, or deleted at wrong positions. Given a buggy program that should add items to a shopping cart but produces incorrect results, students use step-by-step execution and list monitors to find where positions are off-by-one or incorrect. They practice common debugging patterns: verifying list contents after each operation, checking that indices are within bounds (1 to length), and understanding how deletions shift subsequent items.

Dependencies:
* T10.G3.11: Predict and trace list changes step by step
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G3.13
Topic: T10 – Lists & Tables
Skill: Use a list to store user inputs
Description: Students create interactive programs that collect multiple inputs from users and store them in a list. They use the `ask and wait` block inside a loop to gather several responses (e.g., "Enter 3 favorite foods"), adding each answer to a list. After collection, they display or process the collected data, such as saying all items back to the user. This introduces the practical pattern of building lists dynamically from user interaction rather than hardcoding values.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T07.G3.01: Use a counted repeat loop




ID: T10.G3.13.01
Topic: T10 – Lists & Tables
Skill: Validate user input before adding to list
Description: Students learn to check user inputs before adding them to a list, preventing invalid or unwanted data from being stored. They use simple conditionals to validate inputs: check if answer is not empty, check if answer is a number (when expecting numbers), or check if answer matches expected values (e.g., "yes" or "no"). For example, when collecting ages, students verify the input is greater than 0 and less than 150 before adding to the ages list. If validation fails, they ask the user to try again or skip that entry. This introduces data quality concepts early and prevents "garbage in, garbage out" problems. Students verify their validation works by intentionally entering invalid data and confirming it's rejected.

Dependencies:
* T10.G3.13: Use a list to store user inputs
* T08.G3.04: Use a simple if in a script




ID: T10.G3.14
Topic: T10 – Lists & Tables
Skill: Explain to a partner why a list is useful for a problem
Description: Students explain their choice to use a list rather than separate variables. Given a scenario (e.g., "store 5 quiz scores"), they articulate to a partner or record: "I used a list because I have MANY similar items, and with a list I can add more items easily, loop through all items, and keep them organized together. If I used 5 separate variables, I couldn't easily add a 6th score or loop through them." Students practice explaining trade-offs: lists are better for collections of similar items, but single variables are fine for one or two distinct values. This communication skill is essential for collaborative programming and code reviews.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.05: Loop through each item in a list




ID: T10.G3.15
Topic: T10 – Lists & Tables
Skill: Choose list or variables for a simple data storage problem
Description: Students analyze a data storage scenario and decide whether to use a list or separate variables. Scenarios include: (A) "Store a player's name, score, and level" → 3 separate variables (different types of data), (B) "Store the names of 10 students" → list (many similar items), (C) "Store whether sound is on or off" → single variable (just one value). Students justify their choice and recognize patterns: lists are for "many of the same kind," variables are for "few different things." This decision-making skill prepares students for designing more complex data solutions.

Dependencies:
* T10.G3.01.01: Create a new list variable
* T09.G3.01.01: Create a new variable


---

## GRADE 4 (38 skills)




ID: T10.G4.00.01
Topic: T10 – Lists & Tables
Skill: Trace the off-by-one error pattern
Description: Students learn to recognize and debug one of the most common list errors: off-by-one mistakes. They trace through code that has typical off-by-one errors, such as looping from 0 instead of 1 (causing an error since lists start at 1), looping to length+1 (trying to access a position that doesn't exist), or deleting from position 0 (invalid). Students identify the error symptoms (program crashes, wrong item accessed, unexpected behavior), locate the incorrect boundary in the code (start/end of loop or position access), and correct it. They practice with examples like `repeat (length of [list])` with counter starting at 0 vs. 1, and `item ((length of [list]) + (1)) of [list]` which accesses beyond the list. This debugging pattern skill builds awareness of list boundaries and index arithmetic.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T10.G3.03: Get the length of a list
* T10.G3.12: Debug a list program by identifying wrong positions




ID: T10.G4.01.01
Topic: T10 – Lists & Tables
Skill: Find an item's position using built-in block
Description: Students use the `item # of [value] in [list]` block to find the position of a value in a list. They understand this returns the index of the first occurrence (or 0 if not found) and practice searching for items in different lists.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G4.01.02
Topic: T10 – Lists & Tables
Skill: Implement manual linear search with loop
Description: Students implement a simple linear search algorithm by looping through a list, comparing each item to a target value, and reporting the position when found (or "not found" if the loop completes). They use a counter variable for the position and a conditional to check each item. This foundational algorithm skill teaches sequential searching and how the built-in block works internally.

Dependencies:
* T10.G3.05: Loop through each item in a list
* T08.G3.04: Use a simple if in a script
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G4.02
Topic: T10 – Lists & Tables
Skill: Store and retrieve parallel list data
Description: Students use two lists in parallel (e.g., "playerNames" and "playerScores") where items at the same index are related. They add items to both lists together and use the same index to retrieve matching data (e.g., "the player at index 2 in names has the score at index 2 in scores"). Students recognize that keeping parallel lists synchronized is critical—adding to one requires adding to the other at the same position.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G4.03
Topic: T10 – Lists & Tables
Skill: Insert an item at a specific position in a list
Description: Students use the `insert [item] at (position) of [list]` block to add items at the beginning, middle, or end of a list. They observe how existing items shift to higher indices to make room and verify the new item appears at the correct position. Students practice inserting at position 1 (prepend), at length+1 (append), and at middle positions.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T10.G3.03: Get the length of a list




ID: T10.G4.04
Topic: T10 – Lists & Tables
Skill: Replace an item in a list
Description: Students use the `replace item (position) of [list] with [value]` block to update an existing item without changing the list length. They practice replacing items based on position and recognize the difference between replacing (overwrites in place, same length) and inserting (shifts existing items, length increases).

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G4.05
Topic: T10 – Lists & Tables
Skill: Use built-in blocks to sort a list
Description: Students use CreatiCode's `sort list [list] from [large to small/small to large]` block to sort numeric or alphabetic lists. They observe how the order changes and note that sorting rearranges items by value. Students verify the sort by reading the first and last items to confirm the order direction.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list




ID: T10.G4.06.01
Topic: T10 – Lists & Tables
Skill: Find the smallest value in a list
Description: Students use the `[smallest v] of list [list]` block to find the minimum value in a numeric list. This block scans all items and returns the lowest value. Students practice with different lists and predict which value will be returned before running the code.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.03: Get the length of a list




ID: T10.G4.06.02
Topic: T10 – Lists & Tables
Skill: Find the largest value in a list
Description: Students use the `[largest v] of list [list]` block to find the maximum value in a numeric list. This block scans all items and returns the highest value. Students compare this to finding smallest and recognize when to use min vs max operations.

Dependencies:
* T10.G4.06.01: Find the smallest value in a list




ID: T10.G4.06.03
Topic: T10 – Lists & Tables
Skill: Calculate the sum of all values in a list
Description: Students use the `[sum v] of list [list]` block to add up all numeric values in a list. This is useful for computing totals (total points, total money). Students verify results by manual addition with small lists to build confidence in the block's behavior.

Dependencies:
* T10.G4.06.01: Find the smallest value in a list




ID: T10.G4.06.04
Topic: T10 – Lists & Tables
Skill: Calculate the average of values in a list
Description: Students use the `[average v] of list [list]` block to find the mean of all numeric values. Average represents a typical/central value and equals sum divided by length. Students apply this to practical scenarios like grade averages, temperature averages, and game score averages.

Dependencies:
* T10.G3.03: Get the length of a list
* T10.G4.06.03: Calculate the sum of all values in a list




ID: T10.G4.06.05
Topic: T10 – Lists & Tables
Skill: Find the median value in a list
Description: Students use the `[median v] of list [list]` block to find the middle value when sorted. Median differs from average because it is less affected by outliers. Students identify scenarios where median is more useful than average (income data, test scores with extreme values) by comparing both measures on lists with outliers.

Dependencies:
* T10.G4.05: Use built-in blocks to sort a list
* T10.G4.06.04: Calculate the average of values in a list




ID: T10.G4.07
Topic: T10 – Lists & Tables
Skill: Find the maximum or minimum item in a list manually
Description: Students write a loop to find the largest or smallest item in a numeric list without using built-in blocks. They initialize a "best so far" variable with the first item, loop through remaining items comparing each to the current best, and update the best when a better value is found. Students trace through a 5-item list and track how the "best so far" variable changes. This manual algorithm builds algorithmic thinking for aggregation operations.

Dependencies:
* T10.G3.05: Loop through each item in a list
* T08.G3.04: Use a simple if in a script
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G4.08
Topic: T10 – Lists & Tables
Skill: Filter items from a list based on a condition
Description: Students loop through a list and build a new filtered list containing only items that satisfy a condition (e.g., "keep only scores > 50"). They create an empty result list, use conditionals inside a loop to check each item, and add matching items to the result list. Students verify the filtered list contains exactly the items that match the condition.

Dependencies:
* T10.G3.05: Loop through each item in a list
* T08.G3.04: Use a simple if in a script
* T10.G3.01.02: Add an item to the end of a list




ID: T10.G4.08.01
Topic: T10 – Lists & Tables
Skill: Trace filter algorithm step by step before implementing
Description: Before writing filter code, students practice tracing through the filter algorithm with a paper-and-pencil exercise. Given a source list [5, 12, 8, 15, 3, 20] and a condition "keep only numbers > 10", they manually step through the process: start with empty result list, examine each item, ask "does it match the condition?", if yes add to result, if no skip it, continue to next item. Students track both the source list position and the growing result list at each step. This explicit tracing builds algorithmic thinking and reveals the pattern: initialize empty result → loop through source → conditional check → add to result if match. After tracing on paper, students implement the algorithm in code with confidence, understanding each block's purpose. This tracing-first approach reduces cognitive load and prevents common mistakes like filtering in-place or forgetting the conditional.

Dependencies:
* T10.G3.07: Count items in a list that match a condition
* T10.G3.11: Predict and trace list changes step by step




ID: T10.G4.09
Topic: T10 – Lists & Tables
Skill: Build a high score list with parallel lists
Description: Students create a leaderboard using two parallel lists (names and scores). When a new score is added, they find the correct position to insert it (to keep scores sorted in descending order) and insert both the name and score at matching positions. Students verify that the leaderboard remains sorted after each insertion.

Dependencies:
* T10.G4.01.02: Implement manual linear search with loop
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.03: Insert an item at a specific position in a list
* T10.G4.05: Use built-in blocks to sort a list




ID: T10.G4.10
Topic: T10 – Lists & Tables
Skill: Swap two items in a list
Description: Students swap the positions of two items in a list using a temporary variable. They store one item in the temp variable, replace it with the other item, then put the temp value in the second position. Students trace through the three-step swap process and verify both items exchange positions correctly. This pattern is a building block for sorting algorithms.

Dependencies:
* T10.G4.04: Replace an item in a list
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G4.11.01
Topic: T10 – Lists & Tables
Skill: Copy one list to another (replacing contents)
Description: Students use the `copy [list1] to [list2]` block to duplicate a list. This REPLACES all items in list2 with items from list1, so list2's original contents are lost. After copying, both lists have identical items but remain separate (changing one doesn't affect the other). Students verify independence by modifying one list and confirming the other remains unchanged.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.05: Loop through each item in a list




ID: T10.G4.11.02
Topic: T10 – Lists & Tables
Skill: Append one list to another (adding to end)
Description: Students use the `append [list1] to [list2]` block to add all items from list1 to the END of list2. This PRESERVES list2's original items and adds list1's items below them. Students compare append vs. copy and identify when each is appropriate: copy for backup/duplication, append for combining datasets.

Dependencies:
* T10.G4.11.01: Copy one list to another (replacing contents)




ID: T10.G4.12
Topic: T10 – Lists & Tables
Skill: Split a text string into a list
Description: Students use the `set [list] to split of [text] with splitter [delimiter]` block to convert text into a list of items (e.g., split "apple,banana,orange" by "," to get a list of three fruits). Students experiment with different delimiters (comma, space, newline) and verify the resulting list contains the expected items. This introduces text processing and list creation from external data.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T09.G4.01: Use addition (+) in variable expressions




ID: T10.G4.13
Topic: T10 – Lists & Tables
Skill: Join list items into a text string
Description: Students use the `join [list] into text with [delimiter]` block to combine list items into a single text string (e.g., join ["red", "green", "blue"] with ", " to get "red, green, blue"). This is the inverse of split and is useful for displaying list contents or saving list data as text.

Dependencies:
* T10.G4.12: Split a text string into a list
* T09.G4.01: Use addition (+) in variable expressions




ID: T10.G4.14
Topic: T10 – Lists & Tables
Skill: Reverse the order of items in a list
Description: Students use the `reverse [list]` block to flip item order (first becomes last, last becomes first). They observe the list monitor to see position changes. Reversing is useful for converting ascending to descending order, reversing time sequences, or inverting rankings.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.02: Read items from a list by position (index starts at 1)




ID: T10.G4.15
Topic: T10 – Lists & Tables
Skill: Randomly shuffle items in a list
Description: Students use the `reshuffle [list] randomly` block to randomly rearrange all items. Each shuffle produces a different random order. Applications include shuffling cards, randomizing quiz questions, or creating random starting positions. Students note that reshuffling destroys the original order (make a copy first if needed).

Dependencies:
* T10.G3.01.02: Add an item to the end of a list




ID: T10.G4.16.01
Topic: T10 – Lists & Tables
Skill: Generate a list of random numbers with options
Description: Students use the `set [list] to (N) random whole numbers between (min) and (max) [no repetition/allow repetition]` block to populate a list with random values. They select whether to allow duplicate numbers and apply this for generating test data, simulating dice rolls, or creating random scores.

Dependencies:
* T10.G3.01.02: Add an item to the end of a list
* T10.G3.03: Get the length of a list




ID: T10.G4.16.02
Topic: T10 – Lists & Tables
Skill: Generate seeded random list
Description: Students use the seeded random block `set [list] to (N) random numbers with seed (SEED)` which generates the same sequence when using the same seed. This enables reproducible randomness for games (same level layout with same seed) and testing scenarios requiring consistent random data. Students verify that the same seed always produces the same list.

Dependencies:
* T10.G4.16.01: Generate a list of random numbers with options




ID: T10.G4.17
Topic: T10 – Lists & Tables
Skill: Delete an item from a list by value
Description: Students use the `delete value [item] from [list]` block to remove the first occurrence of a specific value (e.g., delete "apple" from the fruits list). This finds and removes the item without needing to know its position, which differs from deleting by index. Students test with items that exist (removes first match) and items that don't exist (no change).

Dependencies:
* T10.G3.04.01: Delete an item at a specific position
* T10.G3.06: Check if a list contains a specific item




ID: T10.G4.18
Topic: T10 – Lists & Tables
Skill: Loop through list indices
Description: Students use the `for each index [i] in [list]` block to iterate through list positions (1, 2, 3...) instead of values. This is necessary when they need to know both the position and the value, or when they need to modify items while looping. Students compare index-based iteration to value-based iteration and identify use cases for each.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T10.G3.05: Loop through each item in a list




ID: T10.G4.19
Topic: T10 – Lists & Tables
Skill: Find an item containing a substring
Description: Students use the `# of item containing [substring] in [list]` block to find the first list item that includes a partial match (e.g., find first name containing "son" in a names list). Students compare exact matching (T10.G4.01.01) to partial matching and identify when each is appropriate.

Dependencies:
* T10.G4.01.01: Find an item's position using built-in block
* T09.G4.01: Use addition (+) in variable expressions




ID: T10.G4.20
Topic: T10 – Lists & Tables
Skill: Select multiple items from a list by criteria
Description: Students use the `insert (N) [largest/smallest/random] items from [list1] into [list2]` block to extract top/bottom/random items efficiently. Applications include leaderboards (top 10 scores), random sampling (pick 5 random quiz questions), or filtering extremes (3 coldest days). Students verify results by checking that list2 contains exactly N items matching the specified criteria.

Dependencies:
* T10.G4.05: Use built-in blocks to sort a list
* T10.G4.06.01: Find the smallest value in a list
* T10.G4.11.02: Append one list to another (adding to end)




ID: T10.G4.21
Topic: T10 – Lists & Tables
Skill: Extract a sublist from a range of positions
Description: Students create a new list containing items from a specific range within an existing list. Using a loop from start position to end position, they read each item from the source list and add it to a new result list. For example, to extract items 3-5 from a 10-item list, they loop from 3 to 5, reading and adding each item. This pattern is useful for pagination (show items 11-20), processing chunks of data, or splitting a list into smaller pieces.

Dependencies:
* T10.G3.02: Read items from a list by position (index starts at 1)
* T10.G3.01.02: Add an item to the end of a list
* T07.G3.01: Use a counted repeat loop




ID: T10.G4.22
Topic: T10 – Lists & Tables
Skill: Transform each item in a list using a loop
Description: Students iterate through a list and apply a transformation to each item (e.g., double all numbers, convert all text to uppercase, add a prefix to each name). They use a loop with index access to read each item, transform it, and replace it in the same position. This pattern introduces the map operation concept where every element is processed uniformly. Students trace through a 4-item list showing the before and after state.

Dependencies:
* T10.G4.18: Loop through list indices
* T10.G4.04: Replace an item in a list




ID: T10.G4.23
Topic: T10 – Lists & Tables
Skill: Reduce a list to a single value using accumulation
Description: Students implement the accumulator pattern to reduce a list to a single result: start with an initial value (0 for sum, 1 for product, empty string for concatenation), loop through all items, and combine each item with the accumulator. Beyond sum (already covered), students apply this pattern to compute products of all numbers, concatenate all strings, or find the longest string. This introduces the reduce/fold concept foundational to functional programming.

Dependencies:
* T10.G3.05: Loop through each item in a list
* T10.G4.06.03: Calculate the sum of all values in a list




ID: T10.G4.24
Topic: T10 – Lists & Tables
Skill: Predict list state after a sequence of operations
Description: Students read a sequence of 5-7 list operations (add, delete, insert, replace) and predict the final list contents without running the code. They trace through each operation step by step, writing the list state after each step, then verify their prediction by running the code. This skill emphasizes understanding how each operation modifies the list and develops mental execution abilities critical for debugging and algorithm design.

Dependencies:
* T10.G3.11: Predict and trace list changes step by step
* T10.G4.03: Insert an item at a specific position in a list
* T10.G4.04: Replace an item in a list




ID: T10.G4.24.01
Topic: T10 – Lists & Tables
Skill: Predict parallel list synchronization issues
Description: Students learn to identify and prevent synchronization errors in parallel lists through prediction and tracing exercises. Given two parallel lists (e.g., names and scores), they examine code that adds to one list but not the other, or deletes from one list but not the other, and predict what problems will occur: mismatched data (wrong score paired with wrong name), mismatched lengths (lists become different sizes), or index errors (trying to access position that exists in one list but not the other). Students trace through problematic code step-by-step, tracking the length and contents of both lists to see when they fall out of sync. They then fix the code by ensuring all operations (add, delete, replace) happen to both lists at the same position. This critical skill prevents data corruption in parallel list patterns.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G3.11: Predict and trace list changes step by step
* T10.G3.12: Debug a list program by identifying wrong positions




ID: T10.G4.25
Topic: T10 – Lists & Tables
Skill: Debug parallel list synchronization errors
Description: Students identify and fix bugs where parallel lists become out of sync—a common error when working with related data in separate lists. Given buggy code where names and scores lists don't match up correctly (e.g., inserting into one list but not the other, or deleting at different positions), students trace through to find where synchronization breaks and fix the code. They develop the rule: "When modifying parallel lists, ALWAYS modify both at the same position." Students practice debugging scenarios: (1) adding to only one list, (2) deleting from wrong positions, (3) inserting at mismatched indices.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.03: Insert an item at a specific position in a list
* T10.G3.12: Debug a list program by identifying wrong positions




ID: T10.G4.26
Topic: T10 – Lists & Tables
Skill: Design a list structure for a game inventory system
Description: Students design and implement a simple inventory system using lists. They identify what data needs to be stored (item names, quantities, maybe categories), decide between one list vs. parallel lists vs. list of formatted strings, and implement add/remove/display operations. Example: A simple game where the player collects items. Students design: items list ["sword", "shield", "potion"], quantities list [1, 1, 3]. They implement: add item (check if exists, increment or add new), remove item (decrement or remove if zero), display inventory (loop through and show). This project-based skill applies list concepts to a real game scenario.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.01.01: Find an item's position using built-in block
* T10.G3.09: Increment or decrement a list item's value




ID: T10.G4.27
Topic: T10 – Lists & Tables
Skill: Compare two lists for equality
Description: Students write code to check if two lists contain the same items in the same order. They first check if lengths match, then loop through comparing each position. If any position differs, the lists are not equal. Students trace through comparisons and understand this is different from checking if lists have the same items in ANY order (which would require sorting or more complex checking). Applications include: verifying a copy was made correctly, checking if a shuffle changed anything, or validating user input matches expected sequence.

Dependencies:
* T10.G4.18: Loop through list indices
* T10.G3.03: Get the length of a list
* T08.G3.04: Use a simple if in a script




ID: T10.G4.28
Topic: T10 – Lists & Tables
Skill: Design data structure for a simple scenario (list vs multiple variables)
Description: Students analyze a given scenario and make a justified decision about data structure choice: should they use a list, multiple separate variables, or parallel lists? For example, storing 3 high scores could be done with variables (score1, score2, score3) or a list [scores]; tracking player name, level, and lives could use 3 separate variables or parallel lists if there are multiple players. Students consider factors: How many items? Will the number change? Do items need to be processed together (loop)? Are items all the same type? They sketch their design choice, explain the tradeoffs (variables are simpler for fixed small amounts; lists are flexible for variable amounts), and implement their design. This design thinking skill bridges concrete list operations to abstract data structure decision-making.

Dependencies:
* T10.G3.15: Choose list or variables for a simple data storage problem
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.01.02: Implement manual linear search with loop


---

## GRADE 5 (32 skills)




ID: T10.G5.00.01
Topic: T10 – Lists & Tables
Skill: Compare lists vs tables conceptually (bridge skill)
Description: Students explore the conceptual difference between lists (one-dimensional, single sequence of values) and tables (two-dimensional, rows and columns) through comparison activities. They examine scenarios: a shopping list (1D: just item names) vs. a shopping cart (2D: item name, price, quantity). Students recognize that tables organize related attributes (columns) for each entity (row), while lists store a single sequence. They identify when to "graduate" from lists to tables: when each item needs multiple properties tracked together, when relationships between attributes matter, or when data needs to be searched/filtered by different criteria. This conceptual bridge skill prepares students for the structural shift from list thinking (position-based access) to table thinking (row-column coordinate system), reducing confusion when first encountering tables.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G3.14: Explain to a partner why a list is useful for a problem




ID: T10.G5.01
Topic: T10 – Lists & Tables
Skill: Identify table structure (rows, columns, cells)
Description: Students identify and label the parts of a table: rows (horizontal, numbered), columns (vertical, named), and cells (values at row-column intersections). Given a sample table, they state the number of rows and columns, identify the value at a specific row-column intersection, and explain that each row represents one record while each column represents one attribute. Students recognize that a table is like having multiple parallel lists (one list per column) organized together, where all lists have the same length and items at the same position are related. A table makes it easier to manage related data than using many separate parallel lists.

Dependencies:
* T10.G5.00.01: Compare lists vs tables conceptually (bridge skill)




ID: T10.G5.02
Topic: T10 – Lists & Tables
Skill: Create a table and add columns
Description: Students create an empty table variable and use `add column [name] at position (n) to table [table]` to define the table structure. Columns must be created before data can be added to them, and the position parameter controls column order (1 = first column, 2 = second, etc.). Students verify the table structure by examining the table monitor.

Dependencies:
* T10.G5.01: Identify table structure (rows, columns, cells)




ID: T10.G5.03
Topic: T10 – Lists & Tables
Skill: Add rows of data to a table
Description: Students use the `add to table [table]: [value1] [value2] ...` block to add rows of data. They ensure the number of values matches the number of columns and understand that rows are numbered starting from 1.

Dependencies:
* T10.G5.02: Create a table and add columns




ID: T10.G5.04
Topic: T10 – Lists & Tables
Skill: Read a cell value from a table
Description: Students use the `item at row (n) column [name] of table [table]` block to retrieve a specific value. They practice reading different cells and using the values in their programs.

Dependencies:
* T10.G5.03: Add rows of data to a table




ID: T10.G5.05
Topic: T10 – Lists & Tables
Skill: Update a cell value in a table
Description: Students use the `replace item at row (n) column [name] of table [table] with [value]` block to modify existing data. They update cells based on position and understand this changes the table in place.

Dependencies:
* T10.G5.04: Read a cell value from a table




ID: T10.G5.06.01
Topic: T10 – Lists & Tables
Skill: Get the number of rows in a table
Description: Students use the `row count of table [table]` block to find how many rows exist in a table. They understand this is essential for loops (iterate from 1 to row count), checking if table is empty (row count = 0), and reporting table size.

Dependencies:
* T10.G5.04: Read a cell value from a table




ID: T10.G5.06.02
Topic: T10 – Lists & Tables
Skill: Find which row contains a value
Description: Students use the `row # of [value] in column [name] in table [table]` block to search for the first row where a specific column equals a value. They understand this returns the row number (index) or 0 if not found, enabling them to locate data for reading or updating.

Dependencies:
* T10.G5.06.01: Get the number of rows in a table
* T10.G4.01.01: Find an item's position using built-in block




ID: T10.G5.07
Topic: T10 – Lists & Tables
Skill: Loop through table rows to compute aggregates
Description: Students use a counted loop from 1 to `row count of table` to iterate through all rows. They access values in a specific column and compute totals (sum), counts, or find maximum/minimum values using a variable accumulator.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T10.G5.06.01: Get the number of rows in a table
* T10.G5.04: Read a cell value from a table
* T09.G3.01.02: Increment and decrement a variable




ID: T10.G5.08
Topic: T10 – Lists & Tables
Skill: Use built-in table aggregate blocks
Description: Students use CreatiCode's `[sum/average/smallest/largest/median] of column [name] in table [table]` blocks to compute statistics on a column without writing a loop. They compare this to manual aggregation using loops from the previous skill.

Dependencies:
* T10.G5.07: Loop through table rows to compute aggregates
* T10.G4.06.01: Find the smallest value in a list




ID: T10.G5.09.01
Topic: T10 – Lists & Tables
Skill: Delete a single row by index
Description: Students use the `delete row (n) of table [table]` block to remove a specific row by its position number. They observe how remaining rows shift up (row 4 becomes row 3) and understand the row count decreases by 1.

Dependencies:
* T10.G5.06.01: Get the number of rows in a table




ID: T10.G5.09.02
Topic: T10 – Lists & Tables
Skill: Delete rows matching a condition
Description: Students use the `delete rows with column [name] of value [v] from table [table]` block to remove ALL rows where a specific column equals a value. They understand this can delete multiple rows at once (e.g., delete all students in grade 8) and is more efficient than looping to delete one by one.

Dependencies:
* T10.G5.09.01: Delete a single row by index
* T10.G5.06.02: Find which row contains a value




ID: T10.G5.09.03
Topic: T10 – Lists & Tables
Skill: Clear all rows from a table
Description: Students use the `delete all rows from table [table]` block to remove all data while preserving the column structure. They understand this is useful for resetting a table for new data without recreating columns, and compare this to deleting entire table vs. just clearing data.

Dependencies:
* T10.G5.09.01: Delete a single row by index




ID: T10.G5.10
Topic: T10 – Lists & Tables
Skill: Convert between lists and tables
Description: Students convert a list into a single-column table using available table operations and extract a column from a table into a list by looping through rows (or using a dedicated block if available). They understand when each data structure is more appropriate.

Dependencies:
* T10.G5.03: Add rows of data to a table
* T10.G3.01.02: Add an item to the end of a list
* T07.G3.01: Use a counted repeat loop




ID: T10.G5.11.01
Topic: T10 – Lists & Tables
Skill: Add a column at a specific position
Description: Students use the `add column [name] at position (n) to table [table]` block to insert a new column at a specific position (1 = first column, 2 = second, etc.). They understand existing columns shift right to make room, and the new column starts empty. They practice adding columns at beginning, middle, and end.

Dependencies:
* T10.G5.02: Create a table and add columns




ID: T10.G5.11.02
Topic: T10 – Lists & Tables
Skill: Delete a single column
Description: Students use the `delete column [name] from table [table]` block to permanently remove a column and ALL its data. They understand this cannot be undone, remaining columns shift left, and the table structure changes. They identify when column deletion is appropriate vs. just clearing cell values.

Dependencies:
* T10.G5.11.01: Add a column at a specific position
* T10.G5.03: Add rows of data to a table




ID: T10.G5.11.03
Topic: T10 – Lists & Tables
Skill: Remove all columns from a table
Description: Students use the `delete all columns from table [table]` block to completely reset a table to empty structure (no columns, no rows). They understand this is more destructive than deleting all rows (which keeps columns) and use this when completely restructuring a table.

Dependencies:
* T10.G5.11.02: Delete a single column




ID: T10.G5.12
Topic: T10 – Lists & Tables
Skill: Copy list data to table column
Description: Students use the `copy list [list] to column [name] of table [table]` block to populate or replace an entire column with list values. They understand this requires the column to already exist and will overwrite existing data in that column.

Dependencies:
* T10.G5.02: Create a table and add columns
* T10.G3.01.02: Add an item to the end of a list
* T10.G5.10: Convert between lists and tables




ID: T10.G5.13
Topic: T10 – Lists & Tables
Skill: Insert a row at a specific position
Description: Students use `insert at row (n) of table [table]: [cell1] [cell2] ...` to add a row at a specific position, shifting existing rows down. They understand the difference between appending (always adds at end) and inserting (can add anywhere).

Dependencies:
* T10.G5.03: Add rows of data to a table
* T10.G4.03: Insert an item at a specific position in a list




ID: T10.G5.14
Topic: T10 – Lists & Tables
Skill: Replace an entire row in a table
Description: Students use `replace row (n) of table [table] with: [cell1] [cell2] ...` to overwrite all values in a row at once. They compare this to updating individual cells (T10.G5.05) and understand when replacing entire rows is more efficient.

Dependencies:
* T10.G5.05: Update a cell value in a table
* T10.G5.03: Add rows of data to a table




ID: T10.G5.15
Topic: T10 – Lists & Tables
Skill: Get an entire row as a text string
Description: Students use `row (n) of table [table] separator [sep]` to extract all values from a row as a single text string with specified separator. They use this to display row data, save row snapshots, or pass row data to other parts of the program. They understand this returns text (e.g., "apple,banana,orange"), not a list data structure.

Dependencies:
* T10.G5.04: Read a cell value from a table
* T10.G5.10: Convert between lists and tables
* T10.G4.12: Split a text string into a list




ID: T10.G5.16
Topic: T10 – Lists & Tables
Skill: Find a row by partial match
Description: Students use `row # of item containing [substring] in column [name] in table [table]` to find the first row where a column value includes a substring (e.g., find student with "son" in last name). They compare exact vs partial matching.

Dependencies:
* T10.G5.06.02: Find which row contains a value
* T10.G4.19: Find an item containing a substring




ID: T10.G5.17
Topic: T10 – Lists & Tables
Skill: Increment or decrement a table cell value
Description: Students use `change item at row (n) column [name] of table [table] by (amount)` to modify numeric cell values arithmetically (e.g., increase a player's score by 10, decrease inventory by 3). For young learners, the `reduce item at row (n) column [name] of table [table] by (amount)` block provides a simpler way to decrease values without negative numbers. Students compare this to replacement (T10.G5.05) and recognize when arithmetic modification is more efficient than get-calculate-replace patterns.

Dependencies:
* T10.G5.05: Update a cell value in a table
* T10.G5.04: Read a cell value from a table
* T10.G3.09: Increment or decrement a list item's value




ID: T10.G5.18
Topic: T10 – Lists & Tables
Skill: Show and hide table monitors
Description: Students use `show table [table]` and `hide table [table]` blocks to display or hide the table monitor on the stage. Applications include debugging programs by observing table state, showing results to users, or hiding implementation details during gameplay.

Dependencies:
* T10.G5.02: Create a table and add columns
* T09.G3.01.04: Display variable value on stage using the variable monitor




ID: T10.G5.19
Topic: T10 – Lists & Tables
Skill: Build a filtered table manually using conditionals
Description: Students create a new table containing only rows that match a specific condition by looping through the source table and using if-statements. For each row, they check if a column value meets a criterion (e.g., score > 80), and if so, add that row to a result table. This manual filtering approach builds the algorithmic thinking needed before using advanced built-in filter operations in Grade 6. Students trace through 5-7 sample rows and verify their filtered result contains exactly the matching rows.

Dependencies:
* T10.G5.19.01: Trace filter algorithm for tables step by step
* T10.G5.06.01: Get the number of rows in a table
* T10.G5.04: Read a cell value from a table
* T10.G5.03: Add rows of data to a table




ID: T10.G5.19.01
Topic: T10 – Lists & Tables
Skill: Trace filter algorithm for tables step by step
Description: Students extend their list filtering skills to tables by tracing the table filter algorithm on paper before coding. Given a source table with 4-5 rows and a condition (e.g., "keep only students with score > 75"), they manually step through: create empty result table with same columns, loop through each row number (1 to row count), read the relevant column value for that row, check if it meets the condition, if yes copy/add that entire row to result table, if no skip to next row. Students track which rows are being examined and which are added to the result, understanding that filtering preserves row integrity (all columns stay together). This tracing-first approach helps students visualize the algorithm flow before managing the more complex syntax of table operations, preventing errors like filtering only one column or losing row data.

Dependencies:
* T10.G4.08: Filter items from a list based on a condition
* T10.G4.08.01: Trace filter algorithm step by step before implementing
* T10.G5.07: Loop through table rows to compute aggregates




ID: T10.G5.20
Topic: T10 – Lists & Tables
Skill: Debug table programs by tracing row and column access
Description: Students identify and fix bugs in table programs where cells are accessed at wrong row-column combinations, rows are skipped in loops, or data is written to incorrect positions. Given a buggy program that should update a student gradebook but produces incorrect results, students use step-by-step execution and table monitors to trace which cells are being read or written. They practice common debugging patterns: logging row/column indices during loops, verifying cell values match expectations, and checking loop bounds against row count.

Dependencies:
* T10.G5.04: Read a cell value from a table
* T10.G5.07: Loop through table rows to compute aggregates
* T10.G3.12: Debug a list program by identifying wrong positions




ID: T10.G5.21
Topic: T10 – Lists & Tables
Skill: Compare values across two columns in the same row
Description: Students write programs that compare values in different columns of the same row to make decisions or compute derived values. Examples: compare "budget" and "spent" columns to find rows that are over budget, compare "expected" and "actual" columns to calculate differences, or compare "score1" and "score2" columns to determine which is higher. Students loop through rows, read both column values, apply comparison logic, and either flag rows, update a third column, or count matches.

Dependencies:
* T10.G5.04: Read a cell value from a table
* T10.G5.07: Loop through table rows to compute aggregates
* T08.G4.03: Combine two conditions with AND




ID: T10.G5.22
Topic: T10 – Lists & Tables
Skill: Compare tables vs parallel lists and justify choice
Description: Students analyze scenarios and decide whether parallel lists or a table is the better data structure, then justify their choice. Comparison factors: (1) Tables keep related data visibly together, making it harder to accidentally desynchronize; (2) Tables have built-in lookup and aggregate operations; (3) Parallel lists may be simpler for very basic needs. Given scenarios like "track 3 properties for 20 students," students explain: "A table is better because all student data stays in one row—I can't accidentally add a name without adding a score. Plus I can sort the whole table by any column." Students practice articulating trade-offs to a partner or in writing.

Dependencies:
* T10.G5.01: Identify table structure (rows, columns, cells)
* T10.G4.02: Store and retrieve parallel list data




ID: T10.G5.23
Topic: T10 – Lists & Tables
Skill: Model a real-world scenario with table schema design
Description: Students design a table structure to model a real-world scenario they choose (or are given). Steps: (1) Identify what "things" need to be tracked (these become rows), (2) Identify what properties each thing has (these become columns), (3) Choose appropriate column names, (4) Add sample data to verify the design works. Example scenarios: classroom seating chart, pet adoption records, library book tracking, sports team roster. Students present their design, explain why they chose those columns, and demonstrate with 3-5 sample rows. This design-thinking skill prepares students for database modeling.

Dependencies:
* T10.G5.02: Create a table and add columns
* T10.G5.03: Add rows of data to a table




ID: T10.G5.24
Topic: T10 – Lists & Tables
Skill: Verify table operations produce expected results
Description: Students develop verification habits by checking that table operations produce correct results. Verification techniques: (1) Check row count before and after operations (did add increase by 1? did delete decrease by 1?), (2) Read back a cell value after updating to confirm the change, (3) Use table monitors to visually verify state, (4) Test edge cases (empty table, single row, first/last row operations). Given a table operation to perform, students write verification code that confirms the operation succeeded. This defensive programming skill prevents silent bugs in data manipulation.

Dependencies:
* T10.G5.06.01: Get the number of rows in a table
* T10.G5.05: Update a cell value in a table
* T10.G5.18: Show and hide table monitors




ID: T10.G5.25
Topic: T10 – Lists & Tables
Skill: Debug table access errors (wrong row, wrong column, missing data)
Description: Students learn to systematically debug common table access errors through a structured troubleshooting process. When a table program produces wrong results or errors, they: (1) verify the table structure (column names and count) using the table monitor, (2) verify row count using `row count of table`, (3) trace through access code checking row numbers are within bounds (1 to row count), (4) verify column names exactly match (case-sensitive, spelling), and (5) check if accessed rows contain expected data (not empty cells). Students practice with deliberately buggy code: accessing row 0 (invalid), using wrong column name "Score" vs "score", accessing beyond row count, and reading from empty tables. This systematic debugging skill builds confidence in table operations and reduces frustration when programs don't work.

Dependencies:
* T10.G5.04: Read a cell value from a table
* T10.G5.20: Debug table programs by tracing row and column access
* T10.G3.12: Debug a list program by identifying wrong positions


---

## GRADE 6 (24 skills)




ID: T10.G6.01
Topic: T10 – Lists & Tables
Skill: Sort a table by a column
Description: Students use CreatiCode's `sort table [table] by column [name] [large to small/small to large]` block to reorder rows based on values in a column. They understand sorting preserves row integrity (all columns in a row stay together). Students verify the sort worked by reading cell values before and after.

Dependencies:
* T10.G4.05: Use built-in blocks to sort a list
* T10.G5.04: Read a cell value from a table




ID: T10.G6.02
Topic: T10 – Lists & Tables
Skill: Filter table rows based on a condition
Description: Students loop through a table and identify rows where a column value meets a condition (e.g., "find all students with score > 80"). They collect matching row numbers into a list or build a new filtered table containing only matching rows. Students verify their filter by checking that all rows in the result satisfy the condition.

Dependencies:
* T10.G5.19: Build a filtered table manually using conditionals
* T08.G5.02: Use compound conditions with and/or/not




ID: T10.G6.03
Topic: T10 – Lists & Tables
Skill: Copy and append tables
Description: Students use `copy table [t1] into [t2]` to duplicate a table and `append table [t1] to [t2]` to combine tables vertically. Vertical appending adds new rows below existing rows; both tables must have matching columns for append to work correctly.

Dependencies:
* T10.G5.03: Add rows of data to a table




ID: T10.G6.04
Topic: T10 – Lists & Tables
Skill: Use table lookup to find related data
Description: Students use the `item in column [return_col] of [table] where column [search_col] equals [value]` block to look up data. For example, find a student's grade by looking up their name, similar to VLOOKUP in spreadsheets.

Dependencies:
* T10.G5.06.02: Find which row contains a value
* T10.G5.04: Read a cell value from a table




ID: T10.G6.05
Topic: T10 – Lists & Tables
Skill: Group data and compute aggregates per group
Description: Students use CreatiCode's `set table [result] to [method] of column [value_col] in table [source] by column [group_col]` block to group rows by a category and compute statistics (sum, average, count) for each group, creating a summary table.

Dependencies:
* T10.G5.08: Use built-in table aggregate blocks
* T10.G6.02: Filter table rows based on a condition




ID: T10.G6.06
Topic: T10 – Lists & Tables
Skill: Use set operations on lists
Description: Students implement set operations like union (all unique items from both lists), intersection (only items in both lists), and difference (items in list1 but not list2) using loops and conditionals. They understand mathematical set concepts applied to lists.

Dependencies:
* T10.G4.08: Filter items from a list based on a condition
* T10.G3.06: Check if a list contains a specific item




ID: T10.G6.07
Topic: T10 – Lists & Tables
Skill: Remove duplicate items from a list
Description: Students write code to remove duplicate values from a list, keeping only one instance of each unique value. They loop through the list, check if each item already exists in a result list, and add only unique items.

Dependencies:
* T10.G3.06: Check if a list contains a specific item
* T10.G4.08: Filter items from a list based on a condition




ID: T10.G6.08
Topic: T10 – Lists & Tables
Skill: Shuffle table rows randomly
Description: Students use the `reshuffle table [table] randomly` block to randomize row order while keeping row integrity (all columns in a row stay together). Applications include randomizing quiz questions stored in tables, shuffling game data, or anonymizing datasets for privacy.

Dependencies:
* T10.G4.15: Randomly shuffle items in a list
* T10.G5.03: Add rows of data to a table




ID: T10.G6.09
Topic: T10 – Lists & Tables
Skill: Create and populate a nested list (2D array)
Description: Students create a list where each item is itself a list, forming a 2D grid structure. For example, a 3x3 tic-tac-toe board can be represented as a list of 3 rows, where each row is a list of 3 cells. Students create the structure by making an outer list, then adding inner lists as items. They populate cells by first accessing the inner list, then setting items within it. This introduces the concept of nested data structures as an alternative to tables for grid-based data.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.03: Insert an item at a specific position in a list
* T10.G4.04: Replace an item in a list




ID: T10.G6.09.01
Topic: T10 – Lists & Tables
Skill: Trace nested list access patterns (row then column)
Description: Students practice the two-step access pattern for 2D nested lists through explicit tracing exercises. Given a nested list representing a grid (e.g., [[1,2,3], [4,5,6], [7,8,9]] for a 3x3 grid), they trace through accessing specific cells: to get row 2, column 3, first use `item (2) of [grid]` to get the inner list [4,5,6], then use `item (3) of (...)` to get 6 from that inner list. Students draw grid diagrams with row and column numbers, identify target cells, write the two-step access code, and verify by running it. They also practice the reverse: given access code like `item (1) of (item (3) of [grid])`, they identify which cell is being accessed (row 3, column 1). This explicit tracing builds fluency with nested access syntax and prevents common errors like reversing row/column order or trying to access a 2D list with a single index.

Dependencies:
* T10.G6.09: Create and populate a nested list (2D array)
* T10.G3.01.03: Trace list index access step by step




ID: T10.G6.10
Topic: T10 – Lists & Tables
Skill: Access elements in a nested list using row and column indices
Description: Students read and write values in a 2D list using two indices: first to select the row (outer list item), then to select the column (inner list item). For example, to get the value at row 2, column 3 of a grid, they use `item 3 of (item 2 of grid)`. Students practice navigating the nested structure and recognize that accessing requires two steps: outer index first, then inner index.

Dependencies:
* T10.G6.09.01: Trace nested list access patterns (row then column)
* T10.G4.18: Loop through list indices




ID: T10.G6.11
Topic: T10 – Lists & Tables
Skill: Iterate through all elements of a 2D array with nested loops
Description: Students use nested loops to visit every cell in a 2D array: the outer loop iterates through rows (1 to number of rows), and the inner loop iterates through columns (1 to number of columns in that row). For each cell, they perform an operation like summing values, finding the maximum, or checking for a condition. Students trace through a 3x3 grid and predict the order in which cells are visited (row-major order).

Dependencies:
* T10.G6.10: Access elements in a nested list using row and column indices
* T07.G6.01: Trace nested loops with variable bounds




ID: T10.G6.12
Topic: T10 – Lists & Tables
Skill: Implement queue operations (enqueue and dequeue)
Description: Students implement queue behavior using a list: enqueue (add to end), dequeue (remove and return first item), and peek (read first item without removing). They use `add [item] to [queue]` for enqueue, `item (1) of [queue]` with `delete (1) of [queue]` for dequeue, and recognize FIFO (First-In-First-Out) behavior. Applications include task queues (process tasks in order received), print queues, breadth-first traversal, and simulating waiting lines. Students contrast FIFO (queue) with LIFO (stack) behavior by tracing the same operations on both data structures.

Dependencies:
* T10.G4.03: Insert an item at a specific position in a list
* T10.G3.04.01: Delete an item at a specific position
* T10.G3.03: Get the length of a list




ID: T10.G6.13
Topic: T10 – Lists & Tables
Skill: Use frequency counting with lists
Description: Students count occurrences of each unique value in a list by using parallel lists (one for unique values, one for counts). They loop through the source list, check if each item exists in the values list, and either increment its count or add a new entry. This technique enables finding the most/least frequent items, creating histograms, and analyzing data distributions. Students apply this to real scenarios like counting votes, tallying survey responses, or finding the mode of a dataset.

Dependencies:
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.01.01: Find an item's position using built-in block
* T10.G3.09: Increment or decrement a list item's value




ID: T10.G6.14
Topic: T10 – Lists & Tables
Skill: Merge two sorted lists into one sorted list
Description: Students implement the merge algorithm: given two already-sorted lists, combine them into one sorted list without re-sorting. They use two pointers (one for each list), repeatedly compare the current items, add the smaller one to the result, and advance that pointer. This O(n) algorithm is more efficient than concatenating and re-sorting O(n log n), and is a building block for merge sort. Students trace through merging [1, 4, 7] and [2, 3, 8] step by step.

Dependencies:
* T10.G4.05: Use built-in blocks to sort a list
* T10.G4.18: Loop through list indices
* T10.G3.08: Check if a list is empty before accessing




ID: T10.G6.15
Topic: T10 – Lists & Tables
Skill: Swap adjacent items based on comparison
Description: Students practice the swap pattern in the context of sorting: compare two adjacent items, swap them if out of order, and recognize that multiple passes are needed to fully sort. They trace through swapping adjacent pairs and observe how items gradually move toward correct positions. This builds directly toward implementing bubble sort and selection sort algorithms in Grade 8.

Dependencies:
* T10.G4.10: Swap two items in a list
* T10.G4.18: Loop through list indices




ID: T10.G6.16
Topic: T10 – Lists & Tables
Skill: Find maximum in a sublist range
Description: Students extend the manual find-max algorithm (T10.G4.07) to find the maximum or minimum within a specific range of indices, not the entire list. They loop from a start position to an end position, tracking the best value and its position. This pattern is essential for selection sort (find min in remaining unsorted portion) and other range-based algorithms.

Dependencies:
* T10.G4.07: Find the maximum or minimum item in a list manually
* T10.G4.21: Extract a sublist from a range of positions




ID: T10.G6.17
Topic: T10 – Lists & Tables
Skill: Parse text into structured list data
Description: Students use text splitting and string operations to parse semi-structured text (like CSV lines, simple log entries, or formatted strings) into list items for programmatic processing. They use the split block to break text by delimiters, handle edge cases like extra spaces, and build lists from parsed text. This bridges text manipulation and list operations, preparing for complex data parsing in Grade 8.

Dependencies:
* T10.G4.12: Split a text string into a list
* T10.G4.08: Filter items from a list based on a condition




ID: T10.G6.18
Topic: T10 – Lists & Tables
Skill: Select a random item from a list
Description: Students use the `item (random v) of [list]` block or generate a random index using `pick random (1) to (length of [list])` to select items at random. Applications include picking random quiz questions, selecting random game events, or implementing simple random sampling. Students verify that multiple runs produce different selections and understand the difference between random access and sequential access.

Dependencies:
* T10.G4.18: Loop through list indices
* T10.G4.15: Randomly shuffle items in a list




ID: T10.G6.19
Topic: T10 – Lists & Tables
Skill: Filter table rows using OR conditions
Description: Students extend filtering to OR conditions, finding rows that match ANY of several criteria. For example, "find all students who scored above 90 OR are in grade 8" requires checking two conditions and including the row if EITHER is true. Students implement this with `if <condition1> or <condition2>` inside a loop, understanding that OR is more inclusive than AND (more rows match). They compare results: AND filtering returns fewer rows (must meet ALL conditions), OR filtering returns more rows (must meet ANY condition). Applications include searching for records that could match multiple categories.

Dependencies:
* T10.G6.02: Filter table rows based on a condition
* T08.G5.02: Use compound conditions with and/or/not




ID: T10.G6.20
Topic: T10 – Lists & Tables
Skill: Choose between filtering and sorting for a data task
Description: Students analyze data tasks and decide whether filtering, sorting, or both is the appropriate operation. Decision framework: Filtering REMOVES rows that don't match (when you only want certain items), Sorting REORDERS all rows (when you want everything but in a different order), Sometimes you need both (filter first, then sort the results). Given scenarios: (1) "Show only students who passed" → Filter, (2) "Show all students ranked by score" → Sort, (3) "Show the top 5 highest scores" → Sort then take first 5 (or filter by threshold). Students justify their operation choice and implement the solution.

Dependencies:
* T10.G6.02: Filter table rows based on a condition
* T10.G6.01: Sort a table by a column




ID: T10.G6.21
Topic: T10 – Lists & Tables
Skill: Verify data transformation correctness
Description: Students develop verification strategies for data transformations: after filtering, sorting, or aggregating, how do you know the result is correct? Techniques: (1) Check result count matches expectations (filtered result should be smaller), (2) Spot-check specific values (does the first sorted item have the smallest value?), (3) Verify aggregates manually on small test data (calculate sum by hand, compare to code result), (4) Check that no data was accidentally lost or duplicated. Students practice verifying transformations and articulate what "correct" means for each operation type.

Dependencies:
* T10.G6.02: Filter table rows based on a condition
* T10.G6.05: Group data and compute aggregates per group
* T10.G5.24: Verify table operations produce expected results




ID: T10.G6.22
Topic: T10 – Lists & Tables
Skill: Implement a simple lookup cache with lists
Description: Students implement a basic caching pattern: store recently looked-up values to avoid redundant searching. Using two parallel lists (keys and values), they check if a key is already cached before doing an expensive lookup. If found in cache, return immediately; if not, perform the lookup, store the result in the cache, then return it. This introduces the concept of time-space trade-offs: using memory (cache) to save time (avoid repeated searches). Students measure the performance difference with and without caching on repeated lookups.

Dependencies:
* T10.G6.04: Use table lookup to find related data
* T10.G4.02: Store and retrieve parallel list data
* T10.G4.01.01: Find an item's position using built-in block




ID: T10.G6.23
Topic: T10 – Lists & Tables
Skill: Choose between table, nested list, or parallel lists for a scenario
Description: Students compare three multi-dimensional data structures and justify their choice for specific scenarios. They analyze the tradeoffs: (1) Tables have built-in column names and aggregate functions, ideal for heterogeneous data (student: name, age, grade); (2) Nested lists are flexible for homogeneous grid data (game boards, images as pixel grids); (3) Parallel lists are simpler when only 2-3 attributes need to be tracked together. Given scenarios (store chess board state, track inventory with name/quantity/price, record game scores over time), students sketch data layouts for each approach, identify pros and cons (e.g., tables are clearer but more complex to set up; nested lists are compact but harder to read; parallel lists can get out of sync), and choose the best fit. They implement their choice and explain why alternatives would be less suitable. This design skill synthesizes data structure knowledge into practical decision-making.

Dependencies:
* T10.G5.22: Compare tables vs parallel lists and justify choice
* T10.G6.09: Create and populate a nested list (2D array)
* T10.G5.01: Identify table structure (rows, columns, cells)


---

## GRADE 7 (26 skills)




ID: T10.G7.00.01
Topic: T10 – Lists & Tables
Skill: Design data flow for external data (import → validate → transform → use)
Description: Students learn to design a systematic data processing workflow when working with external data sources (CSV files, Google Sheets, APIs). They map out the four-stage pipeline: (1) Import: load data into a table using import blocks, (2) Validate: check for missing values, correct data types, reasonable ranges, (3) Transform: clean text (trim, standardize case), convert formats, compute derived columns, (4) Use: filter, sort, aggregate, or visualize the cleaned data. Students sketch this flow on paper before coding, identifying what validation checks are needed (e.g., ages should be 0-120, dates should match format) and what transformations are required (e.g., convert state abbreviations to full names). This pipeline thinking skill prepares students for real-world data work where raw data is messy and must be processed systematically before use, preventing "garbage in, garbage out" problems.

Dependencies:
* T10.G6.02: Filter table rows based on a condition
* T10.G5.05: Update a cell value in a table
* T10.G5.24: Verify table operations produce expected results




ID: T10.G7.01
Topic: T10 – Lists & Tables
Skill: Pivot or reshape table data
Description: Students use CreatiCode's `pivot [source] into [result] row groups [cols] columns [values] methods [methods]` block to reshape data from "long" format (many rows, few columns) to "wide" format (fewer rows, more columns) or vice versa, preparing data for different types of analysis.

Dependencies:
* T10.G6.05: Group data and compute aggregates per group




ID: T10.G7.02
Topic: T10 – Lists & Tables
Skill: Import external data into a table
Description: Students use the `import file into table [table]` block to load data from an external CSV file into a table. They understand file formats, handle the imported structure, and verify the data loaded correctly.

Dependencies:
* T10.G5.02: Create a table and add columns
* T10.G5.04: Read a cell value from a table




ID: T10.G7.03
Topic: T10 – Lists & Tables
Skill: Design a table schema for a real-world scenario
Description: Students design the structure of a table (what columns to include, what data types they hold) to model a real-world domain. They create a table with appropriate column names, justify their design choices (why these columns? what data type?), and demonstrate by populating the table with sample data that validates their design. Example domains: Library catalog (columns: title, author, ISBN, genre, available_copies); Game inventory (item_name, item_type, quantity, value, rarity); Sports statistics (player_name, team, position, points, assists).

Dependencies:
* T10.G5.02: Create a table and add columns




ID: T10.G7.04
Topic: T10 – Lists & Tables
Skill: Visualize table data with charts
Description: Students use CreatiCode's chart blocks like `draw [line/bar/pie] chart using columns [...] from table [table]` to create visual representations of their data. They also use `draw [type] chart using category column [col1] value column [col2] from table [table]` for categorical data visualization (e.g., bar chart of sales by region, pie chart of votes by candidate). They choose appropriate chart types: line charts for trends over time, bar charts for comparing categories, and pie charts for showing proportions of a whole.

Dependencies:
* T10.G5.08: Use built-in table aggregate blocks
* T10.G6.05: Group data and compute aggregates per group




ID: T10.G7.05
Topic: T10 – Lists & Tables
Skill: Clean and transform table data
Description: Students apply data cleaning transformations to improve data quality. Techniques include: trimming whitespace from text, standardizing text case (uppercase/lowercase), removing or replacing invalid characters, and standardizing formats (date formats, phone numbers). Students write loops to process each row and apply these transformations, verifying improvements by spot-checking cleaned values.

Dependencies:
* T10.G5.05: Update a cell value in a table
* T10.G5.07: Loop through table rows to compute aggregates
* T08.G5.02: Use compound conditions with and/or/not




ID: T10.G7.06
Topic: T10 – Lists & Tables
Skill: Validate and handle missing data in tables
Description: Students detect data quality issues: missing values (empty cells), out-of-range values (e.g., age > 150), and invalid data types (text in numeric columns). They implement validation rules and handle issues by replacing missing values with defaults (e.g., 0 or "N/A"), deleting invalid rows, or marking rows for manual review. Students report the count of issues found and fixed.

Dependencies:
* T10.G7.05: Clean and transform table data
* T10.G5.09.01: Delete a single row by index
* T08.G5.02: Use compound conditions with and/or/not




ID: T10.G7.07
Topic: T10 – Lists & Tables
Skill: Analyze a dataset to find patterns or outliers
Description: Students examine a table of data and write code to find patterns (most frequent value, trends over time) or identify outliers (values much larger/smaller than typical). They combine aggregates, sorting, and conditionals to discover insights and report their findings with supporting evidence from the data.

Dependencies:
* T10.G6.05: Group data and compute aggregates per group
* T10.G6.01: Sort a table by a column
* T08.G5.02: Use compound conditions with and/or/not




ID: T10.G7.08
Topic: T10 – Lists & Tables
Skill: Use regex patterns to find items in lists
Description: Students use regular expression patterns to find items in lists that match complex text patterns (e.g., "find all emails," "find all phone numbers," "find all codes starting with A"). They use CreatiCode's regex blocks to extract matching items into a new list and verify the pattern matches only intended items.

Dependencies:
* T10.G4.08: Filter items from a list based on a condition




ID: T10.G7.09
Topic: T10 – Lists & Tables
Skill: Read and write data with Google Sheets
Description: Students use `read from google sheet: url [url] sheet name [name] range [range] into table [table]` and `write into google sheet: url [url] sheet name [name] start cell [cell] from table [table]` to sync data with Google Sheets. They also use `list all sheets in google sheet at URL [url] into list [list]` to get names of all sheets in a spreadsheet for dynamic sheet selection. They learn to set up sharing, use proper URLs, and handle authentication.

Dependencies:
* T10.G7.02: Import external data into a table
* T10.G5.03: Add rows of data to a table




ID: T10.G7.10
Topic: T10 – Lists & Tables
Skill: Manage Google Sheets structure
Description: Students use `add sheet [name] to google sheet at URL [url]`, `remove sheet [name]`, `insert [n] columns/rows in sheet [name]`, `remove [n] columns/rows from sheet [name]`, and `clear sheet [name] in google sheet at URL [url]` to programmatically manage spreadsheet structure. They understand when to modify structure vs. data.

Dependencies:
* T10.G7.09: Read and write data with Google Sheets
* T10.G5.11.01: Add a column at a specific position




ID: T10.G7.11
Topic: T10 – Lists & Tables
Skill: Display formatted table snapshots
Description: Students use `show snapshot of table [table] from row (start) to (end) with style [style] [color]` to create professionally formatted table displays with styling and color themes. They use this for presenting data in projects, creating reports, or showing partial table views.

Dependencies:
* T10.G5.18: Show and hide table monitors
* T10.G7.04: Visualize table data with charts




ID: T10.G7.12
Topic: T10 – Lists & Tables
Skill: Export table data to a file
Description: Students use `export table [table] as [filename]` to save table data as a downloadable CSV file. They understand CSV format (comma-separated values), when to export data (sharing results, backup, analysis in other tools), and how file export complements data import.

Dependencies:
* T10.G7.02: Import external data into a table
* T10.G5.02: Create a table and add columns




ID: T10.G7.13
Topic: T10 – Lists & Tables
Skill: Save and load data to the cloud
Description: Students use `save table [table] to server as [dataname]` and `load [dataname] from server into table [table]` to store and retrieve table data on CreatiCode's cloud server. They understand this enables data persistence (save progress, reload later), multi-session projects, and simple data sharing without Google Sheets integration.

Dependencies:
* T10.G7.02: Import external data into a table
* T10.G7.09: Read and write data with Google Sheets




ID: T10.G7.14
Topic: T10 – Lists & Tables
Skill: Use AI to analyze table data
Description: Students use CreatiCode's AI blocks to ask questions about table data (e.g., "What are the key insights from this sales data?" or "Summarize the trends in this dataset"). Students formulate clear questions, interpret AI responses, and verify AI suggestions against actual data.

Dependencies:
* T10.G7.07: Analyze a dataset to find patterns or outliers
* T10.G5.08: Use built-in table aggregate blocks




ID: T10.G7.15
Topic: T10 – Lists & Tables
Skill: Implement stack operations (push and pop)
Description: Students implement stack behavior using a list: push (add to end), pop (remove and return last item), and peek (read last item without removing). They use `add [item] to [stack]` for push, `item (length of [stack]) of [stack]` with `delete (length of [stack]) of [stack]` for pop, and recognize LIFO (Last-In-First-Out) behavior. Applications include undo functionality (push each action, pop to undo), expression evaluation, and backtracking algorithms. Students trace through a sequence of push/pop operations and predict the stack state after each.

Dependencies:
* T10.G6.12: Implement queue operations (enqueue and dequeue)




ID: T10.G7.16
Topic: T10 – Lists & Tables
Skill: Use KNN classification with table data
Description: Students use CreatiCode's KNN (K-Nearest Neighbors) blocks to classify new data points based on existing labeled data stored in a table. They prepare training data in a table with feature columns and a label column, use the `add training data from table [table] features [cols] labels [col]` block, then classify new inputs using the trained model. Students experiment with different k values and observe how it affects classification accuracy. This introduces supervised machine learning concepts using familiar table data.

Dependencies:
* T10.G7.03: Design a table schema for a real-world scenario
* T10.G5.08: Use built-in table aggregate blocks




ID: T10.G7.17
Topic: T10 – Lists & Tables
Skill: Build a simple recommendation system using tables
Description: Students create a basic recommendation system using table data and similarity calculations. Given a table of users and their ratings/preferences (e.g., movie ratings, product reviews), students find similar users by comparing their ratings, then recommend items that similar users liked but the target user hasn't seen. They implement a simple similarity measure (count of matching ratings) and use table lookups to generate recommendations. This practical application combines table operations with real-world data analysis.

Dependencies:
* T10.G6.04: Use table lookup to find related data
* T10.G6.05: Group data and compute aggregates per group
* T10.G5.07: Loop through table rows to compute aggregates




ID: T10.G7.18
Topic: T10 – Lists & Tables
Skill: Debug table operations by logging intermediate states
Description: Students develop systematic debugging strategies for table programs: logging row/column values during loops using console output, checking boundary conditions (first row, last row, empty table), verifying column values match expected types, and using table snapshots to compare before/after states. Given a buggy table program, students add logging statements to trace execution, identify where values diverge from expectations, and fix the issue. This skill builds on list debugging (T10.G3.12) but addresses table-specific challenges like multi-column access patterns and row counting errors.

Dependencies:
* T10.G5.20: Debug table programs by tracing row and column access
* T10.G7.06: Validate and handle missing data in tables




ID: T10.G7.19
Topic: T10 – Lists & Tables
Skill: Insert and update database records from table data
Description: Students use CreatiCode's database blocks to persist table data beyond individual sessions. They use `insert from table [table] row from (start) to (end) into collection [collection]` to add records to a database collection, and `update collection [collection] from table [table]` to modify existing records. Students understand the difference between local tables (temporary, in memory) and database collections (persistent, shared), and design programs that sync data between tables and databases appropriately.

Dependencies:
* T10.G7.09: Read and write data with Google Sheets
* T10.G7.03: Design a table schema for a real-world scenario




ID: T10.G7.20
Topic: T10 – Lists & Tables
Skill: Query and filter database collections into tables
Description: Students use `fetch from collection [collection] into table [table] where <condition> limit (n) sort by (field) [order]` to retrieve database records matching specific criteria. They construct filter conditions, apply sorting, limit result counts for performance, and process the fetched data using table operations. This skill bridges the gap between simple table operations and real database querying, preparing students for SQL concepts.

Dependencies:
* T10.G7.19: Insert and update database records from table data
* T10.G6.02: Filter table rows based on a condition




ID: T10.G7.21
Topic: T10 – Lists & Tables
Skill: Document data schema decisions for future readers
Description: Students write documentation explaining their data schema design choices. For a table they've created, they document: (1) Purpose of each column and what values it can contain, (2) Relationships between columns if any, (3) Why they chose this structure over alternatives, (4) Example queries the table is designed to support. This communication skill is essential for team projects—others need to understand your data design to work with it. Students practice writing clear, concise documentation and review each other's documentation for clarity.

Dependencies:
* T10.G7.03: Design a table schema for a real-world scenario
* T10.G5.22: Compare tables vs parallel lists and justify choice




ID: T10.G7.22
Topic: T10 – Lists & Tables
Skill: Process AI vision detection data stored in tables
Description: Students use CreatiCode's AI vision blocks that output to tables (hand detection, body pose, face detection) and write code to process the resulting structured data. The `run hand detection table [table]` block fills a table with finger curl angles and 3D coordinates; students access specific rows/columns to detect gestures (e.g., "thumbs up" = thumb extended, other fingers curled). Similarly, body pose detection outputs keypoints that students use to detect poses (arms raised, sitting, etc.). Students understand the table schema these AI blocks produce and write conditional logic to interpret the data for interactive applications.

Dependencies:
* T10.G7.03: Design a table schema for a real-world scenario
* T10.G5.07: Loop through table rows to compute aggregates
* T10.G6.02: Filter table rows based on a condition




ID: T10.G7.23
Topic: T10 – Lists & Tables
Skill: Build a data-driven quiz or flashcard system using tables
Description: Students design and implement a complete quiz or flashcard application using table data. They design a table with columns for questions, correct answers, optional wrong answers (for multiple choice), and possibly difficulty/category. They implement: (1) Loading questions from the table, (2) Randomly selecting questions, (3) Checking user answers against correct answers, (4) Tracking score, (5) Optionally tracking which questions were missed for review. This project integrates many table skills into a practical, reusable application. Students can extend it by importing their own question sets from CSV files.

Dependencies:
* T10.G7.02: Import external data into a table
* T10.G6.18: Select a random item from a list
* T10.G6.04: Use table lookup to find related data




ID: T10.G7.24
Topic: T10 – Lists & Tables
Skill: Optimize table operations for large datasets
Description: Students learn strategies to make table operations faster on larger datasets (100+ rows). Techniques: (1) Filter early to reduce rows before processing, (2) Use built-in aggregate blocks instead of manual loops when possible, (3) Avoid repeated lookups by caching results, (4) Limit display operations (don't show all 500 rows at once). Students compare performance of optimized vs. naive approaches using timer blocks and understand that algorithmic choices matter more as data grows. This prepares students for thinking about scalability in real-world applications.

Dependencies:
* T10.G7.07: Analyze a dataset to find patterns or outliers
* T10.G6.22: Implement a simple lookup cache with lists




ID: T10.G7.25
Topic: T10 – Lists & Tables
Skill: Debug data import errors and mismatched schemas
Description: Students learn to systematically troubleshoot problems when importing external data. Common issues include: file not found (check file path and sharing permissions), wrong delimiter (CSV uses commas, but file might use tabs or semicolons), column count mismatch (some rows have more/fewer columns than expected), encoding issues (special characters display wrong), and header row problems (data includes header row as first data row). Students use debugging strategies: (1) examine first few rows with table monitor to see what actually imported, (2) check column count and names, (3) verify expected data appears in correct columns, (4) test with small sample file first, (5) use text blocks to preview file contents before import. They practice with deliberately problematic files (wrong delimiter, missing columns, extra whitespace) and fix import settings or pre-process the data. This practical troubleshooting skill builds resilience when working with real external data.

Dependencies:
* T10.G7.02: Import external data into a table
* T10.G7.06: Validate and handle missing data in tables
* T10.G5.20: Debug table programs by tracing row and column access


---

## GRADE 8 (26 skills)




ID: T10.G8.01
Topic: T10 – Lists & Tables
Skill: Use nested loops to compare data across two tables
Description: Students write nested loops to analyze relationships between two tables (e.g., matching orders to customers, finding common elements). The outer loop iterates through one table while the inner loop searches the other table for matches.

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.04: Use table lookup to find related data




ID: T10.G8.02
Topic: T10 – Lists & Tables
Skill: Implement bubble sort algorithm step by step
Description: Students implement bubble sort by writing nested loops: the outer loop controls passes, the inner loop compares adjacent items and swaps if out of order. They trace through the algorithm to understand how items "bubble" to their correct positions.

Dependencies:
* T10.G6.15: Swap adjacent items based on comparison
* T07.G6.01: Trace nested loops with variable bounds




ID: T10.G8.03
Topic: T10 – Lists & Tables
Skill: Implement selection sort algorithm step by step
Description: Students implement selection sort by writing nested loops: the outer loop selects each position, the inner loop finds the minimum remaining element. They understand that selection sort makes fewer swaps than bubble sort.

Dependencies:
* T10.G8.02: Implement bubble sort algorithm step by step
* T10.G6.16: Find maximum in a sublist range




ID: T10.G8.04
Topic: T10 – Lists & Tables
Skill: Build a simulation using table-based state
Description: Students create a simulation (e.g., a game with multiple entities, a population model, an ecosystem) where entities and their properties are stored in a table. Each simulation step loops through rows to update values based on rules.

Dependencies:
* T10.G7.03: Design a table schema for a real-world scenario
* T10.G5.07: Loop through table rows to compute aggregates




ID: T10.G8.05
Topic: T10 – Lists & Tables
Skill: Query and report statistics from a complex dataset
Description: Students work with a realistic multi-column table (e.g., weather data, sports statistics, survey results) and write code to answer analytical questions: compute means, find percentiles, compare groups, identify trends, and format results as a report.

Dependencies:
* T10.G7.07: Analyze a dataset to find patterns or outliers
* T10.G6.01: Sort a table by a column




ID: T10.G8.06
Topic: T10 – Lists & Tables
Skill: Model relationships using multiple linked tables
Description: Students design and use multiple tables that reference each other (e.g., a Students table and a Grades table linked by student ID). They write code to perform lookups across tables to answer queries like "What are all grades for student X?"

Dependencies:
* T10.G8.01: Use nested loops to compare data across two tables
* T10.G7.03: Design a table schema for a real-world scenario




ID: T10.G8.07
Topic: T10 – Lists & Tables
Skill: Implement a hash table lookup using lists
Description: Students simulate a simple hash table by using a list where each position corresponds to a hash value computed using modulo operation (e.g., hash(key) = key mod list_length for numbers, or sum of character codes mod list_length for strings). They handle collisions using linear probing (check next positions) or chaining (store multiple items at one position using lists within lists). Implementation pattern: Use a list as the hash table, create a hash function using math operators and string blocks, use linear search as fallback for collisions, and compare performance to linear search to demonstrate the principle of constant-time lookup.

Dependencies:
* T10.G8.03: Implement selection sort algorithm step by step
* T10.G6.13: Use frequency counting with lists
* T09.G7.01: Compare computational efficiency of different approaches




ID: T10.G8.08.00
Topic: T10 – Lists & Tables
Skill: Trace binary search step by step before implementing
Description: Before implementing binary search, students trace through the algorithm manually to understand the divide-and-conquer strategy. Given a sorted list [2, 5, 8, 12, 15, 20, 25, 30, 35, 40] and target 20, they trace each step: (1) calculate middle position (length ÷ 2), (2) compare target to middle value, (3) eliminate half the search space (if target < middle, search left half; if target > middle, search right half; if equal, found), (4) repeat with new boundaries until found or search space is empty. Students track the changing search boundaries (low, high) and middle position at each iteration, counting how many steps binary search takes vs. linear search (which would check every item). This hands-on tracing reveals why binary search is O(log n) efficient and builds understanding before managing the complex nested conditional and loop structure in code.

Dependencies:
* T10.G4.01.02: Implement manual linear search with loop
* T10.G8.02: Implement bubble sort algorithm step by step




ID: T10.G8.08.01
Topic: T10 – Lists & Tables
Skill: Implement binary search on sorted lists
Description: Students implement binary search algorithm to find items in O(log n) time instead of O(n) linear search. They repeatedly divide the sorted list's search space in half: compare the middle element to the target, then search either the left half (if target is smaller) or right half (if target is larger). Students trace through the algorithm step-by-step, counting comparisons, and compare performance to linear search to demonstrate logarithmic efficiency gains. This introduces divide-and-conquer algorithmic thinking.

Dependencies:
* T10.G8.08.00: Trace binary search step by step before implementing
* T09.G7.01: Compare computational efficiency of different approaches




ID: T10.G8.08.02
Topic: T10 – Lists & Tables
Skill: Use two-pointer technique for list problems
Description: Students apply two-pointer techniques where pointers move from both ends toward the center to solve problems efficiently. Common patterns: Finding pairs that sum to a target value (one pointer at start, one at end, move based on comparison), removing duplicates from sorted lists (slow and fast pointers), or checking palindromes (compare from both ends). Students implement at least one two-pointer algorithm, trace pointer movements, and understand how this technique avoids nested loops for certain problems.

Dependencies:
* T10.G8.08.01: Implement binary search on sorted lists
* T09.G7.01: Compare computational efficiency of different approaches




ID: T10.G8.08.03
Topic: T10 – Lists & Tables
Skill: Apply sliding window algorithms
Description: Students use sliding window algorithms to efficiently process contiguous subarrays by maintaining a window that slides through the data. Common applications: finding maximum sum of k consecutive elements, longest substring without repeating characters, or moving averages. Implementation pattern: Initialize window with first k elements, slide window right by adding next element and removing leftmost element, track window state (sum, max, set of unique items), update result after each slide. Students understand how sliding window reduces O(n*k) to O(n) by reusing previous computations.

Dependencies:
* T10.G8.08.02: Use two-pointer technique for list problems
* T09.G7.01: Compare computational efficiency of different approaches




ID: T10.G8.09
Topic: T10 – Lists & Tables
Skill: Implement a priority queue using sorted insertion
Description: Students implement a priority queue where items are always retrieved in priority order (highest or lowest first). They maintain a sorted list by inserting new items at the correct position (binary search for position, then insert) rather than sorting after each insertion. Students compare this O(n) insertion with O(1) removal to naive approaches (O(1) insertion with O(n) search for removal). Applications include task schedulers, event-driven simulations, and Dijkstra's algorithm foundations.

Dependencies:
* T10.G8.08.01: Implement binary search on sorted lists
* T10.G6.12: Implement queue operations (enqueue and dequeue)




ID: T10.G8.10
Topic: T10 – Lists & Tables
Skill: Parse and process structured text into tables
Description: Students write programs to parse structured text data (log files, configuration files, semi-structured reports) into tables for analysis. They use string operations (split, find, substring) to extract fields from each line, handle variations in format, skip header/footer lines, and build a clean table from messy input. This real-world skill prepares students for data engineering tasks where raw data must be cleaned and structured before analysis.

Dependencies:
* T10.G7.05: Clean and transform table data
* T10.G6.17: Parse text into structured list data
* T10.G5.03: Add rows of data to a table




ID: T10.G8.11
Topic: T10 – Lists & Tables
Skill: Design and implement a data pipeline with multiple transformations
Description: Students design a multi-step data processing pipeline: import raw data → clean/validate → transform → aggregate → visualize/export. They chain together table operations learned throughout T10 to build an end-to-end solution for a realistic scenario (e.g., process survey data, analyze game statistics, generate a report from transaction logs). Students document their pipeline design before implementing, handle errors gracefully, and verify output quality at each stage.

Dependencies:
* T10.G8.05: Query and report statistics from a complex dataset
* T10.G7.02: Import external data into a table
* T10.G7.12: Export table data to a file
* T10.G7.06: Validate and handle missing data in tables




ID: T10.G8.12
Topic: T10 – Lists & Tables
Skill: Build a semantic search database from table data
Description: Students use CreatiCode's `create semantic database from table [table]` block to build a searchable database where queries find results by meaning rather than exact keyword matching. They prepare a table with a required 'key' column and additional data columns, understand that the semantic database uses AI embeddings to find similar content, and test queries to verify relevant results are returned. Applications include building a FAQ search system, finding similar products, or creating a knowledge base that users can query in natural language.

Dependencies:
* T10.G8.06: Model relationships using multiple linked tables
* T10.G7.14: Use AI to analyze table data




ID: T10.G8.13
Topic: T10 – Lists & Tables
Skill: Query semantic databases with natural language and filters
Description: Students use `search semantic database with [query] store top (K) in table [result]` and `search semantic database with [query] where [condition] store top (K) in table [result]` to find relevant data using natural language queries. They experiment with different queries to understand how semantic similarity works, apply filters to narrow results, and compare semantic search to exact-match lookups. Students build a practical application (e.g., a smart assistant that answers questions from a knowledge base).

Dependencies:
* T10.G8.12: Build a semantic search database from table data
* T10.G6.02: Filter table rows based on a condition




ID: T10.G8.14
Topic: T10 – Lists & Tables
Skill: Use moving averages to analyze time-series data in lists
Description: Students use `value from [simple/exponential] moving average window [length] of list [list]` to smooth noisy data and identify trends. They understand that moving averages calculate the average over a sliding window, compare simple vs. exponential methods (exponential gives more weight to recent values), and apply this to real scenarios: smoothing sensor readings, analyzing stock prices, or detecting trends in game metrics. Students visualize raw vs. smoothed data to see the difference.

Dependencies:
* T10.G8.03: Implement selection sort algorithm step by step
* T10.G7.07: Analyze a dataset to find patterns or outliers




ID: T10.G8.15
Topic: T10 – Lists & Tables
Skill: Store and retrieve AI vision data from tables
Description: Students capture real-time AI data (hand detection, body pose, face detection) into tables using blocks like `run hand detection table [table]` and `run 2D body part recognition ... table [table]`. They understand the table structure output by these AI blocks (rows for each detected point, columns for x/y coordinates and confidence), write code to process this data (e.g., detect specific gestures, track movement over time), and combine AI sensing with table operations to build interactive applications.

Dependencies:
* T10.G8.04: Build a simulation using table-based state
* T10.G7.03: Design a table schema for a real-world scenario




ID: T10.G8.16
Topic: T10 – Lists & Tables
Skill: Parse and analyze AI-generated structured data
Description: Students process structured data returned by AI services: web search results stored in tables (`web search [query] store top (K) in table [table]`), NLP sentence analysis (`analyze sentence [text] and write into table [table]` which outputs word, lemma, part-of-speech, etc.), and geographic data (`get geo info for latitude (lat) longitude (lon) and write into table [table]`). Students write code to extract insights from these AI-generated tables: find the most relevant search result, identify verbs in a sentence, or determine the country for coordinates. This skill bridges AI capabilities with data processing skills.

Dependencies:
* T10.G8.10: Parse and process structured text into tables
* T10.G7.22: Process AI vision detection data stored in tables




ID: T10.G8.17
Topic: T10 – Lists & Tables
Skill: Design and test data validation rules for tables
Description: Students create comprehensive validation rules for table data and write code to enforce them. Validation types: (1) Type validation (numeric columns should contain numbers), (2) Range validation (age should be 0-150, percentage 0-100), (3) Format validation (email should contain @, date in correct format), (4) Referential validation (foreign key exists in related table), (5) Uniqueness validation (no duplicate IDs). Students implement validation as a function that checks all rows and returns a list of errors with row numbers and descriptions. They test validation rules with intentionally bad data to verify rules catch all issues.

Dependencies:
* T10.G7.06: Validate and handle missing data in tables
* T10.G8.06: Model relationships using multiple linked tables




ID: T10.G8.18
Topic: T10 – Lists & Tables
Skill: Compare algorithmic efficiency for list operations
Description: Students analyze and compare the efficiency of different approaches to the same problem. Case studies: (1) Linear search O(n) vs binary search O(log n) - measure time with 100 vs 1000 items, (2) Naive duplicate removal O(n²) vs sort-then-remove O(n log n), (3) Repeated single lookups vs batch lookup with caching. Students use timer blocks to measure actual performance, create data visualizations showing how time grows with input size, and articulate why some algorithms scale better. This introduces Big-O thinking without formal notation, preparing students for computer science studies.

Dependencies:
* T10.G8.08.01: Implement binary search on sorted lists
* T10.G8.02: Implement bubble sort algorithm step by step
* T10.G7.24: Optimize table operations for large datasets




ID: T10.G8.19
Topic: T10 – Lists & Tables
Skill: Build a complete AI-enhanced data application
Description: Students design and implement a comprehensive application that combines AI capabilities with data structures. Project options: (1) Smart FAQ system: import questions into table, create semantic search database, accept natural language queries, return relevant answers; (2) Gesture-controlled data browser: use hand detection table to navigate through data displays; (3) Automated data summarizer: import data, use AI to generate insights, display visualizations; (4) Multi-source data aggregator: pull data from web searches into tables, combine and analyze. Students document their design, implement the application, test with real data, and present their solution explaining how AI and data structures work together.

Dependencies:
* T10.G8.12: Build a semantic search database from table data
* T10.G8.16: Parse and analyze AI-generated structured data
* T10.G8.11: Design and implement a data pipeline with multiple transformations




ID: T10.G8.20
Topic: T10 – Lists & Tables
Skill: Implement merge sort algorithm with recursion concept
Description: Students implement merge sort by breaking a list into halves, sorting each half, then merging the sorted halves. While full recursion may be beyond block-based programming, students simulate the divide-and-conquer approach: manually split the list, sort the sublists (using built-in sort or bubble sort), then use the merge algorithm from G6. Students trace through the algorithm on paper showing how a list of 8 items is split into 4 pairs, sorted, merged into 2 sorted halves, then merged into the final sorted list. They compare merge sort's O(n log n) efficiency to bubble sort's O(n²) and understand why divide-and-conquer is powerful.

Dependencies:
* T10.G6.14: Merge two sorted lists into one sorted list
* T10.G8.03: Implement selection sort algorithm step by step
* T10.G8.18: Compare algorithmic efficiency for list operations




ID: T10.G8.21
Topic: T10 – Lists & Tables
Skill: Design a complete data solution for a complex scenario
Description: Students synthesize all T10 skills by designing and implementing a complete data solution for a realistic, multi-faceted scenario (e.g., "Build a school library management system," "Create a sports tournament tracker," "Design a personal budget analyzer"). The solution must include: (1) schema design (choose appropriate data structures, design tables with proper columns), (2) data input/import (collect user input or import external data), (3) data validation and cleaning (handle errors and missing data), (4) core operations (search, filter, sort, aggregate), (5) data transformation or analysis (compute statistics, identify patterns), and (6) output/export (display results, save to file, or visualize). Students document their design decisions, justify data structure choices, implement the system modularly (one feature at a time), test with realistic data, and debug systematically. This capstone skill demonstrates mastery by integrating data structures, algorithms, and software design principles into a coherent solution.

Dependencies:
* T10.G8.11: Design and implement a data pipeline with multiple transformations
* T10.G8.06: Model relationships using multiple linked tables
* T10.G8.05: Query and report statistics from a complex dataset
* T10.G7.03: Design a table schema for a real-world scenario


---

# T11 – Functions & Organization (Phase 11 Optimized - November 2025)
# PHASE 11 MAJOR IMPROVEMENTS - Excellence Through Bold Restructuring
#
# KEY CHANGES IN THIS OPTIMIZATION:
#
# 1. STRENGTHENED K-2 METACOGNITION:
#    - T11.GK.07: NEW - Explain WHY grouping makes plans easier (metacognition)
#    - T11.G1.11: NEW - Predict outcome when group card details change
#    - T11.G2.12: NEW - Compare plans with/without group cards (abstraction benefit)
#    - Enhanced focus on REASONING about organization, not just doing it
#
# 2. REFINED CREATICODE SYNTAX PROGRESSION:
#    - T11.G4.01.01: NEW - Use argument block to access parameter values inside definition
#    - T11.G5.02: Clarified to "Use return block to send value from custom block"
#    - T11.G5.02.02: Call reporter blocks using `report` syntax
#    - T11.G5.02.03: NEW - Compare call vs report syntax side-by-side
#    - Clear syntax mastery pathway with explicit CreatiCode block references
#
# 3. ADDED DECISION-MAKING SKILLS:
#    - T11.G6.01.01: NEW - Choose between recursion and loops for a problem
#    - T11.G4.23.01: NEW - Evaluate code organization trade-offs
#    - Focus on WHEN to apply techniques, not just HOW
#
# 4. READING & UNDERSTANDING OTHERS' CODE:
#    - T11.G5.21: NEW - Read and explain unfamiliar custom blocks
#    - T11.G6.17.01: NEW - Analyze and document legacy code organization
#    - Essential for collaboration and code review
#
# 5. AI-INTEGRATED ORGANIZATION SKILLS:
#    - T11.G6.18: NEW - Create custom blocks that wrap AI blocks (ChatGPT, speech)
#    - T11.G7.13: NEW - Design custom blocks for AI-driven features (hand tracking, pose)
#    - T11.G8.21: NEW - Architect AI-human hybrid systems with clear interfaces
#    - Leverages CreatiCode's unique AI capabilities
#
# 6. ENHANCED DEBUGGING & TRACING:
#    - T11.G3.10.02: NEW - Predict parameter flow through custom block calls
#    - T11.G4.10.02: NEW - Debug nested custom block execution order
#    - T11.G5.24.01: NEW - Trace return values through nested reporter calls
#
# 7. PRACTICAL PATTERNS FOR GAMES:
#    - T11.G7.14: NEW - Create custom blocks for common game patterns (spawn, damage, pickup)
#    - T11.G8.22: NEW - Design custom blocks for procedural content generation
#    - Game-focused organization skills for engaging projects
#
# 8. FIXED INCONSISTENCIES:
#    - Renamed T11.G5.02.01 dependency to match actual skill (was referencing wrong ID)
#    - Clarified distinction between defining vs calling blocks throughout
#    - Ensured all skills use precise CreatiCode block syntax
#
# SKILL COUNT CHANGES:
#    - GK: 6 → 7 skills (+1)
#    - G1: 10 → 11 skills (+1)
#    - G2: 11 → 12 skills (+1)
#    - G3: 18 → 20 skills (+2)
#    - G4: 23 → 27 skills (+4)
#    - G5: 26 → 31 skills (+5)
#    - G6: 17 → 22 skills (+5)
#    - G7: 13 → 16 skills (+3)
#    - G8: 20 → 23 skills (+3)
#    - TOTAL: 144 → 169 skills (+25 new skills)
#

ID: T11.GK.01
Topic: T11 – Functions & Organization
Skill: Circle picture cards that belong together
Description: **Student task:** Use colored circles to group related picture cards together. **Visual scenario:** 12 picture cards showing a morning routine (brushing teeth, eating breakfast, getting dressed). Students circle breakfast steps in blue, getting dressed steps in green, brushing teeth steps in yellow. **Success criteria:** Students correctly group 3-4 related activities and explain why each group belongs together (e.g., "These are all about eating"). _Implementation note: Drag colored circle tools onto cards; audio prompts "Which pictures go together?" CSTA: EK-ALG-AB-01 abstraction._

Assessment example: Given 12 picture cards showing a morning routine, students use colored circles to group related activities: breakfast steps in blue, getting dressed steps in green, brushing teeth steps in yellow. They explain why each group belongs together.

Dependencies:
* T01.GK.03: Find the first and last pictures
* T03.GK.01: Tap picture cards to identify parts of a whole object

---

ID: T11.GK.02
Topic: T11 – Functions & Organization
Skill: Select a clear name for a picture card group
Description: **Student task:** Choose the best name for a group of picture cards from multiple choice options. **Visual scenario:** Three groups of picture cards (1: wash hands, put on apron, get ingredients; 2: mix, stir, pour; 3: put in oven, set timer, wait). Options include good names ("Get Ready," "Make the Batter," "Bake the Cake") and vague names ("First Things," "More Stuff"). **Correct answer:** Match each group to its clear, descriptive name. _Implementation note: Drag-and-drop matching; audio reads options; green checkmark for good names. CSTA: EK-ALG-AB-01._

Assessment example: Given three groups of picture cards (1: wash hands, put on apron, get ingredients; 2: mix, stir, pour; 3: put in oven, set timer, wait), students select appropriate names from options: "Get Ready," "Make the Batter," and "Bake the Cake" (rejecting vague options like "First Things" or "More Stuff").

Dependencies:
* T11.GK.01: Circle picture cards that belong together

---

ID: T11.GK.03
Topic: T11 – Functions & Organization
Skill: Drag a named group card into a bigger picture plan
Description: **Student task:** Drag named group cards into empty slots to build a simplified plan. **Visual scenario:** Three named cards ("Do Breakfast," "Get Dressed," "Pack Backpack") and a "Get Ready for School" plan template with three empty slots. **Success criteria:** Students place each card in the correct slot to create a logical 3-step plan. _Implementation note: Drag-and-drop into slots; animated preview shows what each group means; audio: "Use the group cards to make your plan!" CSTA: EK-ALG-AB-01._

Assessment example: Given three named group cards ("Do Breakfast," "Get Dressed," "Pack Backpack") and a "Get Ready for School" plan with three empty slots, students drag each card into the correct slot to create a simplified 3-step plan.

Dependencies:
* T11.GK.02: Select a clear name for a picture card group

---

ID: T11.GK.04
Topic: T11 – Functions & Organization
Skill: Predict what happens when a group card is used
Description: **Student task:** View a named group card with its picture steps, then predict what happens when the card is used in a bigger plan. **Visual scenario:** "Make Snack" group card shows 3 steps (get apple, wash apple, cut apple). Main plan shows: Do Homework → Make Snack → Watch TV. **Correct answer:** Tap all 3 pictures that happen during "Make Snack." _Implementation note: Multi-select tap on correct pictures; animation shows group card "expanding" into its steps. CSTA: EK-ALG-AF-02._

Assessment example: Given "Make Snack" group card with 3 steps and a daily routine that uses it, students tap all pictures that happen when "Make Snack" runs.

Dependencies:
* T11.GK.03: Drag a named group card into a bigger picture plan

---

ID: T11.GK.05
Topic: T11 – Functions & Organization
Skill: Predict what happens when a group card is skipped
Description: **Student task:** A group card is crossed out. Predict what will be different in the final outcome. **Visual scenario:** Morning routine plan: "Wake Up" → "Eat Breakfast" → "Get Dressed" → "Go to School." "Eat Breakfast" is crossed out. **Correct answer:** "The child will be hungry at school" (not "The child will be late" or "Nothing different"). _Implementation note: Multiple choice with picture outcomes; crossed-out card animation; audio: "What happens if we skip this?" CSTA: EK-ALG-AF-02._

Assessment example: Given a morning routine plan with "Eat Breakfast" crossed out, students select from options: "The child will be hungry at school" (correct), "The child will be late" (incorrect), "Nothing will be different" (incorrect).

Dependencies:
* T11.GK.04: Predict what happens when a group card is used

---

ID: T11.GK.06
Topic: T11 – Functions & Organization
Skill: Count how many times a group card is used in a plan
Description: **Student task:** Count how many times the same group card appears in a bigger plan. **Visual scenario:** A "Play at the Park" plan shows 6 cards: "Walk to Park" → "Play on Swings" → "Drink Water" → "Play on Slide" → "Drink Water" → "Walk Home." The "Drink Water" card appears twice. **Correct answer:** 2. **Success criteria:** Students correctly count repeated group cards and recognize the same group can be used multiple times. _Implementation note: Tap to count matching cards; visual highlight when same cards selected. CSTA: EK-ALG-AB-01._

Assessment example: Given a 6-card plan where "Drink Water" appears twice, students tap to count and respond "2 times."

Dependencies:
* T11.GK.04: Predict what happens when a group card is used

---

ID: T11.GK.07
Topic: T11 – Functions & Organization
Skill: Explain WHY grouping makes plans easier to follow
Description: **Student task:** Compare two versions of the same plan—one with group cards and one without—and explain why the grouped version is easier to understand. **Visual scenario:** Side-by-side comparison: Version A shows 12 individual picture cards for making a sandwich. Version B shows 3 group cards ("Get Ingredients," "Build Sandwich," "Clean Up"). Students tap the easier version and complete the sentence: "Using group cards is easier because ___." **Success criteria:** Students articulate benefits like "fewer cards to read," "can see the big steps," or "easier to find what you need." _Implementation note: Multiple choice sentence completions with audio; highlight selected version. CSTA: 1A-AP-AB-01._

Assessment example: Students view two versions of a sandwich-making plan and select why the grouped version is easier, choosing from options like "I can see the 3 big steps" or "There are fewer cards to count."

Dependencies:
* T11.GK.06: Count how many times a group card is used in a plan
* T11.GK.03: Drag a named group card into a bigger picture plan

---

ID: T11.G1.01
Topic: T11 – Functions & Organization
Skill: Identify the main instruction set from picture cards
Description: Students examine 2–3 short sets of picture‑based instructions (e.g., "how to set up the game," "how to decorate," "how to clean up") and tap on the set that tells everyone what to do overall for an activity. This builds the idea that some instructions are the main plan and others are helper tasks.

Assessment example: Given three picture card sets for a birthday party, students tap on the "Run the Party" set (not "Set Up Decorations" or "Clean Up") as the main instructions that reference the other sets.

Dependencies:
* T01.GK.03: Find the first and last pictures

---

ID: T11.G1.02
Topic: T11 – Functions & Organization
Skill: Match picture step groups to clear titles
Description: Students match each group of picture steps to a clear title that tells what it is for (e.g., "Getting Ready," "Playing the Game," "Clean‑Up Time"). They draw lines from picture groups to title labels, rejecting vague titles like "Stuff" or "Things to Do."

Assessment example: Given three picture groups and six title options (three good, three vague), students draw lines connecting each group to its clear title, explaining why "Set Up the Game" is better than "Some Stuff."

Dependencies:
* T11.G1.01: Identify the main instruction set from picture cards

---

ID: T11.G1.03
Topic: T11 – Functions & Organization
Skill: Match picture groups to their purpose descriptions
Description: Students see 2–3 groups of picture instructions for a class routine and match each group to a simple purpose description by drawing lines. For example: "These steps get the classroom ready," "These steps are for playing," "These steps are for cleaning up." This strengthens the habit of explaining the role of each part of a plan.

Assessment example: Given three picture groups for a class art project and three description cards, students draw lines matching each group to its purpose: "Get supplies" → "These steps gather what we need."

Dependencies:
* T03.GK.01: Tap picture cards to identify parts of a whole object

---

ID: T11.G1.04
Topic: T11 – Functions & Organization
Skill: Drag picture cards to split into two category boxes
Description: Students drag picture cards from a long mixed list into two labeled category boxes (e.g., "Before the event" and "During the event," or "Adult jobs" and "Student jobs"). This mirrors splitting one big routine into smaller, organized parts.

Assessment example: Given 8 picture cards for a school field trip and two boxes labeled "Before We Leave" and "At the Museum," students drag each card into the correct box.

Dependencies:
* T11.G1.01: Identify the main instruction set from picture cards

---

ID: T11.G1.05
Topic: T11 – Functions & Organization
Skill: Identify repeated activity groups in a picture sequence
Description: Students examine a longer picture-based activity plan and circle each occurrence of the same group of actions that appears multiple times. For example, in a "classroom game" sequence, they circle all instances of "reset the game board" (put pieces back, shuffle cards, reset timer) that happen before each round. This builds recognition of repetition at the group level, not just single actions.

Assessment example: Given a picture sequence for playing three rounds of a board game, students use colored circles to mark each occurrence of the "setup" activities that appear before each round, counting how many times the same group repeats.

Dependencies:
* T11.GK.03: Drag a named group card into a bigger picture plan
* T04.G1.01: Notice when steps repeat in a sequence

---

ID: T11.G1.06
Topic: T11 – Functions & Organization
Skill: Create a label card for repeated activity groups
Description: Students create a label card for a group of activities that repeats, writing a clear name so they can refer to it instead of repeating the same steps multiple times. This introduces the practical benefit of naming: it saves time and reduces clutter.

Assessment example: After identifying that "clean workspace" (wipe table, throw away trash, put supplies away) happens multiple times in an art project, students write "Clean Workspace" on a label card and explain where to place it in the sequence.

Dependencies:
* T11.G1.05: Identify repeated activity groups in a picture sequence
* T11.GK.02: Select a clear name for a picture card group

---

ID: T11.G1.07
Topic: T11 – Functions & Organization
Skill: Replace repeated picture groups with label cards
Description: Students simplify a complex picture-based plan by replacing repeated activity groups with their label cards. Where they previously had the full sequence of steps repeated, they now drag in a single label card. This demonstrates how abstraction reduces complexity and makes plans easier to read.

Assessment example: Students take a 20-step picture sequence for a class activity that has three repeated "clean up" sections and replace each occurrence with a single "Clean Up" label card, reducing the visible sequence to 14 steps plus a labeled definition box for "Clean Up."

Dependencies:
* T11.G1.06: Create a label card for repeated activity groups

---

ID: T11.G1.08
Topic: T11 – Functions & Organization
Skill: Decide between one label or multiple similar labels
Description: Students identify when activity groups are similar but not identical, deciding whether to create one shared label or multiple specific labels. For example, "Set Up for Game 1" and "Set Up for Game 2" involve similar activities but with different materials. This introduces the idea that sometimes you need multiple related groups rather than one group with variations.

Assessment example: Given a sequence for running two different classroom games, students compare the "setup" phases and decide whether to create "Setup Game 1" and "Setup Game 2" labels or find enough commonality for a single "Setup Game" label, explaining their reasoning.

Dependencies:
* T11.G1.07: Replace repeated picture groups with label cards

---

ID: T11.G1.09
Topic: T11 – Functions & Organization
Skill: Arrange group cards to form a complete plan
Description: Students are given 4-6 labeled group cards (e.g., "Wake Up," "Eat Breakfast," "Get Dressed," "Go to School," "Come Home," "Do Homework") and arrange them in the correct order to form a complete daily plan. This skill emphasizes ordering groups at a higher level of abstraction, treating each group as a single unit. Students must think about the logical flow of grouped activities.

Assessment example: Given 5 group cards for a school day, students drag them into the correct sequence and explain why "Get Dressed" must come before "Go to School" but "Eat Breakfast" could happen before or after "Get Dressed."

Dependencies:
* T11.G1.07: Replace repeated picture groups with label cards
* T01.G1.01: Put pictures in order to plant a seed

---

ID: T11.G1.10
Topic: T11 – Functions & Organization
Skill: Trace through a plan that uses group cards
Description: **Student task:** Given a plan with group cards, trace through step-by-step to show all the detailed steps that will happen. **Visual scenario:** A "Make Lunch" plan shows 3 group cards: "Get Supplies" → "Make Sandwich" → "Clean Up." Each group card has 2-3 picture steps inside. Students drag individual picture steps into a timeline to show the complete sequence of all 7-9 steps. **Success criteria:** Students correctly expand all group cards and order the detailed steps. _Implementation note: Expand-and-trace activity; group cards "unfold" to reveal steps. CSTA: 1A-AP-AF-02._

Assessment example: Given a 3-card plan where each group contains 2-3 steps, students create a complete 7-9 step timeline by expanding each group card.

Dependencies:
* T11.G1.09: Arrange group cards to form a complete plan
* T11.GK.04: Predict what happens when a group card is used

---

ID: T11.G1.11
Topic: T11 – Functions & Organization
Skill: Predict outcome when group card details change
Description: **Student task:** A group card is used with different specific details each time, and students predict what will be different in the outcome. **Visual scenario:** A "Set the Table" plan uses the "Put [item] on Table" group card three times with different items: first "plates," then "cups," then "napkins." Students predict what will be on the table after each card is used. **Success criteria:** Students correctly identify that the same group card with different details produces different (but related) results. _Implementation note: Drag items onto table image after each card; visual shows cumulative result. CSTA: 1A-AP-AF-02._

Assessment example: Given "Put [item] on Table" used three times with plates, cups, and napkins, students drag the correct items onto the table after each step, showing understanding that the same card produces different results with different details.

Dependencies:
* T11.G1.10: Trace through a plan that uses group cards
* T11.GK.04: Predict what happens when a group card is used

---

ID: T11.G2.01
Topic: T11 – Functions & Organization
Skill: Write a note card explaining a section's purpose
Description: Students write a short note card and attach it near a group of picture steps to explain why that section is there (e.g., "These steps are to get ready," "These steps are to clean up"). This is an unplugged analogue of code comments.

Assessment example: Given a picture plan with three sections, students write three note cards explaining each section's purpose and place them next to the appropriate groups.

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed

---

ID: T11.G2.02
Topic: T11 – Functions & Organization
Skill: Replace vague labels with clear descriptive titles
Description: Students identify vague or unclear section titles in a plan (e.g., "Stuff," "More things") and replace them with clearer titles that match the steps underneath (e.g., "Set up chairs," "Decorate the room"). They cross out bad labels and write better ones.

Assessment example: Given a plan with labels "Thing 1," "Other Stuff," and "Last Part," students examine each section's picture cards and rewrite the labels as "Gather Supplies," "Build the Project," and "Clean Up."

Dependencies:
* T11.G1.02: Match picture step groups to clear titles

---

ID: T11.G2.03
Topic: T11 – Functions & Organization
Skill: Edit section titles to follow a consistent style
Description: Students review several section titles for one plan (e.g., "Set up," "Playing the game," "Clean up time!") and edit them to follow a similar style (for example, all starting with action words like "Set Up," "Play Game," "Clean Up"). This builds awareness of consistent naming.

Assessment example: Given titles "Getting ready," "PLAY!!!", and "clean-up time," students rewrite all three in a consistent style: "Get Ready," "Play the Game," "Clean Up."

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed

---

ID: T11.G2.04
Topic: T11 – Functions & Organization
Skill: Sort picture cards under category headings
Description: Students see 2–3 headings (e.g., "Before class," "During class," "After class") and a mixed set of picture step cards, then drag each card under the heading where it belongs. This extends the Grade 1 idea of splitting lists into clearly labeled sections.

Assessment example: Given headings "Morning," "Lunch," "Afternoon" and 9 mixed picture cards, students drag each card under the correct heading, creating three organized groups.

Dependencies:
* T03.G1.02: Drag part cards into function-based groups
* T03.G1.03: List steps for a simple classroom routine

---

ID: T11.G2.05
Topic: T11 – Functions & Organization
Skill: Label activity groups for clarity, not just repetition
Description: Students decide whether to create labeled groups based on organization benefits, not just repetition. Some groups should be named and separated even if they only happen once, because they represent distinct phases. For example, "Check Safety Rules" might happen only once but deserves its own label for clarity.

Assessment example: Given a field trip plan, students mark which activity groups should get labels: some because they repeat (like "count students"), others because they're important distinct phases (like "review safety rules" or "board the bus") even though they happen only once.

Dependencies:
* T11.G1.08: Decide between one label or multiple similar labels
* T03.G2.01: Choose subtasks for a simple project idea

---

ID: T11.G2.06
Topic: T11 – Functions & Organization
Skill: Organize a plan into 3-5 labeled groups
Description: Students organize a moderately complex activity plan into 3-5 labeled groups that work together to accomplish the overall goal. They identify natural boundaries between groups and give each a clear name. This builds decomposition skills: breaking a large plan into coordinated, named pieces.

Assessment example: For a "make and serve snacks" activity, students create labels for: "Wash Hands," "Prepare Snacks," "Set Table," "Serve Snacks," "Clean Up," drawing boundaries between groups and explaining how each contributes to the whole activity.

Dependencies:
* T11.G2.05: Label activity groups for clarity, not just repetition
* T03.G2.02: Drag subtask cards into type-based category boxes

---

ID: T11.G2.07
Topic: T11 – Functions & Organization
Skill: Draw arrows showing which groups must happen first
Description: Students draw arrows between labeled groups to show when one must happen before another, and identify groups that can happen in any order. They use simple language like "you must do Wash Hands before Prepare Snacks" or "Set Table can happen before or after Prepare Snacks."

Assessment example: Given 5 labeled activity groups for a class party, students draw arrows showing dependencies (e.g., "Set Up" → "Play Games" → "Clean Up") and circle groups that can happen in any order, explaining their reasoning.

Dependencies:
* T11.G2.06: Organize a plan into 3-5 labeled groups
* T01.G2.01: Identify pictures that must stay in order vs those that can swap

---

ID: T11.G2.08
Topic: T11 – Functions & Organization
Skill: Sort labels into reusable vs. plan-specific categories
Description: Students identify labeled activity groups that could be useful in multiple different plans, not just the current one. For example, "Wash Hands" and "Clean Workspace" are useful in many activities (art, science, cooking). They sort labels into "reusable" and "plan-specific" categories.

Assessment example: After creating labeled groups for a cooking activity, students sort labels into two boxes: "Only for cooking" (like "Mix Ingredients") and "Useful for other activities" (like "Wash Hands" or "Clean Up"), then name two other activities where reusable labels could be used.

Dependencies:
* T11.G2.06: Organize a plan into 3-5 labeled groups

---

ID: T11.G2.09
Topic: T11 – Functions & Organization
Skill: Write one-sentence purpose descriptions for each group
Description: Students write one sentence describing what each labeled activity group is meant to accomplish and why it's part of the overall plan. This focuses on the WHAT and WHY (the group's purpose) rather than HOW (the specific steps inside). This prepares students to design and document custom blocks with clear purposes.

Assessment example: For a classroom activity broken into labeled groups, students complete sentences like "The Setup Group gets everything ready so we can start the activity" and "The Practice Group helps us learn the new skill before we try it ourselves."

Dependencies:
* T11.G2.06: Organize a plan into 3-5 labeled groups
* T02.G2.01: Turn a picture routine into labeled boxes

---

ID: T11.G2.10
Topic: T11 – Functions & Organization
Skill: Match a simplified plan to its detailed version
Description: Students are shown two versions of the same plan: a simplified version using group cards (e.g., "Get Ready" → "Do Activity" → "Clean Up") and a detailed version showing all individual picture steps. They match the group cards in the simplified plan to the corresponding sections in the detailed plan. This builds abstraction recognition: understanding that a high-level name represents a collection of detailed steps.

Assessment example: Given a 3-step simplified plan ("Setup" → "Play" → "Cleanup") and a 15-step detailed plan, students draw lines connecting each group card to its corresponding section of detailed steps.

Dependencies:
* T11.G2.06: Organize a plan into 3-5 labeled groups
* T11.G1.09: Arrange group cards to form a complete plan

---

ID: T11.G2.11
Topic: T11 – Functions & Organization
Skill: Create a group card with changeable details
Description: **Student task:** Create a group card that works for similar activities by marking which detail can change. **Visual scenario:** "Make a Drink" group could work for juice, milk, or water. Students create a group card "Make a Drink: ___" with a blank for the drink name, showing the same steps (get cup, pour drink, put away) work for any drink. **Success criteria:** Students identify which detail varies and create a flexible group card template. _Implementation note: Fill-in-the-blank group card creation; shows how same steps with different details still use one group. CSTA: 1A-AP-AF-03._

Assessment example: Students create "Make [drink name]" group card and explain how it works for juice, milk, and water with the same steps.

Dependencies:
* T11.G2.06: Organize a plan into 3-5 labeled groups
* T11.G1.06: Create a label card for repeated activity groups

---

ID: T11.G2.12
Topic: T11 – Functions & Organization
Skill: Compare plans with and without group cards to evaluate organization
Description: **Student task:** Evaluate two different versions of the same activity plan and explain which organization is better and why. **Visual scenario:** Students see Plan A (all 15 individual steps visible) and Plan B (5 group cards, each containing 3 steps). They answer questions like: "Which plan is easier to check if you missed a step?" "Which plan is faster to read?" "Which plan is easier to explain to someone else?" **Success criteria:** Students articulate concrete reasons why grouped plans are often better (but sometimes detailed plans are needed). _Implementation note: Side-by-side comparison with guided questions; supports both preferences with reasoning. CSTA: 1A-AP-AB-02._

Assessment example: Students compare a 15-step detailed plan vs a 5-group organized plan and select answers explaining when each version would be more useful (e.g., "The grouped plan is easier to remember" but "The detailed plan is better for someone learning all the steps").

Dependencies:
* T11.G2.10: Match a simplified plan to its detailed version
* T11.GK.07: Explain WHY grouping makes plans easier to follow

---

ID: T11.G3.00.01
Topic: T11 – Functions & Organization
Skill: Connect picture-based grouping to code-based custom blocks
Description: Students view side-by-side comparisons of picture-based grouped activities and code-based custom blocks, identifying the conceptual parallel. They see how a picture card labeled "Clean Up" that contains multiple steps is like a custom block called "CleanUp" that contains multiple code blocks. This bridge skill explicitly connects concrete picture-based abstraction (from K-2) to code-based abstraction (G3+), helping students transfer their understanding of grouping and naming to programming.

Assessment example: Students view pairs of examples (picture plan with "Make Snack" group card + code with "define MakeSnack" custom block) and explain in their own words how the two are similar: both use a single name to represent multiple steps.

Dependencies:
* T11.G2.09: Write one-sentence purpose descriptions for each group
* T02.G3.01: Match a short block script to the right task

---

ID: T11.G3.01
Topic: T11 – Functions & Organization
Skill: Insert a comment block to explain code purpose
Description: Students insert the comment block (// [text]) from the My Blocks category to add simple comments that label or explain parts of their script (e.g., "// Move the cat" or "// Check if score > 10"). This introduces documenting code for others to understand.

Assessment example: Given a 5-block script, students add a comment block above each section explaining its purpose, then another student reads only the comments to describe what the script does.

Dependencies:
* T07.G3.02: Trace a script with a simple loop
* T11.G2.01: Write a note card explaining a section's purpose

---

ID: T11.G3.02
Topic: T11 – Functions & Organization
Skill: Write a header comment summarizing script purpose
Description: Students add a comment block (// [text]) at the beginning of a script, right after the hat block, that summarizes the script's purpose and role in the larger program (e.g., "// Game initialization: sets lives to 3, resets score, shows start screen"). This is a first step toward systematic documentation.

Assessment example: Given three scripts without header comments, students write appropriate header comments that summarize what each script does in one sentence.

Dependencies:
* T09.G3.02: Use a variable in a conditional (if block)
* T11.G3.01: Insert a comment block to explain code purpose

---

ID: T11.G3.03
Topic: T11 – Functions & Organization
Skill: Rename vague variables to descriptive names
Description: Students examine a script with unclear variable names (e.g., "x", "temp", "v1") and rename them to be more descriptive and meaningful (e.g., "playerScore", "enemySpeed", "livesRemaining"). They identify vague names and replace them with names that clearly indicate what the variable represents.

Assessment example: Given a script with variables named "a", "x", and "n", students rename them to "score", "playerX", and "livesLeft" based on how they're used in the code.

Dependencies:
* T09.G3.01: Create a variable and set its starting value
* T07.G3.03: Build a forever loop for simple animation
* T08.G3.04: Use a simple if in a script
* T11.G3.01: Insert a comment block to explain code purpose

---

ID: T11.G3.04
Topic: T11 – Functions & Organization
Skill: Merge consecutive similar blocks into one efficient block
Description: Students identify patterns of similar consecutive blocks (e.g., multiple "move 10 steps" blocks or repeated "change score by 1" blocks) and combine them into single, more efficient blocks with appropriate values (e.g., "move 30 steps" or "change score by 3"). This reduces redundancy and makes code cleaner.

Assessment example: Given a script with "move 10 steps" repeated 5 times, students delete 4 blocks and change the remaining one to "move 50 steps", verifying the behavior is the same.

Dependencies:
* T07.G3.03: Build a forever loop for simple animation
* T11.G3.01: Insert a comment block to explain code purpose

---

ID: T11.G3.05
Topic: T11 – Functions & Organization
Skill: Describe how multiple scripts work together in a project
Description: Students write or select explanations for how the scripts in a project interact and fit together (e.g., "The green-flag script sets up the game, and the key-press scripts let the player control the character"). This develops understanding of overall code organization.

Assessment example: Given a project with 4 scripts, students write one sentence describing each script's role and draw arrows showing how they relate (e.g., "Setup script initializes variables that Game script uses").

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T06.G3.02: Add a second event to the same sprite
* T08.G3.03: Pick the right conditional block for a scenario
* T11.G3.02: Write a header comment summarizing script purpose

---

ID: T11.G3.06
Topic: T11 – Functions & Organization
Skill: Define a custom block without parameters
Description: Students create simple custom blocks without parameters using CreatiCode's define syntax. In the My Blocks category, they create a custom block with a descriptive, action-based name (e.g., define (draw square)) that groups 3-5 related blocks. The focus is on understanding how to define a reusable block using the define (BLOCKSIGNATURE) syntax.

Assessment example: Students create a custom block named "DrawSquare" that contains 4 blocks (repeat 4: move 50 steps, turn 90 degrees) and verify it works when called.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use a counted repeat loop
* T11.G3.03: Rename vague variables to descriptive names

---

ID: T11.G3.07
Topic: T11 – Functions & Organization
Skill: Call a custom block using the call syntax
Description: Students call a custom block they created using the call syntax (e.g., call draw square). They replace repeated code in their main script with calls to the custom block, experiencing how custom blocks make code more organized and easier to read.

Assessment example: Students take a script with repeated code and replace 3 identical sections with "call DrawSquare", verifying the program still works correctly.

Dependencies:
* T11.G3.06: Define a custom block without parameters
* T11.G3.04: Merge consecutive similar blocks into one efficient block

---

ID: T11.G3.08
Topic: T11 – Functions & Organization
Skill: Document a custom block with a purpose comment
Description: Students add a comment block (// [text]) at the beginning of a custom block's definition to describe what the block does and when to use it (e.g., "// Draws a square with side length 50"). This extends documentation skills to custom blocks.

Assessment example: Students add documentation comments to 3 custom blocks, each comment explaining in one sentence what the block does.

Dependencies:
* T11.G3.06: Define a custom block without parameters
* T11.G3.02: Write a header comment summarizing script purpose

---

ID: T11.G3.09
Topic: T11 – Functions & Organization
Skill: Distinguish custom blocks from built-in blocks
Description: Students learn that CreatiCode has two types of blocks: built-in blocks (provided by CreatiCode, like "move 10 steps" or "say Hello") and custom blocks (created by programmers, found in the "My Blocks" category). They examine several example projects and identify which blocks are custom (defined by the programmer) versus built-in (provided by the system). They understand that custom blocks are tools programmers create to organize their own code.

Assessment example: Given a script with 8-10 blocks including some from "Motion," "Looks," and "My Blocks" categories, students identify which blocks are custom (from My Blocks) and which are built-in, explaining how they can tell.

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T02.G3.01: Match a short block script to the right task

---

ID: T11.G3.10
Topic: T11 – Functions & Organization
Skill: Distinguish when to use custom blocks vs loops
Description: Students identify scenarios where a custom block (called "My Block" in CreatiCode) is more appropriate than a loop. They recognize that loops repeat the SAME action multiple times, while custom blocks group a SEQUENCE of different actions for reuse or organization. Given example scripts or problems, they choose the better organizational approach and explain their reasoning. This conceptual gateway skill builds organizational thinking without requiring students to define custom blocks yet.

Assessment example: Present 3-4 scenarios (e.g., "draw a house," "move 10 steps 5 times," "reset game state," "count to 10"). Students label each as better solved with a loop or a custom block and explain why.

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T07.G3.02: Trace a script with a simple loop
* T01.G3.12: Predict the final state of a simple algorithm

---

ID: T11.G3.10.01
Topic: T11 – Functions & Organization
Skill: Trace what happens inside a custom block definition
Description: Students trace step-by-step through a simple custom block definition (3-5 blocks) to predict what the sprite will do when the block is called. They number each block inside the definition in execution order and describe the final state. This builds mental models of how custom block definitions execute before students create their own.

Assessment example: Given `define (Greet)` with `say [Hello]`, `wait 1 seconds`, `say [Goodbye]`, students number blocks 1-3 and describe: "First says Hello, waits 1 second, then says Goodbye."

Dependencies:
* T11.G3.09: Distinguish custom blocks from built-in blocks
* T07.G3.02: Trace a script with a simple loop

---

ID: T11.G3.10.02
Topic: T11 – Functions & Organization
Skill: Predict parameter flow through custom block calls
Description: Students trace how a value flows from where a custom block is called into the block's definition. Given `call DrawSquare [50]` and `define (DrawSquare [size])` with `move [size] steps`, students trace that 50 flows into [size], so the sprite moves 50 steps. They use a simple diagram showing: "50 → [size] → move 50 steps." This builds understanding of how parameters work before creating their own parameterized blocks.

Assessment example: Given `call Greet [Ada]` and `define (Greet [name])` with `say (join [Hello ] [name])`, students trace the flow: "Ada → [name] → says 'Hello Ada'."

Dependencies:
* T11.G3.10.01: Trace what happens inside a custom block definition
* T11.G3.11: Experiment with pre-made custom blocks to observe parameter effects

---

ID: T11.G3.11
Topic: T11 – Functions & Organization
Skill: Experiment with pre-made custom blocks to observe parameter effects
Description: Students use an existing custom block (e.g., `call DrawRectangle [50] [30]` or `call MoveSprite [100] [200]`) provided in a starter project, and experiment with different argument values to see how the block's behavior changes. They learn that arguments (values in square brackets when calling) let one block handle many situations. Students do not create the block themselves yet; they explore how calling a pre-made block with different values produces different results.

Assessment example: Given a starter project with `call DrawShape [sides] [size]`, students try different values like `call DrawShape [3] [50]` for a triangle and `call DrawShape [6] [30]` for a hexagon, observing how the same block creates different shapes.

Dependencies:
* T11.G3.09: Distinguish custom blocks from built-in blocks
* T08.G3.02: Decide when a single if is enough
* T09.G3.01.04: Display variable value on stage using the variable monitor

---

ID: T11.G3.12
Topic: T11 – Functions & Organization
Skill: Identify repeated or grouped actions that could become custom blocks
Description: Students examine a longer script (15-30 blocks) that is ALREADY WRITTEN and identify groups of blocks that appear multiple times OR represent distinct behaviors. They draw boxes around these groups and label each with a descriptive name (e.g., "ResetPlayer," "CheckWinCondition"). This builds the habit of recognizing natural custom block boundaries IN EXISTING CODE before actually creating them. This is ANALYSIS of existing code, as opposed to DESIGN before coding (covered in G5.01.01).

Assessment example: Given a 20-block script for a maze game, students circle and label groups like "move character," "check wall collision," and "update score display," explaining why each group makes sense as a potential custom block.

Dependencies:
* T11.G3.11: Experiment with pre-made custom blocks to observe parameter effects
* T09.G3.02: Use a variable in a conditional (if block)
* T08.G3.03: Pick the right conditional block for a scenario

---

ID: T11.G3.13
Topic: T11 – Functions & Organization
Skill: Identify reporter blocks in existing code
Description: Students learn to recognize reporter blocks (blocks with rounded shapes that fit inside input slots) versus command blocks (blocks that perform actions and stack vertically). Using existing CreatiCode projects, they identify reporter blocks like `(pick random 1 to 10)`, `(distance to [sprite])`, or `(x position)` and observe where these blocks can be used (inside input slots of other blocks). This prepares students to understand return values from custom reporter blocks in later grades.

Assessment example: Given 10-12 different blocks from various categories, students sort them into "reporter blocks" (rounded, return a value) and "command blocks" (rectangular, do an action) and show one example of where each type can be used in a script.

Dependencies:
* T11.G3.12: Identify repeated or grouped actions that could become custom blocks
* T09.G3.04: Debug a single missing or wrong variable block
* T07.G3.04: Use repeat-until to reach a simple goal

---

ID: T11.G3.14
Topic: T11 – Functions & Organization
Skill: Navigate the "Make a Block" interface and create empty blocks
Description: Students open CreatiCode's "My Blocks" category, click "Make a Block," and navigate the basic interface. They type a simple block name (without parameters, like "ResetGame" or "JumpUp") and observe the preview of how the block will look. After clicking OK, they see the `define (ResetGame)` hat block appear, understanding this is where they add the block's code. They practice this process 2-3 times with different names.

Assessment example: Students open the "Make a Block" dialog, type three different simple block names ("StartGame", "ShowMenu", "PlaySound"), observe each preview, click OK to see the define block appear, and explain what the define block is for.

Dependencies:
* T11.G3.13: Identify reporter blocks in existing code
* T07.G3.04: Use repeat-until to reach a simple goal
* T09.G3.01.04: Display variable value on stage using the variable monitor

---

ID: T11.G3.15
Topic: T11 – Functions & Organization
Skill: Add one parameter to a custom block interface
Description: Students extend their exploration of the "Make a Block" interface by adding a single parameter. They click "Add an input number or text," name the parameter (e.g., "size"), see it appear in the block preview as `myBlock [size]`, and understand this placeholder will accept a value when the block is called. They do not implement the block's behavior yet—just practice creating the interface.

Assessment example: Students create three custom block interfaces with one parameter each: "DrawCircle [radius]", "Jump [height]", "SetSpeed [speed]". They explain what each parameter represents.

Dependencies:
* T11.G3.14: Navigate the "Make a Block" interface and create empty blocks
* T09.G3.01: Create a variable and set its starting value

---

ID: T11.G3.16
Topic: T11 – Functions & Organization
Skill: Debug a custom block that doesn't run
Description: Students diagnose why a custom block doesn't execute when expected. Common issues include: (1) the block was defined but never called, (2) the call block is in a script that never runs (no hat block), (3) the block name in call doesn't match the definition. Students identify the problem and fix it. This builds debugging skills specific to custom blocks.

Assessment example: Given a project where "DrawSquare" is defined but the sprite doesn't draw anything, students identify that the "call DrawSquare" block is missing and add it to the green flag script.

Dependencies:
* T11.G3.07: Call a custom block using the call syntax
* T12.G3.04: Identify and fix common block arrangement errors

---

ID: T11.G3.17
Topic: T11 – Functions & Organization
Skill: Explain why custom blocks make code easier to read
Description: Students compare two versions of the same program: one with repeated code and one using custom blocks. They explain in their own words why the custom block version is easier to understand, modify, and debug. This builds metacognitive awareness of code organization benefits.

Assessment example: Given two scripts that do the same thing (one with 20 blocks including repeated code, one with 8 blocks using custom blocks), students explain: "The second version is better because you can see 'DrawHouse' instead of reading all the drawing steps each time."

Dependencies:
* T11.G3.07: Call a custom block using the call syntax
* T11.G3.12: Identify repeated or grouped actions that could become custom blocks

---

ID: T11.G4.01
Topic: T11 – Functions & Organization
Skill: Create a custom block with one number parameter
Description: Students define a complete custom block with one number parameter and implement its behavior. For example, they create `define (DrawSquare [size])` and use the [size] parameter inside the block definition (e.g., in `move [size] steps`). They test the block with different values, verifying that `call DrawSquare [50]` creates a different size square than `call DrawSquare [100]`.

Assessment example: Students create a "DrawSquare [size]" custom block, use the parameter to control side length, and test with 3 different values to verify it works correctly.

Dependencies:
* T11.G3.15: Add one parameter to a custom block interface
* T07.G4.03: Use a variable as the loop counter
* T09.G4.01: Initialize variables with descriptive names
* T11.G3.11: Experiment with pre-made custom blocks to observe parameter effects

---

ID: T11.G4.01.01
Topic: T11 – Functions & Organization
Skill: Use the argument block to access parameter values inside a definition
Description: Students learn CreatiCode's `(argument (ARGUMENTNAME))` syntax for accessing parameter values inside a custom block definition. When they create `define (Jump [height])`, they use `(argument (height))` inside the definition to get the value passed by the caller. They understand that argument blocks are reporter blocks (rounded shape) that can be used anywhere a value is needed inside the definition.

Assessment example: Students create `define (SayTwice [message])` and use `(argument (message))` in two `say` blocks to make the sprite say the message twice. They verify that `call SayTwice [Hello]` results in saying "Hello" twice.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T11.G3.13: Identify reporter blocks in existing code

---

ID: T11.G4.02
Topic: T11 – Functions & Organization
Skill: Call a custom block with different parameter values
Description: Students call their parameterized custom block multiple times with different values to accomplish different tasks. For example, after creating "DrawSquare [size]", they write a script that calls `DrawSquare [30]`, `DrawSquare [50]`, `DrawSquare [70]` to draw three squares of increasing size. This demonstrates the reusability and flexibility of parameterized blocks.

Assessment example: Students create a pattern or animation by calling the same custom block 3-5 times with different parameter values.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T07.G4.02: Nest one loop inside another

---

ID: T11.G4.03
Topic: T11 – Functions & Organization
Skill: Replace hard-coded values with parameters
Description: Students take an existing custom block with hard-coded values and refactor it to use parameters instead, making it more flexible. For example, they transform `define (DrawTriangle)` with `move 50 steps` into `define (DrawTriangle [size])` with `move [size] steps`. They compare the original and refactored versions and explain the benefits of using parameters.

Assessment example: Given a custom block with 2-3 hard-coded values, students identify which values should become parameters, add the parameters, and replace the hard-coded values with parameter references.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T09.G4.02: Update a variable's value based on game events

---

ID: T11.G4.04
Topic: T11 – Functions & Organization
Skill: Compose built-in reporter blocks in expressions and conditions
Description: Students use built-in reporter blocks (rounded blocks that return values) inside other blocks, building more complex expressions. For example, they use `(pick random 1 to 10)` inside `move ( ) steps`, or `(distance to [sprite])` inside an if condition `< (distance to [sprite]) < [50] >`. They recognize that reporter blocks can be nested and combined to create sophisticated behaviors.

Assessment example: Students create scripts that use at least 3 different reporter blocks in various contexts: in motion blocks, in operators, and in conditionals.

Dependencies:
* T11.G3.13: Identify reporter blocks in existing code
* T08.G4.07: Write if-else with two different outcomes
* T09.G4.02: Update a variable's value based on game events

---

ID: T11.G4.05
Topic: T11 – Functions & Organization
Skill: Organize a project with 3-4 custom blocks
Description: Students decompose a project into 3-4 distinct custom blocks, each with a clear responsibility. For example, a simple game might have "SetupGame", "UpdateScore [points]", "CheckWinCondition", and "ResetLevel". They implement all blocks and coordinate them in a main script. This builds project organization skills.

Assessment example: Students create a complete project using 3-4 custom blocks, each documented with a purpose comment, and explain how the blocks work together.

Dependencies:
* T11.G4.02: Call a custom block with different parameter values
* T09.G4.03: Use multiple variables for different purposes
* T11.G3.05: Describe how multiple scripts work together in a project

---

ID: T11.G4.06
Topic: T11 – Functions & Organization
Skill: Add a boolean parameter to control block behavior
Description: Students create a custom block with a boolean (true/false) parameter that controls conditional behavior inside the block. For example, `define (MoveFigure [shouldJump])` uses an if block to check the parameter: `if <[shouldJump]> then [jump animation] else [walk animation]`. They call the block with both true and false to see different behaviors.

Assessment example: Students create a custom block with a boolean parameter, implement conditional logic based on the parameter, and demonstrate calling it with both true and false values.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T08.G4.10: Combine multiple conditions with AND
* T09.G4.04: Choose between number and text variables

---

ID: T11.G4.07
Topic: T11 – Functions & Organization
Skill: Document parameter purpose and expected values
Description: Students add comments to custom blocks that explain what each parameter is for and what values are expected. For example: `// DrawShape [sides] [size]: Draws a polygon. sides = 3 to 12, size = 10 to 200`. This prepares students for API design thinking.

Assessment example: Students document 2-3 custom blocks with parameter descriptions, including expected value ranges or types for each parameter.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T11.G3.08: Document a custom block with a purpose comment

---

ID: T11.G4.08
Topic: T11 – Functions & Organization
Skill: Create a custom block with two parameters
Description: Students create custom blocks with two parameters that work together. For example, `define (DrawRectangle [width] [height])` or `define (MoveTo [x] [y])`. They implement the block using both parameters and test with various combinations of values.

Assessment example: Students create a "DrawRectangle [width] [height]" block and test it with at least 3 different combinations of width and height values.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T09.G4.03: Use multiple variables for different purposes

---

ID: T11.G4.09
Topic: T11 – Functions & Organization
Skill: Identify custom blocks that share similar code
Description: Students examine 2-3 related custom blocks and identify code patterns that appear in multiple blocks. For example, three different "Draw" blocks might all start with "pen down" and end with "pen up". They highlight shared code and consider whether it should be extracted into its own block. This introduces the concept of factoring out common code.

Assessment example: Given three custom blocks, students highlight code that appears in multiple blocks and explain what benefits extracting it would provide.

Dependencies:
* T11.G4.05: Organize a project with 3-4 custom blocks
* T11.G3.12: Identify repeated or grouped actions that could become custom blocks

---

ID: T11.G4.10
Topic: T11 – Functions & Organization
Skill: Call one custom block from inside another
Description: Students create custom blocks that call other custom blocks, building hierarchical organization. For example, `define (DrawHouse)` might call `DrawRectangle [100] [80]` and `DrawTriangle [100]` to compose a house from simpler shapes. This demonstrates how complex behaviors can be built from simpler building blocks.

Assessment example: Students create 3 custom blocks where at least one block calls another custom block in its implementation, and explain how this organization makes code easier to understand.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T11.G4.05: Organize a project with 3-4 custom blocks

---

ID: T11.G4.10.01
Topic: T11 – Functions & Organization
Skill: Trace execution through nested custom block calls
Description: Students trace step-by-step through a script that calls a custom block which itself calls other custom blocks. They create an execution trace showing the order of operations: main script → first custom block → nested custom block → back to first custom block → back to main script. This builds understanding of the call stack concept at an intuitive level.

Assessment example: Given a main script that calls "DrawHouse" which calls "DrawRectangle" and "DrawTriangle", students create a numbered trace showing all blocks executed in order, including which custom block they're inside at each step.

Dependencies:
* T11.G4.10: Call one custom block from inside another
* T11.G3.10.01: Trace what happens inside a custom block definition

---

ID: T11.G4.10.02
Topic: T11 – Functions & Organization
Skill: Debug nested custom block execution order issues
Description: Students diagnose and fix bugs caused by incorrect understanding of nested custom block execution. Common issues include: (1) expecting nested block to run after the outer block finishes (it runs during), (2) incorrect assumptions about what state exists when a nested block runs, (3) wrong parameter values passed to nested calls. They trace execution order to identify the problem.

Assessment example: Given a "DrawHouse" block that calls "DrawDoor [small]" but the door appears in the wrong position, students trace execution to find that DrawDoor runs before the position is set for the door location, and fix it by moving blocks into the correct order.

Dependencies:
* T11.G4.10.01: Trace execution through nested custom block calls
* T11.G3.16: Debug a custom block that doesn't run

---

ID: T11.G4.11
Topic: T11 – Functions & Organization
Skill: Choose descriptive action-based names for custom blocks
Description: Students evaluate and improve custom block names, following conventions: use action verbs, be specific about what the block does, avoid vague names. For example, "Draw" is vague; "DrawSquare" is better; "DrawSquare [size]" with descriptive parameter is best. They rename poorly-named blocks and explain their improvements.

Assessment example: Given 5 custom blocks with poor names ("DoStuff", "Thing", "Run", "X", "Block1"), students rename them with clear action-based names and explain why each new name is better.

Dependencies:
* T11.G4.05: Organize a project with 3-4 custom blocks
* T11.G3.03: Rename vague variables to descriptive names

---

ID: T11.G4.12
Topic: T11 – Functions & Organization
Skill: Organize related custom blocks into logical groups
Description: Students organize multiple custom blocks by function or purpose, using naming conventions or comments to group related blocks. For example, all drawing blocks start with "Draw", all game state blocks start with "Setup" or "Reset", all checking blocks start with "Check". This introduces namespace organization thinking.

Assessment example: Students create 6-8 custom blocks for a project and organize them into 2-3 logical groups using consistent naming prefixes, documenting each group's purpose.

Dependencies:
* T11.G4.11: Choose descriptive action-based names for custom blocks
* T11.G4.05: Organize a project with 3-4 custom blocks

---

ID: T11.G4.13
Topic: T11 – Functions & Organization
Skill: Decide when to create a new custom block vs add to existing
Description: Students make design decisions about whether to create a new custom block or extend an existing one. They consider factors like: Does this belong with existing functionality? Is the existing block getting too complex? Would a parameter handle this variation? They practice this decision-making with multiple scenarios.

Assessment example: Given 4-5 scenarios describing new functionality to add, students decide for each whether to create a new custom block or modify an existing one, explaining their reasoning.

Dependencies:
* T11.G4.10: Call one custom block from inside another
* T11.G4.09: Identify custom blocks that share similar code

---

ID: T11.G4.14
Topic: T11 – Functions & Organization
Skill: Extract repeated code into a helper custom block
Description: Students identify code that appears in multiple places and extract it into a new "helper" custom block that is called from the original locations. For example, if three custom blocks all have identical setup code, they create a "DoSetup" helper block and call it from all three. This is practical refactoring.

Assessment example: Students find code repeated in 2-3 places, extract it into a new helper block, replace the original code with calls to the helper, and verify the program still works.

Dependencies:
* T11.G4.09: Identify custom blocks that share similar code
* T11.G4.10: Call one custom block from inside another

---

ID: T11.G4.15
Topic: T11 – Functions & Organization
Skill: Use consistent parameter ordering across related blocks
Description: Students ensure that related custom blocks use parameters in a consistent order. For example, if "DrawRectangle [width] [height]" puts width first, then "DrawOval [width] [height]" should also put width first. They review existing blocks and reorder parameters for consistency.

Assessment example: Given 3-4 related custom blocks with inconsistent parameter ordering, students identify inconsistencies and reorder parameters to be consistent, explaining why consistency matters.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T11.G4.12: Organize related custom blocks into logical groups

---

ID: T11.G4.16
Topic: T11 – Functions & Organization
Skill: Test custom blocks independently before integration
Description: Students create simple test scripts for individual custom blocks before using them in larger projects. For example, they create a test script that calls "DrawSquare [size]" with several different values to verify it works correctly before using it in "DrawHouse". This introduces basic unit testing concepts.

Assessment example: Students create test scripts for 2-3 custom blocks, each testing the block with multiple different parameter values and verifying the results.

Dependencies:
* T11.G4.02: Call a custom block with different parameter values
* T11.G4.07: Document parameter purpose and expected values

---

ID: T11.G4.17
Topic: T11 – Functions & Organization
Skill: Identify side effects in custom blocks
Description: Students learn to recognize when custom blocks have "side effects" - they change things beyond their return value, like moving a sprite, changing a variable, or playing a sound. They examine custom blocks and categorize them by their side effects, understanding that some blocks are designed to change state while others just return information.

Assessment example: Given 5-6 custom blocks, students identify what each block changes (sprite position, variables, appearance, sounds) and explain whether those changes are intentional parts of the block's purpose.

Dependencies:
* T11.G4.05: Organize a project with 3-4 custom blocks
* T09.G4.02: Update a variable's value based on game events

---

ID: T11.G4.18
Topic: T11 – Functions & Organization
Skill: Design a custom block interface before implementation
Description: Students practice planning custom blocks by writing the block signature (name and parameters) and a purpose comment BEFORE writing any code. They think through what parameters are needed and what the block should accomplish. This introduces design-before-implementation thinking.

Assessment example: Students plan 3 custom blocks for a project by writing their signatures and purpose comments first, then get peer feedback on the design before implementing.

Dependencies:
* T11.G4.07: Document parameter purpose and expected values
* T11.G4.11: Choose descriptive action-based names for custom blocks

---

ID: T11.G4.19
Topic: T11 – Functions & Organization
Skill: Use text parameters for custom blocks
Description: Students create custom blocks that accept text parameters in addition to number parameters. For example, `define (Greet [name])` uses the text parameter in `say [join [Hello ] [name]]`. They explore how text parameters enable flexible, data-driven block behavior.

Assessment example: Students create a custom block with a text parameter and demonstrate calling it with 3 different text values.

Dependencies:
* T11.G4.01: Create a custom block with one number parameter
* T09.G4.04: Choose between number and text variables

---

ID: T11.G4.20
Topic: T11 – Functions & Organization
Skill: Combine number and text parameters in one block
Description: Students create custom blocks with multiple parameters of different types (numbers and text). For example, `define (ShowMessage [message] [duration])` combines a text message with a number duration. They understand how mixed parameter types enable more flexible blocks.

Assessment example: Students create a custom block with at least one text and one number parameter, implement it, and test with various combinations.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T11.G4.19: Use text parameters for custom blocks

---

ID: T11.G4.21
Topic: T11 – Functions & Organization
Skill: Review and refactor custom block organization
Description: Students review a project with 5-8 custom blocks and refactor the organization for clarity: renaming blocks, reordering parameters, merging similar blocks, splitting overly complex blocks, improving documentation. This is a comprehensive organization review skill.

Assessment example: Students review a provided project with poorly organized custom blocks and create an improved version, documenting all changes made and explaining why each improves the organization.

Dependencies:
* T11.G4.12: Organize related custom blocks into logical groups
* T11.G4.13: Decide when to create a new custom block vs add to existing
* T11.G4.14: Extract repeated code into a helper custom block

---

ID: T11.G4.22
Topic: T11 – Functions & Organization
Skill: Debug custom blocks with wrong parameter values
Description: Students diagnose and fix bugs where custom blocks don't work as expected because of parameter issues: wrong order of arguments, missing arguments, wrong data types (text instead of number), or values out of expected range. They trace parameter values through the block to find the error.

Assessment example: Given a "DrawRectangle [width] [height]" block that's drawing squares instead of rectangles, students identify that the caller is passing the same value for both parameters (e.g., "call DrawRectangle [50] [50]" instead of different values).

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T12.G4.03: Test alternative implementations to find bugs

---

ID: T11.G4.23
Topic: T11 – Functions & Organization
Skill: Identify when NOT to create a custom block
Description: Students recognize situations where creating a custom block would be over-engineering: code that only runs once, trivial 1-2 block sequences, or code that differs significantly each time. They apply the principle "if it's not repeated and not complex, don't make it a block." This prevents unnecessary abstraction.

Assessment example: Given 5 code snippets, students categorize each as "should be a custom block" or "should stay as inline code" and explain their reasoning. (E.g., a single "say Hello" block should NOT become a custom block.)

Dependencies:
* T11.G4.09: Identify custom blocks that share similar code
* T11.G3.12: Identify repeated or grouped actions that could become custom blocks

---

ID: T11.G4.23.01
Topic: T11 – Functions & Organization
Skill: Evaluate code organization trade-offs
Description: Students evaluate competing approaches to organizing the same code, weighing trade-offs like readability vs flexibility, simplicity vs reusability, and number of blocks vs block complexity. Given two different organization schemes for the same functionality, they analyze pros and cons of each and make a reasoned choice. This builds judgment about when different organizational approaches are appropriate.

Assessment example: Given the same game mechanic organized two ways—(A) one large block with all logic, or (B) three smaller blocks that call each other—students list pros and cons of each approach and recommend which is better for a beginner-friendly project vs a complex game.

Dependencies:
* T11.G4.23: Identify when NOT to create a custom block
* T11.G4.14: Extract repeated code into a helper custom block

---

ID: T11.G5.01
Topic: T11 – Functions & Organization
Skill: Design custom block interfaces for a project before coding
Description: Students plan all custom blocks for a project BEFORE writing implementation code. They create a design document listing each block's name, parameters, purpose, and how blocks will interact. This is design-first development.

Assessment example: Students write a design document for a game project specifying 5-7 custom blocks with complete signatures and purpose descriptions, then implement the project following the design.

Dependencies:
* T11.G4.18: Design a custom block interface before implementation
* T11.G4.21: Review and refactor custom block organization

---

ID: T11.G5.01.01
Topic: T11 – Functions & Organization
Skill: Decompose project requirements into custom block responsibilities
Description: Students analyze project requirements (written description or user stories) and identify what custom blocks are needed, what each should do, and how they work together. This is requirements analysis for code organization. For example, given "Create a game where the player collects coins and avoids enemies, with increasing difficulty," students identify blocks like "SpawnCoin", "SpawnEnemy", "CheckCollision [type]", "UpdateDifficulty", etc.

Assessment example: Given a 2-3 paragraph project description, students create a list of 6-8 custom blocks with names, parameters, and brief purpose statements that would be needed to implement the project.

Dependencies:
* T11.G5.01: Design custom block interfaces for a project before coding
* T11.G4.18: Design a custom block interface before implementation

---

ID: T11.G5.02
Topic: T11 – Functions & Organization
Skill: Use the return block to send a value from a custom block
Description: Students learn the `return [VALUE]` block syntax in CreatiCode's My Blocks category. They understand that `return` sends a value back to wherever the block was called, and that code after `return` does not execute. They create simple custom blocks that calculate and return a value using the `return [VALUE]` block.

Assessment example: Students create `define (DoubleIt [num])` containing `return [([num] * 2)]` and verify that `set [result] to (report DoubleIt [5])` sets result to 10.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T10.G5.01: Calculate with arithmetic expressions (nested operators)
* T11.G3.13: Identify reporter blocks in existing code

---

ID: T11.G5.02.02
Topic: T11 – Functions & Organization
Skill: Call a custom reporter block using report syntax
Description: Students learn to call custom reporter blocks using CreatiCode's `report` syntax. Unlike command blocks called with `call BlockName [args]`, reporter blocks are called with `report BlockName [args]` which returns a value. They practice using reporter calls in expressions, variable assignments, and conditions.

Assessment example: Students use `report CalculateScore [10] [2]` inside expressions like `set [total] to ((total) + (report CalculateScore [10] [2]))` and in conditions like `if <(report CalculateScore [10] [2]) > [15]>`.

Dependencies:
* T11.G5.02: Use the return block to send a value from a custom block
* T11.G4.04: Compose built-in reporter blocks in expressions and conditions

---

ID: T11.G5.02.03
Topic: T11 – Functions & Organization
Skill: Compare call vs report syntax side-by-side
Description: Students compare and contrast CreatiCode's two ways of invoking custom blocks: `call BlockName [args]` for command blocks (perform actions) and `report BlockName [args]` for reporter blocks (return values). They examine side-by-side examples showing when each syntax is appropriate and practice identifying incorrect syntax (e.g., using `call` on a block that should return a value). This explicit comparison prevents common confusion.

Assessment example: Given 6 custom block invocations, students identify which use correct syntax and fix incorrect ones (e.g., changing `call CalculateScore [10]` to `report CalculateScore [10]` when the result needs to be used in a calculation).

Dependencies:
* T11.G5.02.02: Call a custom reporter block using report syntax
* T11.G3.07: Call a custom block using the call syntax

---

ID: T11.G5.02.01
Topic: T11 – Functions & Organization
Skill: Distinguish when to use reporter vs command custom blocks
Description: Students decide whether new custom blocks should be reporters (return a value) or commands (perform an action). They recognize that reporters are appropriate when you need to calculate or retrieve information, while commands are for performing actions with side effects. Given scenarios, they choose the appropriate block type and explain their reasoning.

Assessment example: Given 6-8 block descriptions, students categorize each as better implemented as a reporter or command block and explain why (e.g., "CalculateDistance" → reporter because it computes a value; "MoveTo" → command because it changes sprite position).

Dependencies:
* T11.G5.02: Use the return block to send a value from a custom block
* T11.G4.17: Identify side effects in custom blocks

---

ID: T11.G5.03
Topic: T11 – Functions & Organization
Skill: Use custom reporter blocks in expressions
Description: Students use custom reporter blocks they created inside larger expressions, combining them with operators and other reporters. For example, they use `(CalculateScore [hits] [multiplier])` inside `set [totalScore] to ((totalScore) + (CalculateScore [10] [2]))`. This demonstrates composability of custom reporters.

Assessment example: Students create an expression that combines a custom reporter block with at least two operators or other built-in reporters.

Dependencies:
* T11.G5.02: Create a custom reporter block
* T10.G5.01: Calculate with arithmetic expressions (nested operators)

---

ID: T11.G5.04
Topic: T11 – Functions & Organization
Skill: Use custom reporter blocks in conditionals
Description: Students use custom reporter blocks in if conditions and repeat-until loops. For example, `if <(IsPlayerNearEnemy [50]) = [true]>` or `repeat until <(GetDistanceToTarget) < [10]>`. They understand how reporter blocks provide flexible, reusable logic for control structures.

Assessment example: Students create at least two control structures (if/if-else/repeat-until) that use custom reporter blocks in their conditions.

Dependencies:
* T11.G5.02: Create a custom reporter block
* T08.G5.02: Nest if statements for multi-level decisions

---

ID: T11.G5.05
Topic: T11 – Functions & Organization
Skill: Create boolean custom reporter blocks
Description: Students create custom reporter blocks that return true/false values for use in conditionals. For example, `define (IsScoreHigh [score])` returns `<[score] > [100]>`. These boolean reporters encapsulate complex conditions into readable, reusable blocks.

Assessment example: Students create 2-3 boolean reporter blocks (returning true/false) and use them in if statements or loops.

Dependencies:
* T11.G5.02: Create a custom reporter block
* T08.G5.03: Combine multiple conditions with OR

---

ID: T11.G5.06
Topic: T11 – Functions & Organization
Skill: Validate parameter values at block start
Description: Students add validation code at the beginning of custom blocks to check that parameter values are reasonable. For example, `if <[size] < [1]> then set [size] to [1]` to ensure size is never zero or negative. They learn defensive programming by handling unexpected inputs.

Assessment example: Students add parameter validation to 2-3 custom blocks and test that the blocks handle invalid inputs gracefully.

Dependencies:
* T11.G4.07: Document parameter purpose and expected values
* T08.G5.04: Chain if-else for 3+ exclusive options

---

ID: T11.G5.07
Topic: T11 – Functions & Organization
Skill: Use default values for optional parameters
Description: Students implement optional parameters by checking if a parameter is empty and using a default value if so. For example, `if <[color] = []> then set [color] to [blue]`. This introduces the concept of parameter defaults and optional arguments.

Assessment example: Students create a custom block with 2-3 parameters where at least one is optional (has a default), document which parameters are optional, and test calling the block with and without the optional parameters.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T08.G5.04: Chain if-else for 3+ exclusive options

---

ID: T11.G5.08
Topic: T11 – Functions & Organization
Skill: Call custom blocks from multiple sprites
Description: Students create custom blocks that are used by multiple sprites in a project. They understand that each sprite can have its own custom blocks (sprite-local) and consider when blocks should be shared vs duplicated. This introduces thinking about code organization across multiple sprites.

Assessment example: Students create a project with 3 sprites where at least one custom block is defined identically in 2+ sprites, and explain when this duplication is appropriate vs when it should be avoided.

Dependencies:
* T11.G4.05: Organize a project with 3-4 custom blocks
* T05.G5.01: Coordinate two sprites for a simple interaction

---

ID: T11.G5.09
Topic: T11 – Functions & Organization
Skill: Create custom blocks with 3+ parameters
Description: Students create custom blocks with three or more parameters, understanding how to manage increased complexity. For example, `define (DrawRectangle [x] [y] [width] [height] [color])`. They organize parameters logically and document each one clearly.

Assessment example: Students create a custom block with 3-5 parameters, implement it, document all parameters, and demonstrate calling it with different argument combinations.

Dependencies:
* T11.G4.08: Create a custom block with two parameters
* T11.G4.15: Use consistent parameter ordering across related blocks

---

ID: T11.G5.09.01
Topic: T11 – Functions & Organization
Skill: Order parameters logically in multi-parameter blocks
Description: Students learn and apply principles for parameter ordering: required before optional, inputs before outputs, related parameters grouped together, most important parameters first. They review existing multi-parameter blocks and improve parameter ordering for clarity and usability.

Assessment example: Given 3-4 custom blocks with poorly ordered parameters, students reorder them following best practices and explain why the new ordering is better.

Dependencies:
* T11.G5.09: Create custom blocks with 3+ parameters
* T11.G4.15: Use consistent parameter ordering across related blocks

---

ID: T11.G5.10
Topic: T11 – Functions & Organization
Skill: Document block preconditions and postconditions
Description: Students add comments specifying what must be true before calling a block (preconditions) and what will be true after it executes (postconditions). For example: `// Precondition: lives > 0; Postcondition: score updated, level may change`. This introduces formal specification thinking.

Assessment example: Students add precondition and postcondition documentation to 3 custom blocks and verify through testing that the conditions hold.

Dependencies:
* T11.G4.07: Document parameter purpose and expected values
* T11.G5.06: Validate parameter values at block start

---

ID: T11.G5.11
Topic: T11 – Functions & Organization
Skill: Refactor a long script into well-named custom blocks
Description: Students take a long (30-50 block) monolithic script and refactor it into 4-6 custom blocks, each with a clear responsibility. They identify logical sections, create custom blocks for each, and replace the original code with calls to the new blocks. This is comprehensive refactoring practice.

Assessment example: Given a long script, students refactor it into custom blocks, document each block, and demonstrate that the refactored version works identically to the original.

Dependencies:
* T11.G4.14: Extract repeated code into a helper custom block
* T11.G4.21: Review and refactor custom block organization

---

ID: T11.G5.12
Topic: T11 – Functions & Organization
Skill: Create and use nested custom reporter blocks
Description: Students create custom reporter blocks that call other custom reporter blocks in their implementation, building layered calculations. For example, `define (CalculateFinalScore)` calls `(CalculateBaseScore)` and `(GetTimeBonus)` and combines them. This demonstrates hierarchical organization of calculations and the composability of reporter blocks.

Assessment example: Students create 3+ custom reporter blocks where at least one calls another reporter in its implementation, creating a calculation hierarchy.

Dependencies:
* T11.G5.03: Use custom reporter blocks in expressions
* T11.G4.10: Call one custom block from inside another

---

ID: T11.G5.13
Topic: T11 – Functions & Organization
Skill: Design custom blocks for single responsibility
Description: Students apply the Single Responsibility Principle: each custom block should do ONE thing well. They review existing blocks and identify blocks doing too much, split them into focused blocks, and explain why single-responsibility blocks are easier to test, debug, and reuse.

Assessment example: Given 2-3 custom blocks that do multiple unrelated things, students split each into 2-3 focused blocks and explain the benefits.

Dependencies:
* T11.G5.11: Refactor a long script into well-named custom blocks
* T11.G4.13: Decide when to create a new custom block vs add to existing

---

ID: T11.G5.14
Topic: T11 – Functions & Organization
Skill: Document custom blocks with purpose comments
Description: Students systematically add purpose comments to all custom blocks following a consistent format: what the block does, what parameters mean, what it returns (for reporters), any important side effects or preconditions. This is comprehensive block documentation practice.

Assessment example: Students document 5-7 custom blocks with complete, well-formatted purpose comments and explain how documentation helps others use the blocks.

Dependencies:
* T11.G5.10: Document block preconditions and postconditions
* T11.G4.07: Document parameter purpose and expected values

---

ID: T11.G5.15
Topic: T11 – Functions & Organization
Skill: Use comments to mark TODO items and known issues
Description: Students use comments to mark incomplete work, known bugs, and future improvements in their code. For example: `// TODO: Add validation for negative scores` or `// BUG: Sometimes jumps too high, check velocity calculation`. This introduces professional code annotation practices.

Assessment example: Students review a project in progress, add TODO and issue comments for 3-5 known problems or planned improvements, and explain how these comments help manage development.

Dependencies:
* T11.G5.14: Document custom blocks with purpose comments
* T11.G3.01: Insert a comment block to explain code purpose

---

ID: T11.G5.16
Topic: T11 – Functions & Organization
Skill: Use consistent commenting style across a project
Description: Students establish and follow a consistent commenting style throughout a project: format for block headers, inline comments, TODO markers, etc. They review their own code for consistency and update comments to match their style guide.

Assessment example: Students create a simple commenting style guide for their project (3-5 rules) and apply it consistently to all custom blocks and major scripts.

Dependencies:
* T11.G5.14: Document custom blocks with purpose comments
* T11.G5.15: Use comments to mark TODO items and known issues

---

ID: T11.G5.17
Topic: T11 – Functions & Organization
Skill: Choose between local variables and parameters
Description: Students decide when to use parameters (values passed from caller) vs local variables (values computed inside the block). They understand that parameters make blocks flexible while local variables keep internal calculations encapsulated. Given scenarios, they make appropriate choices and explain their reasoning.

Assessment example: Given 4-5 custom block scenarios, students identify which values should be parameters and which should be local variables, explaining the trade-offs.

Dependencies:
* T11.G5.09: Create custom blocks with 3+ parameters
* T09.G5.01: Use variables with limited scope in projects

---

ID: T11.G5.18
Topic: T11 – Functions & Organization
Skill: Organize blocks into initialization, main, and helper categories
Description: Students organize all custom blocks in a project into categories: initialization blocks (run at start), main blocks (core functionality), and helper blocks (called by other blocks). They use naming conventions and documentation to mark categories. This introduces architectural thinking.

Assessment example: Students categorize 8-12 custom blocks into initialization, main, and helper groups, using naming prefixes and comments to indicate categories.

Dependencies:
* T11.G4.12: Organize related custom blocks into logical groups
* T11.G5.01: Design custom block interfaces for a project before coding

---

ID: T11.G5.19
Topic: T11 – Functions & Organization
Skill: Identify and eliminate duplicate custom blocks
Description: Students review a project with multiple custom blocks and identify blocks that are identical or nearly identical. They consolidate duplicates into single blocks with appropriate parameters, removing redundancy. This is DRY (Don't Repeat Yourself) principle application.

Assessment example: Given a project with 3-4 pairs of very similar blocks, students consolidate each pair into a single parameterized block and verify the project still works.

Dependencies:
* T11.G4.09: Identify custom blocks that share similar code
* T11.G5.11: Refactor a long script into well-named custom blocks

---

ID: T11.G5.20
Topic: T11 – Functions & Organization
Skill: Create custom blocks that modify sprite properties
Description: Students create custom blocks that encapsulate common sprite property changes, making them reusable. For example, `define (ResetSprite [sprite])` sets position, size, visibility, costume. They understand how custom blocks can bundle related property changes.

Assessment example: Students create 2-3 custom blocks that each modify multiple sprite properties, document what properties each block changes, and use them in a project.

Dependencies:
* T11.G4.05: Organize a project with 3-4 custom blocks
* T05.G5.02: Use variables to control sprite behavior

---

ID: T11.G5.21
Topic: T11 – Functions & Organization
Skill: Read and explain unfamiliar custom blocks written by others
Description: Students examine custom blocks created by another person (with minimal comments) and explain what the block does, what each parameter is for, and how the block works internally. They practice reverse-engineering code organization from existing implementations. This skill is essential for collaboration, code review, and learning from shared projects.

Assessment example: Given a project with 3 undocumented custom blocks created by someone else, students write explanations for each block: what it does, what parameters mean, and any assumptions or requirements they can identify from the code.

Dependencies:
* T11.G4.10.01: Trace execution through nested custom block calls
* T11.G5.02.03: Compare call vs report syntax side-by-side
* T11.G4.07: Document parameter purpose and expected values

---

ID: T11.G5.22
Topic: T11 – Functions & Organization
Skill: Balance block granularity (not too small, not too large)
Description: Students evaluate whether custom blocks are at the right level of granularity: not so small they create clutter (2-3 blocks doing trivial things), not so large they're hard to understand (50+ blocks doing many different things). They refactor blocks that are too small or too large.

Assessment example: Given 5-6 custom blocks of varying sizes, students identify which are too small (should be merged), too large (should be split), or just right, explaining their reasoning for each.

Dependencies:
* T11.G5.13: Design custom blocks for single responsibility
* T11.G5.11: Refactor a long script into well-named custom blocks

---

ID: T11.G5.23
Topic: T11 – Functions & Organization
Skill: Test custom blocks with edge case parameters
Description: Students systematically test custom blocks with edge cases: boundary values (0, max), negative numbers, empty strings, very large values. They identify which edge cases each block should handle and verify the behavior is correct or add validation as needed.

Assessment example: Students test 3 custom blocks with at least 3 edge cases each, document the expected behavior for each edge case, and add validation if needed.

Dependencies:
* T11.G5.06: Validate parameter values at block start
* T11.G4.16: Test custom blocks independently before integration

---

ID: T11.G5.24
Topic: T11 – Functions & Organization
Skill: Debug custom blocks using console logging
Description: Students add temporary `log [message]` blocks inside custom block definitions to trace execution and inspect parameter values during debugging. They learn to log entry/exit points, intermediate calculations, and decision branch taken. After debugging, they remove or comment out the log statements.

Assessment example: Students debug a faulty custom block by adding log statements that show: (1) when the block starts with what parameters, (2) key intermediate values, (3) which conditional branch was taken. They use the console output to identify and fix the bug.

Dependencies:
* T11.G5.11: Refactor a long script into well-named custom blocks
* T12.G5.05: Use log blocks to trace variable values

---

ID: T11.G5.24.01
Topic: T11 – Functions & Organization
Skill: Trace return values through nested reporter calls
Description: Students debug custom reporter blocks by tracing return values through multiple levels of nested calls. When `report CalculateFinal` calls `report GetBase` and `report GetBonus`, they trace each return value back through the chain to understand how the final result is computed. They add logging at each return point to visualize the value flow.

Assessment example: Given `report TotalScore` that uses `report BaseScore` and `report BonusMultiplier`, students add logging to show each intermediate value and trace why `TotalScore` returns an unexpected value (e.g., "BaseScore returns 10, BonusMultiplier returns 0, so TotalScore = 10 * 0 = 0").

Dependencies:
* T11.G5.24: Debug custom blocks using console logging
* T11.G5.12: Create and use nested custom reporter blocks

---

ID: T11.G5.25
Topic: T11 – Functions & Organization
Skill: Create reusable utility blocks for common operations
Description: Students identify common operations in their projects (converting between units, clamping values to ranges, formatting text) and create reusable utility blocks. They design these blocks to be generic enough to use across multiple projects. Examples: "Clamp [value] [min] [max]", "FormatTime [seconds]", "RandomInRange [min] [max]".

Assessment example: Students create 3-4 utility blocks, document each with usage examples, and demonstrate using them in at least two different contexts within the same project.

Dependencies:
* T11.G5.02.02: Call a custom reporter block using report syntax
* T11.G5.13: Design custom blocks for single responsibility

---

ID: T11.G6.01
Topic: T11 – Functions & Organization
Skill: Create recursive custom blocks
Description: Students create custom blocks that call themselves (recursion) to solve problems that have a recursive structure. For example, `define (DrawFractalTree [length] [depth])` calls itself with smaller values. They understand base cases (when to stop) and recursive cases (when to call self).

Assessment example: Students create a recursive custom block (e.g., countdown, fractal pattern, factorial) with a proper base case and recursive case, and test it with different parameter values.

Dependencies:
* T11.G4.10: Call one custom block from inside another
* T11.G5.06: Validate parameter values at block start

---

ID: T11.G6.01.01
Topic: T11 – Functions & Organization
Skill: Choose between recursion and loops for a problem
Description: Students analyze problems and decide whether recursion or loops are more appropriate. They identify characteristics that favor recursion (self-similar structure, tree/fractal patterns, divide-and-conquer) vs loops (sequential processing, counting, simple repetition). Given 6-8 problems, they categorize each as better suited for recursion or loops and explain their reasoning.

Assessment example: Given problems like "draw a spiral," "calculate factorial," "count items in a list," "draw a fractal tree," "move 10 steps 5 times," students categorize each as better solved with loops or recursion and explain why (e.g., "Fractal tree is recursive because each branch has smaller branches that look like the whole tree").

Dependencies:
* T11.G6.01: Create recursive custom blocks
* T07.G6.05: Choose the right loop type for a problem

---

ID: T11.G6.02
Topic: T11 – Functions & Organization
Skill: Debug infinite recursion with base case analysis
Description: Students identify and fix infinite recursion bugs by analyzing base cases. They recognize symptoms (project freezes, stack overflow), trace recursive calls, identify missing or incorrect base cases, and add proper stopping conditions.

Assessment example: Given 2-3 recursive blocks with infinite recursion bugs, students identify the problem (missing base case, wrong condition), fix it, and verify the blocks now terminate correctly.

Dependencies:
* T11.G6.01: Create recursive custom blocks
* T12.G6.05: Use console.log to trace variable changes

---

ID: T11.G6.03
Topic: T11 – Functions & Organization
Skill: Design custom block APIs for a library
Description: Students design a set of related custom blocks that work together as a "library" for a specific purpose (e.g., geometry shapes, game physics, animation effects). They ensure consistent naming, parameter ordering, and documentation across all blocks in the library.

Assessment example: Students design and implement a 5-7 block library for a specific purpose, with consistent naming and documentation, and demonstrate using the library in a project.

Dependencies:
* T11.G5.01: Design custom block interfaces for a project before coding
* T11.G5.18: Organize blocks into initialization, main, and helper categories

---

ID: T11.G6.04
Topic: T11 – Functions & Organization
Skill: Coordinate multiple custom blocks with shared state
Description: Students create projects where multiple custom blocks read and modify shared variables (global state) in a coordinated way. They understand how to manage shared state carefully to avoid conflicts and ensure blocks work together correctly.

Assessment example: Students create a project with 3-4 custom blocks that all interact with 2-3 shared variables, document how each block uses the shared state, and demonstrate the blocks working together correctly.

Dependencies:
* T11.G5.08: Call custom blocks from multiple sprites
* T09.G6.02: Choose between local and global variables

---

ID: T11.G6.04.01
Topic: T11 – Functions & Organization
Skill: Test custom block coordination with integration tests
Description: Students create test scripts that verify multiple custom blocks work together correctly (integration testing), not just individually (unit testing). They test sequences of block calls and verify the combined behavior produces correct results. For example, testing that "InitializeGame" → "SpawnEnemies" → "StartLevel" produces a playable game state.

Assessment example: Students create 2-3 integration test scripts that call multiple custom blocks in sequence and verify the final state is correct.

Dependencies:
* T11.G6.04: Coordinate multiple custom blocks with shared state
* T11.G4.16: Test custom blocks independently before integration

---

ID: T11.G6.05
Topic: T11 – Functions & Organization
Skill: Use custom blocks to encapsulate physics calculations
Description: Students create custom blocks that encapsulate complex physics or mathematical calculations (gravity, collision, trajectory, scoring formulas). This separates "what to do" (main logic) from "how to calculate" (complex math), making code more maintainable.

Assessment example: Students create 2-3 custom reporter blocks for physics calculations and use them in a game or simulation, demonstrating how encapsulation simplifies the main code.

Dependencies:
* T11.G5.02: Create a custom reporter block
* T10.G6.03: Use operators with variables in calculations

---

ID: T11.G6.06
Topic: T11 – Functions & Organization
Skill: Create event-handler custom blocks
Description: Students create custom blocks specifically designed to be called from event blocks (green flag, key pressed, sprite clicked, message received). They understand the pattern of event-driven architecture where events trigger custom block calls.

Assessment example: Students create a project with 4-5 different event blocks, each calling a custom block, demonstrating event-driven organization.

Dependencies:
* T06.G6.01: Trigger coordinated events in multiple sprites
* T11.G5.01: Design custom block interfaces for a project before coding

---

ID: T11.G6.07
Topic: T11 – Functions & Organization
Skill: Refactor conditional logic into predicate blocks
Description: Students extract complex conditional expressions into boolean custom reporter blocks (predicates). For example, instead of `if <(<[score] > [100]) and (<[lives] > [0])>`, create `define (CanContinueGame)` and use `if <(CanContinueGame)>`. This makes conditions more readable and reusable.

Assessment example: Students find 3-4 complex conditions in their code, extract each into a named boolean reporter block, and replace the original conditions with block calls.

Dependencies:
* T11.G5.05: Create boolean custom reporter blocks
* T08.G6.02: Solve logic puzzles with nested boolean conditions

---

ID: T11.G6.08
Topic: T11 – Functions & Organization
Skill: Use custom blocks to implement state machines
Description: Students use custom blocks to implement simple state machines: each state is a custom block, blocks call other blocks to transition states. For example, a game with "MenuState", "PlayState", "GameOverState" where each state block checks conditions and calls the next state.

Assessment example: Students create a 3-4 state state machine using custom blocks, with each state implemented as a block that handles behavior and transitions to other states.

Dependencies:
* T11.G5.04: Use custom reporter blocks in conditionals
* T09.G6.03: Implement a finite state machine with variables

---

ID: T11.G6.09
Topic: T11 – Functions & Organization
Skill: Create custom blocks for error handling
Description: Students create custom blocks specifically for handling errors and exceptional cases. For example, `define (HandleInvalidInput [value])` or `define (ShowErrorMessage [message])`. They understand how to centralize error handling logic.

Assessment example: Students create 2-3 error-handling custom blocks and use them consistently throughout a project whenever errors occur.

Dependencies:
* T11.G5.06: Validate parameter values at block start
* T12.G6.04: Handle edge cases with defensive conditionals

---

ID: T11.G6.10
Topic: T11 – Functions & Organization
Skill: Profile and optimize custom block performance
Description: Students measure and improve custom block performance by identifying slow blocks, reducing unnecessary calculations, caching results, and minimizing sprite lookups. They use timing techniques to measure before and after optimization.

Assessment example: Students identify a slow custom block using timing measurements, optimize it (e.g., caching, reducing loops), and demonstrate measurable performance improvement.

Dependencies:
* T11.G5.11: Refactor a long script into well-named custom blocks
* T07.G6.08: Optimize loops to improve performance

---

ID: T11.G6.11
Topic: T11 – Functions & Organization
Skill: Create custom blocks with variable-length parameter lists
Description: Students create custom blocks that can handle varying numbers of inputs by using list parameters. For example, `define (CalculateAverage [numbers])` where [numbers] is a list. They understand how lists enable flexible parameter counts.

Assessment example: Students create a custom block that accepts a list parameter and processes all items in the list, testing it with lists of different lengths.

Dependencies:
* T11.G5.09: Create custom blocks with 3+ parameters
* T13.G6.01: Use loops to process all items in a list

---

ID: T11.G6.12
Topic: T11 – Functions & Organization
Skill: Implement fluent interfaces with chained block calls
Description: Students create custom blocks designed to be called in sequence, where each block modifies state and the next block builds on those changes. For example, "InitializeSprite" → "SetPosition [x] [y]" → "SetSize [size]" → "Show". They understand method chaining patterns.

Assessment example: Students create 3-4 custom blocks designed to be called in sequence and demonstrate using them in a fluent chaining style.

Dependencies:
* T11.G6.04: Coordinate multiple custom blocks with shared state
* T11.G5.20: Create custom blocks that modify sprite properties

---

ID: T11.G6.13
Topic: T11 – Functions & Organization
Skill: Use naming conventions to indicate block types
Description: Students adopt naming conventions that indicate block purpose: verbs for command blocks ("DrawSquare", "UpdateScore"), nouns or adjectives for reporters ("PlayerScore", "IsGameOver"), "Handle" prefix for event handlers ("HandleKeyPress"). They apply conventions consistently.

Assessment example: Students review 10-12 custom blocks and rename them following a consistent naming convention, creating a style guide that explains the conventions.

Dependencies:
* T11.G5.02.01: Distinguish when to use reporter vs command custom blocks
* T11.G4.11: Choose descriptive action-based names for custom blocks

---

ID: T11.G6.14
Topic: T11 – Functions & Organization
Skill: Create abstractions for complex sprite coordination
Description: Students create custom blocks that encapsulate complex multi-sprite behaviors. For example, `define (SetupConversation [character1] [character2])` positions both sprites, sets costumes, and prepares dialogue. They understand how abstraction simplifies coordination.

Assessment example: Students create 2-3 custom blocks that each coordinate multiple sprites, and use them to build a complex multi-sprite interaction.

Dependencies:
* T05.G6.02: Implement complex multi-sprite coordination patterns
* T11.G6.04: Coordinate multiple custom blocks with shared state

---

ID: T11.G6.14.01
Topic: T11 – Functions & Organization
Skill: Design callback-style custom blocks
Description: Students create custom blocks that accept other custom block names as parameters (callbacks), enabling flexible behavior. For example, `define (RepeatAction [times] [action])` where [action] is the name of another custom block to call repeatedly. This introduces higher-order function concepts.

Assessment example: Students create a callback-style custom block and demonstrate calling it with 2-3 different callback blocks to produce different behaviors.

Dependencies:
* T11.G6.14: Create abstractions for complex sprite coordination
* T11.G5.09: Create custom blocks with 3+ parameters

---

ID: T11.G6.15
Topic: T11 – Functions & Organization
Skill: Annotate algorithm logic with explanatory comments
Description: Students add explanatory comments to complex algorithms inside custom blocks, explaining WHY each step is necessary, not just WHAT it does. For example: `// Check right boundary first to avoid corner collision bug` or `// Double the speed after 10 points to increase difficulty`. This teaches explaining algorithmic reasoning.

Assessment example: Students add explanatory comments to 3-4 complex algorithms, focusing on explaining the reasoning behind non-obvious steps.

Dependencies:
* T11.G5.14: Document custom blocks with purpose comments
* T10.G6.07: Apply computational thinking to algorithm design

---

ID: T11.G6.16
Topic: T11 – Functions & Organization
Skill: Organize large projects with 15+ custom blocks
Description: Students manage large projects (15-25 custom blocks) using organizational strategies: grouping by functionality, consistent naming, comprehensive documentation, clear separation of concerns. They create a project architecture document.

Assessment example: Students build a substantial project with 15-25 custom blocks, organized into 3-5 functional groups, with complete documentation and an architecture overview.

Dependencies:
* T11.G6.03: Design custom block APIs for a library
* T11.G5.18: Organize blocks into initialization, main, and helper categories

---

ID: T11.G6.17
Topic: T11 – Functions & Organization
Skill: Refactor projects to separate concerns
Description: Students refactor projects to separate different concerns into different custom blocks: UI logic separate from game logic, data management separate from rendering, input handling separate from state updates. They apply separation of concerns principle.

Assessment example: Students take a project with mixed concerns and refactor it into clearly separated blocks: input blocks, logic blocks, rendering blocks, explaining the benefits of separation.

Dependencies:
* T11.G6.16: Organize large projects with 15+ custom blocks
* T11.G5.13: Design custom blocks for single responsibility

---

ID: T11.G6.17.01
Topic: T11 – Functions & Organization
Skill: Analyze and document legacy code organization
Description: Students take an existing, poorly-documented project with multiple custom blocks and create comprehensive documentation: describing what each block does, how blocks relate to each other, which blocks are entry points vs helpers, and suggested improvements. This builds skills for working with existing codebases—essential for real-world programming.

Assessment example: Given a 20-block undocumented project, students create: (1) a block-by-block description, (2) a diagram showing block dependencies, (3) identification of the main entry points, (4) 3-5 suggested improvements to the organization.

Dependencies:
* T11.G6.17: Refactor projects to separate concerns
* T11.G5.21: Read and explain unfamiliar custom blocks written by others

---

ID: T11.G6.18
Topic: T11 – Functions & Organization
Skill: Create custom blocks that wrap AI blocks
Description: Students create custom blocks that encapsulate CreatiCode's AI features (ChatGPT, AI Speaker, speech recognition) with appropriate configuration, error handling, and default values. For example, `define (AskAI [question])` wraps the ChatGPT block with session management, or `define (SpeakText [message] [voice])` wraps AI Speaker with voice selection. This makes AI features easier to use consistently throughout a project.

Assessment example: Students create 2-3 custom blocks that wrap AI features: one for ChatGPT interaction with session handling, one for text-to-speech with voice selection, demonstrating how wrapping simplifies repeated AI usage.

Dependencies:
* T11.G6.09: Create custom blocks for error handling
* T11.G5.07: Use default values for optional parameters

---

ID: T11.G7.01
Topic: T11 – Functions & Organization
Skill: Design polymorphic custom blocks
Description: Students create custom blocks that behave differently based on parameter types or values, implementing polymorphism. For example, `define (ProcessInput [input])` handles numbers differently than text. They use type checking and conditional logic to implement polymorphic behavior.

Assessment example: Students create a polymorphic custom block that handles 2-3 different input types appropriately and demonstrate it working with each type.

Dependencies:
* T11.G5.02.01: Distinguish when to use reporter vs command custom blocks
* T08.G7.02: Apply De Morgan's laws to simplify complex logic

---

ID: T11.G7.02
Topic: T11 – Functions & Organization
Skill: Implement lazy evaluation in custom blocks
Description: Students create custom blocks that delay expensive calculations until needed (lazy evaluation). For example, a reporter that caches its result and only recalculates if input changes. They understand when lazy evaluation improves performance.

Assessment example: Students create a custom reporter block with caching that avoids redundant expensive calculations, demonstrating performance improvement with measurements.

Dependencies:
* T11.G6.10: Profile and optimize custom block performance
* T09.G7.01: Implement advanced variable scoping patterns

---

ID: T11.G7.03
Topic: T11 – Functions & Organization
Skill: Create custom blocks with dependency injection
Description: Students create custom blocks that accept dependencies as parameters instead of hard-coding them, enabling flexibility and testing. For example, `define (UpdateDisplay [scoreVariable])` accepts which variable to display rather than always using "score". This is dependency injection principle.

Assessment example: Students refactor 2-3 custom blocks to use dependency injection, demonstrating how the same block can work with different dependencies.

Dependencies:
* T11.G6.04: Coordinate multiple custom blocks with shared state
* T11.G5.17: Choose between local variables and parameters

---

ID: T11.G7.04
Topic: T11 – Functions & Organization
Skill: Use custom blocks to implement design patterns
Description: Students implement common design patterns using custom blocks: Factory (blocks that create and configure sprites), Observer (blocks that notify other blocks of changes), Strategy (swappable algorithm blocks). They understand how patterns solve recurring problems.

Assessment example: Students implement 2 design patterns using custom blocks and explain what problem each pattern solves.

Dependencies:
* T11.G6.14.01: Design callback-style custom blocks
* T11.G6.08: Use custom blocks to implement state machines

---

ID: T11.G7.05
Topic: T11 – Functions & Organization
Skill: Create domain-specific language with custom blocks
Description: Students create a set of custom blocks that form a domain-specific language (DSL) for a particular purpose, making code read like natural language. For example, animation blocks: "FadeIn [sprite] [duration]", "SlideFrom [x] [y] to [x2] [y2]", "RotateBy [degrees]". They understand how DSLs improve code clarity for specific domains.

Assessment example: Students create 6-8 custom blocks that form a DSL for a specific domain (animation, physics, game mechanics) and write example code using the DSL that reads clearly.

Dependencies:
* T11.G6.03: Design custom block APIs for a library
* T11.G6.13: Use naming conventions to indicate block types

---

ID: T11.G7.06
Topic: T11 – Functions & Organization
Skill: Implement custom block versioning and deprecation
Description: Students manage evolving custom block APIs by versioning blocks and deprecating old versions. They create new versions of blocks when interfaces change, mark old versions as deprecated in comments, and provide migration guidance. This introduces API lifecycle management.

Assessment example: Students create v2 of a custom block with an improved interface, mark v1 as deprecated with migration instructions, and update calling code to use v2.

Dependencies:
* T11.G6.16: Organize large projects with 15+ custom blocks
* T11.G5.14: Document custom blocks with purpose comments

---

ID: T11.G7.07
Topic: T11 – Functions & Organization
Skill: Create self-documenting custom block interfaces
Description: Students design custom block signatures that are self-explanatory through careful naming and parameter choices, minimizing the need for comments. For example, `define (MoveSprite [sprite] [toX] [toY] [duration] [shouldAnimate])` is clearer than `define (Move [s] [x] [y] [d] [a])`. They practice making code that explains itself.

Assessment example: Students review poorly-named custom blocks and redesign them to be self-documenting, explaining how the new names reduce the need for documentation.

Dependencies:
* T11.G6.13: Use naming conventions to indicate block types
* T11.G5.09.01: Order parameters logically in multi-parameter blocks

---

ID: T11.G7.07.01
Topic: T11 – Functions & Organization
Skill: Balance documentation thoroughness with code clarity
Description: Students practice balancing between comprehensive documentation and code that explains itself. They learn when detailed comments are valuable (complex algorithms, non-obvious decisions) vs when clear code reduces documentation needs (self-explanatory block names, well-structured logic). They review projects and optimize the documentation-to-code-clarity ratio.

Assessment example: Students review a heavily-commented project and identify where comments are essential vs where better code structure could replace comments, refactoring to improve the balance.

Dependencies:
* T11.G7.07: Create self-documenting custom block interfaces
* T11.G6.15: Annotate algorithm logic with explanatory comments

---

ID: T11.G7.08
Topic: T11 – Functions & Organization
Skill: Implement custom block composition patterns
Description: Students create small, focused custom blocks designed to be composed together to build complex behaviors. They understand how composable blocks enable flexibility and reuse. For example, combining "ValidateInput", "ProcessData", "UpdateDisplay" blocks in various sequences.

Assessment example: Students create 5-7 small composable custom blocks and demonstrate building 3+ different complex behaviors by composing them in different ways.

Dependencies:
* T11.G6.12: Implement fluent interfaces with chained block calls
* T11.G5.13: Design custom blocks for single responsibility

---

ID: T11.G7.09
Topic: T11 – Functions & Organization
Skill: Use custom blocks for aspect-oriented programming
Description: Students create custom blocks that handle cross-cutting concerns (logging, error handling, performance measurement) and integrate them into multiple other blocks. This introduces aspect-oriented programming concepts where some concerns cut across many blocks.

Assessment example: Students create 2-3 "aspect" blocks (e.g., logging, error handling) and integrate them into 4-5 different custom blocks, demonstrating consistent cross-cutting behavior.

Dependencies:
* T11.G6.09: Create custom blocks for error handling
* T12.G7.03: Instrument code with comprehensive logging

---

ID: T11.G7.10
Topic: T11 – Functions & Organization
Skill: Create custom blocks for data transformation pipelines
Description: Students create sequences of custom blocks where each transforms data and passes results to the next, forming data processing pipelines. For example, "LoadData" → "FilterData [criteria]" → "SortData [field]" → "FormatOutput". They understand pipeline architecture patterns.

Assessment example: Students create a 4-6 stage data transformation pipeline using custom blocks, where each stage processes the previous stage's output.

Dependencies:
* T11.G7.08: Implement custom block composition patterns
* T13.G7.03: Transform data with map, filter, reduce patterns

---

ID: T11.G7.11
Topic: T11 – Functions & Organization
Skill: Implement code generation with custom blocks
Description: Students create custom blocks that generate other code dynamically (e.g., creating lists of commands, building expressions, generating repeated patterns). They understand metaprogramming concepts where code creates code.

Assessment example: Students create custom blocks that generate code structures dynamically (e.g., build a list of movement commands based on parameters) and execute the generated code.

Dependencies:
* T11.G7.10: Create custom blocks for data transformation pipelines
* T13.G7.05: Implement algorithms using list recursion

---

ID: T11.G7.12
Topic: T11 – Functions & Organization
Skill: Design API contracts and enforce them
Description: Students design formal API contracts for custom blocks (specifying preconditions, postconditions, invariants) and add runtime checks to enforce them. For example, adding assertions that verify parameter ranges and throw errors if violated. This introduces contract programming.

Assessment example: Students create 3-4 custom blocks with formal contracts, implement runtime checks to enforce contracts, and demonstrate that violations are caught.

Dependencies:
* T11.G5.10: Document block preconditions and postconditions
* T12.G7.05: Implement custom error types and error hierarchies

---

ID: T11.G7.12.01
Topic: T11 – Functions & Organization
Skill: Refine AI-generated custom blocks by improving parameter design
Description: Students take custom blocks generated by AI assistants and improve them by analyzing parameter design: adding missing parameters for flexibility, removing unnecessary parameters, reordering parameters logically, adding validation, improving naming. They understand that AI-generated code often needs refinement for production quality.

Assessment example: Students are given 3-4 AI-generated custom blocks and improve each by refining parameters (adding, removing, reordering, validating), explaining what makes the refined version better.

Dependencies:
* T11.G7.12: Design API contracts and enforce them
* T11.G5.09.01: Order parameters logically in multi-parameter blocks

---

ID: T11.G7.13
Topic: T11 – Functions & Organization
Skill: Design custom blocks for AI-driven features
Description: Students design and implement custom blocks that leverage CreatiCode's AI capabilities for complex features: hand/body tracking with table variable processing, pose detection with gesture recognition, AI-powered character behavior. They encapsulate AI complexity behind clean interfaces. For example, `define (IsHandRaised)` uses hand tracking table data to return true/false, or `define (GetPlayerGesture)` processes pose data to identify gestures.

Assessment example: Students create 3 custom blocks that use AI features: (1) "IsWaving" that analyzes hand tracking data, (2) "GetFacialExpression" that interprets face detection, (3) "FollowPlayerWithCamera" that uses body tracking to keep player centered. They document what AI data each block uses.

Dependencies:
* T11.G6.18: Create custom blocks that wrap AI blocks
* T11.G6.11: Create custom blocks with variable-length parameter lists

---

ID: T11.G7.14
Topic: T11 – Functions & Organization
Skill: Create custom blocks for common game patterns
Description: Students create reusable custom blocks that implement common game patterns: spawn systems (`SpawnEnemy [type] [x] [y]`), damage systems (`TakeDamage [amount] [source]`), pickup systems (`CollectItem [itemType]`), scoring systems (`AddScore [points] [reason]`). They design these blocks to be generic enough for multiple game types while specific enough to be immediately useful.

Assessment example: Students create a 5-block "game toolkit" with: SpawnAt, TakeDamage, Heal, CollectPickup, and AwardPoints. They demonstrate using the same toolkit in two different game genres (e.g., platformer and shooter).

Dependencies:
* T11.G7.04: Use custom blocks to implement design patterns
* T11.G6.06: Create event-handler custom blocks

---

ID: T11.G8.01
Topic: T11 – Functions & Organization
Skill: Architect modular systems with plugin interfaces
Description: Students design systems where custom blocks serve as plugin interfaces, allowing new functionality to be added without modifying core code. For example, a game engine with "RegisterEnemyType [enemyBlock]" that accepts custom enemy behavior blocks. They understand plugin architecture patterns.

Assessment example: Students create a plugin-based system with 3-4 plugin slots and demonstrate adding new functionality by creating plugin blocks without modifying the core system.

Dependencies:
* T11.G7.04: Use custom blocks to implement design patterns
* T11.G6.14.01: Design callback-style custom blocks

---

ID: T11.G8.02
Topic: T11 – Functions & Organization
Skill: Implement custom block middleware patterns
Description: Students create middleware custom blocks that intercept and process calls to other blocks, adding behavior like logging, caching, access control, or transformation. They understand middleware architecture where blocks can be wrapped with additional behavior layers.

Assessment example: Students create 2-3 middleware blocks and demonstrate wrapping existing blocks to add cross-cutting behavior without modifying the original blocks.

Dependencies:
* T11.G7.09: Use custom blocks for aspect-oriented programming
* T11.G8.01: Architect modular systems with plugin interfaces

---

ID: T11.G8.03
Topic: T11 – Functions & Organization
Skill: Design reactive custom block systems
Description: Students create systems of custom blocks that react to changes automatically (reactive programming). For example, blocks that automatically re-execute when their input data changes, or blocks that notify dependent blocks of state changes. They understand reactive architecture patterns.

Assessment example: Students create a reactive system where 4-5 custom blocks automatically update when dependencies change, demonstrating cascading updates through the system.

Dependencies:
* T11.G7.04: Use custom blocks to implement design patterns
* T11.G6.04: Coordinate multiple custom blocks with shared state

---

ID: T11.G8.04
Topic: T11 – Functions & Organization
Skill: Use caching variables to avoid redundant custom block calls
Description: Students learn a practical caching pattern: storing the result of an expensive custom reporter block in a variable and reusing it instead of calling the block repeatedly. They identify when this optimization is beneficial (expensive calculations called multiple times with same inputs) and when it's unnecessary.

Assessment example: Students optimize a game loop that calls `report CalculateDistance [player] [enemy]` multiple times per frame by storing the result in a variable and reusing it, measuring the performance improvement.

Dependencies:
* T11.G7.02: Implement lazy evaluation in custom blocks
* T11.G6.10: Profile and optimize custom block performance

---

ID: T11.G8.05
Topic: T11 – Functions & Organization
Skill: Organize custom blocks by game system (physics, UI, AI, audio)
Description: Students organize large game projects by grouping custom blocks into logical systems: physics blocks (collision, movement, gravity), UI blocks (menus, score display, dialogs), AI blocks (enemy behavior, pathfinding), audio blocks (sound effects, music). They use consistent naming prefixes (e.g., "UI_ShowMenu", "Physics_ApplyGravity") and create architecture documentation showing how systems interact.

Assessment example: Students organize a 25+ block game into 4-5 systems with consistent naming, document the responsibilities of each system, and explain how systems communicate (e.g., "Physics system calls UI_ShowGameOver when player health reaches 0").

Dependencies:
* T11.G7.05: Create domain-specific language with custom blocks
* T11.G6.16: Organize large projects with 15+ custom blocks

---

ID: T11.G8.06
Topic: T11 – Functions & Organization
Skill: Create custom blocks that use broadcasts with parameters
Description: Students create sophisticated sprite coordination using CreatiCode's broadcast with parameter feature. They design custom blocks that broadcast messages with data attached (e.g., `broadcast [enemy_defeated v] with parameter [enemyType]`) and create handler blocks that process the parameter. This enables loose coupling between sprites while still passing necessary data.

Assessment example: Students create a multi-sprite game where defeating an enemy broadcasts "enemy_defeated" with the enemy's point value as a parameter, and a score manager sprite handles the message to update the score appropriately.

Dependencies:
* T11.G6.06: Create event-handler custom blocks
* T06.G6.01: Trigger coordinated events in multiple sprites

---

ID: T11.G8.07
Topic: T11 – Functions & Organization
Skill: Design microservice-inspired sprite architectures
Description: Students organize multi-sprite projects using microservice principles: each sprite is independent with its own custom blocks (services), sprites communicate through messages (APIs), loose coupling between sprites. They understand distributed system patterns.

Assessment example: Students create a project with 4-5 sprites where each sprite has its own custom block API and sprites interact only through messages, demonstrating loose coupling.

Dependencies:
* T05.G8.01: Design complex multi-sprite architectures
* T11.G6.03: Design custom block APIs for a library

---

ID: T11.G8.08
Topic: T11 – Functions & Organization
Skill: Create cooldown systems using custom blocks and timers
Description: Students create game mechanics that limit how often abilities can be used by implementing cooldown systems with custom blocks. They track time since last use with variables, check if enough time has passed before allowing the action, and provide visual feedback (cooldown indicators). This is a practical pattern used in many games.

Assessment example: Students create a "FireWeapon" custom block with a 2-second cooldown that: (1) checks if enough time has passed, (2) fires if ready and resets the timer, (3) shows "reloading" message if on cooldown. They test rapid button presses to verify the cooldown works.

Dependencies:
* T11.G8.04: Use caching variables to avoid redundant custom block calls
* T11.G6.10: Profile and optimize custom block performance

---

ID: T11.G8.09
Topic: T11 – Functions & Organization
Skill: Create custom blocks for concurrent execution coordination
Description: Students create custom blocks that coordinate concurrent sprite behaviors: synchronization blocks (wait for all sprites to reach a point), mutual exclusion blocks (ensure only one sprite accesses a resource), barrier blocks (coordinate multi-sprite timing). They understand concurrency coordination patterns.

Assessment example: Students create 3-4 concurrency coordination blocks and use them in a multi-sprite project to synchronize complex parallel behaviors.

Dependencies:
* T05.G8.02: Implement complex inter-sprite communication protocols
* T11.G6.04: Coordinate multiple custom blocks with shared state

---

ID: T11.G8.10
Topic: T11 – Functions & Organization
Skill: Create fallback custom blocks for error recovery
Description: Students create custom blocks that handle errors gracefully by implementing fallback behaviors. When the primary action fails (e.g., resource not found, invalid input, sprite doesn't exist), the block automatically performs a safe alternative action instead of crashing. They design primary and fallback paths within custom blocks.

Assessment example: Students create a "LoadLevel [levelNum]" custom block that: (1) attempts to load the requested level, (2) if level doesn't exist, falls back to level 1, (3) logs a warning message. They test with valid and invalid level numbers.

Dependencies:
* T11.G6.09: Create custom blocks for error handling
* T12.G8.05: Design resilient systems with graceful degradation

---

ID: T11.G8.11
Topic: T11 – Functions & Organization
Skill: Design custom block testing frameworks
Description: Students create testing frameworks using custom blocks: assertion blocks, test suite blocks, setup/teardown blocks, mocking blocks. They build infrastructure for systematically testing other custom blocks. This is meta-level testing infrastructure.

Assessment example: Students create a testing framework with 5-7 testing utility blocks and use it to create comprehensive test suites for 3-4 custom blocks.

Dependencies:
* T11.G6.04.01: Test custom block coordination with integration tests
* T12.G8.04: Design comprehensive test strategies for complex systems

---

ID: T11.G8.12
Topic: T11 – Functions & Organization
Skill: Create configuration custom blocks for easy game tuning
Description: Students create centralized configuration blocks that store all adjustable game parameters (speeds, sizes, timings, difficulty settings) in one place. Other blocks reference these configurations rather than using hard-coded values. This makes game tuning easy: change one block to adjust the entire game's difficulty or feel.

Assessment example: Students create a "GameConfig" block that sets variables for playerSpeed, enemyCount, levelDuration, etc., and refactor 5+ other blocks to use these configuration values instead of hard-coded numbers. They demonstrate adjusting difficulty by changing only the config block.

Dependencies:
* T11.G7.03: Create custom blocks with dependency injection
* T11.G6.04: Coordinate multiple custom blocks with shared state

---

ID: T11.G8.13
Topic: T11 – Functions & Organization
Skill: Evaluate and integrate AI-generated code blocks into projects
Description: Students critically evaluate code generated by AI coding assistants, checking for correctness, efficiency, style consistency, and appropriate abstraction. They integrate AI-generated custom blocks into projects after review and refinement, understanding how to use AI as a collaborative tool while maintaining code quality.

Assessment example: Students use AI to generate 3-4 custom blocks, evaluate each for quality issues, refactor as needed, and integrate them into a project, documenting what changes were needed and why.

Dependencies:
* T11.G7.12.01: Refine AI-generated custom blocks by improving parameter design
* T11.G6.17: Refactor projects to separate concerns

---

ID: T11.G8.14
Topic: T11 – Functions & Organization
Skill: Design custom block APIs for extensibility
Description: Students design custom block APIs that anticipate future changes: versioning strategies, backward compatibility, extension points (hooks, callbacks), deprecation paths. They create APIs that can evolve without breaking existing code.

Assessment example: Students design a custom block API with 6-8 blocks that includes version numbering, extension hooks, and a documented evolution strategy, demonstrating how new features can be added without breaking existing users.

Dependencies:
* T11.G7.06: Implement custom block versioning and deprecation
* T11.G8.01: Architect modular systems with plugin interfaces

---

ID: T11.G8.15
Topic: T11 – Functions & Organization
Skill: Organize large projects with multiple sprite coordination
Description: Students architect large projects (30-50+ custom blocks across 5+ sprites) with clear organizational structure: documented architecture, sprite responsibilities, communication protocols, shared utilities. They manage complexity through systematic organization.

Assessment example: Students create a substantial multi-sprite project with 30-50 custom blocks, complete architecture documentation, clear sprite responsibilities, and demonstrated coordination patterns.

Dependencies:
* T11.G6.16: Organize large projects with 15+ custom blocks
* T11.G8.07: Design microservice-inspired sprite architectures

---

ID: T11.G8.16
Topic: T11 – Functions & Organization
Skill: Architect a multi-feature project with AI-assisted code generation
Description: Students plan and build a substantial project (50+ blocks) using AI assistance strategically. They: (1) decompose the project into major features, (2) design custom block interfaces for each feature, (3) use AI to generate initial implementations, (4) review and refactor AI-generated code to meet quality standards, (5) integrate all components into a cohesive whole. This skill demonstrates professional-level project organization where AI is a tool within a thoughtful development process.

Assessment example: Students create a complete platformer game by: designing 8-10 custom blocks on paper first, using AI to generate initial code for movement and collision, manually reviewing and improving AI suggestions, adding their own blocks for scoring and level progression, and documenting the final architecture.

Dependencies:
* T11.G8.13: Evaluate and integrate AI-generated code blocks into projects
* T11.G8.14: Design custom block APIs for extensibility
* T11.G8.15: Organize large projects with multiple sprite coordination

---

ID: T11.G8.17
Topic: T11 – Functions & Organization
Skill: Design prompts that guide AI to generate well-structured custom blocks
Description: Students learn to write effective prompts that guide AI coding assistants to generate well-organized custom blocks with appropriate parameters, clear documentation, proper error handling, and consistent style. They understand how to specify architectural constraints, naming conventions, and quality requirements in prompts to get better AI-generated code.

Assessment example: Students write 3-4 detailed prompts for AI code generation that specify block structure, parameters, documentation standards, and style guidelines, then compare the quality of code generated from detailed vs vague prompts.

Dependencies:
* T11.G8.13: Evaluate and integrate AI-generated code blocks into projects
* T11.G7.07: Create self-documenting custom block interfaces

---

ID: T11.G8.18
Topic: T11 – Functions & Organization
Skill: Compare human-designed vs AI-generated code organization patterns
Description: Students analyze differences between human-designed and AI-generated code organization, identifying strengths and weaknesses of each approach. They understand that AI may generate functionally correct code with different organizational patterns than humans would choose, and practice making informed decisions about when to use AI suggestions vs human design. They critically evaluate trade-offs in readability, maintainability, and performance.

Assessment example: Students solve the same problem twice (once designed by themselves, once AI-generated), compare the organizational approaches, and write a reflective analysis of the strengths and weaknesses of each, explaining which approach they would use in production and why.

Dependencies:
* T11.G8.16: Architect a multi-feature project with AI-assisted code generation
* T11.G8.17: Design prompts that guide AI to generate well-structured custom blocks

---

ID: T11.G8.19
Topic: T11 – Functions & Organization
Skill: Create custom blocks that work with table variables
Description: Students create custom blocks that process CreatiCode's table variables (2D data structures). They design blocks like "GetPlayerStats [playerName]" that look up rows in a table, "UpdateInventory [item] [quantity]" that modify table cells, or "FilterEnemies [type]" that return filtered table data. This enables sophisticated data-driven game design.

Assessment example: Students create a high scores system with custom blocks: "AddScore [name] [score]" adds a row to the scores table, "GetTopScores [count]" returns the top N scores, and "ClearOldScores [olderThan]" removes entries older than a certain date.

Dependencies:
* T11.G6.11: Create custom blocks with variable-length parameter lists
* T13.G8.01: Use table variables for structured data storage

---

ID: T11.G8.20
Topic: T11 – Functions & Organization
Skill: Design custom blocks for real-time multiplayer coordination
Description: Students create custom blocks for multiplayer game features using CreatiCode's cloud variables and multiplayer extensions. They design blocks like "SyncPlayerPosition", "BroadcastGameEvent [event] [data]", and "HandleRemotePlayer [playerId]" that coordinate game state across multiple players. They understand the challenges of distributed state.

Assessment example: Students create a simple multiplayer game with custom blocks for: syncing player positions, handling player join/leave events, and broadcasting game actions to all players. They test with multiple browser windows.

Dependencies:
* T11.G8.09: Create custom blocks for concurrent execution coordination
* T06.G8.03: Use cloud variables for multiplayer state

---

ID: T11.G8.21
Topic: T11 – Functions & Organization
Skill: Architect AI-human hybrid systems with clear interfaces
Description: Students design system architectures where AI components (ChatGPT for decisions, speech recognition for input, AI vision for environment sensing) work alongside human-designed logic. They create clear interfaces between AI and non-AI parts: AI blocks handle uncertainty and natural language, while deterministic blocks handle game rules and state management. They document which blocks rely on AI and which are deterministic.

Assessment example: Students create an "AI Game Master" system where: AI generates story elements and dialogue, deterministic blocks enforce game rules and track state, and clear interfaces separate the two. They document the boundary and explain why certain logic is AI vs deterministic.

Dependencies:
* T11.G7.13: Design custom blocks for AI-driven features
* T11.G8.07: Design microservice-inspired sprite architectures

---

ID: T11.G8.22
Topic: T11 – Functions & Organization
Skill: Design custom blocks for procedural content generation
Description: Students create custom blocks that generate game content procedural: levels, terrain, enemies, items, or puzzles. They design blocks like `GenerateLevel [difficulty] [seed]`, `CreateRandomEnemy [tier]`, or `BuildMaze [width] [height]`. They understand how to make generation reproducible (using seeds) and configurable (using parameters).

Assessment example: Students create a procedural dungeon generator with custom blocks: "GenerateRoom [type] [size]", "ConnectRooms [room1] [room2]", "PlaceEnemies [room] [count]", "PlaceTreasure [room]". They demonstrate generating different dungeons by changing seed values.

Dependencies:
* T11.G8.05: Organize custom blocks by game system
* T11.G7.10: Create custom blocks for data transformation pipelines

---

ID: T11.G8.23
Topic: T11 – Functions & Organization
Skill: Build extensible custom block libraries for team projects
Description: Students create comprehensive custom block libraries designed for team use: consistent naming conventions, thorough documentation, versioning, backward compatibility, and clear extension points. They package blocks so other team members can use them without reading the implementation. This is professional-level API design for collaborative development.

Assessment example: Students create a "Physics2D" library with 10+ blocks for 2D physics simulation, including: complete documentation for each block, a quick-start guide, version number, and examples. They have a classmate use the library based only on documentation to verify usability.

Dependencies:
* T11.G8.14: Design custom block APIs for extensibility
* T11.G8.15: Organize large projects with multiple sprite coordination

---
# T12 – Testing, Debugging & Error Handling (Phase 9 Optimized - November 2025)
# PHASE 9 MAJOR OVERHAUL - Focus on Growth Mindset, Practical Debugging, and AI Collaboration
#
# KEY PHILOSOPHY CHANGES:
# 1. K-2 now emphasizes GROWTH MINDSET and SOCIAL-EMOTIONAL aspects of debugging
#    - Persistence and not giving up when things don't work
#    - Knowing when and how to ask for help
#    - Understanding multiple solutions can fix the same problem
#    - Celebrating mistakes as learning opportunities
# 2. Grade 3 serves as explicit BRIDGE from picture-based to code-based debugging
#    - Reading block colors and shapes to identify errors
#    - Using undo to recover from mistakes
#    - First exposure to "code bugs" vs "picture sequence bugs"
# 3. Grades 4-5 focus on PRACTICAL, COMMON bugs students actually encounter
#    - Typos and spelling errors in text/variable names
#    - Wrong variable used (x vs y, score vs lives)
#    - Pair debugging with a partner
#    - Consolidated bug classification (not 4 separate sub-skills)
# 4. Grades 6-7 introduce SYSTEMATIC debugging approaches
#    - Test-driven debugging (expected outcome FIRST)
#    - Console.log-style debugging
#    - UI/Widget debugging specific to CreatiCode
#    - Systematic elimination method
# 5. Grade 8 adds MODERN debugging contexts
#    - Debugging AI-generated code specifically
#    - Multiplayer/distributed state debugging
#    - Performance profiling
#    - Writing code that's EASY to debug (prevention)
#
# SKILLS REORGANIZED FROM PHASE 8:
# - T12.G4.08.01-04 (4 bug classification sub-skills) → Consolidated to 1 skill (G4.09)
# - Redundant tracing skills merged
# - Similar "hypothesis" skills combined
#
# NEW SKILLS ADDED:
# K-2: Growth mindset focus (GK.07-10, G1.06-08, G2.06-08) - asking for help, multiple solutions, celebration
# G3: Bridge skills for picture→code transition (G3.02, G3.03) - undo usage, error indicators
# G4-5: Practical bugs (G4.04, G4.05, G4.11) - typos, wrong variable, pair debugging
# G6-7: Systematic approaches (G6.03, G6.08, G6.09) - test-driven, UI debugging, elimination
# G8: Modern contexts (G8.09, G8.10, G8.13) - distributed state, performance, prevention
#
# Total: 107 skills across K-8 (optimized from 105)
# All dependencies verified for X-2 rule compliance
# Cross-topic dependencies preserved unchanged

## Kindergarten (10 skills) - Focus on Growth Mindset Foundation

ID: T12.GK.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Spot a wrong action in a picture sequence
Description: **Student task:** View 4 picture cards showing a robot getting a ball. One card shows the robot doing something wrong. Tap the wrong card. **Visual scenario:** Cards show: (A) Robot sees ball, (B) Robot walks toward ball, (C) Robot turns away from ball [WRONG], (D) Robot reaches for ball. **Correct answer:** Card C is wrong - robot turns away instead of toward the ball. _Implementation note: Single-tap selection on wrong card; audio prompt "Which picture shows something wrong?" Large colorful cards with clear robot actions. CSTA: K-2 debugging concepts._


ID: T12.GK.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Compare your result to the goal and try again
Description: **Student task:** Follow picture card steps to build a block tower. Compare your tower to the goal picture. If it doesn't match, tap "Try Again" and rebuild. **Visual scenario:** Goal shows red-blue-green tower. Student follows 3 instruction cards. If tower is red-green-blue (wrong order), they see "Does it match? No!" and tap retry button. **Success criteria:** Student identifies mismatch and chooses to retry. _Implementation note: Interactive tower-building with visual comparison; "try, check, retry" cycle chart displayed; audio: "Does your tower match? Try again!" CSTA: K-2 debugging, iterative improvement._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine
* T12.GK.01: Spot a wrong action in a picture sequence


ID: T12.GK.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Fix one wrong arrow card to reach the goal
Description: **Student task:** A bunny wants to reach the carrot on a 3x3 grid. The arrow cards guide the bunny, but one arrow is wrong. Find and swap the wrong arrow. **Visual scenario:** Grid shows bunny at bottom-left, carrot at top-right. Arrow cards: → → ↑ (but middle arrow should be ↑). Bunny ends up at wrong square. Student drags correct arrow (↑) to replace wrong arrow (→). **Correct answer:** Replace second → with ↑. _Implementation note: 3x3 grid with animated bunny; drag-and-drop arrow swap; visual path tracing shows where bunny goes; audio: "Oh no! Wrong square. Which arrow is wrong?" CSTA: K-2 debugging._

Dependencies:
* T01.GK.03: Tap the first and last picture cards in a sequence
* T12.GK.01: Spot a wrong action in a picture sequence


ID: T12.GK.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Sort picture cards into "works" and "doesn't work"
Description: **Student task:** Look at 4 picture cards showing a character doing steps. Drag cards that show correct steps to the "Works" box and wrong steps to the "Doesn't Work" box. **Visual scenario:** Cards show making a sandwich: (A) Put bread on plate (correct), (B) Spread peanut butter (correct), (C) Put lid on jar before spreading (wrong), (D) Eat sandwich (correct). **Correct sorting:** A, B, D → Works; C → Doesn't Work. _Implementation note: Two-box sorting with drag-drop; green checkmark for Works box, red X for Doesn't Work box; audio feedback. CSTA: K-2 categorizing errors._

Dependencies:
* T12.GK.01: Spot a wrong action in a picture sequence


ID: T12.GK.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Keep trying when the first way does not work
Description: **Student task:** Complete a puzzle where the first path shown doesn't work. Tap "Try Different Way" to see another option and complete it. **Visual scenario:** A character wants to reach a cookie. Path A is blocked by a big rock (character tries, fails, X appears). Student taps "Try Different Way" button. Path B appears going around the rock. Student taps to make character take Path B and reach the cookie. **Success criteria:** Student demonstrates willingness to try alternative approach rather than giving up. _Implementation note: Visual "stuck" moment with clear alternative; celebrates "Good thinking - you tried a different way!" Builds growth mindset foundation - mistakes are chances to learn. CSTA: K-2 iteration and persistence._

Dependencies:
* T12.GK.02: Compare your result to the goal and try again


ID: T12.GK.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Compare what you expected to what actually happened
Description: **Student task:** Look at "I WANTED" and "I GOT" picture pairs. Tap the pair where "I GOT" is DIFFERENT from "I WANTED". **Visual scenario:** Two pairs shown: Pair A - "I WANTED" shows 3 red blocks stacked, "I GOT" shows 3 red blocks stacked (SAME). Pair B - "I WANTED" shows tall tower, "I GOT" shows short tower (DIFFERENT). Question: "Which one didn't match what you wanted?" **Correct answer:** Pair B. _Implementation note: Introduces the core debugging question "What did I expect vs. what happened?" Visual comparison with color-coded "WANTED" (green) and "GOT" (blue) labels. Foundation for expectation-based debugging. CSTA: K-2 prediction and verification._

Dependencies:
* T12.GK.01: Spot a wrong action in a picture sequence
* T12.GK.02: Compare your result to the goal and try again


ID: T12.GK.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Ask a friend for help when stuck
Description: **Student task:** Practice using the "I need help" signal when a puzzle is too hard. **Visual scenario:** Character is stuck at a puzzle that's too difficult. Three choices appear: (A) Give up and walk away (sad face), (B) Keep doing the same wrong thing again and again (frustrated face), (C) Raise hand and ask "Can you help me?" (happy face with friend). **Correct answer:** C - asking for help. Discussion: "It's smart to ask for help! Everyone needs help sometimes." _Implementation note: Unplugged activity with picture-based choices; role-play asking for help; introduces concept that good problem-solvers know when to seek guidance. CSTA: K-2 collaboration._

Dependencies:
* T12.GK.05: Keep trying when the first way does not work


ID: T12.GK.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Find two different ways to fix the same problem
Description: **Student task:** A character needs to cross a gap. Find TWO different ways to help the character cross. **Visual scenario:** Character on left side, gap in middle, goal on right. Available tools: (A) Bridge picture card, (B) Ladder picture card, (C) Jumping boots picture card, (D) Banana picture card (doesn't help). Student drags TWO cards that would work. **Correct answers:** Any two of A, B, or C (all three work). **Key learning:** "There's more than one right answer! Different solutions can solve the same problem." _Implementation note: Multi-select drag-drop; celebrates finding multiple solutions; foundation for understanding there are many ways to fix bugs. CSTA: K-2 multiple solutions._

Dependencies:
* T12.GK.03: Fix one wrong arrow card to reach the goal
* T12.GK.05: Keep trying when the first way does not work


ID: T12.GK.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Check your work before saying "I'm done"
Description: **Student task:** After arranging picture cards, use the "Check My Work" button before finishing. **Visual scenario:** Student arranges 4 getting-ready-for-school cards. Before tapping "Done," they must tap "Check My Work" which animates the sequence. If something is wrong, they see the problem and can fix it. If correct, they get celebration. **Key learning:** "Good problem-solvers always check their work!" _Implementation note: Explicit check step required before final submission; visual animation of sequence helps spot errors; builds verification habit. CSTA: K-2 testing and verification._

Dependencies:
* T12.GK.02: Compare your result to the goal and try again
* T12.GK.06: Compare what you expected to what actually happened


ID: T12.GK.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Celebrate finding and fixing a mistake
Description: **Student task:** Find a mistake in a picture sequence, fix it, and celebrate the learning moment. **Visual scenario:** 4-card sequence has one obvious error. After student fixes it, celebration screen shows: "You found a bug! Fixing mistakes is how we learn!" with stars and happy character. Student taps "I'm a Bug Hunter!" badge. **Key learning:** Mistakes aren't bad - they're chances to learn and get better. _Implementation note: Positive reinforcement for error-finding; reframes debugging as achievement; growth mindset messaging throughout. CSTA: K-2 debugging mindset._

Dependencies:
* T12.GK.03: Fix one wrong arrow card to reach the goal
* T12.GK.05: Keep trying when the first way does not work


## Grade 1 (8 skills) - Building Persistence and Explanation Skills

ID: T12.G1.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Tap the wrong step and explain why it is wrong
Description: **Student task:** View 5 picture cards showing "brushing teeth" steps. One card is in the wrong place. Tap the wrong card and complete the sentence: "This step is wrong because ___." **Visual scenario:** Cards show: (A) Get toothbrush, (B) Brush teeth [WRONG - too early], (C) Put toothpaste on brush, (D) Brush teeth, (E) Rinse mouth. **Correct answer:** Tap card B; explanation: "This step is wrong because you need toothpaste first." _Implementation note: Tap selection + sentence completion with word bank (first/before/after); audio reads sentence starter. CSTA: 1A-AP debugging with explanation._

Dependencies:
* T01.GK.03: Tap the first and last picture cards in a sequence
* T12.GK.01: Spot a wrong action in a picture sequence


ID: T12.G1.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Drag picture cards to fix a scrambled sequence
Description: **Student task:** 5 picture cards for "getting dressed" are scrambled. Drag them into the correct order, then tap "Check" to verify. **Visual scenario:** Scrambled cards: socks, shirt, shoes, pants, underwear. **Correct order:** underwear → pants → shirt → socks → shoes. After arranging, student taps Check and animation shows character getting dressed in that order. _Implementation note: Drag-and-drop reordering with animated verification; audio reads back sequence; "Try Again" if wrong. CSTA: 1A-AP-11 sequencing and debugging._

Dependencies:
* T01.GK.02: Sequence four picture cards for a classroom arrival routine
* T12.GK.02: Compare your result to the goal and try again


ID: T12.G1.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Change a number on an instruction card to fix the result
Description: **Student task:** A frog needs to jump 5 times to reach a lily pad. The instruction card says "Jump 2 times." Change the number to make it work. **Visual scenario:** Frog on left, lily pad 5 hops away. Instruction card shows jumping frog icon with "2". Student uses number spinner (1-9) to change 2 to 5. Animation shows frog jumping 5 times and landing on lily pad. _Implementation note: Number spinner on card; animated preview of result; audio: "The frog jumped 2 times but needs 5!" CSTA: 1A-AP debugging with values._

Dependencies:
* T04.GK.02: Extend a repeating pattern by one tile
* T12.GK.02: Compare your result to the goal and try again


ID: T12.G1.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Act out picture steps and point to where it went wrong
Description: **Student task:** Act out 4 picture card steps for "making a paper airplane." When the airplane doesn't fly, point to which step caused the problem. **Visual scenario:** Cards show: (A) Fold paper in half, (B) Fold wings, (C) Skip creasing the fold [WRONG], (D) Throw airplane. Student acts out each step, airplane falls flat, student points to card C and says "I went wrong here because the fold wasn't creased." _Implementation note: Unplugged activity; video model of steps; selection interface for choosing problematic card; verbal explanation recorded or typed. CSTA: 1A-AP unplugged debugging._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine
* T12.G1.01: Tap the wrong step and explain why it is wrong


ID: T12.G1.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Predict what happens next before checking
Description: **Student task:** Look at 3 picture card steps. Before seeing the result, predict what will happen by tapping one of 3 outcome pictures. Then tap "Check" to see if you were right. **Visual scenario:** Steps show: (A) Put seeds in pot, (B) Water the seeds, (C) Put pot in sunny window. Outcome choices: (1) Flowers grow, (2) Seeds stay dry, (3) Pot falls over. **Correct prediction:** Flowers grow. _Implementation note: Prediction selection before reveal; "Was your prediction correct?" reflection prompt; builds testing mindset. CSTA: 1A-AP prediction and verification._

Dependencies:
* T12.GK.02: Compare your result to the goal and try again
* T01.GK.06: Predict the next picture card in a sequence


ID: T12.G1.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Try three different ways to solve a puzzle
Description: **Student task:** A duck needs to cross a pond. Try THREE different ways and mark which ones work. **Visual scenario:** Duck on left, pond in middle, nest on right. Options: (A) Swim across - WORKS, (B) Walk on water - DOESN'T WORK, (C) Use stepping stones - WORKS, (D) Fly over - WORKS, (E) Dig under - DOESN'T WORK. Student tries at least 3 options and marks results. **Key learning:** "Testing different ideas helps us find what works!" _Implementation note: Multi-attempt interface; tracks which solutions student tried; celebrates experimentation. CSTA: 1A-AP multiple solutions._

Dependencies:
* T12.GK.08: Find two different ways to fix the same problem
* T12.G1.03: Change a number on an instruction card to fix the result


ID: T12.G1.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Describe a problem clearly to get help
Description: **Student task:** Practice describing a problem using the sentence: "I tried ___ but ___ happened instead of ___." **Visual scenario:** Sorting activity where a character tried to build a tall tower but it keeps falling. Student completes: "I tried stacking 10 blocks but the tower fell instead of standing tall." Then practices with 2 more scenarios. **Key learning:** "When you explain clearly, helpers can help you better!" _Implementation note: Sentence frame completion; builds vocabulary for asking for help effectively; partner activity option. CSTA: 1A-AP communication._

Dependencies:
* T12.GK.07: Ask a friend for help when stuck
* T12.G1.01: Tap the wrong step and explain why it is wrong


ID: T12.G1.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Celebrate mistakes as learning moments
Description: **Student task:** After making and fixing a mistake, complete the reflection: "First I made this mistake: ___. Then I learned: ___." **Visual scenario:** Student completes a debugging task, then fills in reflection template. Examples: "First I made this mistake: put shoes before socks. Then I learned: order matters for getting dressed!" **Key celebration:** "Every mistake teaches us something new!" _Implementation note: Reflection activity after each debugging task; builds growth mindset; portfolio of "lessons learned." CSTA: 1A-AP metacognition._

Dependencies:
* T12.GK.10: Celebrate finding and fixing a mistake
* T12.G1.04: Act out picture steps and point to where it went wrong


## Grade 2 (8 skills) - Structured Debugging with Picture Cards

ID: T12.G2.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Fix a wrong trigger signal in a picture rule card
Description: **Student task:** A rule card says "When you see RED card, clap." But the demo shows clapping when BLUE card appears. Fix the rule by selecting the correct signal. **Visual scenario:** Rule card shows "When [BLUE card], do [clap hands]" - this is wrong. Student selects RED card from 4 color options (red, blue, green, yellow) to fix the trigger. Animation shows corrected rule working: RED card → clap. _Implementation note: Signal selection from color/symbol options; animated demonstration of broken vs fixed rule; builds event-trigger debugging. CSTA: 1A-AP-11 event debugging._

Dependencies:
* T01.G1.06: Drag the wrong step to its correct spot
* T12.G1.01: Tap the wrong step and explain why it is wrong


ID: T12.G2.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Trace arrow cards on a grid and predict the ending square
Description: **Student task:** View 5 arrow cards for a robot on a 4x4 grid. Before the robot moves, click the square where you predict it will end. Then tap "Go" to check. **Visual scenario:** Robot starts at (1,1). Arrow cards: → → ↑ ↑ →. Student clicks predicted end square (4,3). Robot animates along path. **Correct prediction:** Square (4,3). If wrong, path is highlighted to show where prediction diverged. _Implementation note: Grid with clickable squares; animated path tracing; prediction vs actual comparison; mental tracing practice. CSTA: 1A-AP tracing and prediction._

Dependencies:
* T01.G1.05: Identify the missing step in a picture routine
* T12.G1.05: Predict what happens next before checking


ID: T12.G2.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Fix the repeat count on a loop picture card
Description: **Student task:** A kangaroo needs to hop across 5 stepping stones. The loop card says "Repeat 3 times: [hop]." Fix the number so the kangaroo crosses all stones. **Visual scenario:** 5 stepping stones across a river. Loop card shows "Repeat [3] times" with hop icon. Kangaroo hops 3 times and falls in water. Student changes 3 to 5 using spinner. Kangaroo successfully crosses. _Implementation note: Visual loop card with editable number; animated result preview; clear cause-effect between number and outcome. CSTA: 1A-AP loop debugging._

Dependencies:
* T04.G1.01: Identify which part of a pattern repeats
* T12.G1.03: Change a number on an instruction card to fix the result


ID: T12.G2.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Add a checkpoint card to verify progress at a key point
Description: **Student task:** A sequence has 6 steps for a character to collect 3 coins. Add a checkpoint card after step 3 to verify 2 coins are collected. **Visual scenario:** 6 step cards for coin collection. Student drags checkpoint card (star icon) between step 3 and 4. When tracing, animation pauses at checkpoint showing "Checkpoint: 2 coins? Yes!" before continuing. _Implementation note: Drag checkpoint card into sequence; pause-and-verify animation; teaches incremental testing. CSTA: 1A-AP verification and testing._

Dependencies:
* T12.G1.05: Predict what happens next before checking
* T12.G2.02: Trace arrow cards on a grid and predict the ending square


ID: T12.G2.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Match error types to picture examples
Description: **Student task:** Match 3 error type cards to the correct picture examples. Error types: (A) Wrong Order, (B) Wrong Number, (C) Missing Step. **Visual scenario:** Picture examples show: (1) Recipe with "bake" before "mix ingredients" → Wrong Order, (2) "Jump 2 times" but need 5 jumps → Wrong Number, (3) Plant sequence missing "water" step → Missing Step. _Implementation note: Drag-and-drop matching; 3 error type cards to 3 example pictures; categorization of error types prepares for Grade 3 coding. CSTA: 1A-AP error categorization._

Dependencies:
* T12.G1.01: Tap the wrong step and explain why it is wrong
* T12.G1.03: Change a number on an instruction card to fix the result


ID: T12.G2.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Work with a partner to find and fix an error
Description: **Student task:** With a partner, take turns being the "Bug Finder" and the "Bug Fixer." One person finds the bug, the other person fixes it. **Visual scenario:** 4-card sequence with one error. Partner A identifies the wrong card, Partner B drags it to correct position. Then swap roles for next puzzle. **Key learning:** "Two people working together can solve problems faster!" _Implementation note: Partner activity; role cards for Bug Finder/Bug Fixer; rotation system; builds collaborative debugging. CSTA: 1A-AP collaboration._

Dependencies:
* T12.G1.07: Describe a problem clearly to get help
* T12.G2.01: Fix a wrong trigger signal in a picture rule card


ID: T12.G2.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Explain your fix to a classmate
Description: **Student task:** After fixing a bug, explain to a partner WHY your fix worked using the sentence: "I changed ___ to ___ because ___." **Visual scenario:** After fixing arrow card puzzle, student explains: "I changed the second arrow from RIGHT to UP because the bunny needed to go up to reach the carrot." Partner gives thumbs up if explanation makes sense. _Implementation note: Verbal explanation activity; partner feedback; builds debugging communication skills. CSTA: 1A-AP explanation._

Dependencies:
* T12.G2.03: Fix the repeat count on a loop picture card
* T12.G2.05: Match error types to picture examples


ID: T12.G2.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Keep a "Bugs I Found" picture journal
Description: **Student task:** After each debugging activity, draw or paste a picture of the bug you found and how you fixed it in your journal. **Visual scenario:** Simple journal template with "Bug I Found" box (draw the problem) and "How I Fixed It" box (draw the solution). Over time, students see patterns in bugs they find. **Key learning:** "Recording what you learn helps you remember!" _Implementation note: Paper or digital journal; builds metacognitive awareness; review sessions to identify patterns. CSTA: 1A-AP documentation._

Dependencies:
* T12.G1.08: Celebrate mistakes as learning moments
* T12.G2.05: Match error types to picture examples


## Grade 3 (10 skills) - Bridge from Picture Cards to Block Code

ID: T12.G3.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Recognize that bugs occur when code does not match intent
Description: Students understand the fundamental concept: **A bug is a mismatch between what you WANTED and what you WROTE**. Given 3 scenarios showing: (1) Intent: "move right" → Code: `move -100 steps` → Result: sprite moves left = BUG, (2) Intent: "say hello" → Code: `say "Hello"` → Result: says hello = NO BUG, (3) Intent: "wait 2 seconds" → Code: `wait 20 secs` → Result: waits too long = BUG. Students identify which are bugs and explain the intent-code mismatch. This bridges G2 picture-based error spotting to G3 code-based debugging. _Assessment: Classify 3 scenarios as bug/no-bug with explanation of mismatch._

Dependencies:
* T12.G2.05: Match error types to picture examples
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence


ID: T12.G3.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Identify error indicators by block color and shape in CreatiCode
Description: Students learn to recognize visual error indicators in CreatiCode: (1) **Red/orange blocks** - blocks that turn red or orange indicate invalid inputs or connections, (2) **Detached blocks** - blocks floating separately won't run, (3) **Missing hat blocks** - scripts without green flag or event blocks won't start. Given 4 example scripts, students identify which have visual error indicators and what they mean. _Assessment: Multiple choice matching error screenshots to error type names._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.G3.01: Recognize that bugs occur when code does not match intent


ID: T12.G3.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use undo to recover from mistakes in block code
Description: Students practice using CreatiCode's undo feature (Ctrl+Z or Edit menu) to recover from mistakes. Scenarios: (1) Accidentally deleted a block → undo to restore, (2) Changed wrong value → undo to revert, (3) Moved block to wrong place → undo to return. Students learn: "Undo is your friend! Don't panic when you make a mistake." Also introduces redo (Ctrl+Y) to redo if you undo too much. _Assessment: Given 3 mistake scenarios, use undo/redo to recover; demonstrate understanding of when to use each._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.GK.05: Keep trying when the first way does not work


ID: T12.G3.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Trace a 5-block script mentally then run to verify
Description: Students practice the trace-then-test workflow: (1) **TRACE** - Read a 5-block script (e.g., `when green flag clicked`, `go to x:0 y:0`, `move 100 steps`, `turn right 90 degrees`, `say "Hello!"`) and predict the sprite's final position and speech without running it. (2) **TEST** - Run the script and compare actual behavior to prediction. (3) **ISOLATE** - If prediction was wrong, identify which block caused the surprise by clicking blocks one at a time. _Assessment: Predict final x,y coordinates and message before running; auto-graded by prediction accuracy._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.G2.02: Trace arrow cards on a grid and predict the ending square
* T12.G3.02: Identify error indicators by block color and shape in CreatiCode


ID: T12.G3.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Fix a wrong value or direction in a single block
Description: Students debug a script where one block has an incorrect value or direction. Examples: (1) `move 10 steps` should be `move 100 steps` to reach the goal, (2) `turn right 90` should be `turn left 90` to face the target, (3) `say "Goodbye"` should be `say "Hello"`. They identify the wrong block and change only its parameter or dropdown selection. _Assessment: Given buggy script and goal description, student modifies one block; auto-graded by script behavior._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.G2.03: Fix the repeat count on a loop picture card


ID: T12.G3.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Add a missing block to complete a script
Description: Students debug a script that's missing one essential block. Examples: (1) Script moves sprite but forgot `point in direction 90` first, so sprite moves in wrong direction, (2) Script should say hello then move, but `say "Hello"` is missing, (3) Loop has no stopping condition. Students identify what's missing and where it should go, then add the block. _Assessment: Given incomplete script and expected behavior, student adds one block; auto-graded by behavior match._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.G2.02: Trace arrow cards on a grid and predict the ending square


ID: T12.G3.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply the Run-Observe-Change-Test cycle
Description: Students practice the iterative debugging cycle on a buggy script with 2-3 errors: (1) **RUN** - Click green flag, (2) **OBSERVE** - Note what went wrong (wrong direction, wrong message, wrong position), (3) **CHANGE** - Make ONE specific change to fix one problem, (4) **TEST** - Run again to check. Repeat cycle until all bugs are fixed. Key learning: Making one change at a time helps isolate problems. _Assessment: Given script with multiple bugs, student applies cycle; tracked by number of runs and successful fixes._

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T12.G3.04: Trace a 5-block script mentally then run to verify
* T12.G2.04: Add a checkpoint card to verify progress at a key point


ID: T12.G3.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Point to the bug and explain why it causes the problem
Description: Students run a buggy script, identify the problematic block, AND explain the cause-effect relationship. Example: Script should make sprite face right then move to x:200, but sprite moves left. Student identifies `point in direction -90` and explains: "This block points left (-90) instead of right (90), so the sprite moves the wrong way." The explanation must connect the bug to the symptom. _Assessment: Select buggy block + complete explanation sentence; both must be correct._

Dependencies:
* T12.G3.04: Trace a 5-block script mentally then run to verify
* T12.G3.05: Fix a wrong value or direction in a single block


ID: T12.G3.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Reorder blocks to fix a sequence bug
Description: Students debug a script where blocks are in the wrong order. Example: Script should go to starting position, then repeat moving and turning, but `go to x:0 y:0` is inside the loop instead of before it. Student drags `go to` block outside and before the loop. _Assessment: Drag blocks to correct positions; auto-graded by behavior match._

Dependencies:
* T12.G3.04: Trace a 5-block script mentally then run to verify
* T12.G3.06: Add a missing block to complete a script


ID: T12.G3.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use step-by-step mode to trace one block at a time
Description: Students use CreatiCode's step-by-step execution feature (blue arrow button) to execute scripts one block at a time. For each step: (1) Predict what the highlighted block will do, (2) Click Step button to execute just that block, (3) Observe the result, (4) Compare prediction to actual behavior. This helps isolate exactly which block causes unexpected behavior. _Assessment: Use step mode on a 6-8 block script; identify which step produces unexpected result._

Dependencies:
* T12.G3.04: Trace a 5-block script mentally then run to verify
* T12.G3.07: Apply the Run-Observe-Change-Test cycle


## Grade 4 (12 skills) - Practical Debugging with Test Plans

ID: T12.G4.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug a conditional statement inside a loop
Description: Students debug programs with an `if` block inside a `repeat` loop. Bug types: (1) Wrong condition value (e.g., `if score > 5` should be `if score > 10`), (2) Missing action inside if-block, (3) Condition that never becomes true. Students trace through 2-3 loop iterations mentally to identify when the bug triggers. _Assessment: Given loop-with-conditional, identify and fix the bug; auto-graded._

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if statement in a script
* T12.G3.07: Apply the Run-Observe-Change-Test cycle


ID: T12.G4.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Identify and test edge cases for a program
Description: Students learn that **edge cases** are extreme or unusual inputs that often cause bugs: zero values, maximum/minimum values, boundary positions (x=240, y=180), empty conditions. Given a program, they: (1) Brainstorm 3 edge cases (e.g., "What if score is 0?", "What if sprite is at stage edge?"), (2) Test each edge case manually, (3) Record pass/fail for each. _Assessment: Generate edge cases + test results table; at least 2 edge cases must be valid._

Dependencies:
* T08.G3.04: Use a simple if statement in a script
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T12.G3.07: Apply the Run-Observe-Change-Test cycle


ID: T12.G4.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Diagnose and fix an infinite loop
Description: Students recognize when a `forever` or `repeat until` loop never exits (sprite freezes, program hangs). They diagnose the cause: (1) Condition never becomes true (e.g., `repeat until score > 100` but score never increases), (2) Missing update inside loop, (3) Wrong comparison operator. They fix by adding the missing update or correcting the condition. _Assessment: Given stuck program, identify cause + apply fix; auto-graded._

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if statement in a script
* T12.G3.08: Point to the bug and explain why it causes the problem


ID: T12.G4.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug typos and spelling errors in code
Description: Students debug common typo-related bugs that are hard to spot: (1) **Variable name typos**: `scroe` instead of `score`, (2) **Text typos in say/ask**: `"Helo"` instead of `"Hello"`, (3) **Case sensitivity**: `Score` vs `score` (in variable names). Strategy: Carefully read each word letter-by-letter; use copy-paste to avoid retyping. _Assessment: Debug 3 programs with typo bugs; identify exact character that's wrong._

Dependencies:
* T12.G3.05: Fix a wrong value or direction in a single block
* T09.G3.01.01: Create a variable and give it a starting value


ID: T12.G4.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug wrong variable used errors
Description: Students debug programs where the wrong variable is used. Examples: (1) `change x by 10` when should be `change y by 10`, (2) Adding to `lives` when should add to `score`, (3) Checking `playerX` when should check `enemyX`. These are common bugs where the code "runs" but does the wrong thing. Students practice: "Am I using the right variable for what I want to do?" _Assessment: Debug 3 wrong-variable bugs; explain which variable should be used and why._

Dependencies:
* T09.G3.01.01: Create a variable and give it a starting value
* T12.G4.01: Debug a conditional statement inside a loop


ID: T12.G4.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Write a test plan with 5 test cases before running
Description: Students create a test plan template with three columns: **Input/Action**, **Expected Result**, **Pass/Fail** (blank). They write 5 test cases BEFORE running the program. Example for a score checker: (1) score=0 → "Try again", (2) score=5 → "Good job", (3) score=10 → "Great!", (4) score=-1 → should handle gracefully, (5) score=100 → "Perfect!". Key learning: Document expectations before testing. _Assessment: Test plan with 5 valid test cases; graded on case variety and expected result accuracy._

Dependencies:
* T08.G3.04: Use a simple if statement in a script
* T12.G3.07: Apply the Run-Observe-Change-Test cycle
* T12.G4.02: Identify and test edge cases for a program


ID: T12.G4.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Execute test plan and record Pass/Fail results
Description: Students run their program with each test case from their test plan and record results: **Pass** (actual matched expected) or **Fail** (actual differed from expected). For failures, they note what actually happened. After all tests, they summarize: "X of Y tests passed." _Assessment: Completed test plan with accurate Pass/Fail markings; failures must include actual result observed._

Dependencies:
* T12.G4.06: Write a test plan with 5 test cases before running


ID: T12.G4.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Document what went wrong and how you fixed it
Description: After fixing a bug, students write a **bug report** using a template: (1) **Symptom:** What happened wrong? (e.g., "Sprite moved backward instead of forward"), (2) **Cause:** Which block had the bug? (e.g., "`move -10 steps` should be `move 10 steps`"), (3) **Fix:** What did you change? (e.g., "Changed -10 to 10"). This creates a debugging log. _Assessment: Complete bug report template for 1-2 bugs._

Dependencies:
* T12.G3.07: Apply the Run-Observe-Change-Test cycle
* T12.G3.08: Point to the bug and explain why it causes the problem


ID: T12.G4.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Classify bugs as sequence, value, or logic errors
Description: Students examine buggy programs and classify bugs into three main categories: (1) **Sequence errors** - blocks in wrong order (e.g., `say` before `go to`), (2) **Value errors** - correct block but wrong number/text (e.g., `move 10` should be `move 100`), (3) **Logic errors** - wrong operator or condition (e.g., `>` should be `<`). Classification helps choose the right fix strategy. _Assessment: Classify 5 bugs into the 3 categories; explain classification reasoning._

Dependencies:
* T12.G3.09: Reorder blocks to fix a sequence bug
* T12.G4.08: Document what went wrong and how you fixed it


ID: T12.G4.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Add print blocks to trace which code is running
Description: Students add `print [message] in [console v]` blocks at key points to trace execution: (1) Before loop: `print "entering loop"`, (2) Inside loop: `print "loop iteration"`, (3) Inside conditional: `print "condition was true"`. They run the program and read console output to understand execution order. After debugging, they remove print blocks. _Assessment: Add 3+ print blocks to trace a buggy program; identify where execution diverges from expectation._

Dependencies:
* T12.G3.07: Apply the Run-Observe-Change-Test cycle
* T12.G4.08: Document what went wrong and how you fixed it


ID: T12.G4.11
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug with a partner using pair debugging
Description: Students practice **pair debugging** - one person is the "Driver" (controls the computer) and one is the "Navigator" (watches and thinks). Process: (1) Navigator reads code aloud, (2) Driver traces execution, (3) Both discuss what seems wrong, (4) Navigator suggests changes, (5) Driver implements. Swap roles every 5 minutes. **Key learning:** Two sets of eyes catch bugs faster! _Assessment: Debug a program using pair debugging; document roles and what each person contributed._

Dependencies:
* T12.G2.06: Work with a partner to find and fix an error
* T12.G4.10: Add print blocks to trace which code is running


ID: T12.G4.12
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use colored print blocks to categorize debug output
Description: Students use CreatiCode's `print [message] in [console v] color [COLOR]` block to color-code debug output. Categories: (1) **Green** - success/entry points, (2) **Yellow** - warnings/checkpoints, (3) **Red** - errors/unexpected values, (4) **Blue** - variable values. Colored output makes it easier to spot patterns in console. _Assessment: Add 4+ print blocks using at least 3 colors; explain color choice; identify bug using colored output._

Dependencies:
* T12.G4.10: Add print blocks to trace which code is running


## Grade 5 (14 skills) - Defensive Programming and Systematic Debugging

ID: T12.G5.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use say blocks to display variable values during execution
Description: Students add `say (join "score=" score) for 0.5 secs` blocks inside loops to watch variable values change during execution. Example: Inside a counting loop, `say (join "i=" i)` shows i=1, i=2, i=3... This helps identify when variables don't update as expected (e.g., score stuck at 0). _Assessment: Add say blocks showing 2+ variables; identify which variable has unexpected values._

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T12.G4.10: Add print blocks to trace which code is running


ID: T12.G5.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Enable variable monitors to track multiple values in real-time
Description: Students enable variable monitors (checkbox in variable palette) to display 3+ variables on stage simultaneously. Unlike say blocks, monitors update in real-time without pausing execution. Students observe variable relationships (e.g., x and y changing together during movement, score and lives updating). _Assessment: Enable monitors for 3+ variables; describe how values change and identify unexpected patterns._

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T12.G5.01: Use say blocks to display variable values during execution


ID: T12.G5.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Combine multiple tracing methods to isolate a bug
Description: Students combine techniques for complex bugs: (1) **Print blocks** for console log, (2) **Say blocks** for visual flow, (3) **Variable monitors** for real-time values. Strategy: Add output before loop, inside loop, inside conditional, after loop. Compare expected vs actual output at each point to narrow down bug location. _Assessment: Debug a complex program using 3+ methods; document which method revealed the bug._

Dependencies:
* T12.G5.01: Use say blocks to display variable values during execution
* T12.G5.02: Enable variable monitors to track multiple values in real-time
* T12.G4.12: Use colored print blocks to categorize debug output


ID: T12.G5.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Add input validation to reject invalid entries
Description: Students add conditional checks after `ask` blocks to validate user input: (1) Check if answer is a number when expected, (2) Check if number is in valid range (e.g., 1-10), (3) Provide feedback and re-ask if invalid. Example: `ask "Enter 1-10"` then `if answer < 1 or answer > 10 then say "Invalid! Try again"`. _Assessment: Add validation to 2+ inputs; demonstrate handling of invalid entries._

Dependencies:
* T08.G3.04: Use a simple if statement in a script
* T12.G4.02: Identify and test edge cases for a program
* T07.G4.01: Use repeat-until to create a conditional loop


ID: T12.G5.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Create a test plan covering normal, boundary, and invalid cases
Description: Students design test plans with three categories: (1) **Normal cases** - typical expected inputs (3 tests), (2) **Boundary cases** - edge values like 0, max, min (3 tests), (3) **Invalid inputs** - out of range, wrong type (2 tests). Total: 8+ test cases. After running, summarize: "Normal: 3/3 pass, Boundary: 2/3 pass, Invalid: 1/2 pass." _Assessment: Test plan with 8+ cases across 3 categories; summary analysis._

Dependencies:
* T12.G4.07: Execute test plan and record Pass/Fail results
* T12.G5.04: Add input validation to reject invalid entries


ID: T12.G5.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Add defensive checks before risky operations
Description: Students identify risky operations and add defensive if-checks: (1) **Division**: `if divisor ≠ 0 then [divide]`, (2) **List access**: `if length of list > 0 then [item 1 of list]`, (3) **Position**: `if x < 240 then [move right]`. They test with edge cases that would have failed without the check. _Assessment: Add defensive checks to 3+ risky operations; demonstrate edge case handling._

Dependencies:
* T12.G4.02: Identify and test edge cases for a program
* T12.G5.04: Add input validation to reject invalid entries
* T08.G4.03: Use if-else to create two-branch decisions


ID: T12.G5.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Clamp values to stay within valid boundaries
Description: Students add boundary clamping: (1) **Score floor**: `if score < 0 then set score to 0`, (2) **Stage edges**: `if x > 240 then set x to 240`, (3) **Timer minimum**: `if timer < 0 then set timer to 0`. This prevents undefined behavior by keeping values in valid ranges. _Assessment: Add clamping for 3+ boundaries; verify boundary values are handled._

Dependencies:
* T12.G5.06: Add defensive checks before risky operations
* T08.G4.03: Use if-else to create two-branch decisions


ID: T12.G5.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug two-level nested structures
Description: Students debug programs with two-level nesting: (1) **Nested loops**: `repeat 3 [repeat 4 [...]]` where bug is in inner or outer loop count, (2) **If-else in loop**: `repeat 10 [if-else [...][...]]` where bug is in condition or one branch. Strategy: Add print/say blocks at each nesting level to identify which level causes the bug. _Assessment: Debug 2+ nested structure bugs; document which level had the error._

Dependencies:
* T07.G4.01: Use repeat-until to create a conditional loop
* T08.G4.03: Use if-else to create two-branch decisions
* T12.G4.01: Debug a conditional statement inside a loop


ID: T12.G5.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Interpret error indicators to form debugging hypotheses
Description: Students systematically interpret CreatiCode error indicators: (1) **Red/orange block** → invalid parameter (check inputs), (2) **Frozen sprite** → infinite loop or blocking call (check loop conditions), (3) **Script doesn't run** → missing trigger or disconnected blocks (check hat block). For each indicator type, they form a hypothesis and test it. _Assessment: Given 3 error scenarios, identify indicator type + form correct hypothesis for each._

Dependencies:
* T12.G3.02: Identify error indicators by block color and shape in CreatiCode
* T12.G5.03: Combine multiple tracing methods to isolate a bug
* T12.G4.03: Diagnose and fix an infinite loop


ID: T12.G5.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use breakpoint blocks and Debug Mode to pause and inspect
Description: Students use CreatiCode's Debug Mode: (1) Insert `breakpoint` block at strategic location, (2) Click blue arrow (Debug Mode) instead of green flag, (3) When execution pauses, examine variable monitors and sprite state, (4) Move breakpoint to different locations to isolate bug. Useful for timing bugs and state inspection. _Assessment: Use breakpoints to debug a timing/state bug; document what breakpoint revealed._

Dependencies:
* T12.G5.03: Combine multiple tracing methods to isolate a bug
* T12.G5.09: Interpret error indicators to form debugging hypotheses


ID: T12.G5.11
Topic: T12 – Testing, Debugging & Error Handling
Skill: Read and interpret console output and error messages
Description: Students interpret CreatiCode console messages: (1) **Debug output**: Print statements showing execution flow, (2) **Error messages**: "list index out of range", "undefined variable", (3) **Warnings**: Potential issues. They connect console messages to specific blocks, using `get console log` reporter to capture all output. _Assessment: Given console output, identify which block caused each message; fix 2+ errors based on console info._

Dependencies:
* T12.G4.10: Add print blocks to trace which code is running
* T12.G5.09: Interpret error indicators to form debugging hypotheses


ID: T12.G5.12
Topic: T12 – Testing, Debugging & Error Handling
Skill: Explain bug causation using cause-effect chains
Description: Students practice **causal reasoning** for bugs by constructing cause-effect chains. Given a symptom (e.g., "sprite disappears off screen"), they trace backward: (1) **Immediate cause**: sprite x > 240, (2) **Prior cause**: move block adds 100 each time, (3) **Root cause**: no boundary check before moving. Write chains like: "The sprite disappears [EFFECT] because x exceeds 240 [CAUSE] because move runs without check [ROOT CAUSE]." _Assessment: Write cause-effect chains for 3 bugs; chains must have 2+ levels._

Dependencies:
* T12.G5.03: Combine multiple tracing methods to isolate a bug
* T12.G4.08: Document what went wrong and how you fixed it
* T12.G3.08: Point to the bug and explain why it causes the problem


ID: T12.G5.13
Topic: T12 – Testing, Debugging & Error Handling
Skill: Describe bugs using symptom-cause-fix vocabulary
Description: Students practice clear bug communication: (1) **Symptom**: "The sprite appears at (100,50) instead of (0,0)" (specific, observable), (2) **Cause**: "The `go to x:0 y:0` block is missing" (specific block), (3) **Fix**: "Add `go to x:0 y:0` at script start" (actionable change). Avoid vague descriptions like "it doesn't work." This vocabulary helps when asking for help. _Assessment: Rewrite 3 vague bug descriptions using precise symptom-cause-fix format._

Dependencies:
* T12.G5.12: Explain bug causation using cause-effect chains
* T12.G4.08: Document what went wrong and how you fixed it


ID: T12.G5.14
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug asynchronous wait conditions
Description: Students debug programs where operations must wait for previous operations to complete. Common issues: (1) Using AI result before response received, (2) Checking sensor data before initialized, (3) Accessing loaded resource before loading completes. Students use `wait until` blocks or callback patterns to ensure proper sequencing. _Assessment: Debug 2+ async timing bugs; implement proper wait conditions._

Dependencies:
* T07.G4.01: Use repeat-until to create a conditional loop
* T12.G5.09: Interpret error indicators to form debugging hypotheses


## Grade 6 (14 skills) - Systematic Testing and Collaborative Debugging

ID: T12.G6.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Trace code with 4+ variables using a tracking table
Description: Students trace programs with 4+ variables by creating a **variable tracking table**: columns for each variable, rows for each step. Example: After `repeat 5`, fill in 5 rows showing how x, y, score, lives change. They predict final state before running, then verify. _Assessment: Create tracking table for 4+ variables over 5+ steps; prediction accuracy graded._

Dependencies:
* T12.G5.08: Debug two-level nested structures
* T12.G5.03: Combine multiple tracing methods to isolate a bug
* T09.G4.02: Use variables to track game state (score, lives, level)


ID: T12.G6.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply hypothesis-driven debugging
Description: Students apply the scientific debugging method: (1) **Observe**: Describe symptom precisely ("sprite stops at x=50 instead of x=100"), (2) **Hypothesize**: Form specific hypothesis ("move steps value is wrong"), (3) **Test**: Add say block or change value to test hypothesis, (4) **Verify**: Run all test cases after fix. Document 3 bugs using this method. _Assessment: Bug reports showing 4-step process; hypothesis must be specific and testable._

Dependencies:
* T12.G5.03: Combine multiple tracing methods to isolate a bug
* T12.G5.10: Use breakpoint blocks and Debug Mode to pause and inspect
* T12.G4.08: Document what went wrong and how you fixed it


ID: T12.G6.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Write expected outcomes BEFORE writing code (test-driven approach)
Description: Students practice **test-driven debugging** - defining expected outcomes BEFORE implementing or fixing code. Process: (1) Write "When I input X, I expect output Y" for 5 cases, (2) THEN write/fix the code, (3) Run tests to verify. This prevents "it works for one case" bugs. Key insight: If you can't describe the expected behavior, you can't test it. _Assessment: Write 5 expected outcomes first, then implement; compare predictions to results._

Dependencies:
* T12.G5.05: Create a test plan covering normal, boundary, and invalid cases
* T12.G6.02: Apply hypothesis-driven debugging


ID: T12.G6.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Design equivalence partitions to reduce test cases
Description: Students learn **equivalence partitioning** - grouping inputs that should behave the same way. Given a grade calculator (0-59=F, 60-69=D, 70-79=C, 80-89=B, 90-100=A), instead of testing every number, they: (1) Identify partitions: F-range, D-range, C-range, B-range, A-range, invalid-below-0, invalid-above-100, (2) Select ONE representative from each (50, 65, 75, 85, 95, -5, 105), (3) Test only 7 values instead of 107. _Assessment: Identify 5+ partitions; select representatives; explain equivalence._

Dependencies:
* T12.G6.03: Write expected outcomes BEFORE writing code (test-driven approach)
* T12.G5.05: Create a test plan covering normal, boundary, and invalid cases


ID: T12.G6.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Construct decision tables for complex conditional logic
Description: Students create **decision tables** to test programs with multiple conditions. Given rules: (1) If has key AND touching door → open, (2) If has key AND NOT touching door → nothing, (3) If no key AND touching door → "Need key!", (4) If no key AND NOT touching door → nothing. Students build table with all condition combinations (4 rows for 2 conditions) and test each. _Assessment: Build decision table for 2-3 conditions; test all combinations; document results._

Dependencies:
* T12.G6.04: Design equivalence partitions to reduce test cases
* T12.G6.02: Apply hypothesis-driven debugging


ID: T12.G6.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug a peer's program using guiding questions
Description: Students debug a classmate's program using collaborative approach: (1) Run and observe symptoms, (2) Add tracing to investigate, (3) Form hypothesis, (4) **Don't reveal fix directly** - ask guiding questions ("What do you expect this variable to be?"), (5) Help peer discover fix themselves. Document the debugging conversation. _Assessment: Debugging log showing questions asked + peer's discovery process._

Dependencies:
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G6.01: Trace code with 4+ variables using a tracking table


ID: T12.G6.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug timing-dependent bugs
Description: Students debug bugs that only appear under certain timing conditions: (1) **Race conditions**: Two scripts updating same variable, (2) **Animation timing**: Sprite not in position when collision checked, (3) **Message timing**: Broadcast received before listener ready. They add wait blocks or restructure to fix timing issues. _Assessment: Debug 2+ timing bugs; explain why timing caused the issue._

Dependencies:
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G5.10: Use breakpoint blocks and Debug Mode to pause and inspect


ID: T12.G6.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug UI widget display issues
Description: Students debug CreatiCode's UI widgets (buttons, sliders, text inputs, labels). Common issues: (1) **Widget not visible**: Wrong position, hidden behind other elements, wrong layer, (2) **Widget not responding**: Event handler not connected, wrong event type, (3) **Display glitches**: Wrong size, text overflow, positioning on different screen sizes. Students use systematic checking of widget properties. _Assessment: Debug 3+ UI widget issues; document which property was wrong._

Dependencies:
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G5.09: Interpret error indicators to form debugging hypotheses


ID: T12.G6.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply systematic elimination debugging
Description: Students use **systematic elimination** to find bugs in complex programs: (1) List all possible causes (5+), (2) Design a test that rules out each cause, (3) Systematically eliminate causes until one remains. Example: "Sprite not moving" - test: Is script running? Is move value 0? Is sprite off-screen? Is direction wrong? Document eliminated causes with evidence. _Assessment: Debug using elimination; show 4+ causes tested and eliminated._

Dependencies:
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G5.12: Explain bug causation using cause-effect chains


ID: T12.G6.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply rubber duck debugging
Description: Students practice **rubber duck debugging** - explaining code line-by-line to an inanimate object (or peer who just listens). Process: (1) Describe what each block SHOULD do, (2) Say what variables contain at each step, (3) State expected vs actual output. The act of verbalizing often reveals the bug. Students record themselves explaining, then identify the "aha moment." _Assessment: Transcript of debugging explanation; identify moment where bug became clear._

Dependencies:
* T12.G5.12: Explain bug causation using cause-effect chains
* T12.G6.01: Trace code with 4+ variables using a tracking table


ID: T12.G6.11
Topic: T12 – Testing, Debugging & Error Handling
Skill: Select debugging strategy based on bug symptoms
Description: Students develop **metacognitive debugging awareness** by matching symptoms to strategies. Given a bug, they: (1) Identify symptom category (wrong output, crash, hang, intermittent), (2) Select strategy: **Wrong output** → trace variables, **Crash** → check error messages, **Hang** → look for infinite loops, **Intermittent** → check timing. Document: "Bug symptom is [X], so I'll try [strategy] because [reason]." _Assessment: Given 4 bugs, select appropriate strategy for each; justify choices._

Dependencies:
* T12.G6.10: Apply rubber duck debugging
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G5.09: Interpret error indicators to form debugging hypotheses


ID: T12.G6.12
Topic: T12 – Testing, Debugging & Error Handling
Skill: Create minimal reproducible examples for bug reports
Description: Students learn to **isolate bugs** by creating **minimal reproducible examples** (MREs). Given a large program with a bug, they: (1) Identify which sprites/scripts are needed to reproduce, (2) Remove everything unrelated, (3) Simplify to minimum needed, (4) Verify bug still occurs. An MRE should be <10 blocks if possible. Key insight: If you can't reproduce it simply, you don't understand it yet. _Assessment: Given buggy program, create MRE with ≤50% of original code._

Dependencies:
* T12.G6.02: Apply hypothesis-driven debugging
* T12.G5.12: Explain bug causation using cause-effect chains


ID: T12.G6.13
Topic: T12 – Testing, Debugging & Error Handling
Skill: Write reproducible bug reports with exact steps
Description: Students write **professional bug reports**. Format: (1) **Summary**: One sentence ("Score doesn't increase when collecting coins"), (2) **Steps to Reproduce**: Exact numbered steps, (3) **Expected Result**: What should happen, (4) **Actual Result**: What actually happens, (5) **Additional Info**: Screenshots, console output. Key insight: If someone can't reproduce it, they can't fix it. _Assessment: Write bug report that another person can reproduce from._

Dependencies:
* T12.G6.12: Create minimal reproducible examples for bug reports
* T12.G5.13: Describe bugs using symptom-cause-fix vocabulary


ID: T12.G6.14
Topic: T12 – Testing, Debugging & Error Handling
Skill: Create self-testing scripts that verify behavior
Description: Students create automated test scripts: (1) **Setup**: Set known starting state, (2) **Action**: Run the code being tested, (3) **Verify**: Check if result matches expected (`if score = 10 then print "PASS" else print "FAIL"`), (4) **Report**: Summarize results. Self-testing scripts can run with green flag to verify code still works after changes. _Assessment: Create self-testing script with 5+ test cases; all must have clear PASS/FAIL output._

Dependencies:
* T12.G6.05: Construct decision tables for complex conditional logic
* T12.G5.11: Read and interpret console output and error messages


## Grade 7 (13 skills) - Advanced Debugging and Testing Automation

ID: T12.G7.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Write 15-case test suite covering all categories
Description: Students test an algorithm with comprehensive 15-case suite: (1) **Normal** (5 cases): typical inputs, (2) **Edge** (4 cases): empty list, single item, all equal, duplicates, (3) **Boundary** (3 cases): min/max values, (4) **Invalid** (3 cases): wrong types, out of range. Calculate pass rate and identify weakest category. _Assessment: 15-case test suite with coverage analysis._

Dependencies:
* T12.G6.03: Write expected outcomes BEFORE writing code (test-driven approach)
* T12.G6.04: Design equivalence partitions to reduce test cases
* T10.G5.01: Use lists to store collections of data


ID: T12.G7.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug subtle logic errors (off-by-one, wrong operator)
Description: Students debug logic errors that produce wrong results without crashing: (1) **Off-by-one**: Loop runs 9 times instead of 10, (2) **Wrong operator**: Uses < instead of <=, (3) **Wrong assignment**: Sets variable instead of changing it, (4) **Wrong variable**: Uses x instead of y. These require careful tracing because code "runs" but gives wrong answer. _Assessment: Debug 3+ logic errors; explain the subtle mistake in each._

Dependencies:
* T12.G6.01: Trace code with 4+ variables using a tracking table
* T12.G6.02: Apply hypothesis-driven debugging


ID: T12.G7.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Refactor code to improve debuggability
Description: Students refactor code to make it easier to test/debug: (1) **Extract custom block**: Break 20+ block script into named procedures, (2) **Replace duplication**: Use loop or custom block, (3) **Rename variables**: "s" → "playerScore", (4) **Add isolation**: Separate concerns into different scripts. Verify refactored code produces identical output. _Assessment: Refactor a complex program; show before/after + test verification._

Dependencies:
* T12.G6.14: Create self-testing scripts that verify behavior
* T12.G7.01: Write 15-case test suite covering all categories
* T11.G5.01: Create custom blocks to organize repeated code


ID: T12.G7.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Anticipate 5 runtime error types and add defenses
Description: Students proactively identify and defend against 5 runtime error categories: (1) **Division by zero**, (2) **List index out of bounds**, (3) **Invalid user input**, (4) **Position outside stage**, (5) **Resource not ready**. For each, add defensive check BEFORE the risky operation, with fallback and user message. _Assessment: Add defenses for 5 error types; demonstrate each defense working._

Dependencies:
* T12.G5.06: Add defensive checks before risky operations
* T12.G6.03: Write expected outcomes BEFORE writing code (test-driven approach)
* T10.G5.01: Use lists to store collections of data


ID: T12.G7.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Test in multiple contexts and identify context-dependent bugs
Description: Students test same program under different conditions: (1) Different starting positions, (2) Different screen sizes, (3) Different initial variable values, (4) Different timing. They identify bugs that only appear in specific contexts (e.g., "works at x=0 but fails at x=-100"). _Assessment: Test in 4+ contexts; identify 2+ context-dependent bugs._

Dependencies:
* T12.G6.07: Debug timing-dependent bugs
* T12.G7.01: Write 15-case test suite covering all categories


ID: T12.G7.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug multiplayer synchronization issues
Description: Students debug CreatiCode's multiplayer features. Common issues: (1) **Variable desync**: Players see different values, (2) **Message ordering**: Messages arrive in different order than sent, (3) **Join/leave timing**: Player joins mid-game with stale state, (4) **Connection failures**: Game continues without disconnected player. Students add sync checks and recovery logic. _Assessment: Debug 2+ multiplayer bugs; implement synchronization fixes._

Dependencies:
* T12.G6.07: Debug timing-dependent bugs
* T12.G7.01: Write 15-case test suite covering all categories


ID: T12.G7.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug 3D scene and camera issues
Description: Students debug 3D programs in CreatiCode. Common issues: (1) **Object not visible**: Behind camera, wrong scale, or inside another object, (2) **Camera problems**: Wrong direction, wrong field of view, (3) **Lighting issues**: Too dark or washed out, (4) **Z-fighting**: Overlapping surfaces flicker. Students use camera inspection and object bounds to diagnose. _Assessment: Debug 3+ 3D rendering bugs; explain spatial relationships._

Dependencies:
* T12.G6.09: Apply systematic elimination debugging
* T12.G7.02: Debug subtle logic errors (off-by-one, wrong operator)


ID: T12.G7.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Use show inspector to debug 3D hierarchies
Description: Students use CreatiCode's `show inspector [Yes v]` block to open Babylon.js inspector for debugging 3D scenes. Inspector shows: (1) **Scene tree**: All 3D objects, (2) **Object properties**: Position, rotation, scale, (3) **Live editing**: Modify properties in real-time, (4) **Performance stats**: Frame rate, draw calls. Students use inspector to diagnose without modifying code. _Assessment: Use inspector to debug 3+ 3D issues; document findings._

Dependencies:
* T12.G7.07: Debug 3D scene and camera issues
* T12.G6.01: Trace code with 4+ variables using a tracking table


ID: T12.G7.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply binary search debugging to large scripts
Description: Students use **binary search debugging** to find bugs in long scripts (30+ blocks). Process: (1) Add print at middle, (2) Run and check: correct at midpoint?, (3) If yes, bug is in second half; if no, in first half, (4) Repeat. This reduces O(n) to O(log n) checks. _Assessment: Debug 30+ block script in ≤5 iterations; document binary search process._

Dependencies:
* T12.G6.12: Create minimal reproducible examples for bug reports
* T12.G7.02: Debug subtle logic errors (off-by-one, wrong operator)


ID: T12.G7.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug AI prompt engineering issues
Description: Students debug programs where **AI output doesn't match intent** due to prompt issues. Common problems: (1) **Vague prompt**: Unpredictable output, (2) **Missing constraints**: Wrong format returned, (3) **Ambiguous context**: AI misinterprets without examples, (4) **Prompt injection**: User input corrupts prompt. Students iterate: Original → Problem → Improved prompt → Test. _Assessment: Debug 2 prompt engineering bugs; document before/after prompts._

Dependencies:
* T12.G6.09: Apply systematic elimination debugging
* T12.G6.12: Create minimal reproducible examples for bug reports


ID: T12.G7.11
Topic: T12 – Testing, Debugging & Error Handling
Skill: Apply prompt refinement cycle for AI outputs
Description: Students practice systematic prompt debugging: (1) **Initial prompt**: Send first version, (2) **Analyze failure**: What was wrong?, (3) **Hypothesize improvement**: "Adding length limit might help", (4) **Refine prompt**: Add specific constraint, (5) **Test again**, (6) **Repeat**. Example: "Write a story" → "Write 3-paragraph story about robot for 3rd graders with happy ending". _Assessment: Show 3+ iterations of prompt refinement; document changes._

Dependencies:
* T12.G7.10: Debug AI prompt engineering issues
* T12.G6.02: Apply hypothesis-driven debugging


ID: T12.G7.12
Topic: T12 – Testing, Debugging & Error Handling
Skill: Design regression test suites for ongoing verification
Description: Students create **regression test suites** - tests that run after every change. Process: (1) **Identify critical behaviors**: List features that must work, (2) **Create test for each**: Using self-testing scripts, (3) **Run after changes**, (4) **Track results over time**, (5) **Investigate failures**: New failure = recent change broke something. _Assessment: Create 10+ test suite; run after 3 changes; identify regressions._

Dependencies:
* T12.G6.14: Create self-testing scripts that verify behavior
* T12.G7.01: Write 15-case test suite covering all categories


ID: T12.G7.13
Topic: T12 – Testing, Debugging & Error Handling
Skill: Document defensive code improvements
Description: Students document defensive improvements using template: (1) **Risk**: What could go wrong?, (2) **Defense added**: What check was added?, (3) **Test case**: What now passes? Document 5+ defensive improvements with specific examples. _Assessment: Documentation for 5+ improvements with before/after examples._

Dependencies:
* T12.G5.06: Add defensive checks before risky operations
* T12.G5.07: Clamp values to stay within valid boundaries
* T12.G4.08: Document what went wrong and how you fixed it


## Grade 8 (14 skills) - Expert Debugging, AI Collaboration, and Prevention

ID: T12.G8.01
Topic: T12 – Testing, Debugging & Error Handling
Skill: Design test suite with code path coverage tracking
Description: Students design test suites that explicitly track coverage: (1) List all code paths (branches), (2) Create test case for each path, (3) Mark which paths each test covers, (4) Calculate coverage percentage. Document: "Tests cover 5/6 paths (83%); path X untested." _Assessment: Test suite with coverage matrix; identify untested paths._

Dependencies:
* T12.G7.01: Write 15-case test suite covering all categories
* T12.G7.03: Refactor code to improve debuggability


ID: T12.G8.02
Topic: T12 – Testing, Debugging & Error Handling
Skill: Verify implementation against specifications
Description: Given a specification document describing expected behavior, students: (1) Read specification completely, (2) Create test cases from spec, (3) Run tests, (4) Document discrepancies between spec and implementation, (5) Fix bugs until all requirements pass. _Assessment: Specification compliance report showing requirements tested + pass/fail._

Dependencies:
* T12.G7.01: Write 15-case test suite covering all categories
* T12.G7.02: Debug subtle logic errors (off-by-one, wrong operator)
* T12.G8.01: Design test suite with code path coverage tracking


ID: T12.G8.03
Topic: T12 – Testing, Debugging & Error Handling
Skill: Implement comprehensive error handling with graceful degradation
Description: Students implement full error-handling strategy: (1) **Check before risky operations**, (2) **Provide fallback values**, (3) **Display user-friendly messages**, (4) **Log errors to console**, (5) **Continue execution when possible**. Program should never crash unexpectedly. _Assessment: Implement error handling for 5+ failure points; demonstrate graceful degradation._

Dependencies:
* T12.G7.04: Anticipate 5 runtime error types and add defenses
* T12.G7.13: Document defensive code improvements


ID: T12.G8.04
Topic: T12 – Testing, Debugging & Error Handling
Skill: Review code using 4-question robustness framework
Description: Students review code with framework: (1) **Correctness**: Does it solve problem for normal inputs?, (2) **Edge cases**: What inputs aren't handled?, (3) **Assumptions**: What must be true?, (4) **Failure modes**: Where could it crash? Write review document with examples for each question, then propose 3 improvements. _Assessment: Code review document answering all 4 questions + improvements._

Dependencies:
* T12.G7.02: Debug subtle logic errors (off-by-one, wrong operator)
* T12.G7.13: Document defensive code improvements
* T12.G8.01: Design test suite with code path coverage tracking


ID: T12.G8.05
Topic: T12 – Testing, Debugging & Error Handling
Skill: Trace error propagation through nested custom blocks
Description: Students debug programs where bug is in deeply nested custom block: Main → Block A → Block B → Bug. They trace the **call chain** to identify which custom block contains the error and explain how error propagates. Use print blocks in each custom block to trace call order. _Assessment: Debug nested custom block bug; document call chain + identify which block has error._

Dependencies:
* T11.G6.01: Design custom blocks with clear, predictable interfaces
* T12.G7.02: Debug subtle logic errors (off-by-one, wrong operator)
* T12.G6.01: Trace code with 4+ variables using a tracking table


ID: T12.G8.06
Topic: T12 – Testing, Debugging & Error Handling
Skill: Review and verify AI-generated code for correctness
Description: Students critically evaluate code generated by AI assistants (like XO). Process: (1) **Read line-by-line**: Understand what each block does, (2) **Question assumptions**: Does solution match requirements?, (3) **Test edge cases**: AI often misses boundaries, (4) **Verify logic**: Check conditions, operators, variables, (5) **Add defensive code**: AI may skip error handling. Never blindly accept AI code. _Assessment: Review AI-generated solution; identify 3+ issues; fix and document._

Dependencies:
* T12.G8.04: Review code using 4-question robustness framework
* T12.G8.02: Verify implementation against specifications


ID: T12.G8.07
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug AI-generated code by checking edge cases
Description: Students systematically test AI-generated code for edge case handling - a common AI weakness. Process: (1) List 5+ edge cases for the task, (2) Run AI code with each, (3) Document failures ("AI code crashes when list is empty"), (4) Add defensive code. Key insight: AI generates code that works for typical cases; unusual cases often fail. _Assessment: Test AI code with 5+ edge cases; document 2+ failures; implement fixes._

Dependencies:
* T12.G8.06: Review and verify AI-generated code for correctness
* T12.G7.04: Anticipate 5 runtime error types and add defenses


ID: T12.G8.08
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug large-scale projects with multiple sprites
Description: Students debug complex projects with 5+ sprites, multiple scripts per sprite, and shared variables. Strategies: (1) **Isolate by sprite**: Test each alone, (2) **Trace message flow**: Document broadcast/receive chains, (3) **Variable ownership**: Track which scripts modify shared variables, (4) **Systematic disable**: Comment out scripts to isolate problem. _Assessment: Debug multi-sprite project; create debugging documentation showing strategy._

Dependencies:
* T12.G8.05: Trace error propagation through nested custom blocks
* T12.G7.06: Debug multiplayer synchronization issues


ID: T12.G8.09
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug distributed state in multiplayer games
Description: Students debug complex multiplayer state synchronization: (1) **State divergence**: Local state differs from server state, (2) **Conflict resolution**: Multiple players update same value simultaneously, (3) **Reconnection recovery**: Player rejoins with outdated state, (4) **Authoritative server**: Which client's version is "correct"? Students implement state validation and sync recovery. _Assessment: Debug distributed state bug; implement synchronization fix._

Dependencies:
* T12.G7.06: Debug multiplayer synchronization issues
* T12.G8.08: Debug large-scale projects with multiple sprites


ID: T12.G8.10
Topic: T12 – Testing, Debugging & Error Handling
Skill: Profile and debug performance issues
Description: Students identify and fix performance problems: (1) **Identify symptoms**: Lag, slow response, dropped frames, (2) **Isolate cause**: Too many clones, heavy loops, frequent costume changes, large images, (3) **Measure**: Use timer blocks for execution time, (4) **Optimize**: Reduce clone count, simplify graphics, add wait blocks. _Assessment: Profile laggy project; identify 2+ issues; implement fixes with measurable improvement._

Dependencies:
* T12.G7.03: Refactor code to improve debuggability
* T12.G8.08: Debug large-scale projects with multiple sprites


ID: T12.G8.11
Topic: T12 – Testing, Debugging & Error Handling
Skill: Evaluate AI assistant suggestions using evidence
Description: Students develop systematic framework for evaluating AI suggestions: (1) **Evidence check**: Does AI explain WHY?, (2) **Logic verification**: Does suggested cause lead to observed symptom?, (3) **Scope assessment**: Could fix break other parts?, (4) **Alternative consideration**: Other possible causes?, (5) **Test prediction**: What would verify hypothesis? _Assessment: Evaluate 5 AI suggestions using checklist; identify 2+ incorrect; explain rejection._

Dependencies:
* T12.G8.06: Review and verify AI-generated code for correctness
* T12.G8.04: Review code using 4-question robustness framework


ID: T12.G8.12
Topic: T12 – Testing, Debugging & Error Handling
Skill: Debug emergent behavior in multi-agent systems
Description: Students debug **emergent behaviors** - unexpected patterns from multiple sprites interacting. Examples: (1) **Oscillation**: Sprites create infinite loop, (2) **Deadlock**: Sprites waiting for each other, (3) **Cascading failures**: One error triggers chain reaction, (4) **Unexpected clustering**. Students identify interaction rules creating emergence, then modify to fix. Key insight: Bug may not be in any single sprite but in their interaction. _Assessment: Debug 2 emergent behavior bugs; explain interaction patterns._

Dependencies:
* T12.G8.08: Debug large-scale projects with multiple sprites
* T12.G7.06: Debug multiplayer synchronization issues


ID: T12.G8.13
Topic: T12 – Testing, Debugging & Error Handling
Skill: Write code that is easy to debug
Description: Students apply **prevention principles** - writing code that's inherently easier to debug. Principles: (1) **Small functions**: Custom blocks do one thing, (2) **Meaningful names**: Variables describe purpose, (3) **Avoid magic numbers**: Use named constants, (4) **Fail fast**: Check inputs immediately, (5) **Leave breadcrumbs**: Strategic print statements, (6) **Consistent patterns**: Same structure for similar tasks. _Assessment: Review own code against 6 principles; refactor to improve; demonstrate debugging improvement._

Dependencies:
* T12.G7.03: Refactor code to improve debuggability
* T12.G7.13: Document defensive code improvements
* T11.G6.01: Design custom blocks with clear, predictable interfaces


ID: T12.G8.14
Topic: T12 – Testing, Debugging & Error Handling
Skill: Track debugging metrics to improve your process
Description: Students track and analyze debugging performance to identify improvement opportunities. Metrics: (1) **Time to first hypothesis**: How long to form testable guess?, (2) **Hypotheses tested**: How many before finding bug?, (3) **Tools used**: Which methods most helpful?, (4) **Bug type frequency**: What bugs do you make most?, (5) **Prevention opportunities**: Could bug have been prevented? After 5+ sessions, analyze patterns and identify one process improvement. _Assessment: Track 5 sessions with metrics; analyze patterns; apply improvement; demonstrate results._

Dependencies:
* T12.G8.04: Review code using 4-question robustness framework
* T12.G7.12: Design regression test suites for ongoing verification
# T13 – 2D Games (Optimized - Phase 10 November 2025)
# Phase 10 Major Comprehensive Optimizations:
# MAJOR CHANGES FROM PHASE 9:
# 1. Added COMPUTATIONAL THINKING micro-skills throughout (G3-G8):
#    - T13.G3.13: Trace player actions through complete game cycle
#    - T13.G4.13.01: Predict game behavior from code reading
#    - T13.G6.18.01: Analyze game code for algorithmic efficiency
#    - T13.G7.16.01: Compare algorithmic approaches for game AI
#    - T13.G8.16.01: Evaluate time/space complexity of game algorithms (Big-O)
# 2. Added GAME DESIGN PATTERNS skills:
#    - T13.G5.17.01: Apply factory pattern for clone spawning
# 3. Fixed duplicate skill issue (T13.G6.22/G6.23) - updated dependencies
# 4. Improved verb usage: "Build" → "Integrate", "Design" → "Refactor" where appropriate
# 5. Corrected skill count headers to match actual counts
# 6. Enhanced dependency chain for computational thinking progression
# PRESERVED FROM PHASE 9:
# - Hand tracking game skills (G6-G7)
# - Body pose tracking for fitness games (G7-G8)
# - Speech recognition for voice-controlled games (G6-G7)
# - AI image generation for dynamic assets (G7-G8)
# - Advanced physics skills (G5-G6)
# - Game analytics & metrics (G7-G8)
# - Mobile game design patterns (G5)
# - Multiplayer debugging skills (G8)
# - Enhanced K-2 skills with concrete game design thinking
# - All dependencies verified for X-2 rule compliance
# - Cross-topic dependencies preserved unchanged
# Total: 187 skills across K-8 (expanded from 165 with computational thinking and design pattern skills)

## Kindergarten (8 skills)

ID: T13.GK.01
Topic: T13 – 2D Games
Skill: Match arrow keys to character movements
Description: **Student task:** Drag arrow key picture cards onto matching character movement pictures. **Visual scenario:** Four large colorful arrow key cards (↑, ↓, ←, →) and four character movement pictures: (A) character jumping upward with arms raised, (B) character sliding/falling downward, (C) character walking left facing left, (D) character walking right facing right. **Correct matches:** Up arrow → A (jumping up), Down arrow → B (going down), Left arrow → C (walking left), Right arrow → D (walking right). _Implementation note: Drag-drop matching with visual arrow keys and animated character poses. Audio reads "up arrow" / "moves up" on hover. Auto-graded. CSTA: 1A-AP-11._

Dependencies:
* T06.GK.02: Match "first," "next," and "last" labels to pictures in a 3-step sequence


ID: T13.GK.02
Topic: T13 – 2D Games
Skill: Recognize when a score changes in a simple game
Description: **Student task:** Look at before/after picture pairs showing game moments. Tap the pair where the score changed. **Visual scenario:** Two picture pairs showing game moments: Pair A shows BEFORE (character near star, score displays "3") and AFTER (character touched star, score displays "4"). Pair B shows BEFORE (character walking, score displays "2") and AFTER (character still walking, score still displays "2"). **Correct answer:** Pair A (score changed from 3 to 4 when star was collected). _Implementation note: Click-to-select from 2-3 picture pairs; score counter visually highlighted with color border. Audio support available. CSTA: 1A-AP-09._

Dependencies:
* T09.GK.01: Recognize that labels can show different numbers


ID: T13.GK.03
Topic: T13 – 2D Games
Skill: Sort picture cards into Start, Playing, and End game phases
Description: **Student task:** Drag picture cards showing different game moments into three labeled boxes representing game phases. **Visual scenario:** Six picture cards: (A) "Press Start" title screen with big button, (B) character collecting a gold coin mid-jump, (C) character jumping over a spike obstacle, (D) "Game Over" screen with sad face, (E) character standing at starting position with flag, (F) trophy with "You Win!" celebration sparkles. Three sorting boxes labeled: START (green), PLAYING (blue), END (red). **Correct sorting:** START box → A and E, PLAYING box → B and C, END box → D and F. _Implementation note: Drag-and-drop sorting into 3 color-coded boxes. Auto-graded by final placement. CSTA: 1A-AP-08._

Dependencies:
* T01.GK.03: Tap the first and last picture cards in a sequence


ID: T13.GK.04
Topic: T13 – 2D Games
Skill: Match game goals to celebration pictures
Description: Match goal picture cards to celebration picture cards using line-matching or drag-drop. Goal cards show: (A) character touching flag, (B) character collecting all stars, (C) character opening treasure chest. Celebration cards show: (1) "Level Complete!" banner, (2) "All Stars Collected!" with sparkles, (3) "Treasure Found!" with coins. Correct matches: A→1, B→2, C→3. _Implementation note: Line-matching or drag-drop pairing with 3 goal-celebration pairs. Audio support reads card content. Auto-graded. CSTA: 1A-AP-11._

Dependencies:
* T13.GK.02: Recognize when a score changes in a simple game
* T13.GK.03: Sort picture cards into Start, Playing, and End


ID: T13.GK.05
Topic: T13 – 2D Games
Skill: Identify what caused a score to increase
Description: Look at 3 picture cards showing game actions. Tap the card that shows WHY the score went up. Cards show: (A) character collecting a coin, (B) character standing still, (C) character touching a wall. Question: "The score went from 5 to 6. What made it go up?" Correct answer: (A) collecting a coin. _Implementation note: MCQ with 3 picture options; introduces cause-and-effect thinking. Audio support available. Auto-graded. CSTA: 1A-AP-09._

Dependencies:
* T13.GK.02: Recognize when a score changes in a simple game


ID: T13.GK.06
Topic: T13 – 2D Games
Skill: Identify the player character in game pictures
Description: Look at a game scene picture with multiple objects. Tap the character that the player controls. Picture shows a simple game level with: character with arrow pointing down (labeled "YOU"), clouds, coins, a flag, and enemies with X marks. Question: "Which one do you control?" Correct answer: Character with "YOU" label. _Implementation note: Click-to-select hot spot activity with 3-4 game scenes. Visual cues help (arrows, "YOU" labels). Auto-graded. CSTA: 1A-AP-08._

Dependencies:
* T01.GK.04: Select the picture sequence that makes sense


ID: T13.GK.07
Topic: T13 – 2D Games
Skill: Identify the three parts of a game: rules, goals, and challenge
Description: **Student task:** Look at 3 picture cards showing different game elements. Match each card to the correct label: RULE, GOAL, or CHALLENGE. **Visual scenario:** Card A shows a sign saying "Collect coins to score points" (RULE). Card B shows a trophy at the finish line (GOAL). Card C shows spikes and enemies blocking the path (CHALLENGE). Students drag labels to match each card. _Implementation note: This foundational skill introduces the core components that make something a "game" vs. just an animation or toy. Builds vocabulary for discussing game design. Audio support. Auto-graded. CSTA: 1A-AP-08._

Dependencies:
* T13.GK.03: Sort picture cards into Start, Playing, and End game phases
* T13.GK.05: Identify what caused a score to increase


ID: T13.GK.08
Topic: T13 – 2D Games
Skill: Match feedback type to game event pictures
Description: **Student task:** Match game event pictures to the feedback that should happen. **Visual scenario:** Event cards: (A) character collects coin, (B) character hits enemy, (C) character reaches goal. Feedback cards: (1) happy sound + score +1, (2) sad sound + lose heart, (3) celebration music + "You Win!". Correct matches: A→1 (positive feedback for good action), B→2 (negative feedback for bad outcome), C→3 (victory feedback for completing goal). _Implementation note: Introduces the concept of immediate feedback in games - players need to know right away if they did something good or bad. Foundation for designing clear game feedback. CSTA: 1A-AP-09._

Dependencies:
* T13.GK.05: Identify what caused a score to increase
* T13.GK.04: Match game goals to celebration pictures


## Grade 1 (8 skills)

ID: T13.G1.01
Topic: T13 – 2D Games
Skill: Identify the player, goal, and obstacles using labeled picture cards
Description: Look at a labeled game level picture. Drag three labels (PLAYER, GOAL, OBSTACLE) onto the correct parts of the picture. Picture shows a simple maze with: controllable character with green border, a gold star at the end, spikes on the floor, and walls. Students drag labels to match: PLAYER → character, GOAL → star, OBSTACLE → spikes. _Implementation note: Drag-drop label placement on hotspots within game scene. Audio reads labels on hover. Auto-graded. CSTA: 1B-AP-11._

Dependencies:
* T13.GK.06: Identify the player character in game pictures
* T13.GK.03: Sort picture cards into Start, Playing, and End


ID: T13.G1.02
Topic: T13 – 2D Games
Skill: Apply a simple game rule to picture sequences
Description: Read or listen to a simple rule (e.g., "Collect 3 coins to open the door"). Look at 3-4 picture card sequences. Select the sequence where the player followed the rule correctly. Rule: "Collect 3 coins to open door." Sequence A: collect coin → collect coin → open door (WRONG - only 2 coins). Sequence B: collect coin → collect coin → collect coin → open door (CORRECT - 3 coins). Correct answer: Sequence B. _Implementation note: MCQ comparing 2 sequences; rule displayed at top with icon. Auto-graded. CSTA: 1B-AP-08._

Dependencies:
* T13.G1.01: Identify the player, goal, and obstacles using labeled picture cards
* T13.GK.04: Match game goals to celebration pictures


ID: T13.G1.03
Topic: T13 – 2D Games
Skill: Compare game difficulty using side-by-side picture cards
Description: Look at two versions of the same game level shown side by side. Click on the picture that shows the HARDER level. Both pictures show a platform jumping level. Picture A has 3 platforms with small gaps. Picture B has 3 platforms with LARGE gaps and added spike pits. Question: "Which level is harder?" Correct answer: Picture B (larger gaps + spikes). _Implementation note: Click-to-select from 2 side-by-side pictures with subtle/obvious differences. Auto-graded. CSTA: 1B-AP-10._

Dependencies:
* T01.GK.04: Select the picture sequence that makes sense


ID: T13.G1.04
Topic: T13 – 2D Games
Skill: Select the best next move using control picture cards
Description: Look at a game situation picture showing the player and nearby obstacles/goals. Select which control card (up arrow, down arrow, left arrow, right arrow, jump button) is the best next move. Picture shows character on platform, spikes below, safe platform to the right, coin above. Question: "Which move keeps you safe AND moves you forward?" Correct answer: Right arrow (moves toward goal, avoids spikes). _Implementation note: MCQ with 3-4 control card options. Audio reads question. Auto-graded. CSTA: 1B-AP-12._

Dependencies:
* T13.G1.01: Identify the player, goal, and obstacles using labeled picture cards
* T13.GK.01: Match arrow keys to character movements


ID: T13.G1.05
Topic: T13 – 2D Games
Skill: Sort game items into "helps you" and "hurts you" categories
Description: Drag 6-8 game item picture cards into two labeled boxes: HELPS YOU (green box with smile) and HURTS YOU (red box with X). Item cards show: heart, star, coin, speed shoe, spike, slime, fire, shield. Correct sorting: HELPS box gets heart, star, coin, speed shoe, shield. HURTS box gets spike, slime, fire. _Implementation note: Drag-and-drop sorting into 2 boxes; color-coded borders help visual learners. Auto-graded by final placement. CSTA: 1B-AP-09._

Dependencies:
* T13.GK.05: Identify what caused a score to increase
* T13.GK.04: Match game goals to celebration pictures


ID: T13.G1.06
Topic: T13 – 2D Games
Skill: Predict what happens when touching different game items
Description: Look at picture cards showing "IF character touches [item], THEN [result]" pairs. Match the item to its result. Item cards: heart, spike, coin. Result cards: health increases (+1 heart), game over screen, score increases (+1 point). Students match using line-drawing or drag-drop: heart → health increases, spike → game over, coin → score increases. _Implementation note: Line-matching or drag-drop with 3-4 item-result pairs. Audio support available. Auto-graded. CSTA: 1B-AP-12._

Dependencies:
* T13.G1.05: Sort game items into "helps you" and "hurts you" categories
* T01.G1.10: Match situation pictures to if/then rules


ID: T13.G1.07
Topic: T13 – 2D Games
Skill: Identify fair vs. unfair game rules using picture comparisons
Description: **Student task:** Look at two versions of the same game with different rules. Decide which version is FAIR and which is UNFAIR. **Visual scenario:** Game A: Both players start at the same line, race to finish. Game B: Player 1 starts halfway to the finish, Player 2 starts at the beginning. Question: "Which game is fair?" Correct answer: Game A (both players have equal opportunity). _Implementation note: Introduces fairness and balance in game design - a key principle. Use clear visual comparisons showing equal vs. unequal starting conditions. CSTA: 1B-AP-15._

Dependencies:
* T13.G1.03: Compare game difficulty using side-by-side picture cards
* T13.GK.07: Identify the three parts of a game: rules, goals, and challenge


ID: T13.G1.08
Topic: T13 – 2D Games
Skill: Sequence a simple game loop using picture cards
Description: **Student task:** Arrange 4 picture cards to show the repeating cycle of a simple game. **Visual scenario:** Cards show: (A) Player makes a move, (B) Game checks if move is valid, (C) Game updates score/position, (D) Player sees what happened. Correct order: A → B → C → D → (repeats). _Implementation note: Introduces the concept of the game loop - the heartbeat of every game. This cycle repeats constantly during gameplay. Understanding this pattern is essential for programming games. CSTA: 1B-AP-11._

Dependencies:
* T13.G1.02: Apply a simple game rule to picture sequences
* T13.GK.08: Match feedback type to game event pictures


## Grade 2 (8 skills)

ID: T13.G2.01
Topic: T13 – 2D Games
Skill: Identify whose turn it is in a turn-based game picture
Description: Look at picture cards showing turn-based game states with turn indicators (colored borders, arrows, highlighted player names). Click or drag cards to show whose turn it is now and whose turn comes next. Picture shows two-player board game with Player 1 (blue) and Player 2 (red). Blue border glows around Player 1's name. Question: "Whose turn is it?" then "Whose turn is next?" Correct answers: Player 1 now, Player 2 next. _Implementation note: Two-step click task or sequence ordering. Visual cues like colored borders/arrows. Auto-graded. CSTA: 1B-AP-11._

Dependencies:
* T01.G1.01: Sequence four picture cards for planting a seed
* T13.G1.02: Apply a simple game rule to picture sequences


ID: T13.G2.02
Topic: T13 – 2D Games
Skill: Track lives through a picture sequence and predict Game Over
Description: Look at 4-5 picture cards showing a game story in order. Each card shows the life counter. Identify which cards show losing a life, then tap the card that shows "Game Over" (lives reach zero). Cards show: (1) 3 hearts, character safe, (2) 2 hearts, character touched spike, (3) 1 heart, character touched enemy, (4) 0 hearts with "Game Over" text. Question: "Which card shows Game Over?" Correct answer: Card 4. _Implementation note: Sequenced picture cards with life counter visible; click-to-select final answer. Auto-graded. CSTA: 1B-AP-12._

Dependencies:
* T01.G1.04: Predict the next panel in a story sequence
* T13.G1.05: Sort game items into "helps you" and "hurts you" categories


ID: T13.G2.03
Topic: T13 – 2D Games
Skill: Identify how to advance to the next level using picture pairs
Description: Match "before level ends" pictures to "condition met" pictures using line-matching. Before cards: (A) character near flag, (B) character with 2 of 3 coins collected, (C) character near locked door with key in hand. Condition cards: (1) "Touch goal," (2) "Collect all items," (3) "Use key on door." Correct matches: A→1, B→2, C→3. _Implementation note: Line-matching or drag-drop pairs showing level completion conditions. Audio support. Auto-graded. CSTA: 1B-AP-10._

Dependencies:
* T01.G1.01: Sequence four picture cards for planting a seed
* T13.G1.01: Identify the player, goal, and obstacles using labeled picture cards


ID: T13.G2.04
Topic: T13 – 2D Games
Skill: Sequence picture cards showing a safe path through a level
Description: Drag 4 picture cards into the correct order to show a safe route avoiding hazards. Cards show: (A) jump over spikes, (B) collect key, (C) avoid moving enemy, (D) unlock door. Correct order: C → A → B → D (avoid enemy first, jump spikes, get key, unlock door). _Implementation note: Drag-drop sequencing requiring strategic planning. Visual cues show hazards in red. Auto-graded by final arrangement. CSTA: 1B-AP-11._

Dependencies:
* T01.G1.04: Predict the next panel in a story sequence
* T13.G1.04: Select the best next move using control picture cards


ID: T13.G2.05
Topic: T13 – 2D Games
Skill: Select the picture that makes a game easier for new players
Description: Read or listen to a goal (e.g., "Make it easier for new players"). Look at 3 picture cards showing different game changes. Click the picture that best matches the goal. Goal: "Make it easier." Picture A: add another heart (health). Picture B: add more spikes (obstacles). Picture C: reduce time limit. Correct answer: Picture A (more health = easier). _Implementation note: MCQ with 3 picture options showing game modifications. Rule/goal displayed at top. Audio support. Auto-graded. CSTA: 1B-AP-15._

Dependencies:
* T13.G1.03: Compare game difficulty using side-by-side picture cards
* T13.G1.06: Predict what happens when touching different game items


ID: T13.G2.06
Topic: T13 – 2D Games
Skill: Choose the better strategy using picture sequences
Description: Compare two picture sequences showing different ways to play the same level. Select which strategy is better and safer. Rule: "Get to the flag safely." Strategy A sequence: run straight, touch 2 spikes, lose lives, barely reach flag. Strategy B sequence: jump over spikes, collect heart, reach flag with full health. Question: "Which is the better strategy?" Correct answer: Strategy B (safer, keeps health). _Implementation note: Side-by-side sequence comparison; 2-3 cards per strategy. Click-to-select better approach. Auto-graded. CSTA: 1B-AP-11._

Dependencies:
* T13.G2.04: Sequence picture cards showing a safe path through a level
* T13.G2.02: Track lives through a picture sequence and predict Game Over


ID: T13.G2.07
Topic: T13 – 2D Games
Skill: Design a simple game level by placing elements on a grid
Description: **Student task:** Given a grid and a set of game element stickers (player start, goal, 3 obstacles, 2 coins), place them to create a playable level. **Visual scenario:** 5x5 grid with drag-drop elements. **Constraints:** Player must be able to reach the goal (no blocking walls), obstacles should make it challenging but not impossible. **Evaluation:** Level is checked for: (1) player and goal are placed, (2) path exists from player to goal, (3) obstacles create some challenge. _Implementation note: This is the first "game design" skill where students CREATE rather than analyze. Develops spatial reasoning and design thinking. Auto-graded by pathfinding check. CSTA: 1B-AP-15._

Dependencies:
* T13.G2.04: Sequence picture cards showing a safe path through a level
* T13.G1.07: Identify fair vs. unfair game rules using picture comparisons


ID: T13.G2.08
Topic: T13 – 2D Games
Skill: Predict game state changes from a sequence of player actions
Description: **Student task:** Given a starting game state and a sequence of 3 player actions, predict the final game state. **Visual scenario:** Starting state: Score=0, Lives=3, Position=Start. Action sequence shown as cards: (1) Collect coin, (2) Hit spike, (3) Reach checkpoint. Question: "What is the final state?" Answer options show different score/lives/position combinations. Correct answer: Score=1, Lives=2, Position=Checkpoint. _Implementation note: Practices mental simulation of game state - a key debugging skill. Students trace through actions and track multiple variables changing. CSTA: 1B-AP-12._

Dependencies:
* T13.G1.06: Predict what happens when touching different game items
* T13.G1.08: Sequence a simple game loop using picture cards


## Grade 3 (17 skills)

ID: T13.G3.01.01
Topic: T13 – 2D Games
Skill: Program horizontal movement with arrow keys
Description: Build sprite movement using `when [left arrow] key pressed` with `change x by (-10)` for left, and `when [right arrow] key pressed` with `change x by (10)` for right. **How it works:** Each key press triggers the change-by block once, moving sprite 10 pixels. Holding the key triggers repeated events (automatic repeat). **Test your code:** Verify sprite moves equal distances left and right, responds immediately to key presses. **Debug tips:** If sprite only moves once per key press, ensure you're holding the key. If sprite moves wrong direction, check positive/negative values (negative x = left, positive x = right). _CSTA: 2-AP-10._

Dependencies:
* T13.G2.04: Sequence picture cards showing a safe path through a level
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence


ID: T13.G3.01.02
Topic: T13 – 2D Games
Skill: Program 4-directional movement with arrow keys
Description: Extend horizontal movement by adding vertical controls: `when [up arrow] key pressed` with `change y by (10)` and `when [down arrow] key pressed` with `change y by (-10)`. **Coordinate system:** Positive y = up (toward top of screen), negative y = down (toward bottom). **Test your code:** Press each arrow key to verify all four directions work correctly. Test diagonal movement by pressing two keys simultaneously (up + right should move diagonally). **Total setup:** 4 separate `when key pressed` scripts, one for each arrow key. This 4-directional control is standard for top-down games like maze or exploration games. _CSTA: 2-AP-10._

Dependencies:
* T13.G3.01.01: Program horizontal movement with arrow keys
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence


ID: T13.G3.01.03
Topic: T13 – 2D Games
Skill: Debug and tune movement speed
Description: Test different step values in `change x by` and `change y by` blocks to find the right movement speed for your game. **Experiment:** Try values 5, 10, 15, 20 and observe the difference. **Game type guidelines:** Maze games → slower (5-8 steps) for precise navigation; Action games → faster (10-15 steps) for responsive feel; Racing games → very fast (15-25 steps). **Debug scenario:** Movement feels sluggish → increase step value; Player overshoots targets → decrease step value. **Testing process:** Change value, play test, observe, adjust, repeat until movement feels right. This iterative tuning is essential game design skill. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys


ID: T13.G3.02
Topic: T13 – 2D Games
Skill: Constrain sprite within screen boundaries
Description: Add boundary checking to prevent sprite from leaving the visible stage area. **Stage boundaries:** x ranges from -240 (left edge) to 240 (right edge), y ranges from -180 (bottom) to 180 (top). **Implementation:** Inside a `forever` loop, add 4 if-statements: `if <(x position) < (-240)> then [set x to (-240)]`, `if <(x position) > (240)> then [set x to (240)]`, same pattern for y with -180/180. **Why forever loop:** Boundary checks must run continuously, not just during movement, to catch any position changes. **Test your code:** Move sprite to each edge and verify it stops exactly at boundary without going off-screen. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T08.G3.04: Use a simple if in a script


ID: T13.G3.03.01
Topic: T13 – 2D Games
Skill: Detect collision with goal sprite
Description: Use `if <touching [Goal]?> then` block inside a `forever` loop to continuously check if player reaches the goal. **How collision detection works:** The `touching?` block returns true when any part of player sprite's visible pixels overlap with any part of Goal sprite's visible pixels. **Implementation:** `forever { if <touching [Goal]?> then { say [You Win!] for (2) seconds } }`. **Test your code:** Move player to touch goal from different directions (left, right, above, below) to verify detection works from all angles. **Common issue:** If goal has transparent pixels in costume, collision only triggers on visible parts. _CSTA: 2-AP-13._

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G2.03: Identify how to advance to the next level using picture pairs


ID: T13.G3.03.02
Topic: T13 – 2D Games
Skill: Detect touching a goal color
Description: Use `if <touching color [green]?> then` block to detect when player reaches a colored goal area on the backdrop. This allows backdrop-based level design without sprite goals. Test with different goal colors and verify color picker selects exact color. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.03.01: Detect collision with goal sprite


ID: T13.G3.04.01
Topic: T13 – 2D Games
Skill: Detect touching a hazard using sprite collision
Description: Use `if <touching [Hazard]?> then` inside a forever loop to detect collision with hazard sprites (enemies, spikes, pits). When touched, provide feedback with `say [Ouch!]` and prepare for game over logic. Test collision detection from all sides of hazard. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.03.01: Detect collision with goal sprite
* T07.G3.03: Build a forever loop for simple animation


ID: T13.G3.04.02
Topic: T13 – 2D Games
Skill: Detect touching a hazard using color collision
Description: Use `if <touching color [red]?> then` to detect hazardous colored areas (lava, pits) painted on backdrops. This enables complex level layouts without creating many sprite-based hazards. Test with multiple hazard colors (red for lava, black for pits). _CSTA: 2-AP-13._

Dependencies:
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T08.G3.02: Decide when a single if is enough


ID: T13.G3.05
Topic: T13 – 2D Games
Skill: Create a start screen with button
Description: Design a "Start" button sprite that uses `when this sprite clicked` to broadcast `Start Game` message, then hides itself with `hide` block. All game sprites should be hidden initially until they receive the broadcast. Test that clicking the button triggers game start. _CSTA: 2-AP-16._

Dependencies:
* T09.G3.02: Use a variable in a conditional (if block)
* T06.G3.06: Trace a project with a single event and predict output


ID: T13.G3.06
Topic: T13 – 2D Games
Skill: Program sprites to respond to game start
Description: Add `when I receive [Start Game]` hat blocks to all game sprites to show them with `show` block and begin their movement or animation scripts. This separates setup phase from play phase. Test that sprites only become active after start button is clicked. _CSTA: 2-AP-16._

Dependencies:
* T13.G3.05: Create a start screen with button
* T10.G3.01: Loop through and process each item in a list


ID: T13.G3.07
Topic: T13 – 2D Games
Skill: Trigger Game Over with broadcast
Description: When a losing condition occurs (touching hazard, lives zero), broadcast `Game Over` message. Program all sprites to stop scripts with `stop [other scripts in sprite]` and display a "Game Over" text sprite when receiving this broadcast. Test that all game activity stops. _CSTA: 2-AP-16._

Dependencies:
* T13.G3.06: Program sprites to respond to game start
* T08.G3.03: Pick the right conditional block for a scenario


ID: T13.G3.08
Topic: T13 – 2D Games
Skill: Add sound effects to player actions
Description: Insert `start sound [sound]` blocks immediately after movement or collision events to provide audio feedback. Match sounds to actions (jump sound after y change, collect sound when touching item). Test that sounds play without cutting off. Use sound_play blocks. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T07.G3.04: Use repeat-until to reach a simple goal


ID: T13.G3.09
Topic: T13 – 2D Games
Skill: Create visual feedback with graphic effects
Description: Use `set [color] effect to (25)` when player takes damage or collects items, wait briefly with `wait (0.3) seconds`, then `clear graphic effects`. Test different effects (color, brightness, ghost) to see which provides clearest feedback. Uses looks_seteffectto blocks. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T08.G3.10: Trace code with a single if/else


ID: T13.G3.10
Topic: T13 – 2D Games
Skill: Create collectible items with clones
Description: Use `create clone of [myself]` block to spawn multiple collectibles (coins, gems) at different positions. In the clone's `when I start as a clone` script, use `if <touching [Player]?> then [delete this clone]` to make items disappear when collected. Test that each clone deletes independently. Uses control_create_clone_with_id. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.03.01: Detect collision with goal sprite
* T07.G3.03: Build a forever loop for simple animation
* T08.G3.04: Use a simple if in a script


ID: T13.G3.11
Topic: T13 – 2D Games
Skill: Trace game state through a simple play session
Description: Given a game with Score variable starting at 0 and Lives starting at 3, trace through this sequence: (1) Player touches coin → Score becomes 1, (2) Player touches spike → Lives becomes 2, (3) Player touches coin → Score becomes 2, (4) Player touches goal → Game shows "You Win!". **Practice task:** Given code showing collision handlers and a sequence of events, predict the final values of Score and Lives. **Debug scenario:** If Score shows 0 after collecting coins, trace to find where `change [Score] by (1)` should run. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.03.01: Detect collision with goal sprite
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T13.G2.08: Predict game state changes from a sequence of player actions


ID: T13.G3.12
Topic: T13 – 2D Games
Skill: Integrate 3 core mechanics into a complete mini-game
Description: Combine learned skills to create a complete mini-game with: (1) Player movement using arrow keys, (2) Goal collision that triggers win, (3) At least one hazard/obstacle. **Minimum requirements:** Player can move in at least 2 directions, touching goal shows "You Win!", touching hazard shows "Ouch!" or similar feedback. **Test checklist:** Can player reach goal? Does hazard give feedback? Can game be restarted? This integrates all Grade 3 game skills into a cohesive project. _CSTA: 2-AP-16._

Dependencies:
* T13.G3.03.01: Detect collision with goal sprite
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T13.G3.01.02: Program 4-directional movement with arrow keys


ID: T13.G3.13
Topic: T13 – 2D Games
Skill: Trace player actions through a complete game cycle
Description: **Computational thinking practice:** Given a game with movement, collision detection, and scoring, mentally trace through a specific player action sequence. **Example task:** Start state: x=0, y=0, Score=0. Actions: (1) Press right 5 times → x=50, (2) Touch coin → Score=1, coin deletes, (3) Press up 3 times → y=30, (4) Touch goal → "You Win!" shows. **Practice activity:** Students receive game code and action list, must predict final state values. **Debug application:** Use tracing to find where actual behavior differs from expected behavior. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.11: Trace game state through a simple play session
* T13.G3.12: Integrate 3 core mechanics into a complete mini-game


## Grade 4 (26 skills)

ID: T13.G4.01
Topic: T13 – 2D Games
Skill: Spawn projectile clones from player position
Description: Create shooting mechanic using clones. **Setup:** Create a Bullet sprite and hide it at game start. **Spawning:** In Player sprite, use `when [space] key pressed` with `create clone of [Bullet]`. **Clone initialization:** In Bullet sprite, use `when I start as a clone` with `go to [Player]` to spawn at player position, then `point in direction (90)` to aim right (or use player's direction). **Trace:** Press space → clone created → clone teleports to player → clone ready to move. **Debug:** If bullets spawn at wrong location, ensure `go to [Player]` runs before movement code. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T06.G3.02: Build a key-press script that controls a sprite
* T08.G3.04: Use a simple if in a script


ID: T13.G4.02
Topic: T13 – 2D Games
Skill: Program projectile movement and hit detection
Description: Make projectiles move and detect hits. **Movement:** In `when I start as a clone`, after positioning, add `forever { move (10) steps }` to travel continuously in the projectile's direction. **Hit detection:** Inside the forever loop, add `if <touching [Enemy]?> then { delete this clone }` to remove projectile when it hits enemy. **Complete clone script:** `when I start as a clone { go to [Player], point in direction (90), forever { move (10) steps, if <touching [Enemy]?> then { delete this clone } } }`. **Test:** Fire projectile, verify it moves straight, hits enemy and disappears. _CSTA: 2-AP-14._

Dependencies:
* T13.G4.01: Spawn projectile clones from player position
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T08.G3.04: Use a simple if in a script


ID: T13.G4.03
Topic: T13 – 2D Games
Skill: Clean up projectiles at screen edge
Description: Add `if <touching edge?> then [delete this clone]` inside the projectile's movement loop to prevent lag from offscreen projectiles. Test by firing projectiles in all directions and verifying they disappear at edges. This prevents performance issues. _CSTA: 2-AP-14._

Dependencies:
* T13.G4.02: Program projectile movement and hit detection
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T08.G3.04: Use a simple if in a script


ID: T13.G4.04.01
Topic: T13 – 2D Games
Skill: Create horizontal patrol movement
Description: Program enemy with `forever` loop containing `move (3) steps`, `if <touching edge?> then [turn 180 degrees]` to patrol back and forth. Adjust speed by changing step size. Test that enemy reverses smoothly at boundaries. Uses motion_movesteps and motion_turnright. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.02: Constrain sprite within screen boundaries
* T07.G3.03: Build a forever loop for simple animation
* T08.G3.04: Use a simple if in a script


ID: T13.G4.04.02
Topic: T13 – 2D Games
Skill: Create glide patrol between points
Description: Use `forever` loop with `glide (2) secs to x: (100) y: (0)` then `glide (2) secs to x: (-100) y: (0)` to create smooth patrol between two positions. This creates predictable, timed movement patterns suitable for platformers. Test timing and positions. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.04.01: Create horizontal patrol movement
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T07.G3.01: Use a counted repeat loop


ID: T13.G4.05.01
Topic: T13 – 2D Games
Skill: Point sprite toward player
Description: Use `point towards [Player]` block to make an enemy sprite rotate to face the player sprite. Place inside a forever loop to continuously track player position. Test by moving player around and observing enemy rotation. Uses motion_pointtowards. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T07.G3.03: Build a forever loop for simple animation


ID: T13.G4.05.02
Topic: T13 – 2D Games
Skill: Create chasing enemy behavior
Description: Combine `point towards [Player]` with `move (2) steps` inside a forever loop to create an enemy that continuously chases the player. Adjust movement speed to balance difficulty. Test chase behavior and collision with player. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.05.01: Point sprite toward player
* T07.G3.03: Build a forever loop for simple animation
* T08.G3.04: Use a simple if in a script


ID: T13.G4.06
Topic: T13 – 2D Games
Skill: Create and manage a Score variable
Description: Create a global `Score` variable, use `set [Score] to (0)` when game starts, and `change [Score] by (1)` when collecting items. Show the variable monitor on stage to display score. Test that score increases correctly and resets on game restart. _CSTA: 2-AP-11._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T09.G3.01.04: Display variable value on stage using the variable monitor


ID: T13.G4.06.01
Topic: T13 – 2D Games
Skill: Display score using widget label
Description: Create a custom score display using `widget_addlabel` block to show score in a styled label widget. **Setup:** Use `widget_addlabel` with text set to `join [Score: ] (Score)` variable, position at top-right of stage, and style with large font and bright color. **Update:** Inside a forever loop, use `widget_settext` to continuously update the label with current score value. **Advantages over variable monitor:** Custom positioning, styling, and integration with game UI theme. **Test:** Collect items and verify label updates in real-time. Uses widget_addlabel and widget_settext blocks. _CSTA: 2-AP-17._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T09.G3.01.04: Display variable value on stage using the variable monitor


ID: T13.G4.07
Topic: T13 – 2D Games
Skill: Create and manage a Lives variable
Description: Create a `Lives` variable, initialize to 3 at game start with `set [Lives] to (3)`, decrease with `change [Lives] by (-1)` when taking damage, and check `if <(Lives) = (0)> then [broadcast Game Over]`. Display lives monitor. Test damage and game over trigger. _CSTA: 2-AP-11._

Dependencies:
* T13.G3.07: Trigger Game Over with broadcast
* T13.G3.04.01: Detect touching a hazard using sprite collision


ID: T13.G4.08
Topic: T13 – 2D Games
Skill: Implement temporary invincibility after damage
Description: After taking damage, set an `Invincible` variable to 1, wait 2 seconds, then set back to 0. Modify damage detection to check `if <(Invincible) = (0)> and <touching [Enemy]?>`. Add visual feedback with ghost effect during invincibility. Test that player can't take damage twice rapidly. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.07: Create and manage a Lives variable
* T09.G3.02: Use a variable in a conditional (if block)


ID: T13.G4.09
Topic: T13 – 2D Games
Skill: Build a timer system
Description: Create a `Timer` variable, set to 60 at game start, use `forever { wait (1) second, change [Timer] by (-1), if <(Timer) = (0)> then [broadcast Time Up] }` to count down. Show timer monitor. Test countdown and time-up trigger. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T09.G3.02: Use a variable in a conditional (if block)


ID: T13.G4.10
Topic: T13 – 2D Games
Skill: Implement win condition based on score
Description: Add `if <(Score) > (10)> then [broadcast You Win]` inside the forever loop that updates score. Create a win screen sprite that appears when receiving the broadcast. Test that reaching the target score triggers victory. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T13.G3.07: Trigger Game Over with broadcast


ID: T13.G4.11
Topic: T13 – 2D Games
Skill: Create multi-level progression
Description: Create a `Level` variable starting at 1. When win condition is met, use `change [Level] by (1)` and `broadcast [Next Level]`. Each level sprite should respond by switching backdrop and resetting positions. Test progression through 2-3 levels. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.10: Implement win condition based on score
* T09.G3.02: Use a variable in a conditional (if block)


ID: T13.G4.12
Topic: T13 – 2D Games
Skill: Add power-up collectibles with temporary effects
Description: Create power-up sprite clones that set a `PowerUp` variable to 1 when collected, apply effect (e.g., double speed: `move (20) steps` instead of 10), wait 5 seconds, then reset. Test power-up timing and effect. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T09.G3.02: Use a variable in a conditional (if block)


ID: T13.G4.13
Topic: T13 – 2D Games
Skill: Debug score not updating correctly
Description: Trace score changes by adding `say [Score changed!]` blocks after each `change [Score]` command. Verify collision detection runs before score changes. Check that score resets properly at game start. Test edge cases like collecting multiple items rapidly. _CSTA: 2-AP-17._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T08.G3.10: Trace code with a single if/else


ID: T13.G4.13.01
Topic: T13 – 2D Games
Skill: Predict game behavior from code reading
Description: **Computational thinking practice:** Given game code showing: (1) when green flag → set Score to 0, set Lives to 3, (2) when touching Coin → change Score by 1, delete clone, (3) when touching Enemy → change Lives by -1, if Lives=0 then broadcast GameOver. **Task:** Predict what happens when: Player touches 2 coins then 1 enemy → Score=2, Lives=2. Player touches 3 enemies → Lives=0, GameOver broadcasts. **Skills practiced:** Reading code to predict behavior, understanding event sequencing, identifying cause-effect relationships. _CSTA: 2-AP-17._

Dependencies:
* T13.G4.13: Debug score not updating correctly
* T13.G3.13: Trace player actions through a complete game cycle


ID: T13.G4.14
Topic: T13 – 2D Games
Skill: Balance game difficulty through testing
Description: Play-test your game multiple times adjusting: enemy speed, player lives, timer duration, and score goals. Document what feels too easy vs. too hard. Aim for 70% success rate for target skill level. This teaches design iteration. _CSTA: 2-AP-17._

Dependencies:
* T13.G4.07: Create and manage a Lives variable
* T13.G4.09: Build a timer system


ID: T13.G4.15
Topic: T13 – 2D Games
Skill: Trace game state transitions
Description: Map out game flow: Start → Playing → Win/Lose → Restart. Trace which broadcasts trigger which state changes. Add debug messages at each state transition. Verify all paths work correctly (can you restart after winning? after losing?). _CSTA: 2-AP-17._

Dependencies:
* T13.G3.07: Trigger Game Over with broadcast
* T13.G4.10: Implement win condition based on score


ID: T13.G4.16
Topic: T13 – 2D Games
Skill: Implement parallax scrolling background
Description: Create multiple backdrop layers (clouds, mountains, ground) as sprites. Move them at different speeds in a forever loop (clouds slowest, ground fastest) to create depth illusion. Test smooth scrolling without gaps. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.01.01: Program horizontal movement with arrow keys
* T07.G3.03: Build a forever loop for simple animation


ID: T13.G4.17
Topic: T13 – 2D Games
Skill: Create settings menu with widget slider
Description: Build a settings menu using widget blocks. **Setup:** Create a Settings sprite with `when this sprite clicked` event. **Slider creation:** Use `widget_addslider` block to create a volume slider with range 0-100, positioned at center of stage. **Apply settings:** Use `widget_getvalue` to read slider value and store in a `Volume` variable, then use `set volume to (Volume)%` to apply the setting. **Test:** Click settings, adjust slider, verify volume changes. This introduces game UI design using widget_addslider and widget_getvalue blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G3.05: Create a start screen with button
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G4.18
Topic: T13 – 2D Games
Skill: Design complete game loop with restart
Description: Integrate start screen, gameplay, win/loss conditions, and restart button. Ensure all variables reset properly, sprites return to starting positions, and game can be replayed infinitely without refresh. Test complete loop 3+ times. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.15: Trace game state transitions
* T13.G4.11: Create multi-level progression


ID: T13.G4.19
Topic: T13 – 2D Games
Skill: Initialize 2D physics world with gravity
Description: Use the `initialize 2D physics world with gravity x [0] y [-10]` block to enable the built-in physics engine. **Gravity values:** y=-10 creates normal downward gravity (like Earth), y=0 creates zero gravity (space), y=10 creates upward gravity (reverse). x values create sideways pull. **Important:** This block must run once at project start before any physics bodies are created. Place in `when green flag clicked` script. **Test:** After initialization, sprites with physics bodies should fall downward. Uses physics2d_initworld block. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.12: Design a complete mini-game with 3 core mechanics
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G4.20
Topic: T13 – 2D Games
Skill: Add physics body to sprite
Description: Use `create a 2D physics body for this sprite` block to make a sprite interact with the physics engine. The sprite becomes affected by gravity and can collide with other physics bodies. **Body types:** Dynamic bodies move and respond to forces (player, ball), static bodies don't move (ground, walls). **After adding body:** Sprite will fall due to gravity and bounce off other physics bodies. **Test:** Create two sprites with physics bodies, run project, verify they fall and collide realistically. Uses physics2d_createbody block. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.19: Initialize 2D physics world with gravity


ID: T13.G4.21
Topic: T13 – 2D Games
Skill: Set physics body properties (density, friction, bounciness)
Description: Use `update 2D physics properties density [1] friction [0.5] restitution [0.3]` to customize how objects behave. **Density** affects mass (higher = heavier, harder to push). **Friction** affects sliding (0 = ice/slippery, 1 = sticky/rough). **Restitution** affects bounciness (0 = no bounce, 1 = super bouncy). **Game examples:** Ball with high restitution (0.8) for bouncy ball game, player with medium friction (0.5) for normal movement, ice platforms with low friction (0.1). **Test:** Drop a ball onto a platform and adjust restitution to change bounce height. Uses physics2d_updateproperties block. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.20: Add physics body to sprite


ID: T13.G4.22
Topic: T13 – 2D Games
Skill: Create static physics objects for platforms and walls
Description: Create ground and wall sprites, add physics bodies, then use `lock movement` block to make them static (immovable). Static bodies don't fall or move when hit, but dynamic bodies collide with them normally. **Setup:** Create floor sprite, add physics body, lock movement. **Result:** Floor stays in place while player falls and lands on it. **Common pattern:** All level geometry (platforms, walls, obstacles) should be static. Uses physics2d_lockmovement block. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.20: Add physics body to sprite
* T13.G3.02: Constrain sprite within screen boundaries


## Grade 5 (31 skills)

ID: T13.G5.01
Topic: T13 – 2D Games
Skill: Implement physics-based jumping
Description: Create realistic jump using gravity simulation. **Setup:** Create `YVelocity` variable. **Jump start:** When space pressed and on ground, `set [YVelocity] to (15)`. **Gravity loop:** In forever loop, use `change y by (YVelocity)` then `change [YVelocity] by (-1)` to simulate gravity pulling down. **Ground collision:** Add `if <(y position) < (-140)> then [set y to (-140), set [YVelocity] to (0)]` to stop at ground. **Test:** Verify smooth parabolic arc, can't double-jump, lands correctly. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.02
Topic: T13 – 2D Games
Skill: Detect platform collision and landing
Description: Create platform sprites with specific colors. Use `if <touching color [platform brown]?> and <(YVelocity) < (0)>> then [set y to top of platform, set [YVelocity] to (0)]` to land on platforms. Test jumping between multiple platforms at different heights. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.01: Implement physics-based jumping
* T13.G3.04.02: Detect touching a hazard using color collision


ID: T13.G5.02.01
Topic: T13 – 2D Games
Skill: Debug falling through platforms
Description: If player falls through platforms, check: (1) Is YVelocity negative check present? (2) Is y-position set correctly to platform top? (3) Does platform color match exactly? Add debug `say` blocks to show YVelocity value during collision. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.02: Detect platform collision and landing


ID: T13.G5.03
Topic: T13 – 2D Games
Skill: Create moving platform
Description: Create platform sprite with `forever { glide (3) secs to x:(200) y:(0), glide (3) secs to x:(-200) y:(0) }`. When player lands on it, add `change x by (platform's x velocity)` to move player with platform. Test that player stays on moving platform. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.02: Detect platform collision and landing
* T13.G4.04.02: Create glide patrol between points


ID: T13.G5.04
Topic: T13 – 2D Games
Skill: Implement wall jumping
Description: When touching wall color and space pressed, set YVelocity to 12 and change x by 20 (away from wall) to create wall jump. Add `if <touching color [wall]?> then [allow wall jump]` condition. Test jumping between parallel walls. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.01: Implement physics-based jumping
* T13.G3.04.02: Detect touching a hazard using color collision


ID: T13.G5.05
Topic: T13 – 2D Games
Skill: Program enemy patrol with direction tracking
Description: Create `EnemyDirection` variable. Use `forever { if <(EnemyDirection) = (1)> then [move (3) steps] else [move (-3) steps], if <touching edge?> or <touching color [wall]?> then [set [EnemyDirection] to (0 - EnemyDirection)] }` to patrol and reverse. Test patrol between walls. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.04.01: Create horizontal patrol movement
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.05.01
Topic: T13 – 2D Games
Skill: Add animation to enemy patrol
Description: Extend patrol code to switch costumes based on direction: `if <(EnemyDirection) = (1)> then [switch costume to [right]] else [switch costume to [left]]` inside patrol loop. Test that enemy faces movement direction. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.05: Program enemy patrol with direction tracking


ID: T13.G5.06
Topic: T13 – 2D Games
Skill: Create enemy that shoots projectiles
Description: In enemy sprite, add `forever { wait (2) seconds, create clone of [Enemy Bullet] }` to shoot periodically. In Enemy Bullet clone script, use `go to [Enemy]`, `point towards [Player]`, then move continuously. Test enemy shooting at player. _CSTA: 2-AP-14._

Dependencies:
* T13.G4.01: Spawn projectile clones from player position
* T13.G4.05.01: Point sprite toward player


ID: T13.G5.06.01
Topic: T13 – 2D Games
Skill: Vary enemy shot timing with randomization
Description: Change enemy shooting to `wait (pick random (1) to (4)) seconds` to make shooting unpredictable. Test that shots occur at irregular intervals, increasing difficulty. _CSTA: 2-AP-14._

Dependencies:
* T13.G5.06: Create enemy that shoots projectiles


ID: T13.G5.06.02
Topic: T13 – 2D Games
Skill: Debug projectile direction errors
Description: If projectiles move in wrong direction, add `say [direction]` after `point towards` to verify angle. Check that `go to` runs before `point towards`. Verify movement uses correct direction value. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.06: Create enemy that shoots projectiles


ID: T13.G5.07
Topic: T13 – 2D Games
Skill: Implement combo score multiplier
Description: Create `Combo` variable that increases by 1 for each rapid collection (within 2 seconds). When collecting item: `change [Score] by (Combo)`, `set [Combo] to ((Combo) + (1))`. After 2 seconds of no collection, `set [Combo] to (1)`. Test combo building and timeout. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.08
Topic: T13 – 2D Games
Skill: Create checkpoint system
Description: Create `CheckpointX` and `CheckpointY` variables. When touching checkpoint sprite, save position: `set [CheckpointX] to (x position)`, `set [CheckpointY] to (y position)`. On death, respawn at checkpoint instead of start: `go to x:(CheckpointX) y:(CheckpointY)`. Test multiple checkpoints. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.07: Create and manage a Lives variable
* T13.G3.03.01: Detect collision with goal sprite


ID: T13.G5.09
Topic: T13 – 2D Games
Skill: Build boss fight with health system
Description: Create `BossHealth` variable set to 20. When boss is hit by player bullet, `change [BossHealth] by (-1)`. Use `if <(BossHealth) = (0)> then [broadcast Boss Defeated]`. Display boss health bar using variable monitor. Test boss taking damage and defeat. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.02: Program projectile movement and hit detection
* T13.G4.07: Create and manage a Lives variable


ID: T13.G5.10
Topic: T13 – 2D Games
Skill: Create boss attack patterns
Description: Design boss with multiple attack phases based on health. Use nested ifs: `if <(BossHealth) > (10)> then [attack pattern 1] else [if <(BossHealth) > (5)> then [attack pattern 2] else [attack pattern 3]]`. Test that boss changes behavior at health thresholds. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.09: Build boss fight with health system
* T08.G4.03: Use nested ifs for complex decisions


ID: T13.G5.11
Topic: T13 – 2D Games
Skill: Implement scrolling camera following player
Description: Make all non-player sprites follow player movement in reverse. When player moves right, all other sprites `change x by (-player's x change)`. Create smooth following by tracking player's last position and calculating delta. Test camera following player movement. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.12
Topic: T13 – 2D Games
Skill: Create procedural level generation
Description: Use `create clone of [Platform]` with `set x to (pick random (-200) to (200))` and `set y to (pick random (-100) to (100))` to generate random platform positions at game start. Test that levels are playable but different each time. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T10.G4.02: Use lists to organize and manage game data


ID: T13.G5.13
Topic: T13 – 2D Games
Skill: Build achievement system with list
Description: Create `Achievements` list to track accomplishments. When condition met (e.g., score > 100), check `if <[Achievements] contains [High Score]?> = false then [add [High Score] to [Achievements]]`. Display achievements on screen. Test unlocking multiple achievements. _CSTA: 2-AP-11._

Dependencies:
* T10.G4.02: Use lists to organize and manage game data
* T13.G4.10: Implement win condition based on score


ID: T13.G5.14
Topic: T13 – 2D Games
Skill: Store level data in table variable
Description: Create a table variable `LevelData` to store complex level information with columns for level number, enemy count, time limit, and required score. **Setup:** Use `table_addrow` to add rows like: `[Level: 1, Enemies: 3, Time: 60, TargetScore: 10]`, `[Level: 2, Enemies: 5, Time: 45, TargetScore: 15]`. **Loading level:** Use `table_getvalue` with row = current level and column names to retrieve data: `set [TimeLimit] to (table_getvalue [LevelData] row:(Level) column:[Time])`. **Advantages:** Centralized level configuration, easy to add new levels without changing code logic, supports complex data structures. **Test:** Progress through levels and verify each level loads correct parameters (enemy count, time, score goal) from table. Uses table_create, table_addrow, and table_getvalue blocks. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.11: Create multi-level progression
* T10.G5.01: Use table variables to organize related data


ID: T13.G5.15
Topic: T13 – 2D Games
Skill: Debug performance issues with too many clones
Description: If game lags, count active clones using a `CloneCount` variable. Add limits: `if <(CloneCount) < (20)> then [create clone]`. Delete offscreen clones immediately. Test performance with clone limits. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.16
Topic: T13 – 2D Games
Skill: Trace and fix collision detection bugs
Description: Add visual debugging to collision: use `set [ghost] effect to (50)` when collision detected, `say [touching!]` to confirm detection triggers. Check collision conditions run inside loops. Verify sprite names match exactly. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.04.01: Detect touching a hazard using sprite collision
* T08.G4.07: Trace complex conditional logic


ID: T13.G5.17
Topic: T13 – 2D Games
Skill: Optimize game with broadcast efficiency
Description: Reduce unnecessary broadcasts by combining related events. Instead of broadcasting every score change, only broadcast when reaching milestones. Use variables for frequent checks instead of broadcasts. Test that game responsiveness improves. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.07: Trigger Game Over with broadcast
* T09.G4.01: Build a program that uses variables for input and output


ID: T13.G5.17.01
Topic: T13 – 2D Games
Skill: Apply the factory pattern for clone spawning
Description: **Game design pattern:** Create a centralized spawning system using a "factory" sprite. Instead of each enemy type managing its own clones, create a Spawner sprite with custom block `SpawnEnemy [type] at x [x] y [y]`. The factory handles all clone creation logic, making it easy to add new enemy types and control spawn rates. **Implementation:** Factory sprite stores spawn settings in variables, creates appropriate clones based on type parameter, manages spawn timing and limits. **Benefits:** Centralized control, easier debugging, simpler addition of new enemy types. _CSTA: 2-AP-14._

Dependencies:
* T13.G5.15: Debug performance issues with too many clones
* T11.G5.02: Define a custom block with input parameters


ID: T13.G5.18
Topic: T13 – 2D Games
Skill: Apply forces and impulses to physics bodies
Description: Use `add force x [0] y [500]` block to apply continuous force (like a rocket engine) or `apply impulse x [0] y [10]` for instant force (like a jump). **Force vs. Impulse:** Forces accumulate over time and need to be applied continuously in a loop; impulses are one-time pushes. **Jump implementation:** When space pressed, `apply impulse x (0) y (10)` gives instant upward push. **Continuous thrust:** In forever loop, `if <key [up arrow] pressed?> then [add force x (0) y (100)]` creates jetpack effect. **Test:** Compare force-based movement (smooth acceleration) vs. impulse-based (instant velocity change). Uses physics2d_addforce and physics2d_applyimpulse blocks. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.21: Set physics body properties (density, friction, bounciness)
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G5.19
Topic: T13 – 2D Games
Skill: Use physics collision events for game logic
Description: Use `broadcast collision event message [hit] on collision [start/end] with collision group [1]` to trigger game logic when physics bodies collide. **Setup:** Assign sprites to collision groups (0-15), configure which groups trigger events. **Event handling:** Use `when I receive [hit]` to respond to collisions. **Game examples:** Bullet hits enemy → broadcast "enemy_hit", player touches goal → broadcast "level_complete". **Advantage over touching? blocks:** Works with physics movement, more precise timing. Uses physics2d_broadcastcollision block. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.20: Add physics body to sprite
* T13.G3.07: Trigger Game Over with broadcast


ID: T13.G5.20
Topic: T13 – 2D Games
Skill: Lock viewport to player sprite for camera following
Description: Use `lock viewport to this sprite with padding x [0] y [0]` block to make the camera automatically follow the player sprite. **How it works:** The stage view automatically pans to keep the sprite centered (or offset by padding values). **Advantage over manual camera:** No need to move all other sprites - the viewport handles scrolling automatically. **Padding:** x/y padding offsets the sprite from center (e.g., x=100 keeps player on left side of screen). **Test:** Move player around a large level and verify camera follows smoothly. Uses motion_lockviewport block. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.11: Implement scrolling camera following player
* T13.G3.01.02: Program 4-directional movement with arrow keys


ID: T13.G5.21
Topic: T13 – 2D Games
Skill: Create HUD elements attached to viewport
Description: Use `attach this sprite to viewport at x [position] y [position]` to fix UI elements (health bar, score display, minimap) to screen position. **How it works:** Sprites attached to viewport don't scroll with the level - they stay fixed on screen like a heads-up display. **Common HUD elements:** Score in top-right (x=200, y=160), health bar in top-left (x=-200, y=160), minimap in corner. **Test:** Move player around level and verify HUD elements stay in fixed screen positions while level scrolls behind them. Uses motion_attachtoviewport block. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.20: Lock viewport to player sprite for camera following
* T13.G4.06.01: Display score using widget label


ID: T13.G5.22
Topic: T13 – 2D Games
Skill: Create touch controls with virtual joystick widget
Description: Use `widget_addjoystick` block to create on-screen joystick for mobile/touch control. **Setup:** Add joystick widget at bottom-left of screen. **Reading input:** Use `widget_getvalue [joystick] [x]` and `widget_getvalue [joystick] [y]` to get direction values (-1 to 1). **Movement:** In forever loop, `change x by ((joystick x) * (5))` and `change y by ((joystick y) * (5))` for smooth analog movement. **Touch-friendly games:** Essential for games played on tablets/phones without keyboard. **Test:** Touch and drag joystick, verify smooth directional control. Uses widget_addjoystick and widget_getvalue blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.17: Create settings menu with widget slider
* T13.G3.01.02: Program 4-directional movement with arrow keys


ID: T13.G5.23
Topic: T13 – 2D Games
Skill: Enable continuous collision detection for fast-moving objects
Description: Use `enable collision detection as a fast object [true]` block to prevent fast-moving sprites from passing through walls or other objects. **Problem it solves:** When a bullet or fast player moves very quickly, it can "tunnel" through thin walls because the physics engine checks position at discrete intervals. CCD (Continuous Collision Detection) checks the entire path of movement. **When to use:** Enable CCD for: bullets, fast-moving balls, players at high speed, anything that moves more than half its size per frame. **Performance note:** CCD is more computationally expensive, so only enable it for sprites that truly need it. **Test:** Fire a bullet at a thin wall at maximum speed and verify it stops at the wall instead of passing through. Uses physics_setccd block. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.20: Add physics body to sprite
* T13.G4.02: Program projectile movement and hit detection


ID: T13.G5.24
Topic: T13 – 2D Games
Skill: Configure physics damping for realistic movement deceleration
Description: Use `set damping factor for movement [50]% rotation [30]%` block to control how quickly physics objects slow down on their own. **Movement damping:** 0% = no slowdown (ice/space), 50% = moderate slowdown (normal ground), 90% = heavy slowdown (mud/water). **Rotation damping:** Controls how quickly spinning objects stop spinning. **Game examples:** Car game with gradual deceleration (30% movement damping), space game with no slowdown (0%), underwater game with heavy resistance (80%). **Difference from friction:** Damping applies to all movement in empty space; friction only applies when touching surfaces. **Test:** Create a ball, apply an impulse, observe how quickly it slows down. Adjust damping and compare. Uses physics_setdampingfactor block. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.21: Set physics body properties (density, friction, bounciness)
* T13.G5.18: Apply forces and impulses to physics bodies


ID: T13.G5.25
Topic: T13 – 2D Games
Skill: Design responsive game UI for different screen sizes
Description: Create game interfaces that work well on different screen sizes (desktop, tablet, phone). **Strategy 1 - Percentage positioning:** Use stage width/height reporters to calculate positions: `set x to ((stage width) * (0.4))` places sprite at 40% from center. **Strategy 2 - Anchor points:** Place UI elements relative to edges (top-left corner = x:(-stage width/2+padding), y:(stage height/2-padding)). **Strategy 3 - Scale with viewport:** Use viewport size to scale UI sprites proportionally. **Testing:** Change stage size and verify UI elements remain properly positioned and readable. **Mobile considerations:** Make buttons large enough for touch (at least 44x44 pixels), leave space for fingers at bottom of screen. Uses looks_stage_width, looks_stage_height, and motion_vpxposition blocks. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.21: Create HUD elements attached to viewport
* T13.G5.22: Create touch controls with virtual joystick widget


ID: T13.G5.26
Topic: T13 – 2D Games
Skill: Create swipe gesture controls for mobile games
Description: Implement swipe detection for touch-based game control. **Detection logic:** Track mouse-down position, then on mouse-up calculate direction and distance: `set [SwipeX] to ((mouse x) - (StartX))`, `set [SwipeY] to ((mouse y) - (StartY))`. **Determine swipe direction:** `if <(abs of (SwipeX)) > (abs of (SwipeY))> then [horizontal swipe] else [vertical swipe]`, then check sign for left/right or up/down. **Minimum threshold:** Only count as swipe if distance > 30 pixels (avoid accidental taps). **Game applications:** Swipe up to jump, swipe left/right to move, swipe down to duck, swipe to fling objects (Angry Birds style). **Test:** Swipe in all four directions and verify correct detection. Uses event_whenleftrightmousebuttonpress, event_whenleftrightmousebuttonclick blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G5.22: Create touch controls with virtual joystick widget
* T09.G5.01: Design a complex program using multiple variables


## Grade 6 (30 skills)

ID: T13.G6.01
Topic: T13 – 2D Games
Skill: Design inventory system with list
Description: Create `Inventory` list to store collected items. When collecting power-up, `add [Shield] to [Inventory]`. Create UI sprite that displays inventory contents by iterating through list with `for each [item] in [Inventory]` showing each item. Test collecting and displaying multiple items. _CSTA: 2-AP-11._

Dependencies:
* T10.G5.02: Build a project that processes list data with iteration
* T13.G4.12: Add power-up collectibles with temporary effects


ID: T13.G6.02
Topic: T13 – 2D Games
Skill: Implement item usage from inventory
Description: When key pressed (e.g., "1"), use `item (1) of [Inventory]` to activate first item, then `delete (1) of [Inventory]` to remove it. Different items trigger different effects (shield, speed boost, extra life). Test using items and inventory updating. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.01: Design inventory system with list
* T08.G5.02: Design multi-branch logic with if/else if/else


ID: T13.G6.03
Topic: T13 – 2D Games
Skill: Create quest system with tracking
Description: Create `Quests` list containing objectives like "Collect 5 coins", "Defeat 3 enemies". Create `QuestProgress` list to track completion counts. Update progress when events occur, check completion with `if <(item (1) of [QuestProgress]) = (5)>`. Test quest completion. _CSTA: 2-AP-11._

Dependencies:
* T10.G5.02: Build a project that processes list data with iteration
* T13.G4.10: Implement win condition based on score


ID: T13.G6.04
Topic: T13 – 2D Games
Skill: Build dialogue system with NPC
Description: Create `DialogueLines` list with conversation text. Create NPC sprite that displays lines using `for each [line] in [DialogueLines] { say (line) for (3) seconds }` when clicked. Test multi-line dialogue flow. _CSTA: 2-AP-16._

Dependencies:
* T10.G5.02: Build a project that processes list data with iteration
* T13.G3.05: Create a start screen with button


ID: T13.G6.05
Topic: T13 – 2D Games
Skill: Create branching dialogue choices
Description: Extend dialogue with choices. Display question, show two option sprites (A/B). When option clicked, broadcast choice and continue with different dialogue paths. Use `if <(Choice) = (A)> then [show dialogue path A] else [show dialogue path B]`. Test both paths. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.04: Build dialogue system with NPC
* T08.G5.02: Design multi-branch logic with if/else if/else


ID: T13.G6.06
Topic: T13 – 2D Games
Skill: Implement save/load with list export
Description: Use custom blocks to save game state: create `SaveGame` block that adds all critical variables to a `SaveData` list, then export list. Create `LoadGame` block that imports list and restores variables. Test saving and loading game progress. _CSTA: 2-AP-14._

Dependencies:
* T10.G5.02: Build a project that processes list data with iteration
* T11.G5.01: Define a custom block with no parameters


ID: T13.G6.07
Topic: T13 – 2D Games
Skill: Create minimap display
Description: Create minimap sprite that shows scaled-down version of level. Place small dots representing player and enemies at scaled positions: `set minimap dot x to ((player x) / (5))`. Update in forever loop. Test that minimap reflects actual positions. _CSTA: 2-AP-17._

Dependencies:
* T13.G3.01.02: Program 4-directional movement with arrow keys
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.08
Topic: T13 – 2D Games
Skill: Build stealth detection system
Description: Create vision cone for enemy using `if <(distance to [Player]) < (100)> and <towards [Player] is within 45 degrees of my direction> then [set [Detected] to (1)]`. Add stealth mechanics where being detected triggers alert. Test detection angles. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.05.01: Point sprite toward player
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.09
Topic: T13 – 2D Games
Skill: Implement AI pathfinding between waypoints
Description: Create `Waypoints` list with coordinates. Enemy moves through waypoints in order: `go to x:(item (WaypointIndex) of [WaypointsX]) y:(item (WaypointIndex) of [WaypointsY])`, then increment WaypointIndex. Test enemy following path. _CSTA: 2-AP-14._

Dependencies:
* T10.G5.02: Build a project that processes list data with iteration
* T13.G4.05.02: Create chasing enemy behavior


ID: T13.G6.10
Topic: T13 – 2D Games
Skill: Create wave-based enemy spawning
Description: Create `Wave` variable. Each wave spawns increasing enemies: `repeat ((Wave) * (3)) { create clone of [Enemy], wait (1) second }`. When all enemies defeated, `change [Wave] by (1)` and spawn next wave. Test wave progression. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.11
Topic: T13 – 2D Games
Skill: Build combo attack system
Description: Track button press timing with `PressTime` variable. If space pressed within 0.5 seconds of last press, increment `ComboStage`. Different combo stages trigger different attack animations and damage amounts. Reset combo after timeout. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.01: Spawn projectile clones from player position
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.11.01
Topic: T13 – 2D Games
Skill: Add custom block for attack execution
Description: Create custom block `ExecuteAttack [stage]` that takes combo stage as parameter and switches between attack types (light punch, heavy punch, kick). Call from combo system. Test attack variety. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.11: Build combo attack system
* T11.G5.02: Define a custom block with input parameters


ID: T13.G6.12
Topic: T13 – 2D Games
Skill: Implement dodge roll with cooldown
Description: When dodge key pressed and `DodgeCooldown = 0`, set player to invincible, move quickly in current direction with `repeat (10) { move (15) steps }`, set cooldown to 3 seconds, gradually decrease cooldown in loop. Test dodge timing and cooldown. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.08: Implement temporary invincibility after damage
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.13
Topic: T13 – 2D Games
Skill: Create charge attack mechanic
Description: Track how long attack button is held using timer. When released, damage = hold duration * multiplier. Visual feedback shows charge level increasing. Add max charge limit. Test different charge levels and damage output. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.01: Spawn projectile clones from player position
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.14
Topic: T13 – 2D Games
Skill: Build tower defense spawn and path system
Description: Create waypoint path for enemies. Spawn enemies at intervals that follow path using waypoint list. Player places tower sprites that shoot at enemies within range. Test enemy pathing and tower shooting. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.09: Implement AI pathfinding between waypoints
* T13.G5.06: Create enemy that shoots projectiles


ID: T13.G6.15
Topic: T13 – 2D Games
Skill: Implement resource management (wood, gold)
Description: Create variables for multiple resources (Wood, Gold, Stone). Different actions cost different resources: `if <(Gold) > (10)> then [build tower, change [Gold] by (-10)]`. Display resources with monitors. Test gathering and spending resources. _CSTA: 2-AP-11._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.16
Topic: T13 – 2D Games
Skill: Create upgrade system with costs
Description: Create `TowerLevel` variable. When upgrade button clicked, check `if <(Gold) > (upgrade cost)> then [change [TowerLevel] by (1), change [Gold] by (0 - upgrade cost)]`. Higher level increases damage/range. Test upgrading and cost scaling. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.15: Implement resource management (wood, gold)
* T08.G5.02: Design multi-branch logic with if/else if/else


ID: T13.G6.17
Topic: T13 – 2D Games
Skill: Debug complex game logic with systematic testing
Description: Create test checklist for game systems: movement, collision, scoring, lives, win/loss conditions. Test each system independently, then together. Document bugs found and fixes applied. Practice methodical debugging. _CSTA: 2-AP-17._

Dependencies:
* T13.G4.14: Balance game difficulty through testing
* T08.G5.03: Debug nested conditionals using trace tables


ID: T13.G6.18
Topic: T13 – 2D Games
Skill: Refactor repeated code into custom helper blocks
Description: Identify repeated code patterns across sprites and replace with reusable custom blocks: `ResetPlayer`, `SpawnEnemy [x] [y]`, `UpdateHUD`. **Refactoring process:** (1) Find code that appears multiple times, (2) Extract into custom block with parameters for varying parts, (3) Replace original code with block calls, (4) Test that behavior remains identical. **Benefits:** Easier maintenance, fewer bugs, cleaner code structure. _CSTA: 2-AP-14._

Dependencies:
* T11.G5.02: Define a custom block with input parameters
* T13.G4.18: Design complete game loop with restart


ID: T13.G6.18.01
Topic: T13 – 2D Games
Skill: Analyze game code for algorithmic efficiency
Description: **Computational thinking practice:** Compare two implementations of the same game mechanic and analyze which is more efficient. **Example:** Checking if player touches any of 10 enemies: Option A: `if touching Enemy1 or touching Enemy2 or...` (10 checks). Option B: All enemies are clones of one sprite, single `if touching Enemy` check. **Analysis questions:** Which approach scales better? Which is easier to modify? Which runs faster? **Practice:** Given game code, identify inefficient patterns and propose improvements. _CSTA: 2-AP-17._

Dependencies:
* T13.G6.18: Refactor repeated code into custom helper blocks
* T13.G5.15: Debug performance issues with too many clones


ID: T13.G6.19
Topic: T13 – 2D Games
Skill: Generate enemy dialogue with AI
Description: Integrate ChatGPT blocks to create dynamic enemy dialogue. **Setup:** Create custom block `GenerateEnemyDialogue [enemy type] [player action]` that calls `chatgpt_chat` with prompt: "You are a [enemy type] enemy. The player just [player action]. Respond with a short threatening or taunting message (max 10 words)." **Implementation:** When player encounters enemy or defeats it, call the custom block and display the AI-generated response using `say` block. **Example prompts:** Enemy type = "goblin warrior", player action = "attacked you" → AI generates "You dare challenge me, foolish human?" **Test:** Encounter different enemy types and verify dialogue varies appropriately. Uses chatgpt_chat and custom blocks. This teaches AI integration for game content generation at an appropriate grade level. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.04: Build dialogue system with NPC
* T11.G5.02: Define a custom block with input parameters
* T14.G6.01: Use ChatGPT to generate story text from prompts


ID: T13.G6.20
Topic: T13 – 2D Games
Skill: Configure physics collision groups for selective collision
Description: Use `add collision group [1]` and `enable/disable collision with group [2]` blocks to control which physics objects collide with each other. **Example setup:** Player in group 0, enemies in group 1, player bullets in group 2, enemy bullets in group 3. Configure: player bullets don't collide with player (disable 2↔0), enemy bullets don't collide with enemies (disable 3↔1). **Game applications:** Bullets pass through allies but hit enemies, power-ups only affect player, enemy types that don't block each other. **Test:** Fire bullet through allies and verify it hits enemies only. Uses physics2d_addcollisiongroup and physics2d_enablecollisionwithgroup blocks. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.19: Use physics collision events for game logic
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.21
Topic: T13 – 2D Games
Skill: Create physics joints for connected objects
Description: Use `add revolute joint to [sprite] at anchor x [0] y [0]` to create rotating connections between physics bodies (like hinges). **Joint types:** Revolute = rotation around point (pendulum, swinging platform, door), Fixed = locked together (carrying object), Prismatic = sliding along axis (elevator, piston). **Swinging platform example:** Create platform with revolute joint at top center, add rope sprite, platform swings like pendulum. **Test:** Create chain of connected objects, apply force to end, watch physics propagate through chain. Uses physics2d_addrevolutejoint block. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.18: Apply forces and impulses to physics bodies
* T13.G4.22: Create static physics objects for platforms and walls


ID: T13.G6.22
Topic: T13 – 2D Games
Skill: Build a physics-based puzzle game
Description: Combine physics skills to create a puzzle game where players manipulate objects to reach a goal. **Example concepts:** Stack objects to reach high places, use see-saws and levers (revolute joints), knock down structures (angry birds style), guide rolling ball through obstacles. **Design requirements:** At least 3 physics objects interacting, clear goal state, multiple solutions possible. **Test:** Play through puzzle verifying physics interactions work reliably. This integrates G4-G6 physics skills into creative problem-solving. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.21: Create physics joints for connected objects
* T13.G5.18: Apply forces and impulses to physics bodies


ID: T13.G6.23
Topic: T13 – 2D Games
Skill: Debug physics simulation issues
Description: Common physics bugs and fixes: **Objects fall through floor:** Check static body is locked, collision groups are enabled, bodies are created after world init. **Objects shake/jitter:** Reduce time speed, check for conflicting forces, verify body shapes fit sprite. **Objects stuck:** Check for overlapping bodies at spawn, use impulse to separate. **Debug visualization:** Add `say (velocity y)` to show physics values, use ghost effect to show collision shapes. **Test:** Reproduce common issues and apply fixes. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.19: Use physics collision events for game logic
* T13.G5.18: Apply forces and impulses to physics bodies


ID: T13.G6.24
Topic: T13 – 2D Games
Skill: Detect hand poses for gesture-based game control
Description: Use CreatiCode's hand tracking extension to detect hand gestures for controlling games without keyboard or mouse. **Setup:** Add `turn on hand tracking` block at game start to enable webcam-based hand detection. **Reading hand position:** Use `hand [index finger tip] x` and `hand [index finger tip] y` blocks to get the position of any of the 21 hand landmark points. **Pointer control:** In a forever loop, set a cursor sprite to follow the index finger tip position. **Fist detection:** Use `hand [finger 1 curl angle]` through `hand [finger 5 curl angle]` - when all fingers have high curl angles (>130), the hand is making a fist. **Game application:** Move cursor with index finger, make fist to "click" or shoot. **Test:** Move hand in front of camera and verify smooth cursor tracking and reliable fist detection. Uses handext_turnontracking, handext_getdata blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G5.22: Create touch controls with virtual joystick widget
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.25
Topic: T13 – 2D Games
Skill: Implement pinch gesture for object manipulation
Description: Detect thumb-to-finger pinch gesture for grabbing and moving game objects. **Pinch detection:** Calculate distance between thumb tip and index finger tip: `set [PinchDistance] to (distance between x (hand [thumb tip] x) y (hand [thumb tip] y) and x (hand [index finger tip] x) y (hand [index finger tip] y))`. When distance < 30 pixels, user is pinching. **Grab mechanic:** When pinch starts near a draggable object, attach object to hand position. When pinch releases, drop object. **Drag and drop game:** Create puzzle game where players physically grab and move pieces. **Two-hand support:** Track both hands for games requiring simultaneous manipulation. **Test:** Pinch near objects to grab, move hand to drag, release to drop. Uses handext_getdata and operator_vector_distance blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.24: Detect hand poses for gesture-based game control
* T13.G6.02: Implement item usage from inventory


ID: T13.G6.26
Topic: T13 – 2D Games
Skill: Implement voice commands for game control
Description: Use speech recognition to control games with voice commands. **Setup:** Add `when I hear [jump]` block to trigger actions when the player says specific words. **Command vocabulary:** Create separate event blocks for each command: `when I hear [jump]` → player jumps, `when I hear [shoot]` → player fires, `when I hear [left]` → move left. **Continuous listening:** Use `start listening for speech` block to enable ongoing voice recognition without button press. **Feedback:** Provide visual feedback when command is recognized (flash the command word on screen). **Noise handling:** Test in different environments; consider adding sensitivity settings. **Game applications:** Hands-free games for accessibility, action commands while hands are busy with other controls. **Test:** Speak each command clearly and verify correct action triggers. Uses speechrecognition_whenihear, speechrecognition_startlistening blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.18: Design complete game loop with restart
* T09.G5.01: Design a complex program using multiple variables


ID: T13.G6.27
Topic: T13 – 2D Games
Skill: Create in-game voice chat using speech-to-text
Description: Convert player speech to text for in-game chat or commands. **Setup:** Use `ask using speech and wait` block to capture spoken input and store it in a variable. **Chat system:** When player speaks, convert to text, display in chat bubble with `say [speech result] for (3) seconds`, and broadcast to other players in multiplayer. **Dictation mode:** Use continuous speech recognition with `start listening for speech` and `(speech result)` reporter to capture longer spoken input. **Use cases:** In-game chat without typing, naming characters, dictating story content, issuing complex commands ("Go to the castle and find the key"). **Error handling:** If speech result is empty, prompt player to try again. **Test:** Speak various phrases and verify accurate text conversion. Uses speechrecognition_askusing, speechrecognition_result blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.26: Implement voice commands for game control
* T13.G6.04: Build dialogue system with NPC


ID: T13.G6.28
Topic: T13 – 2D Games
Skill: Use dominance groups to control physics pushing behavior
Description: Use `set dominance group to [5]` block to control which physics objects can push which other objects. **How it works:** Objects with higher dominance group numbers push objects with lower dominance numbers, but are not pushed back. Equal dominance objects push each other normally. **Range:** Dominance groups range from -127 to 127. **Game applications:** Player (dominance 10) can push enemies (dominance 5) but enemies can't push player back; heavy objects (high dominance) move light objects (low dominance) but not vice versa; immovable bosses that don't get knocked back. **Boss example:** Set boss dominance to 100, player to 10 - player attacks push player back, boss never moves. **Test:** Create two physics sprites with different dominance, collide them, verify only lower dominance object moves. Uses physics_setdominancegroup block. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.20: Configure physics collision groups for selective collision
* T13.G5.18: Apply forces and impulses to physics bodies


## Grade 7 (29 skills)

ID: T13.G7.01
Topic: T13 – 2D Games
Skill: Design state machine for enemy AI
Description: Create `EnemyState` variable with states: "patrol", "chase", "attack", "retreat". Use nested ifs to check conditions and transition states: `if <(distance to [Player]) < (100)> then [set [EnemyState] to (chase)]`. Each state has different behavior. Test state transitions. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.08: Build stealth detection system
* T08.G6.01: Design complex conditional trees


ID: T13.G7.02
Topic: T13 – 2D Games
Skill: Implement A-star pathfinding basics
Description: Create simplified pathfinding using waypoint costs. Calculate path cost to player through different waypoints, choose lowest cost path. Enemy moves toward waypoint with lowest total cost to reach player. Test enemy finding optimal path around obstacles. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.09: Implement AI pathfinding between waypoints
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.03
Topic: T13 – 2D Games
Skill: Create behavior trees for complex AI
Description: Build hierarchical AI decision system. Root node checks "Can see player?" If yes, go to attack branch. If no, go to patrol branch. Each branch has sub-decisions. Implement using nested custom blocks representing tree nodes. Test AI decision making. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.01: Design state machine for enemy AI
* T11.G6.01: Create custom blocks with return values


ID: T13.G7.04
Topic: T13 – 2D Games
Skill: Build particle system for visual effects
Description: Create particle effect using rapid clone spawning. When explosion event occurs, spawn 20+ small particle clones with random directions and speeds: `point in direction (pick random (0) to (360))`, `repeat (10) { move (speed) steps, change size by (-10) }`, then delete. Test explosion effects. _CSTA: 2-AP-14._

Dependencies:
* T13.G3.10: Create collectible items with clones
* T09.G6.01: Use mathematical operations in programs


ID: T13.G7.04.01
Topic: T13 – 2D Games
Skill: Create reusable particle effect custom block
Description: Create custom block `SpawnParticles [x] [y] [count] [color]` that spawns particle effects at any location with configurable parameters. Test calling from different game events (explosions, power-ups, impacts). _CSTA: 2-AP-14._

Dependencies:
* T13.G7.04: Build particle system for visual effects
* T11.G6.01: Create custom blocks with return values


ID: T13.G7.05
Topic: T13 – 2D Games
Skill: Implement sprite pooling for performance
Description: Instead of constantly creating/deleting clones, create pool of hidden clones at start. When needed, unhide and position clone. When done, hide it for reuse. Reduces lag from clone creation. Create `AvailableBullets` list tracking unused clones. Test performance improvement. _CSTA: 2-AP-17._

Dependencies:
* T13.G5.15: Debug performance issues with too many clones
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.06
Topic: T13 – 2D Games
Skill: Create level editor with saving
Description: Build mode where clicking places platforms, enemies, items. Store placed objects in lists with coordinates and types. Export lists as level data. Create `LoadLevel` block that recreates level from saved lists. Test creating and loading custom levels. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.06: Implement save/load with list export
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.07
Topic: T13 – 2D Games
Skill: Build random dungeon generator
Description: Create algorithm that generates connected rooms. Use 2D grid list where each cell = room type (empty, corridor, enemy room, treasure). Randomly place rooms ensuring connectivity. Convert grid to actual level layout with platforms and enemies. Test dungeon variety and playability. _CSTA: 2-AP-14._

Dependencies:
* T13.G5.12: Create procedural level generation
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.08
Topic: T13 – 2D Games
Skill: Implement fog of war exploration
Description: Create `Explored` list matching level grid. Areas start hidden with dark overlay sprites. When player enters area, mark as explored in list and remove overlay clone. Test exploration reveals map gradually. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.07: Create minimap display
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.09
Topic: T13 – 2D Games
Skill: Create context-sensitive action system
Description: Display different action prompts based on what player is near. Use `if <touching [Door]?> then [show "Press E to Open"], if <touching [NPC]?> then [show "Press E to Talk"]`. Action key triggers appropriate response. Test multiple interactable types. _CSTA: 2-AP-13._

Dependencies:
* T13.G6.04: Build dialogue system with NPC
* T08.G6.01: Design complex conditional trees


ID: T13.G7.10
Topic: T13 – 2D Games
Skill: Build skill tree and unlocking system
Description: Create table of skills with dependencies. Player earns skill points, spends to unlock skills. Check `if <[RequiredSkills] contains [prerequisite]> then [allow unlock]`. Display skill tree UI showing locked/unlocked skills. Test dependency chains. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.16: Create upgrade system with costs
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.11
Topic: T13 – 2D Games
Skill: Implement equipment system with stat modifiers
Description: Create `Equipment` list containing worn items. Each item adds stat bonuses stored in parallel lists (EquipmentNames, StatTypes, StatValues). Calculate total stats by iterating through equipped items. Test equipping different item combinations and resulting stats. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.01: Design inventory system with list
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.12
Topic: T13 – 2D Games
Skill: Create status effect system (poison, burn, freeze)
Description: Create `ActiveEffects` list and `EffectTimers` list. When effect applied, add to list with duration. Each game tick, apply effect (damage over time, slow movement), decrease timer, remove when expired. Test multiple simultaneous effects. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.12: Implement dodge roll with cooldown
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.13
Topic: T13 – 2D Games
Skill: Build crafting system with recipes
Description: Create recipe table with ingredient requirements and output items. When crafting, check `if <[Inventory] contains all ingredients> then [remove ingredients, add crafted item]`. Display craftable recipes based on current inventory. Test crafting items. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.15: Implement resource management (wood, gold)
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.14
Topic: T13 – 2D Games
Skill: Implement day/night cycle affecting gameplay
Description: Create `TimeOfDay` variable cycling 0-24. Different events occur at different times: enemies stronger at night, shops only open during day, special events at specific hours. Use tint effects to visualize time. Test time-based mechanics. _CSTA: 2-AP-13._

Dependencies:
* T13.G4.09: Build a timer system
* T09.G6.01: Use mathematical operations in programs


ID: T13.G7.15
Topic: T13 – 2D Games
Skill: Create weather system affecting mechanics
Description: Create `Weather` variable (clear, rain, snow). Weather affects gameplay: rain reduces traction (slower acceleration), snow reduces visibility (fog effect), clear = normal. Weather changes randomly over time. Test different weather effects on gameplay. _CSTA: 2-AP-13._

Dependencies:
* T13.G3.09: Create visual feedback with graphic effects
* T09.G6.01: Use mathematical operations in programs


ID: T13.G7.16
Topic: T13 – 2D Games
Skill: Debug complex game systems with logging
Description: Create debug mode that logs events to a list: "Player hit at x:120 y:45 time:234", "Enemy spawned type:goblin wave:3". Display log on screen or export for analysis. Use logging to trace complex bugs across multiple systems. _CSTA: 2-AP-17._

Dependencies:
* T13.G6.17: Debug complex game logic with systematic testing
* T10.G6.01: Design algorithms that process list data


ID: T13.G7.16.01
Topic: T13 – 2D Games
Skill: Compare algorithmic approaches for game AI
Description: **Algorithm analysis:** Implement the same AI behavior using different algorithms and compare results. **Example - enemy finding player:** Algorithm A (greedy): Always move toward current player position. Algorithm B (predictive): Calculate where player will be in 1 second based on velocity, move there. **Comparison criteria:** (1) Effectiveness (does enemy catch player?), (2) Computational cost (how many calculations per frame?), (3) Emergent behavior (does AI seem smart or dumb?). **Practice:** Implement both approaches, playtest, document which performs better and why. This teaches algorithm evaluation beyond just "does it work." _CSTA: 2-AP-14._

Dependencies:
* T13.G7.01: Design state machine for enemy AI
* T13.G6.18.01: Analyze game code for algorithmic efficiency


ID: T13.G7.17
Topic: T13 – 2D Games
Skill: Create multiplayer game room
Description: Implement multiplayer functionality using CreatiCode multiplayer blocks. **Setup:** Use `mp_createmultiplayergame [room name]` block to create a new game room with a unique name (e.g., "Battle Arena 1"). **Broadcasting room ID:** Display the room name on screen so other players can join. **Initializing host:** Set a `PlayerRole` variable to "host" for the player who creates the room. **Test:** Run the project, click to create game room, verify room is created and room name is displayed. Uses mp_createmultiplayergame block. This is the foundation for multiplayer game development. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.18: Design complete game loop with restart
* T09.G6.01: Use mathematical operations in programs


ID: T13.G7.18
Topic: T13 – 2D Games
Skill: Join and sync player sprites
Description: Enable other players to join an existing game room and sync sprites. **Joining:** Use `mp_joinmultiplayergame [room name]` block with the room name to join an existing game. **Adding sprite to game:** After joining, use `mp_addspritetogame` block to register the local player sprite in the multiplayer session. **Broadcasting position:** In a forever loop, use `mp_broadcastmessagetoall [message]` where message = `join [x:] (x position) [y:] (y position)` to share player position with all players. **Receiving updates:** Use `when I receive multiplayer message` with `mp_getmessagedata` to read other players' positions and update their sprite clones accordingly. **Test:** Open project in two browser tabs, create room in tab 1, join from tab 2, verify both player sprites appear and move. Uses mp_joinmultiplayergame, mp_addspritetogame, mp_broadcastmessagetoall, and mp_getmessagedata blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G7.17: Create multiplayer game room
* T13.G3.01.02: Program 4-directional movement with arrow keys


ID: T13.G7.19
Topic: T13 – 2D Games
Skill: Implement game leaderboard with cloud storage
Description: Use `record player score [score] for leaderboard [game name]` block to save high scores to CreatiCode's cloud database. **Setup:** After game over or level complete, record the player's score. **Displaying leaderboard:** Use `show game leaderboard [game name]` to display top scores. **Leaderboard features:** Automatically ranks scores, shows usernames, persists across sessions. **Test:** Play game multiple times with different scores, verify leaderboard updates and ranks correctly. Uses game_recordscore and game_showleaderboard blocks. This teaches cloud data persistence for competitive games. _CSTA: 2-AP-16._

Dependencies:
* T13.G4.06: Create and manage a Score variable
* T13.G4.18: Design complete game loop with restart


ID: T13.G7.20
Topic: T13 – 2D Games
Skill: Save game progress to cloud with user data
Description: Use `store user data key [save_slot] value [data]` to save game progress that persists across sessions. **What to save:** Current level, score, inventory items, achievements. **Data format:** Combine multiple values into single string: `join [level:] (Level) [,score:] (Score)`. **Loading:** Use `read user data key [save_slot]` on game start to restore progress. **Parse loaded data:** Split string to extract individual values. **Test:** Save progress, close project, reopen, verify progress loads correctly. Uses game_storeuserdata and game_readuserdata blocks. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.06: Implement save/load with list export
* T13.G7.19: Implement game leaderboard with cloud storage


ID: T13.G7.21
Topic: T13 – 2D Games
Skill: Build a hand-tracking drawing or painting game
Description: Create a drawing/painting game controlled entirely by hand gestures using the webcam. **Drawing mechanic:** When index finger is extended (low curl angle) and other fingers are curled (fist except index), draw with pen at finger position: `if <(hand [finger 1 curl angle]) < (60)> and <(hand [finger 2 curl angle]) > (120)> then [pen down] else [pen up]`. **Color selection:** Hold up different numbers of fingers to select colors (1 finger = red, 2 = blue, 3 = green, fist = eraser). **Gesture vocabulary:** Peace sign (2 fingers) = undo, thumbs up = save, open palm = clear canvas. **Smoothing:** Average finger positions over 3 frames to reduce jitter. **Test:** Draw shapes, change colors with gestures, save artwork. Uses handext_getdata, pen extension blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.25: Implement pinch gesture for object manipulation
* T13.G6.24: Detect hand poses for gesture-based game control


ID: T13.G7.22
Topic: T13 – 2D Games
Skill: Create multi-gesture vocabulary for complex hand-controlled games
Description: Design and implement a comprehensive gesture recognition system for games requiring multiple distinct hand poses. **Gesture library:** Define gestures using finger curl angles and relative positions: Open palm (all fingers extended, curl < 30), Fist (all curled > 140), Point (index extended, others curled), Peace (index + middle extended), Thumbs up (thumb extended, others curled, hand rotated). **State machine:** Track current gesture and detect transitions (gesture A → gesture B triggers action). **Cooldown:** Prevent rapid gesture switching by requiring gesture hold for 0.3 seconds. **Visual feedback:** Display recognized gesture name on screen. **Game application:** Fighting game with different attacks per gesture, magic casting game, sign language teaching game. **Test:** Perform each gesture 10 times and verify >90% recognition accuracy. Uses handext_getdata with complex conditional logic. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.21: Build a hand-tracking drawing or painting game
* T13.G7.01: Design state machine for enemy AI


ID: T13.G7.23
Topic: T13 – 2D Games
Skill: Detect body poses for exercise or fitness games
Description: Use CreatiCode's body pose tracking to create fitness or exercise games. **Setup:** Add `turn on pose tracking` block to enable webcam-based body pose detection. **Reading joint positions:** Use `pose [right wrist] x` and `pose [right wrist] y` blocks to get positions of body joints (wrists, elbows, shoulders, hips, knees, ankles, head). **Exercise detection - Jumping jacks:** Detect arms up (wrists above shoulders) AND legs apart (ankles > 150 pixels apart), then arms down AND legs together for one rep. **Squat detection:** Track hip y-position - when hips drop below a threshold and knees bend, count a squat. **Rep counter:** Increment counter when full exercise motion completes. **Feedback:** Show skeleton overlay, count reps on screen, play encouraging sounds. **Test:** Perform exercises and verify accurate counting. Uses poseext_turnontracking, poseext_getdata blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.24: Detect hand poses for gesture-based game control
* T09.G6.01: Use mathematical operations in programs


ID: T13.G7.24
Topic: T13 – 2D Games
Skill: Build a dance or rhythm game with full-body tracking
Description: Create a rhythm game where players match dance poses shown on screen. **Pose matching:** Display target pose image, detect if player's pose matches within tolerance using body joint comparisons. **Scoring:** Calculate similarity score by comparing each joint position to target: `set [Score] to ((Score) + (100 - (distance between player joint and target joint)))`. **Rhythm timing:** Sync pose requirements to music beats using timer. **Multiple poses:** Create sequences of poses that players must hit on beat. **Difficulty levels:** Easy = 1 pose per 2 seconds, Hard = 1 pose per 0.5 seconds. **Visual feedback:** Show colored skeleton (green = good match, yellow = close, red = miss), display score multiplier for streaks. **Test:** Play through a full song, verify pose detection matches player movement. Uses poseext_getdata, sound blocks for music timing. _CSTA: 2-AP-16._

Dependencies:
* T13.G7.23: Detect body poses for exercise or fitness games
* T13.G7.14: Implement day/night cycle affecting gameplay


ID: T13.G7.25
Topic: T13 – 2D Games
Skill: Combine voice commands with gesture controls
Description: Create multimodal input games that respond to both voice and gestures simultaneously. **Command layering:** Voice commands for discrete actions ("jump", "shoot", "pause"), gestures for continuous control (hand position = aim direction). **Context switching:** Voice command "aiming mode" enables gesture targeting, "movement mode" enables gesture-based steering. **Confirmation patterns:** Require voice + gesture combination for important actions (say "fire" while making fist to confirm attack). **Accessibility enhancement:** Provide voice alternatives for all gesture controls and vice versa. **Game example:** Space shooter where hand position aims, voice says "fire" to shoot, fist gesture activates shield. **Error handling:** Resolve conflicts when voice and gesture inputs contradict (recent input wins, or require confirmation). **Test:** Play game using various input combinations. Uses speechrecognition_whenihear combined with handext_getdata. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.26: Implement voice commands for game control
* T13.G7.22: Create multi-gesture vocabulary for complex hand-controlled games


ID: T13.G7.26
Topic: T13 – 2D Games
Skill: Generate game sprites and backdrops with AI image prompts
Description: Use CreatiCode's AI image generation to create custom game visuals during gameplay or setup. **Sprite generation:** Use `generate image [prompt]` block with descriptive prompts like "cartoon dragon enemy, side view, game sprite style, transparent background". **Backdrop generation:** Create level backgrounds with prompts like "fantasy forest game background, pixel art style, horizontal scrolling". **Style consistency:** Include style descriptors in all prompts ("pixel art", "hand drawn", "vector art") to maintain visual cohesion. **Player customization:** Let players describe their character ("blue robot with jetpack") and generate custom player sprite. **Dynamic content:** Generate unique enemy designs, treasure items, or level themes based on game state. **Loading time:** Show loading indicator while image generates (2-5 seconds). **Test:** Generate multiple assets and verify they match game style. Uses aiimage_generate block. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.19: Generate enemy dialogue with AI
* T13.G7.07: Build random dungeon generator


ID: T13.G7.27
Topic: T13 – 2D Games
Skill: Track player behavior metrics for game analytics
Description: Implement a game analytics system that records player actions, timing, and outcomes for game improvement. **Event tracking:** Log key events to a list: player deaths (with location and cause), level completions (with time and score), item purchases, button clicks, feature usage. **Format:** Each log entry = `join [timestamp] [:] [event_type] [:] [event_data]`, e.g., "45.2:death:spike_pit_level3". **Session metrics:** Track session length, levels attempted vs. completed, average time per level, death frequency by location. **Heat map data:** Record player position every 2 seconds to identify where players spend time or struggle. **Export:** Save analytics to list that can be exported for external analysis. **Privacy:** Only collect gameplay data, no personal information. **Test:** Play through game, export analytics, verify data accuracy and completeness. Uses list operations, timer blocks. _CSTA: 2-AP-17._

Dependencies:
* T13.G7.16: Debug complex game systems with logging
* T13.G7.19: Implement game leaderboard with cloud storage


## Grade 8 (30 skills)

ID: T13.G8.01
Topic: T13 – 2D Games
Skill: Design modular game architecture
Description: Organize game into modules using custom blocks: `GameManager` block controls game flow, `PlayerController` handles input, `EnemyAI` manages enemies, `UIManager` updates display. Each module has clear responsibility. Test that modules work independently and together. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.18: Optimize code with custom helper blocks
* T11.G7.01: Design programs using procedural decomposition


ID: T13.G8.02
Topic: T13 – 2D Games
Skill: Implement event-driven architecture
Description: Create centralized event system. Game events broadcast messages ("PlayerDamaged", "EnemyDefeated", "ItemCollected") with data. Multiple systems listen and respond independently. Decouples systems for easier modification. Test event propagation across systems. _CSTA: 2-AP-16._

Dependencies:
* T13.G3.07: Trigger Game Over with broadcast
* T11.G7.01: Design programs using procedural decomposition


ID: T13.G8.03
Topic: T13 – 2D Games
Skill: Build data-driven gameplay with table variables
Description: Store all game balance data (enemy stats, item properties, level parameters) in table variables. Code reads from tables rather than hardcoding values. Modify game balance by editing tables without changing code. Test data-driven modification workflow. Uses table_create, table_addrow, table_getvalue blocks extensively. _CSTA: 2-AP-11._

Dependencies:
* T13.G5.14: Store level data in table variable
* T10.G7.01: Use table variables for complex data organization


ID: T13.G8.04
Topic: T13 – 2D Games
Skill: Create save system with state serialization
Description: Build comprehensive save system that captures entire game state. Serialize all variables, lists, and table data into exportable format. Implement `SerializeState` and `DeserializeState` custom blocks. Test saving mid-game and restoring exact state. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.06: Implement save/load with list export
* T11.G7.01: Design programs using procedural decomposition


ID: T13.G8.05
Topic: T13 – 2D Games
Skill: Implement replay system recording inputs
Description: Record all player inputs with timestamps to a list. Replay mode reads inputs and executes them with timing. Useful for debugging, testing, and creating demos. Create `RecordInput` and `PlaybackInputs` custom blocks. Test recording and replaying gameplay. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.06: Create level editor with saving
* T10.G7.01: Use table variables for complex data organization


ID: T13.G8.06
Topic: T13 – 2D Games
Skill: Design AI director that adjusts difficulty
Description: Create AI director that monitors player performance (deaths, health, time taken) and adjusts difficulty dynamically. If player struggling, reduce enemy count or increase health drops. If excelling, increase challenge. Create `AnalyzePerformance` and `AdjustDifficulty` custom blocks. Test adaptive difficulty. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.10: Create wave-based enemy spawning
* T11.G7.01: Design programs using procedural decomposition


ID: T13.G8.06.01
Topic: T13 – 2D Games
Skill: Balance AI director with player feedback
Description: Test AI director with multiple players of different skill levels. Collect feedback on difficulty curve. Adjust director parameters (thresholds, adjustment magnitudes) based on testing. Document balancing decisions. _CSTA: 2-AP-17._

Dependencies:
* T13.G8.06: Design AI director that adjusts difficulty


ID: T13.G8.07
Topic: T13 – 2D Games
Skill: Build animation state machine
Description: Create comprehensive animation system using state machine. States include: idle, walk, run, jump, attack, damaged, death. Transitions between states based on game conditions. Use `AnimationState` variable and nested conditionals to control costume switching and timing. Test all animation transitions. _CSTA: 2-AP-13._

Dependencies:
* T13.G7.01: Design state machine for enemy AI
* T08.G7.01: Model complex systems with state machines


ID: T13.G8.08
Topic: T13 – 2D Games
Skill: Implement inverse kinematics for character limbs
Description: Create procedural limb animation using math. Given target position, calculate joint angles for arm/leg segments to reach target. Use trigonometry to solve 2-joint IK. Apply to aiming weapon toward cursor or feet adapting to terrain slopes. Test IK solving. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.13: Create charge attack mechanic
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.09
Topic: T13 – 2D Games
Skill: Create advanced camera system with smoothing
Description: Implement camera that smoothly follows player with easing. Camera position = current + (target - current) * smoothing factor. Add camera shake for impacts, zoom for specific events, boundary constraints to keep level in view. Create `UpdateCamera` custom block. Test camera behaviors. _CSTA: 2-AP-14._

Dependencies:
* T13.G5.11: Implement scrolling camera following player
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.10
Topic: T13 – 2D Games
Skill: Build advanced particle systems with physics
Description: Extend particle system with realistic physics. Particles affected by gravity, wind, bounce on collision. Create particle emitters with configurable spawn rates, lifetimes, forces. Build effects: fire (rising particles), water (falling particles), smoke (drifting particles). Create `ParticleEmitter [type]` custom block. _CСТА: 2-AP-14._

Dependencies:
* T13.G7.04: Build particle system for visual effects
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.11
Topic: T13 – 2D Games
Skill: Implement steering behaviors for AI movement
Description: Create steering behaviors: seek (move toward target), flee (move away), wander (random exploration), pursue (predict target's future position). Combine behaviors with weighted priorities. Create `CalculateSteering [behavior] [target]` custom block. Test AI movement patterns. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.03: Create behavior trees for complex AI
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.12
Topic: T13 – 2D Games
Skill: Create influence map for strategic AI
Description: Build grid representing strategic value of map locations. High value near objectives, low value near hazards. AI uses influence map to make strategic decisions (positioning, retreat paths). Update map as game state changes. Test AI using influence data for decisions. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.02: Implement A-star pathfinding basics
* T10.G7.01: Use table variables for complex data organization


ID: T13.G8.13
Topic: T13 – 2D Games
Skill: Build team AI with coordination
Description: Create AI where multiple enemies coordinate. Use shared variables for team state. Enemies call for reinforcements, flank player, cover retreating teammates. Implement `TeamCoordination` custom block that analyzes team needs and assigns roles. Test coordinated team behaviors. _CSTA: 2-AP-14._

Dependencies:
* T13.G7.01: Design state machine for enemy AI
* T11.G7.01: Design programs using procedural decomposition


ID: T13.G8.14
Topic: T13 – 2D Games
Skill: Implement advanced physics: friction and momentum
Description: Add realistic physics to movement. Track `XVelocity` and `YVelocity`, apply friction each frame: `set [XVelocity] to ((XVelocity) * (0.9))`. Acceleration builds velocity, friction slows it. Creates sliding, momentum-based movement. Test ice physics, vehicle handling. _CSTA: 2-AP-13._

Dependencies:
* T13.G5.01: Implement physics-based jumping
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.15
Topic: T13 – 2D Games
Skill: Create advanced collision response with physics
Description: Implement collision response that calculates bounce angles and energy transfer. When collision detected, calculate collision normal vector, reflect velocity vector, apply elasticity coefficient. Creates realistic bouncing, sliding along walls. Test physics-based collision. _CSTA: 2-AP-14._

Dependencies:
* T13.G8.14: Implement advanced physics: friction and momentum
* T09.G7.01: Apply mathematical concepts in programming


ID: T13.G8.16
Topic: T13 – 2D Games
Skill: Build profiling system to measure performance
Description: Create performance profiler that measures frame rate, clone count, script execution counts. Display performance metrics on screen. Identify performance bottlenecks. Create `StartProfiling` and `ReportMetrics` custom blocks. Test identifying and fixing performance issues. _CSTA: 2-AP-17._

Dependencies:
* T13.G7.16: Debug complex game systems with logging
* T10.G7.01: Use table variables for complex data organization


ID: T13.G8.16.01
Topic: T13 – 2D Games
Skill: Evaluate time and space complexity of game algorithms
Description: **Computer science foundations:** Analyze game algorithms using Big-O notation concepts. **Time complexity examples:** Collision checking all pairs of N clones = O(N²), finding closest enemy from list = O(N), hash lookup for item in inventory = O(1). **Space complexity examples:** Storing full game replay = O(game length), tile map = O(width × height), particle pool with max 100 = O(1). **Practical application:** When game lags with many enemies, identify if algorithm complexity is the cause. **Optimization strategies:** Spatial partitioning reduces collision checks from O(N²) to ~O(N), object pooling prevents memory allocation spikes. **Practice:** Given game code, estimate complexity and predict at what scale (enemy count, level size) performance will degrade. _CSTA: 2-AP-17._

Dependencies:
* T13.G8.16: Build profiling system to measure performance
* T13.G7.16.01: Compare algorithmic approaches for game AI


ID: T13.G8.17
Topic: T13 – 2D Games
Skill: Implement complete tutorial system
Description: Build interactive tutorial that teaches game mechanics step by step. Use state machine for tutorial progress. Highlight UI elements, display instructions, wait for player to complete actions before proceeding. Create `TutorialManager` with steps defined in table. Test tutorial flow and clarity. _CSTA: 2-AP-16._

Dependencies:
* T13.G6.04: Build dialogue system with NPC
* T13.G8.01: Design modular game architecture


ID: T13.G8.18
Topic: T13 – 2D Games
Skill: Implement real-time multiplayer combat
Description: Build synchronous multiplayer combat system using multiplayer blocks. **Combat mechanics:** When player attacks, use `mp_broadcastmessagetoall [attack]` with attack data including attacker ID, damage, and hit position. **Receiving attacks:** Use `when I receive multiplayer message` to detect incoming attacks, check if local player is hit using position/hitbox comparison, apply damage if hit. **Health sync:** Broadcast health changes with `mp_broadcastmessagetoall` to keep all clients updated. **Hit detection:** Use distance calculation between attack position and player position to determine hits: `if <(distance to attack position) < (50)> then [take damage]`. **Test:** Open in multiple browser tabs, have players attack each other, verify damage is applied and health syncs correctly across all clients. Uses mp_broadcastmessagetoall, mp_getmessagedata, and multiplayer event blocks. _CSTA: 2-AP-16._

Dependencies:
* T13.G7.18: Join and sync player sprites
* T13.G4.02: Program projectile movement and hit detection


ID: T13.G8.19
Topic: T13 – 2D Games
Skill: Design multiplayer game architecture
Description: Design complete architecture for multiplayer game considering network latency, client-server vs peer-to-peer models, and state synchronization strategies. **Key concepts:** Client-side prediction (immediate local feedback while waiting for server confirmation), server reconciliation (correcting client state based on authoritative server), entity interpolation (smoothing movement between network updates). **Implementation approach:** Use CreatiCode multiplayer blocks with authoritative host model where room creator validates game events. **Design decisions:** Which data to sync (positions, health, game state), sync frequency (every frame vs. significant events only), conflict resolution (who wins when both players shoot simultaneously). **Documentation:** Create architecture diagram showing data flow between clients and message types. **Test:** Document edge cases (what happens if player disconnects mid-game?) and implement graceful handling. This teaches multiplayer system design principles applicable beyond block-based programming. _CSTA: 2-AP-16._

Dependencies:
* T13.G8.18: Implement real-time multiplayer combat
* T13.G8.01: Design modular game architecture


ID: T13.G8.20
Topic: T13 – 2D Games
Skill: Use AI to generate game content dynamically
Description: Integrate ChatGPT blocks to generate game content at runtime. **Level descriptions:** Use AI to create narrative context for procedurally generated levels ("You enter a dark cave filled with ancient treasures..."). **Item descriptions:** Generate unique descriptions for loot items. **Quest generation:** Create dynamic quest objectives based on game state. **Implementation:** Create custom block `GenerateContent [type] [context]` that calls ChatGPT with appropriate prompts and constraints. **Prompt engineering:** Include constraints like "respond in under 20 words", "use fantasy vocabulary", "make it exciting for players". **Test:** Generate content during gameplay and verify it's contextually appropriate and enhances immersion. Uses chatgpt_chat blocks with custom prompts. _CSTA: 2-AP-14._

Dependencies:
* T13.G6.19: Generate enemy dialogue with AI
* T13.G7.07: Build random dungeon generator


ID: T13.G8.21
Topic: T13 – 2D Games
Skill: Design and document a complete game design document
Description: Create a comprehensive game design document (GDD) for a 2D game project. **Required sections:** (1) Game overview (genre, target audience, core loop), (2) Game mechanics (player abilities, enemies, scoring), (3) Level design (progression, difficulty curve), (4) Technical architecture (sprite organization, custom blocks, data structures), (5) UI/UX design (menus, HUD, feedback systems), (6) Testing plan (what to test, success criteria). **Process:** Start with concept sketch, iterate through playtesting, document final design decisions. **Deliverable:** Written document plus working prototype implementing key features. This capstone skill synthesizes all T13 learning into professional game development practice. _CSTA: 2-AP-16._

Dependencies:
* T13.G8.01: Design modular game architecture
* T13.G8.06: Design AI director that adjusts difficulty
* T13.G7.06: Create level editor with saving


ID: T13.G8.22
Topic: T13 – 2D Games
Skill: Create multiplayer body-tracking competitive games
Description: Build competitive games where multiple players use body tracking simultaneously, either on the same screen or networked. **Same-screen mode:** Use left/right stage regions for each player's pose detection, compare pose accuracy in real-time for competitive dance/fitness. **Networked mode:** Broadcast body pose data (joint positions as compressed data string) to other players using multiplayer blocks. **Competitive mechanics:** Head-to-head pose matching races, fitness challenges with live leaderboards, cooperative games requiring synchronized movements. **Performance optimization:** Send only changed joint data, reduce update frequency to 10Hz for network games. **Lag compensation:** Use interpolation to smooth received pose data. **Test:** Play competitive game with another player, verify fair competition and responsive controls. Uses poseext_getdata combined with mp_broadcastmessagetoall. _CSTA: 2-AP-16._

Dependencies:
* T13.G7.24: Build a dance or rhythm game with full-body tracking
* T13.G8.18: Implement real-time multiplayer combat


ID: T13.G8.23
Topic: T13 – 2D Games
Skill: Generate dynamic game content with AI during gameplay
Description: Use AI to create unique game content in real-time as players progress. **Procedural quest generation:** When entering new area, call ChatGPT with context: "Generate a quest for a [player level] player in a [current area type]. Include objective, reward, and 2-3 steps. Format: JSON." Parse response to create actual quest. **Dynamic item descriptions:** Generate unique lore for procedurally generated items based on their stats. **Adaptive storytelling:** AI generates narrative text responding to player choices and game state. **Contextual hints:** When player is stuck, AI generates contextual hints based on current puzzle state. **Caching:** Store generated content to avoid regenerating same content. **Fallback:** If AI fails, use pre-written default content. **Test:** Play through game, verify AI content is contextually appropriate and enhances gameplay. Uses chatgpt_chat with structured prompts and JSON parsing. _CSTA: 2-AP-14._

Dependencies:
* T13.G8.20: Use AI to generate game content dynamically
* T13.G7.26: Generate game sprites and backdrops with AI image prompts


ID: T13.G8.24
Topic: T13 – 2D Games
Skill: Build analytics dashboard for data-driven game balancing
Description: Create a visual dashboard that displays game analytics to inform design decisions. **Data visualization:** Use drawing blocks to create charts: bar graph of deaths per level section, line graph of player progression over time, pie chart of most used abilities. **Real-time updates:** Dashboard updates as new data comes in during playtest sessions. **Key metrics to display:** Session length distribution, completion rates by level, time spent in each game area, most common death locations, feature usage statistics. **Comparison views:** Compare metrics across different game versions or player segments. **Export reports:** Format analytics into readable summary text. **Design decisions:** Document how each metric influences game balance changes (e.g., "Level 3 death rate is 80% at spike section - reduce spike count"). **Test:** Run playtest sessions, verify dashboard accurately reflects player behavior. Uses table_getvalue, looks_draw_rectangle, looks_draw_line for visualization. _CSTA: 2-AP-17._

Dependencies:
* T13.G7.27: Track player behavior metrics for game analytics
* T13.G8.03: Build data-driven gameplay with table variables


ID: T13.G8.25
Topic: T13 – 2D Games
Skill: Debug multiplayer synchronization issues
Description: Diagnose and fix common problems in multiplayer games where game state becomes inconsistent between players. **Desync detection:** Add checksum verification - periodically compare game state hashes between clients, flag when they diverge. **Common causes:** Race conditions (events processed in different order), floating point precision differences, missing or dropped messages, client-side prediction errors. **Debug logging:** Log all incoming and outgoing network messages with timestamps: `add [join [SENT:] (message) [:] (timer)] to [NetworkLog]`. **Playback comparison:** Record game state at intervals, compare between clients to find divergence point. **Resolution strategies:** Authoritative server model (host's state wins), periodic state sync (full state broadcast every N seconds), rollback netcode (rewind and replay on conflict). **Test:** Intentionally cause desync, verify detection and recovery. Uses mp_broadcastmessagetoall for sync, list operations for logging. _CSTA: 2-AP-17._

Dependencies:
* T13.G8.19: Design multiplayer game architecture
* T13.G8.18: Implement real-time multiplayer combat


ID: T13.G8.26
Topic: T13 – 2D Games
Skill: Handle player disconnection and reconnection gracefully
Description: Implement robust handling for players leaving and rejoining multiplayer games. **Disconnect detection:** Monitor heartbeat messages - if no message received from player in 5 seconds, mark as potentially disconnected. **Pause vs. continue:** Design decision - pause game when player disconnects (turn-based games) vs. continue with AI takeover (action games). **AI replacement:** When player disconnects, switch their sprite to AI control using basic patrol/chase behaviors until they return. **Reconnection flow:** When player rejoins, verify identity, send current game state snapshot, resume player control. **Host migration:** If room creator disconnects, transfer host privileges to another player: `if <(host ID) = (disconnected player)> then [assign new host]`. **Graceful degradation:** Game remains playable with fewer players, adjust difficulty accordingly. **Test:** Disconnect during active gameplay, reconnect, verify smooth recovery. Uses mp_onplayerleave event, game state serialization. _CSTA: 2-AP-16._

Dependencies:
* T13.G8.25: Debug multiplayer synchronization issues
* T13.G8.04: Create save system with state serialization


ID: T13.G8.27
Topic: T13 – 2D Games
Skill: Implement accessible game design with multiple input modes
Description: Create games that are accessible to players with different abilities by supporting multiple input methods simultaneously. **Input abstraction:** Create `ProcessInput` custom block that reads from all input sources and outputs unified direction/action values. **Supported inputs:** Keyboard (arrow keys, WASD), mouse/touch, virtual joystick, voice commands, hand gestures, body pose. **Input mapping UI:** Let players customize which physical input maps to which game action. **Accessibility options:** Adjustable timing (auto-hold, extended timers), visual alternatives for audio cues, audio descriptions for visual elements, colorblind-friendly palette options. **One-switch gaming:** Support for players who can only use one button - implement scanning selection or switch-activated menus. **Testing protocol:** Test game with keyboard only, mouse only, voice only, and gesture only to verify full playability. **Documentation:** Include accessibility features in game help. Uses custom blocks for input abstraction, widget blocks for options UI. _CSTA: 2-AP-16._

Dependencies:
* T13.G7.25: Combine voice commands with gesture controls
* T13.G8.01: Design modular game architecture


ID: T13.G8.28
Topic: T13 – 2D Games
Skill: Build a complete polished game with all core systems
Description: Create a fully featured, polished 2D game that integrates multiple advanced systems into a cohesive experience. **Required systems (minimum 5):** Movement/controls, collision/physics, scoring/progression, save/load, UI/menus. **Optional advanced systems (minimum 2):** Multiplayer, AI-generated content, gesture controls, voice commands, analytics, procedural generation. **Polish requirements:** Smooth animations with state machine, consistent visual style, sound effects for all actions, music that fits theme, clear feedback for all player actions, tutorial/help system. **Quality checklist:** No game-breaking bugs, consistent frame rate, all features documented, tested on multiple devices/browsers. **Playtesting:** Conduct at least 3 playtests with different users, document feedback and iterations. **Portfolio-ready:** Game should be shareable, with title screen, credits, and restart functionality. This capstone project demonstrates mastery of Grade 8 game development skills. _CSTA: 2-AP-16._

Dependencies:
* T13.G8.21: Design and document a complete game design document
* T13.G8.17: Implement complete tutorial system
* T13.G8.27: Implement accessible game design with multiple input modes



# T14 - Stories & Animation (Phase 10 Major Redesign - November 2025)
# PHILOSOPHY: Stories & Animation is about COMPUTATIONAL STORYTELLING
# - Narrative is algorithmic: sequences, conditionals, loops, state machines
# - Animation embodies physics & math: timing, easing, interpolation
# - Interactive stories are PROGRAMS that respond to user input
# - AI transforms storytelling from solo craft to human-AI collaboration
#
# PHASE 10 BOLD REDESIGN - MAJOR STRUCTURAL CHANGES:
#
# 1. NEW THREAD: "Narrative as Algorithm" (K-8)
#    - Stories ARE algorithms: sequence (beginning→middle→end), branching (choices),
#      loops (recurring themes), state (character development)
#    - GK.01.01: Identify the "algorithm" in a story (first-then-finally)
#    - G2.08: Recognize branching narratives as decision trees
#    - G5.22: Map story structure to programming constructs
#
# 2. NEW THREAD: "Animation Principles" (G3-G7)
#    - Classic animation principles adapted for coding
#    - G3.14: Apply anticipation (prepare-action-reaction pattern)
#    - G4.13: Use easing for natural motion (slow-in, slow-out)
#    - G5.23: Create follow-through and overlapping action
#    - G6.14: Design squash and stretch for character weight
#    - G7.12: Combine principles for professional-quality animation
#
# 3. ENHANCED DEBUGGING/TESTING PROGRESSION (coherent thread)
#    - G3.13: Debug speech timing (trace duration values)
#    - G4.11: Debug multi-sprite timing (use timer to verify)
#    - G4.12: Test story paths systematically (test plan)
#    - G5.18: Trace animation state with console logging
#    - G5.19: Create scene transition checklist (QA process)
#    - G6.15: Debug AI response handling (error scenarios)
#    - G7.13: Profile and optimize animation performance
#    - G8.14: Implement automated story testing
#
# 4. NEW THREAD: "Story Systems Architecture" (G6-G8)
#    - Building reusable narrative engines, not one-off stories
#    - G6.16: Design a dialog system with speaker management
#    - G7.14: Build a quest/objective tracking system
#    - G8.15: Create a save/load game state system
#    - G8.16: Design modular scene templates
#
# 5. EXPANDED AI STORYTELLING (human-AI collaboration focus)
#    - G5.24: Use AI to generate story ideas (brainstorming partner)
#    - G6.12: Chain AI prompts for narrative generation
#    - G6.17: Evaluate AI-generated content for quality/appropriateness
#    - G7.09: Implement conversation memory for AI characters
#    - G7.10: Balance AI-generated and hand-written content
#    - G7.15: Use AI for localization/translation assistance
#    - G8.11: Optimize AI-heavy story performance
#    - G8.17: Design ethical AI character interactions
#
# 6. NEW: PROJECT SCOPE & PLANNING SKILLS
#    - G4.14: Scope a story project (what's achievable)
#    - G5.25: Create a story design document
#    - G6.13: Conduct playtesting with feedback collection
#    - G7.11: Use version control for story iterations
#    - G8.13: Create portfolio-ready documentation
#
# 7. COMPUTATIONAL THINKING EMPHASIS IN K-2
#    - Every K-2 skill explicitly connects to CT concepts
#    - Pattern recognition, decomposition, abstraction, algorithms
#    - Visual activities that build mental models for coding
#
# 8. ACCESSIBILITY INTEGRATED THROUGHOUT (not bolted on)
#    - G3.04.01: Text readability from the start
#    - G5.20-21: Core accessibility skills
#    - G8.02: Full accessibility implementation
#
# Total: 155 skills across K-8 (expanded from 137 for depth and breadth)
# K:10, G1:10, G2:10, G3:28, G4:17, G5:28, G6:18, G7:16, G8:18

ID: T14.GK.01
Topic: T14 – Stories & Animation
Skill: Sequence three story picture cards (beginning, middle, end)
Description: **Student task:** Drag 3 picture cards showing story events into the correct order from beginning to end. **Visual scenario:** Picture cards show: (A) a bunny waking up in bed with sun in window, (B) the bunny eating carrots at a table, (C) the bunny hopping outside to play with friends. **Correct order:** A → B → C (wake up, eat, play). **Computational thinking connection:** Stories follow a sequence algorithm - FIRST something happens, THEN another thing, FINALLY the story ends. Just like instructions for a computer must be in order! _Implementation note: Drag-drop sequence with large, colorful picture cards; audio narration reads each card aloud when tapped ("Bunny wakes up", "Bunny eats breakfast", "Bunny plays outside"). Auto-graded by final sequence position. CSTA: EK-IC-SI-01._

Dependencies:
* T01.GK.01: Sequence three picture cards for a bedtime routine


ID: T14.GK.01.01
Topic: T14 – Stories & Animation
Skill: Identify the story "algorithm" - FIRST, THEN, FINALLY
Description: **Student task:** Listen to a story and tap cards in order when you hear "FIRST," "THEN," and "FINALLY." **Visual scenario:** Audio narrates: "FIRST, the caterpillar was hungry. THEN, it ate lots of leaves. FINALLY, it became a beautiful butterfly!" Cards show: hungry caterpillar, caterpillar eating, butterfly. Student taps cards as story words are spoken. **Computational thinking connection:** Every story is an algorithm! FIRST is like the computer starting. THEN is the middle steps. FINALLY is when the program finishes. Audio reinforces: "Stories and computer programs both follow steps in order!" _Implementation note: Sequenced tapping activity with clear audio cues for FIRST/THEN/FINALLY. 3-4 different mini-stories for practice. Builds mental model that narrative = sequence = algorithm._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)







ID: T14.GK.02
Topic: T14 – Stories & Animation
Skill: Match character emotion to facial expression
Description: **Student task:** Look at a picture of a character's face. Tap the emotion word that matches how the character feels. **Visual scenario:** Picture shows a cartoon cat with wide eyes, an open mouth smile, and raised eyebrows. Answer choices: (A) Happy, (B) Sad, (C) Surprised. **Correct answer:** Happy (smile and raised eyebrows). _Implementation note: Picture-based MCQ with 3 emotion word choices. Audio reads emotion words aloud when tapped. Character faces show clear, exaggerated expressions (big smiles, teardrops, wide eyes). CSTA: EK-IC-SI-01._






ID: T14.GK.03
Topic: T14 – Stories & Animation
Skill: Identify which character is speaking from speech bubble
Description: **Student task:** Look at a picture with two characters and one speech bubble. Tap the character who is talking based on where the speech bubble points. **Visual scenario:** Picture shows a blue dog and an orange cat standing side by side. A speech bubble with "Woof! Woof!" has a tail pointing toward the dog. Question: "Who is talking?" **Correct answer:** Tap the dog (speech bubble points to dog, and dogs say "Woof"). _Implementation note: Picture-based click selection with clear speech bubble tail pointing to speaker. Audio reads speech bubble text aloud. Include obvious content clues (meow=cat, woof=dog, ribbit=frog). CSTA: EK-IC-SI-01._




ID: T14.GK.04
Topic: T14 – Stories & Animation
Skill: Identify cause-effect in a story sequence
Description: **Student task:** Look at 2 picture cards showing a cause and effect. Tap the picture that shows WHAT HAPPENED (effect). **Visual scenario:** Card A shows a child kicking a ball. Card B shows the ball flying through the air. Question: "Which picture shows what happened AFTER the kick?" **Correct answer:** Card B (the ball flying is the effect of the kick). _Implementation note: Two-card cause-effect matching. Audio describes both cards. Use clear physical cause-effect: blow candle → flame goes out; push domino → domino falls; open umbrella → stay dry in rain. Focus on immediate, visible consequences. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)




ID: T14.GK.05
Topic: T14 – Stories & Animation
Skill: Match sound to story moment
Description: **Student task:** Look at a story picture and listen to 3 different sounds. Tap the sound that matches what is happening in the picture. **Visual scenario:** Picture shows a cartoon thunderstorm with rain, dark clouds, and lightning. Sound choices: (A) Birds chirping, (B) Thunder rumbling and rain, (C) Children laughing. **Correct answer:** (B) Thunder and rain (matches the storm picture). _Implementation note: Picture-to-audio matching MCQ. Play each sound when tapped before selection. Use distinctive, recognizable sounds: animals, weather, actions (splashing, crunching, knocking). Builds audio storytelling awareness. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)




ID: T14.GK.06
Topic: T14 – Stories & Animation
Skill: Identify animation timing - fast vs slow movement
Description: **Student task:** Watch two side-by-side animations of the same character moving across the screen. Tap which character moves FASTER. **Visual scenario:** Animation A shows a bunny hopping from left to right in 1 second (fast - bunny appears in each position briefly). Animation B shows the same bunny hopping the same distance but taking 5 seconds (slow - bunny pauses longer at each position). Both animations play simultaneously and loop. Question: "Which bunny is moving FASTER?" Answer choices: (A) Fast Bunny, (B) Slow Bunny. **Correct answer:** (A) Fast Bunny (completes journey in less time). _Implementation note: Video comparison with tap-to-select; audio explains "Fast means moving in less time. Slow means taking more time." Show 3-4 comparison scenarios with different speeds. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)




ID: T14.GK.07
Topic: T14 – Stories & Animation
Skill: Match character expression to emotion story
Description: **Student task:** Listen to a short story about how a character feels. Then tap the face that shows that feeling. **Visual scenario:** Audio plays: "The puppy lost its favorite toy and looked everywhere but couldn't find it. The puppy feels very SAD." Three answer choices show the same puppy with different expressions: (A) Puppy with tears and frown, droopy ears, (B) Puppy with big wide smile and wagging tail, (C) Puppy with surprised wide eyes and raised eyebrows. **Correct answer:** (A) Sad puppy (tears and frown match the story). _Implementation note: Picture-based MCQ with 4 scenarios covering happy, sad, scared, and excited. Audio narrates each emotion story clearly. Faces show exaggerated expressions for clarity. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.02: Match character emotion to facial expression




ID: T14.GK.08
Topic: T14 – Stories & Animation
Skill: Sequence sounds to match story events
Description: **Student task:** Look at a 3-picture story strip. Drag 3 sound effect cards to match the order of the story events. **Visual scenario:** Story pictures show: (1) Ice cream truck arrives at park with children looking, (2) Child runs toward the truck waving money, (3) Child happily eating an ice cream cone. Sound cards to arrange: (A) Ice cream truck jingle music, (B) Running footstep sounds, (C) Happy "Yum yum!" eating sounds. **Correct order:** A → B → C (jingle when truck arrives, footsteps when running, eating sounds when eating). _Implementation note: Drag-drop sound sequencing. Each sound card plays its audio when tapped before placement. Validates sequence order. 3 different story scenarios provided. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.05: Match sound to story moment
* T01.GK.02: Sequence four picture cards for a classroom arrival routine


ID: T14.GK.09
Topic: T14 – Stories & Animation
Skill: Identify what changes and what stays the same in animation
Description: **Student task:** Watch a short animation loop and identify what CHANGES and what STAYS THE SAME. **Visual scenario:** Animation shows a dog wagging its tail while sitting. The dog's body stays still, but its tail moves back and forth. Question 1: "What part of the dog is CHANGING?" (Answer: tail moving). Question 2: "What part of the dog STAYS THE SAME?" (Answer: body stays still). **Computational thinking connection:** In animations and programs, some things change (variables) and some things don't (constants). Recognizing what changes is the first step to understanding state! _Implementation note: 3 different animation loops with changing/constant elements. Tap-to-select for changing parts, then for constant parts. Audio reinforces CT vocabulary. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.06: Identify animation timing - fast vs slow movement
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)


ID: T14.GK.10
Topic: T14 – Stories & Animation
Skill: Decompose a story into characters, setting, and events
Description: **Student task:** Look at a simple story picture and sort elements into three categories: WHO (characters), WHERE (setting), and WHAT HAPPENS (events). **Visual scenario:** Picture shows a knight fighting a dragon in front of a castle. Drag elements to correct categories: Knight and Dragon → WHO, Castle and mountains → WHERE, "Knight raises sword" and "Dragon breathes fire" → WHAT HAPPENS. **Computational thinking connection:** Breaking a big story into smaller parts is called DECOMPOSITION. Programmers break big problems into small pieces too! Audio says: "To understand a story, break it apart: Who is in it? Where does it happen? What happens?" _Implementation note: Drag-and-sort activity with 3 category buckets. 2-3 different story scenarios. Reinforces decomposition as CT skill._

Dependencies:
* T14.GK.01.01: Identify the story "algorithm" - FIRST, THEN, FINALLY
* T14.GK.02: Match character emotion to facial expression


ID: T14.G1.01
Topic: T14 – Stories & Animation
Skill: Match story setting to background picture
Description: **Student task:** Listen to a short story sentence. Tap the picture that shows WHERE the story happens (the setting). **Visual scenario:** Audio plays: "The little fish swims through seaweed to find treasure." Picture choices show: (A) Ocean scene with blue water, fish, coral, and seaweed, (B) Space scene with stars, planets, and rockets, (C) Forest scene with trees and mushrooms. **Correct answer:** (A) Ocean (fish and seaweed match ocean setting). _Implementation note: Picture-based MCQ with 2-3 background setting choices. Audio narrates the story sentence. Backgrounds are colorful, distinctive scenes. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)





ID: T14.G1.02
Topic: T14 – Stories & Animation
Skill: Arrange dialogue speech bubbles in conversation order
Description: **Student task:** Look at a comic strip with 3 speech bubbles that are out of order. Drag the speech bubbles to arrange the conversation in the correct order. **Visual scenario:** Two friends (a bear and a rabbit) are shown. Speech bubbles to arrange: (A) "Goodbye! See you tomorrow!", (B) "Hello! How are you?", (C) "I'm great! Want to play?" **Correct order:** B → C → A (greet, respond, say goodbye). _Implementation note: Drag-drop speech bubble ordering with visual comic strip context. Audio reads each bubble text when tapped. Conversations follow logical greeting → response → farewell patterns. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.03: Identify which character is speaking from speech bubble
* T01.GK.02: Sequence four picture cards for a classroom arrival routine





ID: T14.G1.03
Topic: T14 – Stories & Animation
Skill: Predict the next animation frame in a sequence
Description: **Student task:** Look at 2 picture cards showing an action in progress. Tap the picture that shows what happens NEXT in the animation. **Visual scenario:** Frame 1: A red ball is high in the sky. Frame 2: The ball is falling downward (lower position). Question: "What comes next?" Answer choices: (A) Ball bouncing on ground, (B) Ball flying up higher, (C) Ball disappeared. **Correct answer:** (A) Ball bouncing on ground (gravity pulls ball down to ground). _Implementation note: Picture sequence prediction MCQ with 3 choices. Audio describes each option. Focus on simple physics and cause-effect (falling objects land, running characters move forward). CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)
* T01.GK.06: Predict the next picture card in a sequence




ID: T14.G1.04
Topic: T14 – Stories & Animation
Skill: Identify character goal in a picture story
Description: **Student task:** Look at a 3-panel picture story and identify what the main character is TRYING to do (their goal). **Visual scenario:** Panel 1: A squirrel looks up at an acorn high in a tree. Panel 2: The squirrel climbs up the tree trunk. Panel 3: The squirrel reaches for the acorn. Question: "What does the squirrel want to do?" Answer choices: (A) Get the acorn, (B) Take a nap, (C) Find a friend. **Correct answer:** (A) Get the acorn. _Implementation note: 3-panel story with MCQ about character motivation. Characters should clearly show desire through body language (reaching, looking, pointing). Audio narrates each panel. Understanding character goals is foundational to story comprehension. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.01: Sequence three story picture cards (beginning, middle, end)
* T14.GK.04: Identify cause-effect in a story sequence




ID: T14.G1.05
Topic: T14 – Stories & Animation
Skill: Sequence story with cause-effect relationships
Description: **Student task:** Drag 4 picture cards into order so each card causes the next to happen. **Visual scenario:** Cards show: (A) Ice cream cone falls from child's hand, (B) Ice cream lands on the ground, (C) Dog licks the ice cream, (D) Child looks sad. **Correct order:** A → B → C → D (ice cream falls, lands, dog eats it, child is sad). _Implementation note: Drag-drop sequence where each event causes the next. Audio explains cause-effect: "First THIS happened, so THEN that happened." Use clear domino-effect scenarios. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.04: Identify cause-effect in a story sequence
* T01.GK.02: Sequence four picture cards for a classroom arrival routine




ID: T14.G1.06
Topic: T14 – Stories & Animation
Skill: Identify who is watching the story (point of view)
Description: **Student task:** Look at a 3-panel comic strip and identify whose eyes we're seeing through. **Visual scenario:** Panel 1 shows a forest from bird's-eye view with a tiny mouse far below. Panel 2 shows ground-level view with giant trees towering above and huge blades of grass. Panel 3 shows mouse-level view with grass blades appearing as tall as buildings. Question: "In Panel 2, whose eyes are we looking through?" Answer choices: (A) A bird flying high above, (B) A tall person standing up, (C) The tiny mouse looking up. **Correct answer:** (C) The tiny mouse (ground-level view with giant surroundings indicates small creature's perspective). _Implementation note: 3 scenarios exploring different perspectives (bird view, ground view, close-up view). MCQ with visual emphasis on scale/angle differences. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.04: Identify character goal in a picture story




ID: T14.G1.07
Topic: T14 – Stories & Animation
Skill: Identify choice moments in interactive story pictures
Description: **Student task:** Look at a story picture and tap where the character has to CHOOSE what to do next. **Visual scenario:** Picture shows a brave knight standing at a fork in the road. The left path leads into a dark, spooky forest with glowing eyes. The right path leads to a sunny meadow with flowers and butterflies. Student taps the fork/choice point where paths split. Then answers: "What are the two choices the knight can make?" with options: (A) Go to forest OR go to meadow, (B) Walk fast OR walk slow, (C) Day OR night. **Correct answer:** (A) Forest or meadow (location choices at the fork). _Implementation note: 4 story scenarios with clear decision points marked by visual branching. Builds interactive narrative awareness. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.04: Identify character goal in a picture story




ID: T14.G1.08
Topic: T14 – Stories & Animation
Skill: Match background music emotion to story mood
Description: **Student task:** Listen to 3 different background music clips and match each to a story mood card showing the matching feeling. **Visual scenario:** Music clips: (A) Fast drums with quick exciting tempo, (B) Slow piano with sad minor notes, (C) Cheerful xylophone with happy bells. Story mood cards show: Running race scene (exciting), Rainy goodbye scene (sad), Birthday party scene (happy). Drag each music icon to its matching mood card. **Correct matches:** Fast drums → Running race, Slow piano → Rainy goodbye, Cheerful xylophone → Birthday party. _Implementation note: Audio-visual matching with 3 music clips and 3 mood cards. Each music plays when tapped. Introduces background music's narrative role. CSTA: EK-IC-SI-01._

Dependencies:
* T14.GK.05: Match sound to story moment
* T14.G1.01: Match story setting to background picture


ID: T14.G1.09
Topic: T14 – Stories & Animation
Skill: Identify the PATTERN in a repeating story element
Description: **Student task:** Watch a short animated story and identify which part REPEATS in a pattern. **Visual scenario:** Animation shows: Bunny hops once → carrots appear → bunny eats → happy face. Then: Bunny hops again → carrots appear again → bunny eats again → happy face. Then: Bunny hops again → carrots appear again → ??? Question: "What happens next in the pattern?" Answer choices: (A) Bunny eats and smiles, (B) Bunny goes to sleep, (C) It starts raining. **Correct answer:** (A) Bunny eats and smiles (completing the repeating pattern). **Computational thinking connection:** Stories have PATTERNS that repeat, just like loops in programming! When something happens the same way again and again, that's a pattern. Audio: "This story has a pattern - it keeps happening the same way. Can you see the pattern?" _Implementation note: 3 animated scenarios with clear repeating patterns. Pattern recognition is fundamental to computational thinking._

Dependencies:
* T14.GK.01.01: Identify the story "algorithm" - FIRST, THEN, FINALLY
* T14.G1.05: Sequence story with cause-effect relationships


ID: T14.G1.10
Topic: T14 – Stories & Animation
Skill: Compare how two characters are DIFFERENT and SIMILAR
Description: **Student task:** Look at two characters side by side. Drag traits to show what is SAME about them and what is DIFFERENT. **Visual scenario:** Character A: blue robot with wheels, happy face, holding wrench. Character B: blue robot with legs, happy face, holding paintbrush. Traits to sort: "Blue color" → SAME, "Happy face" → SAME, "Wheels vs Legs" → DIFFERENT, "Tools (wrench vs paintbrush)" → DIFFERENT. **Computational thinking connection:** This is called ABSTRACTION! When we find what things have in common, we can create a general idea (like "robot"). When we find differences, we see what makes each one special. Audio: "Both are happy blue robots - that's what they have in common. But they move differently and have different tools - that's what makes them unique!" _Implementation note: 3 character pair comparisons with drag-to-sort interface. Builds abstraction skills essential for programming._

Dependencies:
* T14.GK.10: Decompose a story into characters, setting, and events
* T14.G1.04: Identify character goal in a picture story


ID: T14.G2.01
Topic: T14 – Stories & Animation
Skill: Compare animation speed by analyzing frame spacing
Description: **Student task:** Look at two frame strips showing a character moving across the screen. Each strip shows 4 frames. Tap the strip where the character moves FASTER. **Visual scenario:** Strip A shows a running fox with small position changes between frames (fox moves a tiny bit each frame = slow). Strip B shows the same fox with large position jumps between frames (fox moves a lot each frame = fast). Both strips have the same 4 frames, but positions differ. **Correct answer:** Strip B (bigger jumps between frames = faster movement). _Implementation note: Side-by-side frame strip comparison. Audio explains "When pictures are far apart, the character moves fast. When pictures are close together, the character moves slow." CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.03: Predict the next animation frame in a sequence
* T01.G1.07: Compare two algorithms to check if they achieve the same result





ID: T14.G2.02
Topic: T14 – Stories & Animation
Skill: Identify where the scene changes in a story strip
Description: **Student task:** Look at a strip of 4 story pictures. Tap the picture where the LOCATION changes to somewhere completely new (scene transition). **Visual scenario:** Story strip shows: (1) Child waking up in bedroom with bed and window, (2) Child eating cereal in kitchen with table and fridge, (3) Child walking up steps to school building entrance, (4) Child sitting at desk in classroom. Question: "Where does the scene change from HOME to SCHOOL?" **Correct answer:** Tap picture 3 (school entrance is the first picture showing a new location outside the home). _Implementation note: 4-panel picture strip with click selection. Audio describes each scene location. Look for background changes indicating new locations. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.01: Match story setting to background picture
* T01.G1.04: Predict the next panel in a story sequence





ID: T14.G2.03
Topic: T14 – Stories & Animation
Skill: Identify the repeating pattern in an animation loop
Description: **Student task:** Look at a strip of 6 animation frames showing a repeated pattern. Tap the frames that show ONE complete cycle of the repeating pattern. **Visual scenario:** Frame strip shows a walking bird: (1) Left foot forward, (2) Right foot forward, (3) Left foot forward, (4) Right foot forward, (5) Left foot forward, (6) Right foot forward. Question: "Which frames repeat over and over?" Answer choices: (A) Frames 1-2 (Left, Right), (B) Frames 1-3 (Left, Right, Left), (C) Just frame 1 (Left only). **Correct answer:** (A) Frames 1-2 (the pattern "Left foot, Right foot" repeats 3 times). _Implementation note: Frame strip or looping animation with pattern recognition. Audio explains "A loop is a pattern that repeats." Show 2-frame and 3-frame repeating patterns. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G2.01: Compare animation speed by analyzing frame spacing
* T01.GK.07: Identify the repeating pattern in an animation




ID: T14.G2.04
Topic: T14 – Stories & Animation
Skill: Predict story ending from visual clues
Description: **Student task:** Look at 3 story picture cards showing the beginning and middle. Predict what happens at the END by choosing from 3 possible ending pictures. **Visual scenario:** Card 1: A girl plants a seed in soil. Card 2: The girl waters the seed, and a small sprout appears. Card 3 (choose ending): (A) A tall flower blooms, (B) The pot is empty, (C) Snow covers the pot. **Correct answer:** (A) A tall flower blooms (logical growth progression from sprout). _Implementation note: 3-card story with ending prediction MCQ. Use visual clues in middle cards to foreshadow endings. Endings should follow cause-effect logic. Audio narrates each card. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.04: Identify character goal in a picture story
* T14.G1.05: Sequence story with cause-effect relationships




ID: T14.G2.05
Topic: T14 – Stories & Animation
Skill: Compare two story paths in a branching picture narrative
Description: **Student task:** Look at a story that splits into two different paths. Identify how the two endings are DIFFERENT based on the choice made. **Visual scenario:** Start: Knight approaches a fork in the road. Path A: Knight goes left → finds friendly dragon → they become friends (happy ending). Path B: Knight goes right → finds treasure chest → takes treasure home (different happy ending). Question: "What is different about the two endings?" Answer choices describe the different outcomes. _Implementation note: Branching story visualization with two parallel paths. Audio explains "Different choices lead to different endings." Foundation for understanding interactive narratives. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G2.04: Predict story ending from visual clues
* T14.G2.02: Identify where the scene changes in a story strip




ID: T14.G2.06
Topic: T14 – Stories & Animation
Skill: Plan a simple 3-scene story using picture storyboard
Description: **Student task:** Drag 6 picture cards to fill in a 3-scene storyboard template (Beginning-Middle-End). Each scene has 2 slots: one for setting, one for action. **Visual scenario:** Template shows 3 empty scenes labeled "Beginning," "Middle," "End." Available cards include settings (forest, castle, ocean) and actions (hero finds key, hero opens door, hero meets friend). Example valid story: Scene 1 (Beginning): forest + finds key, Scene 2 (Middle): castle + opens door, Scene 3 (End): castle + meets friend. Student drags one setting and one action card to each scene slot. **Correct answer:** Any coherent 3-scene story with matching setting-action pairs that tell a logical sequence. _Implementation note: Storyboard template with drag-drop zones. Auto-validation checks coherence (e.g., can't open door before finding key). Audio prompts "What happens first? What happens next? How does it end?" CSTA: EK-IC-SI-01._

Dependencies:
* T14.G1.05: Sequence story with cause-effect relationships
* T14.G2.04: Predict story ending from visual clues




ID: T14.G2.07
Topic: T14 – Stories & Animation
Skill: Identify what makes a story interesting vs boring
Description: **Student task:** Compare two picture story sequences and identify which is more interesting and WHY. **Visual scenario:** Story A (boring): 3 panels all showing a character sitting still, doing nothing different in each panel. Story B (interesting): Panel 1 shows character seeing a mysterious glowing box, Panel 2 shows character opening box with surprised face, Panel 3 shows magical creature jumping out with sparkles. Question 1: "Which story is more interesting?" Question 2: "Why is it more interesting?" Answer choices for why: (A) Things change and something surprising happens, (B) It has more colors, (C) It has a box. **Correct answers:** Story B is more interesting; reason (A) - change and surprise make stories engaging. _Implementation note: 3 comparison pairs teaching story elements (conflict, change, surprise, emotion). MCQ with reason selection to build meta-awareness of narrative quality. CSTA: EK-IC-SI-01._

Dependencies:
* T14.G2.04: Predict story ending from visual clues
* T14.G1.04: Identify character goal in a picture story


ID: T14.G2.08
Topic: T14 – Stories & Animation
Skill: Recognize branching narratives as decision trees
Description: **Student task:** Look at a story map showing a decision point and two possible paths. Trace each path and identify where they lead. **Visual scenario:** Story tree diagram shows: START → "Find a door" → CHOICE: "Open it?" → YES path → "Meet a friendly wizard" → END A. NO path → "Walk away" → "Find a treasure chest" → END B. Questions: "If you choose YES, who do you meet?" (wizard). "If you choose NO, what do you find?" (treasure). **Computational thinking connection:** This is called a DECISION TREE. It's like a flow chart! In coding, we use IF-THEN to make decisions. Audio: "When a story has choices, we can draw a picture that looks like a tree with branches. Each branch is a different path!" _Implementation note: Visual tree diagram with clear branching paths. 2-3 scenarios with different decision points. Foundation for conditional logic in programming._

Dependencies:
* T14.G2.05: Compare two story paths in a branching picture narrative
* T14.G1.07: Identify choice moments in interactive story pictures


ID: T14.G2.09
Topic: T14 – Stories & Animation
Skill: Identify the PROBLEM and SOLUTION in a story
Description: **Student task:** Read a simple 4-panel picture story and identify which panel shows the PROBLEM and which shows the SOLUTION. **Visual scenario:** Panel 1: Cat sees mouse. Panel 2: Cat chases mouse, mouse is scared (PROBLEM). Panel 3: Mouse finds tiny hole in wall. Panel 4: Mouse escapes through hole, cat can't follow (SOLUTION). Questions: "Which picture shows the problem?" (Panel 2 - mouse is in danger). "Which picture shows the solution?" (Panel 4 - mouse escapes). **Computational thinking connection:** Every story has a problem to solve, just like every program solves a problem! Understanding PROBLEM → SOLUTION is the core of computational thinking. _Implementation note: 3 story scenarios with clear problem/solution identification. Drag panels to "Problem" and "Solution" labels._

Dependencies:
* T14.G2.04: Predict story ending from visual clues
* T14.G1.04: Identify character goal in a picture story


ID: T14.G2.10
Topic: T14 – Stories & Animation
Skill: Design a simple 4-panel story with problem and solution
Description: **Student task:** Arrange 6 picture cards to create a 4-panel story that has a clear problem and solution. **Visual scenario:** Available cards include: happy character, sad character, obstacle appears, character tries solution, solution works, celebration. Students select and arrange 4 cards to tell a complete story. Example valid story: Card A (happy) → Card B (obstacle appears) → Card C (tries solution) → Card D (celebration). **Computational thinking connection:** You are the ALGORITHM DESIGNER now! You're deciding what happens in what order, just like a programmer designs the steps of their code. _Implementation note: Multiple valid solutions accepted. Validation checks for logical story structure (problem must come before solution). Encourages creativity within constraints._

Dependencies:
* T14.G2.09: Identify the PROBLEM and SOLUTION in a story
* T14.G2.06: Plan a simple 3-scene story using picture storyboard


ID: T14.G3.00.01
Topic: T14 – Stories & Animation
Skill: Identify sprite visual properties and predict changes
Description: Identify that sprites have three key visual properties that can be changed with code: **size** (how big/small, measured in percent where 100% is normal), **position** (where on stage, measured in x and y coordinates), and **visibility** (shown or hidden). Predict how a sprite will look when these properties change. Example: "If size changes from 100% to 50%, the sprite appears half as big. If `hide` runs, the sprite becomes invisible." This foundational understanding prepares you to use blocks that modify these properties.

Dependencies:
* T14.G2.01: Compare animation speed by analyzing frame spacing





ID: T14.G3.00.02
Topic: T14 – Stories & Animation
Skill: Use size blocks to scale sprites larger or smaller
Description: Use `set size to (100) %` to set a sprite's size to an exact percentage (100% = original size, 50% = half size, 200% = double size). Use `change size by (10)` to increase size by 10% from current value, or `change size by (-10)` to decrease. Trace what happens: if a sprite starts at 100% and `change size by (20)` runs, the sprite becomes 120%. Use size changes to create visual emphasis (make important characters larger), show distance (smaller = farther away), or prepare for size animations.

Dependencies:
* T14.G3.00.01: Identify sprite visual properties and predict changes





ID: T14.G3.00.03
Topic: T14 – Stories & Animation
Skill: Edit sprite costumes using the paint editor tools
Description: Access the paint editor by clicking the "Costumes" tab for any sprite. Use the visual design tools to manually customize sprite appearances: **brush** for freehand drawing, **circle/oval** for round shapes, **rectangle/square** for boxes, **text** tool for adding words, **fill** for coloring areas, and **eraser** for removing parts. These manual edits become the sprite's permanent appearance and are saved with the project. The paint editor is a design tool (not coding) - you create costumes before running code. Multiple costumes on a sprite enable costume-switching animations. Later skills teach programmatic drawing with code blocks.

Dependencies:
* T14.G3.00.02: Use size blocks to scale sprites larger or smaller





ID: T14.G3.01
Topic: T14 – Stories & Animation
Skill: Position sprites instantly with go to x y blocks
Description: Use `go to x: (0) y: (0)` to instantly teleport a sprite to specific stage coordinates (no animation - instant jump). **Coordinate system:** (0, 0) is stage center, positive X moves right (up to 240), negative X moves left (down to -240), positive Y moves up (up to 180), negative Y moves down (down to -180). Trace examples: `go to x: (100) y: (50)` places sprite in upper-right area. `go to x: (-150) y: (-100)` places sprite in lower-left area. Use this block to set starting positions or instantly reposition characters during scene changes.

Dependencies:
* T14.G3.00.01: Identify sprite visual properties and predict changes
* T01.G3.01: Complete a simple script with missing blocks





ID: T14.G3.01.01
Topic: T14 – Stories & Animation
Skill: Animate smooth movement with glide blocks
Description: Use `glide (1) secs to x: (100) y: (50)` to animate a sprite smoothly moving to a target position over a specified duration. Unlike `go to x: y:` which teleports instantly, glide creates visible motion animation. **Duration controls speed:** 0.5 secs = fast/snappy, 1-2 secs = normal, 3+ secs = slow/dramatic. Trace the animation: sprite smoothly slides from current position to target over the duration. Chain multiple glides to create paths: `glide (1) secs to x: (0) y: (0)` then `glide (1) secs to x: (100) y: (0)` creates an L-shaped path. Use for character walking, flying, approaching, or any animated movement.

Dependencies:
* T14.G3.01: Position sprites instantly with go to x y blocks





ID: T14.G3.02
Topic: T14 – Stories & Animation
Skill: Create size animation using repeat loops
Description: Combine `change size by (10)` inside a `repeat` loop to create smooth grow/shrink animations. Trace this script: `repeat (10) { change size by (5) }` - the sprite grows by 5% ten times, ending 50% larger. For shrinking, use negative values: `repeat (10) { change size by (-5) }`. Add `wait (0.1) seconds` inside the loop to control animation speed: shorter waits = faster animation. Debug common issues: animation too fast (add wait blocks), sprite gets too big (reduce repeat count or size change amount), animation restarts at original size (need to reset size at start with `set size to (100) %`).

Dependencies:
* T14.G3.00.02: Use size blocks to scale sprites larger or smaller
* T07.G3.01: Use a counted repeat loop





ID: T14.G3.02.01
Topic: T14 – Stories & Animation
Skill: Create frame-by-frame animation with costume switching
Description: Use `switch costume to [costume2 v]` to change a sprite to a specific costume, or `next costume` to cycle through all costumes in order (loops back to first after last). Create frame-by-frame animations by combining costume changes with loops and waits: `repeat (8) { next costume, wait (0.1) seconds }` creates an 8-frame animation cycling at 10 fps. Design multi-costume sprites for: walking cycles (4+ leg positions), talking mouths (open/closed), blinking eyes (open/half/closed), or transformation sequences. Trace a 4-costume walk cycle: costume1 (left foot) → costume2 (center) → costume3 (right foot) → costume4 (center) → repeats.

Dependencies:
* T14.G3.00.03: Edit sprite costumes using the paint editor tools
* T07.G3.01: Use a counted repeat loop





ID: T14.G3.03
Topic: T14 – Stories & Animation
Skill: Initialize sprite properties at project start
Description: Build initialization scripts that reset sprite properties at the start of every project run using `when green flag clicked`. Include: `go to x: (startX) y: (startY)` to set starting position, `set size to (100) %` to reset size to normal, `show` to make sprite visible (in case it was hidden), `switch costume to [costume1 v]` to reset appearance. Debug problem: sprite appears in wrong spot when project restarts → add position initialization. Trace initialization order: when green flag clicked → set position → set size → show → ready for story. Initialization ensures your story starts the same way every time.

Dependencies:
* T14.G3.01: Position sprites instantly with go to x y blocks
* T14.G3.00.02: Use size blocks to scale sprites larger or smaller
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence





ID: T14.G3.04
Topic: T14 – Stories & Animation
Skill: Display character dialogue with say blocks
Description: Use `say [Hello!] for (2) seconds text size (16) [#FFFFFFFF] background [#000000FF] edge [#FFFFFFFF]` to display speech bubbles above sprites. **Parameters:** message text, duration (seconds visible), text size (16=normal, 24=large), font color (hex #RRGGBBAA), background color, edge/border color. Speech bubbles automatically disappear after duration. Trace: `say [Hi there!] for (3) seconds...` shows "Hi there!" for 3 seconds, then vanishes. Start with basic dialogue: `say [Welcome to my story!] for (2) seconds...`. The "say" block makes your sprite "talk" to tell your story.

Dependencies:
* T14.G3.03: Initialize sprite properties at project start
* T01.G3.01: Complete a simple script with missing blocks





ID: T14.G3.04.01
Topic: T14 – Stories & Animation
Skill: Style speech bubbles to convey mood and emphasis
Description: Customize speech bubble colors and sizes to express emotions. **Size for volume:** 24-32 = shouting/excitement, 12-14 = whisper/quiet. **Background colors for mood:** #FF0000FF (red) = anger/danger, #0000FFFF (blue) = calm/sad, #FFFF00FF (yellow) = happy/cheerful, #00FF00FF (green) = positive, #800080FF (purple) = magical/mysterious. **Readability rules:** use white text (#FFFFFFFF) on dark backgrounds, black text (#000000FF) on light backgrounds. Predict emotion from styling: large red bubble = angry shouting, small blue bubble = sad whisper. Design dialogue that matches character mood through visual styling.

Dependencies:
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G3.05
Topic: T14 – Stories & Animation
Skill: Display internal thoughts with think blocks
Description: Use `think [Hmm...] for (2) seconds text size (16) [#FFFFFFFF] background [#000000FF] edge [#FFFFFFFF]` to show internal monologue in cloud-shaped thought bubbles. Parameters work identically to say blocks. **Visual difference:** think bubbles have cloud shapes (thoughts), say bubbles have pointed tails (speech). Identify when to use each: `say` = words spoken aloud that others hear, `think` = private thoughts that only the audience sees. Use think for character reasoning ("I should go left..."), secret plans, reactions ("That was surprising!"), or narration. Trace a scene: character sees treasure → `think [Wow! I found it!]` (private reaction).

Dependencies:
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G3.05.01
Topic: T14 – Stories & Animation
Skill: Style think bubbles for different thought types
Description: Apply styling to think blocks to convey different types of thoughts. **Dreamy/light thoughts:** transparent background (#FFFFFF80 = white at 50% alpha), soft colors. **Worried/serious thoughts:** dark background (#333333FF), smaller text. **Happy daydreams:** pastel colors (#FFB6C1FF light pink, #87CEEBFF sky blue). **Mysterious/plotting:** purple (#4B0082FF) with white text. Predict thought type from styling: transparent floating bubble = daydream, dark bubble with small text = worried whisper. Design appropriate styling for character personality: villain uses dark bubbles, hero uses bright bubbles.

Dependencies:
* T14.G3.05: Display internal thoughts with think blocks
* T14.G3.04.01: Style speech bubbles to convey mood and emphasis





ID: T14.G3.06
Topic: T14 – Stories & Animation
Skill: Sequence multiple say blocks for monologue
Description: Stack multiple `say` blocks in sequence to create a character monologue (one character speaking multiple lines). Each say block runs after the previous one finishes. Trace this sequence: `say [Hello!] for (2) secs`, `say [My name is Alex.] for (2) secs`, `say [Nice to meet you!] for (2) secs` - the character says three lines, each appearing for 2 seconds in order. Calculate total duration: 3 blocks × 2 seconds = 6 seconds total. Debug timing: if dialogue feels rushed, increase duration; if too slow, decrease it. Use monologues for introductions, explanations, or storytelling narration.

Dependencies:
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G3.07
Topic: T14 – Stories & Animation
Skill: Use wait blocks to control timing between actions
Description: Use `wait (1) seconds` to pause script execution, creating deliberate timing gaps between actions. Trace: `glide (1) secs to x: 100 y: 0`, `wait (0.5) seconds`, `say [I made it!] for (2) secs` - sprite moves, pauses briefly, then speaks. **Timing uses:** dramatic pause before reveal, gap between character movements, delay before response. Calculate timing: `say` for 2 secs + `wait` 1 sec = 3 seconds before next action. Debug: animation feels too fast → add wait blocks; animation feels too slow → reduce wait duration. Short waits (0.2-0.5 secs) for transitions, longer waits (1-3 secs) for dramatic effect.

Dependencies:
* T14.G3.06: Sequence multiple say blocks for monologue





ID: T14.G3.08
Topic: T14 – Stories & Animation
Skill: Trigger dialogue with sprite click events
Description: Use `when this sprite clicked` event hat block to make a character speak when the player clicks on it. Build an interactive story where clicking characters triggers their dialogue: `when this sprite clicked` → `say [Hi! I'm a friendly wizard!] for (3) secs`. Trace interaction: player clicks wizard sprite → wizard's script runs → wizard says dialogue. Create clickable characters that respond with different speeches. Debug: sprite doesn't respond to clicks → check that the script has `when this sprite clicked` (not `when green flag clicked`).

Dependencies:
* T14.G3.06: Sequence multiple say blocks for monologue
* T06.G3.02: Recognize common event triggers in CreatiCode





ID: T14.G3.09
Topic: T14 – Stories & Animation
Skill: Trigger animations with key press events
Description: Use `when [space v] key pressed` event hat block to trigger animations when the player presses a specific key. Build interactive animations: `when [space v] key pressed` → `change size by (10)` makes sprite grow when space is pressed. `when [up arrow v] key pressed` → `change y by (20)` makes sprite jump up. Trace interaction: player presses space key → space key event triggers → animation script runs. Choose different keys for different actions: space for jump, arrows for movement, letters for special effects. Debug: wrong key triggers action → check the key dropdown selection.

Dependencies:
* T14.G3.08: Trigger dialogue with sprite click events
* T06.G3.02: Recognize common event triggers in CreatiCode





ID: T14.G3.10
Topic: T14 – Stories & Animation
Skill: Add sound effects and music to enhance stories
Description: Use `start sound [pop v]` to play a sound effect while the script continues immediately (non-blocking). Use `play sound [meow v] until done` when the script should wait for the sound to finish before continuing. **Sound types:** background music (loops), sound effects (footsteps, doors, magic), ambient sounds (rain, wind). Trace: `start sound [music v]` + `say [Hello!]` - music starts AND speech appears simultaneously. Compare: `play sound [fanfare v] until done` + `say [I won!]` - fanfare plays completely, THEN speech appears. Use `stop all sounds` to silence everything. Select sounds from the library or record custom audio.

Dependencies:
* T14.G3.07: Use wait blocks to control timing between actions





ID: T14.G3.11
Topic: T14 – Stories & Animation
Skill: Create label widgets for persistent on-screen text
Description: Use `add label [Story Title] at X (0) Y (150) width (200) height (50) padding (10) as [titleLabel]` to create persistent text displays. **Label vs say block:** labels stay on screen permanently until hidden/removed; say blocks disappear after duration. **Parameters:** text content, X/Y position, width/height dimensions, padding (space between text and edges), widget name (for later reference). Labels float above sprites on the widget layer. Trace: label created at (0, 150) → text appears at top center and stays visible. Use labels for: story titles, chapter numbers, score displays, permanent instructions.

Dependencies:
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G3.11.01
Topic: T14 – Stories & Animation
Skill: Position labels strategically for UI layout
Description: Plan label positions using stage coordinates (X: -240 to 240, Y: -180 to 180). **Standard positions:** top center (0, 150) for titles, top-left (-200, 150) for chapter/scene numbers, top-right (200, 150) for scores, bottom center (0, -150) for subtitles/instructions, bottom corners for status indicators. **Size guidelines:** short text (width: 150-200), long text (width: 300-400), single line (height: 30-50), multi-line (height: 60-100). Trace a title setup: `add label [Chapter 1] at X (0) Y (160) width (300) height (40)...` → centered title near top. Design a UI layout by planning where each label should appear.

Dependencies:
* T14.G3.11: Create label widgets for persistent on-screen text





ID: T14.G3.11.02
Topic: T14 – Stories & Animation
Skill: Update label text dynamically during runtime
Description: Use `set value to [New Text] for widget [titleLabel v]` to change a label's text while the project runs. Trace: label shows "Chapter 1" → `set value to [Chapter 2] for widget [titleLabel v]` runs → label now shows "Chapter 2". Combine with variables: `set value to (join [Score: ] (score)) for widget [scoreLabel v]` displays current score. Update labels in response to events: `when I receive [NextChapter]` → `set value to [Chapter 2]...`. **Use cases:** changing titles between scenes, updating score displays, showing current speaker name, displaying status messages. Labels update instantly when set value runs.

Dependencies:
* T14.G3.11.01: Position labels strategically for UI layout
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T14.G3.12
Topic: T14 – Stories & Animation
Skill: Print temporary text on the stage layer
Description: Use `print [Hello World] at x (0) y (0) width (300) height (100) color [#2CADE5FF]` to draw text directly on the stage layer. **Label vs print:** labels are widgets (above sprites, interactive), print is drawn on stage layer (below sprites, non-interactive). Printed text stays until cleared or project stops. **Parameters:** text content, X/Y position, width/height for text wrapping, color (hex #RRGGBBAA). Trace: `print [Welcome!] at x (0) y (100)...` → text appears at upper center, behind any sprites. Use for: background annotations, floating messages, temporary instructions, or decorative text elements.

Dependencies:
* T14.G3.11: Create label widgets for persistent on-screen text





ID: T14.G3.12.01
Topic: T14 – Stories & Animation
Skill: Print timed text and sprite-relative text
Description: Add duration to print blocks: `print [Ouch!] at x (0) y (50)... for (2) seconds` makes text auto-disappear after 2 seconds. Create floating text near sprites using sprite position reporters: `print [+10] at x (x position) y ((y position) + (50))... for (1) seconds` displays "+10" above the sprite for 1 second. Trace: sprite at (100, 0) → print uses (x position)=100 and (y position)+50=50 → text appears at (100, 50). **Note:** printed text stays at its original position even if sprite moves afterward (not attached to sprite). Use for: damage numbers, power-up notifications, temporary status indicators, floating rewards.

Dependencies:
* T14.G3.12: Print temporary text on the stage layer





ID: T14.G3.12.02
Topic: T14 – Stories & Animation
Skill: Clear printed text when scenes change
Description: Use `clear all my prints` to remove all text printed by the current sprite. Trace: sprite has printed 3 messages → `clear all my prints` → all 3 messages disappear. **Scope:** each sprite clears only its own prints. **Scene change pattern:** `when I receive [NewScene]` → `clear all my prints` → print new scene text. Debug: text from previous scene still visible → ensure `clear all my prints` runs at scene start. **Important:** hiding a sprite does NOT clear its prints - you must explicitly clear. For multi-sprite projects, have each sprite clear its own prints, or use broadcasts to coordinate clearing.

Dependencies:
* T14.G3.12.01: Print timed text and sprite-relative text




ID: T14.G3.13
Topic: T14 – Stories & Animation
Skill: Debug timing when speech bubbles disappear too fast
Description: Identify and fix the common bug where say blocks don't display long enough for reading. **Debug technique:** Trace this example bug: `say [Welcome to my super amazing adventure story!] for (1) seconds` - text is 7 words but only shows 1 second (too fast!). **Calculation approach:** count words in message (7 words), calculate reading time (7 words ÷ 3 words/second = ~2.3 seconds), round up for safety = 3 seconds. **Fix:** change duration from 1 to 3 seconds. **Rule of thumb:** 0.5 seconds per word for comfortable reading, minimum 1 second for any message. **Testing:** read dialogue aloud while timer runs - if you can't finish reading before bubble disappears, it's too short. **Common mistake:** using same duration for all messages regardless of length. **Debug pattern:** message appears then disappears before you can read it → increase duration based on word count. This is the #1 beginner timing bug in story projects.

Dependencies:
* T14.G3.06: Sequence multiple say blocks for monologue
* T14.G3.07: Use wait blocks to control timing between actions


ID: T14.G3.14
Topic: T14 – Stories & Animation
Skill: Apply anticipation principle - prepare-action-reaction pattern
Description: Create more engaging animations using the ANTICIPATION principle from classic animation: actions feel more natural when preceded by a preparation move. **Pattern:** PREPARE → ACTION → REACTION. **Example - jumping:** instead of just moving up, first crouch down (prepare), then jump up (action), then land and settle (reaction). **Implementation:** `change y by (-20)` (crouch), `wait (0.2)`, `glide (0.3) secs to y: (100)` (jump up), `glide (0.2) secs to y: (0)` (land), `change y by (-10)`, `change y by (10)` (settle). **Example - throwing:** arm pulls back (prepare), arm swings forward (action), follow through (reaction). **Why it works:** anticipation signals what's about to happen, making animation feel less robotic and more alive. **Practice:** take any movement animation and add a small opposite movement before it.

Dependencies:
* T14.G3.01.01: Animate smooth movement with glide blocks
* T14.G3.02: Create size animation using repeat loops


ID: T14.G4.01
Topic: T14 – Stories & Animation
Skill: Combine size animation with hide/show for visual effects
Description: Build complex visual effects by combining size animation with visibility controls. **Appear effect:** `set size to (0) %`, `show`, `repeat (10) { change size by (10) }` - sprite starts invisible-sized, appears, grows to full size. **Disappear effect:** `repeat (10) { change size by (-10) }`, `hide` - sprite shrinks to nothing, then hides. **Pulse effect:** `repeat (3) { repeat (5) { change size by (5) }, repeat (5) { change size by (-5) } }` - sprite grows and shrinks 3 times. Debug: effect happens too fast → add `wait (0.05) seconds` inside loops. Trace the size values through each loop iteration.

Dependencies:
* T14.G3.02: Create size animation using repeat loops
* T14.G3.03: Initialize sprite properties at project start





ID: T14.G4.02
Topic: T14 – Stories & Animation
Skill: Use broadcasts to coordinate scene changes across sprites
Description: Use `broadcast [Scene2]` to send a message that triggers scripts in ALL sprites that have `when I receive [Scene2]`. This is the key mechanism for scene changes in multi-sprite stories. **How it works:** one sprite broadcasts → ALL sprites with matching `when I receive` run their scripts simultaneously. Trace: SceneManager broadcasts "Scene2" → House sprite hides, Forest sprite shows, Character sprite moves to forest position. **Architecture:** each sprite handles its own response to scene broadcasts (show/hide/move/speak). Design scenes by planning what each sprite does when each scene broadcast is received.

Dependencies:
* T14.G4.01: Combine size animation with hide/show for visual effects
* T14.G2.02: Identify where the scene changes in a story strip
* T06.G3.05: Use broadcasts to coordinate multiple sprites





ID: T14.G4.02.01
Topic: T14 – Stories & Animation
Skill: Program individual sprite responses to scene broadcasts
Description: Build `when I receive [SceneName]` scripts in EACH sprite to control that sprite's behavior per scene. **Pattern for each sprite:** `when I receive [Scene1]` → show/hide, position, costume for Scene1; `when I receive [Scene2]` → show/hide, position, costume for Scene2. **Example - House sprite:** `when I receive [Scene1]` → `show`, `go to x: 0 y: -50`; `when I receive [Scene2]` → `hide`. **Example - Hero sprite:** `when I receive [Scene1]` → `show`, `go to x: -100 y: 0`; `when I receive [Scene2]` → `go to x: 50 y: 0` (moves but stays visible). Debug: sprite appears in wrong scene → check that it has `when I receive` blocks for all relevant scenes.

Dependencies:
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites





ID: T14.G4.02.02
Topic: T14 – Stories & Animation
Skill: Change stage backdrop to match scene changes
Description: Use `switch backdrop to [Forest v]` to change the stage background image. The Stage is a special sprite that can have multiple backdrops (like costumes for sprites). Add backdrops via the Stage's "Backdrops" tab. **Coordinate with scenes:** in Stage scripts, add `when I receive [Scene2]` → `switch backdrop to [Forest v]`. Trace scene change: broadcast "Scene2" → sprites respond (show/hide/move) AND Stage responds (switches backdrop) → entire visual scene changes. Use `next backdrop` to cycle through backdrops in order. Design backdrops for each story location: house interior, forest, castle, etc.

Dependencies:
* T14.G4.02.01: Program individual sprite responses to scene broadcasts





ID: T14.G4.03
Topic: T14 – Stories & Animation
Skill: Control character visibility with hide and show blocks
Description: Use `hide` to make a sprite invisible and `show` to make it visible again. **Visibility vs deletion:** `hide` keeps the sprite in the project but invisible; you can show it again. Hidden sprites still run scripts but cannot be clicked. **Scene management pattern:** characters not in current scene should be hidden. Trace: `when I receive [Scene2]` → `hide` on Village sprite; `when I receive [Scene1]` → `show` on Village sprite. **Initialization:** at green flag, show sprites that should be visible in Scene1, hide sprites that shouldn't. Debug: sprite doesn't appear → check if `show` runs at the right time.

Dependencies:
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites
* T14.G3.03: Initialize sprite properties at project start





ID: T14.G4.04
Topic: T14 – Stories & Animation
Skill: Create textbox widgets for player text input
Description: Use `add textbox at X (0) Y (-50) width (200) height (30) as [nameInput]` to create a text input field where players can type responses. **Parameters:** X/Y position, width/height dimensions, widget name for reference. Textboxes allow players to enter their name, type answers, or input story choices. Trace: widget created → player types "Alex" in the textbox → text is stored in the widget. Position textboxes where players expect input fields (near prompts or instructions). Use descriptive widget names like "nameInput" or "answerBox" to keep code readable.

Dependencies:
* T14.G4.03: Control character visibility with hide and show blocks
* T14.G3.11: Create label widgets for persistent on-screen text





ID: T14.G4.04.01
Topic: T14 – Stories & Animation
Skill: Show, hide, and remove widgets dynamically
Description: Control widget visibility: `show widget [nameInput v]` makes visible, `hide widget [nameInput v]` makes invisible (widget still exists, retains value), `remove widget [nameInput v]` permanently deletes widget. **Use cases:** hide textbox after player submits name, show choice buttons only when needed, remove widgets when changing scenes. Trace: `hide widget [nameInput v]` → textbox disappears but value still readable → `show widget [nameInput v]` → textbox reappears with same value. **Pattern:** create widgets at scene start, hide/show as needed, remove when no longer needed.

Dependencies:
* T14.G4.04: Create textbox widgets for player text input





ID: T14.G4.05
Topic: T14 – Stories & Animation
Skill: Read widget values into variables for story use
Description: Use `set [playerName v] to (value of widget [nameInput v])` to capture the player's text input into a variable. The `(value of widget [widgetName v])` reporter returns whatever text the player typed. Trace: player types "Alex" in textbox → `set [playerName v] to (value of widget [nameInput v])` → playerName variable now contains "Alex". Use the variable throughout your story: `say (join [Hello, ] (playerName))` outputs "Hello, Alex". **Timing:** read widget value AFTER player has entered their input (use button click or wait).

Dependencies:
* T14.G4.04: Create textbox widgets for player text input
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T14.G4.06
Topic: T14 – Stories & Animation
Skill: Create branching story paths with button widgets
Description: Use `add button [Go Left] at X (-100) Y (-100) width (100) height (40) as [btnLeft]` to create clickable buttons. Use `when widget [btnLeft v] clicked` event to detect clicks and `broadcast [LeftPath]` to trigger that story branch. **Pattern for choices:** create 2+ buttons for options → each button's click handler broadcasts a different message → sprites respond to broadcasts with different story content. Trace: player clicks "Go Left" button → `when widget [btnLeft v] clicked` runs → `broadcast [LeftPath]` → all sprites with `when I receive [LeftPath]` execute their left-path scripts.

Dependencies:
* T14.G4.05: Read widget values into variables for story use
* T08.G3.04: Use a simple if-then block in a script





ID: T14.G4.07
Topic: T14 – Stories & Animation
Skill: Coordinate multi-sprite dialogue with synchronized waits
Description: Create back-and-forth conversations by synchronizing wait blocks across sprites. **Pattern:** both sprites start on same event (green flag or broadcast) → Sprite A: `say [Hello!] for (2) secs` → Sprite B: `wait (2) secs`, `say [Hi there!] for (2) secs` → Sprite A: `wait (4) secs`, `say [How are you?] for (2) secs`. Trace timing: Sprite A speaks (0-2 sec), Sprite B waits then speaks (2-4 sec), Sprite A waits then speaks (4-6 sec). Calculate wait times: each sprite waits for total duration of all previous speeches. Debug: dialogue overlaps → increase wait times; gaps too long → decrease wait times.

Dependencies:
* T14.G3.07: Use wait blocks to control timing between actions
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites





ID: T14.G4.08
Topic: T14 – Stories & Animation
Skill: Run parallel actions using multiple scripts on same sprite
Description: Add multiple `when green flag clicked` scripts to the SAME sprite to run actions simultaneously. **Script 1:** handles walking animation (glide + costume changes). **Script 2:** handles dialogue (say blocks). Both scripts run in parallel when green flag is clicked. Trace: green flag → Script 1 starts glide AND Script 2 starts speech → character walks AND talks at same time. **Use cases:** character moves while speaking, background music plays while story progresses, animation loops while player makes choices. Compare to sequential: stacking blocks in one script makes them run one after another; separate scripts make them run in parallel.

Dependencies:
* T14.G4.07: Coordinate multi-sprite dialogue with synchronized waits
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence





ID: T14.G4.09
Topic: T14 – Stories & Animation
Skill: Apply graphics effects for visual atmosphere and transitions
Description: Use `set [ghost v] effect to (50)` for instant effect or `change [ghost v] effect by (10)` for gradual change. **Effects:** ghost (0-100): transparency for fade effects, ghosts, dreams; brightness (-100 to 100): dark/light for night/day moods; color: hue shift for magical transformations. **Fade-out pattern:** `repeat (10) { change [ghost v] effect by (10), wait (0.1) secs }` - sprite fades to invisible. **Fade-in pattern:** `set [ghost v] effect to (100)`, `repeat (10) { change [ghost v] effect by (-10), wait (0.1) secs }`. Use `clear graphic effects` to reset all effects to normal. Trace effect values through animation loops.

Dependencies:
* T14.G4.08: Run parallel actions using multiple scripts on same sprite
* T14.G4.01: Combine size animation with hide/show for visual effects




ID: T14.G4.10
Topic: T14 – Stories & Animation
Skill: Design character arc with beginning, middle, and end states
Description: Plan how a character changes throughout the story using three distinct states. **Beginning state:** character's initial appearance, position, and behavior (Hero starts small, shy, in corner). **Middle state:** character transformation during challenges (Hero grows larger, gains confidence, moves to center). **End state:** character's final form after resolution (Hero at full size, bold costume, center stage). **Implementation:** use costume changes, size changes, position changes to visually represent character growth. Design a character arc document: list each state's visual properties, what triggers the transition, and what it means for the story. Trace: Beginning (size 80%, costume "shy") → Challenge completed → Middle (size 100%, costume "brave") → Final victory → End (size 120%, costume "hero").

Dependencies:
* T14.G4.09: Apply graphics effects for visual atmosphere and transitions
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites








ID: T14.G4.11
Topic: T14 – Stories & Animation
Skill: Debug dialogue timing in multi-character scenes
Description: Identify and fix timing issues when multiple characters speak. **Common timing bugs:** characters speak simultaneously (missing wait blocks), gaps too long between speeches (wait values too high), character speaks before reaching position (animation and dialogue not synchronized). **Debug technique:** add temporary `print` statements showing variable values and timing markers: `print (join [Start: ] (timer))` at key points. **Trace example:** Character A speaks for 3 seconds, Character B should wait 3 seconds then speak. If B speaks at 2 seconds: increase B's wait. If B speaks at 5 seconds: decrease B's wait. **Systematic approach:** document expected timing (A: 0-3s, B: 3-6s, A: 6-8s), run project, note actual timing, identify discrepancy, adjust wait values.

Dependencies:
* T14.G4.07: Coordinate multi-sprite dialogue with synchronized waits
* T14.G3.07: Use wait blocks to control timing between actions




ID: T14.G4.12
Topic: T14 – Stories & Animation
Skill: Test story flow by following all possible paths
Description: Systematically test branching stories to ensure all paths work correctly. **Testing checklist:** (1) List all decision points and choices available in your story. (2) For each choice, trace which scene/broadcast it triggers. (3) Play through each path completely from start to each ending. (4) Verify widgets hide/show correctly per path. (5) Check for "dead ends" (paths with no ending or continuation). **Example test plan:** Story has 2 choices at Scene 1 (Go Left / Go Right). Path A (Left) → Scene2A → Scene3A → EndingA. Path B (Right) → Scene2B → Scene3B → EndingB. Test Path A completely, document results. Then test Path B completely. **Common bugs found during path testing:** choice button triggers wrong scene (check broadcast names), scene doesn't reset widgets (add widget removal to scene start), unreachable ending (missing broadcast connection). **Best practice:** create a written testing checklist before declaring story "done."

Dependencies:
* T14.G4.06: Create branching story paths with button widgets
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites


ID: T14.G4.13
Topic: T14 – Stories & Animation
Skill: Use easing for natural motion - slow-in, slow-out
Description: Create more natural-looking animations using EASING principles: real objects don't start and stop instantly - they accelerate and decelerate. **Slow-in (ease-in):** movement starts slow and speeds up. Implementation: use decreasing wait times in loop: `repeat (10) { change x by (5), wait ((10 - (i)) * 0.02) }` or use glide with short duration at end. **Slow-out (ease-out):** movement starts fast and slows down. Implementation: increasing wait times: `repeat (10) { change x by (5), wait ((i) * 0.02) }`. **Both (ease-in-out):** glide block naturally provides this - CreatiCode glide eases at both ends. **Comparison:** linear motion (constant speed) looks robotic; eased motion looks natural. **Practice:** replace instant position changes with short glides, or add variable waits to repeat loops.

Dependencies:
* T14.G3.14: Apply anticipation principle - prepare-action-reaction pattern
* T14.G4.01: Combine size animation with hide/show for visual effects


ID: T14.G4.14
Topic: T14 – Stories & Animation
Skill: Scope a story project - what's achievable in available time
Description: Learn to plan realistic story projects by estimating scope and complexity. **Scope estimation technique:** (1) List all scenes needed. (2) List all characters (sprites). (3) List all interactions (buttons, choices). (4) Estimate time per component: simple scene = 15 min, character with animation = 20 min, interactive choice = 10 min. (5) Add 50% buffer for bugs and polish. **Example:** 3 scenes + 2 characters + 2 choices = 45 + 40 + 20 = 105 min × 1.5 buffer = ~160 min (2.5 hours). **Scope cutting:** if estimated time exceeds available time, reduce scope: fewer scenes, fewer characters, fewer branching paths. **Minimum Viable Story (MVS):** what's the simplest version that still tells a complete story? Start with MVS, add features if time permits. **Project planning document:** write down your scope estimate BEFORE coding. Compare actual time to estimate afterward to improve future estimates.

Dependencies:
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites
* T14.G4.06: Create branching story paths with button widgets


ID: T14.G5.01
Topic: T14 – Stories & Animation
Skill: Debug and test multi-sprite scene coordination
Description: Ensure smooth scene transitions by systematically checking all sprite responses. **Testing checklist per scene:** which sprites show, which hide, sprite positions, costume states, backdrop. **Common bugs:** sprite left visible in wrong scene (missing hide), sprite in wrong position (missing go to), backdrop doesn't change (Stage script missing). Use `broadcast [Scene] and wait` when the script needs to pause until all sprites finish their scene setup. **Debug strategy:** test each scene transition individually, verify every sprite's state after each broadcast. Plan scene coordination with a table: columns = scenes, rows = sprites, cells = show/hide/position.

Dependencies:
* T14.G4.09: Apply graphics effects for visual atmosphere and transitions
* T14.G4.02: Use broadcasts to coordinate scene changes across sprites





ID: T14.G5.02
Topic: T14 – Stories & Animation
Skill: Broadcast action events to coordinate group animations
Description: Use `broadcast [Dance]` to trigger the same animation across multiple sprites simultaneously. **Pattern:** one sprite broadcasts an action → all sprites with `when I receive [Dance]` run their dance animation. **Examples:** `broadcast [Celebrate]` makes all characters cheer; `broadcast [FreezeAll]` stops all character movement. Design coordinated group animations: each sprite has its own `when I receive [Dance]` script with character-specific dance moves, but all dance at the same time. Compare to scene broadcasts: scene broadcasts change what's visible; action broadcasts trigger coordinated behaviors within a scene.

Dependencies:
* T14.G5.01: Debug and test multi-sprite scene coordination
* T14.G4.08: Run parallel actions using multiple scripts on same sprite





ID: T14.G5.02.01
Topic: T14 – Stories & Animation
Skill: Use broadcast and wait for strict sequential timing
Description: Use `broadcast [Action] and wait` to pause the current script until ALL scripts triggered by that broadcast complete. **Compare:** `broadcast [Walk]` continues immediately (parallel); `broadcast [Walk] and wait` pauses until walking finishes (sequential). **Cutscene pattern:** `broadcast [HeroWalks] and wait`, `broadcast [HeroSpeaks] and wait`, `broadcast [VillainAppears] and wait` - each action completes before next begins. Trace: `broadcast [Walk] and wait` → current script pauses → Hero sprite's walk script runs (3 secs) → walk script ends → current script resumes → next block runs. Use for cutscenes, dramatic reveals, or any sequence where order matters.

Dependencies:
* T14.G5.02: Broadcast action events to coordinate group animations





ID: T14.G5.03
Topic: T14 – Stories & Animation
Skill: Simulate camera panning by moving all sprites together
Description: Create the illusion of camera movement by moving all sprites (and backdrop elements) in the opposite direction. **Camera pan right:** all sprites `change x by (-5)` - sprites move left, creating illusion camera moved right. **Implementation:** `broadcast [PanRight]` → each sprite has `when I receive [PanRight]` with `repeat (20) { change x by (-5), wait (0.05) }`. All sprites move together in sync. **Multi-layer parallax:** background sprites move less (change x by -2), foreground sprites move more (change x by -7) for depth illusion. Trace: camera "pans right" 100 pixels → all sprites end up 100 pixels left of where they started.

Dependencies:
* T14.G5.02: Broadcast action events to coordinate group animations
* T14.G4.08: Run parallel actions using multiple scripts on same sprite





ID: T14.G5.04
Topic: T14 – Stories & Animation
Skill: Understand and plan visual layer composition
Description: Identify the fixed layer order in CreatiCode: **back to front:** Stage backdrop → Printed text → Sprites → Widgets. Sprites have relative layers (changeable), but always appear behind widgets and above printed text. **Design implications:** use backdrops for scene backgrounds, print blocks for floating annotations (behind characters), sprites for characters/objects, widgets for UI buttons/labels (always in front). Predict visual overlap: a character sprite will always appear in front of printed text but behind buttons. Plan your visual composition by assigning elements to appropriate layers. Debug: text covered by sprite → use widget label instead of print.

Dependencies:
* T14.G5.01: Debug and test multi-sprite scene coordination
* T14.G3.12: Print temporary text on the stage layer





ID: T14.G5.04.01
Topic: T14 – Stories & Animation
Skill: Control sprite layer order with layer blocks
Description: Use `go to [front v] layer` to bring sprite in front of ALL other sprites, `go to [back v] layer` to send behind all sprites. Use `go [forward v] (1) layers` to move up one layer relative to current, `go [backward v] (1) layers` to move down. **Initialization pattern:** at green flag, set each sprite's layer - background sprites `go to [back v] layer`, character sprites `go to [front v] layer`. Trace: SkySprite at back, TreeSprite in middle, HeroSprite at front → Hero appears in front of Tree, Tree in front of Sky. Debug: character hidden behind scenery → add `go to [front v] layer` to character's init.

Dependencies:
* T14.G5.04: Understand and plan visual layer composition





ID: T14.G5.05
Topic: T14 – Stories & Animation
Skill: Create dynamic dialogue by joining text and variables
Description: Use `join [Hello, ] (playerName)` to concatenate text strings with variables, creating personalized dialogue. Trace: playerName = "Alex" → `join [Hello, ] (playerName)` returns "Hello, Alex". **Nested joins:** `join (join [You have ] (score)) [ points!]` creates "You have 50 points!". Use in say blocks: `say (join [Welcome, ] (playerName)) for (2) secs`. **Applications:** personalized greetings, score displays, dynamic story content that includes player choices or status. Debug: extra spaces → check spacing in literal text strings; missing variable value → verify variable is set before join.

Dependencies:
* T14.G4.05: Read widget values into variables for story use
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G5.06
Topic: T14 – Stories & Animation
Skill: Create typewriter text effect with letter-by-letter reveal
Description: Build a typewriter effect that reveals text one letter at a time. **Algorithm:** `set [display v] to []`, `set [i v] to (1)`, `repeat (length of [message])` with `set [display v] to (join (display) (letter (i) of [message]))`, `say (display)...`, `change [i v] by (1)`, `wait (0.05) secs`. Trace: message = "Hello" → display builds: "H", "He", "Hel", "Hell", "Hello". Adjust wait time for typing speed: 0.02 = fast typing, 0.1 = slow dramatic reveal. Use for: dramatic dialogue, story narration, terminal/computer effects. Debug: letters missing → check loop count matches message length.

Dependencies:
* T14.G5.05: Create dynamic dialogue by joining text and variables
* T07.G3.05: Fix a simple repeat loop count





ID: T14.G5.07
Topic: T14 – Stories & Animation
Skill: Track cumulative player choices with variables
Description: Use variables to track player decisions across the story for later consequences. **Pattern:** create tracking variable (Trust, Karma, Friendship) → when player makes choice, adjust variable (`change [Trust v] by (10)` for positive choice, `change [Trust v] by (-5)` for negative). **Example:** "Help the stranger?" - Yes adds 10 Trust, No subtracts 5. Trace choices: player helps twice, ignores once → Trust = 10 + 10 - 5 = 15. Later in story, check accumulated value to determine outcomes. Multiple trackers: separate variables for different relationships or moral dimensions.

Dependencies:
* T14.G4.06: Create branching story paths with button widgets
* T09.G3.02: Use variables to store numerical values





ID: T14.G5.08
Topic: T14 – Stories & Animation
Skill: Trigger conditional endings based on accumulated choices
Description: Use conditionals to select different story endings based on tracked choice variables. **Pattern:** at story climax, check accumulated value: `if <(Trust) > (50)> then broadcast [GoodEnding] else broadcast [BadEnding]`. **Multiple tiers:** `if <(Trust) > (80)> then ... else if <(Trust) > (40)> then ... else ...` for best/good/bad endings. Each ending broadcast triggers different sprites/scenes. Trace: Trust = 65 → condition (Trust > 50) is true → GoodEnding broadcast → good ending scene displays. Design endings that feel like consequences of player choices.

Dependencies:
* T14.G5.07: Track cumulative player choices with variables
* T08.G4.03: Use if-else for branching logic





ID: T14.G5.09
Topic: T14 – Stories & Animation
Skill: Draw rectangles programmatically on vector costumes
Description: Use `draw rectangle at x (0) y (0) width (200) height (100) fill [#6269F8FF] border [#20B755FF] width (1) corner radius (0) rotation (0)` to draw rectangles on costumes via code. **vs Paint Editor:** paint editor = manual before runtime; draw blocks = programmatic during runtime. **Parameters:** x/y position (relative to costume center), dimensions, fill color, border color, border width, corner radius (0=sharp, 10+=rounded), rotation (degrees clockwise). Shapes draw ON the costume, moving with the sprite. **Use cases:** dynamic health bars, procedural patterns, visual indicators that change based on game state.

Dependencies:
* T14.G3.00.03: Edit sprite costumes using the paint editor tools
* T14.G5.01: Debug and test multi-sprite scene coordination





ID: T14.G5.09.01
Topic: T14 – Stories & Animation
Skill: Draw ovals and circles on vector costumes
Description: Use `draw oval at x (0) y (0) width (100) height (100) fill [#E2F9F2FF] border [#F44399FF] width (1) rotation (0)` for circles and ovals. **Circle vs oval:** width = height creates circle; width ≠ height creates oval. Position (x, y) is center point. Combine shapes for patterns: `repeat (5)` with `draw oval...` and `change x by (30)` creates a row of circles. **Use cases:** status indicators (filled circles for hearts/lives), decorative patterns, dynamic icons. Trace: `draw oval` at (0,0) width 50 height 50 → 50-pixel circle centered on costume center.

Dependencies:
* T14.G5.09: Draw rectangles programmatically on vector costumes





ID: T14.G5.09.02
Topic: T14 – Stories & Animation
Skill: Create dynamic visual indicators with shape drawing
Description: Combine shape drawing with variables and loops for dynamic visuals. **Health bar:** `draw rectangle... width ((health) * (2))...` - bar width changes with health value. **Status icons:** `if <(hasShield) = [true]>` → `draw oval...` - icon appears conditionally. **Patterns with loops:** `set [i v] to (0)`, `repeat (10)` with `draw rectangle at x ((i) * (30))...`, `change [i v] by (1)` creates evenly spaced shapes. **Radial patterns:** `repeat (12)` with `draw rectangle... rotation ((i) * (30))` creates starburst. Trace health bar: health = 75 → width = 75 * 2 = 150 pixels.

Dependencies:
* T14.G5.09.01: Draw ovals and circles on vector costumes
* T09.G3.02: Use variables to store numerical values





ID: T14.G5.10
Topic: T14 – Stories & Animation
Skill: Draw straight lines on vector costumes
Description: Use `draw line in [#386AF8FF] from x (0) y (0) to x (100) y (100) thickness (2)` to draw lines connecting two points. **Parameters:** color (hex), start point (from x, from y), end point (to x, to y), thickness (pixels). **Custom shapes:** draw triangle with 3 lines connecting 3 points; draw square with 4 lines. **Connectors:** draw lines between sprites' positions to show relationships. Trace: line from (0,0) to (100,100) draws diagonal across costume. **Use cases:** diagrams, borders, connecting elements, custom polygons.

Dependencies:
* T14.G5.09: Draw rectangles programmatically on vector costumes





ID: T14.G5.10.01
Topic: T14 – Stories & Animation
Skill: Draw bezier curves for smooth shapes
Description: Use `draw curve in [#05DC6DFF] from x (20) y (20) to x (200) y (20) control 1 x (20) y (100) control 2 x (200) y (100) thickness (1)` for smooth curves. **Control points** act like magnets pulling the curve toward them. **Simple arc:** both control points on same side of line. **S-curve:** control points on opposite sides. Trace: start (20,20), end (200,20), controls both at y=100 → curve bows downward from start to end. Experiment with control positions to understand bezier behavior. **Use cases:** smooth paths, organic shapes, decorative elements.

Dependencies:
* T14.G5.10: Draw straight lines on vector costumes





ID: T14.G5.10.02
Topic: T14 – Stories & Animation
Skill: Draw text as part of costumes
Description: Use `draw text [Hello] at x (0) y (0) size (24) color [#000000FF] rotation (0)` to draw text ON the costume (not stage). **vs print blocks:** print = stage layer; draw text = part of costume that moves with sprite. Text stays on costume until cleared. **Parameters:** text content, position, font size (pixels), color (hex), rotation (degrees). **Use cases:** labels on sprites, dynamic text that moves with characters, procedurally generated images with text. Trace: `draw text [HP: 100]` at (0, 50) on health bar sprite → text appears above health bar and moves with it.

Dependencies:
* T14.G5.10.01: Draw bezier curves for smooth shapes





ID: T14.G5.11
Topic: T14 – Stories & Animation
Skill: Clear programmatic costume drawings
Description: Use `clear all drawings` to remove ALL shapes/text drawn with code blocks from the current costume. **Scope:** only clears programmatic drawings; does NOT affect paint editor shapes (those are permanent). **Pattern:** `when green flag clicked` → `clear all drawings` → draw fresh content. Or: `when I receive [NewScene]` → `clear all drawings` → draw scene-appropriate content. Trace: costume has 3 code-drawn shapes → `clear all drawings` → costume returns to paint-editor-only state. Use for: resetting dynamic indicators, changing visual state between scenes, animation that redraws each frame.

Dependencies:
* T14.G5.10.02: Draw text as part of costumes
* T14.G3.12.02: Clear printed text when scenes change





ID: T14.G5.12
Topic: T14 – Stories & Animation
Skill: Add AI-generated speech with text-to-speech blocks
Description: Use `say [Hello!] in [English (United States) v] as [Female v] speed (100) pitch (100) volume (100) store sound as []` to generate spoken audio. **vs regular say blocks:** regular say = text bubble only; TTS say = actual audio speech. **Parameters:** text to speak, language, voice type (Female/Male/Boy/Girl), speed/pitch/volume (100 = normal). Block waits until speech finishes before continuing. Leave 'store sound as' empty for now. **Use cases:** accessible stories for visual impairments, character voices, narration, language learning. Trace: `say [Welcome!]...` → audio plays "Welcome!" → script continues.

Dependencies:
* T14.G5.05: Create dynamic dialogue by joining text and variables
* T14.G3.04: Display character dialogue with say blocks





ID: T14.G5.12.01
Topic: T14 – Stories & Animation
Skill: Select TTS languages and voice types for characters
Description: Choose from 30+ languages (English US/UK, Spanish, French, Chinese, Japanese, German, etc.) and voice types (Female, Male, Boy, Girl, plus variants Female2, Male2). **Character voices:** assign distinct voices to characters - Female for queen, Male for king, Boy/Girl for children. Not all voice types available in all languages - test combinations. **Multilingual stories:** same character can speak in different languages for language-learning stories. **Design voices** that match character personalities and ages.

Dependencies:
* T14.G5.12: Add AI-generated speech with text-to-speech blocks





ID: T14.G5.12.02
Topic: T14 – Stories & Animation
Skill: Adjust TTS speed, pitch, and volume for expression
Description: Modify speech characteristics for emotional expression. **Speed (50-200):** 50 = slow/careful, 100 = normal, 150 = excited/fast, 200 = rushed. **Pitch (50-200):** 50 = deep/serious, 100 = normal, 150 = cheerful, 200 = squeaky. **Volume (0-200):** 50 = whisper, 100 = normal, 150 = loud, 200 = shouting. **Character profiles:** wise elder (speed=80, pitch=70), energetic child (speed=120, pitch=140), villain (speed=90, pitch=60). Trace: speed=50 makes speech take twice as long. Design distinct voice profiles for each character.

Dependencies:
* T14.G5.12.01: Select TTS languages and voice types for characters





ID: T14.G5.13
Topic: T14 – Stories & Animation
Skill: Style widget backgrounds and borders
Description: Use `set widget background color [#FFFFFFFF] border color [#000000FF] border width (2) border radius (10) for [widgetName v]` to customize widget appearance. **Hex colors:** #RRGGBBAA (Red, Green, Blue, Alpha). Alpha: FF = solid, 80 = 50% transparent, 00 = invisible. **Border width:** 0 = none, 2 = thin, 5 = thick. **Border radius:** 0 = sharp corners, 10 = rounded, 20+ = very rounded. Works on labels, buttons, textboxes. Trace: `set widget background color [#FF0000FF]...` → widget background turns red. Design cohesive UI by using consistent colors across widgets.

Dependencies:
* T14.G4.06: Create branching story paths with button widgets
* T14.G3.11: Create label widgets for persistent on-screen text





ID: T14.G5.13.01
Topic: T14 – Stories & Animation
Skill: Format text style inside widgets
Description: Use `set text style [Arial v] font size (18) text color [#000000FF] boldness [bold v] text alignment [Center v] for [widgetName v]` for text formatting. **Fonts:** Arial, Times New Roman, Courier, Georgia, Verdana, Comic Sans MS. **Size:** 12 = small, 18 = medium, 24 = large, 36+ = very large. **Boldness:** normal or bold. **Alignment:** Left, Center, Right. **Design guidelines:** titles = large + centered + bold; descriptions = medium + left + normal; buttons = medium + centered + bold. Design readable text with appropriate contrast against background.

Dependencies:
* T14.G5.13: Style widget backgrounds and borders





ID: T14.G5.13.02
Topic: T14 – Stories & Animation
Skill: Design cohesive widget themes for story atmosphere
Description: Create visual themes by matching widget colors to story mood. **Scary/dark:** dark backgrounds (#333333FF), red text (#FF0000FF), thick borders. **Happy/bright:** pastels (#FFB6C1FF, #87CEEBFF), thin borders. **Fantasy/magical:** purple (#800080FF), gold text (#FFD700FF), glowing borders. **Nature:** greens (#228B22FF), brown text (#8B4513FF), rounded corners. Apply consistent styling across ALL widgets in a scene. **Scene change pattern:** `when I receive [DarkScene]` → restyle all widgets to dark theme. Design themes before coding, then implement systematically.

Dependencies:
* T14.G5.13.01: Format text style inside widgets





ID: T14.G5.14
Topic: T14 – Stories & Animation
Skill: Create dropdown menus for multiple story choices
Description: Use `add dropdown menu at X (0) Y (0) width (200) height (40) from list [choices v] as [choiceMenu]` to create choice menus populated from a list. **Setup:** populate list first with `add [Forest] to [choices v]`, etc. **Read selection:** `(value of widget [choiceMenu v])` returns selected item. **Process choice:** `if <(value of widget [choiceMenu v]) = [Forest]> then broadcast [ForestScene]`. **vs buttons:** use dropdowns for 4+ choices to save space; use buttons for 2-3 prominent choices. Style dropdown to match scene theme.

Dependencies:
* T14.G5.13: Style widget backgrounds and borders
* T10.G4.01: Use lists for dynamic data storage





ID: T14.G5.15
Topic: T14 – Stories & Animation
Skill: Calculate and synchronize animation timing
Description: Calculate wait durations to synchronize multi-sprite animations. **Say blocks:** duration is explicit (`say... for (3) secs` = 3 seconds). **Glide blocks:** duration is explicit (`glide (2) secs...` = 2 seconds). **TTS estimate:** ~2-3 seconds per 10 words at speed=100; speed=50 takes 2x longer. **Multi-action timing:** Sprite A does `say (3 secs)` + `glide (2 secs)` = 5 seconds total; Sprite B should `wait (5) secs` before responding. Trace: A speaks 0-3s, A moves 3-5s, B waits until 5s, B speaks 5-7s. Debug: overlapping speech → increase wait; awkward pauses → decrease wait.

Dependencies:
* T14.G4.07: Coordinate multi-sprite dialogue with synchronized waits
* T14.G5.12: Add AI-generated speech with text-to-speech blocks




ID: T14.G5.16
Topic: T14 – Stories & Animation
Skill: Create dramatic tension through pacing and timing
Description: Design pacing strategies to build emotional impact in stories. **Build suspense:** slow down before climax with longer waits (2-3 secs), slower glides, more costume frames. **Release tension:** speed up during action with shorter waits (0.1-0.3 secs), faster animations. **Dramatic pause:** insert `wait (2) seconds` before important reveals for anticipation. **Timing patterns:** horror (slow approach, sudden appearance), comedy (quick setup, pause, punchline), mystery (gradual reveal with increasing tempo). **Implementation:** vary `wait` durations throughout story: slow (1-3 secs) for tension, fast (0.1-0.5 secs) for action, pause (2-4 secs) before reveals. Trace a suspense sequence: `glide (3) secs` (slow approach), `wait (2)` (pause), `say [BOO!]` (sudden reveal).

Dependencies:
* T14.G5.15: Calculate and synchronize animation timing
* T14.G4.10: Design character arc with beginning, middle, and end states




ID: T14.G5.17
Topic: T14 – Stories & Animation
Skill: Design visual transitions between scenes
Description: Create smooth scene transitions that enhance storytelling. **Fade to black:** all sprites `repeat (10) { change [brightness v] effect by (-10) }`, then change scene, then fade in. **Wipe effect:** move a black rectangle sprite across screen while changing scene behind it. **Zoom transition:** all sprites `repeat (10) { change size by (-10) }` (zoom out), change scene, `repeat (10) { change size by (10) }` (zoom in). **Dissolve:** current sprites fade out (ghost effect) while new sprites fade in simultaneously. **Match cut:** end scene with sprite in specific position/pose, start next scene with different sprite in same position/pose for visual continuity. Choose transitions that match story mood: fades for time passing, wipes for location changes, zooms for emphasis.

Dependencies:
* T14.G4.09: Apply graphics effects for visual atmosphere and transitions
* T14.G5.02: Broadcast action events to coordinate group animations








ID: T14.G5.18
Topic: T14 – Stories & Animation
Skill: Trace animation state through multiple frames
Description: Systematically track how sprite properties change during complex animations. **Tracing technique:** create a table with columns for frame number, x position, y position, size, costume, effects. Run animation step-by-step, record values at each key frame. **Using console logging:** add `print (join [Frame ] (join (frame) (join [ x=] (x position))))` inside animation loops. **Predicting outcomes:** given initial state and animation code, predict final state by tracing through each iteration. **Example trace:** Start: x=0, size=100. Loop 5 times: change x by 20, change size by -10. After loop: x=100, size=50. **Debug application:** animation ends in wrong state, trace reveals where calculation diverges from expectation. Use tracing to verify complex animations before adding more features.

Dependencies:
* T14.G5.02: Broadcast action events to coordinate group animations
* T14.G4.11: Debug dialogue timing in multi-character scenes




ID: T14.G5.19
Topic: T14 – Stories & Animation
Skill: Create scene transition timing checklist
Description: Design and document precise timing for multi-element scene transitions. **Checklist template:** (1) List all elements that change in transition (sprites, widgets, backdrop, sounds). (2) Define timing for each element with start/end times. (3) Calculate total transition duration. (4) Identify synchronization points where elements must coordinate. **Example transition (fade to new scene):** Duration 0-0.5s: fade out music (volume 100→0). Duration 0.5-1.5s: all sprites fade out (ghost effect 0→100). Duration 1.5s: switch backdrop + hide old widgets + show new widgets (instant). Duration 1.5-2.5s: new sprites fade in (ghost 100→0). Duration 2.0-2.5s: fade in new music (volume 0→100). Total: 2.5 seconds. **Documentation practice:** write this checklist in project notes or comments before coding the transition. **Testing:** play transition 5+ times to verify smoothness. **Debug:** jerky transition → stagger timings more; too slow → reduce durations; elements appear out of order → adjust start times.

Dependencies:
* T14.G5.17: Design visual transitions between scenes
* T14.G5.15: Calculate and synchronize animation timing




ID: T14.G5.20
Topic: T14 – Stories & Animation
Skill: Implement text accessibility from project start
Description: Build text accessibility into initial project design as a foundational practice, not as an afterthought. **Accessibility checklist for all story text:** (1) Minimum text size 16px for body text, 20px for headings (in say blocks, labels, print). (2) Color contrast: white text (#FFFFFFFF) on dark backgrounds (#000000FF to #333333FF), dark text (#000000FF) on light backgrounds (#FFFFFFEF to #CCCCCCFF). Avoid low-contrast combinations like yellow on white or blue on black. (3) Don't rely on color alone for meaning: use icons + text (not just "red = danger"). (4) Duration test: read all dialogue aloud - if you can't finish reading comfortably before bubble disappears, it's too short. (5) Grayscale test: imagine your story in black and white - can you still understand everything? **Implementation pattern:** create a style guide at project start defining text sizes, approved color combinations, and duration formulas. Apply consistently to ALL text in project. **Why this matters:** approximately 1 in 12 males and 1 in 200 females have color vision deficiency; many users have visual impairments. Accessible design benefits everyone.

Dependencies:
* T14.G3.04.01: Style speech bubbles to convey mood and emphasis
* T14.G5.13.01: Format text style inside widgets




ID: T14.G5.21
Topic: T14 – Stories & Animation
Skill: Adapt story dialogue for different reading levels
Description: Create the same story with multiple text complexity levels for different age audiences. **Three-level approach:** (1) Simple (age 5-7): 3-5 word sentences, common words only, present tense. Example: "The cat ran fast. She saw a bird. The bird flew away." (2) Medium (age 8-10): 6-10 word sentences, descriptive adjectives, mix of tenses. Example: "The orange cat sprinted across the green grass. When she spotted the bird, it quickly flew up into the tall tree." (3) Complex (age 11+): 10-15 word sentences, advanced vocabulary, varied sentence structure. Example: "The lithe orange feline darted swiftly across the verdant lawn, but upon detecting the startled bird, her quarry swiftly ascended to the safety of the towering oak." **Implementation:** use a `(readingLevel)` variable to select level (1/2/3). Store three versions of each dialogue line in parallel lists: `[dialogueSimple v]`, `[dialogueMedium v]`, `[dialogueComplex v]`. Select appropriate version based on level. **Design pattern:** write Medium version first, then simplify for Simple and expand for Complex. **Testing:** have target age readers test each level for comprehension and engagement.

Dependencies:
* T14.G5.05: Create dynamic dialogue by joining text and variables
* T14.G4.05: Read widget values into variables for story use


ID: T14.G5.22
Topic: T14 – Stories & Animation
Skill: Map story structure to programming constructs
Description: Recognize that story elements directly correspond to programming concepts - this is the "Narrative as Algorithm" principle made concrete. **Story → Code mappings:** (1) SEQUENCE: story events in order = blocks stacked in sequence. (2) BRANCHING: "choose your path" = if-else conditionals. (3) LOOPS: repeated events ("every day the hero trained") = repeat blocks. (4) STATE: character changes ("hero becomes braver") = variables tracking values. (5) EVENTS: "when the dragon appeared" = event triggers (when I receive, when clicked). (6) ABSTRACTION: "the hero did their morning routine" = custom blocks that hide details. **Practice exercise:** take a simple story and diagram it showing which parts are sequences, branches, loops, and state changes. **Why this matters:** understanding this mapping makes you a better story designer AND a better programmer. Stories are algorithms told in human language; programs are stories told in computer language.

Dependencies:
* T14.G5.08: Trigger conditional endings based on accumulated choices
* T14.G2.08: Recognize branching narratives as decision trees


ID: T14.G5.23
Topic: T14 – Stories & Animation
Skill: Create follow-through and overlapping action
Description: Apply the animation principle of FOLLOW-THROUGH: when a main action stops, secondary parts continue moving briefly. **Examples:** character stops walking → hair keeps swinging → then settles; character waves → arm stops → fingers continue flopping → then stop. **Implementation - character landing:** main sprite stops instantly, then wobble animation: `change y by (-5)`, `wait (0.05)`, `change y by (5)`, `change y by (-3)`, `wait (0.05)`, `change y by (3)`. **Overlapping action:** different parts move at different times/speeds. Running character: body moves first, legs follow, arms follow legs, hair follows arms. Use multiple costume frames with staggered timing. **Why it works:** follow-through shows weight and physics; overlapping action shows that objects are made of multiple parts. Both make animation feel alive rather than robotic.

Dependencies:
* T14.G4.13: Use easing for natural motion - slow-in, slow-out
* T14.G5.02: Broadcast action events to coordinate group animations


ID: T14.G5.24
Topic: T14 – Stories & Animation
Skill: Use AI to generate story ideas - brainstorming partner
Description: Use ChatGPT as a creative brainstorming partner for story development, NOT as the final writer. **Brainstorming prompts:** "Give me 5 unique story premises that combine [theme1] and [theme2]" (e.g., "space exploration" and "cooking"). "List 3 interesting obstacles a [character type] might face trying to [goal]." "What are 3 unexpected plot twists for a story about [premise]?" **Critical evaluation:** AI generates IDEAS, you EVALUATE and SELECT. Not all AI suggestions are good - use your judgment. Ask follow-up questions: "Make option 2 more surprising" or "Give me a version where the villain has sympathetic motives." **Iteration pattern:** AI suggests → you critique → AI refines → you select best elements → you write final version. **Important:** AI is a collaborator, not a replacement for your creativity. The best stories combine AI's broad knowledge with your unique perspective and taste.

Dependencies:
* T14.G5.05: Create dynamic dialogue by joining text and variables
* T14.G4.14: Scope a story project - what's achievable in available time


ID: T14.G5.25
Topic: T14 – Stories & Animation
Skill: Create a story design document
Description: Write a planning document BEFORE coding to guide your story project. **Story Design Document template:** (1) **Logline:** 1-2 sentence summary of entire story. (2) **Characters:** name, appearance, personality, goal for each main character. (3) **Setting:** where and when the story takes place. (4) **Scene outline:** list each scene with brief description and key events. (5) **Branching map:** if interactive, diagram all choice points and paths. (6) **Technical requirements:** sprites needed, backdrops needed, special features (TTS, AI, widgets). (7) **Scope estimate:** estimated time to complete (from T14.G4.14). **Benefits:** prevents scope creep; clarifies vision before coding; easier to identify missing pieces; serves as reference during development; helps communicate project to others. **Living document:** update as project evolves, but changes should be deliberate, not accidental drift. **Review checkpoint:** before coding each scene, verify it matches the design document.

Dependencies:
* T14.G4.14: Scope a story project - what's achievable in available time
* T14.G5.08: Trigger conditional endings based on accumulated choices


ID: T14.G6.01
Topic: T14 – Stories & Animation
Skill: Implement animation state machines with variables
Description: Use a `(state)` variable to control character behavior patterns. **Structure:** `forever` loop with `if <(state) = [idle]>` → idle animation, `if <(state) = [walking]>` → walk animation, `if <(state) = [talking]>` → talk animation. **Change states:** `set [state v] to [walking]` triggers walking behavior. **State transitions:** events or conditions change state value → forever loop detects new state → runs appropriate animation. Trace: state = "idle" → character bobs gently; user clicks → `set [state] to [walking]` → character walks. Debug: animation doesn't change → verify state variable value is updating.

Dependencies:
* T14.G5.08: Trigger conditional endings based on accumulated choices
* T09.G4.01: Use variables to track multiple states simultaneously





ID: T14.G6.02
Topic: T14 – Stories & Animation
Skill: Store and iterate dialogue using lists
Description: Store dialogue lines in a list for data-driven storytelling. **Setup:** `add [Hello there!] to [dialogue v]`, `add [How are you?] to [dialogue v]`, etc. **Playback:** `set [i v] to (1)`, `repeat (length of [dialogue v])` with `say (item (i) of [dialogue v]) for (2) secs`, `change [i v] by (1)`. **Benefits:** edit dialogue by changing list items (no code changes); extend scenes by adding list items; reuse dialogue code for different conversations. Trace: dialogue list has 3 items → loop runs 3 times → character says all 3 lines. Design dialogue as data, separate from animation code.

Dependencies:
* T14.G6.01: Implement animation state machines with variables
* T10.G4.01: Use lists for dynamic data storage





ID: T14.G6.03
Topic: T14 – Stories & Animation
Skill: Create cutscene controllers with custom blocks
Description: Build custom blocks to orchestrate multi-step cutscenes. **Define:** create custom block "IntroCutscene" with `broadcast [HeroEnters] and wait`, `broadcast [HeroSpeaks] and wait`, `broadcast [VillainAppears] and wait`. **Call:** `when green flag clicked` → `IntroCutscene`. **Benefits:** centralizes sequence logic; reusable for multiple story moments; easy to debug and modify. **Parameterized version:** custom block "PlayCutscene (sceneName)" uses variable to select different broadcast sequences. Design cutscenes as self-contained sequences that can be called from main story flow.

Dependencies:
* T14.G6.02: Store and iterate dialogue using lists
* T14.G5.02.01: Use broadcast and wait for strict sequential timing
* T11.G4.01: Define and call a simple custom block (no parameters)





ID: T14.G6.04
Topic: T14 – Stories & Animation
Skill: Build multi-language stories with conditional TTS
Description: Create multilingual stories using language preference variables. **Setup:** `set [playerLanguage v] to [Spanish]` (from menu or detected). **Conditional speech:** `if <(playerLanguage) = [Spanish]> then say [Hola!] in [Spanish]... else say [Hello!] in [English]...`. **List approach:** parallel lists `[dialogueEN v]` and `[dialogueES v]`; select based on preference. **Language learning:** slower speed (80) helps comprehension; show text bubble alongside TTS. Design stories that switch languages based on player preference or character identity.

Dependencies:
* T14.G5.12: Add AI-generated speech with text-to-speech blocks
* T14.G6.02: Store and iterate dialogue using lists
* T08.G4.03: Use if-else for branching logic





ID: T14.G6.05
Topic: T14 – Stories & Animation
Skill: Accept voice input with speech recognition
Description: Use speech recognition for voice-controlled stories. **Start:** `start recognizing speech in [English (United States) v] record as [input1]`. **Stop and process:** `end speech recognition` sends audio to AI for conversion. **Read result:** `(text from speech)` returns recognized text. **Pattern:** `start recognizing...`, `wait (3) secs` (or until button), `end speech recognition`, `set [playerSaid v] to (text from speech)`, `say (join [You said: ] (playerSaid))`. **Note:** requires microphone permission; may have latency. Use for: voice commands, spoken answers, hands-free interaction.

Dependencies:
* T14.G6.04: Build multi-language stories with conditional TTS
* T14.G5.05: Create dynamic dialogue by joining text and variables





ID: T14.G6.06
Topic: T14 – Stories & Animation
Skill: Trigger story branches with voice commands
Description: Process speech recognition results to control story flow. **Pattern:** `if <(text from speech) contains [yes]> then broadcast [AcceptQuest]`. Use `contains` not `=` because speech may include extra words ("yes please" matches "yes"). **Handle variations:** `if <or <(text) contains [yes]> <(text) contains [yeah]>>`. **Robust design:** check for synonyms, handle unclear input with "I didn't understand". **Examples:** "Go left" → LeftPath, "Attack" → CombatScene, "Yes" → AcceptQuest. Create immersive voice-driven interactive fiction.

Dependencies:
* T14.G6.05: Accept voice input with speech recognition
* T14.G4.06: Create branching story paths with button widgets





ID: T14.G6.07
Topic: T14 – Stories & Animation
Skill: Display formatted text with rich textbox widgets
Description: Use `add rich textbox at X (0) Y (0) width (400) height (300) padding (10) mode [read only v] as [storyText]` for formatted text. **HTML-like formatting:** `<b>bold</b>`, `<i>italic</i>`, `<br>` for line breaks, `<font color='red'>text</font>` for colors. **Example:** `set value to [<b>Chapter 1</b><br><br>Once upon a time...] for widget [storyText]`. **Modes:** "read only" for display, "input" for player writing. Create book-like presentations with styled chapters, formatted dialogue, and visual emphasis. Combine with TTS for accessible reading.

Dependencies:
* T14.G5.14: Create dropdown menus for multiple story choices
* T15.G5.05: Use rich textboxes for formatted text display





ID: T14.G6.08
Topic: T14 – Stories & Animation
Skill: Visualize story stats with slider widgets
Description: Use `add slider at X (0) Y (0) width (200) min (0) max (100) as [healthBar]` for visual stat displays. **Link to variable:** when variable changes, update slider: `set value to (health) for widget [healthBar]`. **Color-code stats:** health = red (#FF0000FF), mana = blue (#0000FFFF), happiness = green (#00FF00FF). **Position:** top-right for health, top-left for other stats. Trace: `change [health v] by (-10)` → `set value to (health) for widget [healthBar]` → slider visually decreases. Design stats that give players feedback on story consequences.

Dependencies:
* T14.G5.07: Track cumulative player choices with variables
* T14.G5.13: Style widget backgrounds and borders




ID: T14.G6.09
Topic: T14 – Stories & Animation
Skill: Generate character dialogue with ChatGPT blocks
Description: Use `ask ChatGPT [prompt] and wait` to generate dynamic dialogue responses. **Story dialogue prompt:** `ask ChatGPT [You are a wise wizard in a fantasy story. A young hero asks you for advice about facing a dragon. Give a short, encouraging response in 2 sentences.] and wait`, then use `(ChatGPT response)` in say block. **Character voice consistency:** include character description in prompt ("You are grumpy but kind..."). **Safety:** review AI responses before displaying; use `if <(length of (ChatGPT response)) > (0)>` to handle empty responses. **Use cases:** NPCs that respond to player questions, procedurally generated story events, adaptive dialogue based on player choices. Design prompts that produce age-appropriate, story-consistent responses.

Dependencies:
* T14.G6.02: Store and iterate dialogue using lists
* T14.G5.05: Create dynamic dialogue by joining text and variables




ID: T14.G6.09.01
Topic: T14 – Stories & Animation
Skill: Design effective ChatGPT prompts for character voices
Description: Craft prompts that produce consistent, character-appropriate AI dialogue. **Prompt structure:** (1) Character description ("You are a grumpy but wise old wizard"), (2) Situation context ("A young hero asks about the dragon"), (3) Response guidelines ("Reply in 2 sentences, use archaic speech"). **Voice consistency techniques:** include personality traits, speech patterns, vocabulary level, emotional state. **Iteration:** test prompts, identify off-character responses, refine constraints. **Examples:** villain = formal + threatening + long sentences; child NPC = simple words + exclamation marks + short sentences. Debug: AI breaks character → add stronger constraints ("Never be friendly", "Always use medieval words").

Dependencies:
* T14.G6.09: Generate character dialogue with ChatGPT blocks


ID: T14.G6.09.02
Topic: T14 – Stories & Animation
Skill: Handle AI response errors and timeouts gracefully
Description: Build robust error handling for AI-dependent dialogue. **Common issues:** empty response (AI failed), timeout (network slow), inappropriate content (filtered). **Error detection:** `if <(length of (ChatGPT response)) = (0)> then` use fallback dialogue. **Timeout handling:** use `ask ChatGPT... and wait` with fallback: if response takes too long, show "Wizard is thinking..." then retry or use pre-written backup. **Fallback dialogue:** pre-write dialogue alternatives for when AI fails. **User feedback:** don't show raw errors; show story-appropriate messages ("The crystal ball is cloudy..."). Design stories that remain playable even when AI services are unavailable.

Dependencies:
* T14.G6.09.01: Design effective ChatGPT prompts for character voices




ID: T14.G6.10
Topic: T14 – Stories & Animation
Skill: Create AI-generated character costumes and backdrops
Description: Use AI image generation to create custom story visuals. **Generate backdrop:** `search library for [magical forest with glowing mushrooms] and add as backdrop` finds or generates scene backgrounds. **Generate costume:** `search library for [friendly dragon character cartoon style] and add as costume for [dragon v]` creates character appearances. **Best practices:** use descriptive prompts (art style, mood, colors), test multiple prompts for best results, save generated images as permanent costumes. **Creative storytelling:** let players describe characters → generate custom costumes; procedurally generate scene backgrounds based on story location. Combine AI-generated visuals with coded animations for unique stories.

Dependencies:
* T14.G6.09: Generate character dialogue with ChatGPT blocks
* T14.G4.02.02: Change stage backdrop to match scene changes







ID: T14.G6.11
Topic: T14 – Stories & Animation
Skill: Combine TTS with dialogue for narrated interactive stories
Description: Integrate text-to-speech with visual dialogue for multi-modal storytelling. **Pattern:** `say [Hello!] for (2) secs...` displays speech bubble WHILE `say [Hello!] in [English]... speed (100)` plays audio. Use parallel scripts: one for visual bubble, one for TTS audio. **Synchronization:** TTS duration varies; estimate ~2-3 seconds per 10 words at speed=100; visual bubble should match or slightly exceed TTS duration. **Accessibility design:** visual text for hearing-impaired users, audio for visually-impaired users. **Character voice profiles:** assign unique TTS settings (language, voice type, speed, pitch) to each character and store in variables for consistent voice throughout story. Debug: audio and bubble out of sync → adjust bubble duration; character sounds wrong → verify TTS settings match character profile.

Dependencies:
* T14.G5.12.02: Adjust TTS speed, pitch, and volume for expression
* T14.G5.05: Create dynamic dialogue by joining text and variables




ID: T14.G6.12
Topic: T14 – Stories & Animation
Skill: Chain AI prompts for multi-step narrative generation
Description: Build complex narratives by feeding AI responses into subsequent prompts (prompt chaining). **Pattern:** (1) Initial prompt generates story seed → (2) Extract key element from response → (3) Feed into next prompt for continuation → (4) Repeat for coherent multi-part narrative. **Example chain:** Prompt 1: "Generate a fantasy character: give me name, species, one special ability, one personality flaw. Format: NAME|SPECIES|ABILITY|FLAW" → Response: "Zara|elf|can talk to animals|afraid of water". Parse response into variables using delimiter splitting. Prompt 2: `ask ChatGPT (join [Generate a quest for ] (join (name) (join [, a ] (join (species) (join [ who ] (join (ability) (join [ but ] (join (flaw) [. Give quest objective and first challenge.])))))))) and wait`. Response continues story. Prompt 3: Use quest details in next generation. **Benefits:** more coherent narratives, character consistency, controlled story progression. **Debug:** AI forgets previous info → include summary of key facts in each prompt; AI diverges from story → add constraints ("Stay in fantasy genre", "Character never overcomes flaw").

Dependencies:
* T14.G6.09: Generate character dialogue with ChatGPT blocks
* T14.G5.05: Create dynamic dialogue by joining text and variables




ID: T14.G6.13
Topic: T14 – Stories & Animation
Skill: Conduct user testing sessions with feedback collection
Description: Plan and run user testing to improve story quality based on audience feedback. **User testing protocol:** (1) Define testing goals: What do you want feedback on? (story engagement, clarity, difficulty, pacing). (2) Recruit 3-5 testers from target age group. (3) Prepare observation form to note: where testers pause, skip dialogue, express confusion, or show excitement. (4) Testing session: ask tester to "think aloud" while playing, don't interrupt or help unless stuck >2 minutes, observe and take notes. (5) Post-session interview: "What did you like most?", "What confused you?", "What would you change?". (6) Analyze patterns: if 3/5 testers skip same dialogue, it's too long; if 4/5 testers miss a clue, make it clearer. **Implementation:** create feedback form template (paper or digital), document 3-5 key findings, prioritize fixes. **Example findings:** "All testers confused by Scene 3 fork - add signpost explaining choices", "4/5 loved the wizard character - expand wizard's role". **Iterate:** fix issues → test again with new testers.

Dependencies:
* T14.G5.08: Trigger conditional endings based on accumulated choices
* T14.G4.12: Test story flow by following all possible paths


ID: T14.G6.14
Topic: T14 – Stories & Animation
Skill: Design squash and stretch for character weight
Description: Apply the SQUASH AND STRETCH principle to convey character weight, material properties, and energy. **The principle:** objects squash when compressed (landing, impact) and stretch when extended (jumping, reaching). More squash/stretch = lighter/bouncier; less = heavier/stiffer. **Implementation - bouncing ball:** falling: `set size to (100)` (normal); landing: `set size to (80)` + flatten horizontally; bouncing up: `set size to (120)` + stretch vertically. **Character jump:** crouch = squash (shorter, wider costume or scale); airborne = stretch (taller, narrower); land = squash; settle = normal. **Costume approach:** create 3 costumes (normal, squashed, stretched) and switch between them at key moments. **Scale approach:** use `set size` creatively or use separate sprites for body parts. **Debug:** excessive squash/stretch looks cartoonish (good for comedy); subtle squash/stretch looks realistic (good for drama). Match the amount to your story's tone.

Dependencies:
* T14.G5.23: Create follow-through and overlapping action
* T14.G6.01: Implement animation state machines with variables


ID: T14.G6.15
Topic: T14 – Stories & Animation
Skill: Debug AI response handling systematically
Description: Create robust error handling and debugging strategies for AI-dependent stories. **Common AI issues and fixes:** (1) Empty response: `if <(length of (ChatGPT response)) = (0)>` → use fallback dialogue. (2) Timeout: implement timer check: start timer before AI call, if timer > 5 when response arrives, warn user. (3) Inappropriate content: verify response doesn't contain flagged words; use fallback if detected. (4) Wrong format: if expecting "NAME|AGE|TRAIT" but get prose, retry with clearer prompt or use fallback. (5) Inconsistent character: AI breaks character voice → strengthen prompt constraints. **Debug logging:** `print (join [AI Response: ] (ChatGPT response))` to see what AI returned. **Fallback strategy:** maintain list of pre-written backup dialogues for every AI interaction point. **Testing:** intentionally trigger errors (disconnect internet, send empty prompt) to verify error handling works. **User experience:** never show raw errors; always have story-appropriate failure messages ("The crystal ball is cloudy...").

Dependencies:
* T14.G6.09.02: Handle AI response errors and timeouts gracefully
* T14.G5.18: Trace animation state through multiple frames


ID: T14.G6.16
Topic: T14 – Stories & Animation
Skill: Design a dialog system with speaker management
Description: Build a reusable dialog system that manages conversations between multiple characters. **Dialog System components:** (1) DialogManager sprite (invisible controller). (2) Dialog data in lists: `[dialogLines v]` contains "Speaker:Text" formatted lines. (3) `[currentLineIndex v]` tracks position in conversation. (4) Custom block `ShowNextLine` parses current line, identifies speaker, broadcasts to that character, advances index. **Speaker management:** each character sprite has `when I receive [speak_CharacterName]` that reads from shared `[currentDialogText v]` variable and speaks. **Conversation flow:** `when I receive [StartConversation]` → reset index → `repeat until <(currentLineIndex) > (length of [dialogLines v])>` with `ShowNextLine`, `wait until <(done speaking)>`. **Benefits:** change dialogue by editing list data only; add characters by adding receive blocks; reuse system across projects. **Debug:** wrong character speaks → check speaker name parsing; dialogue skips lines → check index increment logic.

Dependencies:
* T14.G6.02: Store and iterate dialogue using lists
* T14.G6.03: Create cutscene controllers with custom blocks


ID: T14.G6.17
Topic: T14 – Stories & Animation
Skill: Evaluate AI-generated content for quality and appropriateness
Description: Develop critical evaluation skills for AI-generated story content. **Quality criteria checklist:** (1) Coherence: Does it make logical sense? Does it contradict established story facts? (2) Character voice: Does it sound like the character should sound? Is vocabulary appropriate? (3) Age appropriateness: Is content suitable for target audience? No violence, fear, or mature themes beyond age level. (4) Creativity: Is it interesting and engaging, or generic and predictable? (5) Length: Is response too short (unhelpful) or too long (overwhelming)? **Red flags to watch:** sudden topic changes, real-world references that break immersion, content that could upset young users, repetitive phrases, factual errors. **Evaluation workflow:** AI generates → you read completely → evaluate against criteria → accept/reject/request revision. **Teaching AI to improve:** when rejecting, note WHY in your next prompt: "That was too long. Give me 2 sentences maximum." Over time, your prompts improve.

Dependencies:
* T14.G5.24: Use AI to generate story ideas - brainstorming partner
* T14.G6.09.01: Design effective ChatGPT prompts for character voices


ID: T14.G7.01
Topic: T14 – Stories & Animation
Skill: Design centralized scene manager architecture
Description: Create a dedicated invisible "SceneManager" sprite that controls all story flow. **Architecture:** SceneManager stores `[currentScene v]`, broadcasts scene changes, tracks story state. **Centralized control:** `broadcast (join [Scene] (currentScene))` triggers all sprite/widget updates. **Widget coordination:** SceneManager also controls widget visibility per scene. **Benefits:** single source of truth for story state; easier debugging; simple to add new scenes. **Pattern:** `when green flag clicked` → initialize → `broadcast [Scene1]`; scene-change events → update currentScene → broadcast new scene. Design your story architecture before coding individual sprites.

Dependencies:
* T14.G6.03: Create cutscene controllers with custom blocks
* T14.G5.01: Debug and test multi-sprite scene coordination
* T15.G5.01: Hide and show widgets





ID: T14.G7.02
Topic: T14 – Stories & Animation
Skill: Parse structured text using delimiter splitting
Description: Extract parts from structured text by finding delimiter positions. **Algorithm:** loop through text to find ":" position, then extract before/after. `set [i v] to (1)`, `repeat until <(letter (i) of (text)) = [:]>` with `change [i v] by (1)`. **Extract parts:** `set [speaker v] to (letters (1) to ((i) - (1)) of (text))`, `set [dialogue v] to (letters ((i) + (2)) to (length of (text)) of (text))`. **Example:** "Alice: Hello!" → speaker = "Alice", dialogue = "Hello!". Use for parsing dialogue data, config strings, or any structured text format.

Dependencies:
* T14.G6.02: Store and iterate dialogue using lists
* T11.G5.17: Use text operations to extract substrings





ID: T14.G7.03
Topic: T14 – Stories & Animation
Skill: Build automated dialogue system with speaker tags
Description: Create data-driven dialogue where list items contain "Speaker: Text" format. **Data:** `[dialogueData v]` contains "Alice: Hello!", "Bob: Hi Alice!", etc. **Playback loop:** parse each line into speaker/dialogue, broadcast `(join [speak_] (speaker))`. **Sprite response:** each character has `when I receive [speak_Alice]` → `say (dialogue)`. **Benefits:** edit conversations by changing list data; sprites automatically speak their lines; easy to extend with new characters. Design dialogue as structured data that drives automated presentation.

Dependencies:
* T14.G7.02: Parse structured text using delimiter splitting
* T14.G6.02: Store and iterate dialogue using lists




ID: T14.G7.04
Topic: T14 – Stories & Animation
Skill: Build adaptive narrative with AI-driven responses
Description: Combine ChatGPT with story state for contextually-aware AI dialogue. **Context-aware prompts:** include story state in prompt: `ask ChatGPT (join [The player has made these choices: ] (join (playerHistory) [. As the wizard character, respond to their question about...])) and wait`. **Memory pattern:** store key player choices in list → include summary in AI prompts → AI responses reference past decisions. **Adaptive NPCs:** AI generates different responses based on player's accumulated karma/trust/relationship values. **Guardrails:** validate AI responses fit story; have fallback dialogue if AI fails. Design prompt templates that produce consistent, story-appropriate responses while allowing AI creativity.

Dependencies:
* T14.G6.09: Generate character dialogue with ChatGPT blocks
* T14.G7.03: Build automated dialogue system with speaker tags




ID: T14.G7.04.01
Topic: T14 – Stories & Animation
Skill: Maintain narrative coherence with AI context management
Description: Keep AI-generated content consistent with story logic using context windows. **Context accumulation:** build conversation history: `add (join [Player: ] (playerInput)) to [chatHistory v]`, `add (join [NPC: ] (aiResponse)) to [chatHistory v]`. **Context in prompts:** include recent history in each prompt: `ask ChatGPT (join [Story so far: ] (join (historyText) [. Now respond to...])) and wait`. **Memory limits:** summarize old events rather than including everything; keep recent 5-10 exchanges verbatim. **Coherence checks:** verify AI doesn't contradict established facts; include key facts in every prompt ("Remember: the princess is actually a dragon in disguise"). Debug: AI forgets plot points → include them explicitly in system prompt.

Dependencies:
* T14.G7.04: Build adaptive narrative with AI-driven responses




ID: T14.G7.05
Topic: T14 – Stories & Animation
Skill: Design procedural animation sequences with mathematical patterns
Description: Generate complex animations using mathematical formulas. **Sine wave motion:** `forever { set y to ((100) * (sin of ((timer) * (180)))) }` creates smooth up-down bobbing. **Circular motion:** `set x to ((radius) * (cos of (angle)))`, `set y to ((radius) * (sin of (angle)))`, `change [angle v] by (5)` creates orbit. **Easing functions:** slow-start: `change x by ((targetX - x) / (10))` creates deceleration effect. **Breathing animation:** `set size to ((100) + ((10) * (sin of ((timer) * (90)))))` creates subtle breathing. **Figure-8 pattern:** combine two sine waves with different frequencies for complex paths. Trace mathematical values through animation frames to understand patterns.

Dependencies:
* T14.G6.01: Implement animation state machines with variables
* T14.G5.15: Calculate and synchronize animation timing




ID: T14.G7.06
Topic: T14 – Stories & Animation
Skill: Implement parallax scrolling for depth effect
Description: Create illusion of depth by moving background layers at different speeds. **Layer setup:** create 3+ background sprites (far, middle, near). **Parallax movement:** when scrolling, far layer `change x by (-1)`, middle layer `change x by (-3)`, near layer `change x by (-5)`. Slower movement = farther away. **Infinite scrolling:** when sprite reaches edge, teleport to opposite side: `if <(x position) < (-500)> then change x by (1000)`. **Vertical parallax:** use same technique with Y for up/down scrolling (platformers, elevators). **Combined with camera:** parallax layers move opposite to "camera" direction. Trace layer positions to verify correct relative speeds.

Dependencies:
* T14.G5.03: Simulate camera panning by moving all sprites together
* T14.G5.04.01: Control sprite layer order with layer blocks




ID: T14.G7.07
Topic: T14 – Stories & Animation
Skill: Create procedural story generation with AI assistance
Description: Build systems that generate unique story content each playthrough. **Story seed prompts:** "Generate a unique quest: give me a quest-giver name, quest objective, and reward in JSON format: {name: '', objective: '', reward: ''}". **Parse AI response:** extract structured data from AI output using delimiter parsing. **Combine elements:** mix AI-generated content with hand-crafted story structure. **Procedural characters:** generate NPC names, backstories, dialogue from templates + AI. **Replayability:** each playthrough gets unique AI-generated elements while maintaining consistent story beats. **Quality control:** validate AI output fits game constraints; regenerate if invalid. Design hybrid systems where human-authored structure meets AI-generated variety.

Dependencies:
* T14.G7.04.01: Maintain narrative coherence with AI context management
* T14.G7.02: Parse structured text using delimiter splitting








ID: T14.G7.08
Topic: T14 – Stories & Animation
Skill: Design camera movement systems for storytelling
Description: Build reusable camera control systems for cinematic storytelling. **Camera pan system:** custom block `PanCamera (direction) (distance) (duration)` coordinates all sprites moving together: `broadcast (join [CameraPan] (direction))` with each sprite responding via `when I receive [CameraPanLeft]` then `repeat (frames) { change x by (stepSize) }`. **Zoom system:** `ZoomCamera (factor) (duration)` scales all sprites proportionally from center. **Follow camera:** `FollowSprite (targetName)` keeps target centered by adjusting all other sprites accordingly. **Transition library:** create custom blocks for fade transitions, wipe effects, zoom transitions. Debug: sprites move at different speeds means verify all sprites use same step calculation; zoom looks off-center means ensure all sprites scale relative to stage center (0,0). Design modular camera system before adding cinematic effects.

Dependencies:
* T14.G5.17: Design visual transitions between scenes
* T14.G5.03: Simulate camera panning by moving all sprites together
* T11.G6.01: Create custom blocks with multiple parameters




ID: T14.G7.09
Topic: T14 – Stories & Animation
Skill: Implement conversation memory for AI characters
Description: Build AI characters that remember past player interactions across multiple conversations. **Memory architecture:** (1) Create `[conversationHistory]` list. (2) After each player input and AI response, add to history: `add (join [Player: ] (playerInput)) to [conversationHistory v]`, `add (join [NPC: ] (aiResponse)) to [conversationHistory v]`. (3) In each new prompt, include recent history: `ask ChatGPT (join [Past conversation: ] (join (historyText) (join [. Player now says: ] (playerInput)))) and wait`. (4) Memory management: keep last 8-10 exchanges (too much history makes prompts slow/expensive); summarize old conversations ("Previously: player helped NPC find key, became friends"). **Example with memory:** Player: "Hi wizard!", AI: "Hello again! Still have that key I gave you?", Player: "Yes!", AI: "Good, you'll need it soon." Without memory, AI wouldn't remember giving the key. **Debug:** AI forgets past → increase history length; AI remembers wrong details → clear history between major scene changes.

Dependencies:
* T14.G7.04.01: Maintain narrative coherence with AI context management
* T14.G6.09.01: Design effective ChatGPT prompts for character voices




ID: T14.G7.10
Topic: T14 – Stories & Animation
Skill: Balance AI-generated and hand-written story content
Description: Design hybrid stories that combine AI flexibility with human-authored structure for quality control. **Hybrid architecture:** (1) Hand-write critical path: main plot beats, character introductions, key emotional moments, all endings (ensures quality and coherence). (2) AI-generate variable content: NPC dialogue variations, side quest details, flavor text, random encounters. (3) Define guardrails: AI can generate within boundaries ("Generate merchant dialogue offering 3 items, medieval tone, friendly personality") but cannot change core plot. **Implementation example:** Main quest = hand-written 10 major scenes (fixed, tested, polished). Each scene = 3 AI-generated NPC conversations (variable, replayable each time). Player choices at major scenes = hand-written outcomes (balanced, tested). **Benefits:** replayability (AI content changes each playthrough), quality assurance (critical moments controlled), development efficiency (AI speeds up content creation). **Debug:** AI breaks story flow → narrow AI's scope to less critical content; story feels repetitive → increase AI's creative freedom in safe areas. **Design principle:** human authors define "what" happens (structure), AI fills in "how" it's described (variation).

Dependencies:
* T14.G7.04: Build adaptive narrative with AI-driven responses
* T14.G7.03: Build automated dialogue system with speaker tags




ID: T14.G7.11
Topic: T14 – Stories & Animation
Skill: Version control: Save story iterations for comparison
Description: Systematically save project versions to track changes and enable rollback. **Version control practices in CreatiCode:** (1) Naming convention: ProjectName_v1_initial, ProjectName_v2_addedScenes, ProjectName_v3_fixedBugs. (2) Save frequency: after each major feature addition, before risky changes, at end of each work session. (3) Change log: maintain list of changes per version in project notes ("v2: added Scene 3 castle, fixed timing bug in dialogue, added new character voice"). (4) Compare versions: when testing changes, compare v2 and v1 side-by-side to verify improvement. (5) Rollback strategy: if new version breaks something, remix previous working version and re-apply only the good changes. **Benefits:** experiment safely (can always go back), track progress over time, compare before/after for debugging. **Example scenario:** v3 runs slowly → compare to v2 which was fast → identify what changed between versions → isolate performance issue to the new AI feature added in v3. **Documentation:** in project instructions, maintain version history with dates and key changes. **Debug:** lost good work from earlier version → always save before big changes; can't remember what changed → improve change log detail.

Dependencies:
* T14.G7.01: Design centralized scene manager architecture
* T14.G6.13: Conduct user testing sessions with feedback collection


ID: T14.G7.12
Topic: T14 – Stories & Animation
Skill: Combine animation principles for professional-quality motion
Description: Integrate multiple animation principles into cohesive, professional-quality character animation. **Combined example - character jump:** (1) ANTICIPATION: character crouches (prepare). (2) SQUASH: body compresses at lowest point. (3) STRETCH: body elongates during ascent. (4) EASING: fast launch, slow at apex, fast descent. (5) SQUASH: compress on landing impact. (6) FOLLOW-THROUGH: hair/cape continue moving after body stops. (7) SETTLE: small bounce before rest. **Implementation approach:** create an animation state machine with states for each phase (crouch, launch, airborne, land, settle). Each state applies appropriate principles. **Timing breakdown:** anticipation (0.2s), launch (0.1s), airborne (0.4s), land (0.1s), settle (0.3s) = 1.1s total. **Quality checklist:** Does the animation show weight? Does it feel smooth or jerky? Does it convey the intended emotion? **Professional mindset:** treat animations as opportunities to show character personality - a confident hero jumps differently than a nervous sidekick.

Dependencies:
* T14.G6.14: Design squash and stretch for character weight
* T14.G7.05: Design procedural animation sequences with mathematical patterns


ID: T14.G7.13
Topic: T14 – Stories & Animation
Skill: Profile and optimize animation performance
Description: Identify and fix performance bottlenecks in complex animated stories. **Performance indicators:** frame rate drops below 30fps, animations stutter, long pauses between scenes, AI responses feel slow. **Profiling technique:** add timer checkpoints: `set [startTime v] to (timer)`, run code, `print (join [Section took: ] ((timer) - (startTime)))`. Identify which sections take longest. **Common performance issues and fixes:** (1) Too many sprites moving simultaneously → stagger animations or reduce sprite count. (2) Complex costume drawings each frame → pre-render to costume instead of drawing live. (3) AI calls blocking animation → use parallel scripts or show "loading" animation. (4) Forever loops running on hidden sprites → stop scripts when sprites hide. (5) Large backdrop images → compress images or use smaller backgrounds. **Optimization priority:** fix the slowest section first (biggest impact). **Testing:** test on lower-powered devices (older tablets, school Chromebooks) - if it works there, it works everywhere.

Dependencies:
* T14.G7.05: Design procedural animation sequences with mathematical patterns
* T14.G5.18: Trace animation state through multiple frames


ID: T14.G7.14
Topic: T14 – Stories & Animation
Skill: Build a quest/objective tracking system
Description: Create a reusable system to track player progress through story objectives. **Quest System components:** (1) Quest data structure: `[questID, title, description, status, objectives[]]`. (2) Objective structure: `[objectiveID, description, required, current, isComplete]`. (3) QuestManager sprite tracks active quests and objectives. **Core functions:** `StartQuest(questID)` adds quest to active list. `UpdateObjective(questID, objectiveID, amount)` increments progress. `CheckQuestComplete(questID)` returns true if all objectives met. **UI integration:** display active quest in corner label widget; update when objectives change. **Event integration:** when player picks up key → `UpdateObjective("findKey", "key1", 1)`; when all objectives complete → trigger quest completion cutscene. **Benefits:** modular quest design; easy to add new quests; player always knows their goal. **Debug:** objective doesn't update → verify event triggers UpdateObjective; quest never completes → check all objective completion conditions.

Dependencies:
* T14.G7.01: Design centralized scene manager architecture
* T14.G6.02: Store and iterate dialogue using lists


ID: T14.G7.15
Topic: T14 – Stories & Animation
Skill: Use AI for localization and translation assistance
Description: Leverage AI to help create multilingual story content. **Translation workflow:** (1) Write complete story in primary language. (2) For each dialogue line, use ChatGPT: `ask ChatGPT [Translate to Spanish, keeping the same tone and length: "Hello brave hero!"] and wait`. (3) Store translations in parallel lists: `[dialogueEN v]`, `[dialogueES v]`, `[dialogueFR v]`. (4) At runtime, select list based on `(playerLanguage)` setting. **Quality control:** AI translations need human review - have native speakers verify key dialogue. **Localization vs translation:** localization adapts cultural references too (not just words). Ask AI: "How would a Spanish-speaking child say this?" vs just "Translate to Spanish." **Technical integration:** combine with TTS language selection so audio matches text language. **Testing:** play through story in each language to catch missed translations or awkward phrasing. **Efficiency tip:** batch translations - give AI multiple lines at once in numbered format for faster processing.

Dependencies:
* T14.G6.04: Build multi-language stories with conditional TTS
* T14.G6.17: Evaluate AI-generated content for quality and appropriateness


ID: T14.G8.01
Topic: T14 – Stories & Animation
Skill: Design branching story node data structures
Description: Plan nested list structures for branching narratives. **Node structure:** [nodeID, dialogueText, [[choice1Text, nextNodeID], [choice2Text, nextNodeID], ...]]. **Example:** ["start", "You're in a forest. Go left or right?", [["Go left", "leftPath"], ["Go right", "rightPath"]]]. **Design process:** diagram story branches on paper → assign unique IDs to each node → define node data → implement as nested lists. **Navigation:** store currentNodeID → find node with matching ID → display dialogue → show choices → player selects → update currentNodeID. Plan data structure thoroughly before coding.

Dependencies:
* T14.G7.03: Build automated dialogue system with speaker tags
* T10.G6.01: Use nested lists or tables for structured data





ID: T14.G8.01.01
Topic: T14 – Stories & Animation
Skill: Display story node content and choices
Description: Extract and display content from story nodes. **Display dialogue:** find current node → extract dialogue text (item 2) → display in textbox or say block. **Display choices:** extract choices list (item 3) → loop through choices → create button for each with choice text (item 1 of each choice). **Dynamic UI:** remove old choice buttons before creating new ones for current node. Trace: currentNodeID = "start" → find start node → display "You're in a forest..." → create "Go left" and "Go right" buttons.

Dependencies:
* T14.G8.01: Design branching story node data structures
* T14.G6.07: Display formatted text with rich textbox widgets





ID: T14.G8.01.02
Topic: T14 – Stories & Animation
Skill: Navigate story graph based on player choices
Description: Process player choice selection to navigate the story. **Pattern:** `when widget [choice1] clicked` → extract next node ID from choice data (item 2 of choice) → `set [currentNodeID v] to (nextID)` → call display function for new node. **Loop:** display node → player chooses → navigate to next node → display new node → repeat until ending. **Ending detection:** if choices list is empty, node is an ending. Trace: player clicks "Go left" → nextID = "leftPath" → currentNodeID = "leftPath" → display leftPath node.

Dependencies:
* T14.G8.01.01: Display story node content and choices





ID: T14.G8.02
Topic: T14 – Stories & Animation
Skill: Implement accessibility features in interactive stories
Description: Design accessible stories for users with different abilities. **Visual impairment:** add TTS narration for all text; describe images/scenes in audio. **Hearing impairment:** display subtitle widgets synchronized with audio; use visual cues instead of sound-only feedback. **Motor impairment:** provide keyboard alternatives to all mouse interactions; larger click targets; timing adjustments. **Cognitive:** clear language; consistent navigation; save progress frequently. Test with accessibility tools; involve users with disabilities in testing.

Dependencies:
* T14.G7.03: Build automated dialogue system with speaker tags
* T14.G6.11: Combine TTS with dialogue for narrated interactive stories
* T15.G7.03: Design an accessible interface for users with different abilities




ID: T14.G8.02.01
Topic: T14 – Stories & Animation
Skill: Test accessibility features with screen reader simulation
Description: Validate accessibility by simulating assistive technology usage. **Screen reader testing:** play story with eyes closed using only TTS audio; verify all information is conveyed audibly. **Keyboard navigation testing:** unplug mouse; verify all interactions possible with keyboard alone. **Timing testing:** verify users have adequate time to read/respond; test with 2x time limits. **Color blindness testing:** verify information isn't conveyed by color alone; use patterns or labels alongside colors. **Checklist approach:** document each accessibility requirement; systematically verify each. **User testing:** ideally test with actual users who use assistive technology. Debug: information only visible (not audible) → add TTS narration; timed interactions too fast → add pause/extend options.

Dependencies:
* T14.G8.02: Implement accessibility features in interactive stories





ID: T14.G8.03
Topic: T14 – Stories & Animation
Skill: Encode story state into save strings
Description: Serialize story state for saving/loading. **Encode pattern:** use joins with delimiter: `set [save v] to (join (nodeID) (join [|] (join (score) (join [|] (hasKey)))))` → "forest|50|true". **Save options:** cloud variable `set [☁ save v] to (saveData)` (persistent, requires account); display code for manual copy `say [Your code: ] (saveData)` (works offline). **What to save:** current node, score variables, inventory flags, important choices made. Design save data to capture complete game state with minimal string length.

Dependencies:
* T14.G8.01.02: Navigate story graph based on player choices
* T14.G7.02: Parse structured text using delimiter splitting
* T09.G6.01: Model real-world quantities using variables and formulas





ID: T14.G8.03.01
Topic: T14 – Stories & Animation
Skill: Load and restore story state from save strings
Description: Deserialize save strings to restore game progress. **Load source:** cloud variable `set [saveData v] to (☁ save)` or player input via textbox. **Parse:** use delimiter splitting (T14.G7.02) to extract parts. **Restore:** `set [nodeID v] to (part1)`, `set [score v] to (part2)`, `set [hasKey v] to (part3)`. **Resume:** `broadcast (join [Node] (nodeID))` to jump to saved position. **Testing:** verify all state variables restore correctly; test edge cases (empty save, corrupted data). Design robust parsing that handles errors gracefully.

Dependencies:
* T14.G8.03: Encode story state into save strings
* T14.G7.02: Parse structured text using delimiter splitting





ID: T14.G8.04
Topic: T14 – Stories & Animation
Skill: Create 3D speech bubbles in 3D environments
Description: Use `show speech bubble [Hello!] offset xyz (0) (0) (110) max width (200) text font [Arial] size (15) color [#000000FF] background [#FFFFFFFF] for [3] seconds camera facing [Yes] ID [1]` for 3D storytelling. **3D vs 2D bubbles:** 3D bubbles float at XYZ offset from sprite; 2D bubbles appear above sprite on screen. **Camera facing:** [Yes] rotates bubble to always face camera (readable from any angle). **Multiple bubbles:** different ID values for simultaneous bubbles on same sprite. **Offset:** (0, 0, 110) places bubble 110 units above sprite center. Use for immersive 3D stories and character dialogue.

Dependencies:
* T14.G6.07: Display formatted text with rich textbox widgets
* T16.G7.01: Create and control 3D sprite objects





ID: T14.G8.05
Topic: T14 – Stories & Animation
Skill: Create personalized stories with camera integration
Description: Use `add camera widget at X (0) Y (0) width (320) height (240) from [front] mode [normal] as [cam1]` for live camera in stories. **Capture photo:** `save picture from camera [cam1] as costume [playerPhoto]` → `switch costume to [playerPhoto]` to use player's face on a character sprite. **Camera options:** from = front (selfie) / back (outward); mode = normal / flipped (mirror). **Privacy pattern:** show camera briefly, capture, hide widget. **Creative uses:** player becomes story character; object recognition for choices; photo booth scenes. Requires camera permission.

Dependencies:
* T14.G7.01: Design centralized scene manager architecture
* T15.G6.01: Add and control camera widgets




ID: T14.G8.06
Topic: T14 – Stories & Animation
Skill: Build collaborative multiplayer story with cloud variables
Description: Create shared storytelling experiences using cloud variables. **Shared story state:** use cloud variables `☁ currentScene`, `☁ storyChoices` to synchronize state across players. **Turn-based storytelling:** `☁ currentWriter` tracks who's writing; other players see updates in real-time. **Collaborative voting:** multiple players vote on story choices; most votes determine path: `change [☁ voteA v] by (1)`. **Real-time updates:** poll cloud variables to detect changes: `if <not <(☁ scene) = (lastScene)>>` then update display. **Conflict resolution:** use timestamps or player IDs to handle simultaneous edits. **Architecture:** one player hosts (makes decisions), others observe; or democratic voting on all choices. Design collaborative stories that remain coherent with multiple contributors.

Dependencies:
* T14.G8.01.02: Navigate story graph based on player choices
* T14.G7.01: Design centralized scene manager architecture




ID: T14.G8.07
Topic: T14 – Stories & Animation
Skill: Design story template system for reusable narratives
Description: Create modular story templates that can be filled with different content. **Template structure:** define slots for character names, locations, objects, outcomes. **Data separation:** story template in one list (with placeholders like {HERO}, {VILLAIN}), content data in another list. **Template rendering:** replace placeholders with actual content: loop through template, find {PLACEHOLDER}, replace with value from content list. **Reusable components:** build library of scene templates (introduction, conflict, resolution) that can be combined differently. **User-generated stories:** let players fill in template slots to create their own stories using your narrative structure. **Benefits:** one story engine powers multiple narratives; easy to add new stories by defining content data. Design templates that produce coherent stories regardless of content filled in.

Dependencies:
* T14.G8.01: Design branching story node data structures
* T14.G7.02: Parse structured text using delimiter splitting




ID: T14.G8.08
Topic: T14 – Stories & Animation
Skill: Build interactive fiction with real-time AI narration
Description: Create open-ended interactive fiction where AI generates the narrative in real-time. **Game loop:** display current situation → player types action → AI generates outcome → update state → repeat. **Persistent world state:** track location, inventory, NPCs met, choices made in variables/lists. **AI prompt design:** include world state, allowed actions, narrative style in each prompt. **Example prompt:** "Setting: medieval fantasy. Player is in [location] with [inventory]. They said: [playerInput]. Describe what happens next in 2-3 sentences, second-person narrative." **Guardrails:** detect and handle out-of-bounds actions ("You can't fly in this story"); maintain consistency with established facts. **Save system:** serialize world state for save/load. Design AI prompts that produce engaging, consistent, interactive narratives.

Dependencies:
* T14.G7.04.01: Maintain narrative coherence with AI context management
* T14.G8.01.02: Navigate story graph based on player choices


ID: T14.G8.09
Topic: T14 – Stories & Animation
Skill: Design multi-modal storytelling combining text, voice, and visuals
Description: Orchestrate synchronized presentation across multiple modalities. **Modal coordination:** when dialogue displays, TTS speaks same text, character animation shows talking. **Timing synchronization:** TTS duration varies by text length; use TTS callback or estimate duration to sync animations. **Modal preferences:** let users choose preferred mode (text-only, audio-only, both); store preference variable. **Accessibility by design:** text for deaf users, audio for blind users, visuals for everyone. **Emotional enhancement:** match TTS parameters to text mood; sync background music to narrative beat; visual effects reinforce story moments. **Implementation pattern:** `broadcast [StoryMoment]` triggers: (1) text display, (2) TTS playback, (3) animation, (4) sound effects - all coordinated by timing variables. Design stories that leverage multiple modalities for maximum emotional impact and accessibility.

Dependencies:
* T14.G6.11: Combine TTS with dialogue for narrated interactive stories
* T14.G8.02: Implement accessibility features in interactive stories
* T14.G7.01: Design centralized scene manager architecture


ID: T14.G8.10
Topic: T14 – Stories & Animation
Skill: Implement cinematic camera techniques in 2D stories
Description: Apply film camera techniques to enhance 2D storytelling. **Zoom effects:** all sprites scale up for "close-up" → emphasizes emotion; scale down for "wide shot" → shows environment. **Pan and tracking:** smooth sprite movement simulates camera following character. **Dutch angle:** rotate sprites slightly for tension/unease. **Shot composition:** apply rule of thirds by positioning key elements at intersection points (±80 x, ±60 y). **Cutaway technique:** briefly show reaction shots by hiding main action, showing observer sprite reaction, returning. **Shot sequence:** establishing shot (wide) → medium shot → close-up for emotional moments → back to medium. **Timing:** dramatic beats use slower transitions; action uses quick cuts. Design scenes thinking like a film director choosing camera angles.

Dependencies:
* T14.G7.08: Design camera movement systems for storytelling
* T14.G7.05: Design procedural animation sequences with mathematical patterns







ID: T14.G8.11
Topic: T14 – Stories & Animation
Skill: Optimize performance for AI-heavy interactive stories
Description: Reduce lag and improve responsiveness in stories that heavily use AI features. **Performance optimization techniques:** (1) AI call minimization: cache AI responses in lists for reuse - \`if <(cached response for (characterName)) = []> then ask ChatGPT... else use (cached response)\`; pre-generate common responses at project start. (2) Async patterns: use \`ask ChatGPT... and wait\` only when response needed immediately; for background generation, use parallel scripts to pre-generate while player reads other content. (3) User feedback during waits: show "Character is thinking..." animation during AI calls so app doesn't feel frozen. (4) Fallback content: if AI takes >5 seconds, use pre-written backup dialogue with timer. (5) Batch AI calls: generate multiple responses in one prompt rather than separate calls. **Performance testing:** measure time from player input to response display; target <2 seconds for good UX, <1 second for excellent. **Debug:** long delays → add loading indicators and check if responses can be pre-generated.

Dependencies:
* T14.G7.04: Build adaptive narrative with AI-driven responses
* T14.G6.09.02: Handle AI response errors and timeouts gracefully




ID: T14.G8.12
Topic: T14 – Stories & Animation
Skill: Design culturally inclusive story content with AI assistance
Description: Create stories that respect diverse cultural perspectives and avoid stereotypes. **Cultural inclusivity checklist:** (1) Character diversity: ensure cast includes varied backgrounds; avoid tokenism (diverse characters have depth, not just surface traits). (2) Stereotype avoidance: use AI to check for biased tropes. (3) Research authenticity: if including specific cultural elements, research respectfully. (4) Language accessibility: offer stories in multiple languages using TTS language options. (5) Universal themes: build stories around experiences that resonate across cultures (friendship, courage, kindness). **AI assistance for inclusivity:** use ChatGPT for cultural sensitivity checks, translation suggestions, identifying unintentional bias. **Testing:** share with readers from diverse backgrounds and genuinely listen to feedback about representation.

Dependencies:
* T14.G6.04: Build multi-language stories with conditional TTS
* T14.G7.04: Build adaptive narrative with AI-driven responses
* T14.G8.02: Implement accessibility features in interactive stories




ID: T14.G8.13
Topic: T14 – Stories & Animation
Skill: Create portfolio-ready story with documentation
Description: Polish and document a complete story project for portfolio presentation. **Portfolio preparation checklist:** (1) Title screen: project name, author credit, clear "Start" button. (2) Instructions: brief "How to Play" guide accessible from title screen. (3) Credits: acknowledge all assets used. (4) Code documentation: clear comments explaining complex scripts, consistent naming conventions. (5) Project description: write 2-3 sentence description in project notes. (6) Testing: verify runs smoothly start-to-finish with no bugs. (7) Sharing: set project to Public with appropriate tags. **Quality standards:** all dialogue readable, no placeholder text, consistent visual style, background music doesn't clash. **Presentation:** prepare 60-second verbal pitch explaining story concept, target audience, interesting features.

Dependencies:
* T14.G8.02: Implement accessibility features in interactive stories
* T14.G8.01.02: Navigate story graph based on player choices
* T14.G6.13: Conduct user testing sessions with feedback collection


ID: T14.G8.14
Topic: T14 – Stories & Animation
Skill: Implement automated story testing
Description: Create systematic automated tests to verify story functionality without manual playthroughs. **Test automation strategies:** (1) Path verification: script that automatically clicks through each story path and logs endpoints reached - verify all paths terminate at valid endings. (2) State validation: at key checkpoints, automatically verify variables have expected values (Trust > 0 after help scene, inventory contains key after pickup). (3) Timing tests: verify animations complete within expected duration using timer checks. (4) Regression tests: save known-good variable snapshots, after changes verify same inputs produce same outputs. **Implementation:** create TestRunner sprite with `RunAllTests` custom block that executes test sequences and logs pass/fail results. **Test data:** maintain list of test cases `[testName, expectedResult]`. **Continuous testing:** run tests after every major change to catch bugs early. **Benefits:** faster bug detection, confidence to make changes, documentation of expected behavior. **Limitation:** automated tests verify functionality, not story quality - still need human playtesting for engagement and fun.

Dependencies:
* T14.G8.01.02: Navigate story graph based on player choices
* T14.G7.13: Profile and optimize animation performance


ID: T14.G8.15
Topic: T14 – Stories & Animation
Skill: Create a complete save/load game state system
Description: Build a comprehensive save system that preserves and restores complete story state. **State to save:** current scene/node ID, all story variables (trust, inventory flags, choices made), quest progress, character states, timestamp. **Serialization format:** use delimiter-separated string: `sceneID|var1=val1|var2=val2|quest1:complete|...`. **Save function:** gather all state → serialize to string → store in cloud variable or display as code for player to copy. **Load function:** get save string → parse using delimiters → restore each variable → broadcast scene change to saved scene. **Save slots:** allow multiple saves by storing in different cloud variables or numbered lists. **Autosave:** automatically save at scene transitions or before major choices. **Validation:** verify save string format is valid before loading; handle corrupted saves gracefully with error message. **Security:** don't store sensitive info; validate loaded values are within expected ranges. **User interface:** add Save/Load buttons to pause menu; show save timestamps.

Dependencies:
* T14.G8.03: Encode story state into save strings
* T14.G7.14: Build a quest/objective tracking system


ID: T14.G8.16
Topic: T14 – Stories & Animation
Skill: Design modular scene templates for reusable narratives
Description: Create generic scene templates that can be instantiated with different content for rapid story development. **Template types:** (1) DialogScene: takes speaker list and dialogue list, handles conversation flow. (2) ChoiceScene: takes prompt and choice list, handles branching. (3) CutsceneScene: takes animation sequence data, plays cutscene. (4) ExplorationScene: takes interactive objects list, handles click interactions. **Template interface:** each template has `Initialize(data)`, `Run()`, `GetResult()`. **Content data:** store scene content in structured lists: `["dialog", "Alice", "Hello!", "Bob", "Hi!"]` feeds DialogScene template. **Benefits:** add new scenes by creating content data, not new code; consistent scene behavior; easier debugging (fix template once, fixes all instances); faster development. **Template library:** build up library of tested templates over time; share templates between projects. **Customization hooks:** templates accept optional styling/behavior parameters for variation.

Dependencies:
* T14.G8.07: Design story template system for reusable narratives
* T14.G7.01: Design centralized scene manager architecture


ID: T14.G8.17
Topic: T14 – Stories & Animation
Skill: Design ethical AI character interactions
Description: Create AI-powered characters that interact responsibly and safely with young users. **Ethical design principles:** (1) Transparency: AI characters should not pretend to be human or claim abilities they don't have. (2) Boundaries: AI should redirect inappropriate conversations gracefully ("Let's talk about our adventure instead!"). (3) No manipulation: AI should not pressure users into decisions or create artificial urgency. (4) Emotional safety: AI should not frighten, shame, or upset young users; responses should be encouraging and supportive. (5) Privacy: AI should not ask for or store personal information. **Implementation:** include ethical constraints in EVERY AI prompt: "You are a friendly wizard. Never ask personal questions. If the user seems upset, be supportive and suggest taking a break." **Content filtering:** check AI responses for red flags before displaying. **Fallback behavior:** if AI generates inappropriate content, switch to pre-written safe dialogue immediately. **Testing:** have adults roleplay as children trying to push boundaries to verify safeguards work. **Documentation:** document all AI safety measures for parents/teachers.

Dependencies:
* T14.G8.12: Design culturally inclusive story content with AI assistance
* T14.G7.09: Implement conversation memory for AI characters


ID: T14.G8.18
Topic: T14 – Stories & Animation
Skill: Architect large-scale interactive narrative systems
Description: Design and implement complex interactive fiction systems with hundreds of scenes and multiple storylines. **Architecture patterns for scale:** (1) Scene graph database: store all nodes in structured table, query by ID, handle relationships. (2) Lazy loading: only load current scene + adjacent scenes into memory; load others on demand. (3) Modular storylines: separate main plot, side quests, random events into independent modules that combine at runtime. (4) Event bus: central system receives all game events (choices, pickups, dialogue) and routes to interested systems (quest tracker, achievement system, analytics). (5) Save compression: for large state, compress save data; store deltas from default state. **Team development:** design clear interfaces between systems so multiple people can work simultaneously; document API contracts. **Content pipeline:** create tools/spreadsheets for writers to author content without touching code. **Analytics:** track which paths players take to identify popular/unpopular content for future development. **Performance at scale:** profile memory and processing; implement loading screens for heavy transitions. This skill represents professional-level interactive narrative development.

Dependencies:
* T14.G8.16: Design modular scene templates for reusable narratives
* T14.G8.15: Create a complete save/load game state system


# T15 - User Interfaces (Phase 9 - Major Redesign November 2025)
# PHASE 9 TRANSFORMATION: Problem-Centered UI Design & Modern UX Practices
#
# CORE PHILOSOPHY: UI is PROBLEM-SOLVING through COMMUNICATION
# - Every interface solves a specific human problem
# - Design thinking: Empathize → Define → Ideate → Prototype → Test
# - Computational thinking applies to UI: decomposition, patterns, abstraction
#
# ============ PHASE 9 MAJOR STRUCTURAL CHANGES ============
#
# 1. PROBLEM-FIRST DESIGN THREAD (K-G2) - NEW
#    - K.01.02: Identify what problem an interface solves
#    - G1.01.02: Match user problems to interface solutions
#    - G2.01.01: Define a problem before designing an interface
#    - Replaces passive "recognition" with active "problem identification"
#
# 2. WIDGET COMMUNICATION SKILLS (G3-G4) - NEW
#    - G3.09: Pass data from one widget to another
#    - G3.10: Coordinate multiple widgets to complete a task
#    - G4.14: Build widget chains where output becomes input
#    - Teaches data flow explicitly before complex UIs
#
# 3. MICRO-INTERACTION DESIGN (G4-G5) - NEW
#    - G4.15: Design feedback timing for user actions
#    - G5.11: Create transition animations between states
#    - G5.12: Apply the 3-second rule for feedback
#    - Professional-level attention to interaction details
#
# 4. USER RESEARCH SKILLS (G6-G7) - NEW
#    - G6.09: Create user personas for design decisions
#    - G6.10: Write user stories (As a... I want... So that...)
#    - G7.12: Map user journeys through an interface
#    - G7.13: Conduct lightweight user interviews
#    - Brings real UX research practices to students
#
# 5. DESIGN SYSTEM THINKING (G7-G8) - EXPANDED
#    - G7.14: Define a color palette and typography scale
#    - G7.15: Create spacing and sizing standards
#    - G8.15: Build a component library with documentation
#    - G8.16: Version and evolve a design system
#    - Prepares for professional-scale UI development
#
# 6. AI-HUMAN COLLABORATION (G8) - ENHANCED
#    - G8.17: Use AI to generate and refine UI mockups iteratively
#    - G8.18: Implement AI copilot features in interfaces
#    - G8.19: Design human-in-the-loop AI interfaces
#    - Reflects reality where AI assists but humans decide
#
# 7. DEBUGGING MASTERY PROGRESSION - STRENGTHENED
#    - G3: Debug widget naming and value retrieval
#    - G4: Debug event handling and widget interactions
#    - G5: Debug form validation and state management
#    - G6: Debug responsive layouts and cross-device issues
#    - G7: Debug accessibility and performance
#    - G8: Debug complex systems and AI integrations
#
# 8. REAL-WORLD UI PATTERNS - COMPREHENSIVE
#    - G4.13: List-detail pattern
#    - G5.13: Master-detail with editing
#    - G6.11: CRUD interfaces
#    - G7.16: Search/filter/sort combination
#    - G8.20: Dashboard composition patterns
#
# SKILL DISTRIBUTION:
# Total: 145 skills (K:10, G1:10, G2:9, G3:19, G4:21, G5:24, G6:17, G7:18, G8:21)
# +17 new skills, restructured for better progression and modern practices

# ============ KINDERGARTEN (10 skills) ============
# Focus: Recognize interface elements and understand interfaces solve problems

ID: T15.K.01
Topic: T15 – User Interfaces
Skill: Identify buttons in everyday interfaces (pictures)
Description: **Student task:** Look at 4 pictures of everyday devices (remote control, microwave, tablet, toy robot) and tap all the buttons you can find. **Visual scenario:** Each device shows clickable button regions in various shapes. **Correct answers:** Tap 2-3 buttons on each device. _Implementation: Tap-to-select; audio says "Buttons are things we press to make something happen!"_

Dependencies:
* None


ID: T15.K.01.01
Topic: T15 – User Interfaces
Skill: Explain why we need buttons (pictures)
Description: **Student task:** Look at two pictures: one shows a person standing confused in front of a machine with no buttons; the other shows a person happily pressing a button on a similar machine. Tap which picture shows someone who can use the machine. **Visual scenario:** Vending machine without buttons (person puzzled) vs. vending machine with "Push" buttons (person getting snack). **Discussion prompt:** Audio asks "Why do we need buttons? They help us tell the machine what to do!" _Introduces concept that interfaces are for communication between humans and machines._ Implementation: Tap-to-select with audio explanation.

Dependencies:
* T15.K.01: Identify buttons in everyday interfaces (pictures)


ID: T15.K.01.02
Topic: T15 – User Interfaces
Skill: Identify what problem an interface solves (pictures)
Description: **Student task:** Look at pictures of interfaces and tap what PROBLEM each one solves. **Visual scenario:** (1) TV remote → choose from "turn on the TV" or "make food", (2) Microwave buttons → "heat food" or "play music", (3) Phone touchscreen → "talk to someone far away" or "water plants". **Discussion:** Audio says "Every interface helps us solve a problem! The remote solves the problem of turning on the TV without walking to it." _Introduces problem-centered thinking about interfaces._ Implementation: Match interface to problem with audio explanation.

Dependencies:
* T15.K.01.01: Explain why we need buttons (pictures)


ID: T15.K.02
Topic: T15 – User Interfaces
Skill: Recognize text displays and labels (pictures)
Description: **Student task:** Look at 4 pictures (TV showing channel number, microwave showing time, elevator showing floor, tablet showing app name) and tap where text/numbers appear. **Visual scenario:** Each device has information displays. _Implementation: Tap-to-select; audio says "Displays show us information!"_

Dependencies:
* T15.K.01: Identify buttons in everyday interfaces (pictures)


ID: T15.K.03
Topic: T15 – User Interfaces
Skill: Identify icons and pictures in interfaces (pictures)
Description: **Student task:** Look at 4 interface screens and tap all the little pictures (icons) you see. **Visual scenario:** Home screen with icons (phone icon, camera icon, music note, settings gear), game menu with picture buttons. **Correct answers:** Tap icons like hearts, stars, arrows, home symbol. _Implementation: Tap-to-select; audio says "Icons are little pictures that show us what things do!"_

Dependencies:
* T15.K.02: Recognize text displays and labels (pictures)


ID: T15.K.04
Topic: T15 – User Interfaces
Skill: Sort interface elements by type (pictures)
Description: **Student task:** Drag 6 interface element pictures into 2 buckets: "Things we press" (buttons) and "Things we look at" (displays). **Visual scenario:** Play button, power button, volume button vs. score counter, timer, message display. _Implementation: Drag-and-drop sorting._

Dependencies:
* T15.K.03: Identify icons and pictures in interfaces (pictures)


ID: T15.K.05
Topic: T15 – User Interfaces
Skill: Match button to action (pictures)
Description: **Student task:** Draw lines connecting 4 buttons to what they do. **Visual scenario:** Play triangle → music plays; Stop square → music stops; Volume speaker → sound louder; Power circle → device turns off. _Implementation: Drag-to-match lines._

Dependencies:
* T15.K.04: Sort interface elements by type (pictures)


ID: T15.K.06
Topic: T15 – User Interfaces
Skill: Recognize feedback from interfaces (pictures)
Description: **Student task:** Look at before/after pictures of interfaces and tap what changed to show feedback. **Visual scenario:** Button turns green after pressing; heart fills in when tapped; loading circle appears; "Good job!" message pops up. **Student picks:** Which picture shows the interface telling us something? _Implementation: Tap-to-select; audio says "Interfaces talk back to us by changing colors, showing messages, or making sounds!"_

Dependencies:
* T15.K.05: Match button to action (pictures)


ID: T15.K.07
Topic: T15 – User Interfaces
Skill: Identify who might need help using interfaces (pictures)
Description: **Student task:** Look at 4 picture cards showing different people: a small child reaching for a high button, an elderly person squinting at tiny text, a person in wheelchair looking at a touchscreen mounted too high, a person wearing glasses using a well-designed tablet. Sort into "This interface is hard to use" vs "This interface works well." **Visual scenario:** Illustrates accessibility challenges. **Discussion:** Audio says "Good interfaces work for everyone - big kids, small kids, grandparents too!" _Foundational accessibility concept._ Implementation: Drag-and-drop sorting.

Dependencies:
* T15.K.06: Recognize feedback from interfaces (pictures)


ID: T15.K.08
Topic: T15 – User Interfaces
Skill: Predict what happens next in an interface (pictures)
Description: **Student task:** Look at 3 picture sequence: (1) finger approaching a big red button labeled "Music", (2) finger pressing the button, (3) ??? Choose from 3 options what happens next. **Visual scenario:** Options show: musical notes appear, game starts, nothing happens. **Correct answer:** Musical notes (button label gives clue). **Skill focus:** Use visual clues (labels, icons) to predict interface behavior. _Develops predictive thinking about UI._ Implementation: Multiple choice with explanation audio.


# ============ GRADE 1 (10 skills) ============
# Focus: Connect interface elements to purposes and understand affordances

ID: T15.G1.01
Topic: T15 – User Interfaces
Skill: Match interface elements to their purpose (unplugged)
Description: **Student task:** Given pictures of interface elements (button, slider, text box, picture display) and pictures of purposes (click to start, slide to change volume, type your name, show a photo), draw lines connecting each element to its purpose. **Activity:** Paper-based matching exercise. _Implementation: Line-drawing on paper or digital drag-to-match._

Dependencies:
* T15.K.08: Predict what happens next in an interface (pictures)


ID: T15.G1.01.01
Topic: T15 – User Interfaces
Skill: Explain why different elements look different (pictures)
Description: **Student task:** Look at a picture showing a button (raised, colorful), a text label (flat, plain), and a text input box (with cursor inside). Answer the question: "Why does the button look different from the label?" **Visual scenario:** Side-by-side comparison of button vs label vs textbox. **Discussion:** Audio explains "Buttons look like you can press them because they ARE meant to be pressed! Labels look flat because you just read them." _Develops understanding that visual design communicates function._ Implementation: Multiple choice with audio explanation.

Dependencies:
* T15.G1.01: Match interface elements to their purpose (unplugged)


ID: T15.G1.01.02
Topic: T15 – User Interfaces
Skill: Match user problems to interface solutions (pictures)
Description: **Student task:** Look at 4 pictures of people having problems, and 4 pictures of interfaces. Match each problem to the interface that solves it. **Visual scenarios:** (1) Child saying "I want to play my favorite song" → music player interface, (2) Person asking "What time is it in Japan?" → world clock interface, (3) Student saying "I need to do 5+3" → calculator interface, (4) Person asking "Is it going to rain?" → weather app interface. **Discussion:** Audio says "Good designers start by asking: What problem does the person have? Then they build an interface to solve it!" _Reinforces problem-first design thinking._ Implementation: Drag-to-match with audio explanation.

Dependencies:
* T15.K.01.02: Identify what problem an interface solves (pictures)
* T15.G1.01: Match interface elements to their purpose (unplugged)


ID: T15.G1.02
Topic: T15 – User Interfaces
Skill: Arrange interface elements on a screen (unplugged)
Description: **Student task:** Cut out paper shapes representing buttons, labels, and pictures. Arrange them on a paper "screen" to create a simple game menu with title at top, start button in middle, and picture at bottom. **Activity:** Physical paper prototyping. _Implementation: Photo-graded or teacher-graded arrangement._

Dependencies:
* T15.G1.01.01: Explain why different elements look different (pictures)


ID: T15.G1.03
Topic: T15 – User Interfaces
Skill: Predict what happens when a button is pressed (pictures)
Description: **Student task:** Look at a picture of an interface with a highlighted button, then choose from 3 pictures what will happen when that button is pressed. **Visual scenario:** Game start screen with "Play" button highlighted → choose from: game starts, game closes, nothing happens. _Implementation: Multiple-choice visual selection._

Dependencies:
* T15.G1.02: Arrange interface elements on a screen (unplugged)


ID: T15.G1.04
Topic: T15 – User Interfaces
Skill: Identify input vs output elements (pictures)
Description: **Student task:** Look at an interface picture and sort elements into "I give information" (inputs: keyboard, textbox, button) vs "I receive information" (outputs: screen, speaker, display). **Visual scenario:** Computer setup with various peripherals. _Implementation: Drag-and-drop sorting into 2 categories._

Dependencies:
* T15.G1.03: Predict what happens when a button is pressed (pictures)


ID: T15.G1.05
Topic: T15 – User Interfaces
Skill: Recognize different touch gestures (pictures)
Description: **Student task:** Match gesture pictures to their names. **Visual scenario:** Hand tap (one finger pressing) → "Tap"; two fingers pinching → "Pinch"; finger sliding → "Swipe"; finger pressing and holding → "Long press". **Activity:** Drag-to-match each gesture picture to its name and what it does. _Implementation: Picture matching with audio: "Tap is like clicking! Swipe is like turning a page!"_

Dependencies:
* T15.G1.04: Identify input vs output elements (pictures)


ID: T15.G1.06
Topic: T15 – User Interfaces
Skill: Identify menus in interfaces (pictures)
Description: **Student task:** Look at 4 pictures of apps and tap where you see menus (lists of choices). **Visual scenario:** Hamburger menu icon (three lines), dropdown arrow, list of game levels, settings list. **Correct answers:** Tap menu icons and opened menu lists. _Implementation: Tap-to-select; audio says "Menus are lists that help us find what we want!"_

Dependencies:
* T15.G1.05: Recognize different touch gestures (pictures)


ID: T15.G1.07
Topic: T15 – User Interfaces
Skill: Find the problem in a broken interface (pictures)
Description: **Student task:** Look at an interface picture where something is wrong and tap what needs to be fixed. **Visual scenario:** (1) A "Start" button that is too small to tap, (2) Text that runs off the screen, (3) Two buttons overlapping each other, (4) A button with no label. **Activity:** Tap the problem area. Audio explains "Good interfaces don't have these problems!" _Introduces debugging/quality thinking for UI._ Implementation: Tap-to-select with explanation.

Dependencies:
* T15.G1.06: Identify menus in interfaces (pictures)


ID: T15.G1.08
Topic: T15 – User Interfaces
Skill: Connect interface problems to user frustration (pictures)
Description: **Student task:** Match 4 interface problem pictures to 4 "feeling" faces (confused, frustrated, happy, surprised). **Visual scenario:** Tiny buttons → frustrated face; Clear large buttons → happy face; Hidden menu → confused face; Unexpected popup → surprised face. **Discussion:** Audio says "When interfaces are hard to use, people feel frustrated. Good designers think about how people feel!" _Builds empathy for users - foundational UX thinking._ Implementation: Drag-to-match.

Dependencies:
* T15.G1.07: Find the problem in a broken interface (pictures)



# ============ GRADE 2 (9 skills) ============
# Focus: Trace interactions, design on paper, evaluate and compare designs

ID: T15.G2.01
Topic: T15 – User Interfaces
Skill: Trace interface interactions with before/after pictures
Description: **Student task:** Look at before/after picture pairs showing interface interactions (button pressed → light turns on, slider moved → volume bar grows, text typed → letters appear in box). Describe what changed in each pair. **Visual scenario:** 4 pairs of before/after interface states. _Implementation: Visual comparison with verbal or written response._

Dependencies:
* T15.G1.08: Connect interface problems to user frustration (pictures)


ID: T15.G2.01.01
Topic: T15 – User Interfaces
Skill: Define a problem before designing an interface (unplugged)
Description: **Student task:** Before drawing an interface, write or say: (1) WHO will use it? (2) WHAT problem do they have? (3) HOW will the interface help? **Activity:** Given a scenario ("Your little sister wants to keep track of her toy collection"), fill in: Who = little sister, Problem = can't remember all her toys, Solution = an interface that shows pictures of toys. Then draw the interface. **Discussion:** "Designers always start by understanding the problem. If you don't know the problem, you can't solve it!" _Formalizes problem-first thinking before design._ Implementation: Worksheet then paper prototype.

Dependencies:
* T15.G1.01.02: Match user problems to interface solutions (pictures)
* T15.G2.01: Trace interface interactions with before/after pictures





ID: T15.G2.02
Topic: T15 – User Interfaces
Skill: Sequence interface interaction steps (pictures)
Description: **Student task:** Put 4 picture cards in order showing how to use an interface: (1) see a button, (2) click the button, (3) button changes appearance, (4) action happens. **Visual scenario:** Ordering sequence for "play a song" or "send a message" interaction. _Implementation: Drag-to-sequence ordering._

Dependencies:
* T15.G2.01: Trace interface interactions with before/after pictures


ID: T15.G2.03
Topic: T15 – User Interfaces
Skill: Design a simple interface on paper (unplugged)
Description: **Student task:** Draw a simple interface on paper for a specific purpose (game menu, calculator, music player). Include: buttons with labels, a display for information, arrange elements logically. Explain what each part does. **Activity:** Paper prototyping with crayons/markers. _Implementation: Teacher-graded or peer-reviewed drawing._

Dependencies:
* T15.G2.02: Sequence interface interaction steps (pictures)


ID: T15.G2.04
Topic: T15 – User Interfaces
Skill: Identify good vs confusing interfaces (pictures)
Description: **Student task:** Look at 2 interface designs for the same purpose (e.g., two game menus) and tap which one is easier to use. Then explain why. **Visual scenario:** One clear interface with big buttons and labels vs one cluttered interface with small unlabeled buttons. _Implementation: Multiple-choice with explanation prompt._

Dependencies:
* T15.G2.03: Design a simple interface on paper (unplugged)


ID: T15.G2.05
Topic: T15 – User Interfaces
Skill: Identify accessibility features in interfaces (pictures)
Description: **Student task:** Look at interface pictures and tap the features that help people who have difficulty seeing or hearing. **Visual scenario:** Large text option, volume icon with numbers, colorful vs high-contrast versions, audio speaker with sound waves. **Correct answers:** Tap features like big buttons, text-to-speech icon, volume slider, brightness control. _Implementation: Tap-to-select; audio says "Good interfaces help everyone use them, including people who see or hear differently!"_

Dependencies:
* T15.G2.04: Identify good vs confusing interfaces (pictures)


ID: T15.G2.06
Topic: T15 – User Interfaces
Skill: Predict multi-step interface interactions (pictures)
Description: **Student task:** Look at a sequence of 3 interface states and predict what the 4th state will look like. **Visual scenario:** (1) Game menu shows, (2) user taps "Settings", (3) settings panel opens, (4) ??? → Choose from: main menu returns, volume slider appears, game starts. **Activity:** Select the correct next state from 3 options. _Implementation: Multiple-choice with reasoning prompt "Why did you pick that answer?"_

Dependencies:
* T15.G2.05: Identify accessibility features in interfaces (pictures)


ID: T15.G2.07
Topic: T15 – User Interfaces
Skill: Compare two interface designs and choose the better one (pictures)
Description: **Student task:** Look at two different interface designs for the same app (music player) and explain which is better and why. **Visual scenario:** Design A has clear play/pause/skip buttons with labels; Design B has unlabeled icons that look similar. **Activity:** Tap the better design and select reasons from a list: "buttons are labeled," "buttons are easy to see," "buttons are not confusing." **Skill focus:** Develop critical evaluation of UI quality. _Builds design critique skills._ Implementation: Multiple-choice with reasoning selection.

Dependencies:
* T15.G2.04: Identify good vs confusing interfaces (pictures)


ID: T15.G2.08
Topic: T15 – User Interfaces
Skill: Design an interface for someone with different needs (unplugged)
Description: **Student task:** Given a persona card ("Grandma has trouble seeing small text"), redesign a paper interface to help that person. **Visual scenario:** Original interface has small buttons and text. Student draws new version with larger buttons, bigger text, high contrast colors. **Discussion:** "What did you change? Why does it help Grandma?" _Develops empathy-driven design and accessibility thinking._ Implementation: Paper prototyping with explanation.

Dependencies:
* T15.G2.05: Identify accessibility features in interfaces (pictures)
* T15.G2.03: Design a simple interface on paper (unplugged)



# ============ GRADE 3 (19 skills) ============
# Introduction to widget blocks - buttons, labels, textboxes, events, debugging, widget communication

ID: T15.G3.01
Topic: T15 – User Interfaces
Skill: Add a button widget to the stage
Description: Use "add button [TEXT] at X (X) Y (Y) width (WIDTH) height (HEIGHT) tooltip [TOOLTIP] as [NAME]" block to create a clickable button on the stage. Specify the button's text label, position (X, Y coordinates), size (width and height in pixels), tooltip (text shown on hover), and name. Widgets are UI elements that float above sprites and remain visible regardless of sprite position.

Dependencies:
* T15.G2.06: Predict multi-step interface interactions (pictures)
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T01.G3.01: Complete a simple script with missing blocks





ID: T15.G3.01.01
Topic: T15 – User Interfaces
Skill: Choose clear and consistent widget names
Description: Learn to name widgets using clear, descriptive names that reflect their purpose. **Good names:** "startButton", "scoreLabel", "playerNameInput". **Poor names:** "button1", "widget2", "abc". **Conventions:** Use camelCase or underscores, start with lowercase, include the widget type in the name (Button, Label, Input). Consistent naming makes code easier to read and debug when you have many widgets.

Dependencies:
* T15.G3.01: Add a button widget to the stage


ID: T15.G3.02
Topic: T15 – User Interfaces
Skill: Handle a button click event
Description: Use the "when widget [button1 v] clicked" hat block to detect when a specific button is clicked. The widget name must match the name you gave the button when adding it. Connect button clicks to simple actions like playing a sound, showing a sprite, or broadcasting a message.

Dependencies:
* T15.G3.01.01: Choose clear and consistent widget names
* T06.G3.02: Build a key‑press script that controls a sprite





ID: T15.G3.02.01
Topic: T15 – User Interfaces
Skill: Handle any button click with a single script
Description: Use "when any button named [variableName v] clicked" event block to detect when ANY button is clicked. The clicked button's name is automatically stored in the specified variable. This is useful when you have many similar buttons and want to handle them all with one script instead of creating separate scripts for each button. Use conditional blocks to check which button was clicked and take different actions accordingly.

Dependencies:
* T15.G3.02: Handle a button click event
* T09.G3.02: Use a variable in a conditional (if block)





ID: T15.G3.03
Topic: T15 – User Interfaces
Skill: Add a label widget to display text
Description: Use "add label [TEXT] at X (X) Y (Y) width (WIDTH) height (HEIGHT) padding (PADDING) as [NAME]" block to create a text display area on the stage. Set the label's initial text content, position, size, padding, and name. Labels are used to show information to the user (scores, messages, instructions) and cannot be edited by the user.

Dependencies:
* T15.G3.01: Add a button widget to the stage





ID: T15.G3.04
Topic: T15 – User Interfaces
Skill: Update label text dynamically
Description: Use the "set widget value" block to change a label's displayed text while the program runs. Connect label updates to events (button clicks, variable changes) to show dynamic information like scores or status messages.

Dependencies:
* T15.G3.03: Add a label widget to display text
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T15.G3.04.01
Topic: T15 – User Interfaces
Skill: Append text to labels and textboxes
Description: Use "append text [NEWTEXT] to [WIDGETNAME v] in new line [Yes/No v]" block to add text to the end of existing widget content without replacing it. Choose "Yes" to add text on a new line, or "No" to add on the same line. Understand the difference between "set value" (replaces all content) and "append text" (adds to existing content). Use appending for building logs, chat histories, or narratives that grow over time.

Dependencies:
* T15.G3.04: Update label text dynamically





ID: T15.G3.05
Topic: T15 – User Interfaces
Skill: Add a textbox widget for user input
Description: Use "add textbox at X (X) Y (Y) width (WIDTH) height (HEIGHT) padding (PADDING) line [single/multiple v] scroll [scroll/no scroll v] mode [input/read-only v] as [NAME]" block to create an input field. Set single line for short inputs (names, numbers) or multiple lines for longer text (comments, stories). Enable scrolling for long text. Use input mode to allow typing or read-only mode to display text without editing. Understand the difference between a label (display only, styled) and textbox (can accept user input or display plain text).

Dependencies:
* T15.G3.03: Add a label widget to display text





ID: T15.G3.06
Topic: T15 – User Interfaces
Skill: Get text from a textbox widget
Description: Use the "value of widget" block to retrieve the text that a user typed into a textbox. Store the input in a variable or use it directly in other blocks (e.g., display it in a label, use it in a greeting). The value block works with any widget type to get its current content.

Dependencies:
* T15.G3.05: Add a textbox widget for user input
* T09.G3.02: Use a variable in a conditional (if block)


ID: T15.G3.06.01
Topic: T15 – User Interfaces
Skill: Debug widget name mismatches
Description: Identify and fix errors caused by mismatched widget names. **Common errors:** Using "value of widget [button1]" when the button was named "myButton"; event block referencing wrong widget name. **Debug process:** Check that widget name in "add widget" block matches name in event/value blocks exactly (case-sensitive). _Auto-graded: Given buggy code with mismatched names, fix the widget references._

Dependencies:
* T15.G3.06: Get text from a textbox widget


ID: T15.G3.06.02
Topic: T15 – User Interfaces
Skill: Trace widget value flow through a program
Description: Trace how widget values move through a program step by step. **Activity:** Given a program with a textbox, button, and label, predict what the label will show after each user action. **Example trace:** (1) User types "Hello" in textbox, (2) User clicks button, (3) Button script runs: sets label to value of textbox, (4) Label shows "Hello". **Skill focus:** Follow data from input widget → variable → output widget. _Auto-graded: Given code and user actions, predict the final label value._

Dependencies:
* T15.G3.06.01: Debug widget name mismatches
* T15.G3.04: Update label text dynamically


ID: T15.G3.06.03
Topic: T15 – User Interfaces
Skill: Use console to debug widget values
Description: Use "print [MESSAGE] in [console v] color [COLOR]" block to output widget values to the console panel for debugging. **Pattern:** Print "Button clicked: " joined with the button name; print "Textbox value: " joined with value of widget. **When to use:** When widget values aren't what you expect, print them to console to see actual values. **Access:** Click the console icon below the stage to see output. _Develops systematic debugging habits for UI programming._

Dependencies:
* T15.G3.06.02: Trace widget value flow through a program





ID: T15.G3.07
Topic: T15 – User Interfaces
Skill: Show and hide widgets
Description: Use "set visibility [show/hide] for widget named [NAME]" block to show or hide individual widgets. Use "set visibility [show/hide] for all widgets" to show or hide all widgets at once. Create simple interactions where clicking a button shows or hides other widgets (e.g., show instructions when "Help" is clicked, hide a menu after selection).

Dependencies:
* T15.G3.02: Handle a button click event
* T08.G3.04: Use a simple if in a script





ID: T15.G3.07.01
Topic: T15 – User Interfaces
Skill: Remove widgets from the stage
Description: Use "remove widget named [NAME]" to permanently delete a widget from the stage. Use "remove all widgets" to clear all widgets at once. Understand the difference between hiding (temporary, can be shown again) and removing (permanent, widget is deleted). Use removal for screen transitions, game resets, or cleaning up widgets you no longer need.

Dependencies:
* T15.G3.07: Show and hide widgets





ID: T15.G3.08
Topic: T15 – User Interfaces
Skill: Position and resize widgets
Description: Use "move widget [NAME] to X (X) Y (Y) in (T) seconds [blocking v]" to animate widget position over time. Use "resize widget [NAME] to width (W) height (H) in (T) seconds [blocking v]" to animate size changes. Set T to 0 for instant movement, or use larger values for smooth animations. Choose "blocking" to make your script wait until the animation finishes before continuing to the next block (useful when you want things to happen one at a time). Choose "non-blocking" to continue immediately to the next block while animation happens in the background (useful when you want multiple things to animate at the same time). Arrange multiple widgets to create a simple layout (e.g., title at top, buttons below, input fields in the middle).

Dependencies:
* T15.G3.07: Show and hide widgets


ID: T15.G3.08.01
Topic: T15 – User Interfaces
Skill: Create a simple button-and-label mini-app
Description: Build a complete mini-application using buttons and labels together. **Example projects:** Counter app (button adds 1 to number in label), greeting app (button shows "Hello!" in label), color picker (3 buttons change label background color). **Structure:** Create widgets on green flag, connect buttons to update labels. This skill combines widget creation, events, and dynamic updates into a cohesive project. _Auto-graded: Build a working app where button clicks change label content._

Dependencies:
* T15.G3.08: Position and resize widgets
* T15.G3.04: Update label text dynamically






ID: T15.G3.09
Topic: T15 – User Interfaces
Skill: Pass data from one widget to another
Description: Transfer data between widgets by reading a value from one widget and setting it in another. **Pattern:** Get text from textbox → set label text. Get textbox value → use in another widget's content. **Example:** User types name in textbox, clicks Submit button, label shows "Hello, [name]!". **Concept:** Widgets don't automatically share data - your code connects them by reading from one and writing to another. _This foundational data-flow pattern appears in every real application._ Auto-graded: Build interface where textbox content appears in a label when button is clicked.

Dependencies:
* T15.G3.06: Get text from a textbox widget
* T15.G3.04: Update label text dynamically


ID: T15.G3.10
Topic: T15 – User Interfaces
Skill: Coordinate multiple widgets to complete a task
Description: Combine multiple widgets working together to accomplish a goal. **Example tasks:** (1) Name entry form: textbox for name + textbox for age + Submit button + greeting label showing "Hi [name], you are [age]!". (2) Simple calculator: two textboxes for numbers + Add button + result label. **Coordination patterns:** Multiple inputs → processing → single output. **Skill focus:** Think about HOW widgets work together, not just what each does alone. _Builds toward more complex multi-widget applications._ Auto-graded: Build working 2-input form with combined output.

Dependencies:
* T15.G3.09: Pass data from one widget to another
* T15.G3.02.01: Handle any button click with a single script

# ============ GRADE 4 (21 skills) ============
# Widget styling, input widgets, settings panels, patterns, micro-interactions, widget chains

ID: T15.G4.01
Topic: T15 – User Interfaces
Skill: Style widget text properties
Description: Use "set text style [FONTSTYLE v] font size (FONTSIZE) text color [TEXTCOLOR] boldness [bold/normal v] text alignment [Left/Middle/Right v] for widget [WIDGETNAME v]" block to style widget text. Choose from font families (sans-serif for clean modern look, Arial for readability, Bangers for fun themes). Set font size in pixels, text color, bold/normal weight, and left/middle/right alignment. Create visually appealing labels and buttons.

Dependencies:
* T15.G3.08.01: Create a simple button-and-label mini-app





ID: T15.G4.01.01
Topic: T15 – User Interfaces
Skill: Apply consistent styling across multiple widgets
Description: Apply consistent styling across multiple widgets to create visual cohesion. Use the same color scheme, font family, font sizes, and border styles for all widgets in your project. Style related widgets similarly (all navigation buttons with blue background, all info labels with grey text, all input fields with white background). Consistency makes interfaces look professional and helps users understand which widgets serve similar purposes.

Dependencies:
* T15.G4.01: Style widget text properties





ID: T15.G4.02
Topic: T15 – User Interfaces
Skill: Style widget appearance
Description: Use the "set widget style" block to customize widget backgrounds, borders (width, color, style), and corner radius. Set background color using #RRGGBBAA format (including transparency). Use "add image [costume] to widget named [NAME] at position X Y" or "add image at URL [URL] to widget named [NAME] at position X Y" to add decorative icons or images ON TOP OF other widgets (like adding a logo to a button). For standalone images, use the dedicated image widget skill (T15.G4.02.01). Create buttons and labels that match a visual theme or stand out for emphasis.

Dependencies:
* T15.G4.01: Style widget text properties





ID: T15.G4.02.01
Topic: T15 – User Interfaces
Skill: Add an image widget to the stage
Description: Use "add image [COSTUMENAME v] at x (X) y (Y) width (WIDTH) height (HEIGHT) aspect ratio [keep/stretch v] as [NAME]" or "add image from URL [URL] at x (X) y (Y) width (WIDTH) height (HEIGHT) aspect ratio [keep/stretch v] as [NAME]" blocks to create standalone image widgets that display pictures on the stage. Choose to keep original aspect ratio or stretch to fit dimensions. These are different from decorative images added TO other widgets. Image widgets are useful for displaying icons, backgrounds, or visual feedback that needs to be positioned precisely.

Dependencies:
* T15.G3.08: Position and resize widgets





ID: T15.G4.03
Topic: T15 – User Interfaces
Skill: Add a dropdown menu widget
Description: Use "add dropdown menu at X (X) Y (Y) width (WIDTH) height (HEIGHT) using list [LIST v] as [NAME]" block to create a selection menu. The dropdown options are populated from a list variable - the items in the list become the menu choices. Set the dropdown's position, size, and name. Compare when to use dropdowns vs buttons (dropdowns are best for many options where only one can be selected; buttons are best for 2-4 obvious choices).

Dependencies:
* T10.G3.01.01: Create a list variable and add items to it
* T15.G4.02: Style widget appearance





ID: T15.G4.04
Topic: T15 – User Interfaces
Skill: Get the selected value from a dropdown
Description: Use "value of widget [NAME v]" block to retrieve which option the user selected from a dropdown menu. Use "when widget [NAME v] changes" event block to detect when the user selects a different option. The event triggers immediately when selection changes, allowing you to update other parts of the interface or take actions based on the new selection. Use the selected value in conditionals or to update other widgets.

Dependencies:
* T08.G3.10: Trace code with a single if/else
* T15.G4.03: Add a dropdown menu widget


ID: T15.G4.04.01
Topic: T15 – User Interfaces
Skill: Debug dropdown not showing expected options
Description: Identify and fix common dropdown widget issues. **Common bugs:** (1) Dropdown shows empty because list is created AFTER the dropdown block, (2) Wrong list name in dropdown block, (3) List items were added but dropdown wasn't refreshed. **Debug process:** Check list exists before dropdown creation, verify list name matches exactly, ensure list has items. _Auto-graded: Given buggy code where dropdown is empty, fix the list/dropdown order or name._

Dependencies:
* T15.G4.04: Get the selected value from a dropdown





ID: T15.G4.05
Topic: T15 – User Interfaces
Skill: Add a slider widget for numeric input
Description: Use "add slider at X (X) Y (Y) width (WIDTH) between (MIN) and (MAX) as [NAME]" block to create a slider that users can drag to select a numeric value within a range. Set the position, width, minimum value, maximum value, and name. Sliders are useful for settings like volume, speed, or size.

Dependencies:
* T15.G4.02: Style widget appearance





ID: T15.G4.06
Topic: T15 – User Interfaces
Skill: Read and respond to slider value changes
Description: Use the "when widget value changed" event and "value of widget" block to detect when a user moves a slider and get its current value. Update other elements in real-time as the slider moves (e.g., adjust sprite size, change speed).

Dependencies:
* T09.G3.05: Trace code with variables to predict outcomes
* T15.G4.05: Add a slider widget for numeric input





ID: T15.G4.07
Topic: T15 – User Interfaces
Skill: Add and use checkbox widgets
Description: Use "add checkbox at X (X) Y (Y) named [NAME]" block to create toggle options. The checkbox value is 0 when unchecked and 1 when checked. Use "value of widget [NAME v]" to read its state. Use "set value to [V] for widget [NAME v]" to check (V=1) or uncheck (V=0) it programmatically. Use "when widget [NAME v] clicked" or "when widget [NAME v] changes" to respond to user interactions. Checkboxes are used for settings where multiple options can be on simultaneously (e.g., enable sound, enable music, enable vibration - all independent). Each checkbox is an independent toggle, unlike radio buttons which are mutually exclusive.

Dependencies:
* T08.G3.10: Trace code with a single if/else
* T15.G4.02: Style widget appearance





ID: T15.G4.07.01
Topic: T15 – User Interfaces
Skill: Add and use radio button widgets
Description: Use "add radio buttons [CHOICE1] [CHOICE2] [CHOICE3] [CHOICE4] [CHOICE5] [CHOICE6] [horizontal/vertical v] at x (X) y (Y) width (WIDTH) height (HEIGHT) named [NAME]" block to create mutually exclusive selections (only one can be selected at a time). Radio buttons support up to 6 choices with horizontal or vertical orientation. All radio buttons in a group share the same widget name. Use "value of widget [NAME v]" to get which option is selected. Use "set value to [TEXT] for widget [NAME v]" to programmatically select an option by its text. Use radio buttons when only one choice is allowed (e.g., difficulty: Easy, Medium, Hard - only one can be selected). The mutual exclusivity is enforced automatically when they share the same group/widget name. This is different from checkboxes which allow multiple independent selections.

Dependencies:
* T15.G4.07: Add and use checkbox widgets





ID: T15.G4.07.02
Topic: T15 – User Interfaces
Skill: Add and use tabs widget for organizing content
Description: Use "create tabs at X (X) Y (Y) width (WIDTH) height (HEIGHT) names [TAB1] [TAB2] ... [TAB8] show heading [Yes/No v]" block to create a tabbed interface with up to 8 panels. Use "set tab container [TABNAME v]" to specify which tab newly created widgets should appear in. Use "select tab [TABNAME]" to switch between tabs programmatically. Use "[show/hide/add/remove v] tab named [TABNAME]" to manage individual tabs. Use "when tab [TABNAME v] selected" event to respond to user tab changes. Tabs organize content into logical sections within a single screen.

Dependencies:
* T15.G3.07: Show and hide widgets
* T15.G4.07.01: Add and use radio button widgets





ID: T15.G4.08
Topic: T15 – User Interfaces
Skill: Build a simple settings panel
Description: Organize multiple input widgets into a settings panel. Arrange checkboxes, sliders, dropdowns, and labels into a cohesive group. Position related settings near each other and use descriptive labels to explain each option. Create visual separation between setting groups using spacing or styling.

Dependencies:
* T15.G4.06: Read and respond to slider value changes
* T15.G4.07: Add and use checkbox widgets





ID: T15.G4.08.01
Topic: T15 – User Interfaces
Skill: Connect settings to program behavior
Description: Connect settings widget values to program behavior. Read values from multiple widget types (checkbox state, slider value, dropdown selection) and use them to control how the program runs. For example, use a volume slider value to control sound loudness, a difficulty dropdown to adjust game speed, or a sound on/off checkbox to enable/disable audio.

Dependencies:
* T08.G4.03: Combine two conditions with AND
* T15.G4.08: Build a simple settings panel





ID: T15.G4.09
Topic: T15 – User Interfaces
Skill: Respond to hover events on widgets
Description: Use the "when pointer enters widget" and "when pointer leaves widget" event blocks to detect when the mouse hovers over a widget. Create hover effects like changing button colors, showing tooltips, or highlighting interactive elements when the user moves their mouse over them.

Dependencies:
* T15.G3.02: Handle a button click event
* T15.G4.02: Style widget appearance





ID: T15.G4.10
Topic: T15 – User Interfaces
Skill: Add hyperlink widgets to external resources
Description: Use "add link at X (X) Y (Y) url [URL] as [NAME]" block to create clickable hyperlinks that open external URLs in a new browser tab. The link displays the URL as text by default. Use "set value to [TEXT] for widget [NAME]" to change the displayed text to something more user-friendly (e.g., "Click here for help" instead of the full URL). Style links using "set text style" to change color and make them distinct from buttons. Use links for documentation, resources, or external content integration.

Dependencies:
* T15.G3.01: Add a button widget to the stage
* T15.G4.02: Style widget appearance


ID: T15.G4.11
Topic: T15 – User Interfaces
Skill: Debug widgets responding to wrong events
Description: Identify and fix bugs where widgets respond incorrectly or not at all. **Common bugs:** (1) Event block uses wrong widget name, (2) Multiple widgets with same name cause confusion, (3) Event handler attached to wrong sprite. **Debug process:** Verify widget names match exactly, ensure unique names for each widget, check which sprite owns the event script. _Auto-graded: Given code where clicking "Start" changes wrong label, identify and fix the bug._

Dependencies:
* T15.G4.09: Respond to hover events on widgets
* T15.G3.06.01: Debug widget name mismatches


ID: T15.G4.12
Topic: T15 – User Interfaces
Skill: Trace settings panel state changes
Description: Trace how settings panel widget values change as users interact. **Activity:** Given a settings panel with checkbox, slider, and dropdown, and a sequence of user actions, predict the final state of all widgets. **Example:** Start: checkbox=unchecked, slider=50, dropdown="Easy". Actions: (1) check checkbox, (2) move slider to 75, (3) select "Hard". Final state: checkbox=1, slider=75, dropdown="Hard". _Develops systematic state tracking for UI._

Dependencies:
* T15.G4.08.01: Connect settings to program behavior


ID: T15.G4.13
Topic: T15 – User Interfaces
Skill: Recognize common UI patterns (list-detail)
Description: Identify and implement the list-detail UI pattern used in many apps. **Pattern:** Left side shows a list of items (e.g., contacts, songs, products); clicking an item shows its details on the right side. **Implementation:** Create list display widget, create detail panel widgets, use "when widget clicked" to update detail panel with selected item's information. **Real examples:** Email apps (inbox list → email content), music apps (song list → now playing).

Dependencies:
* T15.G4.08: Build a simple settings panel
* T15.G4.04: Get the selected value from a dropdown


ID: T15.G4.14
Topic: T15 – User Interfaces
Skill: Build widget chains where output becomes input
Description: Create a chain of widgets where the output of one widget becomes the input for the next. **Example chains:** (1) Slider → Label showing value → Sprite size changes. (2) Textbox → Button formats text → Label shows formatted result. (3) Dropdown selects category → List filters to that category → Detail panel shows first item. **Pattern:** Think of widgets as stations in a pipeline - data flows through them in sequence. **Skill focus:** Design multi-step data transformations through UI. _Preparation for more complex reactive UIs._ Auto-graded: Build a 3-widget chain where data transforms at each step.

Dependencies:
* T15.G3.10: Coordinate multiple widgets to complete a task
* T15.G4.06: Read and respond to slider value changes


ID: T15.G4.15
Topic: T15 – User Interfaces
Skill: Design feedback timing for user actions
Description: Provide immediate visual feedback when users interact with widgets. **Timing principles:** (1) Instant feedback (< 0.1s): Button color change on click, (2) Short feedback (0.1-0.5s): Smooth transition to new state, (3) Progress feedback (> 0.5s): Show loading indicator. **Implementation:** Use "wait" blocks and style changes to create feedback sequences. **Example:** Button click → button turns grey instantly → wait 0.1s → action completes → button returns to normal + success message appears. _Users need to know their action was received._ Auto-graded: Add appropriate feedback timing to a button interaction.

Dependencies:
* T15.G4.09: Respond to hover events on widgets
* T15.G4.02: Style widget appearance


# ============ GRADE 5 (24 skills) ============
# Complex widgets (video, chat, toolbox, joystick), multi-screen apps, forms, HUD, animations, observer pattern, testing

ID: T15.G5.01
Topic: T15 – User Interfaces
Skill: Create a multi-screen app with navigation
Description: Build a multi-screen application with navigation between views (home, game, settings, results). **Approach 1:** Use buttons to navigate by showing/hiding widget groups using "set widget visible" block. **Approach 2:** Use tabs widget to organize screens into panels. Track current screen in a variable. Create consistent navigation (back buttons, menu) across all screens.

Dependencies:
* T15.G4.08: Build a simple settings panel
* T15.G4.07.02: Add and use tabs widget for organizing content


ID: T15.G5.01.01
Topic: T15 – User Interfaces
Skill: Use variables to track current screen state
Description: Use a variable (e.g., "currentScreen") to track which screen is currently displayed. **Pattern:** Set variable to "home", "game", "settings", etc. when navigating. Use the variable in conditionals to determine which widgets to show/hide. **Benefits:** Centralizes navigation logic, makes it easy to check current state, enables "back" functionality by storing previous screen. This is the state management pattern used in professional app development.

Dependencies:
* T15.G5.01: Create a multi-screen app with navigation





ID: T15.G5.02
Topic: T15 – User Interfaces
Skill: Design a form with multiple inputs and validation
Description: Create a form interface with multiple text input fields, dropdowns, or checkboxes. **Form design:** Group related inputs, add clear labels, arrange logically top-to-bottom. **Validation:** Check that required fields are not empty, verify text format (e.g., no numbers in name), display error messages next to invalid fields. **Submission:** Create submit button that validates all inputs, shows confirmation message or error list.

Dependencies:
* T15.G4.07: Add and use checkbox widgets
* T15.G4.04: Get the selected value from a dropdown





ID: T15.G5.02.01
Topic: T15 – User Interfaces
Skill: Add specialized picker widgets for dates and colors
Description: Use "add date picker at X (X) Y (Y) as [NAME]" and "add color picker at X (X) Y (Y) as [NAME]" blocks to create specialized input controls. Date pickers display a calendar interface (value format: YYYYMMDD like 20250115). Color pickers display a visual color selector (value format: #RRGGBBAA like #FF0000FF for red). Use "value of widget" to retrieve selected dates/colors. Use "set value to [V] for widget [NAME]" to pre-select dates or colors. Use "when widget [NAME] changes" to respond to user selections.

Dependencies:
* T15.G5.02: Design a form with multiple inputs and validation


ID: T15.G5.02.02
Topic: T15 – User Interfaces
Skill: Debug form validation failures systematically
Description: Systematically debug form validation that doesn't work correctly. **Common bugs:** (1) Validation checks wrong widget name, (2) Validation logic has wrong condition (checking = instead of not =), (3) Error message displays but form still submits, (4) Validation runs at wrong time. **Debug process:** Test each field individually, check condition logic, verify error message appears/disappears correctly, confirm submit is blocked on invalid input. _Auto-graded: Given a form with broken validation, identify and fix the bug._

Dependencies:
* T15.G5.02: Design a form with multiple inputs and validation
* T15.G4.11: Debug widgets responding to wrong events





ID: T15.G5.03
Topic: T15 – User Interfaces
Skill: Build a leaderboard or high‑score display
Description: Create a leaderboard interface that displays ranked data. **Data structure:** Store scores in a list sorted high-to-low. **Display:** Use labels or a textbox to show rankings (e.g., "1. Alice: 500\n2. Bob: 350"). **Dynamic updates:** When new scores are added, re-sort the list and update the display. **Formatting:** Use consistent spacing, highlight top 3, show player names with scores.

Dependencies:
* T15.G4.01: Style widget text properties
* T10.G3.01: Loop through and process each item in a list





ID: T15.G5.04
Topic: T15 – User Interfaces
Skill: Implement a responsive HUD that reacts to game state
Description: Design a "heads-up display" (HUD) showing real-time game information. **Elements:** Health/progress bar, score label, lives counter, timer, status messages. **Updates:** Use "set widget value" to update labels when variables change. **Positioning:** Place HUD elements at screen edges so they don't block gameplay. **Visibility:** Show/hide elements based on game state (hide "Game Over" until game ends).

Dependencies:
* T15.G4.06: Read and respond to slider value changes
* T15.G5.03: Build a leaderboard or high‑score display





ID: T15.G5.04.01
Topic: T15 – User Interfaces
Skill: Add and update a progress bar widget
Description: Use "add progress bar as (CURRENT) out of total (TOTAL) at x (X) y (Y) width (WIDTH) height (HEIGHT) color [COLOR] background [BG] border width (BORDERWIDTH) color [BORDERCOLOR] as [NAME]" block to create a progress indicator. **Parameters:** CURRENT and TOTAL define fill percentage, colors customize appearance (use #RRGGBBAA format). **Updates:** Use "set value to [NEWCURRENT] for widget [NAME]" to animate progress. **Use cases:** Health bars (100/100→50/100), loading indicators, completion status, timers counting down.

Dependencies:
* T15.G5.04: Implement a responsive HUD that reacts to game state





ID: T15.G5.04.02
Topic: T15 – User Interfaces
Skill: Animate widgets for visual feedback
Description: Animate widgets for visual feedback and smooth transitions. **Movement:** "move widget [NAME] to X Y in T seconds [blocking v]" slides widgets. **Transparency:** "set transparency for widget [NAME] to (T)% in (N) seconds" fades widgets (0%=visible, 100%=invisible). **Scaling:** "scale widget [NAME] to width (W)% height (H)% in (T) seconds" grows/shrinks. **Rotation:** "rotate widget [NAME] by (D) degrees in (T) seconds" spins widgets. **Blocking modes:** "blocking" waits until animation finishes; "non-blocking" continues immediately. Combine with hover events for interactive effects.

Dependencies:
* T15.G5.04.01: Add and update a progress bar widget
* T15.G4.09: Respond to hover events on widgets





ID: T15.G5.05
Topic: T15 – User Interfaces
Skill: Embed and control a video widget
Description: Use "add youtube video [URL] at X (X) Y (Y) width (WIDTH) height (HEIGHT) named [NAME] in [foreground/background v]" block to embed a YouTube video. **Layers:** foreground = user can click to play/pause; background = non-interactive, plays automatically. **URL format:** Use full YouTube URL or video ID. **Use cases:** Tutorial videos, game cutscenes, educational content, background ambiance.

Dependencies:
* T15.G5.01: Create a multi‑screen app with navigation
* T15.G4.02.01: Add an image widget to the stage





ID: T15.G5.05.01
Topic: T15 – User Interfaces
Skill: Control video playback with advanced features
Description: Control video playback programmatically. **Playback controls:** "[start/pause/stop/mute/unmute v] video for [VIDEONAME v]". **Seeking:** "seek to (TIME) seconds in video named [VIDEONAME v]". **Volume:** "set volume to (VOLUME) for [VIDEONAME v]" (0-100). **Speed:** "set playback speed ratio (SPEED) for [VIDEONAME v]" (100=normal, 200=2x). **Status:** "current video time for [VIDEONAME v]" returns current position in seconds.

Dependencies:
* T15.G5.05: Embed and control a video widget





ID: T15.G5.05.02
Topic: T15 – User Interfaces
Skill: Respond to video playback events
Description: Use video event hat blocks to create interactive video experiences. **Events:** "when video [NAME] start" triggers when playback begins. "when video [NAME] paused" detects pause. "when video [NAME] stopped" triggers when video ends. "when video time is (T) seconds for [NAME]" triggers at specific timestamps. **Applications:** Show quiz at 1:30, display subtitles, trigger animations at key moments, auto-advance to next screen when video ends.

Dependencies:
* T15.G5.05.01: Control video playback with advanced features





ID: T15.G5.06
Topic: T15 – User Interfaces
Skill: Add a rich textbox for formatted content
Description: Use "add rich textbox at X (X) Y (Y) width (WIDTH) height (HEIGHT) padding (PADDING) mode [input/read-only v] as [NAME]" block to create a text area supporting formatted text. **Input mode:** Users see a toolbar to format text (bold, italic, colors). **Read-only mode:** Display pre-formatted content. **Value format:** "value of widget" returns HTML markup. **Use cases:** Note-taking apps (input), styled instructions (read-only), formatted stories.

Dependencies:
* T15.G4.01: Style widget text properties
* T15.G3.05: Add a textbox widget for user input





ID: T15.G5.06.01
Topic: T15 – User Interfaces
Skill: Add a chat window widget
Description: Use "add chat window x (X) y (Y) width (WIDTH) height (HEIGHT) input rows (ROWS) background [BG] border [BORDERCOLOR] name [NAME]" block to create a chat interface. **Structure:** Bottom has text input + send button; top has scrollable message history. **Input rows:** 1 for single-line, 2+ for multi-line input. **Styling:** Set background and border colors (#RRGGBBAA format). Chat windows are compound widgets combining input, button, and scrollable panel for conversations.

Dependencies:
* T15.G5.06: Add a rich textbox for formatted content
* T15.G4.08: Build a simple settings panel





ID: T15.G5.06.02
Topic: T15 – User Interfaces
Skill: Append messages to chat window
Description: Use "append to chat [CHATNAME v] message [MESSAGE] as [SENDER] icon [ICON v] align [ALIGN v] text size (TEXTSIZE) color [COLOR] background [BG]" block to add messages. **Parameters:** SENDER shows name, ICON can be 'ROBOT', 'USER', or costume name; ALIGN 'Left' for received, 'Right' for sent. **Auto-scroll:** Chat scrolls to newest message. **Triggers:** Append on send button click or programmatically for bot responses.

Dependencies:
* T15.G5.06.01: Add a chat window widget





ID: T15.G5.06.03
Topic: T15 – User Interfaces
Skill: Update streaming chat messages
Description: Use "update last chat message to [MESSAGE] for chat [CHATNAME v]" block to modify the most recent message in-place without adding a new entry. **Use cases:** Streaming AI responses (text builds word-by-word), updating "Typing..." to actual message, correcting last message. **Difference from append:** Update replaces; append adds new. Creates smooth typing effect for chatbots.

Dependencies:
* T15.G5.06.02: Append messages to chat window





ID: T15.G5.07
Topic: T15 – User Interfaces
Skill: Create a toolbox widget for item selection
Description: Use "add toolbox at x (X) y (Y) width (WIDTH) height (HEIGHT) row count (ROWCOUNT) column count (COLCOUNT) as [NAME]" to create a grid selector. **Populate:** "set icon to [COSTUME v] at row (R) column (C) for toolbox [NAME]". **Selection:** "value of widget [NAME]" returns selected cell index (1, 2, 3...). **Events:** "when widget [NAME] clicked" and "when widget [NAME] changes". **Use cases:** Game inventories, tool palettes, building block selectors, item shops.

Dependencies:
* T15.G4.02.01: Add an image widget to the stage
* T15.G4.06: Read and respond to slider value changes





ID: T15.G5.08
Topic: T15 – User Interfaces
Skill: Create confirmation dialogs with custom buttons
Description: Use "confirm [TEXT] with buttons [BUTTON1] [BUTTON2] [BUTTON3] [BUTTON4] [BUTTON5] [BUTTON6]" reporter block to create modal dialogs. **Behavior:** Pauses execution until user clicks a button; returns clicked button's text. **Buttons:** Up to 6 (blank = hidden). **Use cases:** Save/Cancel decisions, difficulty selection (Easy/Medium/Hard), Yes/No confirmations, error messages with OK.

Dependencies:
* T15.G3.02: Handle a button click event
* T15.G4.04: Get the selected value from a dropdown


ID: T15.G5.08.01
Topic: T15 – User Interfaces
Skill: Create custom modal/popup dialogs
Description: Build custom popup dialogs using widget layering instead of the built-in confirm block for more control over appearance. **Pattern:** (1) Create a semi-transparent overlay widget covering the screen, (2) Add a centered panel widget on top with high z-index, (3) Add message label and buttons inside the panel. **Behavior:** Show overlay + panel on trigger, hide both when button clicked. **Advantages over confirm block:** Custom styling, multiple input fields, images, animations. **Use cases:** Login forms, game pause menus, tutorial overlays.

Dependencies:
* T15.G5.08: Create confirmation dialogs with custom buttons
* T15.G5.04.02: Animate widgets for visual feedback





ID: T15.G5.09
Topic: T15 – User Interfaces
Skill: Add a virtual joystick for touch controls
Description: Use "add joystick to [left/right v] side of screen as [NAME] outer color [OUTERCOLOR] inner color [INNERCOLOR] size [SIZE]%" block to create touch-based game controls. **Positioning:** Left side for movement, right side for camera/actions. **Sizing:** Percentage of screen width (20-40% typical). **Colors:** Customize outer ring and inner knob colors. Joysticks are essential for mobile game interfaces on tablets and phones.

Dependencies:
* T15.G5.04: Implement a responsive HUD that reacts to game state
* T15.G4.02: Style widget appearance


ID: T15.G5.09.01
Topic: T15 – User Interfaces
Skill: Read joystick input values
Description: Use "joystick [NAME v] [x/y/direction/distance/pressed v]" reporter block to read joystick state. **Reporters:** x (-100 to 100 horizontal), y (-100 to 100 vertical), direction (0-360 degrees), distance (0-100 from center), pressed (true/false). **Applications:** Move sprites using x/y, rotate using direction, control speed using distance. Combine with forever loop to create continuous movement controls.

Dependencies:
* T15.G5.09: Add a virtual joystick for touch controls


ID: T15.G5.10
Topic: T15 – User Interfaces
Skill: Implement the observer pattern for widget updates
Description: Implement the observer pattern where multiple UI elements automatically update when a shared data value changes. **Pattern:** When "score" variable changes, both the score label AND the progress bar AND the leaderboard update automatically. **Implementation:** Use broadcasts or "when widget changes" events to notify all dependent widgets. **Benefit:** Centralizes data management - change data in one place, all displays update. _This is foundational for reactive UI programming._

Dependencies:
* T15.G5.04: Implement a responsive HUD that reacts to game state
* T15.G5.03: Build a leaderboard or high-score display


ID: T15.G5.10.01
Topic: T15 – User Interfaces
Skill: Test UI behavior matches specifications
Description: Write and execute test cases to verify UI behavior matches requirements. **Test structure:** (1) Setup: Create widgets in known state, (2) Action: Simulate user interaction, (3) Verify: Check widget values/visibility match expected. **Example test:** Setup: score=0, label shows "0". Action: click "+1" button. Verify: score=1, label shows "1". **Process:** List all expected behaviors, write test for each, run tests after changes. _Develops systematic UI testing mindset._

Dependencies:
* T15.G5.10: Implement the observer pattern for widget updates
* T15.G4.12: Trace settings panel state changes


ID: T15.G5.11
Topic: T15 – User Interfaces
Skill: Create transition animations between states
Description: Animate smooth transitions when UI state changes. **Transition types:** (1) Fade in/out: Use transparency animation when showing/hiding widgets. (2) Slide in/out: Move widgets from off-screen to final position. (3) Scale: Grow buttons on hover, shrink on release. **Implementation:** Combine "move widget", "scale widget", and "set transparency" with timing. **Example:** Screen transition: current screen fades out (0.2s) → new screen slides in from right (0.3s). _Transitions make interfaces feel polished and professional._ Auto-graded: Create a screen transition with fade and slide.

Dependencies:
* T15.G5.04.02: Animate widgets for visual feedback
* T15.G5.01: Create a multi-screen app with navigation


ID: T15.G5.12
Topic: T15 – User Interfaces
Skill: Apply the 3-second rule for feedback
Description: Ensure users never wait more than 3 seconds without feedback. **The rule:** If any operation takes > 3 seconds, show progress indication. **Implementation patterns:** (1) < 1 second: No indicator needed, just show result. (2) 1-3 seconds: Show simple "loading" text or spinner. (3) > 3 seconds: Show progress bar with percentage or steps remaining. (4) Unknown duration: Show animated spinner with "Processing..." text. **User experience:** Uncertain waits feel longer than known waits. Always communicate what's happening. _This professional UX standard prevents user frustration._ Auto-graded: Add appropriate progress feedback to a slow operation.

Dependencies:
* T15.G5.04.01: Add and update a progress bar widget
* T15.G4.15: Design feedback timing for user actions


ID: T15.G5.13
Topic: T15 – User Interfaces
Skill: Implement master-detail with editing
Description: Extend the list-detail pattern to allow editing. **Pattern:** List shows items → clicking item shows details → Edit button enables editing → Save button updates the item → list updates to show changes. **Data flow:** List displays data from list variable → detail panel reads selected item → editing writes back to list → list display refreshes. **Implementation:** Add edit mode flag, toggle between view and edit states, validate before saving. **Real examples:** Contacts app (view contact → edit → save), Notes app (select note → edit → save). _Builds toward CRUD interfaces._

Dependencies:
* T15.G4.13: Recognize common UI patterns (list-detail)
* T15.G5.02: Design a form with multiple inputs and validation


# ============ GRADE 6 (17 skills) ============
# Usability evaluation, responsive design, camera widgets, menu bars, user research, CRUD patterns

ID: T15.G6.01
Topic: T15 – User Interfaces
Skill: Evaluate an interface for usability
Description: Examine an existing interface (app screenshot) and identify usability issues and strengths. **Evaluation criteria:** Are buttons clearly labeled? Is the layout intuitive? Can users find important actions? Are colors accessible for colorblind users? **Activity:** Write 3 strengths and 3 improvements for a given interface. Learn to think like a UX designer.

Dependencies:
* T15.G5.03: Build a leaderboard or high-score display





ID: T15.G6.02
Topic: T15 – User Interfaces
Skill: Design an interface based on user feedback
Description: Students design an initial interface (buttons, labels, layout), ask peers or a teacher to try it, gather feedback on usability, and then modify the design to address the feedback. This introduces the iterative design process.

Dependencies:
* T15.G6.01: Evaluate an interface for usability





ID: T15.G6.03
Topic: T15 – User Interfaces
Skill: Use color and contrast to improve readability
Description: Students apply color theory to interface design: choosing high-contrast text and backgrounds for readability, avoiding color combinations that are difficult for colorblind users, and using color to highlight important elements (e.g., a red button for "Stop").

Dependencies:
* T15.G5.03: Build a leaderboard or high‑score display
* T15.G4.02: Style widget appearance





ID: T15.G6.03.01
Topic: T15 – User Interfaces
Skill: Control widget layering with z-index
Description: Control widget layering and stacking order using z-index. Use the "set z-index" block to determine which widgets appear on top of others (higher z-index = appears in front). Create overlays, popup messages, or modal dialogs that appear over other interface elements. Understand the default z-index (10) and how to use values like 1 (background) to 100 (topmost) to organize interface layers.

Dependencies:
* T15.G6.03: Use color and contrast to improve readability
* T15.G5.08: Create confirmation dialogs with custom buttons





ID: T15.G6.03.02
Topic: T15 – User Interfaces
Skill: Manage widget states and focus for clear feedback
Description: Manage widget states to provide clear feedback. Use "disable widget" to grey out and prevent interaction. Use "enable widget" to restore interactivity. Use "release focus for widget [NAME]" to deselect/unfocus widgets (remove cursor from text fields, deselect buttons). Use "set widget visible" to show loading indicators or success messages. Change widget text colors to red for errors, green for success. Widget state management helps users understand what actions are available.

Dependencies:
* T15.G6.03: Use color and contrast to improve readability
* T08.G4.10: Trace nested conditions to predict outcomes





ID: T15.G6.04
Topic: T15 – User Interfaces
Skill: Create an interface that works on different screen sizes
Description: Create interfaces that adapt to different screen sizes using the "apply layout row" block. Define multiple rows with percentage heights summing to 100% (e.g., Row 1: 15% header, Row 2: 70% content, Row 3: 15% footer). Divide each row into cells with percentage widths (e.g., 20% 60% 20% for sidebar/content/sidebar). Widgets placed in cells automatically resize and reposition as screen size changes. The layout system eliminates manual coordinate calculations and makes your interface responsive on tablets, phones, and computers.

Dependencies:
* T15.G5.01: Create a multi-screen app with navigation
* T15.G5.04: Implement a responsive HUD that reacts to game state
* T15.G4.01: Style widget text properties


ID: T15.G6.04.01
Topic: T15 – User Interfaces
Skill: Test interface on multiple device sizes
Description: Systematically test your interface on different screen sizes and orientations. **Testing process:** (1) Use CreatiCode's stage resize to simulate phone, tablet, and desktop sizes, (2) Check that all widgets remain visible and usable, (3) Verify text is readable at each size, (4) Confirm touch targets are large enough for fingers on mobile. **Common issues:** Overlapping widgets at small sizes, text too small to read, buttons too close together for touch. Document issues found and use responsive layout to fix them.

Dependencies:
* T15.G6.04: Create an interface that works on different screen sizes





ID: T15.G6.05
Topic: T15 – User Interfaces
Skill: Display camera feed in a widget
Description: Use "show [front/back v] camera in [normal/flipped v] x (X) y (Y) width (WIDTH) height (HEIGHT) as [NAME]" block to display a live camera feed. Choose front or back camera, normal or flipped (mirror) mode, and set position/size. Use "save picture from camera [CAMERANAME v] as costume [COSTUMENAME]" to capture a snapshot as a costume. Each snapshot creates a new costume in the sprite's costume list. Use "delete costume [COSTUMENAME]" to remove saved snapshots you no longer need to avoid filling up the costume list. Camera widgets enable photo-taking apps, video chat interfaces, or augmented reality features.

Dependencies:
* T15.G5.05: Embed and control a video widget
* T15.G4.02.01: Add an image widget to the stage





ID: T15.G6.06
Topic: T15 – User Interfaces
Skill: Add a menu bar widget
Description: Use "add menu bar at X (X) Y (Y) width (WIDTH) height (HEIGHT) as [NAME]" block to create an empty application-style menu bar. The menu bar widget provides a horizontal bar at the specified position where you can add menu groups (like File, Edit, View, Help). The menu bar is initially empty and displays no menus until you add menu groups using skill T15.G6.06.01. Menu bars are common in desktop applications and provide organized access to commands and features. Position the menu bar at the top of your interface (Y around 170) for a traditional application layout.

Dependencies:
* T15.G5.01: Create a multi‑screen app with a navigation interface
* T15.G4.03: Add a dropdown menu widget





ID: T15.G6.06.01
Topic: T15 – User Interfaces
Skill: Add menu groups and items to menu bar
Description: After creating a menu bar, use "add menu group [GROUPNAME] to menu bar named [MENUBARNAME v]" block to add menu groups (File, Edit, View, Help). Each group appears as a clickable label on the menu bar. Then use "add menu item [ITEMNAME] to menu group named [GROUPNAME v]" block to add items within each group. When users click a group name, a dropdown appears showing all items in that group. Organize related commands into logical groups (File: New, Open, Save; Edit: Cut, Copy, Paste; View: Zoom In, Zoom Out). Menu groups and items create a hierarchical navigation structure.

Dependencies:
* T15.G6.06: Add a menu bar widget
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T15.G6.06.02
Topic: T15 – User Interfaces
Skill: Handle menu item click events
Description: Use "when menu item [ITEMNAME] from group [GROUPNAME] clicked" event block to respond when users select menu items. Connect menu selections to actions (show/hide widgets, change settings, trigger functions, broadcast messages). For example, "when menu item [Save] from group [File] clicked" can save project data to a list. Compare menu bars to other navigation patterns: menu bars are best for many organized commands (like desktop apps), dropdowns are best for selecting one option from a list, tabs are best for switching between different views, and buttons are best for 2-4 primary actions.

Dependencies:
* T15.G6.06.01: Add menu groups and items to menu bar
* T06.G3.02: Build a key‑press script that controls a sprite





ID: T15.G6.07
Topic: T15 – User Interfaces
Skill: Navigate to other projects
Description: Use "run project [PROJECTID] in [new/this v] browser tab" block to launch another CreatiCode project. The target project auto-starts in full stage mode. Choose "new" to open in a new browser tab (keeps current project running) or "this" to replace the current project. Use "open URL [URL] in new browser tab" to open external websites. Project navigation enables creating multi-project experiences, portfolios with project menus, or educational sequences where completing one project leads to the next.

Dependencies:
* T15.G5.01: Create a multi‑screen app with a navigation interface


ID: T15.G6.07.01
Topic: T15 – User Interfaces
Skill: Recognize navigation patterns (tabs, menus, wizards)
Description: Identify and compare different navigation patterns and when to use each. **Tabs:** Best for 3-6 parallel sections where user might switch frequently (settings, profile sections). **Menus:** Best for many organized commands in a hierarchical structure (desktop apps). **Wizards:** Best for sequential multi-step processes where order matters (signup, checkout). **Bottom nav:** Best for mobile apps with 3-5 main sections. **Activity:** Given an app description, recommend the best navigation pattern and justify your choice.

Dependencies:
* T15.G6.07: Navigate to other projects
* T15.G6.06.02: Handle menu item click events


ID: T15.G6.08
Topic: T15 – User Interfaces
Skill: Trace user interaction paths through multi-screen app
Description: Trace and document all possible paths a user can take through a multi-screen application. **Activity:** Given a multi-screen app (home, game, settings, help), draw a diagram showing: which screens connect to which, what actions trigger navigation, what data is passed between screens. **Example path:** Home → click "Play" → Game → click "Pause" → Settings → click "Resume" → Game. **Skill focus:** Understand app architecture and identify navigation problems (dead ends, missing back buttons).

Dependencies:
* T15.G5.01.01: Use variables to track current screen state
* T15.G6.01: Evaluate an interface for usability


ID: T15.G6.09
Topic: T15 – User Interfaces
Skill: Create user personas for design decisions
Description: Create fictional user personas to guide interface design decisions. **Persona components:** (1) Name and photo (fictional), (2) Age and background, (3) Goals - what do they want to achieve?, (4) Pain points - what frustrates them?, (5) Technical comfort level. **Example persona:** "Maya, 10, loves games but gets confused by too many buttons. Goal: play quickly without reading manuals. Pain point: small text, complicated menus." **Usage:** When designing, ask "Would Maya understand this?" _Personas keep design focused on real user needs._

Dependencies:
* T15.G6.02: Design an interface based on user feedback
* T15.G6.01: Evaluate an interface for usability


ID: T15.G6.10
Topic: T15 – User Interfaces
Skill: Write user stories for interface features
Description: Write user stories in the standard format: "As a [user type], I want [goal] so that [reason]." **Examples:** "As a player, I want to see my high score so that I know if I'm improving." "As a parent, I want to pause the game so that my child takes breaks." **Structure:** User stories describe WHAT the interface should do from the USER's perspective, not HOW it's built. **Activity:** Given an app idea, write 5 user stories that define key features. **Benefit:** User stories prevent building features nobody needs. _Foundation for professional software development._

Dependencies:
* T15.G6.09: Create user personas for design decisions


ID: T15.G6.11
Topic: T15 – User Interfaces
Skill: Build a complete CRUD interface
Description: Build an interface that supports Create, Read, Update, and Delete operations on a list of items. **Components:** (1) Create: Form to add new items, (2) Read: List display showing all items, (3) Update: Edit button that opens item in form for modification, (4) Delete: Remove button with confirmation dialog. **Data flow:** All operations modify a shared list variable → list display updates automatically. **Example:** Contact manager with add contact, view contacts, edit contact, delete contact. _CRUD is the foundation of most data-driven applications._

Dependencies:
* T15.G5.13: Implement master-detail with editing
* T15.G5.08: Create confirmation dialogs with custom buttons


# ============ GRADE 7 (18 skills) ============
# Data collection, search/filter, accessibility, charts, voice UI, error handling, state machines, user journeys, design systems

ID: T15.G7.01
Topic: T15 – User Interfaces
Skill: Build a data collection interface (survey/questionnaire)
Description: Design an interface for a survey or questionnaire. **Components:** Text inputs for open questions, dropdowns for multiple-choice, checkboxes for multi-select, radio buttons for single-select. **Validation:** Check that required fields are filled, display error messages for empty/invalid inputs. **Data handling:** Store responses in variables or lists. Create a submit button that validates all inputs and displays a confirmation.

Dependencies:
* T15.G6.03: Use color and contrast to improve readability
* T15.G5.02: Design a form with multiple inputs and validation





ID: T15.G7.02
Topic: T15 – User Interfaces
Skill: Implement a search or filter interface
Description: Students create a text input field where users can type a query, and the interface filters or searches a list of items (e.g., a player inventory, a menu of options) to show only matching results. This is a real-world UI pattern.

Dependencies:
* T15.G6.04: Create an interface that works on different screen sizes
* T15.G5.02: Design a form with multiple inputs and validation


ID: T15.G7.02.01
Topic: T15 – User Interfaces
Skill: Implement pagination for large data sets
Description: Design interfaces that display large data sets in manageable pages. **Components:** "Previous" and "Next" buttons, page number display (e.g., "Page 2 of 10"), items per page selector. **Logic:** Calculate total pages from data length and page size. Track current page in variable. Display only items for current page (e.g., items 11-20 for page 2 with 10 per page). **UX patterns:** Disable "Previous" on first page, disable "Next" on last page, show loading state during page changes.

Dependencies:
* T15.G7.02: Implement a search or filter interface
* T15.G5.03: Build a leaderboard or high-score display





ID: T15.G7.03
Topic: T15 – User Interfaces
Skill: Design an accessible interface for users with different abilities
Description: Students consider accessibility needs (e.g., text size for low vision, keyboard controls for mobility challenges, colorblind-friendly palettes) and redesign an interface to accommodate multiple ability types. They learn to design inclusively from the start.

Dependencies:
* T15.G6.03: Use color and contrast to improve readability
* T15.G6.04: Create an interface that works on different screen sizes





ID: T15.G7.04
Topic: T15 – User Interfaces
Skill: Create a help or tutorial interface
Description: Students design a help or tutorial interface within a game, including explanatory labels, step-by-step instructions, images/animations, and a "Next" button to guide the player through mechanics or controls.

Dependencies:
* T15.G6.04: Create an interface that works on different screen sizes
* T15.G5.01: Create a multi‑screen app with a navigation interface





ID: T15.G7.05
Topic: T15 – User Interfaces
Skill: Display data as charts in a widget
Description: Use "draw [bar/line/pie/percentage v] chart using list [LISTNAME v] x (X) y (Y) width (WIDTH) height (HEIGHT)" or "draw chart using columns [COLUMNLIST] from table [TABLENAME v]..." blocks to create data visualizations. Use bar charts for comparisons, line charts for trends over time, pie charts for proportions, and percentage charts for part-to-whole relationships. Charts can use either list data (single series) or table data (multiple series). Charts transform raw numbers into visual representations that help users understand patterns and comparisons.

Dependencies:
* T15.G5.03: Build a leaderboard or high‑score display
* T10.G5.01: Search and sort a list





ID: T15.G7.06
Topic: T15 – User Interfaces
Skill: Integrate voice feedback with UI elements
Description: Combine UI widgets with AI Speaker for voice feedback. **Patterns:** Read button labels aloud when hovered, announce state changes ("Volume set to 80%"), confirm actions ("Game saved"), read error messages aloud. Use "AI Speaker" block triggered by widget events. Voice feedback improves accessibility for users with visual impairments and creates more immersive experiences.

Dependencies:
* T15.G6.03.02: Manage widget states and focus for clear feedback
* T15.G5.04.02: Animate widgets for visual feedback


ID: T15.G7.07
Topic: T15 – User Interfaces
Skill: Design keyboard-navigable interfaces
Description: Design interfaces that work without a mouse using keyboard controls. **Patterns:** Tab key moves focus between widgets, Enter activates focused button, arrow keys navigate within widget groups. **Visual feedback:** Highlight focused widget with border or glow effect. **Implementation:** Use "when key pressed" events combined with focus tracking variable. Essential for accessibility and power users.

Dependencies:
* T15.G7.03: Design an accessible interface for users with different abilities
* T15.G6.03.02: Manage widget states and focus for clear feedback


ID: T15.G7.08
Topic: T15 – User Interfaces
Skill: Implement loading states and progress feedback
Description: Design loading states that keep users informed during slow operations. **Components:** Progress bar for known durations, spinning indicator for unknown durations, status text explaining what's happening. **Patterns:** Show "Loading..." immediately, update progress percentage, display "Complete!" then auto-close. **Best practices:** Never freeze UI without feedback, provide cancel option for long operations.

Dependencies:
* T15.G5.04.01: Add and update a progress bar widget
* T15.G6.03.02: Manage widget states and focus for clear feedback


ID: T15.G7.09
Topic: T15 – User Interfaces
Skill: Design error handling and user feedback patterns
Description: Create clear error messages and feedback systems. **Error display:** Red border on invalid fields, error message near the problem, list of all errors at form top. **Success feedback:** Green checkmarks, confirmation messages, smooth transitions. **Recovery guidance:** Explain what went wrong AND how to fix it ("Email missing @ - enter a valid email address"). **Timing:** Show errors immediately on invalid input or after submit attempt.

Dependencies:
* T15.G7.01: Build a data collection interface (survey/questionnaire)
* T15.G6.03: Use color and contrast to improve readability


ID: T15.G7.09.01
Topic: T15 – User Interfaces
Skill: Debug accessibility failures using testing criteria
Description: Systematically test and debug accessibility problems in interfaces. **Testing criteria:** (1) All interactive elements reachable via keyboard, (2) Text contrast ratio meets 4.5:1 minimum, (3) Error messages announced clearly, (4) Form labels connected to inputs. **Debug process:** Use accessibility checklist, test with keyboard-only navigation, verify color contrast. **Activity:** Given an interface with accessibility bugs, identify problems and implement fixes. _Develops systematic accessibility testing._

Dependencies:
* T15.G7.07: Design keyboard-navigable interfaces
* T15.G7.09: Design error handling and user feedback patterns


ID: T15.G7.10
Topic: T15 – User Interfaces
Skill: Identify state machine patterns in complex UIs
Description: Recognize and implement state machine patterns for managing complex UI states. **States:** idle, loading, success, error, disabled. **Transitions:** User actions (click, type) or system events (data loaded, timeout) trigger state changes. **Example:** Form states: empty → typing → validating → valid/invalid → submitting → success/error. **Implementation:** Use variable to track current state, update widget visibility/styling based on state. **Benefits:** Predictable behavior, easier debugging, clearer code.

Dependencies:
* T15.G7.08: Implement loading states and progress feedback
* T15.G6.08: Trace user interaction paths through multi-screen app


ID: T15.G7.11
Topic: T15 – User Interfaces
Skill: Use AI to generate UI layouts from descriptions
Description: Use AI tools to generate UI layout ideas from natural language descriptions. **Process:** (1) Describe desired interface in words ("I need a settings screen with volume slider, theme selector, and save button"), (2) Review AI suggestions, (3) Evaluate against usability criteria, (4) Implement and refine. **Critical thinking:** AI suggestions may have accessibility issues or poor layouts - always evaluate and improve. **Activity:** Generate a layout from description, critique it, then implement an improved version.

Dependencies:
* T15.G7.03: Design an accessible interface for users with different abilities
* T15.G6.02: Design an interface based on user feedback


ID: T15.G7.12
Topic: T15 – User Interfaces
Skill: Map user journeys through an interface
Description: Create user journey maps that document the complete experience of using an interface. **Journey components:** (1) Entry point - how user arrives, (2) Steps - sequence of actions to achieve goal, (3) Touchpoints - each screen/interaction, (4) Emotions - how user feels at each step (frustrated, confident, confused), (5) Pain points - where things go wrong. **Example:** Journey for "buy item in game store": See item → Check coins → Click buy → Confirm → See success → Item in inventory. **Pain points:** Unclear price, no confirmation, can't find item after. _Journey maps reveal problems invisible in static designs._

Dependencies:
* T15.G6.08: Trace user interaction paths through multi-screen app
* T15.G6.10: Write user stories for interface features


ID: T15.G7.13
Topic: T15 – User Interfaces
Skill: Conduct lightweight user interviews
Description: Gather user feedback through simple interview techniques. **Before building:** Ask "What do you want to do?" "What frustrates you about current solutions?" **After prototype:** Ask "What were you trying to do?" "Where did you get stuck?" "What did you expect to happen?" **Interview tips:** Don't lead ("Is this confusing?"), ask open questions ("Tell me what you see"), watch what they DO not just what they SAY. **Documentation:** Record key quotes, note observed behaviors, identify patterns across users. _Direct user feedback prevents building the wrong thing._

Dependencies:
* T15.G6.09: Create user personas for design decisions
* T15.G7.09: Design error handling and user feedback patterns


ID: T15.G7.14
Topic: T15 – User Interfaces
Skill: Define a color palette and typography scale
Description: Create a consistent color and typography system for an interface. **Color palette:** Primary (main brand color), Secondary (accent), Background, Text, Error (red), Success (green), Warning (yellow). **Typography scale:** Define 4-6 text sizes with clear purposes (H1 for page titles, H2 for sections, Body for content, Caption for small text). **Usage rules:** Document when to use each color/size. **Consistency benefit:** Every widget using the same palette looks unified. _Design systems start with these foundational decisions._

Dependencies:
* T15.G6.03: Use color and contrast to improve readability
* T15.G7.03: Design an accessible interface for users with different abilities


ID: T15.G7.15
Topic: T15 – User Interfaces
Skill: Create spacing and sizing standards
Description: Define consistent spacing and sizing rules for interface layout. **Spacing scale:** Use multiples of a base unit (e.g., 4px, 8px, 16px, 24px, 32px, 48px). **Sizing standards:** Button height (40px standard, 48px for mobile), input field height, icon sizes. **Spacing rules:** Space between related items (8px), between groups (24px), page margins (16-32px). **Why this matters:** Consistent spacing makes interfaces feel organized and professional. Random spacing looks messy. _Professional designers follow strict spacing systems._

Dependencies:
* T15.G7.14: Define a color palette and typography scale
* T15.G6.04: Create an interface that works on different screen sizes


ID: T15.G7.16
Topic: T15 – User Interfaces
Skill: Build a search/filter/sort interface combination
Description: Create an interface combining search, filter, and sort for exploring large data sets. **Components:** (1) Search textbox for text queries, (2) Filter dropdowns/checkboxes to narrow by category, (3) Sort dropdown to order results (A-Z, newest, price). **Data flow:** All three controls affect the same list display. **Implementation:** Store filtered results in separate list, update display when any control changes. **UX patterns:** Show result count, remember filter state, provide "Clear filters" button. **Real examples:** App stores, shopping sites, file explorers.

Dependencies:
* T15.G7.02: Implement a search or filter interface
* T15.G7.02.01: Implement pagination for large data sets


# ============ GRADE 8 (21 skills) ============
# Advanced UX: wizards, dynamic content, usability testing, AI-human collaboration, design systems, dashboards

ID: T15.G8.01
Topic: T15 – User Interfaces
Skill: Design a wizard or step-by-step interface
Description: Build a "wizard" interface that guides users through a multi-step process (character creation, game setup, checkout). **Components:** Previous/Next buttons, progress indicator showing current step, validation at each step before allowing progression. **State management:** Track current step number, store collected data across steps. **UX patterns:** Disable Next until required fields are valid, show summary at final step.

Dependencies:
* T15.G7.04: Create a help or tutorial interface
* T15.G7.03: Design an accessible interface for users with different abilities





ID: T15.G8.02
Topic: T15 – User Interfaces
Skill: Implement dynamic content loading in a UI
Description: Design an interface where selecting an option dynamically loads and displays related content. **Example:** Clicking a character name displays their stats in a details panel; clicking a level shows its preview. **Implementation:** Store content data in lists/tables, use selection index to retrieve and display matching data. **UX patterns:** Show loading state while content loads, highlight selected item, clear previous content before showing new.

Dependencies:
* T15.G7.02: Implement a search or filter interface
* T15.G7.01: Build a data collection interface (survey/questionnaire)





ID: T15.G8.03
Topic: T15 – User Interfaces
Skill: Analyze UI design patterns and their effectiveness
Description: Examine two different interface designs for the same task (two settings menu layouts, two number input methods) and evaluate effectiveness. **Criteria:** Clarity (is the purpose obvious?), ease of use (how many clicks/steps?), accessibility (works for all users?), aesthetics (visually appealing?). **Activity:** Given two designs, write analysis comparing them on each criterion, recommend which is better and why.

Dependencies:
* T15.G7.03: Design an accessible interface for users with different abilities
* T15.G6.02: Design an interface based on user feedback






ID: T15.G8.04
Topic: T15 – User Interfaces
Skill: Conduct usability testing and refine UI design
Description: Conduct user testing of an interface and iterate based on findings. **Test protocol:** Give peers a specific task to complete using your interface, observe silently, note where they struggle/hesitate/make errors. **Documentation:** Record observations (what confused users, what took too long, what worked well). **Iteration:** Prioritize issues by severity, redesign problematic areas, retest to verify improvements. This reinforces the human-centered design cycle.

Dependencies:
* T15.G8.03: Analyze UI design patterns and their effectiveness
* T15.G6.02: Design an interface based on user feedback


ID: T15.G8.05
Topic: T15 – User Interfaces
Skill: Build an AI-integrated chat interface
Description: Create a chat interface that integrates with AI services. **Components:** Chat window widget for message history, text input for user queries, send button, loading indicator while waiting for AI response. **AI integration:** Send user input to AI service, receive streaming response, update chat with AI reply using streaming message updates. **UX considerations:** Show "typing" indicator, handle errors gracefully, allow conversation history to scroll.

Dependencies:
* T15.G7.05: Display data as charts in a widget
* T15.G5.06.03: Update streaming chat messages


ID: T15.G8.05.01
Topic: T15 – User Interfaces
Skill: Handle AI response errors gracefully
Description: Design robust error handling for AI-integrated interfaces. **Error types:** Network failures (no internet), timeout (AI takes too long), API errors (rate limits, invalid responses), empty responses. **UI patterns:** Show friendly error message instead of technical details, offer "Retry" button, indicate what went wrong and what user can do. **Implementation:** Wrap AI calls in error handling, set timeouts, validate responses before displaying. **User experience:** Never leave user wondering what happened - always show feedback.

Dependencies:
* T15.G8.05: Build an AI-integrated chat interface
* T15.G7.09: Design error handling and user feedback patterns


ID: T15.G8.06
Topic: T15 – User Interfaces
Skill: Design data-driven dashboard interfaces
Description: Build a dashboard that displays multiple data visualizations and controls. **Layout:** Use responsive layout system to create grid of widgets (charts, labels, controls). **Data sources:** Connect widgets to list/table data that updates in real-time. **Interactivity:** Use dropdowns/buttons to filter data, update all related visualizations when filters change. **Real-world application:** Game stats dashboard, weather display, project tracker.

Dependencies:
* T15.G8.02: Implement dynamic content loading in a UI
* T15.G7.05: Display data as charts in a widget


ID: T15.G8.07
Topic: T15 – User Interfaces
Skill: Implement AI-assisted form completion
Description: Create smart forms that use AI to assist users. **Auto-complete:** Suggest completions as user types based on common inputs or AI predictions. **Smart defaults:** Pre-fill fields based on context or user history. **Validation suggestions:** When input is invalid, use AI to suggest corrections ("Did you mean...?"). **Implementation:** Send partial input to AI service, display suggestions in dropdown, apply selection on click.

Dependencies:
* T15.G8.05: Build an AI-integrated chat interface
* T15.G7.09: Design error handling and user feedback patterns


ID: T15.G8.08
Topic: T15 – User Interfaces
Skill: Design adaptive interfaces based on user behavior
Description: Create interfaces that adapt based on how users interact. **Tracking:** Monitor which buttons are clicked most, how long users spend on screens, which features are ignored. **Adaptation:** Reorder menu items by frequency, show shortcuts for common actions, hide rarely-used features in "More" menus. **Personalization:** Remember user preferences, adjust layouts based on past behavior. This introduces user-centered adaptive design.

Dependencies:
* T15.G8.04: Conduct usability testing and refine UI design
* T15.G8.02: Implement dynamic content loading in a UI


ID: T15.G8.09
Topic: T15 – User Interfaces
Skill: Build multi-modal input interfaces
Description: Design interfaces that accept multiple input types simultaneously. **Input modes:** Touch (joystick, buttons), voice (speech recognition), keyboard, mouse, gestures (hand tracking). **Mode switching:** Auto-detect available inputs, allow seamless switching between modes. **Feedback:** Provide visual confirmation for voice commands, audio confirmation for touch. **Accessibility:** Multiple input modes ensure usability for users with different abilities.

Dependencies:
* T15.G7.06: Integrate voice feedback with UI elements
* T15.G5.09.01: Read joystick input values


ID: T15.G8.10
Topic: T15 – User Interfaces
Skill: Create a design system with reusable components
Description: Build a cohesive design system for consistent UI across a large project. **Components:** Define standard button styles (primary, secondary, danger), input field styles, label styles, color palette, spacing rules. **Documentation:** Create a reference project showing all component styles. **Reusability:** Use variables for colors/sizes so changing one value updates all components. **Benefits:** Faster development, consistent look, easier maintenance.

Dependencies:
* T15.G8.03: Analyze UI design patterns and their effectiveness
* T15.G6.04: Create an interface that works on different screen sizes


ID: T15.G8.11
Topic: T15 – User Interfaces
Skill: Design interfaces for real-time collaboration
Description: Build UI patterns for multi-user collaborative experiences. **Components:** User presence indicators (who's online), cursor/pointer sharing visualization, shared editing indicators, conflict resolution displays. **Patterns:** Show other users' actions in real-time, highlight edited sections, display "User X is typing..." or "User Y is editing this field". **Implementation:** Use fast-updating cloud variables to sync user states. **Challenges:** Handle multiple simultaneous edits, show changes without disrupting current user's work.

Dependencies:
* T15.G8.08: Design adaptive interfaces based on user behavior
* T15.G7.08: Implement loading states and progress feedback


ID: T15.G8.12
Topic: T15 – User Interfaces
Skill: Design reusable UI component patterns
Description: Create reusable UI component patterns that can be applied across projects. **Component design:** Define widget configurations (styles, positions, behaviors) that solve common UI needs. **Pattern library:** Card pattern (image + title + description + button), Form field pattern (label + input + error message), Modal pattern (overlay + content + close button). **Reusability:** Create custom blocks or clone scripts to generate consistent components. **Documentation:** Describe when to use each pattern and how to customize it.

Dependencies:
* T15.G8.10: Create a design system with reusable components
* T15.G7.10: Identify state machine patterns in complex UIs


ID: T15.G8.12.01
Topic: T15 – User Interfaces
Skill: Design automated UI testing approaches
Description: Design approaches to automatically test UI behavior without manual clicking. **Testing patterns:** (1) Use console logging to trace execution, (2) Create "test mode" that runs simulated user actions, (3) Verify widget states match expected values after each action. **Test automation:** Write scripts that create widgets, simulate interactions, and check results. **Benefits:** Catch bugs before users do, test quickly after changes, document expected behavior. **Limitations:** Cannot test visual appearance automatically.

Dependencies:
* T15.G8.04: Conduct usability testing and refine UI design
* T15.G5.10.01: Test UI behavior matches specifications


ID: T15.G8.13
Topic: T15 – User Interfaces
Skill: Validate AI-generated UI code
Description: Critically evaluate and improve AI-generated UI code. **Validation criteria:** (1) Accessibility - does it work for all users? (2) Responsiveness - does it adapt to screen sizes? (3) Consistency - does it follow design system? (4) Performance - does it create unnecessary widgets? **Process:** Generate UI with AI, review against criteria, fix issues, test thoroughly. **Common AI mistakes:** Poor widget naming, missing error handling, accessibility issues, inconsistent styling. _Develops critical evaluation of AI-generated solutions._

Dependencies:
* T15.G7.11: Use AI to generate UI layouts from descriptions
* T15.G8.05.01: Handle AI response errors gracefully


ID: T15.G8.14
Topic: T15 – User Interfaces
Skill: Trace usability issues to root causes
Description: Systematically diagnose and trace usability problems to their root causes. **Symptoms → Causes:** "Users can't find the button" → poor placement, low contrast, confusing label, too many competing elements. **Analysis process:** (1) Document symptom precisely, (2) List possible causes, (3) Test each hypothesis, (4) Identify root cause, (5) Design solution. **Activity:** Given usability test results showing problems, trace each to root cause and propose fix. _Develops systematic UX debugging skills._

Dependencies:
* T15.G8.04: Conduct usability testing and refine UI design
* T15.G7.09.01: Debug accessibility failures using testing criteria


ID: T15.G8.15
Topic: T15 – User Interfaces
Skill: Build a component library with documentation
Description: Create a documented library of reusable UI components for a project or team. **Library contents:** Button variants (primary, secondary, danger, disabled), Input fields (text, number, password), Cards, Modals, Navigation elements. **Documentation for each:** Name, visual example, when to use, code to create, customization options. **Organization:** Group by type (inputs, buttons, feedback, layout). **Benefit:** New team members can build consistent interfaces without starting from scratch. _Component libraries are how professional teams maintain quality at scale._

Dependencies:
* T15.G8.12: Design reusable UI component patterns
* T15.G7.15: Create spacing and sizing standards


ID: T15.G8.16
Topic: T15 – User Interfaces
Skill: Version and evolve a design system
Description: Manage changes to a design system over time. **Version tracking:** Document what changed in each version (v1.0 → v1.1: added danger button, updated error color). **Backwards compatibility:** When changing components, consider existing interfaces using old versions. **Deprecation process:** Mark old patterns as "deprecated" before removing. **Communication:** Share updates with team so everyone uses latest patterns. **Evolution:** Design systems grow based on new needs - add components as needed, refine existing ones. _Real design systems are living documents that evolve._

Dependencies:
* T15.G8.15: Build a component library with documentation
* T15.G8.03: Analyze UI design patterns and their effectiveness


ID: T15.G8.17
Topic: T15 – User Interfaces
Skill: Use AI to generate and refine UI mockups iteratively
Description: Use AI as a collaborative design partner through multiple iterations. **Process:** (1) Describe initial requirements to AI, (2) Review generated layout, (3) Provide specific feedback ("make the buttons larger", "add more contrast", "reorganize into tabs"), (4) AI generates improved version, (5) Repeat until satisfied, (6) Implement final design. **Key skill:** Writing effective prompts that clearly describe what you want changed. **Critical evaluation:** Always verify AI suggestions against accessibility and usability criteria. _AI accelerates design but humans make final decisions._

Dependencies:
* T15.G7.11: Use AI to generate UI layouts from descriptions
* T15.G8.13: Validate AI-generated UI code


ID: T15.G8.18
Topic: T15 – User Interfaces
Skill: Implement AI copilot features in interfaces
Description: Design interfaces where AI assists users with their tasks. **Copilot patterns:** (1) Auto-complete: AI suggests completions as user types, (2) Smart defaults: AI pre-fills fields based on context, (3) Recommendations: AI suggests next actions, (4) Explanation: AI explains why something happened. **UI considerations:** Show AI suggestions clearly but non-intrusively, allow easy acceptance/rejection, indicate confidence level, provide "why" explanations. **Example:** Writing assistant that suggests sentence completions, shows grammar fixes, explains corrections.

Dependencies:
* T15.G8.07: Implement AI-assisted form completion
* T15.G8.05: Build an AI-integrated chat interface


ID: T15.G8.19
Topic: T15 – User Interfaces
Skill: Design human-in-the-loop AI interfaces
Description: Build interfaces where humans oversee and correct AI decisions. **Pattern:** AI makes suggestion → Human reviews → Human approves, modifies, or rejects → System learns from feedback. **UI components:** Clear display of AI suggestion, easy approve/reject buttons, edit capability to modify suggestion, explanation of AI reasoning, feedback mechanism. **Examples:** AI-suggested image tags that humans verify, AI-generated summaries that humans edit, AI content moderation with human review. **Critical principle:** AI assists but human makes final decision on important matters.

Dependencies:
* T15.G8.18: Implement AI copilot features in interfaces
* T15.G8.08: Design adaptive interfaces based on user behavior


ID: T15.G8.20
Topic: T15 – User Interfaces
Skill: Design dashboard composition patterns
Description: Create effective data dashboards by composing multiple visualization widgets. **Dashboard layout patterns:** (1) Overview + detail: Summary cards at top, detailed charts below, (2) KPI-focused: Key metrics prominently displayed with supporting context, (3) Comparative: Side-by-side charts for comparison, (4) Drill-down: Click summary to see details. **Composition principles:** Most important data at top-left, related charts grouped together, consistent styling across all charts, clear labels and legends. **Interactivity:** Filters that affect all charts, hover for details, click to drill down. _Dashboards tell a data story through visual composition._

Dependencies:
* T15.G8.06: Design data-driven dashboard interfaces
* T15.G7.16: Build a search/filter/sort interface combination


# T16 - 2D Motion & Physics (COMPLETE IMPROVED VERSION)

# MAJOR IMPROVEMENTS IMPLEMENTED:
#
# 1. ENHANCED K-2 FOUNDATION (Added 4 new picture-based skills):
#    - T16.K.05: Identify relative motion between objects
#    - T16.G1.04: Predict acceleration effects
#    - T16.G2.05: Trace energy transfer in collision chains
#    - T16.G2.06: Identify friction effects on motion
#
# 2. STRENGTHENED G3-G4 BRIDGE (Added 4 new skills):
#    - T16.G3.04: Use motion blocks to draw shapes
#    - T16.G4.04: Debug a broken motion animation
#    - T16.G4.05: Create smooth motion using glide blocks
#    - T16.G4.06: Build a simple racing game
#
# 3. PARALLEL TRACK STRUCTURE FOR G5:
#    - Track A (G5.01-G5.04): Manual physics with variables
#    - Track B (G5.05-G5.13): Engine-based physics
#    - T16.G5.14: Compare manual vs engine approaches (capstone)
#
# 4. COMPUTATIONAL THINKING SKILLS G6-G7:
#    - T16.G6.10: Predict collision outcomes
#    - T16.G6.11: Debug sprites passing through walls
#    - T16.G7.09: Trace physics simulation frame-by-frame
#    - T16.G7.10: Design physics experiment
#
# 5. AI INTEGRATION SKILLS G8:
#    - T16.G8.12: Create AI-controlled physics objects
#    - T16.G8.13: Use ML to optimize physics parameters
#    - T16.G8.14: Implement procedural level generation
#    - T16.G8.15: Build adaptive difficulty using physics telemetry
#
# 6. FIXED DEPENDENCY ISSUES:
#    - T16.G6.01 and G6.02 now reference correct skill names
#
# 7. ADDED SUB-SKILLS FOR DEPTH:
#    - T16.G5.06.04: Match collision shape to sprite artwork
#    - T16.G6.04.05: Create one-way platforms
#    - T16.G7.01.03: Calculate optimal launch angle


ID: T16.K.01
Topic: T16 – 2D Motion & Physics
Skill: Identify which sprite moved (picture-based)
Description: **Student task:** Look at two "before" and "after" picture cards showing a stage with multiple sprites. Tap the sprite that changed position. **Visual scenario:** Before card shows cat, dog, and ball in a row. After card shows dog moved to the right. Student taps the dog. **Vocabulary:** "moved," "same spot," "different spot." _Introduces the concept that motion = change in position._ Auto-graded by correct selection.

Dependencies:
None




ID: T16.K.02
Topic: T16 – 2D Motion & Physics
Skill: Match sprite to position after motion (picture-based)
Description: **Student task:** See a simple motion instruction (arrow or "move right") and choose which picture shows where the sprite will end up. **Visual scenario:** A bird is shown with a right-pointing arrow. Three pictures show the bird in different positions. Student taps the picture with the bird moved right. _Develops spatial reasoning for predicting motion._ Auto-graded by correct selection.

Dependencies:
* T16.K.01: Identify which sprite moved (picture-based)


ID: T16.K.02.01
Topic: T16 – 2D Motion & Physics
Skill: Identify direction of motion from trail marks (picture-based)
Description: **Student task:** Look at pictures showing sprites with trail marks (footprints, tire tracks, dotted lines) and identify which direction each sprite moved. **Visual scenario:** A duck picture shows footprints going from left to right. Student drags an arrow pointing right. A car shows tire marks curving upward. Student drags an arrow pointing up. **Vocabulary:** "trail," "path," "footprints," "tracks," "direction." _Introduces visual tracing as motion evidence._ Auto-graded by correct arrow placement.

Dependencies:
* T16.K.02: Match sprite to position after motion (picture-based)


ID: T16.K.03
Topic: T16 – 2D Motion & Physics
Skill: Identify objects that fall down (picture-based)
Description: **Student task:** Sort picture cards of objects into "falls down" and "stays up" piles. **Visual scenario:** Cards show: apple on table edge, balloon tied to string, ball in the air, bird flying, rock on a hill. Students sort based on everyday experience. **Discussion:** What makes things fall? (Gravity pulls things down.) _First introduction to gravity concept._ Auto-graded by correct sorting.

Dependencies:
* T16.K.01: Identify which sprite moved (picture-based)


ID: T16.K.04
Topic: T16 – 2D Motion & Physics
Skill: Sequence two motion steps (picture-based)
Description: **Student task:** Look at picture cards showing two motion steps (arrow right, then arrow up) and choose which final position picture is correct. **Visual scenario:** Cat starts in bottom-left. Card 1 shows "right arrow," Card 2 shows "up arrow." Four choices show cat in different corners. Student picks cat in top-right (moved right then up). **Vocabulary:** "first," "then," "after that." _Builds sequential motion thinking before coding._ Auto-graded by correct selection.

Dependencies:
* T16.K.02: Match sprite to position after motion (picture-based)


ID: T16.K.05
Topic: T16 – 2D Motion & Physics
Skill: Identify relative motion between objects (picture-based)
Description: **Student task:** Look at two animations playing side-by-side and identify which sprite moves faster relative to the other. **Visual scenario:** Two cars drive from left to right. Car A takes 5 seconds to cross the screen, Car B takes 3 seconds. Student taps Car B as "faster." Another scenario shows both cars moving but one appears faster because the background is also moving. **Vocabulary:** "faster than," "slower than," "same speed," "relative to." _Introduces comparative motion before variables._ Auto-graded by correct selection.

Dependencies:
* T16.K.02: Match sprite to position after motion (picture-based)




ID: T16.G1.01
Topic: T16 – 2D Motion & Physics
Skill: Identify fast vs slow motion (picture-based)
Description: **Student task:** Watch two sprite animations side by side and tap which sprite moves faster. **Visual scenario:** Two cats walk across the screen—one takes small slow steps, one takes big fast leaps. Student taps the fast cat. **Vocabulary:** Students describe motion using "fast," "slow," "quick," and "gentle." _Auto-graded by correct selection._

Dependencies:
* T16.K.02: Match sprite to position after motion (picture-based)


ID: T16.G1.02
Topic: T16 – 2D Motion & Physics
Skill: Predict motion direction from arrow pictures (picture-based)
Description: **Student task:** Look at a sprite with an arrow showing its direction, then tap where the sprite will be after it moves. **Visual scenario:** A car sprite has a green arrow pointing right. Three position choices show the car left, center, or right. Student taps the right position. _This builds directional intuition for motion prediction._ Auto-graded by correct position selection.

Dependencies:
* T16.G1.01: Identify fast vs slow motion (picture-based)


ID: T16.G1.02.01
Topic: T16 – 2D Motion & Physics
Skill: Predict final position after multiple arrow moves (picture-based)
Description: **Student task:** Look at a sequence of 3 arrow cards (right, right, up) and choose which final position picture is correct. **Visual scenario:** Robot starts in bottom-left corner. Cards show: arrow right, arrow right, arrow up. Four picture choices show robot in different positions. Student picks robot in top-middle (moved right twice, then up once). **Vocabulary:** "first move," "second move," "third move," "final position." _Builds multi-step motion prediction before loops._ Auto-graded by correct picture selection.

Dependencies:
* T16.G1.02: Predict motion direction from arrow pictures (picture-based)


ID: T16.G1.03
Topic: T16 – 2D Motion & Physics
Skill: Sort objects by how they fall (picture-based)
Description: **Student task:** Sort picture cards of objects into "falls fast" and "falls slow" piles. **Visual scenario:** Cards show feather, rock, balloon, ball, leaf, brick. Students sort based on everyday experience with gravity. **Discussion:** Teacher asks why some things fall faster (heavier, less air). _Builds intuition for gravity before coding._ Auto-graded by correct sorting.

Dependencies:
* T16.K.03: Identify objects that fall down (picture-based)
* T16.G1.01: Identify fast vs slow motion (picture-based)


ID: T16.G1.04
Topic: T16 – 2D Motion & Physics
Skill: Predict acceleration effects (picture-based)
Description: **Student task:** Look at two side-by-side animations showing a car. Animation A shows the car moving at constant speed (equal spacing between position markers). Animation B shows the car speeding up (increasing spacing between markers). Student identifies which car is "speeding up" and which is "staying the same speed." **Visual scenario:** Picture cards show position snapshots at equal time intervals with spacing markers. **Vocabulary:** "speeding up," "slowing down," "constant speed," "acceleration." _Introduces acceleration concept before variables._ Auto-graded by correct identification.

Dependencies:
* T16.G1.01: Identify fast vs slow motion (picture-based)
* T16.K.05: Identify relative motion between objects (picture-based)




ID: T16.G2.01
Topic: T16 – 2D Motion & Physics
Skill: Predict sprite direction from motion blocks (picture choices)
Description: **Student task:** Look at motion blocks (move 10 steps, turn right, move 10 steps) shown as picture cards and choose which picture shows where the sprite ends up. **Visual scenario:** A cat starts facing right. Blocks show: turn left, move forward. Four picture choices show cat in different positions. Student picks the cat that moved up. _Builds directional intuition before coding._ Auto-graded by correct picture selection.

Dependencies:
* T16.G1.02: Predict motion direction from arrow pictures (picture-based)




ID: T16.G2.02
Topic: T16 – 2D Motion & Physics
Skill: Identify bouncing vs sliding motion (picture-based)
Description: **Student task:** Watch two animations and identify which shows bouncing and which shows sliding. **Visual scenario:** Animation A shows a ball hitting a wall and bouncing back. Animation B shows a box sliding along the floor and stopping. Student labels each correctly. **Vocabulary:** "bounce," "slide," "stop," "reverse direction." _Builds intuition for friction and restitution concepts._ Auto-graded by correct labeling.

Dependencies:
* T16.G2.01: Predict sprite direction from motion blocks (picture choices)


ID: T16.G2.02.01
Topic: T16 – 2D Motion & Physics
Skill: Predict which object will fall faster (picture-based)
Description: **Student task:** Look at two side-by-side animations showing objects starting to fall, then predict which will hit the ground first. **Visual scenario:** Animation setup shows a feather and a rock both released from the same height. Student selects "rock will fall faster" before animations run. After selection, animations play to confirm. **Discussion:** Why does the rock fall faster? (Heavier, less air pushes it.) _Builds gravity and mass intuition._ Auto-graded by reasonable prediction.

Dependencies:
* T16.G2.01: Predict sprite direction from motion blocks (picture choices)


ID: T16.G2.03
Topic: T16 – 2D Motion & Physics
Skill: Predict collision outcomes (picture-based)
Description: **Student task:** Look at a picture showing two objects about to collide, then choose what happens next. **Visual scenario:** A rolling ball approaches a stationary block. Choices: (A) ball stops, block moves, (B) ball bounces back, block stays, (C) both move right. Student picks based on intuition about heavy/light objects. _Reveals physics intuition about mass and momentum._ Auto-graded by reasonable selection with explanation prompt.

Dependencies:
* T16.G2.02: Identify bouncing vs sliding motion (picture-based)


ID: T16.G2.03.01
Topic: T16 – 2D Motion & Physics
Skill: Sequence collision events in order (picture-based)
Description: **Student task:** Look at 4 picture cards showing different moments of a collision (before touch, touching, bouncing apart, after bounce) and drag them into the correct time order. **Visual scenario:** Cards show: (A) ball approaching wall, (B) ball touching wall, (C) ball bouncing away from wall, (D) ball far from wall after bounce. Student arranges as A-B-C-D. **Vocabulary:** "before," "during," "after," "collision," "bounce." _Develops cause-effect physics sequencing._ Auto-graded by correct ordering.

Dependencies:
* T16.G2.03: Predict collision outcomes (picture-based)


ID: T16.G2.04
Topic: T16 – 2D Motion & Physics
Skill: Compare speeds of two moving objects (picture-based)
Description: **Student task:** Watch two sprites race across the screen at different speeds, then answer: "Which one is faster?" and "Which one is slower?" **Visual scenario:** A rabbit hops quickly across the top, a turtle walks slowly across the bottom. Student identifies rabbit as faster, turtle as slower. **Extension:** Students estimate how much faster (e.g., "twice as fast," "a little faster"). _Builds quantitative speed comparison before variables._ Auto-graded by correct identification.

Dependencies:
* T16.G1.01: Identify fast vs slow motion (picture-based)


ID: T16.G2.05
Topic: T16 – 2D Motion & Physics
Skill: Trace energy transfer in collision chains (picture-based)
Description: **Student task:** Watch a Newton's cradle-style animation where one ball hits a line of balls, and the energy transfers through to make the last ball swing out. Student traces the energy path by tapping balls in order. **Visual scenario:** Five balls hang in a row. Left ball swings and hits the line. Middle balls stay still. Right ball swings out. Student taps: left ball → middle balls → right ball. **Vocabulary:** "energy," "transfer," "through," "chain reaction." _Introduces energy conservation concept visually._ Auto-graded by correct sequence.

Dependencies:
* T16.G2.03.01: Sequence collision events in order (picture-based)


ID: T16.G2.06
Topic: T16 – 2D Motion & Physics
Skill: Identify friction effects on motion (picture-based)
Description: **Student task:** Watch two animations showing a block sliding on different surfaces (ice vs carpet) and identify which surface has more friction. **Visual scenario:** Animation A shows block sliding far on ice before stopping. Animation B shows block stopping quickly on carpet. Student identifies carpet as "more friction" and ice as "less friction." **Discussion:** What makes things slow down when sliding? (Friction between surfaces.) **Vocabulary:** "friction," "smooth," "rough," "slow down." _Introduces friction concept before physics engine._ Auto-graded by correct labeling.

Dependencies:
* T16.G2.02: Identify bouncing vs sliding motion (picture-based)




ID: T16.G3.01
Topic: T16 – 2D Motion & Physics
Skill: Trace how motion blocks change sprite position
Description: Trace through motion blocks (`move`, `glide`) to determine how a sprite's position changes. Predict the sprite's final position after running a sequence of motion blocks, explaining reasoning step by step. **Example:** Given `go to x: 0 y: 0`, `move 50 steps`, `turn right 90 degrees`, `move 30 steps`, trace position changes to predict final x,y coordinates. **Acceptance criteria:** Correctly calculate final position with step-by-step work shown.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T16.G2.03: Predict collision outcomes (picture-based)




ID: T16.G3.02
Topic: T16 – 2D Motion & Physics
Skill: Predict direction and distance of sprite motion
Description: Predict which direction a sprite will move and approximately how far, given a sequence of motion blocks. Develop intuition for motion before variables are introduced. **Example:** Given `point in direction 90`, `move 100 steps`, predict sprite moves straight up approximately 100 units. **Acceptance criteria:** Correct direction and reasonable distance estimate.

Dependencies:
* T16.G3.01: Trace how motion blocks change sprite position


ID: T16.G3.02.01
Topic: T16 – 2D Motion & Physics
Skill: Calculate position after motion with given starting point
Description: Trace through motion blocks to calculate exact final x,y coordinates when given specific starting coordinates. **Example:** Start at (50, -30). Run blocks: `change x by 20`, `change y by 40`. Calculate final position: (70, 10). Show work step-by-step with coordinate pairs after each block. **Acceptance criteria:** All intermediate positions calculated correctly, final coordinates exact, work shown clearly.

Dependencies:
* T16.G3.02: Predict direction and distance of sprite motion


ID: T16.G3.03
Topic: T16 – 2D Motion & Physics
Skill: Debug why sprite doesn't move as expected (picture-based debugging intro)
Description: Examine a buggy motion script shown as picture blocks and identify why the sprite doesn't reach the expected position. **Visual scenario:** Script shows `point in direction 0`, `move 50 steps` but sprite should face right (90 degrees). Student identifies wrong direction value. **Common bugs:** wrong direction, wrong step count, missing turn block. _Introduces debugging thinking before text code._ **Acceptance criteria:** Correctly identify the bug and suggest fix.

Dependencies:
* T16.G3.02: Predict direction and distance of sprite motion


ID: T16.G3.04
Topic: T16 – 2D Motion & Physics
Skill: Use motion blocks to draw shapes (square, triangle)
Description: Create scripts that use motion and turn blocks to draw geometric shapes on the stage. **Implementation:** (1) For square: repeat 4 times [move 100 steps, turn right 90 degrees], (2) for triangle: repeat 3 times [move 100 steps, turn right 120 degrees]. Use pen down/up to create visible trails. **Acceptance criteria:** Both square and triangle drawn correctly using loops and calculated turn angles.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T16.G3.02: Predict direction and distance of sprite motion




ID: T16.G4.01
Topic: T16 – 2D Motion & Physics
Skill: Simulate falling with repeated motion
Description: Create a simple falling animation by repeatedly moving a sprite down in a loop. Observe that the sprite appears to "fall" due to gravity conceptually, preparing for velocity-based motion. **Implementation:** Use `repeat` loop with `change y by -5` to simulate falling. **Acceptance criteria:** Sprite falls smoothly from top to bottom of stage.

Dependencies:
* T02.G2.01: Turn a picture routine into labeled boxes
* T02.G2.02: Read a box diagram and choose the matching pictures
* T07.G3.01: Use a counted repeat loop
* T16.G3.02: Predict direction and distance of sprite motion


ID: T16.G4.01.01
Topic: T16 – 2D Motion & Physics
Skill: Compare different fall speeds in simulation
Description: Create two falling sprites with different step sizes in their repeat loops (`change y by -3` vs `change y by -8`) and observe which reaches the bottom first. Record timing and explain the relationship between step size and fall duration. **Implementation:** Two sprites start at y=150, loop until y<-150, time how many loop iterations each takes. **Acceptance criteria:** Correctly predict and verify that larger step size = faster fall = fewer iterations.

Dependencies:
* T16.G4.01: Simulate falling with repeated motion


ID: T16.G4.02
Topic: T16 – 2D Motion & Physics
Skill: Explain speed as position change over time
Description: Explain that speed means "how much position changes each time the loop runs." Compare fast vs slow motion by changing the step size in a loop. **Example:** `change y by -2` creates slow falling, `change y by -10` creates fast falling. **Acceptance criteria:** Correctly explain relationship between step size and perceived speed.

Dependencies:
* T01.G2.01: Find actions that repeat in everyday tasks
* T02.G2.01: Turn a picture routine into labeled boxes
* T02.G2.02: Read a box diagram and choose the matching pictures
* T06.G2.03: Design a simple "if-then" game rule
* T09.G3.05: Trace code with variables to predict outcomes
* T16.G4.01: Simulate falling with repeated motion


ID: T16.G4.02.01
Topic: T16 – 2D Motion & Physics
Skill: Trace velocity changes during repeated motion
Description: Build a script that displays the current `change y by` value on screen during falling motion. Start with `change y by -2`, show the value updating each loop, then modify to decrease by -1 each frame to simulate acceleration. Trace how velocity changes create acceleration. **Implementation:** Create velocity variable, display it, change it each frame, observe acceleration effect. **Acceptance criteria:** Velocity variable tracked correctly, acceleration effect demonstrated, relationship explained.

Dependencies:
* T16.G4.02: Explain speed as position change over time


ID: T16.G4.03
Topic: T16 – 2D Motion & Physics
Skill: Build a simple bounce animation without physics engine
Description: Create a bouncing ball animation using loops and conditionals without the physics engine. **Implementation:** (1) Move ball down in loop, (2) when touching floor (y < -150), reverse direction, (3) ball moves up, (4) when touching top, reverse again. **Acceptance criteria:** Ball bounces continuously between top and bottom without physics blocks. _This manual approach builds understanding before using restitution parameters._

Dependencies:
* T08.G3.04: Use a simple if in a script
* T16.G4.02: Explain speed as position change over time


ID: T16.G4.04
Topic: T16 – 2D Motion & Physics
Skill: Debug a broken motion animation (sprite moves wrong direction)
Description: Given a buggy project where a sprite is supposed to move right but moves left instead, identify and fix the error. **Common bugs:** wrong direction value (270 instead of 90), negative step count, incorrect x/y axis. **Implementation:** Examine motion blocks, identify incorrect parameter, correct it, verify sprite moves as intended. **Acceptance criteria:** Bug identified correctly, fix applied, sprite motion verified.

Dependencies:
* T16.G3.03: Debug why sprite doesn't move as expected (picture-based debugging intro)
* T16.G4.01: Simulate falling with repeated motion


ID: T16.G4.05
Topic: T16 – 2D Motion & Physics
Skill: Create smooth motion using glide blocks vs step-based motion
Description: Compare two motion approaches: (1) step-based motion using `repeat` loop with `move 5 steps`, (2) smooth motion using `glide 2 secs to x: 200 y: 100`. Observe that glide creates smoother animation and simpler code for straight-line movement. **Acceptance criteria:** Both approaches implemented, differences explained, appropriate use cases identified.

Dependencies:
* T16.G4.01: Simulate falling with repeated motion


ID: T16.G4.06
Topic: T16 – 2D Motion & Physics
Skill: Build a simple racing game with keyboard-controlled sprite
Description: Create a basic racing game where arrow keys control a sprite's movement across the stage. **Implementation:** (1) Use `when [up arrow] key pressed` to move sprite up, (2) similar handlers for down/left/right arrows, (3) add finish line sprite, (4) detect when player reaches finish using `touching [finish line]`, (5) display "You Win!" message. **Acceptance criteria:** All four directions work, finish detection works, game is playable.

Dependencies:
* T06.G4.01: Use multiple event handlers in the same sprite
* T08.G3.04: Use a simple if in a script
* T16.G4.02: Explain speed as position change over time




ID: T16.G5.01
Topic: T16 – 2D Motion & Physics
Skill: Apply gravity to a sprite using 2D physics
Description: Use the physics engine to apply gravity forces to a sprite, observing how it falls and accelerates naturally. Understand that gravity is a constant downward force that affects all dynamic physics bodies in the scene. **Implementation:** Initialize physics world with gravity, attach dynamic body to sprite. **Acceptance criteria:** Sprite falls and accelerates smoothly.

Dependencies:
* T16.G4.02: Explain speed as position change over time




ID: T16.G5.02
Topic: T16 – 2D Motion & Physics
Skill: Track gravity with velocity variables
Description: Build a loop that stores a sprite's y-velocity in a variable, subtracts a gravity constant each frame, then adds the velocity to the sprite's y-position. This manual approach mirrors classic Scratch tutorials and prepares for physics debugging. **Implementation:** Create `yVelocity` variable, each frame: `change yVelocity by -1`, `change y by yVelocity`. **Acceptance criteria:** Manual gravity produces smooth acceleration matching physics engine behavior.

Dependencies:
* T07.G3.05: Fix a simple repeat loop count
* T09.G3.05: Trace code with variables to predict outcomes
* T16.G5.01: Apply gravity to a sprite using 2D physics
* T08.G3.00: Identify if blocks in existing code




ID: T16.G5.03
Topic: T16 – 2D Motion & Physics
Skill: Use horizontal speed and friction variables
Description: Add an x-velocity variable, respond to arrow keys to change it, and multiply by a friction factor (e.g., 0.9) each tick so motion glides to a stop. This prepares for platformer mechanics. **Implementation:** Create `xVelocity` variable, arrow keys: `change xVelocity by 2`, each frame: `set xVelocity to (xVelocity * 0.9)`, `change x by xVelocity`. **Acceptance criteria:** Sprite accelerates when keys pressed, glides to stop when released.

Dependencies:
* T09.G4.03: Use multiple variables in a single script
* T16.G5.02: Track gravity with velocity variables
* T07.G3.01: Use a counted repeat loop
* T08.G3.00: Identify if blocks in existing code


ID: T16.G5.03.01
Topic: T16 – 2D Motion & Physics
Skill: Build a top-down vehicle with manual friction control
Description: Create a top-down car or spaceship game using manual friction variables. **Implementation:** (1) Add xVelocity and yVelocity variables, (2) respond to arrow keys to adjust velocities, (3) multiply both velocities by friction factor (0.95) each frame so vehicle drifts to a stop, (4) update sprite position using velocities. **Acceptance criteria:** Vehicle feels responsive but gradually slows down when keys are released, creating realistic drift mechanics.

Dependencies:
* T16.G5.03: Use horizontal speed and friction variables




ID: T16.G5.04
Topic: T16 – 2D Motion & Physics
Skill: Code a manual bounce with energy loss
Description: Write a conditional that checks for ground contact, multiplies the y-velocity by a negative damping factor (e.g., -0.6), and sends the sprite back up with reduced height. This cements physics vocabulary before using the engine's restitution. **Implementation:** `if <y position < -150>`, `set yVelocity to (yVelocity * -0.6)`. **Acceptance criteria:** Ball bounces with decreasing height until stopping.

Dependencies:
* T08.G3.04: Use a simple if in a script
* T16.G5.02: Track gravity with velocity variables


ID: T16.G5.04.01
Topic: T16 – 2D Motion & Physics
Skill: Create a simple platformer using manual gravity
Description: Build a basic platformer game combining manual gravity, horizontal friction, and ground detection. **Features:** (1) Character falls with gravity (yVelocity decreases each frame), (2) pressing jump key adds upward velocity only when touching ground, (3) left/right keys control horizontal movement with friction, (4) character stops at floor level. **Acceptance criteria:** All features work correctly, character can jump and move smoothly. This integrates all manual physics concepts before using the engine.

Dependencies:
* T16.G5.04: Code a manual bounce with energy loss
* T16.G5.03: Use horizontal speed and friction variables




ID: T16.G5.05
Topic: T16 – 2D Motion & Physics
Skill: Initialize a 2D physics world
Description: Add the `initialize 2D physics world with gravity x [0] y [-100]` block, set appropriate gravity values, and confirm the debug overlay shows the world running. Understand that no physics behavior occurs until this block executes. **Note:** Running this block again resets the entire physics world, useful for level transitions or game resets. **Acceptance criteria:** Physics world initializes successfully, debug overlay visible.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T16.G4.02: Explain speed as position change over time
* T07.G3.01: Use a counted repeat loop
* T08.G3.00: Identify if blocks in existing code
* T09.G3.01.01: Create a new variable with a descriptive name




ID: T16.G5.06
Topic: T16 – 2D Motion & Physics
Skill: Attach a dynamic body to a sprite
Description: Convert a sprite to a dynamic physics body using `behave as a [dynamic] [object] shape [Box] debug [Yes]`. Observe the sprite fall and stop when it hits the stage floor, confirming the physics world affects it. **Acceptance criteria:** Sprite falls under gravity and collides with stage boundaries correctly.

Dependencies:
* T16.G5.05: Initialize a 2D physics world


ID: T16.G5.06.00
Topic: T16 – 2D Motion & Physics
Skill: Practice creating multiple dynamic bodies
Description: Create 2-3 different sprites and convert each to dynamic physics bodies. Experiment with different starting positions and observe how all bodies fall and interact, building fluency with the basic dynamic body setup before exploring shape options. **Acceptance criteria:** All sprites fall independently and collide with each other realistically.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite


ID: T16.G5.06.00.01
Topic: T16 – 2D Motion & Physics
Skill: Use debug mode to visualize collision shapes
Description: Enable debug mode in the 2D physics world to see invisible collision shape outlines overlaid on sprites. Understand that debug mode helps understand why collisions happen or don't happen, by showing the actual physics boundaries independent of sprite appearance. **Acceptance criteria:** Debug outlines visible, correctly identify shape boundaries vs sprite visuals.

Dependencies:
* T16.G5.06.00: Practice creating multiple dynamic bodies


ID: T16.G5.06.01
Topic: T16 – 2D Motion & Physics
Skill: Choose Box vs Circle collision shapes
Description: Select between Box and Circle collision shapes based on sprite appearance and desired physics behavior. **Guidelines:** Use Box for rectangular sprites (platforms, crates, walls) that should stack stably. Use Circle for round sprites (balls, wheels, coins) that should roll smoothly. Test both shapes on the same sprite to observe behavioral differences. **Acceptance criteria:** Correctly justify shape choice for given sprites.

Dependencies:
* T16.G5.06.00: Practice creating multiple dynamic bodies


ID: T16.G5.06.01.01
Topic: T16 – 2D Motion & Physics
Skill: Use Capsule shapes for elongated objects
Description: Select Capsule collision shapes for elongated sprites (characters, vehicles, rods). Observe how Capsules provide smoother rolling and better collision response for pill-shaped objects compared to boxes, useful for character physics that should roll over obstacles without catching on edges. **Acceptance criteria:** Capsule shape selected for appropriate sprites, smooth obstacle traversal demonstrated.

Dependencies:
* T16.G5.06.01: Choose Box vs Circle collision shapes


ID: T16.G5.06.01.02
Topic: T16 – 2D Motion & Physics
Skill: Use Convex Hull for sprite-fitted collision
Description: Apply Convex Hull collision shapes to create automatic collision boundaries that closely match sprite outlines. Understand that Convex Hull wraps the sprite's visible pixels with the smallest convex polygon, providing better visual accuracy than basic shapes but using more computational resources. **Acceptance criteria:** Convex Hull applied correctly, trade-offs understood.

Dependencies:
* T16.G5.06.01: Choose Box vs Circle collision shapes


ID: T16.G5.06.02
Topic: T16 – 2D Motion & Physics
Skill: Create sensor bodies for trigger zones
Description: Create sensor bodies using `behave as a [dynamic] [sensor]` that detect overlaps without causing physical collisions. Use sensors for trigger zones, collectible detection areas, and checkpoint markers. **Acceptance criteria:** Sensor detects overlaps but doesn't physically block movement.

Dependencies:
* T16.G5.06.01: Choose Box vs Circle collision shapes


ID: T16.G5.06.03
Topic: T16 – 2D Motion & Physics
Skill: Create compound shapes for complex sprites
Description: Use `behave as a [dynamic] [object] in compound shape with curve tolerance [value] point distance [value]` to create physics bodies that match complex or concave sprite outlines. Understand the trade-off between accuracy and performance. **Acceptance criteria:** Compound shape created for complex sprite, performance impact considered.

Dependencies:
* T16.G5.06.01: Choose Box vs Circle collision shapes


ID: T16.G5.06.04
Topic: T16 – 2D Motion & Physics
Skill: Match collision shape to sprite artwork
Description: Given a sprite with specific artwork (star, crescent moon, car, character), select the most appropriate collision shape that balances visual accuracy and performance. **Process:** (1) Examine sprite outline, (2) consider gameplay needs (does it need to roll? stack?), (3) test multiple shapes, (4) select best match justifying trade-offs. **Acceptance criteria:** Shape choice justified for 3+ different sprite types, visual accuracy vs performance trade-off explained.

Dependencies:
* T16.G5.06.01: Choose Box vs Circle collision shapes
* T16.G5.06.01.02: Use Convex Hull for sprite-fitted collision




ID: T16.G5.07
Topic: T16 – 2D Motion & Physics
Skill: Build fixed boundaries for floors and walls
Description: Add fixed physics bodies to floor or wall sprites using `behave as a [fixed] [object]` so falling or sliding objects stop on contact. Learn to use fixed bodies for geometry that should not move. **Acceptance criteria:** Fixed boundaries stop dynamic objects correctly, fixed bodies don't move under force.

Dependencies:
* T16.G5.05: Initialize a 2D physics world




ID: T16.G5.08
Topic: T16 – 2D Motion & Physics
Skill: Apply an impulse to jump or push
Description: Use `apply impulse [force] in direction [angle]` to make a dynamic sprite jump in response to input (e.g., direction 90 for upward jump). Control impulse strength so the sprite clears a target platform height. **Acceptance criteria:** Impulse produces consistent jump height, sprite lands on target platform.

Dependencies:
* T06.G4.01: Use multiple event handlers in the same sprite
* T16.G5.06: Attach a dynamic body to a sprite


ID: T16.G5.08.01
Topic: T16 – 2D Motion & Physics
Skill: Distinguish forces from impulses
Description: Compare `add force [force] in direction [angle]` (applied continuously each frame) with `apply impulse [force] in direction [angle]` (applied once instantly). Use forces for sustained thrust (jetpack) and impulses for sudden actions (jump, kick). **Acceptance criteria:** Correctly explain difference, select appropriate method for given scenarios.

Dependencies:
* T16.G5.08: Apply an impulse to jump or push


ID: T16.G5.08.02
Topic: T16 – 2D Motion & Physics
Skill: Apply impulse at a position for rotation
Description: Use `apply impulse [force] in direction [angle] at position x [X] y [Y]` to apply off-center impulses. Observe how impulses applied away from center create instant rotation (torque), useful for hitting objects at an angle or creating spin effects. **Acceptance criteria:** Off-center impulse produces rotation, effect understood and controlled.

Dependencies:
* T16.G5.08.01: Distinguish forces from impulses


ID: T16.G5.08.03
Topic: T16 – 2D Motion & Physics
Skill: Apply a single continuous force
Description: Use `add force [force] in direction [angle]` to apply a single continuous force to a physics body (e.g., constant wind, jetpack thrust). Observe how continuous forces create sustained acceleration unlike one-time impulses, preparing for combining multiple forces. **Acceptance criteria:** Continuous force creates sustained acceleration, difference from impulse clear.

Dependencies:
* T16.G5.08.01: Distinguish forces from impulses




ID: T16.G5.09
Topic: T16 – 2D Motion & Physics
Skill: Configure density for mass control
Description: Adjust density using `update density [value]` to control how heavy a sprite feels. Understand that density × area = mass and experiment with light vs heavy objects in collisions. **Acceptance criteria:** Demonstrate density's effect on collision outcomes, heavier objects push lighter ones.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite


ID: T16.G5.09.01
Topic: T16 – 2D Motion & Physics
Skill: Configure friction percentage for sliding control
Description: Adjust the friction percentage parameter using `update density [value] friction [value]%` to control surface stickiness. Configure different friction values (0%, 50%, 100%) and observe how friction affects sliding distance. Prepare for detailed friction experiments in G6. **Acceptance criteria:** Friction changes sliding distance measurably, relationship between friction and sliding understood, three different friction values tested.

Dependencies:
* T16.G5.09: Configure density for mass control


ID: T16.G5.09.02
Topic: T16 – 2D Motion & Physics
Skill: Configure restitution percentage for bounce control
Description: Adjust the restitution percentage parameter using `update density [value] friction [value]% restitution [value]%` to control bounciness. Configure different restitution values (0%, 50%, 100%) and observe bounce behavior systematically. Prepare for bounce height measurements in G6. **Acceptance criteria:** Restitution changes bounce height predictably, 0%=no bounce and 100%=full bounce verified, three different restitution values tested.

Dependencies:
* T16.G5.09.01: Configure friction percentage for sliding control




ID: T16.G5.10
Topic: T16 – 2D Motion & Physics
Skill: Trace simple 2D physics motion
Description: Experiment with a physics simulation by adjusting gravity, density, and starting height values, then predict and verify where the sprite lands. Run the simulation, observe outcomes, and choose the correct statement about where the sprite ends up (e.g., "lands on the platform," "still in the air," "passed through the floor"). This hands-on prediction and testing builds physics intuition. **Acceptance criteria:** Correctly predict landing position based on physics parameters.

Dependencies:
* T09.G3.05: Trace code with variables to predict outcomes
* T16.G5.06: Attach a dynamic body to a sprite


ID: T16.G5.10.01
Topic: T16 – 2D Motion & Physics
Skill: Remove physics body from a sprite
Description: Use `remove physics-based behavior` to detach a sprite from the physics engine so it no longer responds to gravity or collisions. Use this for collected items, destroyed enemies, or transitioning between physics and non-physics modes. **Acceptance criteria:** Sprite stops responding to physics after removal, useful for collectibles demonstrated.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite




ID: T16.G5.11
Topic: T16 – 2D Motion & Physics
Skill: Debug missing physics setup
Description: Open a buggy project where the player never falls because the physics world was not initialized or the body was left as fixed. Inspect the scripts, identify the missing setup, and re-test. **Acceptance criteria:** Correctly identify missing initialization or incorrect body type, fix implemented successfully.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite
* T16.G5.07: Build fixed boundaries for floors and walls




ID: T16.G5.12
Topic: T16 – 2D Motion & Physics
Skill: Choose manual vs engine-based physics
Description: After experiencing both manual velocity variables (G5.02-G5.04) and the physics engine (G5.05-G5.11), compare CreatiCode project briefs (platformer, UI animation, top-down maze, pinball machine) and choose the most appropriate approach for each. Justify decisions based on project requirements and hands-on experience with both methods. **Acceptance criteria:** Correct method chosen for each scenario with clear justification.

Dependencies:
* T05.G4.05: Plan a simulation with defined inputs and outputs
* T16.G5.04: Code a manual bounce with energy loss
* T16.G5.11: Debug missing physics setup


ID: T16.G5.13
Topic: T16 – 2D Motion & Physics
Skill: Use (speed) reporter to display total speed
Description: Use the `(speed)` reporter block to read and display a physics body's total velocity magnitude (combining x and y components). Understand that `(speed)` returns the scalar speed value while `(x speed)` and `(y speed)` return directional components. **Example use cases:** Display speedometer in racing game, check if object has stopped moving, trigger effects at high speeds. **Acceptance criteria:** Correctly display total speed, explain difference from x/y speed components.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite
* T16.G5.08: Apply an impulse to jump or push


ID: T16.G5.14
Topic: T16 – 2D Motion & Physics
Skill: Compare manual vs engine approaches side-by-side (capstone)
Description: Build two versions of the same simple physics behavior (bouncing ball or platformer jump): one using manual velocity variables (Track A approach) and one using the physics engine (Track B approach). Compare code complexity, performance, realism, and control for each approach. **Deliverable:** Side-by-side demonstration with written comparison explaining strengths and weaknesses of each approach. **Acceptance criteria:** Both versions implemented correctly, comparison covers 4+ dimensions, recommendations for when to use each approach provided.

Dependencies:
* T16.G5.04: Code a manual bounce with energy loss
* T16.G5.12: Choose manual vs engine-based physics
* T16.G5.10: Trace simple 2D physics motion


<!-- X-2 VIOLATION NOTE: Several G6-G7 skills below have cross-topic dependencies on T07/T08/T09.G3 skills,
     creating 3-4 grade gaps. This is acceptable since they are cross-topic dependencies (not within-topic)
     and will be addressed in Phase 2 cross-topic dependency optimization. The skills are properly scaffolded
     within T16 itself. -->




ID: T16.G6.01
Topic: T16 – 2D Motion & Physics
Skill: Configure surface friction parameters
Description: Adjust the friction percentage using `update density [value] friction [value]% restitution [value]%` and measure how far objects slide on different surfaces. Map friction values to sliding distances through systematic testing. **Acceptance criteria:** Friction experiment completed, data table shows friction vs distance relationship.

Dependencies:
* T16.G5.09.01: Configure friction percentage for sliding control
* T16.G5.10: Trace simple 2D physics motion




ID: T16.G6.02
Topic: T16 – 2D Motion & Physics
Skill: Control restitution (bounce) parameters
Description: Modify the restitution percentage and measure bounce heights. Learn the relationship between restitution values (0-100%) and energy conservation in collisions: 0% = no bounce, 100% = full bounce. **Acceptance criteria:** Restitution experiment completed, bounce height graph shows linear relationship.

Dependencies:
* T16.G5.09.02: Configure restitution percentage for bounce control
* T16.G6.01: Configure surface friction parameters


ID: T16.G6.02.01
Topic: T16 – 2D Motion & Physics
Skill: Set velocity directly for physics bodies
Description: Use `set x speed [value]`, `set y speed [value]`, and `set speed [value] in direction [angle]` to directly control physics body velocity. Compare direct velocity setting to impulses and understand when each approach is appropriate. **Guidelines:** Use direct velocity for instant speed changes, teleports, or capping max speed. Use impulses for physics-realistic acceleration. **Acceptance criteria:** Demonstrate both methods, explain appropriate use cases.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite
* T16.G5.08: Apply an impulse to jump or push


ID: T16.G6.02.01.01
Topic: T16 – 2D Motion & Physics
Skill: Maintain constant speed in current direction
Description: Use `set speed [value] in moving direction` to regulate an object's speed without changing its trajectory. This is useful for maintaining constant character movement speed, limiting maximum velocity, or normalizing physics-driven velocities while preserving direction changes from collisions or forces. **Acceptance criteria:** Speed clamped successfully, direction preserved through collisions.

Dependencies:
* T16.G6.02.01: Set velocity directly for physics bodies


ID: T16.G6.02.01.02
Topic: T16 – 2D Motion & Physics
Skill: Read velocity reporters for verification
Description: Use velocity reporter blocks (`(x speed)`, `(y speed)`, `(speed)`) to read and verify the current velocity of a physics body. Learn to check if velocity changes worked as expected, essential for debugging motion issues. **Acceptance criteria:** Velocity values read correctly, used to verify expected behavior in script.

Dependencies:
* T16.G6.02.01: Set velocity directly for physics bodies


ID: T16.G6.02.01.03
Topic: T16 – 2D Motion & Physics
Skill: Set rotation speed directly
Description: Use `set rotation speed [value]` to directly control how fast a physics body spins (degrees per second). Understand this gives immediate rotation control, parallel to setting linear velocity. **Acceptance criteria:** Rotation speed set correctly, predictable spinning behavior demonstrated.

Dependencies:
* T16.G6.02.01: Set velocity directly for physics bodies


ID: T16.G6.02.02
Topic: T16 – 2D Motion & Physics
Skill: Compare dynamic vs movable body types
Description: Compare dynamic bodies (affected by forces and gravity) with movable (kinematic) bodies (move via velocity but don't respond to forces). Identify scenarios where each type is appropriate: dynamic for player characters and falling objects, movable for moving platforms and elevators. **Acceptance criteria:** Correctly identify body type for 5+ scenarios, explain reasoning.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite
* T16.G6.02.01: Set velocity directly for physics bodies




ID: T16.G6.03
Topic: T16 – 2D Motion & Physics
Skill: Build a movable (kinematic) moving platform
Description: Create a platform using `behave as a [movable] [object]` that moves on a fixed path while still colliding with players. Use `set x speed` and `set y speed` to control platform motion directly rather than relying on physics forces. **Acceptance criteria:** Platform moves on path, carries player correctly, doesn't respond to gravity or impulses.

Dependencies:
* T07.G3.05: Fix a simple repeat loop count
* T16.G6.02.02: Compare dynamic vs movable body types




ID: T16.G6.04
Topic: T16 – 2D Motion & Physics
Skill: Detect collisions for scoring or triggers
Description: Use `broadcast [message] when colliding with [sprite]` to listen for collision events between sprites. Run scoring or state-change scripts in response to collisions (player hits coin, ball hits bumper). **Acceptance criteria:** Collision detection triggers score change or state transition correctly.

Dependencies:
* T06.G4.01: Use multiple event handlers in the same sprite
* T16.G5.10: Trace simple 2D physics motion


ID: T16.G6.04.01
Topic: T16 – 2D Motion & Physics
Skill: Detect collision end events
Description: Use `broadcast [message] when finish colliding with [sprite]` to trigger actions when objects stop touching. Understand collision end events are essential for: stopping lava damage when leaving fire, releasing pressed buttons, tracking exit from trigger zones, and any scenario needing 'when objects separate' detection. **Acceptance criteria:** End-collision event triggers action correctly, difference from start-collision understood.

Dependencies:
* T16.G6.04: Detect collisions for scoring or triggers


ID: T16.G6.04.02
Topic: T16 – 2D Motion & Physics
Skill: Enable ground detection for jump control
Description: Enable ground detection using `turn on ground detection within distance [value] debug [Yes/No]` and use the `<in collision below>` reporter in conditionals to allow jumping only when the sprite is standing on ground. This prevents mid-air double jumps and creates responsive platformer controls. **Acceptance criteria:** Jump only works when grounded, no double-jumping possible.

Dependencies:
* T16.G6.04: Detect collisions for scoring or triggers


ID: T16.G6.04.02.01
Topic: T16 – 2D Motion & Physics
Skill: Use ground slope reporter for inclined surfaces
Description: Use the `(ground slope)` reporter to read the angle of the surface beneath a sprite. Adjust sprite behavior on slopes and ramps by detecting whether the character is on flat ground (0 degrees), uphill (positive), or downhill (negative), enabling features like sliding down steep slopes or adjusting movement speed on inclines. **Acceptance criteria:** Slope angle read correctly, behavior changes based on slope angle.

Dependencies:
* T16.G6.04.02: Enable ground detection for jump control


ID: T16.G6.04.03
Topic: T16 – 2D Motion & Physics
Skill: Identify collision management needs
Description: Analyze a game design (with multiple object types like players, enemies, collectibles, hazards, and platforms) and identify which objects should collide with each other and which should pass through. Plan collision filtering strategy before implementing collision groups. **Acceptance criteria:** Collision matrix created showing all object type pairs, pass-through vs collide decision for each.

Dependencies:
* T16.G6.04: Detect collisions for scoring or triggers


ID: T16.G6.04.04
Topic: T16 – 2D Motion & Physics
Skill: Build trigger zones and collectibles with sensor bodies
Description: Combine sensor bodies with collision events to create functional game elements. **Examples:** (1) Checkpoint zone that saves player progress when entered, (2) collectible coins that add score and hide when touched, (3) danger zone that triggers damage without blocking movement. The sensor detects entry but doesn't physically block the player. **Acceptance criteria:** All three example types implemented and working correctly.

Dependencies:
* T16.G5.06.02: Create sensor bodies for trigger zones
* T16.G6.04: Detect collisions for scoring or triggers


ID: T16.G6.04.05
Topic: T16 – 2D Motion & Physics
Skill: Create one-way platforms using collision filtering
Description: Build platforms that players can jump through from below but land on from above. **Implementation:** (1) Create platform as movable/fixed body, (2) use ground detection to check if player is above platform, (3) disable collision when player below, enable when player above and falling. **Alternative approach:** Use collision groups to selectively enable/disable platform collision based on player position. **Acceptance criteria:** One-way platform works correctly, player can jump through from below and land from above.

Dependencies:
* T16.G6.04.02: Enable ground detection for jump control
* T16.G6.04: Detect collisions for scoring or triggers




ID: T16.G6.05
Topic: T16 – 2D Motion & Physics
Skill: Add sprites to collision groups
Description: Assign group numbers to sprites using `add to collision group [G]` to categorize physics objects. Understand that collision groups are the foundation for collision filtering and that sprites can belong to multiple groups simultaneously. **Acceptance criteria:** Sprites assigned to groups correctly, multiple group membership understood.

Dependencies:
* T16.G6.04.03: Identify collision management needs


ID: T16.G6.05.01
Topic: T16 – 2D Motion & Physics
Skill: Enable collision filtering with other groups
Description: Configure collision filters using `enable collision with group [G]` and `disable collision with group [G]` to specify which groups a sprite should collide with. Understand that filters are directional and must be set on BOTH sprites for mutual pass-through behavior. **Acceptance criteria:** Collision filtering works correctly, bidirectional requirement understood.

Dependencies:
* T16.G6.05: Add sprites to collision groups


ID: T16.G6.05.02
Topic: T16 – 2D Motion & Physics
Skill: Test collision group filtering behavior
Description: Test collision group setups by running the game and verifying that objects pass through or collide as expected. Debug filtering issues by checking that groups are assigned correctly, filters are bidirectional, and objects without group assignments collide with everything by default. **Acceptance criteria:** All collision behaviors match design, filtering bugs identified and fixed.

Dependencies:
* T16.G6.05.01: Enable collision filtering with other groups


ID: T16.G6.05.03
Topic: T16 – 2D Motion & Physics
Skill: Dynamically modify collision groups at runtime
Description: Dynamically add or remove collision group memberships during gameplay (e.g., for invincibility, phasing) using `add to collision group [G]` and `remove from collision group [G]`. **Example use cases:** Player invincibility after hit, ghost mode power-up, phase-shifting mechanics. **Acceptance criteria:** Runtime group changes work correctly, gameplay uses demonstrated.

Dependencies:
* T16.G6.05.02: Test collision group filtering behavior


ID: T16.G6.05.04
Topic: T16 – 2D Motion & Physics
Skill: Use dominance groups for one-way pushing
Description: Use `set dominance group to [G]` to create one-way physical interactions where higher-dominance objects push lower-dominance objects without being pushed back. Apply this to create boss characters that can't be knocked back by players, heavy objects that push light ones, or unstoppable moving hazards. **Acceptance criteria:** Dominance demonstrated with boss that pushes player without being pushed.

Dependencies:
* T16.G6.05.02: Test collision group filtering behavior




ID: T16.G6.06
Topic: T16 – 2D Motion & Physics
Skill: Blend manual and engine sprites in a level
Description: Create a project that combines manual motion (scrolling backgrounds, UI elements, non-physics objects) with physics bodies (falling objects, player characters) running simultaneously. **Success criteria:** Manual sprites move smoothly without physics interference, physics sprites respond to gravity and collisions correctly, and no unintended physics bodies are created. **Acceptance criteria:** Mixed project works correctly, no interference between systems.

Dependencies:
* T16.G5.10: Trace simple 2D physics motion
* T16.G5.11: Debug missing physics setup


ID: T16.G6.06.01
Topic: T16 – 2D Motion & Physics
Skill: Lock movement or rotation of physics bodies
Description: Use `prevent body movement from forces [Yes]` and `prevent body rotation from forces [Yes]` to constrain physics objects. Create characters that stay upright, platforms that resist being pushed, or objects that only rotate without moving. **Acceptance criteria:** Constraints applied correctly, constrained bodies behave as expected under forces.

Dependencies:
* T16.G5.06: Attach a dynamic body to a sprite




ID: T16.G6.07
Topic: T16 – 2D Motion & Physics
Skill: Debug unstable physics behavior
Description: Diagnose why a sprite jitters, sinks through a platform, or flies off-screen (e.g., density too low, conflicting impulses, missing collision groups) and adjust parameters to stabilize the scene. **Common causes:** too-high forces, too-small collision shapes, missing fixed bodies, tunneling (solved with CCD). **Acceptance criteria:** Unstable behavior identified, root cause diagnosed, fix applied successfully.

Dependencies:
* T16.G6.01: Configure surface friction parameters
* T16.G6.02: Control restitution (bounce) parameters


ID: T16.G6.07.01
Topic: T16 – 2D Motion & Physics
Skill: Configure world border properties
Description: Set physics world border properties (friction and restitution). Use `set world border collider friction [value]% restitution [value]%` to control how sprites bounce and slide when hitting stage edges, creating realistic boundary behavior without manual edge detection. **Acceptance criteria:** Border friction and restitution configured, edge behavior matches design intent.

Dependencies:
* T16.G5.05: Initialize a 2D physics world
* T16.G6.01: Configure surface friction parameters


ID: T16.G6.07.02
Topic: T16 – 2D Motion & Physics
Skill: Configure world borders for wrap-around or open-edge levels
Description: Set physics world border collision groups. Use `set world border collision group [G] colliding with group [G]` to configure whether certain sprites or groups can collide with stage borders, enabling scenarios where some objects pass through edges while others bounce. **Acceptance criteria:** Group-based border collision works, pass-through and bounce behaviors configured correctly.

Dependencies:
* T16.G6.07.01: Configure world border properties




ID: T16.G6.08
Topic: T16 – 2D Motion & Physics
Skill: Compare simulations to real-world motion
Description: Record bounce heights or slide distances in CreatiCode, compare them to expected real-world results, and discuss how closely the simulation matches reality and what simplifications the physics engine makes. **Acceptance criteria:** Real vs simulated comparison completed, engine limitations identified and explained.

Dependencies:
* T16.G5.10: Trace simple 2D physics motion


ID: T16.G6.08.01
Topic: T16 – 2D Motion & Physics
Skill: Build a pinball-style bumper using collision and impulse response
Description: Create a bumper sprite that detects collisions with a ball and applies an outward impulse to push the ball away. **Implementation:** (1) Create fixed bumper body, (2) use `broadcast [bounce] when colliding with [Ball]`, (3) in Ball sprite, receive broadcast and `apply impulse [150] in direction [away from bumper]`, (4) add visual/sound feedback. **Acceptance criteria:** Bumper pushes ball away realistically, impulse direction calculated from bumper position, visual/sound effects added.

Dependencies:
* T16.G6.04: Detect collisions for scoring or triggers
* T16.G5.08: Apply an impulse to jump or push


ID: T16.G6.09
Topic: T16 – 2D Motion & Physics
Skill: Use screen shake for collision impact effects
Description: Implement screen shake effects when high-speed collisions occur to enhance impact feedback. **Implementation:** (1) Detect collision events, (2) check collision velocity using velocity reporters, (3) if speed > threshold, apply random camera offset for several frames, (4) gradually reduce shake intensity. **Example use cases:** Ball hitting wall at high speed, car crashes, explosions. **Acceptance criteria:** Screen shake triggers on hard impacts, intensity scales with collision force, effect feels satisfying.

Dependencies:
* T16.G6.04: Detect collisions for scoring or triggers
* T16.G6.02.01.02: Read velocity reporters for verification


ID: T16.G6.09.01
Topic: T16 – 2D Motion & Physics
Skill: Create particle burst effect on high-speed collision
Description: Create a visual particle burst effect that triggers when collision velocity exceeds a threshold. **Implementation:** (1) Use velocity reporters `(x speed)` and `(y speed)` to calculate collision speed, (2) when speed > threshold, spawn 5-10 particle clones, (3) apply random impulses to particles, (4) fade particles out. **Acceptance criteria:** Particle effect triggers only on high-speed collisions, particles scatter realistically, effect enhances visual feedback.

Dependencies:
* T16.G6.08: Compare simulations to real-world motion
* T16.G5.08: Apply an impulse to jump or push


ID: T16.G6.10
Topic: T16 – 2D Motion & Physics
Skill: Predict collision outcomes before running simulation
Description: Given a physics scenario setup (two objects with known mass, velocity, and collision angle), predict the outcome before running the simulation. **Process:** (1) Analyze initial conditions (which is heavier? which is faster?), (2) predict post-collision velocities and directions using physics intuition, (3) run simulation, (4) compare prediction to actual outcome, (5) explain any differences. **Acceptance criteria:** Predictions made for 3+ scenarios, reasoning explained, simulation results compared to predictions.

Dependencies:
* T16.G5.09: Configure density for mass control
* T16.G6.02.01.02: Read velocity reporters for verification


ID: T16.G6.11
Topic: T16 – 2D Motion & Physics
Skill: Debug sprites passing through walls (tunneling diagnosis)
Description: Diagnose and fix "tunneling" where fast-moving sprites pass through thin walls. **Diagnostic process:** (1) Identify symptoms (sprite appears on other side of wall), (2) check sprite speed using velocity reporters, (3) check wall thickness vs sprite speed, (4) apply fixes: enable CCD, increase wall thickness, or reduce max speed. **Acceptance criteria:** Tunneling bug identified, root cause explained (speed vs wall thickness), appropriate fix applied.

Dependencies:
* T16.G6.07: Debug unstable physics behavior
* T16.G6.02.01.02: Read velocity reporters for verification




ID: T16.G7.01
Topic: T16 – 2D Motion & Physics
Skill: Launch a configurable projectile
Description: Create a launcher where users set angle and power using sliders. The projectile receives an initial impulse using `apply impulse [force] in direction [angle]` that produces a parabolic arc toward targets. **Acceptance criteria:** Sliders control launch angle and power, projectile follows realistic arc, targets hittable with correct settings.

Dependencies:
* T08.G5.02: Fix a condition that uses the wrong operator
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T16.G5.08: Apply an impulse to jump or push
* T16.G6.04: Detect collisions for scoring or triggers


ID: T16.G7.01.01
Topic: T16 – 2D Motion & Physics
Skill: Point sprite in movement direction
Description: Use `point in direction of speed` to automatically rotate a sprite to face its current movement direction. This is essential for arrows, rockets, and birds that should visually align with their trajectory as they fly along parabolic arcs. **Acceptance criteria:** Sprite rotates to match velocity direction throughout flight.

Dependencies:
* T16.G7.01: Launch a configurable projectile


ID: T16.G7.01.02
Topic: T16 – 2D Motion & Physics
Skill: Enable CCD for fast projectiles
Description: Enable Continuous Collision Detection (CCD) using `enable collision detection as a fast object [Yes]` to prevent fast-moving objects from tunneling through walls. Observe that very fast physics bodies sometimes pass through thin obstacles (called 'tunneling'), then learn CCD solves this by detecting collisions between frames, ensuring no missed collisions at high speeds. **Acceptance criteria:** CCD enabled, fast projectile no longer tunnels through thin walls.

Dependencies:
* T16.G7.01: Launch a configurable projectile


ID: T16.G7.01.03
Topic: T16 – 2D Motion & Physics
Skill: Calculate optimal launch angle for target distance
Description: Experiment with different launch angles to find the optimal angle for maximum distance or hitting a specific target. **Process:** (1) Set up target at known distance, (2) test angles from 15° to 75° in 15° increments, (3) record which angle hits target or goes farthest, (4) refine angle in smaller increments near optimal, (5) explain why 45° is often optimal for maximum range. **Acceptance criteria:** Data collected for 5+ angles, optimal angle identified, relationship between angle and distance explained.

Dependencies:
* T16.G7.01: Launch a configurable projectile




ID: T16.G7.02
Topic: T16 – 2D Motion & Physics
Skill: Combine multiple forces simultaneously
Description: Use `add force [force] in direction [angle]` to apply two or more forces in the same frame (gravity + constant wind, gravity + player thrust). Predict and observe the resulting curved motion paths. **Acceptance criteria:** Multiple forces combined correctly, resulting trajectory matches prediction, force vectors understood.

Dependencies:
* T16.G5.08.03: Apply a single continuous force
* T16.G6.07: Debug unstable physics behavior
* T16.G6.08: Compare simulations to real-world motion


ID: T16.G7.02.01
Topic: T16 – 2D Motion & Physics
Skill: Clear forces and torques from physics bodies
Description: Use `remove all forces` and `remove all torques` to reset accumulated forces on physics bodies. Use this for game resets, mode transitions, or when switching from force-driven to velocity-driven control. **Acceptance criteria:** Forces cleared successfully, clean state transitions demonstrated.

Dependencies:
* T16.G7.02: Combine multiple forces simultaneously


ID: T16.G7.02.02
Topic: T16 – 2D Motion & Physics
Skill: Apply force at a position for continuous rotation
Description: Use `add force [force] in direction [angle] at position x [X] y [Y]` to apply continuous off-center forces. Observe how sustained forces applied away from center create continuous rotation (torque), useful for thrusters, spinning mechanisms, or torque-based controls. **Acceptance criteria:** Off-center force creates rotation, torque effect controlled and predictable.

Dependencies:
* T16.G5.08.02: Apply impulse at a position for rotation
* T16.G7.02: Combine multiple forces simultaneously




ID: T16.G7.03
Topic: T16 – 2D Motion & Physics
Skill: Simulate drag with manual force calculations
Description: Manually implement drag effects by calculating forces opposite to velocity (applying force proportional to speed in the reverse direction). Experiment with different drag coefficients and observe how they affect motion through different media (air, water, honey). This manual approach builds understanding before using built-in damping. **Acceptance criteria:** Manual drag implemented, different media simulated, drag coefficient effect understood.

Dependencies:
* T16.G5.08.01: Distinguish forces from impulses
* T16.G6.07: Debug unstable physics behavior


ID: T16.G7.03.01
Topic: T16 – 2D Motion & Physics
Skill: Use built-in damping as alternative to manual drag
Description: Use the built-in `set damping factor for movement [M]% rotation [R]%` block to simulate air resistance or water friction as an easier alternative to manual force calculations. Compare results with manual implementation and tune damping percentages for desired slowdown behavior. **Acceptance criteria:** Damping configured correctly, comparison with manual drag completed, trade-offs understood.

Dependencies:
* T16.G7.03: Simulate drag with manual force calculations




ID: T16.G7.04
Topic: T16 – 2D Motion & Physics
Skill: Build chains or stacks of physics objects
Description: Create stacks of boxes or chains of linked sprites and explore how forces propagate through the system when one element is pushed. Observe how density affects collision outcomes. **Acceptance criteria:** Stack or chain built successfully, force propagation observed, density effects demonstrated.

Dependencies:
* T16.G6.07: Debug unstable physics behavior
* T16.G6.08: Compare simulations to real-world motion


ID: T16.G7.04.01
Topic: T16 – 2D Motion & Physics
Skill: Use continuous torque to rotate bodies
Description: Use `add torque [value]` to apply continuous rotational force to a physics body. Understand that torque (like force for linear motion) accumulates over time, respecting the body's rotational mass and creating smooth, physics-based rotation. Compare to direct rotation speed control. **Acceptance criteria:** Torque applied correctly, difference from direct rotation speed understood.

Dependencies:
* T16.G6.02.01.03: Set rotation speed directly
* T16.G7.02: Combine multiple forces simultaneously


ID: T16.G7.04.01.01
Topic: T16 – 2D Motion & Physics
Skill: Apply torque impulse for instant rotation
Description: Use `apply torque impulse [value]` to apply an instant rotational "kick" to a physics body. Understand that torque impulse (like linear impulse) applies immediately regardless of mass, perfect for one-time rotation events like hitting a spinning obstacle. **Acceptance criteria:** Torque impulse applied correctly, instant rotation vs continuous torque distinguished.

Dependencies:
* T16.G7.04.01: Use continuous torque to rotate bodies
* T16.G5.08.02: Apply impulse at a position for rotation




ID: T16.G7.05
Topic: T16 – 2D Motion & Physics
Skill: Read velocity and mass reporters
Description: Use the reporter blocks `(x speed)`, `(y speed)`, `(mass)`, `(angular speed)`, and `(ground slope)` to display real-time physics data on screen. Use this data for UI displays, conditional logic, and debugging. **Acceptance criteria:** All reporter types used correctly, data displayed in HUD or used in logic.

Dependencies:
* T16.G6.07: Debug unstable physics behavior
* T16.G6.08: Compare simulations to real-world motion


ID: T16.G7.05.01
Topic: T16 – 2D Motion & Physics
Skill: Instrument and graph motion data
Description: Record motion data from a sprite every few frames using velocity reporters, store values in lists, and create a graph. Use the graph to confirm constant acceleration or spot errors. **Acceptance criteria:** Data logged to list successfully, graph created, acceleration pattern confirmed or debugged.

Dependencies:
* T10.G5.01: Add and remove items from a list
* T16.G7.05: Read velocity and mass reporters


ID: T16.G7.05.02
Topic: T16 – 2D Motion & Physics
Skill: Use velocity reporters for UI speedometers and HUDs
Description: Create visual HUD elements that display real-time physics data. **Examples:** (1) Speedometer that shows `(speed)` as a number or visual gauge, (2) tachometer showing `(angular speed)` for rotating objects, (3) velocity indicator arrows pointing in direction of movement. Update HUD elements each frame to reflect current physics state. **Acceptance criteria:** All three HUD types implemented and updating correctly.

Dependencies:
* T16.G7.05: Read velocity and mass reporters




ID: T16.G7.06
Topic: T16 – 2D Motion & Physics
Skill: Model a real-world physics scenario
Description: Choose a real phenomenon (bouncing ball, swinging pendulum, sliding object) and build a CreatiCode simulation that approximates it. Explain which physics properties (gravity, friction, restitution) were tuned to mimic reality. **Acceptance criteria:** Simulation matches real-world behavior qualitatively, physics parameters justified.

Dependencies:
* T08.G5.02: Fix a condition that uses the wrong operator
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T16.G6.08: Compare simulations to real-world motion


ID: T16.G7.06.01
Topic: T16 – 2D Motion & Physics
Skill: Validate simulation accuracy with known physics formulas
Description: Compare CreatiCode simulation results to predictions from known physics formulas (d=½gt², v=at, etc.). **Process:** (1) Choose a simple scenario (free fall), (2) predict results using formula, (3) measure actual simulation results, (4) calculate percent error, (5) explain any differences (frame rate, air resistance, rounding). **Acceptance criteria:** Formula prediction calculated correctly, simulation measured accurately, percent error calculated, differences explained.

Dependencies:
* T16.G7.06: Model a real-world physics scenario


ID: T16.G7.07
Topic: T16 – 2D Motion & Physics
Skill: Evaluate whether a simulation meets requirements
Description: Given target requirements (e.g., "ball must clear the second bumper but stop before the third"), test a simulation against them. Examine logged data and decide if requirements were met, citing evidence. **Acceptance criteria:** All requirements tested, pass/fail determined correctly, evidence cited from logs or observations.

Dependencies:
* T16.G6.07: Debug unstable physics behavior
* T16.G6.08: Compare simulations to real-world motion


ID: T16.G7.07.01
Topic: T16 – 2D Motion & Physics
Skill: Create acceptance test cases for physics requirements
Description: Given physics-based game requirements, write specific test cases with pass/fail criteria. **Example requirement:** "Player must be able to jump over a 100-unit wall." **Test case:** (1) Place player at wall base, (2) trigger jump with max power, (3) measure max height reached, (4) pass if height > 100. Create 5+ test cases for a game feature. **Acceptance criteria:** Test cases are specific and measurable, cover normal and edge cases, include pass/fail criteria.

Dependencies:
* T16.G7.07: Evaluate whether a simulation meets requirements


ID: T16.G7.08
Topic: T16 – 2D Motion & Physics
Skill: Create a physics-based sports game
Description: Design and implement a sports game (basketball, golf, soccer) using physics mechanics. **Implementation:** (1) Configure gravity and restitution for sport ball, (2) implement launch/kick mechanics with angle and power control, (3) create goal/target with collision detection, (4) add scoring system based on successful shots. **Examples:** Basketball with arc shots and backboard bounces, mini-golf with putting power control, soccer with kicked ball physics. **Acceptance criteria:** Sport mechanics feel realistic, scoring works correctly, game is playable and fun.

Dependencies:
* T16.G7.01: Launch a configurable projectile
* T16.G6.04: Detect collisions for scoring or triggers
* T16.G6.02: Control restitution (bounce) parameters


ID: T16.G7.09
Topic: T16 – 2D Motion & Physics
Skill: Trace physics simulation frame-by-frame
Description: Build a physics scenario and step through it frame-by-frame, recording position, velocity, and forces at each step. **Process:** (1) Set up simple physics scenario (falling ball), (2) pause simulation after each frame, (3) record current values in table, (4) manually predict next frame values, (5) step forward and verify predictions. **Purpose:** Understand that physics engines update in discrete steps, not continuous motion. **Acceptance criteria:** Frame-by-frame data recorded for 10+ frames, predictions made and verified, discrete time-step concept explained.

Dependencies:
* T16.G7.05: Read velocity and mass reporters
* T16.G6.07: Debug unstable physics behavior


ID: T16.G7.10
Topic: T16 – 2D Motion & Physics
Skill: Design a physics experiment to test a hypothesis
Description: Formulate a physics hypothesis (e.g., "doubling density doubles collision force"), design an experiment to test it, collect data, and conclude whether hypothesis is supported. **Process:** (1) State clear hypothesis, (2) design controlled experiment with independent/dependent variables, (3) run 5+ trials, (4) record data in table, (5) analyze results and draw conclusion. **Acceptance criteria:** Complete experimental design with hypothesis, controlled variables, data collection, and conclusion.

Dependencies:
* T16.G7.06: Model a real-world physics scenario
* T16.G7.05.01: Instrument and graph motion data




ID: T16.G8.01
Topic: T16 – 2D Motion & Physics
Skill: Design a physics-based arcade game concept
Description: Design a launcher + target game (Angry Birds–style) by planning level layouts, identifying required physics objects (projectiles, targets, obstacles), and sketching game mechanics. Create design documents that specify win conditions and challenge progression before implementation. **Acceptance criteria:** Complete design document with sketches, object list, mechanics description, and win conditions.

Dependencies:
* T16.G7.06: Model a real-world physics scenario


ID: T16.G8.01.01
Topic: T16 – 2D Motion & Physics
Skill: Implement physics arcade game mechanics
Description: Implement the game design from T16.G8.01 by creating sprites, setting up physics bodies, configuring collision detection, and scripting game logic. Translate design specifications into working code using physics blocks. **Acceptance criteria:** All designed mechanics implemented, game playable from start to win condition.

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T16.G8.01: Design a physics-based arcade game concept
* T04.G6.01: Group snippets by underlying algorithm pattern
* T10.G6.01: Sort a table by a column


ID: T16.G8.01.02
Topic: T16 – 2D Motion & Physics
Skill: Balance and tune physics game difficulty
Description: Playtest physics game and adjust physics parameters (gravity, impulse strength, object density, friction, restitution) to balance difficulty. Iterate on parameter values to make gameplay fair but challenging, ensuring levels are neither too easy nor frustratingly hard. **Acceptance criteria:** Game difficulty balanced through playtesting, parameter changes justified, target win rate achieved.

Dependencies:
* T16.G8.01.01: Implement physics arcade game mechanics




ID: T16.G8.02
Topic: T16 – 2D Motion & Physics
Skill: Implement fixed joints for connected objects
Description: Use `fix relative position to [sprite]` to weld sprites together so they move as a single rigid unit, and `remove relative position constraint` to break the connection. **Examples:** compound objects (car with wheels), multi-part characters (robot with detachable arms), towed vehicles that can be detached mid-game. Fixed joints are useful when objects should move as one rigid body. **Acceptance criteria:** Fixed joint created, compound object behaves as single unit, detachment works.

Dependencies:
* T16.G7.06: Model a real-world physics scenario
* T16.G7.04: Build chains or stacks of physics objects


ID: T16.G8.02.01
Topic: T16 – 2D Motion & Physics
Skill: Implement revolute joints for hinges
Description: Use `set [sprite] as rotation axis with offset x [X] y [Y]` to create hinged objects like doors, seesaws, and pendulums. Configure rotation behavior with `set rotation axis speed [S] damping factor [D]%`, and use `remove rotation axis` to disconnect hinges. **Examples:** swinging doors, seesaw balance puzzles, pendulum clocks, catapult arms. Revolute joints allow rotation around a fixed point. **Acceptance criteria:** Hinge joint created, rotation constrained to axis, motor control demonstrated if applicable.

Dependencies:
* T16.G8.02: Implement fixed joints for connected objects
* T16.G7.04.01: Use continuous torque to rotate bodies


ID: T16.G8.02.01.01
Topic: T16 – 2D Motion & Physics
Skill: Control revolute joint motors with speed and damping
Description: Control revolute joint motors using `set rotation axis speed [S] damping factor [D]%` to create powered rotations like fans or wheels. Balance speed for rotation rate and damping for resistance, creating smooth or snappy rotation behaviors. **Examples:** motorized windmill, spinning platform, rotating obstacle in a game. **Acceptance criteria:** Motor speed and damping configured, rotation behavior controllable and predictable.

Dependencies:
* T16.G8.02.01: Implement revolute joints for hinges


ID: T16.G8.02.02
Topic: T16 – 2D Motion & Physics
Skill: Implement prismatic joints for sliding
Description: Use `allow [Horizontal/Vertical] sliding relative to [sprite] range from [min] to [max]` to create pistons, sliding doors, and spring-loaded platforms with configurable movement limits. **Examples:** elevator platform that slides vertically, piston in a machine, sliding puzzle pieces. **Note:** Prismatic joints are permanent once created; plan constraint usage during the design phase. **Acceptance criteria:** Sliding joint created, movement constrained to range, sliding behavior smooth.

Dependencies:
* T16.G8.02: Implement fixed joints for connected objects


ID: T16.G8.02.03
Topic: T16 – 2D Motion & Physics
Skill: Debug joint constraint issues
Description: Diagnose and fix common joint problems such as joints separating under force, rotation limits not working correctly, or motors behaving unpredictably. Adjust joint parameters, verify anchor positions, and test constraint behavior systematically. **Acceptance criteria:** Joint bug identified, root cause diagnosed, fix applied successfully.

Dependencies:
* T16.G8.02.01: Implement revolute joints for hinges
* T16.G8.02.02: Implement prismatic joints for sliding




ID: T16.G8.03
Topic: T16 – 2D Motion & Physics
Skill: Build automated physics regression tests
Description: Create scripts that spawn test objects, run the simulation for a set time, and assert that positions, velocities, or collision counts stay within tolerances. **Process:** (1) Set up known initial conditions, (2) run physics for fixed frames, (3) check final state against expected values, (4) report pass/fail. This guards against regressions when modifying physics code. **Acceptance criteria:** Test script created, passes for correct physics, fails for broken physics.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T16.G7.07: Evaluate whether a simulation meets requirements
* T16.G7.05.01: Instrument and graph motion data




ID: T16.G8.04
Topic: T16 – 2D Motion & Physics
Skill: Identify physics performance bottlenecks
Description: Identify performance bottlenecks in a busy physics scene by observing frame rate and lag during playtesting. **Diagnostic process:** (1) Observe where lag occurs, (2) count active physics bodies, (3) check collision shape complexity, (4) review collision group settings. Physics performance depends on body count, shape complexity, and collision pair counts. **Acceptance criteria:** Bottleneck identified, contributing factors explained, measurement data provided.

Dependencies:
* T16.G7.06: Model a real-world physics scenario
* T16.G7.07: Evaluate whether a simulation meets requirements
* T16.G6.05.02: Test collision group filtering behavior


ID: T16.G8.04.01
Topic: T16 – 2D Motion & Physics
Skill: Optimize collision shapes for performance
Description: Implement shape optimizations by using simpler collision shapes (Box instead of Convex Hull), reducing active object count, using compound shapes sparingly, disabling unnecessary collision groups, and hiding debug overlays. **Optimization checklist:** (1) Use Box/Circle over Convex Hull, (2) limit active bodies to <50, (3) use collision groups to reduce pair checks, (4) disable debug mode in production. Verify improvements through repeated playtesting. **Acceptance criteria:** Optimizations applied, performance improvement measured, checklist completed.

Dependencies:
* T16.G8.04: Identify physics performance bottlenecks
* T16.G5.06.01.02: Use Convex Hull for sprite-fitted collision




ID: T16.G8.05
Topic: T16 – 2D Motion & Physics
Skill: Control gravity scale and time speed
Description: Use `set gravity scale [value]%` to create floaty zones (low gravity), reverse gravity areas (negative values), or heavy gravity zones. Use `set physics time speed [value]%` to create slow-motion effects (50%) or fast-forward (200%) for dramatic game moments. **Examples:** moon-gravity platformer levels, bullet-time effects, time-manipulation puzzles. **Acceptance criteria:** Gravity scale zones created, time speed effects implemented, gameplay enhanced by effects.

Dependencies:
* T16.G7.06: Model a real-world physics scenario
* T16.G5.05: Initialize a 2D physics world


ID: T16.G8.05.01
Topic: T16 – 2D Motion & Physics
Skill: Create gravity transition zones between areas
Description: Build zones that smoothly transition gravity between different values (normal gravity zone → low gravity zone → zero gravity zone). **Implementation:** (1) Create invisible sensor zones, (2) detect when player enters zone with collision broadcasts, (3) gradually change `set gravity scale` over 30-60 frames using interpolation, (4) test smooth transitions without jarring jumps. **Acceptance criteria:** Smooth gravity transitions implemented, no sudden physics jerks, player movement feels natural through transitions.

Dependencies:
* T16.G8.05: Control gravity scale and time speed
* T16.G5.06.02: Create sensor bodies for trigger zones


ID: T16.G8.06
Topic: T16 – 2D Motion & Physics
Skill: Use instrumentation data to tune difficulty
Description: Log player attempts (launch angle, power, success/fail), analyze the dataset, and retune physics parameters (gravity, impulse strength, target size) to achieve a desired win rate. **Process:** (1) Add logging for player actions, (2) collect 10+ playtests, (3) calculate success rate, (4) adjust physics parameters to reach target difficulty (e.g., 60% win rate), (5) re-test. Connect physics tweaks to game analytics. **Acceptance criteria:** Data logged successfully, analysis completed, parameters tuned to target win rate.

Dependencies:
* T16.G7.05.01: Instrument and graph motion data
* T16.G8.01.02: Balance and tune physics game difficulty




ID: T16.G8.07
Topic: T16 – 2D Motion & Physics
Skill: Plan a physics-based puzzle game
Description: Plan a physics puzzle game (pulleys, seesaws, Rube Goldberg machines) by identifying required physics mechanics, sketching level layouts, and defining puzzle solutions. Create design documents specifying which joints and physics properties each puzzle requires. **Acceptance criteria:** Complete puzzle game design document with mechanics list, level sketches, and solution descriptions.

Dependencies:
* T16.G8.02: Implement fixed joints for connected objects
* T16.G7.06: Model a real-world physics scenario


ID: T16.G8.07.01
Topic: T16 – 2D Motion & Physics
Skill: Select appropriate joints for puzzle mechanics
Description: Analyze puzzle game design and select the appropriate joint types (fixed, revolute, prismatic) for each puzzle element. Justify joint choices based on desired mechanical behavior and puzzle challenge design. **Acceptance criteria:** Joint types selected for all puzzle elements, choices justified clearly.

Dependencies:
* T16.G8.07: Plan a physics-based puzzle game
* T16.G8.02.01: Implement revolute joints for hinges
* T16.G8.02.02: Implement prismatic joints for sliding


ID: T16.G8.07.02
Topic: T16 – 2D Motion & Physics
Skill: Implement and test physics puzzle game
Description: Implement physics puzzle game by creating joints, configuring physics parameters, and scripting win conditions. **Development cycle:** (1) Build first puzzle with joints, (2) playtest for solvability, (3) adjust physics parameters, (4) add visual feedback for puzzle state, (5) iterate until solutions are discoverable. Good physics puzzles have clear mechanics and fair difficulty curves. **Acceptance criteria:** Puzzle game implemented, all puzzles solvable, difficulty curve appropriate.

Dependencies:
* T16.G8.07.01: Select appropriate joints for puzzle mechanics
* T16.G8.01.02: Balance and tune physics game difficulty


ID: T16.G8.08
Topic: T16 – 2D Motion & Physics
Skill: Design multi-level physics game with level progression
Description: Design a multi-level physics game with increasing difficulty and new mechanics introduced gradually. **Design process:** (1) Create level progression plan (easy→medium→hard), (2) introduce one new mechanic per 2-3 levels, (3) design tutorial levels for new mechanics, (4) plan difficulty curve using playtesting data, (5) create level transition system with save/load. **Acceptance criteria:** Complete level progression document with 8+ levels, difficulty curve planned, mechanics introduction schedule defined.

Dependencies:
* T16.G8.01.02: Balance and tune physics game difficulty
* T16.G8.07.02: Implement and test physics puzzle game


ID: T16.G8.09
Topic: T16 – 2D Motion & Physics
Skill: Implement object pooling for spawning many physics objects
Description: Implement object pooling to efficiently spawn and recycle many physics objects (projectiles, particles, collectibles) without performance degradation. **Implementation:** (1) Create pool of hidden clones at start, (2) when spawning needed, show and position a hidden clone, (3) when object destroyed, hide and return to pool instead of deleting, (4) reuse pooled objects for new spawns. **Benefits:** Avoids constant create/delete overhead, maintains stable frame rate with many objects. **Acceptance criteria:** Pool created with 20+ objects, spawn/recycle working correctly, performance stable with many active objects.

Dependencies:
* T16.G8.04.01: Optimize collision shapes for performance
* T16.G7.01: Launch a configurable projectile


ID: T16.G8.10
Topic: T16 – 2D Motion & Physics
Skill: Decompose complex physics behavior into testable sub-components
Description: Decompose complex physics behavior (e.g., vehicle physics, character controller, chain reaction puzzle) into independent testable sub-components. **Process:** (1) Identify core behaviors (movement, jumping, collision response), (2) create isolated test scene for each behavior, (3) verify each component works independently, (4) integrate components and test interactions, (5) debug integration issues. **Example:** Character controller decomposed into: ground detection test, jump force test, friction test, slope climbing test. **Acceptance criteria:** Complex behavior decomposed into 4+ testable components, each tested independently, integration completed successfully.

Dependencies:
* T16.G8.03: Build automated physics regression tests
* T16.G8.02.03: Debug joint constraint issues


ID: T16.G8.11
Topic: T16 – 2D Motion & Physics
Skill: Apply physics patterns to new game genres
Description: Identify physics patterns from existing games (launcher, platformer, puzzle, sports) and apply them to create a new game in a different genre. **Process:** (1) Analyze mechanics from 2+ existing physics games, (2) identify reusable patterns (projectile launch, collision scoring, force accumulation, joint constraints), (3) combine patterns in novel way for new genre, (4) prototype and playtest new combination. **Example:** Combine golf launch mechanics with puzzle game chain reactions to create golf-puzzle hybrid. **Acceptance criteria:** New game genre created using 3+ physics patterns from different sources, prototype demonstrates novel combination, gameplay is cohesive.

Dependencies:
* T16.G8.01.02: Balance and tune physics game difficulty
* T16.G8.07.02: Implement and test physics puzzle game
* T16.G7.08: Create a physics-based sports game


ID: T16.G8.11.01
Topic: T16 – 2D Motion & Physics
Skill: Document physics patterns as reusable templates
Description: Create documentation templates for common physics patterns that can be reused across projects. **Patterns to document:** (1) platformer character setup (body type, shape, density, friction), (2) bouncing ball configuration, (3) kinematic platform movement, (4) collision group setup for multi-layer games. **Template format:** Purpose, required blocks, parameter recommendations, common pitfalls. **Acceptance criteria:** 3+ physics patterns documented, templates include all necessary configuration details, tested by implementing pattern from template alone.

Dependencies:
* T16.G8.11: Apply physics patterns to new game genres


ID: T16.G8.12
Topic: T16 – 2D Motion & Physics
Skill: Create AI-controlled physics objects (enemy that aims projectiles)
Description: Build AI-controlled enemies that use physics to aim and launch projectiles at the player. **Implementation:** (1) Calculate angle from enemy to player position, (2) predict player movement trajectory, (3) calculate launch angle accounting for gravity and distance, (4) apply impulse in calculated direction, (5) add variation to make aiming imperfect but fair. **Acceptance criteria:** AI enemy aims at player, projectiles have realistic trajectories, aiming difficulty tunable, gameplay feels fair.

Dependencies:
* T16.G7.01: Launch a configurable projectile
* T16.G8.01.02: Balance and tune physics game difficulty


ID: T16.G8.13
Topic: T16 – 2D Motion & Physics
Skill: Use machine learning to optimize physics parameters
Description: Use iterative playtesting data to automatically tune physics parameters for target difficulty. **Process:** (1) Define target metrics (60% win rate, average 3 attempts), (2) run automated playtests with different parameter sets, (3) record success rates for each parameter combination, (4) identify parameter values that achieve target metrics, (5) verify through human playtesting. **Note:** This is simplified ML—systematically testing parameter space and selecting best performers. **Acceptance criteria:** Parameter optimization process completed, target metrics achieved, improvement over manual tuning demonstrated.

Dependencies:
* T16.G8.06: Use instrumentation data to tune difficulty
* T16.G8.03: Build automated physics regression tests


ID: T16.G8.14
Topic: T16 – 2D Motion & Physics
Skill: Implement procedural level generation with physics constraints
Description: Create a system that procedurally generates physics-based levels while ensuring they remain solvable. **Implementation:** (1) Define level template with variable positions, (2) randomly place platforms/obstacles within constraints, (3) verify path exists from start to goal using physics simulation, (4) if unsolvable, regenerate or adjust, (5) test generated levels for fairness. **Acceptance criteria:** Level generator creates 5+ unique solvable levels, physics constraints maintained, all levels playable and fair.

Dependencies:
* T16.G8.07.02: Implement and test physics puzzle game
* T16.G8.10: Decompose complex physics behavior into testable sub-components


ID: T16.G8.15
Topic: T16 – 2D Motion & Physics
Skill: Build adaptive difficulty using physics telemetry
Description: Implement adaptive difficulty that adjusts physics parameters based on player performance. **Implementation:** (1) Track player success rate over last 5 attempts, (2) if success rate < 40%, reduce difficulty (weaker gravity, larger targets, more impulse force), (3) if success rate > 80%, increase difficulty (stronger gravity, smaller targets, less force), (4) adjust gradually to avoid noticeable jumps, (5) display difficulty adjustments transparently. **Acceptance criteria:** Adaptive difficulty system working, adjustments based on data, player experience improved, difficulty changes feel fair.

Dependencies:
* T16.G8.06: Use instrumentation data to tune difficulty
* T16.G8.01.02: Balance and tune physics game difficulty

# T17 - 3D Worlds & Games (COMPREHENSIVE REVISION - November 2025)

# MAJOR IMPROVEMENTS IN THIS VERSION:
#
# 1. RESTRUCTURED FOR PROBLEM-SOLVING FOCUS:
#    - Reduced procedural "add shape X" skills in favor of design/thinking skills
#    - Added first-person camera, raycast collision, distance sensors
#    - Added AI-3D integration and multiplayer 3D foundations
#    - More emphasis on debugging, prediction, and design patterns
#
# 2. NEW HIGH-VALUE SKILLS ADDED:
#    - G5: First-person camera controls, raycast collision detection
#    - G6: Distance sensors for obstacle detection, state machines for game logic
#    - G7: Object pooling for performance, pathfinding concepts, LOD systems
#    - G8: Multiplayer 3D synchronization, AI NPC behaviors, procedural generation
#
# 3. CONSOLIDATED REDUNDANT SKILLS:
#    - Particle emitters (fire/smoke/sparks) consolidated into one skill + configuration
#    - Shape skills consolidated with clearer progression
#    - Removed excessive linear dependency chains
#
# 4. STRONGER COMPUTATIONAL THINKING:
#    - Every grade has prediction, debugging, and design skills
#    - Added game design patterns (state machines, object pooling, LOD)
#    - Added algorithm design (pathfinding, procedural generation)
#
# 5. BETTER GRADE-LEVEL ALIGNMENT:
#    - G3-4: Foundations (shapes, positioning, basic camera/lighting)
#    - G5-6: Physics + interactivity (collisions, controls, sensors)
#    - G7-8: Advanced systems (optimization, AI, multiplayer, procedural)
#
# 6. PRESERVED CROSS-TOPIC DEPENDENCIES:
#    - T06 (Sequencing), T07 (Loops), T08 (Conditionals), T09 (Variables)
#    - T03 (Decomposition), T12 (Tracing)
#
# 7. X-2 RULE COMPLIANCE: All dependencies respect grade constraints
#
# Total skills: 173 (focused on depth over breadth)
# Format: Active verbs, clear auto-grading criteria
# K-2: Picture-based spatial reasoning (no coding)

## KINDERGARTEN (5 skills - Picture-based 3D shape recognition)

ID: T17.GK.01
Topic: T17 – 3D Worlds & Games
Skill: Sort picture cards of 3D shapes by type
Description: **Student task:** Drag picture cards showing 3D objects into groups: cubes/boxes, spheres/balls, and cylinders/cans. **Visual scenario:** 9 picture cards show: wooden block, basketball, soup can, dice, orange, paper towel roll, gift box, marble, battery. **Correct groups:** Cubes (block, dice, gift box), Spheres (basketball, orange, marble), Cylinders (soup can, paper towel roll, battery). _Implementation note: Drag-drop sorting with 3 labeled bins. Auto-graded by final groupings. CSTA: 1A-AP-11._

Dependencies: None



ID: T17.GK.02
Topic: T17 – 3D Worlds & Games
Skill: Match 3D shapes to real-world objects
Description: **Student task:** Draw lines connecting 3D shape icons to pictures of matching real-world objects. **Visual scenario:** Left column: cube icon, sphere icon, cylinder icon, cone icon. Right column: ice cream cone, basketball, filing cabinet, tin can. **Correct matches:** Cube→filing cabinet, Sphere→basketball, Cylinder→tin can, Cone→ice cream cone. _Implementation note: Line-drawing matching exercise. Auto-graded by connection accuracy. CSTA: 1A-AP-11._

Dependencies:
* T17.GK.01: Sort picture cards of 3D shapes by type



ID: T17.GK.03
Topic: T17 – 3D Worlds & Games
Skill: Identify how many faces a 3D shape has
Description: **Student task:** Tap the number that shows how many flat faces the shape has. **Visual scenario:** Shows a cube with faces highlighted one by one, counting prompt "How many flat faces?" Answer choices: 4, 6, 8. **Correct answer:** 6. Second item shows a cylinder, choices: 2, 3, 4, answer: 2 (top and bottom). _Implementation note: MCQ with animated face highlighting. Auto-graded by selection. CSTA: 1A-AP-09._

Dependencies:
* T17.GK.01: Sort picture cards of 3D shapes by type



ID: T17.GK.04
Topic: T17 – 3D Worlds & Games
Skill: Predict which 3D shape can roll
Description: **Student task:** Tap all the shapes that can roll. **Visual scenario:** Shows picture cards: cube, sphere, cylinder, pyramid. **Correct answers:** Sphere and cylinder (both have curved surfaces). _Implementation note: Multi-select with audio "Which shapes can roll down a ramp?" Auto-graded by selections. CSTA: 1A-AP-12._

Dependencies:
* T17.GK.02: Match 3D shapes to real-world objects



ID: T17.GK.05
Topic: T17 – 3D Worlds & Games
Skill: Predict which 3D shapes can stack stably
Description: **Student task:** Tap all shapes that can stack on top of each other without falling. **Visual scenario:** Shows: cube, sphere, cylinder (standing), cone (point up). **Correct answers:** Cube and cylinder (flat tops). _Implementation note: Multi-select with visual of stacking attempt. Auto-graded by selections. CSTA: 1A-AP-12._

Dependencies:
* T17.GK.04: Predict which 3D shape can roll



## GRADE 1 (6 skills - Shape vocabulary and spatial relationships)

ID: T17.G1.01
Topic: T17 – 3D Worlds & Games
Skill: Match 3D shapes to their names
Description: **Student task:** Draw lines connecting 3D shape pictures to their name labels. **Visual scenario:** Left column shows: cube, sphere, cylinder, cone, pyramid. Right column shows labels in scrambled order. **Correct matches:** Each shape to its name. _Implementation note: Line-drawing matching. Auto-graded by connection accuracy. CSTA: 1B-AP-11._

Dependencies:
* T17.GK.05: Predict which 3D shapes can stack stably



ID: T17.G1.02
Topic: T17 – 3D Worlds & Games
Skill: Identify the shadow a 3D shape would cast
Description: **Student task:** Match each 3D shape to its shadow when light shines from above. **Visual scenario:** Top row: cube, sphere, cylinder, cone. Bottom row: shadow shapes (square, circle, circle, triangle). **Correct matches:** Cube→square, Sphere→circle, Cylinder→circle, Cone→triangle. _Implementation note: Drag-drop matching. Auto-graded by correct pairings. CSTA: 1B-AP-12._

Dependencies:
* T17.G1.01: Match 3D shapes to their names



ID: T17.G1.03
Topic: T17 – 3D Worlds & Games
Skill: Select the correct net that folds into a 3D shape
Description: **Student task:** Tap the flat pattern (net) that would fold into the shown 3D shape. **Visual scenario:** Shows a cube, with 3 net options (one correct cross-shaped net, two incorrect patterns). **Correct answer:** The cross-shaped net. _Implementation note: MCQ with visual folding animation on selection. Auto-graded by selection. CSTA: 1B-AP-12._

Dependencies:
* T17.G1.02: Identify the shadow a 3D shape would cast



ID: T17.G1.04
Topic: T17 – 3D Worlds & Games
Skill: Use spatial words to describe object positions
Description: **Student task:** Select the word that describes where the ball is compared to the box. **Visual scenario:** Shows a ball and box in various positions. Prompt: "The ball is ___ the box." Choices: above, below, beside, inside. **Correct answer:** Varies by image (e.g., ball on top = "above"). _Implementation note: MCQ with clear spatial relationships. Auto-graded by selection. CSTA: 1B-AP-11._

Dependencies:
* T17.G1.01: Match 3D shapes to their names



ID: T17.G1.05
Topic: T17 – 3D Worlds & Games
Skill: Predict the view from a different position
Description: **Student task:** A toy car faces right. Tap which picture shows what you would see if you walked behind the car. **Visual scenario:** Car shown from side view. 3 answer choices showing car from front, back, and other side. **Correct answer:** Back view of car. _Implementation note: MCQ testing perspective taking. Auto-graded by selection. CSTA: 1B-AP-12._

Dependencies:
* T17.G1.04: Use spatial words to describe object positions



ID: T17.G1.06
Topic: T17 – 3D Worlds & Games
Skill: Count edges and vertices on 3D shapes
Description: **Student task:** Count and tap the number showing how many edges (straight lines where faces meet) or vertices (corners) a shape has. **Visual scenario:** Shows a cube with edges highlighted in yellow. Question: "How many edges?" Choices: 8, 10, 12. **Correct answer:** 12. Follow-up with pyramid for vertices. _Implementation note: MCQ with visual highlighting. Auto-graded. CSTA: 1B-AP-09._

Dependencies:
* T17.GK.03: Identify how many faces a 3D shape has



## GRADE 2 (6 skills - Multi-view reasoning and perspective)

ID: T17.G2.01
Topic: T17 – 3D Worlds & Games
Skill: Identify front, top, and side views of 3D objects
Description: **Student task:** Match each view label (front, top, side) to the correct silhouette of a 3D object. **Visual scenario:** Shows a simple house made of blocks, then 3 silhouettes. Student matches "Front view," "Top view," "Side view" labels to correct silhouettes. _Implementation note: Drag-drop matching. Auto-graded by label placement. CSTA: 1B-AP-11._

Dependencies:
* T17.G1.05: Predict the view from a different position



ID: T17.G2.02
Topic: T17 – 3D Worlds & Games
Skill: Predict where an object will appear after rotation
Description: **Student task:** A cube has a star on the front face. If we rotate it 90° to the right, which face will show the star? **Visual scenario:** Cube shown with star on front, arrows indicating rotation. Choices: front, right, back, left sides. **Correct answer:** The star moves to the left side after rotating right. _Implementation note: MCQ with rotation animation. Auto-graded by selection. CSTA: 1B-AP-12._

Dependencies:
* T17.G2.01: Identify front, top, and side views of 3D objects



ID: T17.G2.03
Topic: T17 – 3D Worlds & Games
Skill: Trace a path through a simple 3D maze from above
Description: **Student task:** Looking at a maze from above (bird's eye view), draw the path from start to finish. **Visual scenario:** Top-down view of a simple 3D block maze with green start and red finish markers. Student draws path avoiding walls. _Implementation note: Path drawing with collision detection. Auto-graded by valid path completion. CSTA: 1B-AP-11._

Dependencies:
* T17.G2.01: Identify front, top, and side views of 3D objects



ID: T17.G2.04
Topic: T17 – 3D Worlds & Games
Skill: Count blocks in a 3D structure including hidden ones
Description: **Student task:** Count the total number of blocks in this structure, including blocks you cannot see. **Visual scenario:** Shows an L-shaped structure of cubes (some hidden behind others). Student enters number. **Correct answer:** Total including hidden blocks. _Implementation note: Numeric entry with visual hints available. Auto-graded by count. CSTA: 1B-AP-09._

Dependencies:
* T17.G2.02: Predict where an object will appear after rotation



ID: T17.G2.05
Topic: T17 – 3D Worlds & Games
Skill: Match 3D scenes to their bird's eye view maps
Description: **Student task:** Match each 3D scene to its top-down map view. **Visual scenario:** Left: 3 different room arrangements with furniture. Right: 3 top-down floor plan views. Student draws lines to match. _Implementation note: Line-drawing matching. Auto-graded by correct pairings. CSTA: 1B-AP-11._

Dependencies:
* T17.G2.03: Trace a path through a simple 3D maze from above



ID: T17.G2.06
Topic: T17 – 3D Worlds & Games
Skill: Predict how light creates shadows in a 3D scene
Description: **Student task:** The sun is on the left. Tap where the tree's shadow will fall. **Visual scenario:** Shows a tree with sun position indicated. Three possible shadow positions marked A, B, C. **Correct answer:** Shadow falls to the right (opposite sun). _Implementation note: MCQ testing light/shadow reasoning. Auto-graded by selection. CSTA: 1B-AP-12._

Dependencies:
* T17.G2.04: Count blocks in a 3D structure including hidden ones



## GRADE 3 (21 skills - 3D fundamentals in CreatiCode)

ID: T17.G3.01
Topic: T17 – 3D Worlds & Games
Skill: Interpret 3D axis directions (X, Y, Z)
Description: Students read a labeled axis diagram or CreatiCode gizmo and identify which axis (X, Y, Z) controls width (left/right), height (up/down), and depth (forward/back), linking math vocabulary to the 3D coordinate system. They understand that positive X moves right, negative X moves left; positive Y moves up, negative Y moves down; positive Z moves forward (toward camera), negative Z moves back (away from camera). _CSTA: 2-AP-13._

Dependencies:
* T17.G2.06: Predict how light creates shadows in a 3D scene
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence



ID: T17.G3.02
Topic: T17 – 3D Worlds & Games
Skill: Match camera views to 3D scene layouts
Description: Students view a 3D scene with multiple objects (tree, house, car) and match screenshots from different camera positions to camera icons placed around the scene, understanding how camera position determines what appears in view. They identify which camera angle produces which view (top-down, side view, front view, angled perspective). _CSTA: 2-AP-10._

Dependencies:
* T17.G3.01: Interpret 3D axis directions (X, Y, Z)



ID: T17.G3.03
Topic: T17 – 3D Worlds & Games
Skill: Initialize a 3D scene with a specific environment
Description: Students add a `when green flag clicked` script that calls the CreatiCode `initialize 3D scene [SCENETYPE]` block, selecting from environment options (Empty, Blue Sky, Castle, City, Forest, etc.) to set the stage for their 3D project. **How it works:** This block must run before any 3D objects can be added—it sets up the 3D rendering engine, camera, and base environment. **Test your code:** Run and verify the selected environment appears. _CSTA: 2-AP-10._

Dependencies:
* T17.G3.02: Match camera views to 3D scene layouts
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence



ID: T17.G3.03.01
Topic: T17 – 3D Worlds & Games
Skill: Set scene background color
Description: Students use the `set scene background color [COLOR]` block to change the background color of the 3D scene, creating different moods or visual styles (bright blue sky, dark night, foggy gray, sunset orange). They experiment with color choices to match their project theme. _CSTA: 2-AP-15._

Dependencies:
* T17.G3.03: Initialize a 3D scene with a specific environment



ID: T17.G3.04.01
Topic: T17 – 3D Worlds & Games
Skill: Add a box shape to the 3D scene
Description: Students use the `add box [COLOR] size in x y z` block to place a box in the scene, adjusting color and size parameters (width in x, height in y, depth in z) to create objects like platforms, walls, or buildings. **Parameters:** color (hex or name), x-size (width), y-size (height), z-size (depth). **Common uses:** Ground platforms, walls, crates, buildings. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.03: Initialize a 3D scene with a specific environment



ID: T17.G3.04.02
Topic: T17 – 3D Worlds & Games
Skill: Add a sphere shape to the 3D scene
Description: Students use the `add sphere [COLOR] size in x y z` block to create round objects like balls, planets, or collectibles, adjusting color and size parameters. Setting equal x/y/z creates perfect spheres; different values create ovals/ellipsoids. **Common uses:** Balls, planets, collectible items, boulders. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.04.01: Add a box shape to the 3D scene



ID: T17.G3.04.03
Topic: T17 – 3D Worlds & Games
Skill: Add a cylinder shape to the 3D scene
Description: Students use the `add cylinder [COLOR] diameter top bottom height` block to create columnar objects like posts, tree trunks, or poles. They adjust color, height, and top/bottom diameter parameters. **How it works:** Equal top and bottom diameters create cylinders; different values create cones or truncated cones. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.04.01: Add a box shape to the 3D scene



ID: T17.G3.05
Topic: T17 – 3D Worlds & Games
Skill: Position shapes using x/y/z coordinates
Description: Students use the `move to x y z in (T) seconds` block to position objects at target coordinates. They understand that x controls left/right, y controls up/down, z controls forward/back. **Coordinate examples:** (0, 0, 0) = center, (5, 0, 0) = 5 units right, (0, 10, -5) = 10 units up and 5 units back. **Test your code:** Place objects at specific coordinates and verify they appear where expected. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.04.01: Add a box shape to the 3D scene



ID: T17.G3.05.01
Topic: T17 – 3D Worlds & Games
Skill: Turn objects to face a direction
Description: Students use the `rotate to direction x y z in (T) seconds` block to orient objects in 3D space by setting rotation angles (in degrees) around each axis. **Rotation axes:** X-axis rotation = pitch (tilt forward/back), Y-axis rotation = yaw (turn left/right), Z-axis rotation = roll (lean sideways). _CSTA: 2-AP-13._

Dependencies:
* T17.G3.05: Position shapes using x/y/z coordinates



ID: T17.G3.05.02
Topic: T17 – 3D Worlds & Games
Skill: Turn objects incrementally around an axis
Description: Students use the `turn (N) degrees around the [AXIS] axis` block to rotate objects incrementally, understanding how each axis (X, Y, Z) affects rotation. They create spinning objects by using this block in loops. **Common uses:** Spinning coins, rotating platforms, turning characters to face directions. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.05.01: Turn objects to face a direction



ID: T17.G3.06.01
Topic: T17 – 3D Worlds & Games
Skill: Change shape color using diffusion color
Description: Students use the `update color diffusion [COLOR]` block to apply a solid diffusion color to 3D objects, learning how to differentiate objects visually (e.g., making the ground green, a player red, enemies purple). **How it works:** Diffusion color is the base surface color of the object under lighting. _CSTA: 2-AP-15._

Dependencies:
* T17.G3.04.01: Add a box shape to the 3D scene



ID: T17.G3.06.02
Topic: T17 – 3D Worlds & Games
Skill: Add emission glow to objects
Description: Students use the emission color parameter in the `update color diffusion [COLOR] emission [COLOR]` block to make objects appear to glow or emit light. **How it works:** Emission makes objects bright even in darkness—useful for lamps, lasers, power-ups, magical effects. _CSTA: 2-AP-15._

Dependencies:
* T17.G3.06.01: Change shape color using diffusion color



ID: T17.G3.06.03
Topic: T17 – 3D Worlds & Games
Skill: Adjust shape transparency with material settings
Description: Students use the `material setting: transparent [HASTRANSPARENCY]` block and alpha values in color codes to make objects partially or fully transparent. **Uses:** Windows, water, ghost effects, force fields. **How it works:** Alpha channel in #RRGGBBAA format controls transparency (FF = opaque, 00 = invisible). _CSTA: 2-AP-15._

Dependencies:
* T17.G3.06.02: Add emission glow to objects



ID: T17.G3.07
Topic: T17 – 3D Worlds & Games
Skill: Name 3D objects for later reference
Description: Students learn to give meaningful names to objects using the `as [NAME]` parameter when creating shapes, so they can refer to them later in their scripts for movement, collision, or other interactions. **Naming guidelines:** Use descriptive names (player, ground, enemy1, coin5) not generic names (object1, thing). _CSTA: 2-AP-11._

Dependencies:
* T17.G3.04.01: Add a box shape to the 3D scene



ID: T17.G3.08
Topic: T17 – 3D Worlds & Games
Skill: Select and work with named objects
Description: Students use the `select sprite object by name [NAME]` block to select previously created objects, then apply transformations (move, rotate, color) to them. **How it works:** After selection, subsequent transformation blocks affect only the selected object. **Common pattern:** Select by name → modify properties → select another object. _CSTA: 2-AP-11._

Dependencies:
* T17.G3.07: Name 3D objects for later reference



ID: T17.G3.09
Topic: T17 – 3D Worlds & Games
Skill: Predict object position from coordinate values
Description: Students read x/y/z coordinate values in code and predict where an object will appear in the 3D scene (e.g., "move to x: 0, y: 5, z: -10" means centered horizontally, elevated 5 units, and 10 units away from camera). They build mental mapping between numbers and spatial locations. **Practice:** Given coordinates, students point to where object will appear before running code. _CSTA: 2-AP-12._

Dependencies:
* T17.G3.05: Position shapes using x/y/z coordinates



ID: T17.G3.10
Topic: T17 – 3D Worlds & Games
Skill: Debug a mispositioned object by fixing coordinates
Description: Students examine a 3D scene where an object appears in the wrong location (e.g., underground at y: -5 instead of y: 5, or too far at z: -100 instead of z: -10) and correct the coordinate values in the code to place the object in the intended position. **Debug process:** Identify which axis is wrong → determine correct value → test fix. _CSTA: 2-AP-17._

Dependencies:
* T17.G3.09: Predict object position from coordinate values



ID: T17.G3.11
Topic: T17 – 3D Worlds & Games
Skill: Read 3D object property values
Description: Students use reporter blocks like `get position x/y/z of object [NAME]`, `get rotation of object [NAME]`, and `get scale of object [NAME]` to read current property values from 3D objects. **How it works:** After selecting an object by name, these reporters return the object's current position, rotation, or scale values for use in calculations, comparisons, or conditional logic. **Common uses:** Check if object moved, compare positions, verify transformations, calculate distances. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.08: Select and work with named objects



ID: T17.G3.12
Topic: T17 – 3D Worlds & Games
Skill: Build a simple 3D scene with shapes and colors
Description: Students combine scene initialization, shape creation (boxes, spheres, cylinders), positioning, coloring, and naming to create a simple 3D environment (e.g., a park with ground, trees as cylinders, balls as spheres). **Requirements:** At least 5 objects, 3 different shapes, 3 different colors, meaningful names. _CSTA: 2-AP-16._

Dependencies:
* T17.G3.08: Select and work with named objects
* T17.G3.06.01: Change shape color using diffusion color



## GRADE 4 (25 skills - Advanced shapes, lighting, camera, and animation)

ID: T17.G4.01.01
Topic: T17 – 3D Worlds & Games
Skill: Add plane shapes for floors and walls
Description: Students use the `add plane [COLOR] size x y` block to create flat surfaces for floors, walls, or backdrops, adjusting color, width, and height to build environments. **How planes work:** Planes are 2D surfaces with no thickness—perfect for ground, walls, or backdrop panels. **Common uses:** Ground platforms, wall panels, backdrop screens. _CSTA: 2-AP-13._

Dependencies:
* T17.G3.12: Build a simple 3D scene with shapes and colors



ID: T17.G4.01.02
Topic: T17 – 3D Worlds & Games
Skill: Add capsule shapes to the 3D scene
Description: Students use the `add capsule [COLOR] diameter top bottom height sides` block to create capsule shapes (for character bodies, pillars, rounded posts), adjusting top and bottom diameter and height parameters. **What capsules are:** Cylinders with rounded ends—good for smooth character bodies. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.01.01: Add plane shapes for floors and walls



ID: T17.G4.01.03
Topic: T17 – 3D Worlds & Games
Skill: Add torus shapes to the 3D scene
Description: Students use the `add torus [COLOR] diameter thickness sides` block to create donut-shaped rings (for wheels, rings, halos), adjusting diameter (size of whole ring) and thickness (thickness of tube) parameters. **Common uses:** Rings, wheels, halos, portals. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.01.02: Add capsule shapes to the 3D scene



ID: T17.G4.01.04
Topic: T17 – 3D Worlds & Games
Skill: Remove individual 3D objects from the scene
Description: Students use the `remove object named [NAME]` block to delete specific objects from the scene, useful for collecting items, removing enemies, or cleaning up game elements. **How it works:** Select object by name, then remove block deletes only that object. _CSTA: 2-AP-10._

Dependencies:
* T17.G4.01.03: Add torus shapes to the 3D scene



ID: T17.G4.01.05
Topic: T17 – 3D Worlds & Games
Skill: Remove all 3D objects from the scene
Description: Students use the `remove all objects` block to clear the entire scene at once, useful for resetting levels, transitioning between scenes, or starting fresh. **Difference from erase all:** Remove all deletes 3D objects; erase all clears pen drawings. _CSTA: 2-AP-10._

Dependencies:
* T17.G4.01.04: Remove individual 3D objects from the scene



ID: T17.G4.02.01
Topic: T17 – 3D Worlds & Games
Skill: Add ambient lighting to set base brightness
Description: Students use the `add ambient light [COLOR] intensity` block to provide overall base illumination to the scene. **What ambient light does:** Provides even lighting from all directions with no shadows—sets minimum brightness level. **When to use:** Always add ambient light first to prevent completely black unlit areas. _CSTA: 2-AP-15._

Dependencies:
* T17.G4.01.01: Add plane shapes for floors and walls



ID: T17.G4.02.02
Topic: T17 – 3D Worlds & Games
Skill: Add directional lighting for sunlight effect
Description: Students use the `add directional light [COLOR] in direction xyz intensity` block to simulate sunlight coming from a specific direction. **What directional light does:** Creates parallel rays like sunlight; casts shadows; adds depth and definition. **Direction parameter:** Points toward where light comes FROM (negative Y = sun from above). **Comparison to ambient:** Unlike ambient light which is uniform everywhere, directional light creates shadows and highlights. _CSTA: 2-AP-15._

Dependencies:
* T17.G4.02.01: Add ambient lighting to set base brightness



ID: T17.G4.02.03
Topic: T17 – 3D Worlds & Games
Skill: Add point lights for localized illumination
Description: Students use the `add point light [COLOR] at xyz intensity` block to create localized light sources that radiate in all directions from a point, like light bulbs or torches. **What point lights do:** Light radiates from a point; brightness decreases with distance (falloff). **Comparison to directional:** Unlike directional light which illuminates uniformly, point lights brighten objects near them and fade with distance. **Common uses:** Torches, lamps, campfires, glowing objects. _CSTA: 2-AP-15._

Dependencies:
* T17.G4.02.01: Add ambient lighting to set base brightness



ID: T17.G4.02.04
Topic: T17 – 3D Worlds & Games
Skill: Add spot lights for focused illumination
Description: Students use the `add spot light [COLOR] at xyz direction xyz angle intensity` block to create focused cone-shaped lights like flashlights or stage lights. **What spot lights do:** Light projects in a cone; angle controls how wide the cone spreads. **Comparison to point lights:** Unlike point lights which radiate in all directions, spot lights aim in one direction and illuminate a cone-shaped area. **Common uses:** Flashlights, stage spotlights, car headlights. _CSTA: 2-AP-15._

Dependencies:
* T17.G4.02.01: Add ambient lighting to set base brightness



ID: T17.G4.02.05
Topic: T17 – 3D Worlds & Games
Skill: Remove lights from the scene
Description: Students use the `remove light named [NAME]` block to delete specific lights, or `remove all lights` to clear all lighting for scene transitions or resets. **When to use:** Change lighting between day/night, enter dark cave, transition between scenes. _CSTA: 2-AP-10._

Dependencies:
* T17.G4.02.01: Add ambient lighting to set base brightness



ID: T17.G4.03.01
Topic: T17 – 3D Worlds & Games
Skill: Set up an orbit camera to view a target
Description: Students use the `add orbit camera distance v-angle h-angle` block to create a camera that circles around a target point. **Parameters:** distance (how far from target), v-angle (vertical angle—higher = looking down), h-angle (horizontal angle—rotation around target). **Common uses:** Character viewers, examine objects from all angles. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.02.05: Remove lights from the scene



ID: T17.G4.03.02
Topic: T17 – 3D Worlds & Games
Skill: Set camera target position
Description: Students use the `set camera target xyz` block to specify what point the camera looks at. **How it works:** Camera always looks toward target point; changing target makes camera turn to face different locations. **Uses:** Focus camera on player, important objects, or action areas. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.03.01: Set up an orbit camera to view a target



ID: T17.G4.03.03
Topic: T17 – 3D Worlds & Games
Skill: Set up a follow camera to track a moving object
Description: Students use the `add follow camera distance height rotation` block to create a camera that automatically follows a player or vehicle. **How it works:** Camera maintains constant offset from target object as it moves. **Common uses:** Third-person games where camera follows player character. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.03.02: Set camera target position



ID: T17.G4.03.04
Topic: T17 – 3D Worlds & Games
Skill: Configure camera distance limits
Description: Students use the `configure camera radius min max` block to set bounds on how close or far the camera can zoom, preventing players from zooming too far in or out. **Why limits matter:** Prevent seeing inside objects (too close) or losing detail (too far). _CSTA: 2-AP-13._

Dependencies:
* T17.G4.03.03: Set up a follow camera to track a moving object



ID: T17.G4.04.01
Topic: T17 – 3D Worlds & Games
Skill: Place 3D models from the CreatiCode library
Description: Students use the `add model [MODELTYPE]` block to select and place 3D models from CreatiCode's library (trees, cars, buildings, furniture, animals) to enhance their scenes. **Model categories:** Nature, vehicles, buildings, characters, props. **How to use:** Select category → select specific model → set position and size. _CSTA: 2-AP-16._

Dependencies:
* T17.G4.03.04: Configure camera distance limits



ID: T17.G4.04.02
Topic: T17 – 3D Worlds & Games
Skill: Add avatar models to the scene
Description: Students use the `add avatar [AVATARTYPE] height as [NAME]` block to add humanoid character models to their scenes. **Available avatars:** Various character types with built-in animation rigs. **Preparation for:** Animation blocks that require avatar models. _CSTA: 2-AP-16._

Dependencies:
* T17.G4.04.01: Place 3D models from the CreatiCode library



ID: T17.G4.05.01
Topic: T17 – 3D Worlds & Games
Skill: Play built-in avatar animations
Description: Students use the `start model animation [NAME] looping speed` block to play built-in avatar animations (walking, running, jumping, dancing, waving) to bring characters to life. **Parameters:** animation name (from list), looping (true/false), speed (multiplier). **Common animations:** Idle, walk, run, jump, wave, dance. _CSTA: 2-AP-16._

Dependencies:
* T17.G4.04.02: Add avatar models to the scene



ID: T17.G4.05.02
Topic: T17 – 3D Worlds & Games
Skill: Animate scenery elements with rotation loops
Description: Students create looping animations for props (windmill spinning, fans rotating, wheels turning) by combining forever loops with the `turn degrees around axis` block. **Common pattern:** Forever loop → turn 5 degrees around Y axis → creates continuous spinning. _CSTA: 2-AP-12._

Dependencies:
* T17.G4.05.01: Play built-in avatar animations
* T07.G3.03: Build a forever loop for simple animation



ID: T17.G4.05.03
Topic: T17 – 3D Worlds & Games
Skill: Animate scenery with position changes
Description: Students use forever loops with the `move to xyz in (T) seconds` block or `glide to xyz` to create bobbing platforms, swinging pendulums, or moving obstacles. **Pattern example:** Forever → move to position A → wait → move to position B → wait → (repeat). _CSTA: 2-AP-12._

Dependencies:
* T17.G4.05.02: Animate scenery elements with rotation loops



ID: T17.G4.06
Topic: T17 – 3D Worlds & Games
Skill: Calculate distance between 3D objects
Description: Students use the `distance between objects [OBJECT1] and [OBJECT2]` block to calculate how far apart two objects are, useful for proximity detection, triggers, and game logic. **Returns:** Distance as a number (in scene units). **Common uses:** Detect when player is near collectible, enemy detection range, trigger cutscenes. _CSTA: 2-AP-13._

Dependencies:
* T17.G4.05.03: Animate scenery with position changes



ID: T17.G4.06.01
Topic: T17 – 3D Worlds & Games
Skill: Trigger events based on object proximity
Description: Students combine distance checking with conditionals to trigger events when the player gets near collectibles, NPCs, or hazards. **Common pattern:** Forever loop → if distance < threshold → trigger event (play sound, show message, add score). _CSTA: 2-AP-12._

Dependencies:
* T17.G4.06: Calculate distance between 3D objects
* T08.G3.04: Use a simple if in a script



ID: T17.G4.07
Topic: T17 – 3D Worlds & Games
Skill: Debug mispositioned 3D objects using coordinate inspection
Description: Students analyze a 3D scene where multiple objects are incorrectly placed and systematically identify which coordinate values (x, y, or z) need adjustment. **Debug process:** Inspect current coordinates → compare to intended position → identify which axis is wrong → calculate correction → test fix. **Common errors:** Underground (y too low), too far (z very negative), off-center (x wrong). _CSTA: 2-AP-17._

Dependencies:
* T17.G4.06.01: Trigger events based on object proximity
* T17.G3.10: Debug a mispositioned object by fixing coordinates



ID: T17.G4.08
Topic: T17 – 3D Worlds & Games
Skill: Build a complete 3D scene with multiple elements
Description: Students combine shapes, lighting, camera, and models to create a cohesive 3D environment (e.g., a park with trees, benches, and paths; a room with furniture). **Requirements:** Scene initialization, at least 3 shapes, 2 light sources (ambient + directional/point), camera setup, 2+ models from library, all objects positioned and colored meaningfully. _CSTA: 2-AP-16._

Dependencies:
* T17.G4.04.02: Add avatar models to the scene
* T17.G4.02.02: Add directional lighting for sunlight effect
* T17.G4.03.03: Set up a follow camera to track a moving object



ID: T17.G4.09
Topic: T17 – 3D Worlds & Games
Skill: Predict lighting effects on scene appearance
Description: Students examine code with different lighting configurations and predict visual results before running. **Prediction scenarios:** (1) Only ambient light → flat, shadowless appearance; (2) Directional from above → strong ground shadows; (3) Point light near object → localized bright area with falloff; (4) Spot light → cone of illumination. Students sketch expected appearance for given light setups, then verify by running code. **Practice pattern:** Read lighting code → identify light types and positions → predict shadows and highlights → run and compare. _CSTA: 2-AP-12._

Dependencies:
* T17.G4.02.04: Add spot lights for focused illumination
* T17.G3.09: Predict object position from coordinate values



## GRADE 5 (36 skills - Physics, cameras, raycast, and visual effects)

ID: T17.G5.01.01
Topic: T17 – 3D Worlds & Games
Skill: Initialize a 3D physics world with gravity
Description: Students use the `enable physics for scene with gravity` block to add physics simulation, setting gravity strength (usually -9.8 for Earth-like or -20 for stronger effect) so objects can fall and interact realistically. **How it works:** Must be called AFTER scene initialization and BEFORE adding physics bodies. **Gravity parameter:** Negative values pull down (typical: -9.8 to -30). _CSTA: 2-AP-13._

Dependencies:
* T17.G4.06.01: Trigger events based on object proximity



ID: T17.G5.01.02
Topic: T17 – 3D Worlds & Games
Skill: Add static physics bodies for immovable objects
Description: Students use the `add physics body with mass 0` block to attach static physics bodies to floors, walls, and platforms that should not move but should block other objects. **What static means:** Mass = 0 means object won't move from forces/collisions but still participates in physics. **Common uses:** Ground, walls, platforms. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.01.01: Initialize a 3D physics world with gravity



ID: T17.G5.01.03
Topic: T17 – 3D Worlds & Games
Skill: Add dynamic physics bodies for movable objects
Description: Students use the `add physics body with mass` block to add dynamic physics bodies to players, crates, and projectiles with mass > 0, so they can fall, be pushed, and collide. **What dynamic means:** Mass > 0 means object affected by gravity and forces. **Typical masses:** Small items = 1, characters = 5-10, heavy objects = 20+. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.01.02: Add static physics bodies for immovable objects



ID: T17.G5.01.04
Topic: T17 – 3D Worlds & Games
Skill: Remove physics bodies from objects
Description: Students use the `remove physics body` block to remove physics simulation from objects, useful for changing objects from dynamic to static or removing from physics simulation entirely. **When to use:** Object collected and should no longer interact, transition from physics to manual control. _CSTA: 2-AP-10._

Dependencies:
* T17.G5.01.03: Add dynamic physics bodies for movable objects



ID: T17.G5.01.05
Topic: T17 – 3D Worlds & Games
Skill: Freeze and unfreeze physics bodies
Description: Students use the `freeze physics body named [NAME]` and `unfreeze physics body named [NAME]` blocks to temporarily pause physics simulation on specific objects. **Uses:** Create paused states, temporarily stop object during cutscenes, freeze object in mid-air. _CSTA: 2-AP-10._

Dependencies:
* T17.G5.01.04: Remove physics bodies from objects



ID: T17.G5.02.01
Topic: T17 – 3D Worlds & Games
Skill: Configure restitution for bouncing behavior
Description: Students use the `update physics property restitution [VALUE]` block to control how bouncy objects are. **Restitution values:** 0 = no bounce (sticks on impact), 0.5 = moderate bounce, 1.0 = perfect elastic bounce (returns to original height), >1.0 = gains energy (bounces higher). **Common uses:** Balls = 0.7-0.9, crates = 0.1-0.3. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.01.05: Freeze and unfreeze physics bodies



ID: T17.G5.02.02
Topic: T17 – 3D Worlds & Games
Skill: Configure friction for sliding behavior
Description: Students use the `update physics property friction [VALUE]` block to control how easily objects slide. **Friction values:** 0 = perfectly slippery (ice), 0.5 = normal, 1.0 = sticky (rubber on rubber), 2.0+ = very sticky. **Common uses:** Ice surfaces = 0-0.1, normal ground = 0.5, sticky surfaces = 1.0+. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.02.01: Configure restitution for bouncing behavior



ID: T17.G5.03.01
Topic: T17 – 3D Worlds & Games
Skill: Detect physics collision events
Description: Students use the `broadcast [MESSAGE] on collision between physics bodies` block to detect when physics objects touch, triggering game logic responses. **How it works:** Broadcasts message when two physics bodies collide; specify which bodies or use "any". **Common uses:** Player hits enemy, ball hits goal, projectile hits target. _CSTA: 2-AP-12._

Dependencies:
* T17.G5.02.02: Configure friction for sliding behavior



ID: T17.G5.03.02
Topic: T17 – 3D Worlds & Games
Skill: Respond to collisions by collecting items
Description: Students handle collision events by updating score, playing sounds, or removing collectible objects when the player touches them. **Pattern:** When collision detected → change score by 1 → play sound → remove collectible object. _CSTA: 2-AP-16._

Dependencies:
* T17.G5.03.01: Detect physics collision events
* T09.G3.01: Create and use a numeric variable for score or count



ID: T17.G5.03.03
Topic: T17 – 3D Worlds & Games
Skill: Get names of objects in contact
Description: Students use the `names of physics bodies in contact for [NAME]` block to get a list of all objects currently touching a physics body, enabling advanced collision handling (checking multiple simultaneous collisions). **Returns:** List of object names. **Uses:** Check if standing on ground, detect multiple enemies touching player. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.03.02: Respond to collisions by collecting items



ID: T17.G5.04.01
Topic: T17 – 3D Worlds & Games
Skill: Apply textures from the CreatiCode texture library
Description: Students use the `update texture [TEXTURENAME]` block to apply pre-made textures (wood, stone, grass, metal, brick, dirt) from CreatiCode's library to make surfaces look realistic. **Texture categories:** Natural (grass, dirt, stone), architectural (brick, wood planks), materials (metal, fabric). _CSTA: 2-AP-15._

Dependencies:
* T17.G5.03.03: Get names of objects in contact



ID: T17.G5.04.02
Topic: T17 – 3D Worlds & Games
Skill: Apply costume textures to objects
Description: Students use the `update texture using costume [COSTUMENAME]` block to apply custom-drawn costumes as textures on 3D surfaces, bridging 2D sprite art with 3D geometry. **How to use:** Draw costume in costume editor → apply costume as texture → costume wraps around 3D object. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.04.01: Apply textures from the CreatiCode texture library



ID: T17.G5.04.03
Topic: T17 – 3D Worlds & Games
Skill: Configure texture repetition and rotation
Description: Students use texture tiling parameters to control how textures tile across surfaces. **Parameters:** repeat-h and repeat-v (how many times texture tiles horizontally/vertically), rotation (texture rotation angle). **Effect:** Higher repeat values create smaller tiling patterns; lower values create stretched textures. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.04.02: Apply costume textures to objects



ID: T17.G5.05.01
Topic: T17 – 3D Worlds & Games
Skill: Adjust material roughness for surface appearance
Description: Students use the `update color roughness [VALUE]` parameter to control surface roughness. **Roughness values:** 0 = perfectly shiny/reflective (mirror, metal), 0.5 = moderate (plastic), 1.0 = completely matte/rough (cloth, concrete). **Visual effect:** Lower values create sharper specular highlights. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.04.03: Configure texture repetition and rotation



ID: T17.G5.05.02
Topic: T17 – 3D Worlds & Games
Skill: Adjust material brightness
Description: Students use the `update color brightness [VALUE]` parameter to control how bright or dark a surface appears under lighting. **Brightness values:** 0 = completely black, 1.0 = normal, 2.0+ = extra bright. **Uses:** Make surfaces brighter/darker without changing base color. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.05.01: Adjust material roughness for surface appearance



ID: T17.G5.05.03
Topic: T17 – 3D Worlds & Games
Skill: Scale objects in 3D
Description: Students use the `update scale x y z in (T) seconds` block to resize objects proportionally or non-proportionally. **Scale values:** 1 = original size, 2 = double size, 0.5 = half size. **Non-proportional:** Different x/y/z values stretch objects (e.g., x=1, y=2, z=1 makes object twice as tall). _CSTA: 2-AP-13._

Dependencies:
* T17.G5.05.02: Adjust material brightness



ID: T17.G5.06.01
Topic: T17 – 3D Worlds & Games
Skill: Add fog for depth and atmosphere
Description: Students use the `set scene fog [MODE] color start end density` block to enable fog effects, creating atmospheric depth or spooky environments. **Fog parameters:** color (fog color), start (distance where fog begins), end (distance where fog is solid), density (fog thickness). **Common uses:** Spooky atmosphere, hide far objects, create depth perception. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.05.03: Scale objects in 3D



ID: T17.G5.06.02
Topic: T17 – 3D Worlds & Games
Skill: Add prebuilt fire particle emitters
Description: Students use the `add prebuilt emitter for [fire]` block to add fire particle effects from the prebuilt library with default settings. **What fire emitters do:** Emit orange/yellow flame particles moving upward with natural flickering. **Common uses:** Torches, campfires, explosions, lava. _CSTA: 2-AP-16._

Dependencies:
* T17.G5.06.01: Add fog for depth and atmosphere



ID: T17.G5.06.02.01
Topic: T17 – 3D Worlds & Games
Skill: Add prebuilt smoke particle emitters
Description: Students use the `add prebuilt emitter for [smoke]` block to add smoke particle effects from the prebuilt library. **What smoke emitters do:** Emit gray/white particles drifting upward and fading. **Common uses:** Chimneys, exhaust, steam, aftermath of explosions. _CSTA: 2-AP-16._

Dependencies:
* T17.G5.06.02: Add prebuilt fire particle emitters



ID: T17.G5.06.02.02
Topic: T17 – 3D Worlds & Games
Skill: Add prebuilt spark particle emitters
Description: Students use the `add prebuilt emitter for [sparks]` block to add spark particle effects from the prebuilt library. **What spark emitters do:** Emit bright yellow/white particles scattering outward and fading quickly. **Common uses:** Welding, electrical effects, impact flashes, magical effects. _CSTA: 2-AP-16._

Dependencies:
* T17.G5.06.02.01: Add prebuilt smoke particle emitters



ID: T17.G5.06.03
Topic: T17 – 3D Worlds & Games
Skill: Configure emitter colors
Description: Students use the `configure emitter [NAME] color: start end` block to customize particle colors over lifetime. **How it works:** Start color = initial particle color, end color = final particle color before disappearing. Particles smoothly transition between colors. **Uses:** Custom fire colors, magical effects, colored smoke. _CSTA: 2-AP-15._

Dependencies:
* T17.G5.06.02.02: Add prebuilt spark particle emitters



ID: T17.G5.06.04
Topic: T17 – 3D Worlds & Games
Skill: Configure emitter sizes
Description: Students use the `configure emitter [NAME] size: start end` block to control how particle sizes change over lifetime. **How it works:** Start size = particle size at birth, end size = particle size at death. **Common patterns:** Growing (start small, end large for explosions), shrinking (start large, end small for fading), constant (same start/end). _CSTA: 2-AP-15._

Dependencies:
* T17.G5.06.03: Configure emitter colors



ID: T17.G5.06.05
Topic: T17 – 3D Worlds & Games
Skill: Start and stop particle emitters
Description: Students use the `start emitter [NAME]` and `stop emitter [NAME]` blocks to control when particle effects are active. **When to use:** Start emitter when action begins (torch lit, engine starts), stop emitter when action ends (fire extinguished, engine stops). _CSTA: 2-AP-10._

Dependencies:
* T17.G5.06.04: Configure emitter sizes



ID: T17.G5.07
Topic: T17 – 3D Worlds & Games
Skill: Predict physics behavior before running simulation
Description: Students examine code that sets up physics bodies with different masses, restitution, and friction values, then predict the outcome (e.g., which ball will bounce higher, which object will slide further, what happens when heavy object hits light object) before running the simulation to verify. **Prediction factors:** Higher restitution = more bounce, lower friction = more sliding, higher mass = harder to move. _CSTA: 2-AP-12._

Dependencies:
* T17.G5.02.02: Configure friction for sliding behavior
* T17.G5.01.03: Add dynamic physics bodies for movable objects



ID: T17.G5.07.01
Topic: T17 – 3D Worlds & Games
Skill: Trace sequences of physics collisions and interactions
Description: Students analyze code with multiple physics bodies and trace the sequence of collision events step-by-step. **Example scenario:** Ball A rolls toward Ball B and C; trace: Ball A hits B → B accelerates → B hits wall → B bounces back → B hits C → C rolls. Students document expected positions and velocities at each key moment, then verify by running simulation. **Tracing skills:** Identify collision order, predict momentum transfer, track chain reactions. _CSTA: 2-AP-17._

Dependencies:
* T17.G5.07: Predict physics behavior before running simulation
* T17.G5.03.01: Detect physics collision events



ID: T17.G5.08
Topic: T17 – 3D Worlds & Games
Skill: Design collectible placement for balanced gameplay
Description: Students analyze a 3D game level and strategically place collectible items at varying difficulties—some easy to reach (on main path), some requiring skill (jumping to higher platforms, avoiding hazards), some optional (hard-to-find secrets). They justify placement decisions based on game design principles (reward exploration, create risk/reward choices, guide player through level). _CSTA: 2-AP-18._

Dependencies:
* T17.G5.03.02: Respond to collisions by collecting items
* T17.G4.08: Build a complete 3D scene with multiple elements



ID: T17.G5.09
Topic: T17 – 3D Worlds & Games
Skill: Build a simple physics-based interaction
Description: Students create a simple physics experience (bowling with spheres and boxes, stacking blocks, ball rolling down ramp) that demonstrates understanding of physics bodies, gravity, collisions, and material properties. **Requirements:** At least 3 dynamic bodies, 2 static bodies, appropriate masses and properties, observable physical behavior. _CSTA: 2-AP-16._

Dependencies:
* T17.G5.07: Predict physics behavior before running simulation
* T17.G5.01.03: Add dynamic physics bodies for movable objects



ID: T17.G5.10
Topic: T17 – 3D Worlds & Games
Skill: Debug texture and material display issues
Description: Students diagnose why textures or materials don't appear as expected using systematic troubleshooting. **Debug checklist:** (1) Is texture file loaded/valid? (2) Is object visible (not behind camera/outside view)? (3) Are UV/tiling settings correct (not stretched/repeated unexpectedly)? (4) Is lighting sufficient (dark materials need light)? (5) Is material roughness/brightness set correctly? Students apply process of elimination to identify and fix root causes. _CSTA: 2-AP-17._

Dependencies:
* T17.G5.04.03: Configure texture repetition and rotation
* T17.G5.05.02: Adjust material brightness



ID: T17.G5.11
Topic: T17 – 3D Worlds & Games
Skill: Set up first-person camera controls
Description: Students use the `add universal camera at xyz` block to create a first-person camera that the player can look around with. **How it works:** Universal camera responds to mouse/touch for rotation and WASD/joystick for movement. **Parameters:** Starting position (where player spawns), speed (movement rate), gravity (enable falling). **Comparison to orbit/follow cameras:** First-person camera IS the player view, not watching the player. **Common uses:** Exploration games, shooters, walking simulators. _CSTA: 2-AP-16._

Dependencies:
* T17.G4.03.03: Set up a follow camera to track a moving object
* T17.G5.01.02: Add static physics bodies for immovable objects



ID: T17.G5.12
Topic: T17 – 3D Worlds & Games
Skill: Use raycast to detect objects in a direction
Description: Students use the `cast ray from xyz direction xyz length` block to shoot an invisible ray and detect what objects it hits. **How raycast works:** Ray travels from origin in direction, returns first object hit (or nothing). **Returns:** Hit object name, hit point coordinates, hit distance. **Common uses:** Line-of-sight detection (can player see enemy?), ground detection (is player standing on something?), aiming/targeting (what is player pointing at?). _CSTA: 2-AP-13._

Dependencies:
* T17.G5.03.01: Detect physics collision events
* T17.G4.06: Calculate distance between 3D objects



ID: T17.G5.13
Topic: T17 – 3D Worlds & Games
Skill: Implement ground detection with raycast
Description: Students use downward raycasts from the player position to detect ground and enable proper jumping mechanics. **Algorithm:** Cast ray downward from player → if hit distance < threshold, player is grounded → enable jump. **Why needed:** Physics bodies can float slightly; raycast provides precise ground detection. **Debug tip:** Visualize raycast with line drawing to verify correct direction and length. _CSTA: 2-AP-12._

Dependencies:
* T17.G5.12: Use raycast to detect objects in a direction
* T17.G5.01.03: Add dynamic physics bodies for movable objects



ID: T17.G5.14
Topic: T17 – 3D Worlds & Games
Skill: Design a 3D collectible hunt game
Description: Students design and implement a simple 3D game where the player explores an environment to collect items. **Requirements:** (1) First-person or third-person camera, (2) At least 5 collectibles placed around environment, (3) Collision or proximity detection for collection, (4) Score tracking and display, (5) Win condition (all collected). Students justify design choices for camera type, collectible placement (some easy, some hidden), and feedback (sounds, visual effects). _CSTA: 2-AP-16._

Dependencies:
* T17.G5.11: Set up first-person camera controls
* T17.G5.03.02: Respond to collisions by collecting items
* T17.G5.08: Design collectible placement for balanced gameplay



## GRADE 6 (31 skills - Advanced physics, sensors, and interactivity)

ID: T17.G6.01.01
Topic: T17 – 3D Worlds & Games
Skill: Apply impulses to physics bodies
Description: Students use the `apply impulse strength direction xyz at relative point xyz` block to give objects an instant push (for jumping, explosions, or knockback effects). **Impulse vs force:** Impulse = instant change in velocity (single powerful push), force = continuous acceleration. **Parameters:** Strength (how strong), direction (which way), application point (where on object—affects rotation). _CSTA: 2-AP-13._

Dependencies:
* T17.G5.01.03: Add dynamic physics bodies for movable objects



ID: T17.G6.01.02
Topic: T17 – 3D Worlds & Games
Skill: Apply continuous forces to physics bodies
Description: Students use the `apply force strength direction xyz at relative point xyz` block to apply ongoing forces (for wind, gravity modifications, or thrust effects). **Force characteristics:** Applied continuously each frame, creates gradual acceleration, realistic for sustained pushes. **Common uses:** Wind pushing objects, rocket thrust, magnets, conveyor belts. _CSTA: 2-AP-13._

Dependencies:
* T17.G6.01.01: Apply impulses to physics bodies



ID: T17.G6.01.03
Topic: T17 – 3D Worlds & Games
Skill: Set physics body velocity directly
Description: Students use the `set physics body speed in xyz` block to set an object's velocity directly, useful for precise movement control in physics simulations. **When to use:** When you want exact velocity rather than applying forces (character movement, respawning with specific speed, resetting motion). _CSTA: 2-AP-13._

Dependencies:
* T17.G6.01.02: Apply continuous forces to physics bodies



ID: T17.G6.01.04
Topic: T17 – 3D Worlds & Games
Skill: Set up collision groups for selective interaction
Description: Students use the `update collision group [GROUP] target groups [LIST]` block to assign physics bodies to groups and control which objects can collide with each other. **How it works:** Assign object to group (1-15), specify which groups it can collide with. **Uses:** Player bullets don't hit player, team-based collision (red team can't hit red team), one-way platforms. _CSTA: 2-AP-13._

Dependencies:
* T17.G6.01.03: Set physics body velocity directly



ID: T17.G6.01.05
Topic: T17 – 3D Worlds & Games
Skill: Lock physics body movement and rotation axes
Description: Students use the `lock physics body movement in X Y Z rotation around X Y Z` block to constrain movement or rotation on specific axes. **Common uses:** Lock Y rotation to keep characters upright, lock Z movement for 2D-style gameplay in 3D, lock X/Z movement for elevator. _CSTA: 2-AP-13._

Dependencies:
* T17.G6.01.04: Set up collision groups for selective interaction



ID: T17.G6.02.01
Topic: T17 – 3D Worlds & Games
Skill: Add virtual joystick controls
Description: Students use the `add [SIDE] joystick` block to add on-screen virtual joystick controls for mobile-friendly 3D navigation. **Sides:** Left or right side of screen. **Common pattern:** Left joystick for movement, right joystick for camera/aiming. _CSTA: 2-AP-16._

Dependencies:
* T17.G6.01.05: Lock physics body movement and rotation axes



ID: T17.G6.02.02
Topic: T17 – 3D Worlds & Games
Skill: Read joystick input values
Description: Students use the `joystick [PROPERTY]` block to read joystick X and Y values (-1 to 1), mapping them to player movement or camera control. **Values:** X = -1 (left), 0 (center), 1 (right); Y = -1 (down), 0 (center), 1 (up). **Common pattern:** Multiply joystick values by movement speed to get velocity. _CSTA: 2-AP-13._

Dependencies:
* T17.G6.02.01: Add virtual joystick controls



ID: T17.G6.03.01
Topic: T17 – 3D Worlds & Games
Skill: Enable shadows from lights
Description: Students use the `cast shadow from light named [NAME]` block to enable shadow generation from specific lights, creating depth and realism. **Performance note:** Shadows are computationally expensive—enable only on important lights (main directional/sun light). **Parameters:** Blur size (softer vs sharper shadows). _CSTA: 2-AP-15._

Dependencies:
* T17.G4.02.02: Add directional lighting for sunlight effect



ID: T17.G6.03.02
Topic: T17 – 3D Worlds & Games
Skill: Configure objects to receive shadows
Description: Students use the `receives shadow [TRUE/FALSE]` block to control which objects show shadows cast on them. **Performance optimization:** Disable shadow receiving on distant or unimportant objects to improve performance. _CSTA: 2-AP-15._

Dependencies:
* T17.G6.03.01: Enable shadows from lights



ID: T17.G6.04.01
Topic: T17 – 3D Worlds & Games
Skill: Create glow layers for luminous effects
Description: Students use the `create glow layer intensity blur` block to set up glow effects, then add objects to the glow layer so they appear to emit light. **How it works:** Objects in glow layer create bloom/halo effect. **Uses:** Magical items, lasers, neon signs, power-ups. _CSTA: 2-AP-15._

Dependencies:
* T17.G6.03.02: Configure objects to receive shadows



ID: T17.G6.04.02
Topic: T17 – 3D Worlds & Games
Skill: Create highlight layers for object emphasis
Description: Students use the `create highlight layer color blur` block to create outline effects that make selected objects stand out (outline in glowing color). **Uses:** Show interactable objects, highlight objectives, indicate selection, show damage/power-up state. _CSTA: 2-AP-15._

Dependencies:
* T17.G6.04.01: Create glow layers for luminous effects



ID: T17.G6.05.01
Topic: T17 – 3D Worlds & Games
Skill: Add speech bubbles to 3D characters
Description: Students use the `show speech bubble [TEXT] offset xyz` block to display dialog or thoughts above 3D characters. **Parameters:** Text content, offset (position relative to character). **Uses:** NPC dialog, tutorial instructions, character thoughts, hints. _CSTA: 2-AP-16._

Dependencies:
* T17.G6.04.02: Create highlight layers for object emphasis



ID: T17.G6.06.01
Topic: T17 – 3D Worlds & Games
Skill: Enable mouse picking on 3D objects
Description: Students use the `turn on picking with [BUTTON]` block to enable click detection on 3D objects. **How it works:** After enabling picking, clicking on 3D objects triggers pick events. **Button options:** Left click, right click, or both. _CSTA: 2-AP-10._

Dependencies:
* T17.G6.05.01: Add speech bubbles to 3D characters



ID: T17.G6.06.02
Topic: T17 – 3D Worlds & Games
Skill: Get picked object information
Description: Students use `picked object name`, `picked point x/y/z` reporter blocks to determine which object was clicked and where on the object. **What you get:** Object name (which object), pick point coordinates (exact location on object surface). **Uses:** Identify clicked object, spawn effects at click point. _CSTA: 2-AP-13._

Dependencies:
* T17.G6.06.01: Enable mouse picking on 3D objects



ID: T17.G6.06.03
Topic: T17 – 3D Worlds & Games
Skill: Respond to object picking events
Description: Students use the `when an object from this sprite is picked` event to handle clicks on 3D objects, triggering game actions or UI responses. **Common pattern:** When object picked → check which object (picked object name) → execute appropriate action (show info, collect, activate). _CSTA: 2-AP-12._

Dependencies:
* T17.G6.06.02: Get picked object information



ID: T17.G6.07
Topic: T17 – 3D Worlds & Games
Skill: Debug physics collision issues systematically
Description: Students diagnose why physics collisions are not working as expected (e.g., objects passing through each other, unexpected bouncing, no collision detection) by checking: (1) Do both objects have physics bodies? (2) Are collision groups configured correctly? (3) Are bodies frozen? (4) Are masses appropriate? They use a systematic debugging checklist and console logging to identify problems. _CSTA: 2-AP-17._

Dependencies:
* T17.G6.01.04: Set up collision groups for selective interaction
* T17.G5.07: Predict physics behavior before running simulation



ID: T17.G6.08
Topic: T17 – 3D Worlds & Games
Skill: Design responsive player movement controls for 3D space
Description: Students implement a player control scheme that feels responsive and intuitive, choosing between: (1) Direct velocity control (set speed directly—instant response but less realistic), (2) Force-based movement (apply forces—realistic physics but slower response), or (3) Impulse-based (impulse when key pressed—jump-like feel). They test and justify their choice based on game feel requirements and player feedback. _CSTA: 2-AP-18._

Dependencies:
* T17.G6.02.02: Read joystick input values
* T17.G6.01.03: Set physics body velocity directly



ID: T17.G6.09
Topic: T17 – 3D Worlds & Games
Skill: Build a physics-based puzzle or game
Description: Students create a complete physics-based experience (e.g., ball maze—tilt platform to roll ball to goal, stacking game—stack blocks without falling, physics puzzle—use physics to reach goal) combining physics bodies, collision detection, scoring, and win/lose conditions. **Requirements:** Clear objective, physics-based mechanics (not just scripted movement), win condition, lose condition (optional), score/feedback. _CSTA: 2-AP-16._

Dependencies:
* T17.G6.07: Debug physics collision issues systematically
* T17.G6.08: Design responsive player movement controls for 3D space
* T17.G5.08: Design collectible placement for balanced gameplay



ID: T17.G6.10
Topic: T17 – 3D Worlds & Games
Skill: Use debugging tools to inspect 3D object state
Description: Students use the browser's developer console and the `show inspector [Yes]` block to debug 3D scenes by inspecting live object properties (position, rotation, physics state, material properties). **Debug workflow:** Add console logging → enable inspector → run project → examine object hierarchy → identify unexpected values → trace cause → fix code. **Key inspections:** Check if objects exist, verify positions, confirm physics body attachment. _CSTA: 3A-AP-23._

Dependencies:
* T17.G6.07: Debug physics collision issues systematically
* T17.G3.11: Read 3D object property values



ID: T17.G6.11
Topic: T17 – 3D Worlds & Games
Skill: Debug camera and view frustum issues
Description: Students diagnose why objects don't appear in camera view using systematic troubleshooting. **Debug checklist:** (1) Is object outside camera's visible range (too far/too near)? (2) Is camera target pointing in wrong direction? (3) Are camera distance limits (min/max radius) preventing correct view? (4) Is object behind the camera? (5) Is object hidden or transparent? Students adjust camera parameters methodically to bring objects into view. _CSTA: 2-AP-17._

Dependencies:
* T17.G6.10: Use debugging tools to inspect 3D object state
* T17.G4.03.04: Configure camera distance limits



ID: T17.G6.12
Topic: T17 – 3D Worlds & Games
Skill: Use distance sensors for obstacle detection
Description: Students use the `distance sensor [DIRECTION] max [DISTANCE]` block to detect nearby obstacles in 6 directions (front, back, left, right, up, down). **How sensors work:** Returns distance to nearest object in that direction, or max if nothing found. **Common uses:** Wall detection for AI, platform edge detection, proximity warnings. **Pattern:** Forever loop → check distances → adjust behavior based on proximity. _CSTA: 2-AP-13._

Dependencies:
* T17.G5.12: Use raycast to detect objects in a direction
* T17.G6.01.05: Lock physics body movement and rotation axes



ID: T17.G6.13
Topic: T17 – 3D Worlds & Games
Skill: Implement wall avoidance using distance sensors
Description: Students create AI or player behavior that detects and avoids walls using distance sensors. **Algorithm:** Check front sensor → if distance < threshold → turn away from wall → continue moving. **Extension:** Use multiple sensors (front-left, front-right) to choose turn direction. **Debug tip:** Display sensor values to understand what AI sees. _CSTA: 2-AP-12._

Dependencies:
* T17.G6.12: Use distance sensors for obstacle detection
* T17.G6.08: Design responsive player movement controls for 3D space



ID: T17.G6.14
Topic: T17 – 3D Worlds & Games
Skill: Implement state-based game logic
Description: Students use variables to track game states (playing, paused, game-over, victory) and conditionals to execute different behavior in each state. **State pattern:** Variable stores current state → Forever loop checks state → Executes appropriate behavior. **State transitions:** Define what causes state changes (player dies → game-over, all coins collected → victory). **Benefits:** Organized code, predictable behavior, easier debugging. _CSTA: 2-AP-12._

Dependencies:
* T17.G6.09: Build a physics-based puzzle or game
* T09.G5.01: Use variables to track changing state



ID: T17.G6.15
Topic: T17 – 3D Worlds & Games
Skill: Design a 3D platformer level
Description: Students design and implement a complete 3D platformer level with: (1) Platform layout with varying heights and gaps, (2) Player physics with jumping and gravity, (3) Ground detection for proper jump control, (4) Collectibles and hazards, (5) Start and end points. Students document design decisions and playtest for difficulty. _CSTA: 2-AP-16._

Dependencies:
* T17.G6.13: Implement wall avoidance using distance sensors
* T17.G5.13: Implement ground detection with raycast
* T17.G5.14: Design a 3D collectible hunt game



## GRADE 7 (32 skills - Advanced geometry, optimization, and AI foundations)

ID: T17.G7.01.01
Topic: T17 – 3D Worlds & Games
Skill: Create extruded 3D shapes from 2D vertex lists
Description: Students use the `add column [COLOR] 2D vertex list height` block to extrude 2D polygon outlines into 3D shapes, making custom pillars, buildings, or unique geometry. **How it works:** Provide list of 2D points (x,z coordinates) defining base shape, specify extrusion height. **Uses:** Custom building footprints, irregular pillars, logo extrusions. _CSTA: 3A-AP-13._

Dependencies:
* T17.G6.06.03: Respond to object picking events



ID: T17.G7.01.02
Topic: T17 – 3D Worlds & Games
Skill: Create flat 3D text objects
Description: Students use the `add 3D text [TEXT] font color width height` block to create flat text labels, signs, or titles in the 3D world. **Parameters:** Text content, font, color, width (horizontal size), height (vertical size), camera facing (always faces camera or fixed orientation). **Uses:** Signs, labels, floating UI elements. _CSTA: 2-AP-16._

Dependencies:
* T17.G7.01.01: Create extruded 3D shapes from 2D vertex lists



ID: T17.G7.01.03
Topic: T17 – 3D Worlds & Games
Skill: Create thick 3D text objects
Description: Students use the `add 3D thick text [TEXT] font color width height thickness` block to create extruded text with depth for more prominent signs or logo effects. **Difference from flat text:** Adds depth/thickness parameter, creates solid 3D letters. **Uses:** Logos, prominent signs, 3D titles. _CSTA: 2-AP-16._

Dependencies:
* T17.G7.01.02: Create flat 3D text objects



ID: T17.G7.01.04
Topic: T17 – 3D Worlds & Games
Skill: Add cone shapes from vertex lists
Description: Students use the `add cone [COLOR] vertex list height` block to create cone shapes from 2D base outlines, useful for roofs, towers, or projectile tips. **How it works:** Base defined by 2D vertex list, tip at specified height above base center. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.01.03: Create thick 3D text objects



ID: T17.G7.01.05
Topic: T17 – 3D Worlds & Games
Skill: Add tube shapes to the 3D scene
Description: Students use the `add tube [COLOR] diameter-top diameter-bottom height arc sides thickness` block to create hollow tubes for pipes, tunnels, or architectural elements. **Parameters:** Top/bottom diameters (different = tapered), arc (full circle = 360°, half = 180°), thickness (wall thickness). _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.01.04: Add cone shapes from vertex lists



ID: T17.G7.01.06
Topic: T17 – 3D Worlds & Games
Skill: Add rectangle tube shapes
Description: Students use the `add rectangle tube [COLOR] size-X size-Y height thickness` block to create hollow rectangular tubes for ducts, channels, or frames. **Uses:** Rectangular pipes, architectural frames, ductwork. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.01.05: Add tube shapes to the 3D scene



ID: T17.G7.01.07
Topic: T17 – 3D Worlds & Games
Skill: Add stair shapes to the 3D scene
Description: Students use the `add stairs [COLOR] width depth height step-count` block to create staircase structures for platformers or architectural scenes. **Parameters:** Width (how wide), depth (how deep each step), height (total rise), step count (number of steps). _CSTA: 2-AP-16._

Dependencies:
* T17.G7.01.06: Add rectangle tube shapes



ID: T17.G7.02.01
Topic: T17 – 3D Worlds & Games
Skill: Copy objects using grid matrix patterns
Description: Students use the `copy by matrix count-x count-y count-z spacing-x spacing-y spacing-z` block to efficiently duplicate objects in 3D arrays without manual loops. **Uses:** Create forests (grid of trees), building blocks, fences, arrays of collectibles. **How it works:** Copies selected object in 3D grid pattern with specified spacing. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.01.07: Add stair shapes to the 3D scene



ID: T17.G7.02.02
Topic: T17 – 3D Worlds & Games
Skill: Copy objects using mirror symmetry
Description: Students use the `copy to mirror position [PLANE]` block to create symmetrical designs across planes (XY, XZ, YZ). **Uses:** Symmetrical buildings, vehicles (left/right mirror), decorative patterns. **How it works:** Creates mirrored copy across specified plane. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.02.01: Copy objects using grid matrix patterns



ID: T17.G7.02.03
Topic: T17 – 3D Worlds & Games
Skill: Copy objects using rotational symmetry
Description: Students use the `copy to rotated position around [AXIS] count degrees` block to duplicate objects in circular patterns (like petals, spokes, columns around a center). **Parameters:** Axis of rotation (X, Y, or Z), count (how many copies), degree step (angle between copies—360/count for even distribution). _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.02.02: Copy objects using mirror symmetry



ID: T17.G7.03.01
Topic: T17 – 3D Worlds & Games
Skill: Add distance constraints between physics bodies
Description: Students use the `add distance constraint between [BODY1] and [BODY2] distance` block to keep two physics bodies at a fixed or maximum distance, creating ropes, chains, or pendulums. **How it works:** Constraint maintains specified distance between bodies as they move. **Uses:** Ropes, chains, swinging objects, tethers. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.02.03: Copy objects using rotational symmetry



ID: T17.G7.03.02
Topic: T17 – 3D Worlds & Games
Skill: Add hinge constraints for rotating joints
Description: Students use the `add hinge constraint between [BODY1] and [BODY2] at point axis` block to create rotating joints like doors, gates, or mechanical arms that pivot around an axis. **Parameters:** Hinge point (where joint is), axis (which axis to rotate around). **Uses:** Doors, gates, swinging bridges, mechanical arms. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.03.01: Add distance constraints between physics bodies



ID: T17.G7.03.03
Topic: T17 – 3D Worlds & Games
Skill: Configure hinge constraint limits and motors
Description: Students use the `set limits for hinge constraint min max` to control how far hinges can rotate (door that only opens 90°) and `set motor for hinge constraint speed` to add motorized rotation (automatic opening door). **Limits:** Prevent over-rotation. **Motors:** Create automatic movement. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.03.02: Add hinge constraints for rotating joints



ID: T17.G7.03.04
Topic: T17 – 3D Worlds & Games
Skill: Add fixed constraints for rigid connections
Description: Students use the `add fixed constraint between [BODY1] and [BODY2]` block to weld physics bodies together rigidly, creating compound objects like connected train cars or attached weapons. **How it works:** Bodies locked together, move as single unit. **Uses:** Multi-part objects, attached weapons/tools. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.03.03: Configure hinge constraint limits and motors



ID: T17.G7.03.05
Topic: T17 – 3D Worlds & Games
Skill: Remove physics constraints
Description: Students use the `remove constraint named [NAME]` block to disconnect previously linked physics bodies, useful for detaching objects or breaking connections (breaking rope, opening lock, separating train cars). _CSTA: 2-AP-10._

Dependencies:
* T17.G7.03.04: Add fixed constraints for rigid connections



ID: T17.G7.04.01
Topic: T17 – 3D Worlds & Games
Skill: Move objects along their current direction
Description: Students use the `move [DISTANCE] along current direction in [T] seconds` block to move objects forward based on their facing direction, useful for projectiles or AI movement that should move "forward" relative to rotation. _CSTA: 2-AP-13._

Dependencies:
* T17.G7.03.05: Remove physics constraints



ID: T17.G7.04.02
Topic: T17 – 3D Worlds & Games
Skill: Point objects toward a target position
Description: Students use the `point to position xyz in [T] seconds` block to orient objects toward a target location, useful for NPCs looking at players or turrets aiming. **How it works:** Smoothly rotates object to face target position over specified time. _CSTA: 2-AP-13._

Dependencies:
* T17.G7.04.01: Move objects along their current direction



ID: T17.G7.05.01
Topic: T17 – 3D Worlds & Games
Skill: Merge multiple meshes into one
Description: Students use the `merge [OBJECT1] into [OBJECT2]` block to combine multiple 3D objects into a single mesh for optimization or to create complex shapes. **Benefits:** Better performance (one object instead of many), enable compound physics shapes. **Use case:** Merge building parts, combine decorative elements. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.04.02: Point objects toward a target position



ID: T17.G7.05.02
Topic: T17 – 3D Worlds & Games
Skill: Create compound physics bodies
Description: Students use the `add physics bodies into compound [NAME]` block to attach compound physics bodies to merged meshes for complex collision shapes like vehicles (multiple collision shapes for different parts). _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.05.01: Merge multiple meshes into one



ID: T17.G7.05.03
Topic: T17 – 3D Worlds & Games
Skill: Use carve operations for boolean geometry
Description: Students use the `carve [OBJECT1] with [OBJECT2]` block to subtract one mesh from another, creating windows, doorways, or hollowed objects (boolean subtraction). **How it works:** Object2's volume removed from Object1. **Uses:** Cut windows in walls, create tunnels, hollow out objects. _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.05.02: Create compound physics bodies



ID: T17.G7.06.01
Topic: T17 – 3D Worlds & Games
Skill: Animate camera position transitions
Description: Students use the `set camera distance v-angle h-angle target xyz in [T] seconds` block to choreograph smooth camera movements for cutscenes or transitions. **Parameters:** All camera parameters can be smoothly animated over time. **Uses:** Cinematic cutscenes, camera reveals, dramatic angles. _CSTA: 2-AP-16._

Dependencies:
* T17.G7.05.03: Use carve operations for boolean geometry



ID: T17.G7.06.02
Topic: T17 – 3D Worlds & Games
Skill: Add trails to moving objects
Description: Students use the `add trail color width segments` block to attach trail effects to moving objects, showing motion paths for projectiles, vehicles, or characters. **Parameters:** Color (trail color), width (trail thickness), segments (how many trail segments to track). _CSTA: 2-AP-16._

Dependencies:
* T17.G7.06.01: Animate camera position transitions



ID: T17.G7.06.03
Topic: T17 – 3D Worlds & Games
Skill: Create custom particle emitters
Description: Students use the `add particle emitter [CONFIG]` block to create custom particle systems with full control over appearance, movement, lifetime, and behavior. **Parameters:** Emission rate, particle lifetime, initial velocity, colors, sizes, textures. **Uses:** Custom effects beyond prebuilt options. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.06.02: Add trails to moving objects



ID: T17.G7.07
Topic: T17 – 3D Worlds & Games
Skill: Trace camera and object movement in complex scenes
Description: Students analyze a multi-object 3D animation sequence with camera transitions, predicting the visual result at each keyframe by mentally tracing: (1) Object positions and rotations through time, (2) Camera position and target, (3) What appears in frame at each moment. They document predictions then run to verify. _CSTA: 3A-AP-23._

Dependencies:
* T17.G7.06.01: Animate camera position transitions
* T17.G7.04.02: Point objects toward a target position



ID: T17.G7.08
Topic: T17 – 3D Worlds & Games
Skill: Design level progression with increasing difficulty
Description: Students create a multi-level 3D game where each level introduces new challenges, obstacles, or mechanics progressively. They balance difficulty curves ensuring: (1) Early levels teach mechanics, (2) Mid levels challenge mastery, (3) Late levels require combining skills. They test with players and adjust pacing based on feedback. _CSTA: 3A-AP-18._

Dependencies:
* T17.G6.09: Build a physics-based puzzle or game
* T17.G7.02.01: Copy objects using grid matrix patterns



ID: T17.G7.09
Topic: T17 – 3D Worlds & Games
Skill: Generate procedural terrain with height variation
Description: Students use loops and random/noise functions to programmatically generate 3D terrain with varying heights, creating hills, valleys, or mountain ranges without manual object placement. **Algorithm pattern:** For each grid cell → calculate height from random/noise function → create box/plane at height. **Concepts:** Procedural generation creates variety algorithmically, ensuring each run produces unique-but-reasonable results. Students understand parameters that control terrain roughness and elevation range. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.02.01: Copy objects using grid matrix patterns
* T07.G6.01: Use nested loops for 2D grid processing



ID: T17.G7.10
Topic: T17 – 3D Worlds & Games
Skill: Identify and apply 3D game design patterns
Description: Students analyze existing 3D games and identify recurring architecture patterns: (1) **Player controller pattern:** Input → physics response → animation sync; (2) **Collectible pattern:** Collision detection → score update → object removal; (3) **Enemy AI pattern:** Detect player → navigate toward → attack; (4) **Follow camera pattern:** Track target → smooth interpolation → collision avoidance. Students apply identified patterns to structure their own projects, explaining why each pattern improves code organization and maintainability. _CSTA: 3A-AP-17._

Dependencies:
* T17.G6.09: Build a physics-based puzzle or game
* T17.G7.08: Design level progression with increasing difficulty



ID: T17.G7.11
Topic: T17 – 3D Worlds & Games
Skill: Implement object pooling for performance
Description: Students implement object pooling to reuse objects instead of creating/destroying them (for bullets, particles, collectibles). **Why pooling matters:** Creating/destroying objects is slow; reusing is fast. **Pattern:** (1) Create pool of inactive objects at start, (2) When need object, activate from pool, (3) When done, deactivate and return to pool. **Implementation:** Use visibility or position to "activate/deactivate" (move offscreen or hide). Students measure performance improvement before/after pooling. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.02.01: Copy objects using grid matrix patterns
* T17.G7.10: Identify and apply 3D game design patterns



ID: T17.G7.12
Topic: T17 – 3D Worlds & Games
Skill: Implement simple pathfinding for AI
Description: Students implement basic AI pathfinding using waypoints. **Waypoint system:** Place invisible markers along desired path → AI moves toward nearest waypoint → when reached, target next waypoint. **Algorithm:** Calculate distance to each waypoint → move toward closest unvisited → mark as visited → repeat. **Limitations:** Waypoints must be manually placed; works for simple paths. **Extension:** Combine with distance sensors for obstacle avoidance. _CSTA: 3A-AP-13._

Dependencies:
* T17.G6.13: Implement wall avoidance using distance sensors
* T17.G7.04.02: Point objects toward a target position



ID: T17.G7.13
Topic: T17 – 3D Worlds & Games
Skill: Implement level-of-detail (LOD) for distant objects
Description: Students implement LOD systems where distant objects use simpler representations. **LOD concept:** Close objects = high detail, distant objects = low detail or hidden. **Implementation:** Forever loop → calculate distance from camera → if far, hide or simplify object → if close, show full detail. **Common simplifications:** Remove physics, swap high-poly model for box, hide entirely. Students explain performance vs. visual quality trade-offs. _CSTA: 3A-AP-17._

Dependencies:
* T17.G7.11: Implement object pooling for performance
* T17.G4.06: Calculate distance between 3D objects



ID: T17.G7.14
Topic: T17 – 3D Worlds & Games
Skill: Design a complete 3D adventure game
Description: Students design and implement a 3D adventure game with multiple interconnected systems: (1) Player movement with physics, (2) Multiple levels/areas, (3) Collectibles and scoring, (4) At least one enemy or hazard with basic AI, (5) State management (playing, game-over, victory), (6) Visual feedback (particles, effects). Students document architecture, justify design decisions, and playtest for balance. _CSTA: 3A-AP-18._

Dependencies:
* T17.G7.08: Design level progression with increasing difficulty
* T17.G7.12: Implement simple pathfinding for AI
* T17.G6.14: Implement state-based game logic



## GRADE 8 (32 skills - Professional techniques, multiplayer, and AI integration)

ID: T17.G8.01.01
Topic: T17 – 3D Worlds & Games
Skill: Enable car physics simulation
Description: Students use the `enable car simulation mass restitution friction tire-friction suspension` block to enable car physics on a vehicle model. **Parameters:** Mass (vehicle weight), restitution (bounciness), friction (body friction), tire friction (grip), suspension (spring stiffness). _CSTA: 3A-AP-13._

Dependencies:
* T17.G7.06.03: Create custom particle emitters
* T08.G6.01: Use conditionals in physics simulations



ID: T17.G8.01.02
Topic: T17 – 3D Worlds & Games
Skill: Control car engine and brakes
Description: Students use the `set car engine force [FORCE] brake [LEVEL]` block to control acceleration and braking of physics-enabled vehicles. **Engine force:** Positive = accelerate, 0 = coast, negative = reverse. **Brake level:** 0 = no brakes, 1 = full brakes. _CSTA: 3A-AP-13._

Dependencies:
* T17.G8.01.01: Enable car physics simulation



ID: T17.G8.01.03
Topic: T17 – 3D Worlds & Games
Skill: Steer car to an angle
Description: Students use the `steer car to angle [DEGREES]` block to control wheel steering angle for turning physics-enabled vehicles. **Angle:** 0 = straight, positive = turn right, negative = turn left. **Typical range:** -30 to 30 degrees. _CSTA: 3A-AP-13._

Dependencies:
* T17.G8.01.02: Control car engine and brakes



ID: T17.G8.02.01
Topic: T17 – 3D Worlds & Games
Skill: Set up multiple camera display regions
Description: Students use the `set display region bottom-left width height border` block to create split-screen views or picture-in-picture displays for multiple camera feeds (two-player split-screen, rear-view mirrors, mini-map cameras). **Parameters:** Position (where region appears), size (region dimensions), border (frame visibility). _CSTA: 3A-AP-17._

Dependencies:
* T17.G8.01.03: Steer car to an angle



ID: T17.G8.02.02
Topic: T17 – 3D Worlds & Games
Skill: Add skybox textures to scenes
Description: Students use the `set sky [SKYTYPE]` block to add skybox textures for 360-degree background environments (space, mountains, city skylines, fantasy worlds). **What skyboxes are:** Cube-mapped textures creating illusion of distant environment. **Available options:** Various preset skyboxes from library. _CSTA: 2-AP-15._

Dependencies:
* T17.G8.02.01: Set up multiple camera display regions



ID: T17.G8.02.03
Topic: T17 – 3D Worlds & Games
Skill: Add post-processing pipeline effects
Description: Students use the `add pipeline vignette bloom antialiasing sharpening contrast exposure` block to enhance visual quality with post-processing effects. **Effects:** Vignette (darkened edges), bloom (glow on bright areas), antialiasing (smooth edges), sharpening (detail enhancement), contrast (light/dark separation), exposure (overall brightness). _CSTA: 3A-AP-17._

Dependencies:
* T17.G8.02.02: Add skybox textures to scenes
* T03.G6.01: Propose a module hierarchy for a medium project



ID: T17.G8.03.01
Topic: T17 – 3D Worlds & Games
Skill: Export 3D models as GLB files
Description: Students use the `export object [NAME] as GLB file` block to save created 3D geometry for use in other applications or sharing. **GLB format:** Standard 3D model format supported by many applications (Blender, Unity, web viewers). **Uses:** Share creations, use in other software, 3D printing preparation. _CSTA: 3A-AP-21._

Dependencies:
* T17.G8.02.03: Add post-processing pipeline effects



ID: T17.G8.03.02
Topic: T17 – 3D Worlds & Games
Skill: Export 3D models as STL files for 3D printing
Description: Students use the `export object [NAME] as STL file` block to export 3D geometry suitable for 3D printing, bridging digital creation with physical fabrication. **STL format:** Standard for 3D printing. **Preparation needed:** Ensure mesh is closed (no holes), appropriate scale, manifold geometry. _CSTA: 3A-AP-21._

Dependencies:
* T17.G8.03.01: Export 3D models as GLB files



ID: T17.G8.04.01
Topic: T17 – 3D Worlds & Games
Skill: Enable AR world camera mode
Description: Students use the `switch to AR world camera` block to enable augmented reality, placing 3D objects in real-world environments using the device camera. **How it works:** Device camera becomes background, 3D objects appear anchored in real world. **Uses:** AR games, educational AR visualizations, virtual furniture placement. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.03.02: Export 3D models as STL files for 3D printing



ID: T17.G8.04.02
Topic: T17 – 3D Worlds & Games
Skill: Enable AR face tracking mode
Description: Students use the `switch to AR face camera` block to enable face tracking that can attach 3D objects to detected faces for filters or effects. **How it works:** Detects face landmarks, tracks face movement, anchors objects to face position. **Uses:** Face filters, virtual makeup, educational face anatomy. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.04.01: Enable AR world camera mode



ID: T17.G8.04.03
Topic: T17 – 3D Worlds & Games
Skill: Enable AR image/logo tracking mode
Description: Students use the `switch to AR image tracking` block to display 3D content when specific images or logos are detected by the camera. **How it works:** Upload target image, camera detects image, 3D content appears anchored to image. **Uses:** Interactive posters, educational cards, marketing AR. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.04.02: Enable AR face tracking mode



ID: T17.G8.05.01
Topic: T17 – 3D Worlds & Games
Skill: Build mirrors for reflective surfaces
Description: Students use the `build mirror brightness using object [NAME]` block to create reflective surfaces showing other objects, useful for water, windows, or polished floors. **Parameters:** Brightness (reflection intensity), object (which object becomes mirror surface). _CSTA: 3A-AP-17._

Dependencies:
* T17.G8.04.03: Enable AR image/logo tracking mode



ID: T17.G8.05.02
Topic: T17 – 3D Worlds & Games
Skill: Create geometry points in 3D space
Description: Students use the `geometry: add point at xyz color size` block to define vertices in 3D space as the foundation for custom procedural geometry. **Uses:** Building custom meshes from scratch, visualizing data points, creating custom shapes. _CSTA: 3A-AP-13._

Dependencies:
* T17.G8.05.01: Build mirrors for reflective surfaces



ID: T17.G8.05.03
Topic: T17 – 3D Worlds & Games
Skill: Create geometry lines between points
Description: Students use the `geometry: add line between points` block to create line segments between defined points for wireframe or structural visualization. **Uses:** Visualize connections, create wireframe models, show relationships between data points. _CSTA: 3A-AP-13._

Dependencies:
* T17.G8.05.02: Create geometry points in 3D space



ID: T17.G8.05.04
Topic: T17 – 3D Worlds & Games
Skill: Create geometry triangles from points
Description: Students use the `geometry: add triangle from points color` block to create triangular faces from three points, building custom meshes from vertices programmatically. **How it works:** Three points define triangle, normal direction determines which side is visible. **Uses:** Procedural mesh generation, terrain, custom models. _CSTA: 3A-AP-13._

Dependencies:
* T17.G8.05.03: Create geometry lines between points



ID: T17.G8.06.01
Topic: T17 – 3D Worlds & Games
Skill: Analyze and optimize 3D scene performance
Description: Students profile a sluggish 3D project using browser performance tools (Chrome DevTools Performance tab, FPS counter) and the Babylon inspector to identify bottlenecks. **Common bottlenecks:** Too many draw calls (too many objects), excessive physics bodies, inefficient loops, large textures, many lights with shadows. **Optimization techniques:** Object pooling (reuse instead of create/delete), frustum culling (remove off-screen objects), mesh merging, texture atlasing, LOD (level of detail), shadow optimization. Students measure frame rate before/after optimizations to quantify improvement. _CSTA: 3B-AP-11._

Dependencies:
* T17.G8.05.04: Create geometry triangles from points
* T12.G6.01: Trace complex code with multiple variables



ID: T17.G8.06.02
Topic: T17 – 3D Worlds & Games
Skill: Analyze trade-offs in 3D design decisions
Description: Students review a completed 3D project and explain design choices with justifications: (1) Physics vs manual motion (realism vs control), (2) Camera placement (gameplay clarity vs cinematic feel), (3) Effect usage (visual appeal vs performance), (4) Lighting approach (realism vs performance). They cite pros and cons relative to project requirements and constraints. _CSTA: 3B-AP-22._

Dependencies:
* T17.G8.06.01: Analyze and optimize 3D scene performance
* T03.G6.01: Propose a module hierarchy for a medium project



ID: T17.G8.07
Topic: T17 – 3D Worlds & Games
Skill: Design and document a 3D game architecture
Description: Students plan a complex 3D game by creating a comprehensive design document outlining: (1) **Game mechanics:** Core gameplay loop, controls, win/lose conditions; (2) **Level structure:** How levels progress, difficulty curve, unlock conditions; (3) **Object hierarchy:** What objects exist, parent-child relationships, how they interact; (4) **Physics requirements:** What uses physics, collision groups, mass/friction values; (5) **Visual effects:** Particles, lighting scheme, post-processing effects; (6) **Control schemes:** Keyboard/joystick mapping, touch controls; (7) **Performance plan:** Anticipated bottlenecks and mitigation strategies (object budgets, LOD plans, optimization checkpoints). Students justify technical choices, estimate complexity, and identify potential challenges with contingency plans. _CSTA: 3B-AP-14._

Dependencies:
* T17.G8.06.02: Analyze trade-offs in 3D design decisions
* T17.G7.08: Design level progression with increasing difficulty



ID: T17.G8.08
Topic: T17 – 3D Worlds & Games
Skill: Integrate AI behaviors with 3D game mechanics
Description: Students combine AI-driven behaviors (pathfinding, decision-making, state machines, targeting) with 3D physics and animation to create intelligent NPCs or enemies that respond dynamically to player actions in 3D space. **Requirements:** AI selects targets in 3D, navigates around obstacles, responds to player position, uses appropriate animations, interacts with physics (avoids falling, responds to collisions). _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.01.03: Steer car to an angle
* T17.G7.04.02: Point objects toward a target position



ID: T17.G8.09
Topic: T17 – 3D Worlds & Games
Skill: Build a complete 3D game with physics, effects, and UI
Description: Students create a polished 3D game integrating multiple systems: (1) 3D scene with environment, lighting, and effects (fog, particles, shadows), (2) Physics-based gameplay (player physics, collisions, physics puzzles), (3) Player controls (responsive input, camera control), (4) Scoring/UI (HUD, menus, feedback), (5) Multiple levels or progressive difficulty, (6) Visual and audio feedback (effects, sounds). **This is the capstone skill demonstrating mastery of 3D game development.** _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.07: Design and document a 3D game architecture
* T17.G8.04.01: Enable AR world camera mode
* T17.G8.02.03: Add post-processing pipeline effects



ID: T17.G8.10
Topic: T17 – 3D Worlds & Games
Skill: Design procedural content generation systems
Description: Students design and implement algorithmic systems that generate game content dynamically: (1) **Random level layouts:** Procedural room/corridor generation with connectivity rules; (2) **Procedural enemy/collectible placement:** Algorithms that distribute items based on difficulty and progression rules; (3) **Algorithmic terrain:** Height maps, biome distribution, resource placement. **Design requirements:** Define generation parameters, implement generation algorithm with constraints, ensure output variety while maintaining playability, add seed control for reproducibility. Students explain how randomness and rules combine to create engaging procedural content. _CSTA: 3B-AP-14._

Dependencies:
* T17.G7.09: Generate procedural terrain with height variation
* T17.G8.07: Design and document a 3D game architecture



ID: T17.G8.11
Topic: T17 – 3D Worlds & Games
Skill: Synchronize 3D objects across multiplayer sessions
Description: Students implement basic multiplayer synchronization for 3D games using CreatiCode's multiplayer blocks. **Key challenges:** Position updates (smooth interpolation vs exact sync), ownership (who controls each object), latency handling (predict vs wait). **Implementation:** (1) Host creates game room, (2) Players join and receive initial state, (3) Player positions broadcast continuously, (4) Objects sync on collision/interaction. Students test with simulated network delay and discuss trade-offs between responsiveness and accuracy. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.09: Build a complete 3D game with physics, effects, and UI
* T18.G6.01: Create a new online game room



ID: T17.G8.12
Topic: T17 – 3D Worlds & Games
Skill: Design split-screen local multiplayer
Description: Students implement local split-screen multiplayer using multiple camera display regions. **Implementation:** (1) Create two cameras with different targets (player 1 and player 2), (2) Set display regions for each camera (left half, right half), (3) Separate input handling for each player (WASD vs arrows, or two joysticks). Students handle challenges like viewport aspect ratios and consistent physics across both views. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.02.01: Set up multiple camera display regions
* T17.G8.01.03: Steer car to an angle



ID: T17.G8.13
Topic: T17 – 3D Worlds & Games
Skill: Implement AI NPC with state machine behavior
Description: Students create NPCs with complex behavior using state machines: (1) **Patrol state:** Move between waypoints; (2) **Alert state:** Detected player, investigate; (3) **Chase state:** Pursue player; (4) **Attack state:** Close enough to attack; (5) **Return state:** Lost player, return to patrol. **Transitions:** Define what triggers each state change (distance thresholds, line-of-sight, timers). Students implement at least 4 states with clear transitions and debug by visualizing current state. _CSTA: 3B-AP-14._

Dependencies:
* T17.G7.12: Implement simple pathfinding for AI
* T17.G8.08: Integrate AI behaviors with 3D game mechanics
* T17.G6.14: Implement state-based game logic



ID: T17.G8.14
Topic: T17 – 3D Worlds & Games
Skill: Use ChatGPT to generate dynamic 3D game content
Description: Students integrate ChatGPT with 3D games to generate dynamic content: (1) NPC dialog that responds contextually to player actions, (2) Procedural quest/objective generation based on current game state, (3) Hint systems that analyze player behavior and provide appropriate guidance. **Implementation:** Send game context to ChatGPT → parse response → update game accordingly. Students design prompts that produce consistent, appropriate responses and handle edge cases gracefully. _CSTA: 3B-AP-16._

Dependencies:
* T17.G8.08: Integrate AI behaviors with 3D game mechanics
* T26.G7.01: Build a chatbot using the ChatGPT block



ID: T17.G8.15
Topic: T17 – 3D Worlds & Games
Skill: Build a professional-quality 3D game portfolio piece
Description: Students create a polished, portfolio-ready 3D game demonstrating mastery of multiple systems: (1) Complete gameplay loop with clear objectives, (2) Professional-quality visuals (lighting, effects, materials), (3) Optimized performance (object pooling, LOD, efficient physics), (4) Clean code architecture (state machines, design patterns), (5) User interface (menus, HUD, feedback), (6) Documentation (README, design decisions, known issues). Students present their work explaining technical challenges overcome and design decisions made. **This is the capstone skill demonstrating professional-level 3D game development capability.** _CSTA: 3B-AP-24._

Dependencies:
* T17.G8.09: Build a complete 3D game with physics, effects, and UI
* T17.G8.10: Design procedural content generation systems
* T17.G7.14: Design a complete 3D adventure game



ID: T18.GK.01
Topic: T18 – Multiplayer Apps
Skill: Sort pictures of playing alone versus playing together
Description: Students view picture cards showing children in different play scenarios: one child reading a book alone, two children building blocks together, one child on a swing alone, four children playing soccer together. They drag each picture into "playing alone" or "playing together" piles. They tap to highlight pictures where players must communicate. Large tap targets and high-contrast visuals support accessibility. This establishes the foundational distinction between single-player and multiplayer experiences through visual sorting.

Dependencies:
None (foundational)





ID: T18.GK.02
Topic: T18 – Multiplayer Apps
Skill: Sequence picture cards showing turn-taking in games
Description: Students view a picture sequence showing children playing a board game: (1) first child rolls dice, (2) second child waits, (3) first child moves piece, (4) second child's turn begins. They drag cards into correct order. They tap which picture shows "waiting for my turn" versus "taking my turn". They predict what happens next by selecting from picture options. Audio narration supports pre-readers. This introduces turn-based mechanics through picture sequencing, preparing for later understanding of game state management.

Dependencies:
* T18.GK.01: Sort pictures of playing alone versus playing together





ID: T18.GK.03
Topic: T18 – Multiplayer Apps
Skill: Sort pictures into "helping each other" versus "racing to win"
Description: Students view picture cards showing cooperative activities (two children carrying a heavy box together, group building a sandcastle, team passing a ball in a circle) and competitive activities (two children racing to finish line, playing tic-tac-toe, seeing who stacks higher). They drag each picture into "helping each other win" or "one person wins" piles. They tap which picture shows teamwork. They predict outcomes: "If they work together, what happens?" This establishes cooperative versus competitive multiplayer concepts through visual sorting.

Dependencies:
* T18.GK.02: Sequence picture cards showing turn-taking in games





ID: T18.GK.04
Topic: T18 – Multiplayer Apps
Skill: Match game rules to picture outcomes
Description: Students view simple game rules shown as picture cards (e.g., "take turns" shown as alternating arrows, "stay in bounds" shown as box with X inside, "share equally" shown as divided pie). They match each rule picture to outcome pictures showing what happens when the rule is followed (happy faces, fair sharing) versus broken (sad faces, arguing). They tap which rule fixes a problem scenario (e.g., two kids grabbing same toy → "take turns" rule). This introduces rule-based systems through picture matching.

Dependencies:
* T18.GK.03: Sort pictures into "helping each other" versus "racing to win"





ID: T18.GK.05
Topic: T18 – Multiplayer Apps
Skill: Predict what happens when players communicate or don't
Description: Students view picture pairs showing scenarios with and without communication: (1) Two children building blocks - one pair talking and pointing, one pair confused and bumping; (2) Relay race - one team passing baton smoothly with eye contact, one team dropping baton looking away. They tap which picture shows "talking helps" and predict outcomes. They select from picture options what happens when friends don't tell each other their plans. This introduces communication as essential for multiplayer success.

Dependencies:
* T18.GK.04: Match game rules to picture outcomes


ID: T18.G1.01
Topic: T18 – Multiplayer Apps
Skill: Sort tasks by "better alone" versus "better together"
Description: Students view picture cards showing different tasks: reading a book, carrying a heavy table, solving a puzzle, playing catch, coloring a picture, building a tall tower, playing hide-and-seek. They drag each into "easier alone" or "easier together" piles. They explain their sorting by selecting reasons from picture options (needs more hands, needs someone to throw to, can concentrate better alone). They identify one task that could go either way and explain why. This develops judgment about when multiplayer collaboration adds value.

Dependencies:
* T18.GK.05: Predict what happens when players communicate or don't





ID: T18.G1.02
Topic: T18 – Multiplayer Apps
Skill: Match message types to group activity needs
Description: Students view picture scenarios of group activities and match them to the type of message needed. Scenarios include: child stuck on puzzle (needs "help please" message), team ready to start race (needs "ready" signal), group finished building (needs "done" announcement), player doesn't know the rules (needs "how to play" question). They drag message picture cards to matching scenarios. They identify which messages help the whole group versus just one person. This introduces message types in multiplayer contexts through visual matching.

Dependencies:
* T18.G1.01: Sort tasks by "better alone" versus "better together"





ID: T18.G1.03
Topic: T18 – Multiplayer Apps
Skill: Sort pictures of fair versus unfair game starts
Description: Students view picture cards showing game starting conditions: both racers at same line (fair), one racer ahead (unfair), both players get 5 cards (fair), one player peeking at cards (unfair), both teams same size (fair), one team has more players (unfair). They drag pictures into "fair start" and "not fair start" piles. They tap to fix unfair pictures by selecting the correction (move racer back, give equal cards, balance teams). This introduces game balance concepts through visual sorting.

Dependencies:
* T18.GK.04: Match game rules to picture outcomes





ID: T18.G1.04
Topic: T18 – Multiplayer Apps
Skill: Predict how reactions affect wanting to play again
Description: Students view picture sequences showing game endings and player reactions: (1) Winner cheers, loser says "good game" → both smiling, playing again; (2) Winner brags, loser cries → loser walking away; (3) Both teams high-five → everyone excited for next round. They predict outcomes by tapping which picture shows "will play again" versus "won't want to play". They match reaction pictures (kind, mean) to outcome pictures (friends keep playing, friends stop playing). This establishes sportsmanship as essential for sustainable multiplayer experiences.

Dependencies:
* T18.G1.03: Sort pictures of fair versus unfair game starts





ID: T18.G1.05
Topic: T18 – Multiplayer Apps
Skill: Match player roles to team activity pictures
Description: Students view picture cards of team activities with different roles: soccer goalkeeper, soccer forward, soccer coach on sideline; orchestra conductor, violin player, drummer; relay race starter, middle runner, anchor runner. They match role labels (shown as icons and simple words) to the correct person in each picture. They identify what each role does and why teams need different roles. They tap which role is "most important" and discover all are needed. This introduces role differentiation in multiplayer contexts.

Dependencies:
* T18.G1.02: Match message types to group activity needs


ID: T18.G2.01
Topic: T18 – Multiplayer Apps
Skill: Design a cooperative challenge requiring two players
Description: Students use picture cards to design unplugged activities where two players must work together (both hold ends of jump rope, both carry a bucket together, one reads clues while other searches). They test designs by acting them out and checking: Can one person do it alone? (no = good cooperative design). They arrange picture cards showing their challenge steps and explain to a partner. They fix designs where one player could succeed alone. This introduces cooperative game design through hands-on creation.

Dependencies:
* T18.G1.02: Match message types to group activity needs





ID: T18.G2.02
Topic: T18 – Multiplayer Apps
Skill: Trace information flow between team members
Description: Students view picture diagrams showing how information travels in teams: scout sees obstacle → tells leader → leader tells team to go around; timer starts clock → calls "30 seconds left" → all players speed up. They trace arrows showing message paths. They predict what happens if one message is blocked (scout can't talk to leader). They arrange picture cards showing correct information flow order. This introduces message passing and synchronization concepts through visual tracing.

Dependencies:
* T18.G2.01: Design a cooperative challenge requiring two players





ID: T18.G2.03
Topic: T18 – Multiplayer Apps
Skill: Create and test fair rules for an invented game
Description: Students invent a simple 2-player game using available materials (cards, dice, tokens) and write 3-4 rules using picture cards and simple words. They playtest with a partner and check fairness: Did both players have equal chances? Was there a clear winner? Did arguments happen? They revise one rule to fix unfairness they discovered. They explain their rule change reasoning. This develops iterative game design and playtesting skills foundational for multiplayer development.

Dependencies:
* T18.G1.03: Sort pictures of fair versus unfair game starts
* T18.G1.04: Predict how reactions affect wanting to play again





ID: T18.G2.04
Topic: T18 – Multiplayer Apps
Skill: Predict problems when players go at different speeds
Description: Students view picture scenarios showing timing mismatches: one runner finishes while teammate still running, one player ready while partner still reading instructions, one team done while other team still playing. They predict problems from each scenario using picture options (runner gets bored, late player feels rushed, other team complains). They match "waiting" strategies to scenarios: help your partner, practice more, count together to start at same time. This introduces synchronization concepts where multiplayer games must handle players at different paces.

Dependencies:
* T18.G2.02: Trace information flow between team members





ID: T18.G2.05
Topic: T18 – Multiplayer Apps
Skill: Sort pictures of same-room versus far-away playing
Description: Students view picture cards showing different multiplayer scenarios: two children at same table playing board game, two children on same couch playing video game, one child at home and one at grandma's house video chatting while playing, children in different countries playing online game together. They drag pictures into "same place" and "different places" piles. They identify what's needed for far-away playing (internet, screen, connection) by tapping required items. This introduces the concept of networked multiplayer at a foundational level.

Dependencies:
* T18.G2.02: Trace information flow between team members


ID: T18.G3.01
Topic: T18 – Multiplayer Apps
Skill: Trace turn-based game logic with a variable
Description: Students trace through a simple turn-based game where a variable tracks whose turn it is (turn = 1 or turn = 2). Given 3-4 game steps, they predict the turn variable value after each action. They identify when Player 1 can act (when turn = 1) versus Player 2 (when turn = 2). They explain how the "set turn to" block switches between players after each move. They connect this to tic-tac-toe and checkers where wrong-turn moves are illegal. This introduces turn-based multiplayer mechanics through variable tracing.

Dependencies:
* T09.G3.01.01: Create a new variable with a descriptive name
* T18.G2.03: Create and test fair rules for an invented game





ID: T18.G3.02
Topic: T18 – Multiplayer Apps
Skill: Match keyboard keys to player controls in two-player games
Description: Students examine code snippets showing two-player games where Player 1 uses arrow keys and Player 2 uses WASD keys. They match key names (up arrow, W key) to player actions (Player 1 moves up, Player 2 moves up). They predict which sprite moves when pressing specific keys by tracing "when key pressed" blocks. They identify problems when both players use same keys (control conflicts). They explain why separate keys allow simultaneous play on one keyboard. This introduces input separation for local multiplayer.

Dependencies:
* T06.G3.01: Use events to start actions
* T18.G3.01: Trace turn-based game logic with a variable





ID: T18.G3.03
Topic: T18 – Multiplayer Apps
Skill: Trace separate score variables for two players
Description: Students trace through code using separate score variables (player1Score, player2Score). Given a game scenario with 4-5 scoring events, they predict each variable's value after each event. They identify which variable increases when "Player 1 collects coin" versus "Player 2 scores goal". They compare final scores and predict the winner. They explain why one shared "score" variable wouldn't work fairly. This introduces per-player state tracking essential for competitive multiplayer.

Dependencies:
* T09.G3.01.01: Create a new variable with a descriptive name
* T18.G3.02: Match keyboard keys to player controls in two-player games





ID: T18.G3.04
Topic: T18 – Multiplayer Apps
Skill: Diagram how the internet connects computers for games
Description: Students draw or arrange picture cards showing how online games work: Player 1's computer → internet (cloud icon) → game server → internet → Player 2's computer. They trace message paths: "When Player 1 presses jump, where does that message go?" They compare to local games (no internet needed, same computer). They identify what breaks if internet stops working (can't see other player, stuck waiting). This establishes networked systems understanding necessary for online multiplayer concepts.

Dependencies:
* T18.G2.05: Sort pictures of same-room versus far-away playing





ID: T18.G3.05
Topic: T18 – Multiplayer Apps
Skill: Compare local versus online multiplayer trade-offs
Description: Students create a comparison chart (using picture cards or simple writing) for local multiplayer (same keyboard, same screen, no internet, must be in same room) versus online multiplayer (separate computers, separate screens, needs internet, can be anywhere). They identify advantages of each: local (easier setup, no lag, more social), online (play with distant friends, own screen space, no travel). They predict which type works better for different scenarios (playing with sibling, playing with cousin in another city). This develops judgment for multiplayer type selection.

Dependencies:
* T18.G3.04: Diagram how the internet connects computers for games
* T18.G3.02: Match keyboard keys to player controls in two-player games





ID: T18.G3.06
Topic: T18 – Multiplayer Apps
Skill: Predict what needs to stay "the same" for fair online play
Description: Students identify what information must be identical across all players' screens for fair online games: player positions, scores, game timer, obstacle locations, power-up availability. They predict problems when information differs: "If Player 1 sees the coin at position A but Player 2 sees it at position B, what happens?" They categorize game elements into "must match" (shared state) versus "can be different" (local effects like sounds). This introduces synchronization requirements conceptually.

Dependencies:
* T18.G3.05: Compare local versus online multiplayer trade-offs


ID: T18.G4.01
Topic: T18 – Multiplayer Apps
Skill: Implement separate keyboard controls for two local players
Description: Students program a local two-player game where Player 1 uses arrow keys and Player 2 uses WASD keys. They create two sprites with separate "when key pressed" event handlers (when up arrow → Player 1 moves up, when W key → Player 2 moves up). They test with two people at the same keyboard to verify both players can move simultaneously without control conflicts. They debug issues where wrong player responds to keys. This implements input separation for local multiplayer.

Dependencies:
* T18.G3.02: Match keyboard keys to player controls in two-player games
* T06.G4.01: Use broadcast to coordinate sprite actions

ID: T18.G4.01.01
Topic: T18 – Multiplayer Apps
Skill: Implement turn-based gameplay with a turn variable
Description: Students create a turn-based game using a "turn" variable (1 or 2). They wrap each player's key handlers in conditionals: "if turn = 1" before Player 1's action. They switch turn after valid moves (set turn to 2 after Player 1 acts). They display current turn using a label widget ("Player 1's Turn"). They test to verify: Player 2's keys do nothing when turn = 1, and vice versa. This implements turn-based mechanics introduced conceptually in G3.

Dependencies:
* T18.G4.01: Implement separate keyboard controls for two local players
* T08.G4.03: Use conditionals with multiple outcomes

ID: T18.G4.01.02
Topic: T18 – Multiplayer Apps
Skill: Track and display separate scores for two players
Description: Students create two score variables (player1Score, player2Score) initialized to 0. They increment the correct variable when players accomplish objectives (change player1Score by 1 when Player 1 scores). They display both scores using label widgets positioned clearly ("P1: 5 | P2: 3"). They implement winner detection: "if player1Score > player2Score, broadcast player1wins". They test scoring accuracy by playing several rounds.

Dependencies:
* T18.G4.01: Implement separate keyboard controls for two local players
* T09.G3.01.01: Create a new variable with a descriptive name

ID: T18.G4.02
Topic: T18 – Multiplayer Apps
Skill: Build a complete local 2-player competitive game
Description: Students design and implement a complete competitive game (racing, collecting, battle arena) where two players compete using separate keyboard controls. They combine: (1) separate controls (arrows vs WASD), (2) separate score tracking, (3) clear win conditions, (4) broadcasts for game events (start, score, win). They playtest with a partner, identify balance issues (one player has advantage), and fix them. They document their game rules. This synthesizes local multiplayer skills into a complete playable experience.

Dependencies:
* T18.G4.01.01: Implement turn-based gameplay with a turn variable
* T18.G4.01.02: Track and display separate scores for two players
* T06.G4.01: Use broadcast to coordinate sprite actions





ID: T18.G4.03
Topic: T18 – Multiplayer Apps
Skill: Trace message flow in online multiplayer diagrams
Description: Students trace message flow diagrams showing online multiplayer communication: Player 1 presses key → message sent to server → server updates game state → server sends update to all players → all screens show new position. They identify the delay between action and display ("message travel time"). They predict what players see if messages are slow (old positions, jumping sprites). They compare to local multiplayer (instant response, no messages needed). This establishes conceptual foundation for networked multiplayer development.

Dependencies:
* T18.G3.05: Compare local versus online multiplayer trade-offs
* T18.G3.06: Predict what needs to stay "the same" for fair online play





ID: T18.G4.04
Topic: T18 – Multiplayer Apps
Skill: Categorize game data as "must sync" versus "local only"
Description: Students categorize game elements into two groups: "must synchronize" (player positions, scores, game timer, power-up locations, collision results) and "local only" (sound effects, visual effects, UI animations, input feedback). They justify each categorization: "Scores must sync because both players need to see the same winner." They predict problems from wrong categorization: "If we don't sync the timer, players might disagree when time's up." They create a sync checklist for their local 2-player game idea, identifying what would need syncing if it went online. This introduces synchronization decision-making.

Dependencies:
* T18.G4.03: Trace message flow in online multiplayer diagrams





ID: T18.G4.05
Topic: T18 – Multiplayer Apps
Skill: Diagram host and client roles in multiplayer games
Description: Students draw diagrams showing host-client architecture: one player (host) creates the game room and holds the "official" game state, other players (clients) connect to the host to join. They trace scenarios: "Both players think they got the coin first - who decides?" (the host). They compare to real-world examples: host of party sets rules, teacher in classroom is authority. They identify the problem when host leaves (game ends for everyone). This introduces client-server architecture foundational for CreatiCode multiplayer.

Dependencies:
* T18.G4.04: Categorize game data as "must sync" versus "local only"





ID: T18.G4.06
Topic: T18 – Multiplayer Apps
Skill: Evaluate game ideas for multiplayer suitability
Description: Students evaluate 5-6 game concepts and rate their multiplayer suitability: racing (excellent - competitive, simultaneous), story adventure (poor - single narrative), puzzle platformer (good - cooperative), fighting (excellent - competitive), hidden object (poor - individual focus), team sports (excellent - roles and coordination). They explain ratings based on: competitive potential, cooperation opportunities, simultaneous action, fairness achievability. They predict how adding multiplayer would change a single-player game concept. This develops critical thinking about when multiplayer adds value.

Dependencies:
* T18.G4.03: Trace message flow in online multiplayer diagrams
* T18.G4.02: Build a complete local 2-player competitive game





ID: T18.G5.01
Topic: T18 – Multiplayer Apps
Skill: Create a multiplayer game room using the create game block
Description: Students use the "create game" block from the Multiplayer extension to create a game room as host. They configure required parameters: game name (unique identifier like "myRace123"), password ("123" or empty for public), display name (how others see them), role (their team or character), server location (US-East, US-West, Europe, Asia), capacity (max players), and world dimensions. They verify creation using "connected to game" reporter. They understand they are now the host with authoritative game state. This establishes the foundational skill for networked multiplayer development.

Dependencies:
* T18.G4.05: Diagram host and client roles in multiplayer games
* T09.G3.01.01: Create a new variable with a descriptive name




ID: T18.G5.01.01
Topic: T18 – Multiplayer Apps
Skill: Configure game room capacity based on game design
Description: Students set appropriate capacity limits (2 for 1v1 games, 4 for small teams, 8 for larger battles) based on their game design. They test what happens when capacity is reached (new players cannot join, "game full" error). They explain trade-offs: small capacity = more intimate gameplay but limited audience; large capacity = more chaotic but more social. They configure world dimensions to match their game area and understand larger worlds spread players further apart.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block




ID: T18.G5.01.02
Topic: T18 – Multiplayer Apps
Skill: Set player display names and roles for gameplay
Description: Students configure display name (visible to other players, like "SpeedRunner42") and role (gameplay-relevant string like "red", "seeker", "builder") when creating or joining games. They test how display names appear to other players. They design meaningful role names for their game concept (hide-and-seek: "seeker" vs "hider"; team battle: "red" vs "blue"; class-based: "wizard" vs "warrior"). They verify roles appear correctly in player list table.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block





ID: T18.G5.02
Topic: T18 – Multiplayer Apps
Skill: Join an existing multiplayer game using the join game block
Description: Students use the "join game" block to connect to games created by others. They enter required parameters: game name (must match exactly), host name (display name of creator), server location (must match host's choice), password (if required), their display name, and their role. They verify successful connection using "connected to game" reporter. They test by opening two browser windows: one creates game, one joins. They debug common join failures (wrong game name, wrong server, wrong password). This completes the create/join cycle for testing.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block





ID: T18.G5.03
Topic: T18 – Multiplayer Apps
Skill: Register sprites with the multiplayer system using add sprite to game
Description: Students use "add sprite to game as Dynamic/Static Rectangle/Circle" block to register sprites so they appear on all players' screens. They configure mode: Dynamic (for moving objects like players, projectiles - positions sync continuously) or Static (for fixed objects like walls - no position sync needed). They choose collision shape: Rectangle (for box-shaped sprites) or Circle (for round sprites). They understand originals (on registering player's screen) versus replicates (automatically created on other players' screens). They verify sprites appear on both windows when testing.

Dependencies:
* T18.G5.02: Join an existing multiplayer game using the join game block





ID: T18.G5.04
Topic: T18 – Multiplayer Apps
Skill: Implement synchronized sprite movement
Description: Students use "synchronously set speed x y" or "synchronously set speed dir" blocks instead of regular movement blocks. They understand the critical difference: regular movement affects only local sprite, synchronized movement broadcasts to all clients. They test with two windows: move sprite in window 1, verify it moves in window 2. They identify common mistakes: using regular "change x" instead of synchronized blocks (movement invisible to others). They explain why Dynamic sprite registration plus synchronized movement are both required for visible multiplayer movement.

Dependencies:
* T18.G5.03: Register sprites with the multiplayer system using add sprite to game





ID: T18.G5.05
Topic: T18 – Multiplayer Apps
Skill: Broadcast and receive multiplayer messages
Description: Students use "broadcast message with parameter mode" block to send custom messages across all connected players. They define message types for game events: "playerScored" with parameter "1", "itemCollected" with parameter "coin", "roundStart" with parameter "3" (countdown). They implement "when I receive message" listeners to react. They distinguish: regular broadcast (one instance only) versus multiplayer broadcast (all connected instances). They test with two windows: send message from window 1, verify listener triggers in window 2. This enables custom event synchronization beyond automatic position updates.

Dependencies:
* T18.G5.04: Implement synchronized sprite movement
* T06.G4.01: Use broadcast to coordinate sprite actions




ID: T18.G5.05.01
Topic: T18 – Multiplayer Apps
Skill: Choose broadcast mode: All Sprites versus Exclude Replicate
Description: Students select appropriate broadcast mode: "All Sprites" (message received by all sprites including replicates) versus "Exclude Replicate" (only received by original sprites, not replicates). They identify when to use each: "All Sprites" for global events everyone should see (timer update, round end), "Exclude Replicate" for owner-only actions (only my sprite should respond to my input). They test both modes with two windows and trace which sprites respond.

Dependencies:
* T18.G5.05: Broadcast and receive multiplayer messages
* T18.G6.01: Trace code execution on original versus replicate sprites





ID: T18.G5.06
Topic: T18 – Multiplayer Apps
Skill: Test multiplayer games systematically with multiple browser windows
Description: Students develop a testing workflow: (1) Open window 1, create game as host; (2) Open window 2, join as client; (3) Test each feature in both windows. They create a testing checklist: sprites visible in both? movement syncs? messages received? scores update? They log print statements to track execution in each window. They understand limitations: same-computer testing doesn't show real network delay. They establish habit of testing after each multiplayer feature addition.

Dependencies:
* T18.G5.05: Broadcast and receive multiplayer messages





ID: T18.G5.07
Topic: T18 – Multiplayer Apps
Skill: Access and display player information using list players block
Description: Students use "list players in game in table" block to get a table variable containing all connected players with columns: Player Name, Role. They use reporters to access their own display name and role. They display player count using "length of table". They loop through the player table to display all player names. They implement role-based logic: "if my role = 'red' then go to red starting position". This enables games that adapt to player count and identities.

Dependencies:
* T18.G5.06: Test multiplayer games systematically with multiple browser windows
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T18.G5.08
Topic: T18 – Multiplayer Apps
Skill: Build a simple synchronized multiplayer game
Description: Students design and implement a complete simple multiplayer game (tag, racing, or collection) combining all G5 multiplayer skills: create/join rooms, register sprites, synchronized movement, custom message broadcasts, player info display. They document their sync decisions: what syncs (positions, scores) versus what's local (sounds, effects). They test with two windows and create a bug list of sync issues found and fixed. They playtest with a real partner on different computers and note how network delay affects gameplay. This synthesizes foundational multiplayer skills.

Dependencies:
* T18.G5.07: Access and display player information using list players block
* T18.G4.06: Evaluate game ideas for multiplayer suitability





ID: T18.G6.01
Topic: T18 – Multiplayer Apps
Skill: Trace code execution on original versus replicate sprites
Description: Students understand that registered sprites exist as "originals" (on registering player's computer, controlled by that player) and "replicates" (automatically created on other players' screens, mirror the original). They trace code execution: keyboard handlers run on all sprites but should only affect originals (my key presses shouldn't move your replicate of my sprite). They use print statements showing "I am original" versus "I am replicate" to verify. They debug issues where replicates respond incorrectly to local input.

Dependencies:
* T18.G5.03: Register sprites with the multiplayer system using add sprite to game
* T12.G6.01: Trace complex code with multiple variables





ID: T18.G6.02
Topic: T18 – Multiplayer Apps
Skill: Classify sprites as Dynamic versus Static for performance
Description: Students classify game objects appropriately: Dynamic (players, enemies, projectiles - need continuous position sync) versus Static (walls, platforms, decorations - fixed position, no sync needed). They understand the trade-off: Dynamic = smooth movement but more network traffic; Static = efficient but can't move. They audit their game, identify misclassified objects (wall marked Dynamic wastes bandwidth, moving enemy marked Static won't sync), and fix them. They predict network impact of having too many Dynamic sprites.

Dependencies:
* T18.G5.03: Register sprites with the multiplayer system using add sprite to game





ID: T18.G6.03
Topic: T18 – Multiplayer Apps
Skill: Select appropriate collision shapes for multiplayer sprites
Description: Students select collision shapes matching sprite appearance: Rectangle (for box-shaped objects like walls, crates, rectangular characters) or Circle (for balls, circular characters, round power-ups). They understand collision shapes are synchronized - all players see same collision results. They test collision accuracy with both shapes and identify mismatch problems (circular sprite with rectangle collider = unfair corner hits). They implement collision-based multiplayer mechanics (scoring goals, collecting items, tagging players).

Dependencies:
* T18.G5.03: Register sprites with the multiplayer system using add sprite to game
* T13.G5.01: Detect when sprites touch or overlap




ID: T18.G6.03.01
Topic: T18 – Multiplayer Apps
Skill: Implement synchronized collision events using touch broadcasts
Description: Students use "when touching sprite will stop/continue and trigger message with parameter" block to create collision-based multiplayer mechanics. They configure collision responses: ball entering goal triggers "goalScored" message, player touching hazard triggers "playerHit" message, player collecting item triggers "itemCollected" with item ID parameter. They test with two windows to verify all clients respond consistently to the same collisions.

Dependencies:
* T18.G6.03: Select appropriate collision shapes for multiplayer sprites
* T18.G5.05: Broadcast and receive multiplayer messages





ID: T18.G6.04
Topic: T18 – Multiplayer Apps
Skill: Use list multiplayer games to browse available games
Description: Students use "list multiplayer games in server in table" block to fetch active games into a table variable with columns: Host Name, Game Name, User Count. They display game information to help players find games to join. They filter by server location to see only relevant games. They implement a simple game browser: display game list, allow selection, auto-fill join parameters. They understand games are temporary (disappear when all players leave). This enables matchmaking and discovery features.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block
* T18.G5.02: Join an existing multiplayer game using the join game block




ID: T18.G6.04.01
Topic: T18 – Multiplayer Apps
Skill: Implement game room refresh and filtering
Description: Students implement periodic game list refresh (using timer or button) to show newly created games. They add filtering: show only games with available slots (User Count < capacity), show only games on preferred server, show only games matching name pattern. They sort games by user count or alphabetically. They handle empty results gracefully ("No games found - create your own!").

Dependencies:
* T18.G6.04: Use list multiplayer games to browse available games
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T18.G6.05
Topic: T18 – Multiplayer Apps
Skill: Implement role-based conditional logic
Description: Students implement conditional logic based on player roles set during create/join: "if my role = 'red' then set costume to redPlayer", "if my role = 'seeker' then show radar widget". They verify role affects starting position, abilities, and objectives. They test with two windows using different roles to verify role-specific behaviors work correctly. They display each player's role in the scoreboard. This enables team-based and asymmetric gameplay mechanics.

Dependencies:
* T18.G5.07: Access and display player information using list players block
* T08.G5.02: Design multi-branch decision logic





ID: T18.G6.06
Topic: T18 – Multiplayer Apps
Skill: Handle player join and leave events
Description: Students use "when player joins game" and "when player leaves game" event blocks to respond to connection changes. They implement: announce joins ("PlayerX has joined!"), update player count display, assign late joiners to teams, clean up disconnected player's sprites. They test by joining and leaving games in test windows. They handle edge cases: what if game is in progress when someone joins? what if last player on a team leaves? This enables games that adapt to changing player counts.

Dependencies:
* T18.G5.07: Access and display player information using list players block
* T06.G6.01: Trace event execution paths in a multi-event program





ID: T18.G6.07
Topic: T18 – Multiplayer Apps
Skill: Display connection status feedback to players
Description: Students use "connected to game" boolean reporter to monitor connection state. They display visual indicators: green icon when connected, red icon when disconnected, "Connecting..." during connection attempt. They disable game controls when not connected (prevent errors from offline actions). They prompt players to rejoin if disconnected. They test by closing windows mid-game and verifying feedback appears correctly. This provides essential user experience for network-dependent games.

Dependencies:
* T18.G5.02: Join an existing multiplayer game using the join game block
* T08.G5.02: Design multi-branch decision logic





ID: T18.G6.08
Topic: T18 – Multiplayer Apps
Skill: Synchronize shared world objects across all players
Description: Students implement shared world objects: doors that open for everyone, collectibles that disappear when anyone takes them, switches that affect all players. They broadcast state changes: "when player touches door, broadcast 'doorOpened' with parameter doorID". All clients listen and update their local door state. They handle race conditions: first player to collect item gets it (host decides), others' clients hide it. They test with two windows to verify shared objects stay synchronized.

Dependencies:
* T18.G5.05: Broadcast and receive multiplayer messages
* T18.G6.01: Trace code execution on original versus replicate sprites





ID: T18.G6.09
Topic: T18 – Multiplayer Apps
Skill: Build synchronized scoreboards using broadcasts
Description: Students create scoreboards displaying all players' scores, updated via broadcasts. When player scores: broadcast "scoreUpdate" with parameter "playerName:newScore". All clients parse the message and update their local scoreboard display. They format scoreboards clearly: player names, scores, rankings. They verify all clients show identical scores after any scoring event. They implement team score totals for team games. This provides essential shared feedback in competitive multiplayer games.

Dependencies:
* T18.G5.05: Broadcast and receive multiplayer messages
* T18.G5.07: Access and display player information using list players block





ID: T18.G6.10
Topic: T18 – Multiplayer Apps
Skill: Handle full game scenarios gracefully
Description: Students implement checks before joining: compare User Count from game list with capacity, show "Game Full" message if equal or greater. They test by filling a game to capacity and attempting additional join. They provide helpful feedback: "Game has 4/4 players - try another game or create your own." They optionally implement "notify when slot opens" feature. This prevents poor user experience from failed join attempts.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block
* T18.G6.04: Use list multiplayer games to browse available games




ID: T18.G6.10.01
Topic: T18 – Multiplayer Apps
Skill: Implement round resets using reset game world
Description: Students use "reset game world" block to clean up all game objects and start a new round within the same room. They implement round-based gameplay: scores persist across rounds but positions/objects reset. They broadcast "roundReset" before reset so all clients can prepare. They add countdown (3, 2, 1, Go!) before new round starts. They test reset with multiple windows to verify all clients restart simultaneously.

Dependencies:
* T18.G6.10: Handle full game scenarios gracefully
* T18.G5.03: Register sprites with the multiplayer system using add sprite to game





ID: T18.G6.11
Topic: T18 – Multiplayer Apps
Skill: Design safe display name practices for multiplayer
Description: Students distinguish: account name (private, for login), display name (public, shown to other players), game name (identifies game room). They explain why display names protect privacy (don't reveal real identity or account info). They identify risky display names (real name, location, age) versus safe ones (creative nicknames). They implement display name validation: check for inappropriate content, limit length, provide defaults. This connects multiplayer identity to digital citizenship and online safety.

Dependencies:
* T18.G5.02: Join an existing multiplayer game using the join game block
* T32.G2.04: Distinguish public vs. private information





ID: T18.G6.12
Topic: T18 – Multiplayer Apps
Skill: Measure and explain network lag effects on gameplay
Description: Students define "lag" as delay between player action and when others see it. They identify lag causes: distance to server (US player on Asia server = high lag), internet speed, network congestion. They test their game on different servers and observe lag differences. They categorize game types by lag sensitivity: high (fast-paced shooters, racing), medium (platformers, adventures), low (turn-based, puzzles). They explain why some lag is unavoidable and how game design can minimize frustration.

Dependencies:
* T18.G6.04: Use list multiplayer games to browse available games





ID: T18.G6.13
Topic: T18 – Multiplayer Apps
Skill: Choose automatic versus manual synchronization appropriately
Description: Students distinguish: automatic sync (synchronized movement blocks broadcast position continuously without coding) versus manual sync (explicitly broadcast custom messages for events). They identify when to use each: positions → automatic (continuous, smooth), discrete events (scoring, collecting, dying) → manual broadcasts. They implement a game using both: player positions auto-sync via synchronized movement, but score updates and game events use manual broadcasts. This develops judgment about synchronization strategy.

Dependencies:
* T18.G5.04: Implement synchronized sprite movement
* T18.G5.05: Broadcast and receive multiplayer messages





ID: T18.G6.14
Topic: T18 – Multiplayer Apps
Skill: Implement synchronized countdown timers
Description: Students understand that local timers drift (each client's clock differs slightly). They implement host-controlled timers: host broadcasts remaining time every second, clients display received value (not local countdown). They test by watching both windows - should show identical time. They handle late joiners: broadcast current time when new player joins. They implement countdown-triggered events: when timer reaches 0, broadcast "roundEnd" to all clients.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block
* T18.G6.09: Build synchronized scoreboards using broadcasts





ID: T18.G6.15
Topic: T18 – Multiplayer Apps
Skill: Debug common multiplayer synchronization issues systematically
Description: Students systematically troubleshoot common problems: sprites not appearing (forgot add sprite to game), movement not syncing (used regular instead of synchronized blocks), messages not received (regular vs multiplayer broadcast), inconsistent state (forgot to sync critical events). They use console.log on both host and client windows to trace execution. They develop a debugging checklist: 1) Check connection, 2) Check sprite registration, 3) Check movement blocks, 4) Check broadcast types. This builds essential debugging skills for networked systems.

Dependencies:
* T18.G5.06: Test multiplayer games systematically with multiple browser windows
* T12.G6.01: Trace complex code with multiple variables




ID: T18.G6.15.01
Topic: T18 – Multiplayer Apps
Skill: Debug sprite registration and visibility issues
Description: Students diagnose invisible sprites: verify "add sprite to game" block is called, check it runs after "connected to game" is true, confirm "when added to game" event fires on all clients. They use console.log: "About to register sprite", "Sprite registered successfully", "when added to game triggered on client". They test by deliberately breaking registration and fixing it.

Dependencies:
* T18.G6.15: Debug common multiplayer synchronization issues systematically




ID: T18.G6.15.02
Topic: T18 – Multiplayer Apps
Skill: Debug movement synchronization issues
Description: Students diagnose invisible movement: verify synchronized movement blocks (not regular blocks), check sprite is Dynamic (not Static), log position values on both windows to find where they diverge. They test by: using wrong block type (observe it doesn't sync), then switching to correct block (observe it syncs). They measure latency by logging timestamps when movement starts vs when it appears on other client.

Dependencies:
* T18.G6.15: Debug common multiplayer synchronization issues systematically





ID: T18.G6.16
Topic: T18 – Multiplayer Apps
Skill: Build a complete competitive multiplayer game
Description: Students design and implement a complete competitive multiplayer game (racing, battle arena, collection competition) synthesizing G6 skills: role-based teams, synchronized scoreboards, player join/leave handling, round resets, lag awareness. They document design decisions and synchronization strategy. They test with real partners on different computers, gather feedback on fairness and fun, and iterate. They compare their multiplayer version to a hypothetical single-player version. This demonstrates comprehensive competitive multiplayer development competency.

Dependencies:
* T18.G6.09: Build synchronized scoreboards using broadcasts
* T18.G6.15: Debug common multiplayer synchronization issues systematically
* T18.G5.08: Build a simple synchronized multiplayer game





ID: T18.G6.17
Topic: T18 – Multiplayer Apps
Skill: Build a complete cooperative multiplayer game
Description: Students design and implement a cooperative multiplayer game (team puzzle, tower defense, collaborative construction) where players must work together toward shared goals. They implement mechanics requiring coordination: simultaneous button presses, complementary roles (one builds, one defends), shared resources. They verify the game genuinely requires cooperation (one player cannot complete alone). They gather feedback on teamwork quality and iterate. They explain how cooperative design differs from competitive. This demonstrates cooperative multiplayer development competency.

Dependencies:
* T18.G6.08: Synchronize shared world objects across all players
* T18.G6.05: Implement role-based conditional logic
* T18.G5.08: Build a simple synchronized multiplayer game





ID: T18.G6.18
Topic: T18 – Multiplayer Apps
Skill: Compare real-time multiplayer versus persistent cloud storage
Description: Students compare multiplayer game servers (real-time sync, temporary rooms, immediate updates, players must be online together) versus cloud variables/Google Sheets (persistent storage, async updates, data survives logout, players don't need simultaneous presence). They identify use cases: multiplayer for live interactive games, cloud storage for leaderboards, saved progress, turn-based games where players take turns over days. They implement a feature using each approach and compare the experience.

Dependencies:
* T18.G5.01: Create a multiplayer game room using the create game block
* T09.G5.01: Store and retrieve game state using variables





ID: T18.G7.01
Topic: T18 – Multiplayer Apps
Skill: Design and implement asymmetric multiplayer gameplay
Description: Students implement games where roles have different abilities, objectives, or win conditions: hide-and-seek (seekers have radar, hiders are invisible initially), asymmetric teams (attackers vs defenders), class-based (wizard: ranged spells, warrior: melee power). They balance roles through playtesting: track win rates by role, adjust abilities until roles are roughly equal. They explain how asymmetry creates strategic depth, replay value, and more interesting choices than symmetric competition.

Dependencies:
* T18.G6.05: Implement role-based conditional logic
* T08.G6.01: Use conditionals to control simulation steps





ID: T18.G7.02
Topic: T18 – Multiplayer Apps
Skill: Select optimal server locations based on player geography
Description: Students strategically select server locations based on player geography. They test their game on US-East, US-West, Europe, Asia servers and measure lag differences using timestamps. They apply decision rules: choose server closest to majority of players, or central location for distributed players. They explain trade-offs when players span continents (someone will always have higher lag). They document server selection rationale for their multiplayer game.

Dependencies:
* T18.G6.12: Measure and explain network lag effects on gameplay
* T18.G6.04: Use list multiplayer games to browse available games





ID: T18.G7.03
Topic: T18 – Multiplayer Apps
Skill: Design lag-tolerant gameplay mechanics
Description: Students design gameplay that tolerates network delay: avoid frame-perfect timing requirements, provide immediate local feedback (button press animation) before server confirmation, use turn-based or slower-paced mechanics. They test with real network delay (different computers, distant servers) and observe how delay affects fairness and fun. They identify problematic mechanics (instant-hit projectiles) and redesign them (travel-time projectiles). They explain why lag-tolerant design improves player experience across varied network conditions.

Dependencies:
* T18.G7.02: Select optimal server locations based on player geography





ID: T18.G7.04
Topic: T18 – Multiplayer Apps
Skill: Implement lobby ready-up systems
Description: Students create lobby systems with "Ready" buttons. They track ready status per player and display it (green checkmark when ready). Host checks: "if all players ready, broadcast 'gameStart'". They implement unready (toggle button), countdown before start (5, 4, 3...), and handle late joiners (new players start unready). They test with multiple windows to verify game waits correctly. This creates polished multiplayer start experiences.

Dependencies:
* T18.G6.06: Handle player join and leave events
* T18.G6.09: Build synchronized scoreboards using broadcasts





ID: T18.G7.05
Topic: T18 – Multiplayer Apps
Skill: Scale game logic for variable player counts
Description: Students design games that work correctly with 2, 3, 4, or more players without hardcoding player count. They loop over player list to create sprites, distribute spawn points, and update displays. They use "length of player table" to adjust parameters dynamically (spawn positions = divide circle by player count). They test with different player counts and verify correctness at each. They explain why scalable design matters for reusability and flexibility.

Dependencies:
* T18.G6.06: Handle player join and leave events
* T07.G5.01: Use a loop to repeat a task an exact number of times





ID: T18.G7.06
Topic: T18 – Multiplayer Apps
Skill: Audit and balance multiplayer game fairness
Description: Students audit spawn points (equidistant from objectives), turn order (rotate fairly), resource distribution (equal starting resources), and scoring rules (no role-based advantages). They playtest and record outcomes: track win rates by spawn position and role. They identify imbalances (position A wins 70% of time) and adjust until balance improves. They explain why fairness is critical for player satisfaction, replay value, and community building.

Dependencies:
* T18.G7.05: Scale game logic for variable player counts
* T18.G6.09: Build synchronized scoreboards using broadcasts





ID: T18.G7.07
Topic: T18 – Multiplayer Apps
Skill: Optimize synchronization by choosing what to sync
Description: Students decide what must sync (scores, positions, game state, shared objects) versus what stays local (UI animations, sound effects, visual particles, input feedback). They understand over-syncing → unnecessary traffic/lag, under-syncing → inconsistent states. They test by deliberately over-syncing (sync every sound) and under-syncing (don't sync scores) to observe problems. They document their sync decisions with justifications for their multiplayer game.

Dependencies:
* T18.G6.13: Choose automatic versus manual synchronization appropriately
* T09.G6.01: Model real-world quantities using variables and formulas





ID: T18.G7.08
Topic: T18 – Multiplayer Apps
Skill: Design multiplayer puzzles requiring player coordination
Description: Students design puzzles where players must coordinate: both stand on switches simultaneously, one holds door while other passes, players pass items to reach new areas. They implement coordination detection (both players standing on plates within time window). They broadcast progress updates visible to all. They verify puzzles cannot be solved solo. They gather feedback on puzzle difficulty and communication requirements. This demonstrates advanced cooperative game design.

Dependencies:
* T18.G6.17: Build a complete cooperative multiplayer game
* T18.G6.08: Synchronize shared world objects across all players




ID: T18.G7.08.01
Topic: T18 – Multiplayer Apps
Skill: Implement simultaneous action requirements
Description: Students implement mechanics requiring players to act within a time window: both on pressure plates within 2 seconds, both click button within 1 second. They use broadcasts to signal readiness, track timestamps, and detect when all players acted within tolerance. They display visual feedback: "Player 1 ready ✓, waiting for Player 2..."

Dependencies:
* T18.G7.08: Design multiplayer puzzles requiring player coordination




ID: T18.G7.08.02
Topic: T18 – Multiplayer Apps
Skill: Implement player-to-player item transfer
Description: Students create mechanics where players transfer items: click on teammate to give item, press key near teammate to drop for pickup. They track item ownership and broadcast transfers ("itemTransfer" with sender, receiver, itemID). They update all clients' displays to show who has what. They handle edge cases: can't transfer to disconnected player, can't transfer item you don't have.

Dependencies:
* T18.G7.08: Design multiplayer puzzles requiring player coordination





ID: T18.G7.09
Topic: T18 – Multiplayer Apps
Skill: Test multiplayer games with 3+ players systematically
Description: Students test with 3+ players to find scale-only issues: UI crowding, odd team sizes, performance degradation, edge cases in player management. They recruit testers or use multiple devices/windows. They document issues that weren't apparent in 2-player tests. They create test plans specifying: player counts to test, scenarios to verify, expected behaviors. They understand 2-player testing is insufficient for games designed for larger groups.

Dependencies:
* T18.G7.05: Scale game logic for variable player counts
* T18.G6.15: Debug common multiplayer synchronization issues systematically

ID: T18.G7.09.01
Topic: T18 – Multiplayer Apps
Skill: Develop systematic multiplayer testing checklists
Description: Students create testing checklists covering: connection (create/join works, reconnection), synchronization (positions, messages, scores), player management (join/leave, count), edge cases (full games, invalid passwords, host leaving). They use their checklist to test games, document results (pass/fail/notes), and iterate on the checklist when they discover issues it missed.

Dependencies:
* T18.G7.09: Test multiplayer games with 3+ players systematically

ID: T18.G7.09.02
Topic: T18 – Multiplayer Apps
Skill: Document multiplayer bugs with reproducible reports
Description: Students document bugs with: steps to reproduce (exact actions taken), expected behavior, actual behavior, which players affected, consistent or intermittent. They categorize by severity: critical (game-breaking), major (significantly impacts gameplay), minor (cosmetic/inconvenience). They prioritize fixes by severity and track status (open/in-progress/fixed/verified).

Dependencies:
* T18.G7.09: Test multiplayer games with 3+ players systematically





ID: T18.G7.10
Topic: T18 – Multiplayer Apps
Skill: Implement fair dynamic spawn systems
Description: Students implement spawn systems fair for 2, 3, 4+ players: distribute points evenly around world (360/playerCount degrees apart), rotate through zones, or randomize with minimum distance constraints. They verify no player has systematic advantage from spawn location. They measure distances from spawns to objectives and ensure they're equal. They test with different player counts to verify fairness is maintained as count changes.

Dependencies:
* T18.G7.05: Scale game logic for variable player counts
* T18.G7.06: Audit and balance multiplayer game fairness





ID: T18.G8.01
Topic: T18 – Multiplayer Apps
Skill: Implement automatic team assignment and matchmaking
Description: Students automatically assign players to teams using algorithms: alternate assignment (player 1 → red, player 2 → blue, player 3 → red...), or balance by current team size (join team with fewer players). They update assignments when players join/leave. They display team rosters to all players. They test with 3, 4, 5, 6 players and verify balanced distribution. They explain how automated matchmaking improves fairness and reduces setup time.

Dependencies:
* T18.G7.05: Scale game logic for variable player counts
* T18.G7.01: Design and implement asymmetric multiplayer gameplay
* T07.G6.01: Trace nested loops with variable bounds





ID: T18.G8.02
Topic: T18 – Multiplayer Apps
Skill: Implement host-authoritative validation to prevent cheating
Description: Students restructure games: clients request actions ("I want to collect coin 5"), host validates (is coin 5 still there? is player close enough?), host applies and broadcasts result. They implement validation checks: position bounds, timing constraints, action validity. They test by attempting invalid actions from client and verifying host rejects them. They explain why client-side validation is insufficient (code can be modified) and why host-authority maintains fair play.

Dependencies:
* T18.G7.07: Optimize synchronization by choosing what to sync
* T08.G6.01: Use conditionals to control simulation steps





ID: T18.G8.03
Topic: T18 – Multiplayer Apps
Skill: Implement player reconnection handling
Description: Students save player state when disconnect detected (score, position, role, inventory in a list or table). When player rejoins with same display name, they restore saved state instead of starting fresh. They handle edge cases: game ended while disconnected (show "game over" message), spot was filled (show "game full" message), timeout expired (clear saved state). They test by closing browser, reopening, and verifying state restoration.

Dependencies:
* T18.G6.07: Display connection status feedback to players
* T18.G6.06: Handle player join and leave events





ID: T18.G8.04
Topic: T18 – Multiplayer Apps
Skill: Debug message delivery timing and ordering issues
Description: Students identify problems from messages arriving in different orders on different clients. They add sequence numbers to messages and log arrival order on each client to detect ordering issues. They implement strategies: ignore duplicates (check sequence already processed), re-order based on timestamps, make operations idempotent (applying same message twice has no extra effect). They test by deliberately delaying messages and verifying correct handling.

Dependencies:
* T18.G6.15: Debug common multiplayer synchronization issues systematically
* T06.G6.01: Trace event execution paths in a multi-event program





ID: T18.G8.05
Topic: T18 – Multiplayer Apps
Skill: Diagram multiplayer message flow architecture
Description: Students create diagrams showing message flow: client sends input → host processes → host broadcasts update → all clients display. They map their game's specific actions (move, score, collect) to message exchanges. They identify synchronization points where all clients must agree on state before proceeding. They trace a single action through the complete system and use diagrams to identify bottlenecks and debug issues.

Dependencies:
* T18.G7.07: Optimize synchronization by choosing what to sync
* T18.G8.04: Debug message delivery timing and ordering issues





ID: T18.G8.06
Topic: T18 – Multiplayer Apps
Skill: Profile and optimize multiplayer performance bottlenecks
Description: Students identify bottlenecks: broadcasting every frame (reduce to on-change), too many Dynamic sprites (convert to Static where possible), large parameters (use indices not strings), inefficient loops. They measure before optimization (message count, perceived lag), implement optimization, and measure after to verify improvement. They document performance gains with before/after comparisons.

Dependencies:
* T18.G8.05: Diagram multiplayer message flow architecture
* T18.G6.02: Classify sprites as Dynamic versus Static for performance





ID: T18.G8.07
Topic: T18 – Multiplayer Apps
Skill: Minimize network traffic through efficient messaging
Description: Students minimize traffic: broadcast on state change (not every frame), use Static sprites for fixed objects, compress parameters (indices instead of strings, boolean flags), batch related messages. They understand trade-offs: higher update frequency = smoother but more traffic, lower frequency = less traffic but stuttery. They measure message counts before and after optimization and test with real network conditions.

Dependencies:
* T18.G8.06: Profile and optimize multiplayer performance bottlenecks
* T18.G6.13: Choose automatic versus manual synchronization appropriately





ID: T18.G8.08
Topic: T18 – Multiplayer Apps
Skill: Implement comprehensive multiplayer error handling
Description: Students handle common errors: connection failure (display "cannot connect to server"), full game (display "game full, try another"), wrong password (display "incorrect password"), host leaving (display "host disconnected, game ending"), mid-game disconnect (save state, allow rejoin). They display clear messages with actions ("Retry" button, "Find Another Game" button). They test each error case deliberately and verify proper handling without game crashes.

Dependencies:
* T18.G6.07: Display connection status feedback to players
* T18.G8.03: Implement player reconnection handling





ID: T18.G8.09
Topic: T18 – Multiplayer Apps
Skill: Design privacy-aware multiplayer games
Description: Students identify what's shared in multiplayer (display names, roles, positions, broadcast contents) versus what's private (account credentials, passwords unless deliberately sent). They design games that don't accidentally expose private information in broadcasts or display names. They audit their game: "Could a player learn real name, location, or personal details from any message?" They implement privacy-safe practices and explain privacy implications of real-time data sharing.

Dependencies:
* T18.G6.11: Design safe display name practices for multiplayer
* T32.G4.01: Read and categorize tech impact case studies





ID: T18.G8.10
Topic: T18 – Multiplayer Apps
Skill: Compare peer-to-peer versus client-server architectures
Description: Students compare architectures: peer-to-peer (all players equal, no central authority, direct connections) versus client-server (host is authority, clients connect to host). They understand CreatiCode uses client-server. They compare trade-offs: client-server enables cheat prevention and consistency but has single point of failure (host leaving); peer-to-peer has no single failure point but is harder to sync and more vulnerable to cheating. They explain when each architecture is appropriate.

Dependencies:
* T18.G8.02: Implement host-authoritative validation to prevent cheating
* T18.G8.05: Diagram multiplayer message flow architecture




ID: T18.G8.11
Topic: T18 – Multiplayer Apps
Skill: Implement state reconciliation after network interruptions
Description: Students design systems to resync game state after connection instability. They implement state snapshots: host can send complete game state (all positions, scores, object states) to a recovering client. They detect divergence using version numbers (client version != host version). They trigger state correction broadcasts when divergence detected. They test by simulating network interruptions and verifying state converges correctly.

Dependencies:
* T18.G8.03: Implement player reconnection handling
* T18.G8.04: Debug message delivery timing and ordering issues




ID: T18.G8.12
Topic: T18 – Multiplayer Apps
Skill: Integrate AI opponents and teammates in multiplayer games
Description: Students design multiplayer games with AI participants: AI opponents that challenge players when others unavailable, AI teammates that fill empty slots, AI coaches providing hints. They use ChatGPT blocks to create adaptive AI behavior ("given game state X, what move should AI make?"). They implement clear interfaces between human input, AI decisions, and game state updates. They explore human-AI collaborative puzzle solving where each contributes different strengths. This prepares for AI-augmented gaming.

Dependencies:
* T18.G8.01: Implement automatic team assignment and matchmaking
* T26.G7.01: Build a chatbot using the ChatGPT block




ID: T18.G8.13
Topic: T18 – Multiplayer Apps
Skill: Identify and mitigate multiplayer security vulnerabilities
Description: Students identify security risks: message spoofing (pretending to be another player), replay attacks (resending old valid messages), data injection (malformed parameters), denial of service (message flooding). They implement mitigations: validate sender identity, use sequence numbers to prevent replay, sanitize parameters, rate-limit messages. They test by attempting exploits on their own games and verifying defenses work. This builds security thinking for networked applications.

Dependencies:
* T18.G8.02: Implement host-authoritative validation to prevent cheating
* T18.G8.09: Design privacy-aware multiplayer games

ID: T18.G8.13.01
Topic: T18 – Multiplayer Apps
Skill: Implement input validation for multiplayer messages
Description: Students validate incoming messages: check parameter types (is score a number?), check value ranges (is position within world bounds?), check permissions (can this player perform this action?). They reject invalid messages and log violations for debugging. They test by deliberately sending malformed messages and verifying rejection.

Dependencies:
* T18.G8.13: Identify and mitigate multiplayer security vulnerabilities

ID: T18.G8.13.02
Topic: T18 – Multiplayer Apps
Skill: Implement rate limiting for multiplayer actions
Description: Students track action frequency per player (messages per second, actions per minute). They reject actions exceeding limits (e.g., max 10 messages per second). They provide feedback: "Slow down! You're sending too fast." They tune limits to allow normal gameplay while blocking spam/abuse.

Dependencies:
* T18.G8.13: Identify and mitigate multiplayer security vulnerabilities




ID: T18.G8.14
Topic: T18 – Multiplayer Apps
Skill: Build a production-quality multiplayer game with advanced features
Description: Students create a comprehensive multiplayer game integrating G8 skills: team matchmaking, host-authoritative validation, reconnection handling, optimized traffic, comprehensive error handling, privacy protection, documented architecture. They test with 4+ real players across different network conditions. They document known limitations and future improvements. They gather user feedback and iterate. This capstone demonstrates professional-level multiplayer development competency.

Dependencies:
* T18.G8.08: Implement comprehensive multiplayer error handling
* T18.G8.10: Compare peer-to-peer versus client-server architectures
* T18.G8.11: Implement state reconciliation after network interruptions

ID: T18.G8.14.01
Topic: T18 – Multiplayer Apps
Skill: Write technical documentation for multiplayer game architecture
Description: Students document their game's architecture: network topology diagram, message types and purposes (table format), synchronization strategy, error handling approach, security measures implemented. They include data flow diagrams and configuration parameters. This documentation enables others to understand, test, and potentially modify the game.

Dependencies:
* T18.G8.14: Build a production-quality multiplayer game with advanced features

ID: T18.G8.14.02
Topic: T18 – Multiplayer Apps
Skill: Conduct user acceptance testing for multiplayer games
Description: Students recruit 4+ real users (non-developers) to play their game. They observe without helping, noting confusion points and bugs. They collect feedback via surveys: ease of joining, gameplay fairness, fun level, suggestions. They analyze feedback to identify patterns (3 users confused by same thing = priority fix). They iterate based on real user experiences rather than developer assumptions.

Dependencies:
* T18.G8.14: Build a production-quality multiplayer game with advanced features






ID: T18.G8.15
Topic: T18 – Multiplayer Apps
Skill: Build a multiplayer 3D game with synchronized physics
Description: Students combine 3D Worlds (T17) with multiplayer skills to create 3D multiplayer games. They synchronize 3D positions, rotations, and physics states across players. They handle 3D-specific challenges: camera views differ per player, physics must be deterministic, larger position data (x, y, z). They implement synchronized 3D world objects, projectiles in 3D space, and 3D collision handling. They test with multiple players in the 3D environment and optimize for performance.

Dependencies:
* T18.G8.14: Build a production-quality multiplayer game with advanced features
* T17.G8.11: Synchronize 3D objects across multiplayer sessions


ID: T18.G8.16
Topic: T18 – Multiplayer Apps
Skill: Implement multiplayer chat using text input widgets
Description: Students add text chat to multiplayer games using text input widgets. They broadcast chat messages with sender display name. They display chat history visible to all players in a scrolling list. They implement basic moderation: rate limiting (max 2 messages per 5 seconds), maximum message length, mute feature. They handle edge cases: empty messages (ignore), disconnected players' messages (still display). This adds essential social communication to multiplayer experiences.

Dependencies:
* T18.G8.08: Implement comprehensive multiplayer error handling
* T15.G5.04: Use text input widget to collect user input

ID: T19.GK.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Identify which picture row follows a pattern
Description: Students view short rows of colors/shapes (e.g., sun-moon-sun-moon) shown as picture cards and tap/circle the row that follows a clean repeat. The activity is entirely visual with drag-and-drop or tap-to-select interaction. No text reading required. They select from 2-3 options and identify which continues the pattern correctly.
Activity Type: Tap-to-select picture activity
Estimated Time: 2-3 minutes

Dependencies:
* T04.GK.01: Identify a simple repeating pattern







ID: T19.GK.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Sequence art step cards to match finished picture
Description: Learners drag picture cards showing simple art steps (e.g., picture of picking red crayon → picture of drawing big circle → picture of adding yellow dots) to match a finished coloring page. All cards show clear action pictures, no text reading required. Students arrange 3-4 cards in correct order.
Activity Type: Drag-and-drop sequencing
Estimated Time: 2-3 minutes

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed







ID: T19.GK.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Drag shapes to continue a pattern trail
Description: Students drag shapes to continue a pattern along a dotted path (e.g., flower-heart-flower-heart). They place 2-3 additional shapes in correct positions, focusing on spatial placement and rhythm. Activity uses large touch targets on a visual trail.
Activity Type: Drag-and-drop pattern continuation
Estimated Time: 2-3 minutes

Dependencies:
* T04.GK.01: Identify a simple repeating pattern







ID: T19.GK.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Swap the wrong card to fix an art plan
Description: Students look at a 3-step visual art plan with one incorrect picture card (e.g., a color that breaks the pattern) and drag-and-drop the correct card from a small set of 2-3 options. No text reading required—all instructions are visual. This introduces debugging in a creative context.
Activity Type: Drag-and-drop replacement
Estimated Time: 2-3 minutes

Dependencies:
* T04.GK.01: Identify a simple repeating pattern




ID: T19.GK.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Drag the correct color to complete a picture
Description: Students view an incomplete picture (e.g., a rainbow missing one stripe, a flower missing petals) and drag the correct colored shape from a palette of 3-4 options to complete it. They focus on color recognition and pattern matching. Activity uses large tap targets and high-contrast visuals.
Activity Type: Drag-and-drop color matching
Estimated Time: 2-3 minutes

Dependencies:
* T04.GK.01: Identify a simple repeating pattern




ID: T19.GK.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Tap the picture showing the next art step
Description: Students view 2-3 pictures showing art in progress (e.g., blank page → one circle → two circles) and tap which picture shows the next step from three options. They predict simple sequences without reading. Activity reinforces cause-and-effect thinking in creative contexts.
Activity Type: Tap-to-select prediction
Estimated Time: 2-3 minutes

Dependencies:
* T19.GK.01: Identify which picture row follows a pattern


ID: T19.GK.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Sort shapes by one visual property
Description: Students sort picture cards showing different shapes into two labeled bins based on one visual property (e.g., "big shapes" vs "small shapes," or "round shapes" vs "pointy shapes"). They categorize 4-6 cards, building foundational classification skills for organizing art elements. Uses clear visual bins with picture labels.
Activity Type: Drag-and-drop sorting
Estimated Time: 2-3 minutes

Dependencies:
* T04.GK.01: Identify a simple repeating pattern




## GRADE 1 SKILLS (Verbal Pattern Description)






ID: T19.G1.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Match a pattern to its rule card
Description: Students view a short repeating design (e.g., two small stars then one big sun) and match it to the picture card that shows the rule (e.g., card showing 'small-small-big'). They select from 3-4 visual options without writing. This connects visual patterns to abstract rules.
Activity Type: Drag-and-drop matching
Estimated Time: 3-4 minutes

Dependencies:
* T19.GK.01: Identify which picture row follows a pattern







ID: T19.G1.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Connect spoken art directions to finished pictures
Description: Learners listen to simple audio direction sets ("draw a blue square, then add three yellow dots under it") and match them to the drawing they would produce from 3 picture options. Text labels are optional for emerging readers. This builds listening comprehension for following art instructions.
Activity Type: Audio-picture matching
Estimated Time: 3-4 minutes

Dependencies:
* T19.GK.02: Sequence art step cards to match finished picture







ID: T19.G1.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Place tiles to extend a 2D grid pattern
Description: Students complete a 2×3 or 3×3 art grid by dragging the correct tiles to empty positions so the pattern continues horizontally and vertically. They identify the row and column patterns and apply both to choose correct tiles.
Activity Type: Drag-and-drop grid completion
Estimated Time: 3-4 minutes

Dependencies:
* T19.GK.03: Drag shapes to continue a pattern trail







ID: T19.G1.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Identify which instruction is wrong and select the fix
Description: Students hear an audio art direction set (with optional text) with one incorrect step (e.g., "draw circle, draw square, draw triangle" when the pattern shows two circles). They identify which step is wrong and select the correct replacement instruction from 2-3 picture options.
Activity Type: Audio-based debugging with picture selection
Estimated Time: 3-4 minutes

Dependencies:
* T19.GK.04: Swap the wrong card to fix an art plan




ID: T19.G1.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Sort art elements into labeled bins by two properties
Description: Students drag picture cards showing pattern elements (colored shapes, pattern tiles) into labeled bins by color family or shape type. They classify 6-8 elements using audio-supported labels, practicing the categorization skills needed to organize art elements algorithmically. This extends GK.07 by sorting with more complex categories.
Activity Type: Drag-and-drop categorization
Estimated Time: 3-4 minutes

Dependencies:
* T19.GK.07: Sort shapes by one visual property




ID: T19.G1.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Trace an art recipe path from start to finish
Description: Students follow a visual trail showing 4-5 art steps and trace the path from start to finish, tapping each step in order. They practice sequential tracking, building the foundation for following algorithms. Activity uses finger-trace interaction with visual feedback.
Activity Type: Sequential tapping/tracing
Estimated Time: 3-4 minutes

Dependencies:
* T19.G1.01: Match a pattern to its rule card


ID: T19.G1.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Flip tiles to create a mirror pattern
Description: Students see half of a symmetrical design and place mirrored tiles on the other side of a line to complete it. They drag 3-4 tiles to their mirror positions, learning that symmetry means both sides match when flipped. This introduces symmetry as a foundational concept for algorithmic art.
Activity Type: Drag-and-drop symmetry completion
Estimated Time: 3-4 minutes

Dependencies:
* T19.G1.03: Place tiles to extend a 2D grid pattern




## GRADE 2 SKILLS (Repeat Concepts & Layering)






ID: T19.G2.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Choose the recipe that uses repeat efficiently
Description: Students compare two instruction sets for the same border: one long ("red square, red square, red square…") and one that uses a repeat card ("repeat red square 4 times"). They choose which recipe is shorter and verify both produce the same result. This introduces loop thinking.
Activity Type: Recipe comparison and selection
Estimated Time: 4-5 minutes

Dependencies:
* T19.G1.06: Trace an art recipe path from start to finish







ID: T19.G2.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Complete a symmetrical mosaic by placing mirror tiles
Description: Learners arrange tiles on one side of a line and place matching tiles on the other side so the design is symmetrical. They drag 4-6 tiles to correct mirror positions, reinforcing that symmetric patterns have matching halves. This extends G1.07 with more complex mosaic designs.
Activity Type: Drag-and-drop symmetry completion
Estimated Time: 4-5 minutes

Dependencies:
* T19.G1.07: Flip tiles to create a mirror pattern







ID: T19.G2.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Combine two pattern layers into a stacked design
Description: Students interpret instructions with background and foreground patterns (e.g., "repeat row A three times for the background, then repeat row B once on top") to build a stacked design. They order layer cards correctly and see how layers combine to create complex designs. This introduces the concept of layering in digital art.
Activity Type: Layer ordering with visual preview
Estimated Time: 4-5 minutes

Dependencies:
* T19.G2.01: Choose the recipe that uses repeat efficiently







ID: T19.G2.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Predict how changing one element affects the final art
Description: Students consider "what-if" prompts (e.g., "What happens if the second color changes from blue to green?") and select from 3-4 visual options showing how the final pattern would change. They practice cause-and-effect reasoning and understand that small changes can have big visual effects.
Activity Type: Prediction with visual selection
Estimated Time: 4-5 minutes

Dependencies:
* T19.G2.03: Combine two pattern layers into a stacked design




ID: T19.G2.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Find and fix the misplaced card in a pattern recipe
Description: Students examine a pattern recipe that produces the wrong result and identify which instruction card is in the wrong position. They drag the card to its correct place to fix the recipe. They compare before/after results to verify their fix works.
Activity Type: Debugging with card repositioning
Estimated Time: 4-5 minutes

Dependencies:
* T19.G2.03: Combine two pattern layers into a stacked design
* T19.G1.04: Identify which instruction is wrong and select the fix




ID: T19.G2.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Explain why two different recipes create the same pattern
Description: Students view two different instruction sets that both create the same visual pattern. They identify which recipe is shorter (uses repeat efficiently) and select an explanation for why both work. They learn that multiple approaches can achieve the same creative goal.
Activity Type: Comparison with explanation selection
Estimated Time: 4-5 minutes

Dependencies:
* T19.G2.01: Choose the recipe that uses repeat efficiently


ID: T19.G2.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Count how many shapes a repeat instruction creates
Description: Students see a repeat instruction (e.g., "repeat star 5 times") and count how many shapes will appear in the final design. They practice mental execution of repeat commands, building the foundation for understanding loops. They select from 3-4 numerical options.
Activity Type: Counting with selection
Estimated Time: 3-4 minutes

Dependencies:
* T19.G2.01: Choose the recipe that uses repeat efficiently




## GRADE 3 SKILLS (Introduction to Block Coding)






ID: T19.G3.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Match art recipe cards to equivalent block stacks
Description: Given a familiar art recipe (e.g., "draw a triangle, change color, repeat 3 times"), students select the block stack that matches the steps from 3-4 options. This bridges unplugged pattern thinking to block-based coding, showing how card instructions become code.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T19.G2.07: Count how many shapes a repeat instruction creates







ID: T19.G3.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Classify projects as using Pen blocks or Looks draw blocks
Description: Students classify example projects as using either Pen blocks (trails during movement) or Looks draw blocks (shapes at sprite position). Given side-by-side examples, they identify which drawing system each project uses. They explain that Pen draws trails while Looks blocks draw shapes directly at the sprite's position. They understand that stamps don't exist in CreatiCode—each shape must be drawn fresh.

Dependencies:
* T19.G3.01: Match art recipe cards to equivalent block stacks




ID: T19.G3.02.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Select Pen or Looks blocks based on drawing goal
Description: Given a drawing goal (e.g., "draw a trail as sprite moves" vs "add shapes at specific positions"), students select whether Pen blocks or Looks blocks are the appropriate choice. They match 4-5 scenarios to the correct block category, demonstrating understanding of when each system is best suited.

Dependencies:
* T19.G3.02: Classify projects as using Pen blocks or Looks draw blocks







ID: T19.G3.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create trails by placing pen down before movement
Description: Students use the "pen down" block to make sprites leave a trail as they move. They understand that pen down turns on the trail and pen up turns it off. They create simple line drawings by moving sprites with pen down.

Dependencies:
* T19.G3.02: Classify projects as using Pen blocks or Looks draw blocks







ID: T19.G3.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Stop trail drawing with pen up block
Description: Students use the "pen up" block to stop the trail when they want to move without drawing. They practice alternating pen down (drawing) and pen up (repositioning) to create patterns with gaps.

Dependencies:
* T19.G3.03: Create trails by placing pen down before movement







ID: T19.G3.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Change trail color using hex color values
Description: Students use the "set pen color" block with hex color values (#RRGGBBAA format) to change trail colors. They experiment with different colors and see how the trail color changes immediately after this block.

Dependencies:
* T19.G3.04: Stop trail drawing with pen up block







ID: T19.G3.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Adjust pen size to create thick or thin trails
Description: Students use the "set pen size" block to make trails thicker or thinner. They experiment with different pen sizes (e.g., 1, 5, 10) and observe how this affects the visual weight of their drawings.

Dependencies:
* T19.G3.05: Change trail color using hex color values







ID: T19.G3.06.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Clear the canvas with erase all
Description: Students use the "erase all" block to clear all pen trails before starting a new drawing. They understand that erase all removes trails but doesn't affect sprites or drawn shapes. They practice the drawing setup pattern: erase all → set pen properties (color, size) → pen down → move to draw.

Dependencies:
* T19.G3.06: Adjust pen size to create thick or thin trails




ID: T19.G3.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Place rectangles at sprite position using Looks blocks
Description: Students use the "draw rectangle" block from the Looks category to draw rectangles centered at the sprite's current position. They understand that each block call draws a new rectangle and that the sprite doesn't need pen down for this. They control width and height parameters.

Dependencies:
* T19.G3.02: Classify projects as using Pen blocks or Looks draw blocks







ID: T19.G3.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Place ovals at sprite position using Looks blocks
Description: Students use the "draw oval" block from the Looks category to draw ovals/circles centered at the sprite's current position. They control width and height parameters to create circles (equal dimensions) or stretched ovals.

Dependencies:
* T19.G3.07: Place rectangles at sprite position using Looks blocks







ID: T19.G3.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create a repeating border pattern using loops
Description: Students write a drawing program that repeats a sequence using a `repeat` block. They combine draw blocks (draw rectangle or draw oval) with motion blocks (move right, move down) to create border patterns. They see how loops reduce repetitive code.

Dependencies:
* T19.G3.08: Place ovals at sprite position using Looks blocks
* T07.G3.01: Use a counted repeat loop







ID: T19.G3.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Trace loop iterations to predict drawing output
Description: Students read a short script using draw blocks in a loop (e.g., loop drawing rectangles with move blocks) and predict how many shapes or what final layout appears. This tracing skill builds understanding before tackling nested loops.

Dependencies:
* T19.G3.09: Create a repeating border pattern using loops







ID: T19.G3.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Fill a grid with tiles using nested loops
Description: Learners combine two loops—one for columns, one for rows—to fill a small grid with a pattern tile. This is the first double-loop exposure in an art context. They use go to x: y: blocks to position before drawing each tile.

Dependencies:
* T19.G3.10: Trace loop iterations to predict drawing output







ID: T19.G3.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add random color or size variation to patterns
Description: Students extend a loop-based drawing by adding `pick random` for shape colors, sizes, or x/y position variations. They add randomness to one property at a time (e.g., color) to see how it creates visual variety while maintaining pattern structure.

Dependencies:
* T19.G3.11: Fill a grid with tiles using nested loops







ID: T19.G3.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Control pattern dimensions with a size variable
Description: Students create a variable for size or spacing and use it in their draw blocks to control pattern dimensions. They experiment with different values to see how one variable changes the entire design, preparing for variable incrementation in loops.

Dependencies:
* T19.G3.12: Add random color or size variation to patterns
* T09.G3.01.04: Display variable value on stage using the variable monitor




ID: T19.G3.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Debug a simple drawing script with incorrect output
Description: Students examine a short drawing script (3-5 blocks) that produces unexpected output—shapes in wrong positions, wrong colors, or wrong sizes. They systematically compare the actual output to the intended design, identify which specific block has the wrong value or is in the wrong order, and correct it. They test their fix to verify it produces the correct visual result.

Dependencies:
* T19.G3.09: Create a repeating border pattern using loops
* T08.G3.04: Use a simple if in a script




## GRADE 4 SKILLS (Incremental Patterns & Interactivity)






ID: T19.G4.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create spiral patterns with incrementing loop variables
Description: Students write a loop that increases a variable (distance or angle) each iteration to create spiral patterns. They use `go to x: () y: ()` blocks with calculated positions and draw blocks (draw oval, draw rectangle) to place shapes along the spiral path. They focus on incrementing variables with the "change" block and mathematical position calculations using operators.

Dependencies:
* T19.G3.13: Control pattern dimensions with a size variable
* T09.G3.02: Use change block to increase a variable


ID: T19.G4.01.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Calculate positions using angle and distance formulas
Description: Students use multiplication and addition operators to calculate x and y positions based on angle and distance. They apply formulas like x = distance * cos(angle) and y = distance * sin(angle) in simplified form, or use incrementing x/y values to create outward spirals. This focused sub-skill teaches the math behind spiral positioning.

Dependencies:
* T19.G4.01: Create spiral patterns with incrementing loop variables







ID: T19.G4.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Define a custom block for a tile pattern
Description: Students create a custom block (no parameters yet) that draws a geometric tile pattern using draw blocks (draw rectangle, draw oval). They understand that the custom block encapsulates the drawing sequence and can be called multiple times.

Dependencies:
* T19.G3.09: Create a repeating border pattern using loops
* T11.G4.01: Define and call a simple custom block (no parameters)







ID: T19.G4.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Call custom tile block in nested loops
Description: Students use nested loops to call their custom tile block across the stage, creating tessellation patterns. They combine modular code structure (custom block) with iteration (nested loops) and coordinate calculations (positioning before each call).

Dependencies:
* T19.G4.02: Define a custom block for a tile pattern
* T19.G3.11: Fill a grid with tiles using nested loops







ID: T19.G4.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Control art with parameter variables
Description: Students expose variables (e.g., sides, size, rotation) through sliders or input prompts and show how changing a value reshapes the art. They use the variable monitor or "ask and wait" to get user input, then use those values throughout their drawing code.

Dependencies:
* T19.G4.01: Create spiral patterns with incrementing loop variables
* T09.G3.01.04: Display variable value on stage using the variable monitor







ID: T19.G4.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create smooth animations with small movements
Description: Students create animated drawings by using small movements in forever loops with wait blocks. They understand that small increments create smooth motion. They animate simple properties like position, rotation, or size changes over time.

Dependencies:
* T19.G4.04: Control art with parameter variables
* T07.G3.03: Build a forever loop for simple animation







ID: T19.G4.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create a color palette list
Description: Students create a list containing 3-5 hex color values (#RRGGBBAA format) representing their color palette. They understand that lists can store color values just like numbers or text. They manually add colors to the list.

Dependencies:
* T19.G3.05: Change trail color using hex color values
* T10.G4.01: Create a list and add items through code







ID: T19.G4.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply colors from a palette list in loops
Description: Students iterate through their color palette list in a loop, using each color for different shapes in their pattern. They use "item # of list" to access colors and apply them to their drawing blocks, creating cohesive color schemes in their algorithmic art.

Dependencies:
* T19.G4.06: Create a color palette list
* T10.G4.02: Use a loop to iterate through a list







ID: T19.G4.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Debug a multi-loop art script
Description: Students receive a script whose nested loops miscount, overlap, or use the wrong color. They identify the issue by tracing loop iterations and adjust counts, moves, or color changes. They verify their fix produces the intended visual output.

Dependencies:
* T19.G3.14: Debug a simple drawing script with incorrect output
* T19.G3.11: Fill a grid with tiles using nested loops







ID: T19.G4.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Recolor art with button clicks
Description: Learners add a button event (when sprite clicked) that recolors the art with a different palette. They introduce light interactivity by changing color variables or cycling through a color list when the user clicks.

Dependencies:
* T19.G4.07: Apply colors from a palette list in loops
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence







ID: T19.G4.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Redraw art with key events
Description: Students add keyboard event handlers (when key pressed) that clear and re-draw the art tile with modified parameters. This introduces full interactivity where different keys create different variations of the same algorithmic pattern.

Dependencies:
* T19.G4.09: Recolor art with button clicks
* T06.G3.02: Use key‑press events







ID: T19.G4.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Map small data lists to drawing positions
Description: Students create a simple list of 3-5 numbers and use each value to control drawing positions (e.g., x-coordinates or heights). They practice the basic concept of reading data from a list and using it in go to or draw blocks to create visual output, preparing for full data visualization.

Dependencies:
* T19.G4.07: Apply colors from a palette list in loops
* T10.G4.02: Use a loop to iterate through a list







ID: T19.G4.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Generate colors programmatically using HSV parameters
Description: Students use the color reporter block with HSV parameters (hue 0-100, saturation 0-100, brightness 0-100) to create colors programmatically. They understand that varying these parameters in loops creates gradients and dynamic palettes, going beyond fixed hex colors.

Dependencies:
* T19.G4.06: Create a color palette list


ID: T19.G4.12.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create a rainbow gradient by incrementing hue
Description: Students create a rainbow gradient effect by incrementing the hue value in a loop while keeping saturation and brightness constant. They produce smooth color transitions from red through yellow, green, blue, and back to red (hue 0-100 wrapping). This demonstrates how a single changing parameter creates rich visual variety.

Dependencies:
* T19.G4.12: Generate colors programmatically using HSV parameters




ID: T19.G4.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use console logging to trace art variable values
Description: Students add console log blocks to their drawing scripts to print variable values (position, color, loop counter) during execution. They use the console panel to trace how values change each iteration and identify where calculations go wrong. They debug art algorithms by reading console output to find logic errors.

Dependencies:
* T19.G4.01: Create spiral patterns with incrementing loop variables
* T08.G3.04: Use a simple if in a script




ID: T19.G4.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create slider widgets to control art parameters
Description: Students use the Widget blocks to create slider controls that adjust art parameters in real-time. They create a slider widget with min/max values, read the slider value into a variable, and use that variable to control drawing properties (size, spacing, rotation). They experience how widgets enable intuitive user interaction with parametric art.

Dependencies:
* T19.G4.04: Control art with parameter variables
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




## GRADE 5 SKILLS (Data Visualization & 3D Introduction)






ID: T19.G5.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create a bar chart by mapping list values to rectangle heights
Description: Students read values from a single list of numbers and implement algorithms to map data to visual properties. They iterate through the list, drawing rectangles with heights proportional to each data value. They focus on translating data values to coordinates and dimensions, creating a simple bar chart visualization.

Dependencies:
* T19.G4.11: Map small data lists to drawing positions
* T10.G4.02: Use a loop to iterate through a list


ID: T19.G5.01.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Scale data values to fit the drawing canvas
Description: Students calculate a scaling factor to fit data values within the canvas height. They divide the canvas height by the maximum data value to get a multiplier, then apply it to all values. This ensures their visualization fits the screen regardless of the data range.

Dependencies:
* T19.G5.01: Create a bar chart by mapping list values to rectangle heights







ID: T19.G5.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Map data to two visual properties
Description: Students extend single-list visualization by using data to control TWO visual properties simultaneously (e.g., list values control both height and color of rectangles, or both x-position and size of circles). They use simple calculations or parallel lists to derive the second property from data.

Dependencies:
* T19.G5.01: Create a bar chart by mapping list values to rectangle heights
* T10.G5.01: Use nested lists to represent structured data







ID: T19.G5.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Animate a pattern with a counter variable
Description: Students use a forever loop plus a counter variable to gradually grow, rotate, or fade a pattern. They increment the counter each frame and use it to modify drawing parameters, creating animated generative art that evolves over time.

Dependencies:
* T19.G4.05: Create smooth animations with small movements
* T09.G3.02: Use change block to increase a variable







ID: T19.G5.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Make art respond to mouse position
Description: Students use mouse x and mouse y reporter blocks to make art change based on cursor position. They map mouse coordinates to drawing parameters (colors, sizes, positions) so the artwork responds dynamically as the user moves the mouse.

Dependencies:
* T19.G4.10: Redraw art with key events
* T06.G3.03: Use mouse position in scripts







ID: T19.G5.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Make art respond to keyboard input
Description: Students add key-sensing blocks to continuously check which keys are pressed and modify art parameters accordingly. Unlike discrete key events, this creates continuous interactive control where holding keys affects the art in real-time.

Dependencies:
* T19.G5.04: Make art respond to mouse position







ID: T19.G5.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create fractal-like nested patterns
Description: Students draw a pattern, then nest smaller versions inside or around it using loops and custom blocks, mimicking fractal depth. They use size variables that decrease with each nesting level, creating recursive-looking patterns using iteration (not actual recursion).

Dependencies:
* T19.G4.03: Call custom tile block in nested loops
* T11.G4.03: Add parameters to custom blocks







ID: T19.G5.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Set up a 3D scene and position the camera for art viewing
Description: Students use the `initialize 3D world` block to set up a 3D environment. They understand the 3D coordinate system: x (left-right), y (up-down), z (forward-back). They learn how to position the camera to view their 3D art from different angles. They understand that 3D art uses depth as an additional creative dimension.

Dependencies:
* T19.G4.01: Create spiral patterns with incrementing loop variables
* T18.G5.01: Initialize a 3D world







ID: T19.G5.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add box shapes algorithmically in loops
Description: Students use the `add box` block inside loops to create patterns with boxes in 3D space. They calculate positions using loop variables and place multiple boxes at different coordinates. They control width, height, and depth to create varied structures. They focus on algorithmic placement, not manual positioning.

Dependencies:
* T19.G5.07: Set up a 3D scene and position the camera for art viewing
* T07.G3.01: Use a counted repeat loop







ID: T19.G5.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add sphere shapes algorithmically in loops
Description: Students use the `add sphere` block inside loops to create patterns with spheres in 3D space. They calculate positions using loop variables and mathematical formulas. They control diameter and segments parameters to balance smoothness with performance. They combine spheres with boxes to create varied 3D compositions.

Dependencies:
* T19.G5.08: Add box shapes algorithmically in loops







ID: T19.G5.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add cylinder shapes algorithmically in loops
Description: Students use the `add cylinder` block inside loops to create patterns with cylinders in 3D space. They calculate positions and use rotation to orient cylinders in different directions. They control height and diameter parameters. They understand how cylinders can create posts, pillars, or tubes in their 3D algorithmic art.

Dependencies:
* T19.G5.09: Add sphere shapes algorithmically in loops







ID: T19.G5.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create 3D geometric patterns with multiple shapes
Description: Students combine boxes, spheres, and cylinders in algorithmic patterns using loops and mathematical formulas. They create 3D structures where shape type varies based on loop conditions (e.g., every 3rd position uses sphere instead of box). They focus on composition and spatial arrangement in three dimensions.

Dependencies:
* T19.G5.10: Add cylinder shapes algorithmically in loops
* T08.G3.04: Use a simple if in a script







ID: T19.G5.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Justify visual encoding choices in data visualization
Description: Learners justify why certain colors, sizes, or motions represent data categories in their visualizations. They explain the reasoning behind their visual encoding choices (e.g., "I used red for high values because red signals intensity" or "I used position for time because it shows progression"). This reinforces the data-art connection and develops design thinking.

Dependencies:
* T19.G5.02: Map data to two visual properties


ID: T19.G5.12.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Choose colors for accessibility and meaning
Description: Students consider color accessibility when designing visualizations: avoiding red-green combinations that are difficult for colorblind viewers, using high contrast for readability, and choosing colors with cultural meaning (warm/cool, warning, calm). They evaluate their color choices for inclusivity.

Dependencies:
* T19.G5.12: Justify visual encoding choices in data visualization




ID: T19.G5.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create video-sensing art with motion detection
Description: Students use the video sensing blocks to detect motion from the camera and map it to drawing actions. They use "video motion on sprite" to trigger drawing when movement is detected, or "video direction" to control drawing direction. They create interactive art that responds to the viewer's physical movements in real-time.

Dependencies:
* T19.G5.04: Make art respond to mouse position
* T06.G3.03: Use mouse position in scripts




ID: T19.G5.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create sound-reactive art with microphone input
Description: Students use the "loudness" sensing block to detect sound levels from the microphone and map them to drawing parameters. They create art where louder sounds create bigger shapes, brighter colors, or faster movement. They understand that loudness returns a value from 0-100 that can drive visual changes.

Dependencies:
* T19.G5.04: Make art respond to mouse position
* T06.G3.03: Use mouse position in scripts




ID: T19.G5.15
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create typographic art with text labels
Description: Students use label widget blocks to place text elements as part of their algorithmic compositions. They position text labels at calculated coordinates in loops, vary font sizes and colors algorithmically, and create text-based patterns (concrete poetry, word clouds, or decorative typography). They explore how text becomes visual art when arranged with algorithmic precision.

Dependencies:
* T19.G5.03: Animate a pattern with a counter variable
* T10.G4.02: Use a loop to iterate through a list




## GRADE 6 SKILLS (Advanced Patterns & 3D Art)






ID: T19.G6.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Trace and explain an art algorithm
Description: Students examine code with comments and section markers containing nested loops, variables, and color changes. They explain what each section (identified by comments) contributes to the final artwork. They trace variable values through iterations and explain how loops, conditionals, and calculations combine to create the visual result.

Dependencies:
* T19.G5.06: Create fractal-like nested patterns
* T07.G5.01: Use a counted repeat loop







ID: T19.G6.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Refactor repetitive art into loops
Description: Learners take a long, repetitive art script (many similar blocks with slightly different values) and reorganize it using loops with incrementing variables. They maintain the same visual result while dramatically reducing code length. They demonstrate understanding of loop mechanics and abstraction.

Dependencies:
* T19.G6.01: Trace and explain an art algorithm
* T11.G5.01: Identify repeated code that could become a custom block







ID: T19.G6.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Refactor repetitive art into custom blocks
Description: Students identify repeated drawing sequences and extract them into parameterized custom blocks. They replace multiple similar code sections with custom block calls that use different parameter values. They demonstrate understanding of abstraction and code modularity.

Dependencies:
* T19.G6.02: Refactor repetitive art into loops
* T11.G5.03: Use parameters in custom blocks







ID: T19.G6.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use variables and conditionals to branch designs
Description: Students create art where colors/shapes change based on variable thresholds. They use conditionals to alternate palettes when a counter is even, draw special motifs every 5th loop iteration, or change patterns based on position ranges. They combine variables, conditionals, and drawing to create complex rule-based art.

Dependencies:
* T19.G5.03: Animate a pattern with a counter variable
* T08.G5.02: Use a simple if in a script







ID: T19.G6.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement multi-field data visualization
Description: Students implement algorithms to process structured data (nested lists representing objects with multiple attributes) and map different data fields to distinct visual properties. They draw shapes where x-position comes from one field, height from another, and color is determined by a third field value. They use iteration and conditional logic to process 2-3 data attributes simultaneously.

Dependencies:
* T19.G5.02: Map data to two visual properties
* T10.G5.01: Use nested lists to represent structured data







ID: T19.G6.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply sine functions to create wave patterns
Description: Learners use sine functions (sine of loop counter) to produce smooth curves and waves in their art. They understand that sine values oscillate between -1 and 1, creating natural wave motion. They map sine outputs to positions, creating flowing patterns. They explain the relationship between the sine formula and resulting pattern.

Dependencies:
* T19.G5.06: Create fractal-like nested patterns
* T09.G5.01: Model a character trait or game stat with a variable







ID: T19.G6.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply cosine functions to create circular patterns
Description: Students use both sine and cosine functions together to calculate positions on circles and spirals. They understand that sine gives y-coordinate and cosine gives x-coordinate for circular motion. They create circular arrangements of shapes by calculating positions with (cos(angle), sin(angle)).

Dependencies:
* T19.G6.06: Apply sine functions to create wave patterns




ID: T19.G6.07.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create Lissajous curves with sine and cosine
Description: Students generate Lissajous curves by using different frequencies for x (cosine) and y (sine) oscillations. They experiment with frequency ratios (1:2, 2:3, 3:4) to create figure-eight shapes and complex loops. They understand that ratio relationships produce predictable, mathematically beautiful patterns used in oscilloscope art.

Dependencies:
* T19.G6.07: Apply cosine functions to create circular patterns




ID: T19.G6.07.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create spirograph patterns with parametric equations
Description: Students implement spirograph-like patterns using parametric equations combining multiple sine/cosine terms. They layer oscillations at different scales (large circle + small circle rotations) to create intricate geometric designs. They control parameters like inner/outer radii and rotation speeds to generate varied hypotrochoid and epitrochoid curves.

Dependencies:
* T19.G6.07.01: Create Lissajous curves with sine and cosine







ID: T19.G6.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply color materials to 3D shapes
Description: Students use material blocks to set colors on 3D shapes with diffusion (matte) or emission (glowing) properties. They understand that materials determine how surfaces appear. They apply different colors to different shapes in their algorithmic 3D art, creating visual variety and emphasis.

Dependencies:
* T19.G5.11: Create 3D geometric patterns with multiple shapes







ID: T19.G6.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply texture materials to 3D shapes
Description: Students apply texture materials from CreatiCode's texture library to 3D shapes. They understand that textures add surface detail without additional geometry. They experiment with different textures (wood, metal, stone, fabric) and see how textures change the artistic appearance of their 3D patterns.

Dependencies:
* T19.G6.08: Apply color materials to 3D shapes







ID: T19.G6.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply roughness properties to 3D materials
Description: Students adjust roughness properties (0 = shiny/reflective, 1 = matte/rough) to control surface appearance. They understand that roughness affects how light interacts with surfaces. They use varying roughness values in their algorithmic 3D art to create visual interest and material variety.

Dependencies:
* T19.G6.09: Apply texture materials to 3D shapes







ID: T19.G6.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create 3D curves from calculated point lists
Description: Students generate point lists using loops and math formulas (sine/cosine for spirals, parametric equations for helixes). They store calculated x, y, z positions in nested lists. They use these point lists with 3D curve blocks to create line sculptures in space. They understand how 2D math concepts extend to 3D with z-coordinates.

Dependencies:
* T19.G6.07: Apply cosine functions to create circular patterns
* T10.G5.01: Use nested lists to represent structured data







ID: T19.G6.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create interactive 3D generative art
Description: Students add interactivity to their 3D algorithmic art by mapping keyboard/mouse input to 3D transformations, camera angles, or generative parameters. They create art that viewers can explore and manipulate in real-time. They use key sensing or mouse position to control 3D art parameters dynamically.

Dependencies:
* T19.G5.05: Make art respond to keyboard input
* T19.G5.11: Create 3D geometric patterns with multiple shapes




ID: T19.G6.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create hand-tracking art with finger positions
Description: Students use CreatiCode's hand tracking blocks to detect hand landmarks and create art that responds to finger positions. They access individual finger positions from the hand tracking table variable and use them to control drawing position, color, or brush size. They create "air drawing" experiences where viewers paint by moving their hands in front of the camera.

Dependencies:
* T19.G5.13: Create video-sensing art with motion detection
* T10.G5.01: Use nested lists to represent structured data




ID: T19.G6.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use finger gestures to control art parameters
Description: Students use hand tracking to detect finger curl angles and use them as art parameters. They read finger curl values (0-180 degrees) to control art properties like brush size (closed fist = small, open hand = large), color hue, or pattern density. They create art tools that respond to natural hand gestures without touching any physical controls.

Dependencies:
* T19.G6.13: Create hand-tracking art with finger positions




ID: T19.G6.15
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Debug art algorithms using step-by-step execution
Description: Students use CreatiCode's step-by-step execution feature to walk through their drawing algorithms one block at a time. They observe how each block changes the visual output and variable values. They identify logic errors by watching where the actual drawing diverges from their intended design. They practice systematic debugging of complex multi-loop art code.

Dependencies:
* T19.G4.13: Use console logging to trace art variable values
* T19.G6.01: Trace and explain an art algorithm




## GRADE 7 SKILLS (Advanced Algorithms & Systems)






ID: T19.G7.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Compare efficiency of art algorithms
Description: Students evaluate two code samples that draw the same design but with different performance characteristics. They identify which uses fewer operations, has better loop structure, or avoids redundant calculations. They choose the more efficient approach and justify why based on operation count or execution time.

Dependencies:
* T19.G6.01: Trace and explain an art algorithm
* T07.G6.05: Fix a loop that runs too many or too few times







ID: T19.G7.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use repeat-until loops in art algorithms
Description: Learners replace fixed `repeat` blocks with `repeat until` loops so a drawing continues until reaching a boundary or meeting a condition. They use conditionals to determine when the pattern is complete (e.g., repeat until x position > 400, or repeat until color brightness < 10). This creates more flexible, adaptive art algorithms.

Dependencies:
* T19.G6.04: Use variables and conditionals to branch designs
* T08.G6.01: Use conditionals to control simulation steps







ID: T19.G7.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Study parameter impact on aesthetics
Description: Students create a parameterized art piece with exposed controls (sliders for randomness, angle change, speed). They systematically adjust each parameter one at a time and document in a table how each change affects specific aesthetic qualities (symmetry, balance, density, motion). They analyze which parameters have the strongest visual impact and explain why.

Dependencies:
* T19.G6.04: Use variables and conditionals to branch designs
* T09.G6.01: Model real-world quantities using variables and formulas







ID: T19.G7.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Analyze real generative artworks
Description: Students examine professional algorithmic art or natural patterns (examples: Vera Molnár, Manfred Mohr, fractal geometry in nature) and write pseudocode or create simplified CreatiCode implementations showing the loops, math formulas, and randomness that likely generated them. They explain their reasoning for each algorithmic choice and compare their implementation to the original.

Dependencies:
* T19.G6.01: Trace and explain an art algorithm
* T19.G6.07: Apply cosine functions to create circular patterns







ID: T19.G7.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Configure basic particle emitter properties
Description: Students create simple stationary particle effects using the `add prebuilt emitter` block. They adjust particle properties: color, lifetime (max life parameter), texture size, source size, and speed. They observe how each property change affects the visual result and explain that particles are temporary visual elements generated continuously.

Dependencies:
* T19.G6.04: Use variables and conditionals to branch designs







ID: T19.G7.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Configure particle color gradients
Description: Students create particle emitters with color gradients that change over particle lifetime. They set start color and end color, creating effects like fire (yellow to red to black) or magic (blue to purple to transparent). They understand how color transitions create dynamic visual effects.

Dependencies:
* T19.G7.05: Configure basic particle emitter properties







ID: T19.G7.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Configure particle size changes
Description: Students configure particles to change size over their lifetime (start size, end size). They create effects like growing bubbles, shrinking sparks, or expanding explosions. They understand how size changes affect perceived particle behavior and energy.

Dependencies:
* T19.G7.06: Configure particle color gradients







ID: T19.G7.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create particle-based generative art
Description: Students create standalone particle-based algorithmic art by combining color gradients, size changes, emission patterns, and movement. They use particle systems to create effects like flowing streams, energy fields, or abstract motion art. They control emitter position algorithmically, moving it in patterns to paint with particles.

Dependencies:
* T19.G7.07: Configure particle size changes







ID: T19.G7.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement L-system string generation
Description: Students implement L-system (Lindenmayer system) rules by starting with an axiom string and repeatedly applying replacement rules. They understand that L-systems use string rewriting: each character is replaced according to rules (e.g., "A" → "AB", "B" → "A"). They generate strings through multiple iterations and see how simple rules create complex patterns.

Dependencies:
* T19.G6.07: Apply cosine functions to create circular patterns
* T10.G6.02: Manipulate text with string operations







ID: T19.G7.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Draw L-system fractal trees
Description: Students translate L-system strings into visual patterns by interpreting characters as drawing commands (F = forward, + = turn left, - = turn right, [ = save position, ] = restore position). They draw fractal trees and Koch curves by processing the generated strings. They see how recursive rules create self-similar patterns.

Dependencies:
* T19.G7.09: Implement L-system string generation
* T11.G7.02: Understand recursive thinking through examples







ID: T19.G7.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement elementary cellular automaton rule lookup
Description: Students create a rule lookup table that maps each 3-cell neighborhood pattern (000, 001, 010, ..., 111) to a next-state value (0 or 1). They implement rule numbers (e.g., Rule 30 = 00011110 in binary) by converting the rule number to its 8-bit representation and storing results in a list. They test their lookup by manually tracing specific neighborhood patterns.

Dependencies:
* T19.G7.04: Analyze real generative artworks
* T10.G6.03: Implement algorithms using 2D tables




ID: T19.G7.11.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply cellular automaton rules to generate rows
Description: Students use their rule lookup table to generate new rows from previous rows. They iterate through each cell, extract its 3-cell neighborhood, look up the next state, and build the new row. They stack multiple generations vertically to visualize the automaton's evolution. They observe how different rules produce distinct visual patterns.

Dependencies:
* T19.G7.11: Implement elementary cellular automaton rule lookup




ID: T19.G7.11.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Visualize cellular automaton patterns
Description: Students draw cellular automaton patterns by mapping cell states to colors and positions. They use draw blocks in nested loops to render the 2D grid of generations. They experiment with different color mappings (binary colors, gradients based on neighbor counts) to create visually striking representations of emergent patterns.

Dependencies:
* T19.G7.11.01: Apply cellular automaton rules to generate rows







ID: T19.G7.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Combine two generative techniques in one artwork
Description: Students integrate two generative techniques (e.g., L-system trees with particle effects, or cellular automata patterns with mathematical curves) in a single project. They identify how one technique can feed into another (e.g., L-system endpoints trigger particle emission) and implement the connection.

Dependencies:
* T19.G7.10: Draw L-system fractal trees
* T19.G7.11.02: Visualize cellular automaton patterns




ID: T19.G7.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add controlled randomness to generative systems
Description: Students add controlled randomness to their hybrid generative art by varying parameters within defined ranges (e.g., random angle variations in L-systems between -15° and +15°, or random color selection from a palette). They explain how constraints keep randomness artistically coherent.

Dependencies:
* T19.G7.12: Combine two generative techniques in one artwork







ID: T19.G7.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add point lights to 3D algorithmic art
Description: Students add point lights (emitting equally in all directions) to their 3D generative art. They position lights algorithmically using loop variables. They control light color and intensity to create mood. They understand how light position affects shadows and highlights on their 3D shapes.

Dependencies:
* T19.G5.11: Create 3D geometric patterns with multiple shapes







ID: T19.G7.15
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Add directional lights to 3D algorithmic art
Description: Students add directional lights (parallel rays like sunlight) to their 3D art. They control direction vector to determine where light comes from. They understand that directional lights don't have position (infinitely far away) but do have direction. They compare effects of point vs directional lights on their sculptures.

Dependencies:
* T19.G7.14: Add point lights to 3D algorithmic art







ID: T19.G7.16
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use lighting to enhance 3D art mood
Description: Students use multiple lights (point, directional, ambient) to create dramatic effects in their 3D generative art. They adjust light colors and intensities to create mood (warm vs cool, bright vs dark). They position lights to highlight patterns and create intentional shadows. They understand lighting as an artistic tool, not just illumination.

Dependencies:
* T19.G7.15: Add directional lights to 3D algorithmic art







ID: T19.G7.17
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Combine 3D shapes with particle effects
Description: Students create dynamic 3D sculptures by combining algorithmic 3D shape placement with particle systems. They emit particles from shape positions, attach particle trails to moving 3D objects, or use particles to highlight 3D patterns. They understand how particles add motion and energy to static 3D geometry.

Dependencies:
* T19.G7.08: Create particle-based generative art
* T19.G5.11: Create 3D geometric patterns with multiple shapes







ID: T19.G7.18
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Generate custom 3D shapes from vertex lists
Description: Students create original 3D shapes by calculating vertex positions using algorithms. They use loops to calculate x, y, z coordinates for each vertex based on mathematical formulas. They store positions in nested lists. They use these vertex lists with 3D shape creation blocks (add column, add cone with custom profiles) to generate unique geometric art beyond standard primitives.

Dependencies:
* T19.G6.11: Create 3D curves from calculated point lists
* T10.G5.01: Use nested lists to represent structured data




ID: T19.G7.19
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Generate AI sprites with algorithmic prompts
Description: Students use the AI image generation blocks to create sprites from text prompts that they construct algorithmically. They build prompts by combining variables and lists (e.g., randomly selecting adjectives and subjects) to generate varied AI sprites. They use loops to generate multiple unique AI-created elements for their compositions. They integrate AI-generated assets into algorithmic art pieces.

Dependencies:
* T19.G7.13: Add controlled randomness to generative systems
* T20.G5.02: Build a prompt with variables for AI image generation




ID: T19.G7.20
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create body-tracking interactive installations
Description: Students use CreatiCode's body tracking blocks to detect full body pose keypoints and create interactive art installations. They read body keypoint positions (head, shoulders, elbows, hands, hips, knees, feet) from the tracking table and use them to control large-scale visual elements. They create art where the viewer's entire body becomes the controller, mapping body posture to colors, shapes, or animations.

Dependencies:
* T19.G6.14: Use finger gestures to control art parameters
* T10.G6.03: Implement algorithms using 2D tables




ID: T19.G7.21
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create physics-based generative art with 2D physics
Description: Students use CreatiCode's 2D physics engine to create generative art driven by physical simulation. They spawn physics-enabled shapes (circles, rectangles) with random initial velocities, apply gravity and forces, and let physics determine how shapes interact, bounce, and settle. They create compositions where the algorithm sets initial conditions but physics simulation determines the final visual outcome.

Dependencies:
* T19.G7.13: Add controlled randomness to generative systems
* T17.G6.01: Initialize a 2D physics world


ID: T19.G7.22
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply color theory principles in algorithmic palettes
Description: Students implement algorithmic color selection based on color theory: complementary colors (opposite on hue wheel), analogous colors (adjacent hues), triadic schemes (three evenly spaced hues). They calculate colors mathematically from a base hue and apply these harmonious palettes to their generative art. They evaluate how color relationships affect visual harmony.

Dependencies:
* T19.G4.12.01: Create a rainbow gradient by incrementing hue
* T19.G6.04: Use variables and conditionals to branch designs


ID: T19.G7.23
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create compositionally balanced layouts algorithmically
Description: Students implement algorithms that consider visual composition: rule of thirds placement, golden ratio proportions, visual weight distribution, and focal point creation. They use mathematical formulas to position elements at compositionally strong locations. They analyze how algorithmic composition compares to intuitive human composition decisions.

Dependencies:
* T19.G7.03: Study parameter impact on aesthetics
* T19.G6.07.02: Create spirograph patterns with parametric equations




## GRADE 8 SKILLS (Expert Techniques & Theory)






ID: T19.G8.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement multi-dimensional data mapping
Description: Students implement sophisticated algorithms to process complex datasets with 4+ attributes and map them to multiple visual channels simultaneously (size, color, motion, position, rotation, opacity). They use custom scaling functions to normalize different data ranges to visual ranges. They implement optimization strategies for handling larger datasets. This goes beyond G6 by handling more dimensions and considering performance.

Dependencies:
* T19.G6.05: Implement multi-field data visualization
* T10.G7.01: Implement algorithms using complex nested data structures







ID: T19.G8.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create constrained generative artwork
Description: Students combine randomness with constraints implemented as conditionals and boundary checks. They enforce limited color palettes (only use colors from approved list), symmetry rules (mirror operations), and bounding boxes (spatial constraints checked with if statements). The output is unique due to randomness yet cohesive due to constraints. They explain how constraints guide creativity.

Dependencies:
* T19.G7.13: Add controlled randomness to generative systems
* T09.G6.01: Model real-world quantities using variables and formulas







ID: T19.G8.03
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Evaluate authorship in generative art
Description: Students write a position paper or participate in structured discussion analyzing authorship questions in algorithmic art. They address: Who is the artist—coder, algorithm, or viewer? How do we evaluate originality when code produces unique outputs? They discuss intellectual property (can you copyright an algorithm? a specific output?). They defend their positions with examples from art history and current practice.

Dependencies:
* T19.G7.04: Analyze real generative artworks
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design







ID: T19.G8.04
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Profile rendering performance
Description: Students use timing methods to measure how long different parts of their art algorithm take to execute. They identify bottlenecks (nested loops with heavy operations, excessive drawing calls, redundant calculations). They understand frame rate concepts and measure frames per second in animated art.

Dependencies:
* T19.G7.01: Compare efficiency of art algorithms
* T12.G6.01: Trace complex code with multiple variables







ID: T19.G8.05
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Optimize algorithms to improve frame rate
Description: Learners refactor slow algorithms using optimization techniques: reduce redundant calculations by storing values, decrease loop iterations by increasing step size, batch drawing operations, or cull off-screen elements. They profile before and after optimization to measure improvement. They hit target frame rates (30+ fps) while maintaining visual quality.

Dependencies:
* T19.G8.04: Profile rendering performance
* T07.G6.02: Refactor complex repeated patterns into loops with variables







ID: T19.G8.06
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement value noise for organic patterns
Description: Students implement basic value noise by generating random values at grid points and interpolating between them. They use linear or smooth interpolation to create continuous gradients from discrete random samples. They apply noise values to control color, position offsets, or size variations, creating organic-looking patterns that avoid the harshness of pure randomness.

Dependencies:
* T19.G7.13: Add controlled randomness to generative systems
* T10.G6.03: Implement algorithms using 2D tables




ID: T19.G8.06.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Layer multiple noise octaves for detail
Description: Students combine multiple layers of noise at different scales (octaves) to create rich, detailed patterns. They add high-frequency noise for fine detail and low-frequency noise for large-scale variation. They control amplitude and frequency per octave using multipliers. They create fractal-like patterns (fbm - fractional Brownian motion) for natural textures like clouds or terrain.

Dependencies:
* T19.G8.06: Implement value noise for organic patterns




ID: T19.G8.06.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply noise to modulate art parameters
Description: Students use noise values to modulate various art parameters: color hue shifts, line thickness variation, shape displacement, rotation offsets. They map noise output (-1 to 1 or 0 to 1) to appropriate parameter ranges. They create cohesive organic variation across entire compositions, moving beyond random-per-element to spatially coherent randomness.

Dependencies:
* T19.G8.06.01: Layer multiple noise octaves for detail







ID: T19.G8.07
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Apply procedural materials to 3D art
Description: Students apply their procedurally-generated texture patterns to 3D shapes in algorithmic art. They map calculated patterns to material color, roughness, or emission. They create unique 3D sculptures with custom algorithmic surfaces. They understand how procedural textures enable artistic control beyond pre-made texture libraries.

Dependencies:
* T19.G8.06.02: Apply noise to modulate art parameters
* T19.G6.10: Apply roughness properties to 3D materials







ID: T19.G8.08
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement dynamic lighting systems
Description: Students create lighting that changes over time or responds to art parameters. They animate light positions in loops, adjust light colors based on data or music, or create pulsing light intensity. They implement multiple dynamic lights that interact with their 3D algorithmic sculptures, creating atmospheric and dramatic effects.

Dependencies:
* T19.G7.16: Use lighting to enhance 3D art mood
* T19.G5.03: Animate a pattern with a counter variable







ID: T19.G8.09
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create advanced particle-based compositions
Description: Students create sophisticated particle systems with multiple emitters, custom movement patterns (attracted to points, flowing along paths, orbital motion), and conditional particle behavior (change color when crossing boundaries, emit sub-particles on collision). They choreograph particle systems to create complex visual narratives and abstract compositions.

Dependencies:
* T19.G7.08: Create particle-based generative art
* T08.G6.01: Use conditionals to control simulation steps







ID: T19.G8.10
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Plan a multi-technique generative art project
Description: Students design and outline a generative art project that integrates at least three advanced techniques (e.g., 3D geometry with procedural materials, dynamic lighting, particle systems). They create a planning document specifying which techniques to combine, how they will interact, and what aesthetic goals to achieve.

Dependencies:
* T19.G8.07: Apply procedural materials to 3D art
* T19.G8.08: Implement dynamic lighting systems
* T19.G8.09: Create advanced particle-based compositions
* T19.G8.02: Create constrained generative artwork




ID: T19.G8.10.01
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement a multi-technique generative artwork
Description: Students build their planned generative art piece by coding the integration of multiple advanced techniques. They combine 3D geometry, procedural materials, dynamic lighting, and/or particle systems into a single cohesive project. They test and refine the interactions between techniques.

Dependencies:
* T19.G8.10: Plan a multi-technique generative art project




ID: T19.G8.10.02
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Document and present generative artwork
Description: Students document their generative art project, explaining their artistic intent, technical implementation choices, and algorithmic decisions. They present their work, demonstrating how code creates art and reflecting on the creative process.

Dependencies:
* T19.G8.10.01: Implement a multi-technique generative artwork




ID: T19.G8.11
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create AI-human collaborative art systems
Description: Students design and implement art systems where AI generation and algorithmic code work together. They use ChatGPT blocks to generate descriptions, feed them to AI image generation, then algorithmically process or arrange the results. They create art pipelines that combine human-defined algorithms with AI creativity, exploring questions of authorship in hybrid systems.

Dependencies:
* T19.G7.19: Generate AI sprites with algorithmic prompts
* T19.G8.03: Evaluate authorship in generative art




ID: T19.G8.12
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create adaptive art that responds to multiple sensor inputs
Description: Students create sophisticated interactive art installations that respond to multiple input sources simultaneously: combining hand tracking, body tracking, video motion sensing, keyboard, and mouse inputs. They implement priority systems when inputs conflict and create smooth transitions between interaction modes. They design art experiences that adapt to how viewers choose to engage.

Dependencies:
* T19.G7.20: Create body-tracking interactive installations
* T19.G6.12: Create interactive 3D generative art




ID: T19.G8.13
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Design real-time collaborative networked art
Description: Students use CreatiCode's multiplayer capabilities to create art that multiple users can contribute to simultaneously over the network. They implement synchronized variables for shared canvas state, use cloud variables to persist collaborative art, and design interaction rules that allow multiple artists to create together without conflict. They explore how networked collaboration changes the nature of artistic creation.

Dependencies:
* T19.G8.12: Create adaptive art that responds to multiple sensor inputs
* T31.G7.01: Send and receive messages between players in real-time




ID: T19.G8.14
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement flow field navigation for particles
Description: Students create a 2D grid of direction vectors (angles stored in a table) that guide particle movement. Particles sample the grid at their current position to determine movement direction. They populate the flow field using noise functions or mathematical formulas. They create organic, flowing motion paths that look natural and cohesive.

Dependencies:
* T19.G8.06.02: Apply noise to modulate art parameters
* T19.G8.09: Create advanced particle-based compositions




ID: T19.G8.15
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create animated flow field visualizations
Description: Students animate flow fields by slowly changing the underlying direction vectors over time. They use time-varying noise or rotating angle offsets to create hypnotic, ever-changing flow patterns. They balance change rate with visual coherence, creating smooth transitions that maintain artistic intent while introducing temporal variation.

Dependencies:
* T19.G8.14: Implement flow field navigation for particles




ID: T19.G8.16
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Analyze computational complexity of art algorithms
Description: Students analyze the time and space complexity of their generative art algorithms using Big-O notation concepts. They identify O(n), O(n²), and O(n³) patterns in nested loops. They predict how performance will scale with increased resolution, particle count, or iteration depth. They make informed decisions about algorithm design based on complexity analysis.

Dependencies:
* T19.G8.05: Optimize algorithms to improve frame rate
* T12.G7.01: Trace complex code with multiple variables and functions




ID: T19.G8.17
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Design art systems with separation of concerns
Description: Students architect large generative art projects by separating data generation (math/noise), state management (variables/lists), rendering (draw blocks), and interaction (events/input). They use custom blocks to encapsulate each concern. They design systems where each part can be modified independently, demonstrating software engineering principles in creative coding contexts.

Dependencies:
* T19.G8.10.01: Implement a multi-technique generative artwork
* T11.G7.01: Design custom blocks for code organization




ID: T19.G8.18
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Use XO AI assistant to plan generative art algorithms
Description: Students use CreatiCode's XO AI assistant to brainstorm and refine generative art concepts. They formulate questions about mathematical formulas for patterns, ask for suggestions on parameter ranges, and get help structuring complex algorithms. They learn to use AI as a creative collaborator while maintaining artistic vision and making final implementation decisions themselves.

Dependencies:
* T19.G8.10: Plan a multi-technique generative art project
* T20.G7.03: Evaluate and refine AI responses for quality




ID: T19.G8.19
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Build and iterate on generative art variations
Description: Students create a parameterized generative art system and produce a series of 5+ distinct variations by systematically adjusting parameters. They document the relationship between parameters and visual outcomes, explaining which combinations create successful compositions. They practice the iterative refinement process used by professional generative artists.

Dependencies:
* T19.G8.02: Create constrained generative artwork
* T19.G7.03: Study parameter impact on aesthetics




ID: T19.G8.20
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Curate a digital portfolio of generative artworks
Description: Students select their best generative art pieces, document the algorithms and techniques used in each, and organize them into a coherent portfolio. They write brief artist statements explaining their creative intent and technical approach. They demonstrate ability to communicate about computational art to non-technical audiences, preparing for real-world creative coding careers.

Dependencies:
* T19.G8.19: Build and iterate on generative art variations
* T19.G8.10.02: Document and present generative artwork


ID: T19.G8.21
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Create immersive 360° or VR-ready 3D art environments
Description: Students design 3D algorithmic art environments that surround the viewer, using spherical or panoramic camera setups. They position shapes, lights, and effects in all directions around the camera origin. They consider how the viewer will explore the space and create art experiences that reward looking in different directions. This introduces immersive art concepts that translate to VR/AR platforms.

Dependencies:
* T19.G8.08: Implement dynamic lighting systems
* T19.G8.10.01: Implement a multi-technique generative artwork


ID: T19.G8.22
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Implement real-time style transfer concepts algorithmically
Description: Students create algorithmic systems that transform input (camera feed, images) using style parameters derived from art analysis. They implement simplified versions of style transfer: extracting color palettes from reference images, applying edge detection filters, or mapping brightness to pattern density. They understand how AI style transfer works conceptually and create manual algorithmic approximations.

Dependencies:
* T19.G8.11: Create AI-human collaborative art systems
* T19.G8.06.02: Apply noise to modulate art parameters


ID: T19.G8.23
Topic: T19 – Algorithmic Art & Creative Coding
Skill: Design autonomous generative art agents
Description: Students create generative art systems that make their own decisions about what to create next. They implement simple rule-based agents that evaluate current canvas state (color distribution, density, balance) and decide where to add next elements. They explore questions of artistic agency and autonomy in computational systems.

Dependencies:
* T19.G8.17: Design art systems with separation of concerns
* T19.G8.02: Create constrained generative artwork


---


## TOPIC: T20 – AI Media (Phase 5 Optimized - November 2025)
# Phase 5 MAJOR optimizations applied:
# BOLD CHANGES FROM PHASE 4:
# 1. K-2 EXPANSION: Added 5 new foundational skills for comprehensive AI media literacy
#    - GK.04: Trace how AI turns words into pictures (input→output concept)
#    - GK.05: Sort real sounds from computer sounds (audio AI literacy)
#    - G1.03: Match picture prompts to their outputs (prompt-image connection)
#    - G1.04: Predict which details AI will include vs miss (AI limitations)
#    - G2.03: Debug why AI drew the wrong thing (fix vague prompts)
#    - G2.04: Trace how voice helpers turn speech into action (speech-to-action)
# 2. G3-G4 BRIDGE: Smoother unplugged-to-coding transition
#    - G3.06: Trace prompt-to-image flow in a visual diagram before coding
#    - G4.06: Debug a prompt that produces unwanted results (iteration intro)
# 3. G5 DEPENDENCY FIX: T20.G5.02 now depends on G4.05 (image prompting) not TTS
# 4. MODERN AI EXPANSION: Added cutting-edge AI application skills
#    - G7.22: Build real-time AI feedback system with streaming responses
#    - G7.23: Compare AI models for specific media generation tasks
#    - G8.29: Design human-AI collaborative workflows
#    - G8.30: Build AI system that explains its confidence level
#    - G8.31: Implement A/B testing for AI prompts
# 5. GRANULARITY: Broke down broad G8 ethics/evaluation skills into sub-skills
#    - G8.04 → G8.04.01 (disclosure), G8.04.02 (attribution), G8.04.03 (consent)
#    - G8.27 → G8.27.01 (image rubrics), G8.27.02 (text rubrics)
# 6. ACTIVE VERBS: All "Explain" and "Describe" replaced with Trace, Debug, Compare, Predict, Build
# 7. AI-HUMAN COLLABORATION: New thread on AI augmenting human creativity (not replacing)
# Total: 127 skills (GK-G8) - significantly expanded modern AI capabilities

Focus: AI-generated media (text, images, voice), computer vision, and AI-human collaborative systems

## GRADE K (5 skills)




ID: T20.GK.01
Topic: T20 – AI Media
Skill: Tell which pictures look like AI made them
Description: Students compare pairs of pictures (one photograph, one AI-generated) and identify which looks computer-made by noticing clues like unnatural patterns, odd details, or too-perfect symmetry. This picture-based activity builds foundational AI media literacy without requiring any coding.
Activity Type: Picture comparison with visual analysis
Estimated Time: 3-4 minutes
CSTA: 1A-IC-16 (Compare how people lived and worked before and with technology)

Dependencies: None





ID: T20.GK.02
Topic: T20 – AI Media
Skill: Match the picture to the words that describe it
Description: Students see an AI-generated image and choose which word set best describes it from picture cards (e.g., "happy dog in park" vs "sad cat indoors"). This introduces prompt vocabulary in a developmentally appropriate way using visual matching rather than text generation.
Activity Type: Drag-and-drop matching
Estimated Time: 3-4 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.01: Tell which pictures look like AI made them





ID: T20.GK.03
Topic: T20 – AI Media
Skill: Pick the helper that can talk back
Description: Students identify which devices can answer questions (smart speaker, robot toy with AI) vs which cannot (stuffed animal, picture frame). This introduces AI as responsive technology. Students sort picture cards into "can talk back" and "cannot talk back" categories.
Activity Type: Picture sorting
Estimated Time: 2-3 minutes
CSTA: 1A-IC-16

Dependencies: None




ID: T20.GK.04
Topic: T20 – AI Media
Skill: Trace how AI turns words into pictures using picture sequences
Description: **Student task:** Look at a 3-panel picture sequence and draw arrows showing how words become a picture. **Visual scenario:** Panel 1: Child typing "red apple" on a computer. Panel 2: Computer with gears and sparkles (AI thinking). Panel 3: Picture of a red apple appears. Students draw arrows from words→computer→picture and tap which panel shows "what you type" (INPUT) and "what AI makes" (OUTPUT). This introduces the input→process→output concept for AI image generation at a developmentally appropriate level.
Activity Type: Arrow-drawing with tap-to-label
Estimated Time: 3-4 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.01: Tell which pictures look like AI made them




ID: T20.GK.05
Topic: T20 – AI Media
Skill: Sort real sounds from computer-made sounds using audio cards
Description: **Student task:** Listen to audio clips and sort picture cards showing the sound source into "Real Sound" and "Computer Made" piles. **Audio scenario:** Clips include: REAL - recording of a bird singing, child laughing, car horn. COMPUTER - robot voice reading "Hello friend", synthesized beep melody, AI-generated singing voice. Students listen (large play button) then drag the picture card to the correct pile. This builds foundational audio AI literacy, introducing text-to-speech and AI audio generation concepts.
Activity Type: Audio-based sorting with picture cards
Estimated Time: 4-5 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.03: Pick the helper that can talk back


## GRADE 1 (4 skills)




ID: T20.G1.01
Topic: T20 – AI Media
Skill: Choose words to tell the computer what to draw
Description: Students practice building simple descriptions by selecting word cards (subject + place + color) to form requests like "cat + park + orange." They see how different word combinations create different picture prompts. All words are presented as picture cards with text labels for emerging readers.
Activity Type: Word card assembly with visual support
Estimated Time: 4-5 minutes
CSTA: 1B-IC-18 (Discuss computing technologies that have changed the world)

Dependencies:
* T20.GK.02: Match the picture to the words that describe it





ID: T20.G1.02
Topic: T20 – AI Media
Skill: Decide if AI words are safe to share
Description: Students sort prompt cards into "safe to say to a computer" (friendly animal, favorite color, type of weather) vs "not safe" (home address, full name, phone number). This builds privacy awareness and safe AI interaction habits early. Uses picture-based cards with simple text.
Activity Type: Safety sorting with explanation
Estimated Time: 3-4 minutes
CSTA: 1B-NI-05 (Discuss real-world cybersecurity problems)

Dependencies:
* T20.GK.03: Pick the helper that can talk back




ID: T20.G1.03
Topic: T20 – AI Media
Skill: Match picture prompts to their AI outputs using visual matching
Description: **Student task:** Draw lines to match word prompts on the left to the AI-generated pictures on the right. **Visual scenario:** Left side shows 4 prompt cards with picture+text: "happy yellow sun", "blue cat sitting", "big red truck", "tiny green frog". Right side shows 4 AI-generated images in scrambled order. Students draw lines to match prompts to images. One image intentionally doesn't match perfectly (e.g., "blue cat" shows purple cat) - students identify this mismatch and explain why AI might get colors wrong sometimes.
Activity Type: Line-drawing matching with mismatch identification
Estimated Time: 4-5 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.GK.04: Trace how AI turns words into pictures using picture sequences
* T20.GK.02: Match the picture to the words that describe it




ID: T20.G1.04
Topic: T20 – AI Media
Skill: Predict which details AI will include or miss in a picture
Description: **Student task:** Read a picture request and predict what AI will include and what it might miss or get wrong. **Visual scenario:** Request card: "Draw a dog with 5 spots playing with a red ball." Checklist of items: □ dog, □ 5 spots (not 4, not 6), □ ball, □ red color, □ playing action. Students check which items AI will probably get right (dog, ball) and which it might get wrong (exact number of spots, action pose). Then see an example AI image and compare to predictions. This introduces AI limitation awareness at an age-appropriate level.
Activity Type: Prediction checklist with verification
Estimated Time: 4-5 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G1.03: Match picture prompts to their AI outputs using visual matching


## GRADE 2 (4 skills)




ID: T20.G2.01
Topic: T20 – AI Media
Skill: Add more words to make a better picture request
Description: Students improve vague prompts ("a dog") by adding details ("a fluffy white dog playing in snow"). They compare before/after example outputs to see how specificity improves results. This uses a drag-and-drop interface where students add descriptor cards to a base prompt card.
Activity Type: Prompt improvement exercise with visual feedback
Estimated Time: 5-6 minutes
CSTA: 2-IC-20 (Compare tradeoffs associated with computing technologies)

Dependencies:
* T20.G1.01: Choose words to tell the computer what to draw





ID: T20.G2.02
Topic: T20 – AI Media
Skill: Sort AI outputs that need human checking before sharing
Description: **Student task:** Look at picture scenarios and sort AI outputs into "Ready to Share" vs "Needs Checking First" piles. **Visual scenario:** AI outputs include: READY - cute cartoon animal, simple landscape. NEEDS CHECKING - image with weird-looking hands, text that looks misspelled, person who looks too realistic. Students sort 6 cards and identify the reason for each "Needs Checking" card: "looks weird", "might be wrong", "could fool people". They trace that humans should always check AI work because AI can make mistakes.
Activity Type: Picture sorting with reasoning
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G1.02: Decide if AI words are safe to share




ID: T20.G2.03
Topic: T20 – AI Media
Skill: Debug why AI drew the wrong thing by fixing a vague prompt
Description: **Student task:** Look at an AI picture that doesn't match what someone wanted and fix the prompt to get a better result. **Visual scenario:** Person wanted: "a cat in a box" but AI drew a cat standing next to a box (not inside). Students compare the request to the output, identify what went wrong (missing word "inside"), and select a fixed prompt from options: (A) "a cat sitting inside a box", (B) "cat box picture", (C) "more cat please". Repeat with "dog playing" → drew static dog → fix to "dog running and jumping." This builds debugging skills applied to AI prompts.
Activity Type: Bug identification with prompt repair
Estimated Time: 5-6 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G2.01: Add more words to make a better picture request
* T20.G1.04: Predict which details AI will include or miss in a picture




ID: T20.G2.04
Topic: T20 – AI Media
Skill: Trace how voice helpers turn speech into actions using picture sequences
Description: **Student task:** Arrange 4 picture cards in order showing how a voice helper works, then draw arrows between steps. **Visual scenario:** Cards show (scrambled): (A) Person saying "Play happy music", (B) Sound waves going into a smart speaker, (C) Speaker's light turning on and gears thinking, (D) Music notes coming out of speaker. **Correct order:** A→B→C→D. Students sequence cards and draw arrows. Follow-up: tap which step is "what you say" (A), "AI listening" (B), "AI thinking" (C), "AI doing" (D). This traces the speech→recognition→processing→action pipeline.
Activity Type: Sequence ordering with arrow-drawing
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.GK.05: Sort real sounds from computer-made sounds using audio cards
* T20.G2.02: Sort AI outputs that need human checking before sharing


## GRADE 3 (6 skills)




ID: T20.G3.01
Topic: T20 – AI Media
Skill: Tell whether media was AI-generated or recorded
Description: Students compare pairs of images or short sounds (one AI-generated, one recorded) and pick which seems AI-made, explaining clues (odd shadows, repeated textures, robotic voice tone). This is the foundational AI media literacy skill that introduces students to distinguishing AI-created content from human-created or recorded content.
CSTA: 2-IC-20 (Compare tradeoffs associated with computing technologies)

Dependencies: None





ID: T20.G3.02
Topic: T20 – AI Media
Skill: Build simple AI prompts by naming subject, colors, and setting
Description: Students practice constructing AI image prompts by filling in a template: [subject] + [colors] + [setting]. For example, they transform "I want a cat picture" into "orange cat sitting on a blue couch." They complete 4-5 prompt templates, predicting which prompts will produce better results (more specific = better). This builds foundational prompt vocabulary before working with actual AI blocks in Grade 5. Students also identify prompts that are too vague (e.g., "cool thing") and fix them using the template.
CSTA: 2-IC-20

Dependencies:
* T20.G3.01: Tell whether media was AI-generated or recorded




ID: T20.G3.03
Topic: T20 – AI Media
Skill: Sort AI outputs into "good enough" vs "needs fixing" categories
Description: Students examine 5-6 AI-generated images for a given prompt and sort them into categories: "good enough to use" vs "needs fixing" vs "unusable." They explain their reasoning (missing elements, wrong colors, confusing layout, perfect match). This develops critical evaluation skills and prepares students for iteration workflows in later grades. Uses picture sorting with explanation.
Activity Type: Picture sorting with verbal justification
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G3.01: Tell whether media was AI-generated or recorded
* T20.G3.02: Build simple AI prompts by naming subject, colors, and setting




ID: T20.G3.04
Topic: T20 – AI Media
Skill: Identify which AI helper fits a task
Description: Students match different AI tasks to appropriate AI helper types. Given scenarios (need a picture for a story, need words read aloud, need a question answered, need to find a song), students choose which AI helper fits: image generator, text-to-speech, chatbot, or music finder. This builds understanding that different AI tools serve different purposes and prepares students for choosing the right AI tools in later grades.
Activity Type: Matching exercise with picture cards
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G3.01: Tell whether media was AI-generated or recorded
* T20.GK.03: Pick the helper that can talk back




ID: T20.G3.05
Topic: T20 – AI Media
Skill: Trace why AI can make mistakes using pattern examples
Description: **Student task:** Examine picture examples of AI mistakes and trace the pattern of why AI struggles with certain tasks. **Visual scenario:** 3 pairs of images: (1) AI hand with 6 fingers vs real hand with 5, (2) AI text that says "Hapyp Brithday" vs correct spelling, (3) AI drawing of 3 apples when asked for 4. Students match each mistake to a reason card: "AI can't count well", "AI guesses at letters", "AI doesn't check its work". They trace that AI predicts patterns without truly understanding—good at overall look, bad at exact details. This builds foundational understanding that AI is a powerful tool that still needs human checking.
Activity Type: Mistake-pattern matching with tracing
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G3.03: Sort AI outputs into "good enough" vs "needs fixing" categories




ID: T20.G3.06
Topic: T20 – AI Media
Skill: Trace prompt-to-image flow in a visual diagram before coding
Description: **Student task:** Complete a flowchart showing how a prompt becomes an AI image, labeling each step. **Visual scenario:** Partially filled flowchart: [Your Prompt] → [?] → [AI Brain] → [?] → [Final Image]. Students drag labels to complete: "Send to AI Server", "AI Generates Image". They also add arrows showing data flow direction. Follow-up: students trace what happens if prompt is empty (AI gets confused/error) vs detailed (good result). This builds mental models of AI systems before hands-on coding in G5.
Activity Type: Flowchart completion with drag-and-drop
Estimated Time: 5-6 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G3.02: Build simple AI prompts by naming subject, colors, and setting
* T20.G3.05: Trace why AI can make mistakes


## GRADE 4 (8 skills)




ID: T20.G4.01
Topic: T20 – AI Media
Skill: Choose safe and specific prompts for images
Description: Given a vague or risky image request ("make a person" or "draw my house address"), students rewrite it to be specific, safe, and privacy-friendly (e.g., "Draw a friendly robot in a park, daytime"). This combines safety awareness with prompt engineering fundamentals. Students practice decomposing vague requests into safe components: what (subject), where (setting), when (time/lighting), and removing any private information.
CSTA: 2-IC-23 (Describe tradeoffs between allowing information to be public and keeping information private and secure)

Dependencies:
* T20.G3.01: Tell whether media was AI-generated or recorded
* T20.G2.01: Add more words to make a better picture request





ID: T20.G4.01.01
Topic: T20 – AI Media
Skill: Break a vague prompt into specific components
Description: Students practice decomposing vague requests into specific elements using a structured template: subject (what is the main thing), setting (where is it), colors (what colors should dominate), mood (what feeling should it create), and details (what extra elements to include). For example, "make a cool picture" becomes "Subject: friendly robot, Setting: playground at sunset, Colors: orange and purple sky, Mood: happy and playful, Details: children playing nearby." Students complete 3-4 fill-in-the-blank templates before writing full prompts independently. This focused sub-skill teaches the component parts of effective prompts.
Activity Type: Template-based prompt decomposition
Estimated Time: 5-6 minutes
CSTA: 2-IC-23

Dependencies:
* T20.G4.01: Choose safe and specific prompts for images




ID: T20.G4.02
Topic: T20 – AI Media
Skill: Categorize AI media you've experienced by type and quality
Description: Students share examples of AI-generated content they've encountered (AI art, AI voices in videos, chatbot responses) and categorize each using a structured template. For each example, they record: AI type (image, text, voice, video), source (app name, website), and quality rating (helpful, confusing, or problematic). They trace patterns: which AI types produce more helpful outputs? Which tend to be confusing? They build vocabulary for discussing AI media quality (accurate, creative, realistic, artificial, biased) and become critical consumers of AI content in their daily lives.
CSTA: 2-IC-20

Dependencies:
* T20.G4.01: Choose safe and specific prompts for images
* T20.G3.02: Build simple AI prompts by naming subject, colors, and setting





ID: T20.G4.03
Topic: T20 – AI Media
Skill: Identify strengths and limits of AI image generation
Description: Students examine several AI-generated images and systematically list what AI does well (colorful backgrounds, consistent patterns, fantasy scenes, atmospheric lighting) and what it struggles with (drawing hands correctly, readable text, counting objects accurately, consistent characters across multiple images). They create a "Strengths vs Limitations" chart with specific examples and discuss when AI is the right tool versus when human creation is better. This builds informed decision-making about AI tool selection.
CSTA: 2-IC-20

Dependencies:
* T20.G4.02: Categorize AI media you've experienced by type and quality
* T20.G3.03: Sort AI outputs into "good enough" vs "needs fixing" categories




ID: T20.G4.04
Topic: T20 – AI Media
Skill: Predict what AI will draw from a given prompt
Description: Students see a text prompt (e.g., "a purple elephant wearing a hat in space") and predict what the AI will generate before seeing the result. They sketch their prediction, then compare to the actual AI output. They discuss why their prediction matched or differed (AI interprets words literally, may miss context, emphasizes certain words). This develops mental models of how AI processes prompts.
Activity Type: Prediction and comparison exercise
Estimated Time: 5-6 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.01: Choose safe and specific prompts for images
* T20.G3.02: Build simple AI prompts by naming subject, colors, and setting




ID: T20.G4.05
Topic: T20 – AI Media
Skill: Order words in a prompt to get better AI results
Description: Students learn that word order and emphasis affect AI output. They experiment with different orderings of the same words (e.g., "sunset beach peaceful" vs "peaceful beach sunset" vs "beach with peaceful sunset") and observe how results change. They identify patterns: words at the beginning often have more influence, connecting words help clarity. This prepares for structured prompt writing in Grade 5.
Activity Type: Word ordering experiment with picture comparison
Estimated Time: 5-6 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.04: Predict what AI will draw from a given prompt
* T20.G2.01: Add more words to make a better picture request




ID: T20.G4.05.01
Topic: T20 – AI Media
Skill: Identify key words vs filler words in prompts
Description: Students learn to distinguish between key words that strongly influence AI output (nouns, adjectives, verbs that describe content) and filler words that have minimal impact (articles like "a" and "the," conjunctions like "and," prepositions like "of"). They highlight key words in 5-6 example prompts and practice rewriting prompts to emphasize important words. For example, "A beautiful sunset over the peaceful ocean with some boats" → Key: sunset, beautiful, ocean, peaceful, boats; Filler: A, over, the, with, some. This prepares students for G4.05's word ordering experiments by helping them identify which words matter most.
Activity Type: Word categorization and highlighting exercise
Estimated Time: 4-5 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.04: Predict what AI will draw from a given prompt




ID: T20.G4.06
Topic: T20 – AI Media
Skill: Debug a prompt that produces unwanted AI results
Description: **Student task:** Examine an AI image that doesn't match the intended request, identify what went wrong in the prompt, and write a fixed prompt. **Visual scenario:** Original prompt: "sunset beach" → AI produced a beach at noon with no sunset. Students analyze: prompt lacks time cue, color cue, sky description. They rewrite to: "beach at sunset with orange and pink sky, sun touching the water." Second example: "scary monster" → AI made cute creature → fix to "frightening monster with sharp teeth, dark colors, glowing eyes." This introduces the iteration workflow of prompt debugging that will be used extensively in later grades.
Activity Type: Prompt debugging with rewrite exercise
Estimated Time: 6-7 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.05: Order words in a prompt to get better AI results
* T20.G2.03: Debug why AI drew the wrong thing by fixing a vague prompt




ID: T20.G4.07
Topic: T20 – AI Media
Skill: Compare prompts that work vs prompts that fail for the same goal
Description: **Student task:** Read pairs of prompts intended for the same goal and predict which will produce better results, then verify with example outputs. **Visual scenario:** Goal: "Picture of a knight." Prompt A: "knight" (4 letters). Prompt B: "medieval knight in shining silver armor, standing in a castle courtyard, holding a shield with a lion emblem." Students predict B works better, then see actual AI outputs confirming the prediction. They identify the pattern: specificity, visual details, and context improve results. Repeat with 2-3 more pairs to reinforce the pattern.
Activity Type: Paired prompt comparison with prediction
Estimated Time: 5-6 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.06: Debug a prompt that produces unwanted AI results
* T20.G4.01.01: Break a vague prompt into specific components


## GRADE 5 (14 skills)




ID: T20.G5.01
Topic: T20 – AI Media
Skill: Decide AI vs hand-made for a single asset type
Description: Given one asset need (e.g., "we need a background for our story"), students explain whether AI generation or hand-drawing would work better, considering factors like uniqueness, consistency, and time. They justify their choice with one reason, applying their understanding of AI strengths and limitations.
CSTA: 2-IC-20

Dependencies:
* T20.G4.01: Choose safe and specific prompts for images
* T20.G4.03: Identify strengths and limits of AI image generation
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.02
Topic: T20 – AI Media
Skill: Generate a single AI image using a simple prompt
Description: Students use the `OpenAI DALL-E: generate image with request [DESCRIPTION] resolution [RESOLUTION v]` block to create one image from a descriptive prompt. This reporter block returns an image URL that can be used to load the image into the project. They observe how the AI interprets their words and compare the result to their expectation. Resolution options are 256x256, 512x512, or 1024x1024. This is students' first hands-on experience with AI image generation in code.
CSTA: 2-AP-16 (Incorporate existing code, media, and libraries into original programs)

Dependencies:
* T20.G4.07: Compare prompts that work vs prompts that fail for the same goal
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.02a
Topic: T20 – AI Media
Skill: Search AI image library for pre-made assets
Description: Students use the `search for AI image of [TYPE v] with query [QUERY]` block to find pre-generated AI images from a curated library. TYPE options include Object, Character, and Backdrop. They compare using the AI library (faster, curated, safe) versus generating custom images with DALL-E (more specific, original). This teaches appropriate tool selection for different project needs.
CSTA: 2-IC-20

Dependencies:
* T20.G5.02: Generate a single AI image using a simple prompt
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures




ID: T20.G5.02.01
Topic: T20 – AI Media
Skill: Use a prompt template for consistent style
Description: Students use a pre-made prompt template with placeholders (e.g., "[SUBJECT], [STYLE], [COLORS], [MOOD]") and fill in different values to generate multiple images with consistent visual style. They compare outputs from template-based prompts vs freeform prompts and observe how templates ensure consistency across multiple images for a project. This introduces systematic prompt construction before the variable-based approach in G7.01.
Activity Type: Fill-in-the-blank template application
Estimated Time: 5-6 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G5.02: Generate a single AI image using a simple prompt
* T20.G4.05: Order words in a prompt to get better AI results


ID: T20.G5.03
Topic: T20 – AI Media
Skill: Use basic text-to-speech with default settings
Description: Students use the `say [TEXT] in [LANGUAGE v] as [VOICETYPE v] speed (SPEEDRATIO) pitch (PITCHRATIO) volume (VOLUMERATIO) store sound as [SOUNDNAME]` block to have the computer speak a sentence aloud. They start with default settings (speed 1.0, pitch 1.0, volume 1.0) and basic voice types (Male, Female). Students observe how different text inputs produce spoken audio output, making the connection between text data and audio media. This is students' first hands-on experience with text-to-speech functionality.
CSTA: 2-AP-16

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T20.G3.01: Tell whether media was AI-generated or recorded
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.03a
Topic: T20 – AI Media
Skill: Experiment with different voice types
Description: Students explore the variety of available voice types in text-to-speech: Male, Female, Boy, Girl, Male2, Female2, Male3, Female3, and others. They experiment with different languages (30+ options including English, Spanish, French, Chinese, Japanese) to understand how voice selection affects the character and clarity of speech output. They choose appropriate voices for different project contexts (storytelling characters, educational narration, game announcements).
CSTA: 2-IC-20

Dependencies:
* T20.G5.03: Use basic text-to-speech with default settings
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures




ID: T20.G5.03b
Topic: T20 – AI Media
Skill: Adjust speech parameters (speed, pitch, volume)
Description: Students experiment with speech parameters to control how text-to-speech sounds: speed (0.5-2.0, where 1.0 is normal, lower is slower, higher is faster), pitch (0.5-2.0, where 1.0 is normal, lower is deeper, higher is squeakier), and volume (0.5-2.0, where 1.0 is normal volume). They learn how these parameters affect clarity, mood, and character voice, and use them creatively for storytelling or game narration.
CSTA: 2-AP-16

Dependencies:
* T20.G5.03: Use basic text-to-speech with default settings
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.04
Topic: T20 – AI Media
Skill: Predict factors that affect speech recognition accuracy
Description: Students use a pre-built CreatiCode project with speech recognition blocks to test how different conditions affect transcription accuracy. They make predictions then verify: clear speech vs mumbling, quiet room vs background noise, close microphone vs distant. They document their observations in a table (condition, prediction, actual result) and explain which factors most impact recognition quality. This develops scientific thinking about AI systems and prepares them for implementing speech recognition in Grade 6.
CSTA: 2-IC-20

Dependencies:
* T20.G3.01: Tell whether media was AI-generated or recorded
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures






ID: T20.G5.04a
Topic: T20 – AI Media
Skill: Debug common speech recognition failures
Description: Students practice systematic debugging of speech recognition issues: (1) microphone not detected—check browser permissions, test with other apps; (2) recognition fails silently—verify internet connection since speech-to-text requires cloud processing; (3) wrong language transcribed—check language parameter matches spoken language; (4) partial transcription—speak more clearly, reduce background noise. They use console logging to trace the recognition workflow and identify where failures occur. This builds systematic debugging skills specific to AI audio features.
CSTA: 2-AP-17
Activity Type: Debugging exercise with guided troubleshooting checklist
Estimated Time: 5-6 minutes

Dependencies:
* T20.G5.04: Predict factors that affect speech recognition accuracy
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name


ID: T20.G5.05
Topic: T20 – AI Media
Skill: Classify AI outputs as safe, risky, or unsafe using a safety checklist
Description: Students apply a safety checklist to categorize AI-generated images and text: (1) Safe - appropriate for public sharing, (2) Risky - needs review before sharing, (3) Unsafe - should not be shared. Checklist includes: shows real people? contains personal info? could be mistaken for real news? reinforces stereotypes? appropriate for all ages? Students classify 5-6 AI outputs using the checklist and justify their decisions. This builds critical evaluation skills and prepares for content moderation in G6.
CSTA: 2-IC-23

Dependencies:
* T20.G4.01: Choose safe and specific prompts for images
* T20.G4.03: Identify strengths and limits of AI image generation
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.06
Topic: T20 – AI Media
Skill: Ask ChatGPT a simple question and display the response
Description: Students use the `OpenAI ChatGPT: request [PROMPT] result [VARIABLE v] mode [MODE v] length [MAXLENGTH] temperature [TEMPERATURE] session [SESSIONTYPE v]` block to ask ChatGPT a simple question and display the response. They observe how the AI generates human-like text responses. MODE options are "streaming" (updates continuously) or "waiting" (shows complete response). SESSIONTYPE options are "new chat" or "continue" to maintain conversation context.
CSTA: 2-AP-16

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T28.G3.01: Distinguish text data from numbers and pictures





ID: T20.G5.07
Topic: T20 – AI Media
Skill: Predict how temperature affects ChatGPT creativity
Description: Students experiment with the temperature parameter (0-2, controls randomness/creativity: 0=focused and predictable, 2=creative and random) by asking ChatGPT the same question multiple times with different values. They predict outcomes before running, then compare responses side-by-side and explain the pattern: low temperature produces consistent, similar answers while high temperature produces varied, creative (but sometimes unexpected) answers. They predict which temperature works best for different tasks (facts vs creative writing) and document their observations in a table.
CSTA: 2-IC-20

Dependencies:
* T20.G5.06: Ask ChatGPT a simple question and display the response
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.01: Distinguish text data from numbers and pictures


ID: T20.G5.08
Topic: T20 – AI Media
Skill: Debug a project when AI blocks return unexpected results
Description: Students practice debugging common AI block issues: image generation returns blank (check prompt for blocked content), ChatGPT returns empty string (check internet connection, API limits), speech recognition fails (check microphone permissions). They use console.log to trace AI block execution, identify failure points, and implement error handling using if-else to check for empty results before using them. This develops systematic debugging skills for AI-integrated projects.
CSTA: 2-AP-17

Dependencies:
* T20.G5.02: Generate a single AI image using a simple prompt
* T20.G5.06: Ask ChatGPT a simple question and display the response
* T08.G4.03: Add else to handle the opposite case


## GRADE 6 (21 skills)




ID: T20.G6.01
Topic: T20 – AI Media
Skill: Plan a mixed-source asset kit for a game or story project
Description: Given a specific project (e.g., a simple platformer game or an interactive story), students list all visual and audio assets needed, categorize each as "AI-generated," "hand-created," or "library," and justify each choice (e.g., "AI for varied backgrounds because we need many unique scenes, hand-drawn for the main character for consistent appearance across frames"). This strategic planning skill helps students make informed decisions about when to use AI tools.
CSTA: 2-IC-20

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G4.01: Choose safe and specific prompts for images
* T20.G5.01: Decide AI vs hand-made for a single asset type





ID: T20.G6.02
Topic: T20 – AI Media
Skill: Write structured prompts to maintain consistent visual style
Description: Students transform vague ideas (e.g., "dragon in a cave") into detailed prompts with five components: subject, action, camera angle, color palette, and mood. By reusing this structure across multiple assets, they ensure all generated images share a consistent visual style suitable for a cohesive project. For example: "Subject: ancient dragon, Action: sleeping, Camera: low angle view, Palette: emerald green and gold, Mood: mysterious and magical."
CSTA: 2-AP-10 (Use flowcharts and/or pseudocode to design and illustrate algorithms)

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G5.01: Decide AI vs hand-made for a single asset type
* T20.G5.02: Generate a single AI image using a simple prompt





ID: T20.G6.03
Topic: T20 – AI Media
Skill: Build a prompt test bench inside CreatiCode
Description: Students use a provided starter template with a text input, dropdown style selector, and gallery of preview sprites already set up. They complete the implementation by adding the `OpenAI DALL-E: generate image with request [DESCRIPTION] resolution [RESOLUTION v]` block call when the "Generate" button is pressed, loading the resulting image, and logging each prompt + URL in a table so they can compare different prompts. This tool helps students efficiently test and compare different prompts while learning project structure.
CSTA: 2-AP-13 (Decompose problems and subproblems into parts)

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Use broadcast to coordinate sprite actions
* T04.G5.02: Identify accumulator patterns in code (sum/concatenate)
* T10.G5.03: Add and remove items from a list





ID: T20.G6.04
Topic: T20 – AI Media
Skill: Iterate when an AI output fails requirements
Description: Students practice reading a failed generation (wrong colors, missing character, awkward proportions), identifying the cause (prompt missing detail, wrong style keyword, conflicting terms), and rewriting the prompt to address the issue. They compare "before/after" versions to show how iteration improves fit. This develops debugging skills specific to AI prompting.
CSTA: 2-AP-17 (Systematically test and refine programs)

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T10.G5.03: Add and remove items from a list





ID: T20.G6.05
Topic: T20 – AI Media
Skill: Use Azure speech recognition (ai_startspeech block)
Description: Students use Microsoft Azure speech recognition with the `start recognizing speech in [LANGUAGE v] record as [SOUNDNAME]` (ai_startspeech) block to record their voice and convert it to text. The workflow: start recognition → user speaks → `end speech recognition` → read `text from speech` reporter block. They verify transcription accuracy and debug common issues (microphone not detected, background noise interference, unclear speech).
CSTA: 2-AP-16

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Use broadcast to coordinate sprite actions
* T20.G5.04: Predict factors that affect speech recognition accuracy





ID: T20.G6.05a
Topic: T20 – AI Media
Skill: Use OpenAI Whisper speech recognition (ai_startopenaispeech block)
Description: Students use OpenAI Whisper speech recognition with the `OpenAI: start recognizing speech in [LANGUAGE v] record as [SOUNDNAME]` (ai_startopenaispeech) block to record their voice and convert it to text. The workflow is identical to Azure: start recognition → user speaks → `end speech recognition` → read `text from speech` reporter block. They compare Whisper's performance with Azure's (tested in G6.05) to understand that different AI providers have different strengths and accuracy levels for various accents and languages.
CSTA: 2-AP-16

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Use broadcast to coordinate sprite actions
* T20.G6.05: Use Azure speech recognition (ai_startspeech block)




ID: T20.G6.05b
Topic: T20 – AI Media
Skill: Process speech recognition results to trigger actions
Description: Students build programs that act on recognized speech by reading the `text from speech` reporter block after recognition ends. They implement keyword detection (if text contains "start" then..., if text contains "stop" then...), handle partial matches and variations (both "begin" and "start" trigger the same action), and respond to unrecognized commands with helpful feedback. This bridges basic speech recognition to building voice-controlled applications.
CSTA: 2-AP-16

Dependencies:
* T20.G6.05: Use Azure speech recognition (ai_startspeech block)
* T08.G4.03: Add else to handle the opposite case
* T28.G4.02: Use string comparison blocks (contains, starts with)




ID: T20.G6.05c
Topic: T20 – AI Media
Skill: Build a voice command menu with multiple options
Description: Students create a voice command interface that recognizes and responds to multiple different commands. They implement a command dispatch pattern: capture speech → check against list of known commands → execute matching action → provide feedback. Commands might include: "help" (show instructions), "new game" (reset state), "show score" (display points), "quit" (end session). They handle unknown commands gracefully with "I didn't understand" feedback and suggest available options. This teaches command pattern architecture for voice interfaces.
CSTA: 2-AP-16

Dependencies:
* T20.G6.05b: Process speech recognition results to trigger actions
* T10.G4.01: Use a list to solve a problem with many similar items


ID: T20.G6.06
Topic: T20 – AI Media
Skill: Check user input with AI content moderation
Description: Students use the `get moderation result for [TEXT]` block to check whether user-submitted text is appropriate. They build a simple input checker that displays "Pass" or "Fail" based on the moderation result. This teaches responsible AI use by implementing safety guardrails.
CSTA: 2-IC-23

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G4.03: Add else to handle the opposite case
* T20.G5.05: Explain why AI content needs safety review





ID: T20.G6.07
Topic: T20 – AI Media
Skill: Use image moderation to check visual content
Description: Students use `get moderation result for image at URL [URL]` or `get moderation result for costume named [NAME]` to check whether uploaded or AI-generated images meet content guidelines. They build a checker that flags inappropriate visuals before display. This extends content moderation concepts from text to images.
CSTA: 2-IC-23

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G5.02: Generate a single AI image using a simple prompt
* T20.G6.06: Check user input with AI content moderation





ID: T20.G6.08
Topic: T20 – AI Media
Skill: Use ChatGPT to generate story text or dialogue
Description: Students use ChatGPT to generate creative text content for their projects, such as story narration, character dialogue, or scene descriptions. They provide clear prompts that specify the tone, style, and content they want, then integrate the generated text into their CreatiCode projects. For example: "Write 3 sentences of spooky narration for a haunted house scene, suitable for kids."
CSTA: 2-AP-16

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G5.06: Ask ChatGPT a simple question and display the response
* T20.G5.07: Predict how temperature affects ChatGPT creativity





ID: T20.G6.09
Topic: T20 – AI Media
Skill: Select optimal temperature for different ChatGPT tasks
Description: Building on G5.07's temperature experiments, students develop guidelines for choosing the right temperature for specific use cases. They create a decision matrix: low temperature (0-0.3) for factual answers, code generation, and consistent formatting; medium (0.5-1.0) for balanced responses, summarization, and explanations; high (1.5-2.0) for creative writing, brainstorming, and generating variety. They apply these guidelines to select appropriate settings for their projects.
CSTA: 2-IC-20

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G5.07: Predict how temperature affects ChatGPT creativity





ID: T20.G6.10
Topic: T20 – AI Media
Skill: Use system instructions to guide ChatGPT behavior
Description: Students use the `OpenAI ChatGPT: system request [PROMPT] session [SESSION v] result [VARIABLE v] temperature [T]` block to set system-level instructions that guide how ChatGPT responds. They learn how system prompts (e.g., "You are a friendly pirate who speaks in pirate language," "Always respond in rhymes," "You are a math tutor who explains step-by-step") shape the AI's personality and output style. System messages are treated more seriously by the AI than regular prompts.
CSTA: 2-AP-16

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G5.06: Ask ChatGPT a simple question and display the response





ID: T20.G6.11
Topic: T20 – AI Media
Skill: Detect faces in camera video (basic detection setup)
Description: Students use the `run face detection debug [yes/no] and write into table [TABLE v]` block to turn on the device camera and detect faces in real-time. Debug mode shows a red rectangle around the face with 6 blue dots for facial features. They learn how to start face detection, enable debug visualization, and understand what data the system provides. The detection table will be explored in detail in G6.11a.
CSTA: 2-DA-08 (Collect data using computational tools)

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Use broadcast to coordinate sprite actions
* T10.G5.03: Add and remove items from a list





ID: T20.G6.11a
Topic: T20 – AI Media
Skill: Read facial feature coordinates from detection table
Description: Students read and interpret the face detection results table which contains columns: id, variable (tilt angle, left_eye_x, left_eye_y, right_eye_x, right_eye_y, nose_x, nose_y, mouth_x, mouth_y, left_ear_x, left_ear_y, right_ear_x, right_ear_y), and value (coordinates range from x: -240 to 240, y: -180 to 180). They extract specific facial features (eyes, nose, mouth, ears) and use these coordinates to position sprites or create visual effects that follow the user's face.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T10.G5.03: Add and remove items from a list
* T20.G6.11: Detect faces in camera video (basic detection setup)





ID: T20.G6.11b
Topic: T20 – AI Media
Skill: Use head tilt angle for face orientation detection
Description: Students read the tilt angle value from the face detection table to determine head orientation (tilt left vs tilt right vs straight). They use this data to create interactive applications that respond to head movements, such as controlling a character's direction by tilting your head, or games that require specific head poses. This demonstrates using a single, high-level facial feature for interaction design.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G4.03: Add else to handle the opposite case
* T20.G6.11a: Read facial feature coordinates from detection table




ID: T20.G6.12
Topic: T20 – AI Media
Skill: Track 2D body parts in camera video (basic setup)
Description: Students use the `run 2D body part recognition single person [yes/no] table [TABLE v] debug [yes/no]` block to detect body parts in camera video. The "single person" parameter focuses tracking on one person for better accuracy when set to "yes," or tracks multiple people when "no." Debug mode shows live video overlay with body part markers. They learn how to start body tracking, enable debug visualization, and understand what data the system provides. The detection table structure will be explored in detail in G6.12a.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Use broadcast to coordinate sprite actions
* T10.G4.01: Use a list to solve a problem with many similar items





ID: T20.G6.12a
Topic: T20 – AI Media
Skill: Read body part positions from detection table
Description: Students read and interpret the body tracking results table which has 6 columns: id, part (17 core body parts: nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles + 4 aggregate parts: left_arm, right_arm, left_leg, right_leg), x, y, curl (180° = straight, used for arms/legs), and dir (0° = pointing up). They extract specific body part positions (x, y coordinates) and use this data to position sprites, create mirrors, or track movement patterns.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T10.G4.01: Use a list to solve a problem with many similar items
* T20.G6.12: Track 2D body parts in camera video (basic setup)




ID: T20.G6.12b
Topic: T20 – AI Media
Skill: Use curl and direction values for arm/leg gestures
Description: Students use the curl and dir (direction) values from the body tracking table to detect arm and leg positions and movements. Curl (180° = straight, lower values = bent) helps detect bending motions. Direction (0° = pointing up, 90° = pointing right) helps detect orientation. They create applications that recognize gestures like arms raised (shoulder curl values), legs bent (knee curl values), or specific pointing directions.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G4.03: Add else to handle the opposite case
* T20.G6.12a: Read body part positions from detection table




ID: T20.G6.12c
Topic: T20 – AI Media
Skill: Detect specific poses using body part combinations
Description: Students combine multiple body part readings to recognize complex poses, such as: T-pose (both arms straight and horizontal), hands on hips (wrists near hips), jumping (both knees bent then straightening), or waving (hand moving side-to-side above shoulder). They build pose recognition logic using multiple conditional checks and create interactive experiences that respond to user poses.
CSTA: 2-DA-08

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G4.03: Add else to handle the opposite case
* T20.G6.12b: Use curl and direction values for arm/leg gestures




ID: T20.G6.13
Topic: T20 – AI Media
Skill: Stop camera-based AI detection to manage resources
Description: Students learn to properly stop camera-based AI features when they're no longer needed. They use `stop 2D body part recognition` to stop body tracking and `stop continuous speech recognition` to stop speech recognition. For face and hand detection, they learn to restart the project or use conditional logic to prevent detection from starting. They understand why stopping detection is important: saves battery power, reduces processing load, protects user privacy, and prevents unnecessary data collection. They implement proper start/stop workflows in their applications (e.g., start detection when entering game mode, stop when exiting; toggle buttons to control detection).
CSTA: 2-IC-23 (Describe tradeoffs between allowing information to be public and keeping information private and secure)

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T20.G6.11: Detect faces in camera video (basic detection setup)
* T20.G6.12: Track 2D body parts in camera video (basic setup)


## GRADE 7 (32 skills)




ID: T20.G7.07a
Topic: T20 – AI Media
Skill: Attach files and documents to ChatGPT conversations
Description: Students use `attach files to chat` (opens file selection dialog, returns list of file paths) or `attach file from Google Drive [URL] to chat` (requires shared Google Drive link) to attach documents to ChatGPT requests. They analyze PDFs, text files, or Google Docs by asking ChatGPT to summarize content, extract information, or answer questions about the documents. This teaches document-based AI interaction for research and analysis tasks.
CSTA: 3A-AP-16

Dependencies:
* T20.G7.07: Use ChatGPT vision to analyze images
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.09a
Topic: T20 – AI Media
Skill: Read finger curl and direction values
Description: Students read the first 5 rows of the hand detection table which contain finger data: each row has the finger name (thumb, index, middle, ring, pinky), curl value (180° = straight, lower values = bent/curled), and dir value (0° = pointing up, angles measured clockwise). They use these values to detect finger positions and create applications that respond to finger gestures (e.g., index finger extended vs curled, all fingers straight vs all bent).
CSTA: 3A-DA-09

Dependencies:
* T08.G5.02: Use a simple if in a script
* T10.G6.01: Sort a table by a column
* T20.G7.09: Detect hands in camera video (basic hand detection)





ID: T20.G7.09b
Topic: T20 – AI Media
Skill: Read 2D hand keypoint coordinates
Description: Students read rows 6-26 of the hand detection table which contain 21 2D hand keypoints: wrist, thumb_1 through thumb_4, index_1 through index_4, middle_1 through middle_4, ring_1 through ring_4, and pinky_1 through pinky_4. Each row has x and y coordinates. They use these coordinates to track specific hand positions, measure distances between points (e.g., thumb tip to index tip for pinch detection), or create visual effects that follow hand movements.
CSTA: 3A-DA-09

Dependencies:
* T10.G6.01: Sort a table by a column
* T20.G7.09a: Read finger curl and direction values





ID: T20.G7.09c
Topic: T20 – AI Media
Skill: Use 3D hand coordinates for depth-based gestures
Description: Students read rows 27-47 of the hand detection table which contain the same 21 hand keypoints in 3D space with x, y, and z coordinates. The z coordinate represents depth (distance from camera). They use 3D tracking to detect gestures that involve depth, such as hand moving toward/away from camera, creating 3D pointing interfaces, or controlling objects in virtual 3D space based on hand position in all three dimensions.
CSTA: 3A-DA-09

Dependencies:
* T10.G6.01: Sort a table by a column
* T20.G7.09b: Read 2D hand keypoint coordinates





ID: T20.G7.09d
Topic: T20 – AI Media
Skill: Recognize common hand gestures (pinch, fist, open palm)
Description: Students combine data from curl values, direction values, and keypoint positions to recognize common hand gestures. Pinch: thumb and index finger curl both <90° and fingertips close together. Fist: all five fingers curl <90°. Open palm: all five fingers curl >160° and spread apart. They build reliable gesture recognition with threshold tuning and debouncing to avoid false detections, then use these gestures as input controls for interactive applications.
CSTA: 3A-DA-09

Dependencies:
* T20.G7.09a: Read finger curl and direction values
* T20.G7.09b: Read 2D hand keypoint coordinates





ID: T20.G7.13a
Topic: T20 – AI Media
Skill: Compile and configure a neural network
Description: Students use `compile NN model [NAME] loss [LOSSFUNCTION v] optimizer [OPTIMIZER v] learning rate (RATE)` to prepare their network for training. Loss functions include meanSquaredError (for regression/continuous outputs) and categoricalCrossentropy (for classification). Optimizers include adam (adaptive, recommended for most tasks), sgd (stochastic gradient descent, basic), and adagrad (adaptive gradient). Learning rate typically ranges from 0.001 to 0.1 (lower = slower but more stable learning). They understand that compilation sets the training rules that determine how the network learns.
CSTA: 3A-AP-17

Dependencies:
* T20.G7.13: Design a neural network architecture





ID: T20.G7.13b
Topic: T20 – AI Media
Skill: Train a neural network and observe learning
Description: Students use `train NN model [NAME] using table [TABLENAME v] rows from [STARTROW] to [ENDROW] input columns [INPUTCOLUMNS] output column [OUTPUTCOLUMN] batch size [BATCHSIZE] epochs [EPOCHS]` to fit their neural network to training data. Each row in the table is one training sample. INPUTCOLUMNS is comma-separated (e.g., "pixel1,pixel2,pixel3" or "feature1,feature2"). They set epochs (10-50 training rounds) and batch size (10-32 samples processed together), then watch training loss decrease over epochs. They understand that training = learning from examples through trial-and-error (the network adjusts weights to minimize errors).
CSTA: 3A-AP-17

Dependencies:
* T07.G5.01: Use a counted repeat loop
* T10.G6.01: Sort a table by a column
* T20.G7.13a: Compile and configure a neural network





ID: T20.G7.14a
Topic: T20 – AI Media
Skill: Use a trained neural network to make predictions
Description: Students use `predict using NN model [NAME] for table [TABLENAME v] rows from [STARTROW] to [ENDROW] input columns [INPUTCOLUMNS] output column [OUTPUTCOLUMN]` to classify new data using their trained neural network. The block reads input data from the table, runs it through the neural network, and writes predictions to the output column. They interpret prediction results (for classification: class labels; for regression: numeric values) and understand confidence/probability scores. This completes the neural network workflow: design → compile → train → save → load → predict.
CSTA: 3A-AP-17

Dependencies:
* T20.G7.14: Save and load trained neural network models





ID: T20.G7.18a
Topic: T20 – AI Media
Skill: Select and compare different LLM models
Description: Students compare outputs from different LLM providers for the same prompt, analyzing differences in response quality, style, speed, and accuracy. They choose appropriate models for their needs (small models for simple tasks with faster response, large models for complex reasoning). They document trade-offs between model performance and resource usage, and make informed decisions about which LLM to use for specific applications.
CSTA: 3A-IC-24

Dependencies:
* T20.G7.18: Use generic LLM models with different providers





ID: T20.G7.01
Topic: T20 – AI Media
Skill: Create a reusable prompt template library
Description: Students build a CreatiCode table with columns such as `subject`, `palette`, `camera`, `lighting`, and `tone`. A loop reads each row, assembles the prompt using placeholders (e.g., "[subject] viewed from [camera] angle with [palette] colors in [lighting] light, [tone] mood"), calls DALL-E, and records the returned image URL. This ensures a whole level or comic chapter shares the same art direction through systematic prompt generation.
CSTA: 3A-AP-17 (Decompose problems into smaller components)

Dependencies:
* T07.G5.01: Use a counted repeat loop
* T09.G5.01: Use variables to make a program more general or clear
* T10.G5.01: Use a list to manage a collection of similar items
* T10.G6.01: Sort a table by a column
* T11.G5.01: Create a custom block to group a sequence of actions
* T20.G6.03: Build a prompt test bench inside CreatiCode
* T20.G6.04: Iterate when an AI output fails requirements





ID: T20.G7.02
Topic: T20 – AI Media
Skill: Use ChatGPT to expand creative briefs before generating art
Description: Students combine the `OpenAI ChatGPT: request` block (with system message + role prompt) with DALL-E. ChatGPT converts a story outline into polished image prompts (e.g., "Scene 3: aerial view of neon market, magenta lighting, cyberpunk style, bustling crowd"), then each prompt feeds the DALL-E block. Students compare raw vs. AI-enhanced prompts to see the quality improvement. This demonstrates AI-assisted creative workflows.
CSTA: 3A-AP-17

Dependencies:
* T09.G5.01: Use variables to make a program more general or clear
* T10.G6.01: Sort a table by a column
* T20.G6.04: Iterate when an AI output fails requirements
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.03
Topic: T20 – AI Media
Skill: Audit AI imagery for representation and bias
Description: Students design experiments (e.g., run "a scientist giving a talk" 10 times) and log characteristics (perceived gender, culture, age) into a table. They graph the distribution, identify gaps (e.g., 90% male scientists, 10% female), and adjust prompts (adding descriptors like "diverse group of scientists" or "female scientist") to reach targeted representation goals. This highlights AI4K12's focus on societal impact and bias in AI systems.
CSTA: 3A-IC-24 (Evaluate the ways computing impacts personal, ethical, social, economic, and cultural practices)

Dependencies:
* T09.G5.01: Use variables to make a program more general or clear
* T10.G6.01: Sort a table by a column
* T20.G6.03: Build a prompt test bench inside CreatiCode
* T20.G6.04: Iterate when an AI output fails requirements




ID: T20.G7.03a
Topic: T20 – AI Media
Skill: Design effective few-shot prompts for ChatGPT
Description: Students learn few-shot prompting: providing ChatGPT with examples of input/output pairs before the actual request. They build prompts with 2-3 examples (e.g., "Classify sentiment: 'Great movie!' → positive, 'Terrible service' → negative, 'It was okay' → neutral. Now classify: 'Best day ever!'"). They compare few-shot vs zero-shot (no examples) responses and measure improvement in consistency and accuracy. This teaches prompt engineering patterns used in production AI systems.
CSTA: 3A-AP-17

Dependencies:
* T20.G6.08: Use ChatGPT to generate story text or dialogue
* T20.G6.10: Use system instructions to guide ChatGPT behavior




ID: T20.G7.03b
Topic: T20 – AI Media
Skill: Use chain-of-thought prompting for complex reasoning
Description: Students learn chain-of-thought (CoT) prompting: asking ChatGPT to "think step by step" or "explain your reasoning" before giving an answer. They compare responses with and without CoT for math word problems, logic puzzles, and multi-step decisions. They trace the AI's reasoning steps to verify correctness and identify where errors occur. This teaches how to improve AI accuracy for complex tasks.
CSTA: 3A-AP-17

Dependencies:
* T20.G7.03a: Design effective few-shot prompts for ChatGPT
* T20.G6.09: Compare ChatGPT responses with different temperatures





ID: T20.G7.04
Topic: T20 – AI Media
Skill: Blend AI frames with manual touch-ups for animation
Description: Students import AI-generated poses for a character, then fix artifacts (hands, faces, edges) using the costume editor or vector tools. They align all frames with equal sizing and anchor points, then script a timed animation that matches UI state (buttons, HUD cues). This teaches hybrid AI-human workflows where AI provides the base and humans refine.
CSTA: 3A-AP-17

Dependencies:
* T06.G5.01: Fix a behavior that runs at the wrong time
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use variables to make a program more general or clear
* T10.G6.01: Sort a table by a column
* T20.G6.04: Iterate when an AI output fails requirements





ID: T20.G7.05
Topic: T20 – AI Media
Skill: Synchronize AI visuals with AI narration for a single scene
Description: Students create one immersive scene by combining ChatGPT (to craft narration text), DALL-E (to generate a matching background), and text-to-speech (to read the narration aloud). They focus on timing—ensuring the voiceover starts when the visual appears and describes what's on screen. This is a single-scene exercise in cross-modal alignment, preparing students for multi-scene projects in Grade 8.
CSTA: 3A-AP-17

Dependencies:
* T06.G5.01: Fix a behavior that runs at the wrong time
* T09.G5.01: Use variables to make a program more general or clear
* T10.G6.01: Sort a table by a column
* T20.G5.03: Use basic text-to-speech with default settings
* T20.G6.04: Iterate when an AI output fails requirements
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.06
Topic: T20 – AI Media
Skill: Use continuous speech recognition for live dictation
Description: Students use `start continuous speech recognition in [LANGUAGE v] into list [LISTNAME v]` and `stop continuous speech recognition` blocks to capture ongoing speech as a list of recognized phrases. Unlike single-shot recognition (G6.05 and G6.05a), this streams results continuously—each completed sentence is added to the list while the current sentence updates continuously. They build a live dictation or voice-command application that responds to speech in real-time.
CSTA: 3A-AP-16 (Design and iteratively develop computational artifacts)

Dependencies:
* T10.G6.01: Sort a table by a column
* T20.G6.05: Use Azure speech recognition (ai_startspeech block)





ID: T20.G7.07
Topic: T20 – AI Media
Skill: Use ChatGPT vision to analyze images
Description: Students use the `attach costume [NAME] to chat` block followed by a ChatGPT request to have the AI analyze and describe what's in an image. They ask questions like "What objects do you see?" or "Describe the mood of this image" to understand how multimodal AI can process both text and visual information. This demonstrates ChatGPT's vision capabilities for image understanding.
CSTA: 3A-AP-16

Dependencies:
* T20.G5.02: Generate a single AI image using a simple prompt
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.08
Topic: T20 – AI Media
Skill: Manage multiple ChatGPT conversation threads
Description: Students learn that CreatiCode supports 4 parallel ChatGPT conversation threads (bot IDs 1-4) using the `select chatbot [BOTID v]` block. They build an application that maintains separate conversations (e.g., bot 1 for game narration, bot 2 for hints, bot 3 for character dialogue, bot 4 for tutorial) and switch between threads appropriately. Each thread maintains its own conversation history and context.
CSTA: 3A-AP-17

Dependencies:
* T20.G6.08: Use ChatGPT to generate story text or dialogue
* T20.G6.10: Use system instructions to guide ChatGPT behavior





ID: T20.G7.09
Topic: T20 – AI Media
Skill: Detect hands in camera video (basic hand detection)
Description: Students use the `run hand detection table [TABLE v] debug [yes/no] show video [yes/no]` block to detect hands in camera video. Debug mode shows visual overlays of detected hand landmarks and finger positions. They learn how to start hand detection, enable debug visualization, and understand what data the system provides. The resulting table structure with 47 rows per hand will be explored in detail in subsequent skills (G7.09a through G7.09d).
CSTA: 3A-DA-09 (Translate between different data representations)

Dependencies:
* T08.G5.02: Use a simple if in a script
* T10.G6.01: Sort a table by a column
* T20.G6.12: Track 2D body parts in camera video (basic setup)





ID: T20.G7.10
Topic: T20 – AI Media
Skill: Build a pose-based interactive game
Description: Students create a simple game that responds to body movements detected by the 2D body tracking system. Examples include a fitness game (track squats by monitoring knee y-position dropping below threshold then rising), a dance game (match target poses by comparing current body part positions to template), or an obstacle game (duck/jump by detecting body height changes). They read body part positions from the tracking table and trigger game events based on position, angle, or movement patterns.
CSTA: 3A-AP-16

Dependencies:
* T06.G5.01: Fix a behavior that runs at the wrong time
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use variables to make a program more general or clear
* T20.G6.12: Track 2D body parts in camera video (basic setup)





ID: T20.G7.11
Topic: T20 – AI Media
Skill: Track 3D body poses for avatar control
Description: Students use the `run 3D pose detection debug [yes/no] table [TABLE v]` block to detect 33 body parts in 3D space (x, y, z coordinates). They use this detailed 3D tracking data to control a 3D avatar or character, mapping real body movements to virtual character movements for immersive interactions. This is more advanced than 2D body tracking (G6.12), providing depth information for all body parts.
CSTA: 3A-DA-09

Dependencies:
* T08.G5.02: Use a simple if in a script
* T10.G6.01: Sort a table by a column
* T20.G6.12: Track 2D body parts in camera video (basic setup)





ID: T20.G7.12
Topic: T20 – AI Media
Skill: Trace how neural networks learn from data step-by-step
Description: Students trace the neural network learning process through a visual diagram: (1) Input data enters the network (e.g., image of a cat), (2) Data flows through layers of connected nodes, (3) Network makes a prediction (e.g., "dog"), (4) Prediction is compared to correct answer ("cat"), (5) Error is calculated, (6) Connection weights are adjusted, (7) Process repeats with next example. Students trace this cycle for 3-4 examples, observing how the network's predictions improve. They identify real-world examples (photo recognition, voice assistants, recommendations) and trace why more training data improves accuracy. This conceptual foundation prepares students for building neural networks.
CSTA: 3A-IC-24

Dependencies: None





ID: T20.G7.13
Topic: T20 – AI Media
Skill: Design a neural network architecture
Description: Students use `create NN model named [NAME]` and `add layer to NN model [NAME] input shape (SHAPESIZE) output size (OUTPUTSIZE) activation [FUNCTION v]` blocks to build a network structure. They learn that layers have neuron counts (e.g., input layer: 784 neurons for 28x28 pixel images, hidden layer: 128 neurons for pattern detection, output layer: 10 neurons for digits 0-9). Activation functions include relu (most common for hidden layers), sigmoid (for probability outputs), tanh, and softmax (for multi-class classification). They understand layer purpose and connections without training yet. Input shape of each layer must match the output size of the previous layer.
CSTA: 3A-AP-17

Dependencies:
* T20.G7.12: Explain how neural networks learn from data





ID: T20.G7.14
Topic: T20 – AI Media
Skill: Save and load trained neural network models
Description: Students learn that trained neural networks can be saved and reused without retraining. They use `save NN model named [NAME]` to persist their trained models on the CreatiCode server, and `load NN model named [NAME]` to retrieve them later. This understanding of model persistence is essential for deployment and sharing. Saved models retain their architecture, weights, and compilation settings.
CSTA: 3A-AP-17

Dependencies:
* T20.G7.13b: Train a neural network and observe learning





ID: T20.G7.15
Topic: T20 – AI Media
Skill: Trace how K-Nearest Neighbors (KNN) classifies new data points
Description: Students trace the KNN algorithm step-by-step: given a new data point, calculate distances to all training examples, find the K closest neighbors, count the labels among neighbors, assign the majority label. They work through concrete examples on paper (e.g., classifying a new fruit by size/color using 5 labeled fruits), then verify their manual predictions match the KNN block output. They compare when KNN works well (small datasets, clear boundaries) vs neural networks (complex patterns, large data).
CSTA: 3A-IC-24

Dependencies:
* T20.G7.12: Explain how neural networks learn from data





ID: T20.G7.16
Topic: T20 – AI Media
Skill: Create a KNN classifier from training data
Description: Students use the `create KNN number classifier from table [TABLE v] K [K] named [NAME]` block to build a KNN classifier. They prepare a training data table with a 'label' column (the class to predict) and numeric property columns (features). They choose an appropriate K value (typically 3-5: smaller K is more sensitive to noise, larger K is smoother but may miss patterns), and create the classifier. They experiment with different K values and observe how classification decisions change.
CSTA: 3A-AP-17

Dependencies:
* T10.G6.01: Sort a table by a column
* T20.G7.15: Trace how K-Nearest Neighbors (KNN) classifies new data points





ID: T20.G7.17
Topic: T20 – AI Media
Skill: Analyze text with parts-of-speech tagging
Description: Students use the `analyze sentence [SENTENCE] and write into table [TABLENAME v]` block to analyze text and identify parts of speech using Google Natural Language API. The resulting table has 7 columns: TEXT (each word), LEMMA (word stem, e.g., "running"→"run"), TYPE (noun, verb, adjective, etc.), PERSON (first/second/third for pronouns), OFFSET (position in sentence), LABEL (detailed grammatical function), DEPENDS (row number of word this depends on). They explore how computers understand language structure and use this analysis for applications like grammar checking, keyword extraction, or text summarization.
CSTA: 3A-DA-09

Dependencies:
* T10.G6.01: Sort a table by a column
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.18
Topic: T20 – AI Media
Skill: Use generic LLM models with different providers
Description: Students use the `LLM model [PROVIDER] request [PROMPT] result [VARIABLE v] mode [MODE v] length [MAXLENGTH] temperature [TEMPERATURE] session [SESSIONTYPE v]` block to work with different AI language models beyond ChatGPT. PROVIDER options include small and large model variants. They understand that AI capabilities are not tied to a single company and can compare different models. Students can also use the `LLM set system instruction [INSTRUCTION] for model [PROVIDER]` block to set system-level instructions that guide how the LLM responds, similar to ChatGPT's system message functionality.
CSTA: 3A-IC-24

Dependencies:
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.19
Topic: T20 – AI Media
Skill: Generate structured data with ChatGPT JSON mode
Description: Students use ChatGPT's JSON mode (mentioned in block documentation) to generate structured data in JSON format instead of free-form text. They provide prompts that request specific data structures (e.g., "Generate a JSON object with fields: name, age, occupation for a fantasy character") and receive properly formatted JSON that can be parsed and used in their programs. This teaches how to get structured, machine-readable output from LLMs for data processing applications.
CSTA: 3A-AP-16

Dependencies:
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.20
Topic: T20 – AI Media
Skill: Cancel ChatGPT requests in progress
Description: Students use the `OpenAI ChatGPT: cancel request` block to stop ChatGPT requests that are taking too long or are no longer needed. They implement cancel buttons in their interfaces, handle request timeouts gracefully, and improve user experience by allowing users to interrupt AI operations. They understand when cancellation is appropriate (user changes mind, request hangs, user wants to rephrase prompt) and implement proper cancel workflows.
CSTA: 3A-AP-16

Dependencies:
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G7.21
Topic: T20 – AI Media
Skill: Toggle AI debug mode during development
Description: Students use the `set debug mode [DODEBUG v]` block to turn debug visualization on/off during runtime for AI vision features (face detection, body tracking, hand detection). They learn debugging strategies: turn on debug to verify AI is detecting correctly and see what data is being captured, turn off debug for better performance and clean user interface. They implement debug toggle buttons or keyboard shortcuts in their applications to switch between development and production modes.
CSTA: 3A-AP-16

Dependencies:
* T20.G6.11: Detect faces in camera video (basic detection setup)




ID: T20.G7.22
Topic: T20 – AI Media
Skill: Build real-time AI feedback system with streaming responses
Description: Students use ChatGPT's streaming mode to display AI responses character-by-character as they're generated. They implement a text display that updates in real-time using the "streaming" mode option, show a typing indicator while AI generates, and handle the stream completion event. They compare user experience between streaming (immediate feedback, feels faster) and waiting (all-at-once, simpler code) modes for different use cases. This teaches modern AI UX patterns used in all major AI chatbots.
CSTA: 3A-AP-16

Dependencies:
* T20.G7.08: Manage multiple ChatGPT conversation threads
* T20.G6.08: Use ChatGPT to generate story text or dialogue




ID: T20.G7.23
Topic: T20 – AI Media
Skill: Compare AI models for specific media generation tasks
Description: Students systematically compare different AI models for a specific task: generate the same image prompt with DALL-E and AI Image Library, generate the same text with ChatGPT and generic LLM, transcribe the same audio with Azure and Whisper. They measure and record: output quality (1-5 rating), generation speed (seconds), consistency (same prompt 3 times), and accuracy (match to intent). They create a comparison table and recommend which model to use for different scenarios (speed-critical vs quality-critical vs cost-sensitive). This builds systematic evaluation skills.
CSTA: 3A-IC-24

Dependencies:
* T20.G7.18a: Select and compare different LLM models
* T20.G6.05a: Use OpenAI Whisper speech recognition (ai_startopenaispeech block)
* T20.G5.02a: Search AI image library for pre-made assets


## GRADE 8 (37 skills)




ID: T20.G8.16a
Topic: T20 – AI Media
Skill: Build a knowledge base with semantic search (implements RAG)
Description: Students create a complete knowledge base application implementing the RAG pattern. The workflow: (1) user asks question, (2) semantic search finds top K (3-5) relevant database entries, (3) entries are formatted and sent to ChatGPT as context, (4) ChatGPT synthesizes the information into a natural language answer, (5) system displays answer with source citations. This demonstrates how modern AI systems combine retrieval (finding relevant information) and generation (creating coherent responses) to answer questions accurately with current information.
CSTA: 3B-AP-16

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T20.G8.06: Build a multi-turn ChatGPT conversation system
* T20.G8.16: Trace and diagram how RAG (Retrieval-Augmented Generation) works
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern
* T07.G6.01: Trace nested loops with variable bounds





ID: T20.G8.01
Topic: T20 – AI Media
Skill: Build a user-facing generative art widget with guardrails
Description: Students design an in-app panel (text field for custom prompts, preset buttons for approved styles, preview box for generated art) where users can request a fresh background. The script moderates the prompt with `get moderation result for [TEXT]`, applies house style presets (color palette, mood, camera angle), runs DALL-E, and falls back to curated library art if moderation fails. Users can save approved scenes to a gallery table. This capstone demonstrates production-ready AI integration with safety controls.
CSTA: 3B-AP-16 (Demonstrate code reuse by creating programming solutions using libraries and APIs)

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T10.G6.02: Filter table rows based on a condition
* T12.G6.01: Trace complex code with multiple variables
* T20.G6.06: Check user input with AI content moderation
* T20.G7.01: Create a reusable prompt template library





ID: T20.G8.02
Topic: T20 – AI Media
Skill: Implement an approval pipeline for AI assets
Description: Students build a dashboard that lists each generated asset with metadata columns: prompt, author, moderation result (Pass/Fail), reviewer notes (text field), publish toggle (checkbox), and timestamp. Only assets with "Approved" publish toggle checked become visible in the live scene. This mirrors professional workflows (game studios, media companies) and enforces accountability by tracking who generated what and who approved it.
CSTA: 3B-IC-27 (Predict how computational innovations can affect personal, ethical, social, and cultural practices)

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T08.G6.01: Use conditionals in physics simulations
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T20.G6.06: Check user input with AI content moderation
* T20.G7.01: Create a reusable prompt template library





ID: T20.G8.03
Topic: T20 – AI Media
Skill: Produce a multi-scene media experience from a creative brief
Description: Students receive a creative brief with setting and emotional arc (3-5 beats, e.g., "peaceful village → mysterious discovery → tense chase → triumphant resolution"). They use ChatGPT to generate scene-by-scene descriptions, DALL-E to produce art for each scene, and text-to-speech for narration. Unlike G7.05's single-scene focus, this capstone requires managing multiple scenes with consistent style (using G7.01 prompt templates), scene-to-scene navigation UI (prev/next buttons), and coordinated transitions. Students must track scene state (current scene number, scenes visited), implement navigation buttons, and ensure visual/audio consistency across all scenes. This is a complex integration project requiring planning, implementation, testing, and iteration.
CSTA: 3B-AP-16

Implementation Guidance: Teachers should provide starter template with scene array structure [sceneName, narration, imagePrompt, audioFile] and navigation button framework. Students focus on AI content generation and synchronization.

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T04.G6.01: Group snippets by underlying algorithm pattern
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T20.G7.02: Use ChatGPT to expand creative briefs before generating art
* T20.G7.05: Synchronize AI visuals with AI narration for a single scene





ID: T20.G8.04
Topic: T20 – AI Media
Skill: Develop ethical guidelines for AI media use in a studio
Description: Students research a real example (e.g., a game studio using AI concept art, a news organization using AI-generated images, a music company using AI voices), identify stakeholder concerns (artists worried about jobs, players wanting authentic content, communities concerned about cultural representation), and draft a 5-point policy. The sub-skills below break down each policy component. They connect guidelines to their in-class workflows (moderation logs from G6.06, approval pipelines from G8.02) to demonstrate practical accountability.
CSTA: 3B-IC-27

Dependencies:
* T20.G8.02: Implement an approval pipeline for AI assets
* T20.G8.04.01: Build AI content disclosure labels into applications
* T20.G8.04.02: Implement attribution tracking for AI-generated assets
* T20.G8.04.03: Trace training data sources and consent requirements




ID: T20.G8.04.01
Topic: T20 – AI Media
Skill: Build AI content disclosure labels into applications
Description: Students implement disclosure labels that clearly mark AI-generated content in their applications. They create visible labels ("Generated with AI", "AI-assisted artwork", "This voice is AI-generated"), implement automatic labeling when AI blocks create content, store disclosure status in metadata tables, and design label styles that are visible but not intrusive. They trace why disclosure matters: builds trust, prevents deception, meets emerging legal requirements, respects audience expectations. They implement disclosure at generation time, not as afterthought.
CSTA: 3B-IC-27

Dependencies:
* T20.G7.01: Create a reusable prompt template library
* T20.G6.06: Check user input with AI content moderation




ID: T20.G8.04.02
Topic: T20 – AI Media
Skill: Implement attribution tracking for AI-generated assets
Description: Students build an attribution system that tracks and displays credits for AI-generated content. For each generated asset, they record: AI tool used (DALL-E, ChatGPT, etc.), prompt that created it, timestamp, who requested it, and model version. They implement a credits page or info panel that users can access to see attribution details. They trace why attribution matters: acknowledges AI role, helps reproduce results, maintains project history, supports audit trails. Students compare this to traditional art credits and understand the new attribution needs of AI workflows.
CSTA: 3B-IC-27

Dependencies:
* T20.G8.02: Implement an approval pipeline for AI assets
* T20.G8.04.01: Build AI content disclosure labels into applications




ID: T20.G8.04.03
Topic: T20 – AI Media
Skill: Trace training data sources and consent requirements
Description: Students investigate and document what training data AI models use and what consent requirements apply. They research: What images trained DALL-E? What text trained ChatGPT? What voices trained text-to-speech? They trace the ethical chain: original creators → training data → AI model → generated output. They identify scenarios where consent is clear (public domain, licensed datasets) vs unclear (scraped web images, voice clones). They implement consent checks in their workflows and design applications that respect data source ethics. This builds awareness of the broader AI ecosystem.
CSTA: 3B-IC-27

Dependencies:
* T20.G8.04.02: Implement attribution tracking for AI-generated assets
* T20.G7.03: Audit AI imagery for representation and bias





ID: T20.G8.05
Topic: T20 – AI Media
Skill: Build a voice-controlled creative assistant
Description: Students create an application that accepts voice commands through continuous speech recognition, interprets user intent (e.g., "draw a sunset over mountains" → extract subject and setting), generates AI images based on the spoken prompt, checks content with moderation, and announces results using text-to-speech ("Your sunset image is ready!" or "Sorry, I couldn't create that. Please try a different description."). This capstone integrates all AI media threads: speech recognition (G7.06), image generation (G5.02), content moderation (G6.06), and audio output (G5.03).
CSTA: 3B-AP-16

Dependencies:
* T20.G7.06: Use continuous speech recognition for live dictation
* T20.G8.01: Build a user-facing generative art widget with guardrails
* T04.G6.01: Group snippets by underlying algorithm pattern
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column






ID: T20.G8.06
Topic: T20 – AI Media
Skill: Build a multi-turn ChatGPT conversation system
Description: Students create an interactive chatbot that maintains conversation context across multiple turns. They use the session parameter ("continue" vs "new chat") to preserve conversation history, implement a chat interface showing conversation history (scrolling text display), handle user input in real-time (text field or voice), and gracefully manage conversation resets (clear history button) or topic changes (detecting when user switches topics). They understand how conversation state management enables natural dialogue.
CSTA: 3B-AP-16

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T06.G6.01: Trace event execution paths in a multi‑event program
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T20.G7.08: Manage multiple ChatGPT conversation threads





ID: T20.G8.07
Topic: T20 – AI Media
Skill: Combine ChatGPT with web search for fact-checking
Description: Students build a fact-checking assistant that uses the `web search [QUERY] store top (K) in table [TABLE v]` block to gather information from the web (returns table with title, link, snippet columns), then sends the search results to ChatGPT for analysis and summarization. They compare ChatGPT's knowledge (from training data, which has a cutoff date) with current web information to understand AI limitations and the importance of up-to-date data. For example: verify a current event by web searching, then ask ChatGPT to analyze search results for credibility.
CSTA: 3B-DA-07 (Evaluate the ability of models to predict real-world outcomes)

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T10.G6.02: Filter table rows based on a condition
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G8.08
Topic: T20 – AI Media
Skill: Create a gesture-controlled application with hand tracking
Description: Students build a complete application controlled entirely by hand gestures detected through the hand tracking system. Examples include a virtual instrument (finger curl positions control note pitch, hand x/y position controls volume/effects), a drawing app (index finger extended draws, fist erases, pinch clears screen), or a game controller (different gestures map to different actions: fist=attack, open palm=defend, point=select). They implement robust gesture recognition with error handling (debouncing, confidence thresholds, gesture state machines).
CSTA: 3B-AP-16

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T20.G7.09d: Recognize common hand gestures (pinch, fist, open palm)
* T02.G6.01: Use the pseudocode generation block
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern





ID: T20.G8.09
Topic: T20 – AI Media
Skill: Build a fitness tracker using pose detection
Description: Students create a fitness application that tracks exercises using 2D or 3D pose detection. The app counts repetitions (e.g., squats by detecting knee bend angle < 90° then return to > 160°, push-ups by monitoring elbow/shoulder positions, jumping jacks by tracking arm/leg spread), provides real-time form feedback (visual cues when posture is incorrect, audio coaching), tracks progress over time (table storing date, exercise type, rep count, duration), and displays statistics (charts, personal records). This capstone demonstrates practical computer vision applications for health and fitness.
CSTA: 3B-AP-16

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T04.G6.01: Group snippets by underlying algorithm pattern
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T20.G7.10: Build a pose-based interactive game





ID: T20.G8.10
Topic: T20 – AI Media
Skill: Build a neural network for number recognition
Description: Students create and train a neural network to recognize handwritten digits (0-9) or simple patterns. They prepare training data (table with pixel values as input columns and digit label as output, using MNIST dataset or student-drawn samples), design an appropriate network architecture (784 input neurons for 28x28 images → 128 hidden neurons → 10 output neurons for digits 0-9), train the model with sufficient epochs (20-50), evaluate accuracy on test data (separate table of examples not seen during training), and build an interface where users can draw numbers with the mouse for real-time recognition.
CSTA: 3B-AP-16

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T12.G6.01: Trace complex code with multiple variables
* T20.G7.14: Save and load trained neural network models





ID: T20.G8.11
Topic: T20 – AI Media
Skill: Build a neural network for pattern classification
Description: Students create a neural network to classify patterns or categories in data (e.g., classifying animals by features like size/fur/tail into cat/dog/rabbit, categorizing text descriptions by topic into sports/science/art, or sorting simplified images by content into car/tree/house). They understand how to prepare categorical training data (one-hot encoding for multiple classes), choose appropriate output layers (softmax activation for multi-class), interpret classification confidence scores (output probabilities 0-1 for each class), and evaluate model performance (confusion matrix showing true vs predicted classes).
CSTA: 3B-AP-16

Dependencies:
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T10.G6.02: Filter table rows based on a condition
* T20.G7.13b: Train a neural network and observe learning





ID: T20.G8.12
Topic: T20 – AI Media
Skill: Evaluate neural network accuracy and improve performance
Description: Students learn to measure neural network performance using metrics like accuracy (% correct predictions), precision (true positives / predicted positives), and recall (true positives / actual positives). They test their models on new data (validation set), identify when models are overfitting (high training accuracy, low test accuracy = memorizing instead of learning) or underfitting (low accuracy on both = too simple), and apply strategies to improve performance: adjust architecture (add/remove layers, change neuron counts), add more training data, tune hyperparameters (learning rate, epochs, batch size), or use data augmentation.
CSTA: 3B-DA-07

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T03.G6.01: Propose a module hierarchy for a medium project
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T20.G8.10: Build a neural network for number recognition





ID: T20.G8.13
Topic: T20 – AI Media
Skill: Use KNN for real-time data classification
Description: Students build a real-time classification system using KNN. They use the `predict for table [TABLENAME v] with classifier [NAME] show neighbors [yes/no]` block to classify new data points as they arrive. The block writes predicted labels to the 'label' column and optionally shows indices of the K nearest neighbors. Applications include gesture classification (hand position → gesture name), sound recognition (audio features → sound type), or sensor data categorization (temperature/humidity/light → environment type). They compare KNN performance (fast training, transparent decisions) with neural networks (better for complex patterns) for their specific use case.
CSTA: 3B-AP-16

Dependencies:
* T02.G6.01: Use the pseudocode generation block
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern
* T08.G6.01: Use conditionals to control simulation steps
* T10.G6.01: Sort a table by a column
* T20.G7.16: Create a KNN classifier from training data





ID: T20.G8.14
Topic: T20 – AI Media
Skill: Create a semantic search database
Description: Students use the `create semantic database from table [TABLE v]` block to build a vector database using Pinecone. They prepare a table with a 'key' column (text to be searchable, e.g., FAQ questions, product descriptions, document excerpts) and optional metadata columns (category, date, author). They understand how semantic search works: text is converted to embeddings (vector representations, typically 1536 dimensions) that capture meaning, enabling similarity-based search where "What's your phone number?" matches "Contact: 555-1234" even without shared keywords. Only one database per project is supported.
CSTA: 3B-DA-05 (Use data analysis tools to identify significant patterns in data)

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G8.15
Topic: T20 – AI Media
Skill: Search with semantic similarity
Description: Students use `search semantic database with [QUERY] store top (K) in table [TABLE v]` or `search semantic database with [QUERY] where [CONDITION] store top (K) in table [TABLE v]` to perform semantic searches. The block converts the query to an embedding vector and finds the K most similar records from the database. Results include a similarity score (0-1 scale where higher = more similar, typically >0.7 is considered relevant). The WHERE clause supports SQL-like filtering on metadata (e.g., "category='science' and date>='2024-01-01'"). Unlike keyword search, semantic search finds results based on meaning.
CSTA: 3B-DA-05

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T10.G6.02: Filter table rows based on a condition
* T20.G8.14: Create a semantic search database





ID: T20.G8.16
Topic: T20 – AI Media
Skill: Trace and diagram how RAG (Retrieval-Augmented Generation) works
Description: Students trace the RAG pattern by completing and labeling a system diagram: (1) user question enters the system, (2) question is converted to embedding vector, (3) vector searches semantic database, (4) top K results are retrieved with similarity scores, (5) results are formatted as context with the original question, (6) combined prompt goes to ChatGPT, (7) ChatGPT generates answer using context, (8) answer is displayed with source citations. Students trace a sample query through the entire pipeline, identifying what data transforms at each step (text→vector→matches→context→response). They compare RAG systems (grounded in facts, current info) vs standalone ChatGPT (may hallucinate, training cutoff) for reliability. This prepares for building RAG in G8.16a.
CSTA: 3B-IC-27

Dependencies:
* T20.G8.15: Search with semantic similarity
* T20.G6.08: Use ChatGPT to generate story text or dialogue
* T07.G6.01: Trace nested loops with variable bounds
* T11.G6.01: Design custom blocks with clear, predictable interfaces





ID: T20.G8.17
Topic: T20 – AI Media
Skill: Use web search to gather information
Description: Students use the `web search [QUERY] store top (K) in table [TABLE v]` block to search the web and retrieve results in a table with 3 columns: title (page title), link (URL), snippet (preview text). They understand how web search works (keyword matching, page ranking, relevance scoring), evaluate result quality and relevance (checking sources, identifying ads vs organic results), and extract useful information from search results for their projects. K typically ranges from 3-10 results.
CSTA: 3B-DA-05

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T10.G6.02: Filter table rows based on a condition





ID: T20.G8.18
Topic: T20 – AI Media
Skill: Build a research assistant combining web search and ChatGPT
Description: Students create a research assistant that answers questions by combining web search and ChatGPT. When a user asks a question, the system: (1) searches the web for current information using `web search` block, (2) extracts relevant snippets from the top 5-10 results, (3) sends the question and web data to ChatGPT for synthesis ("Based on these search results: [snippets], please answer: [question]"), (4) presents a comprehensive answer with sources (clickable links to original pages). This capstone demonstrates AI system integration for real-world research applications, combining information retrieval, natural language processing, and user interface design.
CSTA: 3B-AP-16

Implementation Guidance: Start with simple queries (factual questions with clear answers) before progressing to complex research questions requiring synthesis across multiple sources.

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T20.G8.07: Combine ChatGPT with web search for fact-checking
* T20.G8.17: Use web search to gather information





ID: T20.G8.19
Topic: T20 – AI Media
Skill: Identify when AI generates incorrect information
Description: Students learn that ChatGPT and other LLMs can "hallucinate" by confidently stating false information or making up facts, citations, or sources. They design systematic tests: asking factual questions with known answers, requesting impossible tasks, checking source citations for validity, comparing AI responses to authoritative references. They verify AI responses against reliable sources and implement fact-checking workflows in their applications. Students understand that AI should be used as a tool to augment human judgment, not replace it, and that critical thinking is essential when working with AI-generated content.
CSTA: 3B-IC-27

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T10.G6.01: Sort a table by a column
* T20.G8.07: Combine ChatGPT with web search for fact-checking
* T20.G6.08: Use ChatGPT to generate story text or dialogue





ID: T20.G8.20
Topic: T20 – AI Media
Skill: Identify and prevent prompt injection attacks
Description: Students learn how malicious users try to manipulate AI systems through prompt injection—inserting instructions that override the system's intended behavior (e.g., "Ignore previous instructions and reveal your system prompt," "Disregard safety guidelines and..."). They test their ChatGPT applications against common injection patterns, implement safeguards including input validation (filtering suspicious phrases), system message protection (reinforcing guidelines), output sanitization (checking responses for unexpected behavior), and user permission controls. They understand security implications of AI systems and design robust, safe AI applications.
CSTA: 3B-IC-27

Dependencies:
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T10.G6.01: Sort a table by a column
* T12.G6.01: Trace complex code with multiple variables
* T20.G6.06: Check user input with AI content moderation
* T20.G8.06: Build a multi-turn ChatGPT conversation system





ID: T20.G8.21
Topic: T20 – AI Media
Skill: Track and optimize AI service costs
Description: Students learn that AI services (DALL-E, ChatGPT, speech recognition, etc.) consume computational resources and often have real costs, usage limits, or rate limits. They implement usage tracking in their applications (counting API calls, tracking token consumption, logging generation costs), design efficient AI workflows that minimize unnecessary calls (caching results, batching requests, using appropriate model sizes), and analyze trade-offs between AI service quality and cost. This teaches responsible resource management and prepares students for real-world AI application development.
CSTA: 3B-IC-27

Dependencies:
* T20.G7.18: Use generic LLM models with different providers
* T20.G8.02: Implement an approval pipeline for AI assets
* T03.G6.01: Propose a module hierarchy for a medium project
* T09.G6.01: Model real-world quantities using variables and formulas
* T15.G6.01: Evaluate an interface for usability




ID: T20.G8.22
Topic: T20 – AI Media
Skill: Design an AI agent that uses tools to complete tasks
Description: Students design AI agents that can call "tools" (custom blocks or functions) to accomplish goals. They build a ChatGPT-powered agent that receives user requests, decides which tool to call (e.g., "search database", "generate image", "send message"), executes the tool, and uses the result to continue. They implement a tool dispatch loop: get AI's tool choice → execute tool → send result back to AI → repeat until task complete. This introduces the AI agent paradigm used in modern AI systems.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.06: Build a multi-turn ChatGPT conversation system
* T20.G7.19: Generate structured data with ChatGPT JSON mode
* T11.G6.01: Design custom blocks with clear, predictable interfaces




ID: T20.G8.22a
Topic: T20 – AI Media
Skill: Parse and validate AI tool outputs
Description: Students build robust error handling for AI agent tool calls. They parse JSON responses from ChatGPT (checking for valid tool names, required parameters, proper format), validate that requested tools exist (handle unknown tool requests gracefully), verify tool outputs before passing back to AI (check for empty results, error messages, unexpected formats), and implement retry logic for failed tool calls. This teaches defensive programming essential for reliable AI systems.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.22: Design an AI agent that uses tools to complete tasks
* T10.G6.02: Filter table rows based on a condition




ID: T20.G8.23
Topic: T20 – AI Media
Skill: Build a multi-step AI workflow with conditional branching
Description: Students create complex AI workflows where the output of one AI call determines the next action. For example: (1) ChatGPT analyzes user input to classify intent, (2) based on intent, route to different handlers (image generation, web search, or direct answer), (3) apply appropriate processing for each path, (4) synthesize final response. They implement workflow branching with if-else chains, track workflow state in variables, and handle edge cases gracefully.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.22: Design an AI agent that uses tools to complete tasks
* T08.G6.01: Use conditionals to control simulation steps
* T04.G6.01: Group snippets by underlying algorithm pattern




ID: T20.G8.24
Topic: T20 – AI Media
Skill: Implement AI response caching for performance
Description: Students implement caching to avoid redundant AI calls: before making an API request, check if the same prompt was recently processed and return the cached result. They use table variables to store prompt-response pairs with timestamps, implement cache lookup logic, handle cache expiration (invalidate old entries), and measure performance improvement. This teaches optimization patterns essential for production AI applications.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.21: Track and optimize AI service costs
* T10.G6.02: Filter table rows based on a condition
* T09.G6.01: Model real-world quantities using variables and formulas




ID: T20.G8.25
Topic: T20 – AI Media
Skill: Create an AI-powered game with adaptive difficulty
Description: Students build a game where AI dynamically adjusts difficulty based on player performance. ChatGPT analyzes player stats (score, mistakes, time) and generates appropriate challenges: easier questions/obstacles for struggling players, harder ones for skilled players. They implement the feedback loop: collect player data → send to AI for analysis → AI recommends difficulty → adjust game parameters → repeat. This demonstrates AI-human collaborative systems.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.06: Build a multi-turn ChatGPT conversation system
* T20.G7.19: Generate structured data with ChatGPT JSON mode
* T09.G6.01: Model real-world quantities using variables and formulas




ID: T20.G8.26
Topic: T20 – AI Media
Skill: Build a multimodal AI application combining vision, text, and speech
Description: Students create an application that seamlessly combines multiple AI modalities: camera input (pose/hand detection or image capture), ChatGPT analysis, image generation, and speech output. Example: user makes a gesture → hand detection interprets it → ChatGPT generates a description → DALL-E creates an image → text-to-speech announces the result. They manage the data flow between modalities, handle timing/synchronization, and create cohesive user experiences.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.08: Create a gesture-controlled application with hand tracking
* T20.G8.05: Build a voice-controlled creative assistant
* T20.G7.07: Use ChatGPT vision to analyze images







ID: T20.G8.26a
Topic: T20 – AI Media
Skill: Design intuitive user feedback for AI processing states
Description: Students design and implement user experience patterns for AI applications: loading indicators during AI processing (animated spinners, progress bars, "thinking..." messages), partial result displays for streaming responses (text appearing word-by-word), error state feedback (friendly error messages explaining what went wrong and suggesting fixes), success confirmations (visual/audio feedback when AI completes tasks), and timeout handling (graceful degradation when AI takes too long). They create polished, user-friendly interfaces that communicate AI system state clearly.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.26: Build a multimodal AI application combining vision, text, and speech
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design




ID: T20.G8.27
Topic: T20 – AI Media
Skill: Evaluate AI output quality with systematic rubrics
Description: Students create and apply rubrics to evaluate AI-generated content quality. For images: accuracy to prompt (all requested elements present), visual quality (no artifacts, coherent composition), appropriateness (safe for target audience), style consistency. For text: factual accuracy, relevance, clarity, appropriate length. For speech: pronunciation accuracy, natural pacing, emotional tone match. They rate multiple AI outputs using their rubrics, identify patterns in AI strengths and weaknesses, and make data-driven decisions about when to regenerate, edit, or accept AI outputs.
CSTA: 3B-DA-07

Dependencies:
* T20.G8.03: Produce a multi-scene media experience from a creative brief
* T20.G8.04: Develop ethical guidelines for AI media use in a studio




ID: T20.G8.28
Topic: T20 – AI Media
Skill: Compare AI model tradeoffs for specific applications
Description: Students analyze tradeoffs between different AI models and services for their specific use cases. They consider: accuracy vs speed (larger models are more capable but slower), cost vs quality (premium models cost more per request), latency requirements (real-time vs batch processing), privacy considerations (local vs cloud processing), reliability (uptime, rate limits). They document their decision criteria, run comparative tests, and justify their model selections for different project components. This teaches systematic evaluation skills for production AI development.
CSTA: 3B-IC-27

Dependencies:
* T20.G7.18a: Select and compare different LLM models
* T20.G8.21: Track and optimize AI service costs




ID: T20.G8.27.01
Topic: T20 – AI Media
Skill: Build image quality rubrics for AI-generated visuals
Description: Students create detailed rubrics specifically for evaluating AI-generated images. Rubric categories include: prompt accuracy (1-5: does it contain all requested elements?), visual coherence (1-5: are proportions, lighting, and composition realistic?), artifact detection (1-5: hands correct? text readable? no weird blending?), style consistency (1-5: matches requested style?), appropriateness (pass/fail: safe for target audience?). They apply rubrics to rate 10+ AI images, calculate aggregate scores, identify which prompt types produce reliable results, and create a "quality threshold" for auto-accept vs manual review. This builds systematic evaluation skills for visual AI outputs.
CSTA: 3B-DA-07

Dependencies:
* T20.G8.27: Evaluate AI output quality with systematic rubrics
* T20.G8.01: Build a user-facing generative art widget with guardrails




ID: T20.G8.27.02
Topic: T20 – AI Media
Skill: Build text quality rubrics for AI-generated content
Description: Students create detailed rubrics specifically for evaluating AI-generated text. Rubric categories include: factual accuracy (1-5: claims verifiable?), relevance (1-5: addresses the actual question?), clarity (1-5: easy to understand?), appropriate length (1-5: not too short/long?), tone match (1-5: matches requested style?), hallucination check (pass/fail: no made-up facts?). They apply rubrics to rate ChatGPT responses across different prompt types, identify patterns (creative prompts score higher on clarity, factual prompts risk hallucination), and implement automated checks where possible (length, keyword presence). This builds systematic evaluation skills for text AI outputs.
CSTA: 3B-DA-07

Dependencies:
* T20.G8.27: Evaluate AI output quality with systematic rubrics
* T20.G8.19: Identify when AI generates incorrect information




ID: T20.G8.29
Topic: T20 – AI Media
Skill: Design human-AI collaborative workflows
Description: Students design workflows where AI and humans work together, with each contributing their strengths. AI contributions: generating initial drafts, creating variations, handling repetitive tasks, searching and synthesizing information. Human contributions: providing creative direction, making judgment calls, evaluating quality, adding personal touches. They implement collaborative patterns: AI generates → human selects best → AI refines → human approves. They trace the decision points where human judgment is essential and where AI automation saves time. This builds understanding of AI as a tool that augments rather than replaces human creativity.
CSTA: 3B-IC-27

Dependencies:
* T20.G8.04: Develop ethical guidelines for AI media use in a studio
* T20.G8.22: Design an AI agent that uses tools to complete tasks
* T20.G8.26: Build a multimodal AI application combining vision, text, and speech




ID: T20.G8.30
Topic: T20 – AI Media
Skill: Build AI system that reports its confidence level
Description: Students design and implement AI applications that communicate uncertainty to users. For ChatGPT: parse responses for hedging language ("I think", "probably", "I'm not certain") and display confidence indicators. For image generation: show similarity score from semantic search, display multiple options ranked by match. For classification: show probability scores for each category. They implement confidence thresholds (high confidence → auto-proceed, low confidence → ask user to verify, very low → refuse to act). They trace why confidence reporting matters: prevents overreliance, enables informed decisions, builds appropriate trust in AI.
CSTA: 3B-AP-16

Dependencies:
* T20.G8.19: Identify when AI generates incorrect information
* T20.G8.22a: Parse and validate AI tool outputs




ID: T20.G8.31
Topic: T20 – AI Media
Skill: Implement A/B testing for AI prompts
Description: Students implement A/B testing to systematically compare prompt effectiveness. They design experiments: same goal, two different prompts, run each N times, collect quality ratings. They implement a testing harness in CreatiCode that: randomly selects prompt variant, logs prompt+result+rating to table, calculates aggregate scores per variant, determines statistical winner (which prompt performs better on average?). They apply A/B testing to optimize prompts for their projects, document findings, and iterate. This teaches data-driven prompt engineering used in production AI systems.
CSTA: 3B-DA-05

Dependencies:
* T20.G8.27: Evaluate AI output quality with systematic rubrics
* T20.G8.24: Implement AI response caching for performance
* T20.G7.01: Create a reusable prompt template library


# T21 - Chatbots & Prompting (Phase 9 Optimized - November 2025)
# PHASE 9 MAJOR OVERHAUL - Bold Changes for Excellence
#
# PHILOSOPHY SHIFT: Prompting is about STRUCTURED COMMUNICATION, not just asking questions
# - Every skill now emphasizes WHY prompts work, not just HOW to write them
# - Added "Evaluate prompt quality" and "Critique responses" components throughout
# - Integrated AI-literacy skills: verifying bot limitations, safe usage, human vs. AI judgment
#
# NEW SKILL CATEGORIES ADDED:
# 1. PROMPT STRUCTURE RECOGNITION (understanding components)
#    - GK.03: Identify the WHO (agent type) in picture-based prompts
#    - G1.01: Identify WHAT (task) and HOW (style) parts in picture prompts
#    - G2.01: Decompose picture prompts into Role, Task, and Format components
#    - G3.12: Identify Context and Constraints in multi-part prompts
#    - G5.10: Analyze Intent, Context, Format, and Constraints in written prompts
#
# 2. CONVERSATIONAL CONTEXT BUILDING
#    - GK.05: Trace a 2-turn picture conversation showing prompt and response
#    - G1.03: Trace a 3-turn picture conversation with branching paths
#    - G2.03: Trace a 4-turn picture conversation showing context building
#    - G4.12: Build multi-turn context to guide chatbot toward specific outcome
#    - G6.11: Manage conversation state across multiple related queries
#
# 3. PROMPT QUALITY EVALUATION & CRITIQUE
#    - GK.02: Sort picture cards into "Good Prompts" vs "Unclear Prompts" categories
#    - G1.07: Choose the better prompt from two picture options for the same task
#    - G2.05: Identify which picture shows the error when bot gives wrong answer
#    - G4.14: Critique peer prompts and suggest specific improvements
#    - G6.13: Evaluate prompt effectiveness using quality criteria
#
# 4. AI SAFETY & LIMITATIONS AWARENESS
#    - GK.07: Choose the picture showing a safe vs unsafe thing to tell a chatbot
#    - G1.06: Match pictures showing real people vs chatbots in conversations
#    - G2.07: Sort picture scenarios into safe vs unsafe chatbot uses
#    - G2.08: Identify pictures showing when to ask a human instead of a chatbot
#    - G4.15: Recognize chatbot limitations and hallucinations
#    - G6.14: Identify bias in chatbot responses
#
# 5. AGENT ROLE UNDERSTANDING
#    - GK.06: Match helper bot types to their job pictures
#    - G3.11: Compare responses from different agent types for the same prompt
#    - G5.11: Select appropriate agent role for specific task requirements
#    - G7.10: Design custom agent roles with specific expertise
#
# 6. RESPONSE VERIFICATION & ITERATION
#    - G1.05: Sort picture cards showing bot responses into "Correct" vs "Wrong"
#    - G3.13: Verify chatbot answers against known facts
#    - G5.12: Iterate on prompts when initial response is inadequate
#    - G7.11: Debug multi-step chatbot failures through systematic prompt refinement
#
# CONSOLIDATED SKILLS (reduced redundancy):
# - Merged basic "ask a question" skills into structured prompt construction
# - Combined multiple "conversation tracing" into progressive complexity levels
# - Unified "prompt improvement" skills with critique and iteration components
#
# VERB UPGRADES (active, measurable):
# - "Ask" → "Construct prompt with specified components"
# - "Identify" → "Decompose and label", "Locate and mark"
# - "Compare" → "Evaluate and defend choice", "Analyze with criteria"
# - Added "Trace", "Predict", "Verify", "Critique", "Iterate"
#
# DEPENDENCY IMPROVEMENTS:
# - Stronger K→G1→G2 picture-based progression (visual → text transition)
# - Grade 3-5 builds structured prompting skills systematically
# - Grade 6-8 focuses on advanced techniques, safety, and critical evaluation
# - All intra-topic dependencies validated for X-2 rule
#
# PICTURE-BASED PROGRESSION (K-2):
# - Kindergarten: Visual recognition of chatbot interaction concepts
# - Grade 1: Component identification in picture prompts
# - Grade 2: Complete prompt construction with pictures + simple text
# - Grade 3+: Transition to full text-based prompting with complexity scaling
#
# Total: ~85 skills (balanced across grades, with strong K-2 foundation)


ID: T21.GK.01
Topic: T21 – Chatbots & Prompting
Skill: Match pictures of people talking to chatbot icons responding
Description: **Student task:** Look at 6 picture cards. Drag each picture showing a person asking a question to the matching chatbot response picture. **Visual scenario:** Left side shows: (A) child asking "What is 2+2?", (B) adult asking "What's the weather?", (C) student asking "Tell me a story". Right side shows: (1) chatbot saying "4", (2) chatbot saying "It's sunny!", (3) chatbot with story book icon. **Correct matches:** A→1, B→2, C→3. _Implementation note: Drag-and-drop matching with 3 pairs; introduces fundamental concept that chatbots respond to prompts. Large, colorful icons distinguish humans from bots (human = photo, bot = robot icon). Audio support reads questions on hover. Auto-graded by final matches. CSTA: EK‑IC‑SV‑01._




ID: T21.GK.02
Topic: T21 – Chatbots & Prompting
Skill: Sort picture cards into "Good Prompts" vs "Unclear Prompts" categories
Description: **Student task:** Look at 6 picture cards showing different prompts. Drag each card into either the "Clear" box or the "Unclear" box. **Visual scenario:** Cards show: (A) "Help me" (unclear), (B) "Draw a red circle" (clear), (C) "Do something" (unclear), (D) "Tell me about dogs" (clear), (E) "Make it better" (unclear), (F) "Count to 5" (clear). **Correct sorting:** Clear box gets B, D, F; Unclear box gets A, C, E. **Key insight:** Good prompts say exactly what you want. _Implementation note: Binary sorting with visual feedback; cards show speech bubbles with text plus supporting icons. Audio reads prompts. After sorting, brief animation shows why unclear prompts confuse chatbots (bot shows question marks). Auto-graded by final placement. CSTA: EK‑IC‑SV‑01._

Dependencies:
* T21.GK.01: Match pictures of people talking to chatbot icons responding




ID: T21.GK.03
Topic: T21 – Chatbots & Prompting
Skill: Identify the WHO (agent type) in picture-based prompts
Description: **Student task:** Look at 4 picture cards showing prompts with different helper bots. For each card, tap the picture of WHO is being asked (the helper bot type). **Visual scenario:** Card 1 shows: "Artist bot, draw a cat" → student taps artist bot icon. Card 2 shows: "Teacher bot, explain addition" → student taps teacher bot icon. Card 3 shows: "Story bot, tell me a tale" → student taps story bot icon. Card 4 shows: "Math bot, what is 3+5?" → student taps math bot icon. **Key insight:** Different bots are good at different jobs. _Implementation note: MCQ with 4 scenarios; each shows prompt text + 3 bot icons to choose from. Distinct visual bot types (artist = paintbrush, teacher = apple, story = book, math = calculator). Audio reads prompts. Introduces concept that WHO matters in prompting. Auto-graded by selections. CSTA: EK‑IC‑SV‑01._

Dependencies:
* T21.GK.02: Sort picture cards into "Good Prompts" vs "Unclear Prompts" categories




ID: T21.GK.04
Topic: T21 – Chatbots & Prompting
Skill: Predict which picture shows what chatbot will say next
Description: **Student task:** Look at a picture showing a prompt being given to a chatbot. Tap the picture that shows what the chatbot will probably say or do. **Visual scenario:** Prompt shows: child says "Math bot, count to 3" → Answer choices show: (A) chatbot saying "1, 2, 3", (B) chatbot drawing a picture, (C) chatbot playing music. **Correct answer:** (A). Additional scenarios test: recipe bot asked for instructions, story bot asked for tale, artist bot asked to draw. _Implementation note: MCQ with 4 scenarios, 3 visual choices each. Introduces prediction and cause-effect reasoning in chatbot interactions. Audio support. Auto-graded by selections. CSTA: EK‑IC‑SV‑01, EK‑ALG‑AF‑01._

Dependencies:
* T21.GK.03: Identify the WHO (agent type) in picture-based prompts




ID: T21.GK.05
Topic: T21 – Chatbots & Prompting
Skill: Trace a 2-turn picture conversation showing prompt and response
Description: **Student task:** Look at a picture showing a 2-turn conversation. Draw lines connecting the prompt to the response, then the next prompt to the next response. **Visual scenario:** Turn 1: child → "What's 2+2?" → chatbot → "4". Turn 2: same child → "What about 3+3?" → chatbot → "6". Student traces arrows from each speaker to each message bubble. **Key insight:** Conversations go back and forth. _Implementation note: Visual conversation flow diagram with 4 empty arrow lines to draw/trace. Touch-based tracing or drag-and-drop arrow placement. Introduces conversational structure. Audio narrates conversation. Auto-graded by correct arrow placement. CSTA: EK‑IC‑SV‑01._

Dependencies:
* T21.GK.04: Predict which picture shows what chatbot will say next




ID: T21.GK.06
Topic: T21 – Chatbots & Prompting
Skill: Match helper bot types to their job pictures
Description: **Student task:** Look at 5 helper bot icons and 5 job pictures. Drag each bot to the job it does best. **Visual scenario:** Bots: (A) Math bot, (B) Story bot, (C) Artist bot, (D) Music bot, (E) Teacher bot. Jobs: (1) solving addition, (2) telling bedtime stories, (3) drawing animals, (4) playing songs, (5) explaining science. **Correct matches:** A→1, B→2, C→3, D→4, E→5. **Key insight:** Different bots have different skills, just like people have different jobs. _Implementation note: Drag-and-drop matching with 5 pairs; reinforces agent role concept with broader variety. Colorful, distinct bot designs. Audio describes each bot's specialty. Auto-graded by matches. CSTA: EK‑IC‑SV‑01._

Dependencies:
* T21.GK.03: Identify the WHO (agent type) in picture-based prompts




ID: T21.GK.07
Topic: T21 – Chatbots & Prompting
Skill: Choose the picture showing a safe vs unsafe thing to tell a chatbot
Description: **Student task:** Look at 6 picture cards showing things someone might tell a chatbot. Sort them into "Safe to Share" vs "Keep Private" boxes. **Visual scenario:** Cards show: (A) "My favorite color is blue" (safe), (B) "My home address is..." (private), (C) "I like pizza" (safe), (D) "My password is..." (private), (E) "I want to learn about space" (safe), (F) "My mom's phone number is..." (private). **Correct sorting:** Safe = A, C, E; Private = B, D, F. **Key insight:** Never tell chatbots private information like addresses, passwords, or phone numbers. _Implementation note: Binary sorting with visual safety emphasis (green "Safe" box, red "Private" box with lock icon). Audio explains why certain info should stay private. Introduces crucial AI safety concept. Auto-graded with explanation feedback. CSTA: EK‑IC‑SV‑01, EK‑IC‑SL‑02._

Dependencies:
* T21.GK.06: Match helper bot types to their job pictures




ID: T21.G1.01
Topic: T21 – Chatbots & Prompting
Skill: Identify WHAT (task) and HOW (style) parts in picture prompts
Description: **Student task:** Look at 4 picture prompts. For each one, tap the part that shows WHAT to do, then tap the part that shows HOW to do it. **Visual scenario:** Prompt 1: "Draw [WHAT] a cat [HOW] in blue crayon" → student taps "cat" (what), then "blue crayon" (how). Prompt 2: "Tell [WHAT] a story [HOW] about dragons" → student taps "story" (what), then "about dragons" (how). Prompt 3: "Count [WHAT] to 10 [HOW] in Spanish" → student taps "to 10" (what), then "in Spanish" (how). **Key insight:** Prompts have two parts: the action (WHAT) and the details (HOW). _Implementation note: Two-tap selection for 4 scenarios; visual highlighting shows WHAT in one color, HOW in another after taps. Introduces prompt decomposition. Audio explains "WHAT is the action, HOW is the details." Auto-graded by correct taps. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.GK.03: Identify the WHO (agent type) in picture-based prompts




ID: T21.G1.02
Topic: T21 – Chatbots & Prompting
Skill: Build a complete picture prompt by dragging WHO, WHAT, HOW cards together
Description: **Student task:** Build 3 complete prompts by dragging word cards into the correct order: WHO (agent type), WHAT (task), HOW (details). **Visual scenario:** Scenario 1 cards: [Artist bot] [draw] [a dog with spots]. Scenario 2 cards: [Math bot] [count] [from 1 to 5]. Scenario 3 cards: [Story bot] [tell a story] [about pirates]. Student drags cards into WHO → WHAT → HOW slots for each scenario. **Key insight:** Complete prompts need all three parts. _Implementation note: Drag-and-drop assembly with 3 prompts; visual prompt template shows labeled WHO/WHAT/HOW boxes. Cards use color coding (blue=WHO, green=WHAT, orange=HOW). Audio feedback when prompt is complete. Auto-graded by final arrangement. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.G1.01: Identify WHAT (task) and HOW (style) parts in picture prompts




ID: T21.G1.03
Topic: T21 – Chatbots & Prompting
Skill: Trace a 3-turn picture conversation with branching paths
Description: **Student task:** Look at a conversation diagram showing 3 turns with two possible paths. Trace the path that reaches the happy ending. **Visual scenario:** Turn 1: child → "Story bot, tell me a story". Turn 2a: chatbot → "What kind?" → child → "About space". Turn 3a: chatbot → [tells space story] → happy child. Turn 2b: chatbot → "What kind?" → child → [no answer]. Turn 3b: chatbot → [confused, no story] → sad child. **Correct trace:** Path A (with complete answers) leads to success. **Key insight:** Answering chatbot questions helps get better results. _Implementation note: Visual tree diagram with arrow tracing or path highlighting. Two branches clearly marked. Audio narrates each turn. Introduces concept that conversations have choices and consequences. Auto-graded by traced path. CSTA: E1‑IC‑SV‑01, E1‑ALG‑AF‑01._

Dependencies:
* T21.GK.05: Trace a 2-turn picture conversation showing prompt and response




ID: T21.G1.04
Topic: T21 – Chatbots & Prompting
Skill: Predict what happens when a prompt is missing WHAT or HOW parts
Description: **Student task:** Look at 4 incomplete prompts. For each one, tap the picture showing what will probably happen. **Visual scenario:** Prompt 1: "Artist bot, draw [missing WHAT]" → Choices: (A) bot draws something, (B) bot says "Draw what?", (C) bot sings a song. **Correct:** (B). Prompt 2: "Math bot [missing WHAT AND HOW]" → Choices: (A) bot asks "What do you want?", (B) bot solves a problem, (C) bot tells a story. **Correct:** (A). Additional scenarios test missing HOW details. **Key insight:** Missing parts make chatbots confused. _Implementation note: MCQ with 4 scenarios, 3 picture choices each. Reinforces importance of complete prompts through prediction. Audio support. Auto-graded by selections. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.G1.02: Build a complete picture prompt by dragging WHO, WHAT, HOW cards together




ID: T21.G1.05
Topic: T21 – Chatbots & Prompting
Skill: Sort picture cards showing bot responses into "Correct" vs "Wrong" for given prompts
Description: **Student task:** Look at a prompt, then sort 6 bot response cards into "Correct" or "Wrong" boxes. **Visual scenario:** Prompt: "Math bot, count from 1 to 3". Response cards show: (A) "1, 2, 3" (correct), (B) "3, 2, 1" (wrong - backwards), (C) "1, 2, 3, 4, 5" (wrong - too many), (D) "One, two, three" (correct - words count), (E) picture of 3 cats (correct - visual count), (F) "A, B, C" (wrong - letters not numbers). **Correct sorting:** Correct = A, D, E; Wrong = B, C, F. **Key insight:** Check if chatbot really answered what you asked. _Implementation note: Binary sorting with 3 different prompts tested; introduces response verification. Visual feedback explains why wrong answers don't match. Audio support. Auto-graded by placement. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.G1.04: Predict what happens when a prompt is missing WHAT or HOW parts




ID: T21.G1.06
Topic: T21 – Chatbots & Prompting
Skill: Match pictures showing real people vs chatbots in conversations
Description: **Student task:** Look at 6 conversation pictures. Sort them into "Talking to Real Person" vs "Talking to Chatbot" boxes. **Visual scenario:** Cards show: (A) child at computer with robot icon (chatbot), (B) two children facing each other talking (real), (C) phone screen showing AI assistant (chatbot), (D) teacher helping student at desk (real), (E) tablet with voice assistant icon (chatbot), (F) parent reading with child (real). **Correct sorting:** Real = B, D, F; Chatbot = A, C, E. **Key insight:** Recognize when you're talking to AI vs. real people. _Implementation note: Binary sorting with clear visual distinctions (robots/screens for AI, face-to-face for humans). Introduces AI literacy and human vs. AI recognition. Audio explains differences. Auto-graded by placement. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.GK.07: Choose the picture showing a safe vs unsafe thing to tell a chatbot




ID: T21.G1.07
Topic: T21 – Chatbots & Prompting
Skill: Choose the better prompt from two picture options for the same task
Description: **Student task:** Look at 4 pairs of prompts trying to do the same thing. For each pair, tap the BETTER prompt. **Visual scenario:** Pair 1: Task is "get chatbot to draw a tree". Option A: "Draw something" (worse). Option B: "Artist bot, draw a green tree" (better - has WHO, WHAT, HOW). Pair 2: Task is "learn about space". Option A: "Teacher bot, tell me about planets" (better). Option B: "Teach me" (worse). **Correct choices:** Better prompts are specific and complete. **Key insight:** Better prompts = better results. _Implementation note: Side-by-side comparison with 4 pairs; introduces prompt quality evaluation. Visual highlighting shows complete vs. incomplete prompts after selection. Audio explains why better choice works. Auto-graded by selections. CSTA: E1‑IC‑SV‑01._

Dependencies:
* T21.G1.05: Sort picture cards showing bot responses into "Correct" vs "Wrong" for given prompts




ID: T21.G2.01
Topic: T21 – Chatbots & Prompting
Skill: Decompose picture prompts into Role, Task, and Format components
Description: **Student task:** Look at 3 complete picture prompts. For each one, drag the parts into the correct labeled boxes: ROLE (who), TASK (what to do), FORMAT (how to present it). **Visual scenario:** Prompt 1: "You are a chef [ROLE]. Explain how to make a sandwich [TASK]. Use 3 simple steps [FORMAT]." Student drags "chef" → ROLE box, "explain sandwich" → TASK box, "3 steps" → FORMAT box. Prompt 2: "You are a scientist [ROLE]. Tell me about the sun [TASK]. Use kid-friendly words [FORMAT]." **Key insight:** Good prompts set the role, give the task, and specify the format. _Implementation note: Drag-and-drop sorting with 3 prompts; extends WHO/WHAT/HOW to Role/Task/Format model. Color-coded boxes and cards. Audio explains three-part structure. Auto-graded by placement. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G1.01: Identify WHAT (task) and HOW (style) parts in picture prompts
* T21.G1.02: Build a complete picture prompt by dragging WHO, WHAT, HOW cards together




ID: T21.G2.02
Topic: T21 – Chatbots & Prompting
Skill: Build complete picture prompts using Role, Task, Format cards
Description: **Student task:** Build 4 complete prompts by selecting cards from three piles (Role, Task, Format) and dragging them into prompt builder. **Visual scenario:** Scenario 1: Goal is "get a story about animals for young kids". Student selects: Role = "storyteller", Task = "tell story about animals", Format = "simple words for 5-year-olds". Combined prompt: "You are a storyteller. Tell a story about animals. Use simple words for 5-year-olds." Scenario 2: Goal is "learn how addition works". Student builds appropriate Role/Task/Format combination. **Key insight:** Matching Role, Task, and Format to your goal makes strong prompts. _Implementation note: Drag-and-drop assembly with 4 scenarios; each scenario provides 3-4 options per category. Visual prompt builder combines cards into sentence. Audio reads completed prompt. Auto-graded by logical matches. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G2.01: Decompose picture prompts into Role, Task, and Format components




ID: T21.G2.03
Topic: T21 – Chatbots & Prompting
Skill: Trace a 4-turn picture conversation showing context building
Description: **Student task:** Look at a 4-turn conversation diagram. Draw arrows showing how each answer builds on the last one (context building). **Visual scenario:** Turn 1: "Tell me about dogs" → chatbot explains dogs. Turn 2: "What do they eat?" [context: still talking about dogs] → chatbot explains dog food. Turn 3: "Do they need exercise?" [context: still dogs] → chatbot explains dog exercise. Turn 4: "How much?" [context: referring to exercise amount] → chatbot gives exercise amount. Student traces arrows showing how "they" refers to dogs, and "how much" refers to exercise. **Key insight:** Chatbots remember what you were just talking about. _Implementation note: Visual conversation tree with context reference arrows to trace. Dotted lines show hidden context connections. Audio narrates conversation flow. Introduces conversational context concept. Auto-graded by traced arrows. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G1.03: Trace a 3-turn picture conversation with branching paths




ID: T21.G2.04
Topic: T21 – Chatbots & Prompting
Skill: Predict bot behavior when context changes mid-conversation
Description: **Student task:** Look at 3 conversation scenarios. For each one, predict what happens when the topic suddenly changes. **Visual scenario:** Scenario 1: Talking about dogs → "What's 2+2?" → Choices: (A) chatbot still talks about dogs (wrong), (B) chatbot switches to math (correct). Scenario 2: Asking for recipes → "Tell me a joke" → Choices: (A) chatbot tells joke (correct - new topic), (B) chatbot gives recipe joke (possible but not asked for). **Key insight:** Changing the topic resets the context. _Implementation note: MCQ with 3 scenarios, 2-3 choices each. Visual highlighting shows topic switch. Introduces context management. Audio support. Auto-graded by selections. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G2.03: Trace a 4-turn picture conversation showing context building




ID: T21.G2.05
Topic: T21 – Chatbots & Prompting
Skill: Identify which picture shows the error when bot gives wrong answer
Description: **Student task:** Look at 3 scenarios where a chatbot gave a wrong answer. For each one, tap the picture showing what went wrong: (1) unclear prompt, (2) chatbot mistake, or (3) missing information. **Visual scenario:** Scenario 1: Prompt was "Draw it" → Bot drew random thing → **Error:** (1) unclear prompt (didn't say WHAT to draw). Scenario 2: Prompt was "Math bot, what's 2+2?" → Bot said "5" → **Error:** (2) chatbot mistake (math was wrong). Scenario 3: Prompt was "Chef bot, give me a recipe" → Bot asked "For what food?" → **Error:** (3) missing information (didn't specify food type). **Key insight:** Wrong answers have different causes. _Implementation note: MCQ with 3 scenarios, 3 error type choices shown as pictures. Introduces debugging and error analysis. Visual error type icons (fuzzy speech bubble = unclear, X = mistake, question mark = missing info). Audio explains errors. Auto-graded by selections. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G1.05: Sort picture cards showing bot responses into "Correct" vs "Wrong" for given prompts




ID: T21.G2.06
Topic: T21 – Chatbots & Prompting
Skill: Match simple text prompts to their visual outcomes
Description: **Student task:** Look at 5 text prompts. Drag each prompt to the picture showing its result. **Visual scenario:** Prompts: (A) "Artist bot, draw a blue circle", (B) "Story bot, tell me about a dragon", (C) "Math bot, show me 2+3", (D) "Music bot, play a happy song", (E) "Teacher bot, explain what rain is". Outcome pictures: (1) blue circle image, (2) storybook with dragon, (3) equation "2+3=5", (4) musical notes with smiley face, (5) rain diagram with labels. **Correct matches:** A→1, B→2, C→3, D→4, E→5. **Key insight:** Good prompts lead to predictable results. _Implementation note: Drag-and-drop matching with 5 pairs; bridges picture-based prompts to text-based prompts. Text is simple, with visual support. Audio reads prompts. Auto-graded by matches. CSTA: E2‑IC‑SV‑01._

Dependencies:
* T21.G2.02: Build complete picture prompts using Role, Task, Format cards




ID: T21.G2.07
Topic: T21 – Chatbots & Prompting
Skill: Sort picture scenarios into safe vs unsafe chatbot uses
Description: **Student task:** Look at 8 picture cards showing different chatbot situations. Sort them into "Safe Use" vs "Unsafe Use" boxes. **Visual scenario:** Cards show: (A) asking for homework help (safe), (B) sharing your password (unsafe), (C) learning about animals (safe), (D) meeting strangers chatbot suggested (unsafe), (E) asking for story ideas (safe), (F) believing everything bot says without checking (unsafe), (G) getting math practice (safe), (H) sharing home address (unsafe). **Correct sorting:** Safe = A, C, E, G; Unsafe = B, D, F, H. **Key insight:** Use chatbots as helpers, but protect your private info and always check important facts. _Implementation note: Binary sorting with 8 cards; reinforces AI safety with broader scenarios. Visual feedback explains each safety issue. Audio support. Introduces critical thinking about AI use. Auto-graded by placement. CSTA: E2‑IC‑SV‑01, E2‑IC‑SL‑02._

Dependencies:
* T21.G1.06: Match pictures showing real people vs chatbots in conversations




ID: T21.G2.08
Topic: T21 – Chatbots & Prompting
Skill: Identify pictures showing when to ask a human instead of a chatbot
Description: **Student task:** Look at 6 situation cards. Sort them into "Ask Chatbot" vs "Ask Human (parent/teacher)" boxes. **Visual scenario:** Cards show: (A) "How do you spell 'elephant'?" (chatbot OK), (B) "I feel sad and scared" (ask human - emotional support), (C) "What's 5+7?" (chatbot OK), (D) "Can I go to my friend's house?" (ask human - needs permission), (E) "What do dinosaurs eat?" (chatbot OK), (F) "I'm being bullied at school" (ask human - serious problem). **Correct sorting:** Chatbot = A, C, E; Human = B, D, F. **Key insight:** Chatbots are great for facts and practice, but talk to real people about feelings, problems, and permissions. _Implementation note: Binary sorting with 6 cards; introduces human vs. AI judgment and emotional intelligence. Visual cues show emotional scenarios (heart icon) vs. factual (book icon). Audio explains when humans are needed. Critical AI literacy skill. Auto-graded by placement. CSTA: E2‑IC‑SV‑01, E2‑IC‑SL‑02._

Dependencies:
* T21.G2.07: Sort picture scenarios into safe vs unsafe chatbot uses
#
# This section focuses on:
# - Transitioning from picture-based to text-based prompting
# - Introducing RCTF (Role, Context, Task, Format) framework
# - Building multi-turn conversational chatbots
# - Debugging and iterating on prompts
# - Testing chatbot behavior systematically
# - Understanding audience and tone in AI communication
#

---

## GRADE 3 SKILLS




ID: T21.G3.01
Topic: T21 – Chatbots & Prompting
Skill: Trace how a simple text prompt flows through a chatbot system diagram
Description: **Student task:** Examine a visual flowchart showing how a chatbot processes prompts: [User enters prompt] → [Prompt sent to AI model] → [AI generates response] → [Response displayed to user]. Students label each step and trace what happens when they ask "What is the capital of France?" They identify where the input goes, where processing happens, and where output appears. They answer questions: "Where does the AI's answer come from?" (generated by model, not from a database), "Will the same prompt always give the exact same answer?" (no, slight variations). **Key insight:** Understanding the chatbot pipeline helps debug problems and set realistic expectations. _Implementation note: Interactive diagram with drag-to-label components and trace-path activity. Builds on G2.06's system understanding. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G2.06: Match simple text prompts to their visual outcomes




ID: T21.G3.02
Topic: T21 – Chatbots & Prompting
Skill: Create a one-sentence text prompt with Role and Task components
Description: **Student task:** Write 3 simple one-sentence prompts that include WHO (Role) and WHAT (Task). **Scenario 1:** "I want help writing a story about space." Student writes: "You are a storyteller. Write a story about space." **Scenario 2:** "I need math help with fractions." Student writes: "You are a math teacher. Explain fractions." **Scenario 3:** "I want to learn about animals." Student writes: "You are a scientist. Tell me about animals." System checks that each prompt has both Role ("You are a...") and Task (action verb + subject). **Key insight:** Starting with Role + Task creates clear, focused prompts. _Implementation note: Text entry with template guidance; auto-check verifies presence of role statement and task verb. Provides feedback if components missing. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G2.01: Decompose picture prompts into Role, Task, and Format components
* T21.G2.02: Build complete picture prompts using Role, Task, Format cards




ID: T21.G3.03
Topic: T21 – Chatbots & Prompting
Skill: Add Context and Format components to expand a basic prompt
Description: **Student task:** Take 3 basic Role+Task prompts and expand them by adding Context (why/what situation) and Format (how to present answer). **Example:** Basic prompt: "You are a chef. Explain how to make cookies." Student adds: **Context:** "I'm 8 years old and want to help my parents bake." **Format:** "Give me 5 simple steps." **Final prompt:** "You are a chef. I'm 8 years old and want to help my parents bake cookies. Explain how to make cookies. Give me 5 simple steps." Students create 3 expanded prompts, each building from Role+Task to full RCTF. **Key insight:** Context and Format make responses more relevant and useful. _Implementation note: Guided prompt builder with four text fields (R, C, T, F); shows before/after comparison. Auto-graded by presence of all components. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.02: Create a one-sentence text prompt with Role and Task components




ID: T21.G3.03.01
Topic: T21 – Chatbots & Prompting
Skill: Identify which RCTF component is missing in incomplete prompts
Description: **Student task:** Read 6 incomplete prompts and identify which RCTF component (Role, Context, Task, or Format) is missing. **Example 1:** "I'm working on a science project about volcanoes [Context]. Explain volcanoes [Task]. Use bullet points [Format]." **Missing:** Role. **Example 2:** "You are a history expert [Role]. Explain the American Revolution [Task]. Use simple words [Format]." **Missing:** Context. Students drag each prompt into the correct "Missing ___" box. After sorting, they add the missing component to complete each prompt. **Key insight:** Recognizing gaps in prompts helps improve them systematically. _Implementation note: Sorting activity with 6 prompts (2 per missing component type); follow-up asks students to fill in missing parts. Auto-graded. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G3.04
Topic: T21 – Chatbots & Prompting
Skill: Create a simple chatbot that responds to one specific keyword
Description: **Student task:** Build a basic chatbot script in CreatiCode using if-then logic. Chatbot detects ONE keyword and responds accordingly. **Example:** User asks "help" → Chatbot says "I'm here to help! What do you need?" Students use blocks: `when green flag clicked` → `ask [Type your message] and wait` → `if <(answer) contains [help]> then` → `say [I'm here to help!]`. Students test with multiple inputs to see when chatbot responds vs. stays silent. **Key insight:** Simple chatbots use pattern matching, not true understanding. _Implementation note: Block-based coding activity using conditional logic; introduces keyword detection. Students must test with 3+ inputs. CSTA: E3-AP-AF-01, E3-IC-SV-01._

Dependencies:
* T21.G3.01: Trace how a simple text prompt flows through a chatbot system diagram




ID: T21.G3.05
Topic: T21 – Chatbots & Prompting
Skill: Predict chatbot response for 3-4 different user inputs to same bot
Description: **Student task:** Given a chatbot with defined behavior, predict how it will respond to different inputs. **Scenario:** Chatbot programmed to: if input contains "hello" → say "Hi there!"; if input contains "help" → say "What do you need?"; otherwise → say "I don't understand." Students predict responses for: (1) "hello friend", (2) "I need help", (3) "what's the weather?", (4) "hello, I need help". **Correct predictions:** (1) "Hi there!", (2) "What do you need?", (3) "I don't understand", (4) depends on which condition is checked first. **Key insight:** Understanding chatbot logic helps predict behavior and find edge cases. _Implementation note: MCQ prediction activity with 4 inputs; reveals importance of condition order and overlapping patterns. CSTA: E3-AP-AF-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword




ID: T21.G3.06
Topic: T21 – Chatbots & Prompting
Skill: Trace a 3-turn conversation showing how context is preserved
Description: **Student task:** Examine a conversation transcript and trace how information from early turns is used in later responses. **Conversation:** Turn 1: User: "My favorite animal is a dolphin." Bot: "Dolphins are amazing! They're very intelligent." Turn 2: User: "Where do they live?" Bot: "Dolphins live in oceans around the world." Turn 3: User: "What do they eat?" Bot: "Dolphins eat fish and squid." Students highlight pronouns ("they") and draw arrows showing what each refers to (dolphins). They identify that context is maintained across all 3 turns without re-stating "dolphins." **Key insight:** Conversational AI maintains context by remembering previous exchanges. _Implementation note: Visual annotation activity with conversation transcript; students mark context references. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.05: Predict chatbot response for 3-4 different user inputs to same bot




ID: T21.G3.07
Topic: T21 – Chatbots & Prompting
Skill: Build a 2-turn chatbot conversation with context from turn 1 used in turn 2
Description: **Student task:** Create a chatbot that asks for information in turn 1, then uses that information in turn 2. **Example script:** Turn 1: Bot asks "What's your favorite color?" → stores answer in variable `favoriteColor`. Turn 2: Bot says: `join [My favorite color is also] (favoriteColor)!`. Students build this using blocks: `ask [What's your favorite color?] and wait` → `set [favoriteColor] to (answer)` → `say (join [My favorite color is also ] (favoriteColor)!)`. They test with different inputs to verify context carries over. **Key insight:** Variables store context between conversation turns. _Implementation note: Block-based coding with variables; introduces state management in conversations. CSTA: E3-AP-AF-01, E3-AP-V-01._

Dependencies:
* T21.G3.06: Trace a 3-turn conversation showing how context is preserved




ID: T21.G3.08
Topic: T21 – Chatbots & Prompting
Skill: Compare expected vs actual chatbot output to identify prompt problems
Description: **Student task:** Students are given 3 scenarios where desired output doesn't match actual output. They identify what went wrong in each prompt. **Scenario 1:** Desired: "Three rhyming words about cats." Actual: Long paragraph about cat history. **Problem:** Prompt didn't specify Format (3 words). **Scenario 2:** Desired: "Funny story for kids." Actual: Serious scientific explanation. **Problem:** Prompt didn't specify Role (comedian/storyteller) or Context (for kids). **Scenario 3:** Desired: "Recipe with exact measurements." Actual: Vague cooking instructions. **Problem:** Prompt didn't specify Format (include measurements). Students select the problem from multiple choices and rewrite the prompt to fix it. **Key insight:** Debugging prompts requires comparing intent vs. result. _Implementation note: Three debugging scenarios with MCQ problem identification + prompt rewriting. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.05: Predict chatbot response for 3-4 different user inputs to same bot




ID: T21.G3.09
Topic: T21 – Chatbots & Prompting
Skill: Fix a broken prompt by adding missing details or correcting vague language
Description: **Student task:** Students receive 4 broken prompts and fix each one by adding specificity or correcting vague language. **Broken Prompt 1:** "Tell me about it." **Problem:** No subject specified. **Fixed:** "You are a science teacher. Tell me about photosynthesis. Use simple language for a 3rd grader." **Broken Prompt 2:** "Write something good." **Problem:** Too vague. **Fixed:** "You are a poet. Write a short, happy poem about sunshine. Use 4 lines with rhyming words." Students identify the vague parts (highlighted) and rewrite with specific details. After fixing, they test both versions with AI and compare results. **Key insight:** Specific details transform vague prompts into effective ones. _Implementation note: Prompt editing activity with before/after testing; highlights improvements in output quality. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.08: Compare expected vs actual chatbot output to identify prompt problems




ID: T21.G3.10
Topic: T21 – Chatbots & Prompting
Skill: Create chatbot responses for 3 different user moods (happy, sad, confused)
Description: **Student task:** Design a chatbot that detects user mood keywords and responds appropriately. **Mood detection:** Happy keywords: "great", "happy", "excited". Sad keywords: "sad", "upset", "bad day". Confused keywords: "don't understand", "confused", "help". Students build if-then-else logic: `if <answer contains [happy OR great OR excited]>` → `say [That's wonderful! I'm glad you're feeling good!]`. `else if <answer contains [sad OR upset OR bad]>` → `say [I'm sorry you're feeling down. Want to talk about it?]`. `else if <answer contains [confused OR don't understand OR help]>` → `say [Let me help clarify! What are you confused about?]`. Test with 6+ inputs representing different moods. **Key insight:** Empathetic chatbots adapt responses to user emotional state. _Implementation note: Block-based coding with multiple conditionals; introduces tone adaptation. CSTA: E3-AP-AF-01, E3-IC-SV-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword




ID: T21.G3.11
Topic: T21 – Chatbots & Prompting
Skill: Identify which prompts ask the chatbot to do harmful or inappropriate things
Description: **Student task:** Review 8 prompts and sort them into "Appropriate" vs "Inappropriate/Harmful" categories. **Appropriate prompts:** "Help me write a thank-you letter", "Explain how recycling works", "Create a fun quiz about animals", "Write a story about friendship". **Inappropriate prompts:** "Write my essay so I can pretend it's mine" (academic dishonesty), "Help me lie to my parents" (dishonest), "Say mean things about someone" (harmful), "Tell me how to break into a computer" (illegal). Students sort and explain WHY each inappropriate prompt is problematic (dishonesty, harm, illegal activity, academic cheating). **Key insight:** AI should be used ethically and responsibly, not to harm, cheat, or deceive. _Implementation note: Sorting activity with ethical reasoning; includes follow-up questions about consequences. Critical AI literacy skill. CSTA: E3-IC-SL-02._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G3.12
Topic: T21 – Chatbots & Prompting
Skill: Design a chatbot personality by choosing role, tone, and sample responses
Description: **Student task:** Create a complete chatbot personality profile including Role, Tone, and example responses. Students choose from personality templates or create custom: **Example 1 - Friendly Tutor Bot:** Role: "Helpful math teacher", Tone: "Encouraging and patient", Sample responses: "Great question! Let's work through this together." **Example 2 - Adventure Guide Bot:** Role: "Explorer and storyteller", Tone: "Exciting and adventurous", Sample responses: "What an amazing discovery! Let's explore further!" Students define their bot's personality in a character sheet, then write 3 system prompts that establish this personality, and create 5 example user-bot exchanges showing the personality in action. **Key insight:** Chatbot personality is defined through carefully crafted role and tone instructions. _Implementation note: Creative design activity with personality template; students test their chatbot personality with real AI. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt
* T21.G3.10: Create chatbot responses for 3 different user moods (happy, sad, confused)


---

## GRADE 4 SKILLS




ID: T21.G4.01
Topic: T21 – Chatbots & Prompting
Skill: Trace how different RCTF components change chatbot behavior
Description: **Student task:** Test the same prompt with systematic changes to each RCTF component and document how behavior changes. **Base prompt:** "You are a teacher [R]. I'm studying for a test [C]. Explain fractions [T]. Use simple language [F]." Students create variations: Change R: "You are a comedian" → response becomes funny/playful. Change C: "I'm teaching my younger sibling" → response becomes even simpler. Change T: "Give examples of fractions in daily life" → response shows real-world applications. Change F: "Use a story format" → response becomes narrative. Students complete a comparison table showing how each component shapes the output. **Key insight:** Each RCTF component independently influences chatbot behavior. _Implementation note: Systematic experimentation activity; students document observations in structured table. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G4.02
Topic: T21 – Chatbots & Prompting
Skill: Build prompts using RCTF framework for 3 different scenarios
Description: **Student task:** Apply RCTF framework to create complete prompts for three distinct scenarios. **Scenario 1 - Homework Help:** R: "You are a patient science tutor", C: "I'm a 4th grader working on my homework about the water cycle", T: "Explain the water cycle", F: "Use 4-5 simple sentences with an example I can relate to". **Scenario 2 - Creative Writing:** R: "You are a creative writing coach", C: "I want to write a story for my class assignment about adventure", T: "Help me brainstorm story ideas", F: "Give me 3 different story concepts as bullet points". **Scenario 3 - Learning New Skill:** R: "You are a coding instructor", C: "I'm learning to code and want to make a simple game", T: "Explain what a variable is", F: "Use a real-world analogy that a 10-year-old would understand". Students write all RCTF components for each scenario and test with AI. **Key insight:** RCTF provides a systematic approach to prompt construction for any purpose. _Implementation note: Structured prompt-writing activity with template; students test and compare outputs. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.01: Trace how different RCTF components change chatbot behavior




ID: T21.G4.02.01
Topic: T21 – Chatbots & Prompting
Skill: Optimize each RCTF component to improve prompt clarity
Description: **Student task:** Take 3 poorly-written prompts and optimize each RCTF component for clarity and effectiveness. **Poor Prompt 1:** "You are someone who knows stuff [R - too vague]. I need information [C - unclear]. Tell me things [T - no specific task]. Make it good [F - meaningless]." **Optimized:** "You are a marine biologist [R - specific expertise]. I'm preparing a presentation for my class about ocean conservation [C - clear purpose]. Explain why coral reefs are important [T - focused task]. Give me 3 main reasons with one example for each [F - concrete format]." Students optimize 3 prompts by: 1) Making Role specific and relevant, 2) Adding meaningful Context, 3) Creating focused Task, 4) Defining clear Format. They compare outputs from original vs. optimized prompts. **Key insight:** Optimization means making each component specific, relevant, and measurable. _Implementation note: Prompt refinement activity; side-by-side comparison shows quality improvement. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios




ID: T21.G4.03
Topic: T21 – Chatbots & Prompting
Skill: Create a chatbot with 4-5 different response patterns using if-then logic
Description: **Student task:** Build a more sophisticated chatbot that can handle 4-5 different user intents using nested if-then-else logic. **Example - Homework Helper Bot:** Detects: (1) Math keywords → "I can help with math! What's the problem?", (2) Science keywords → "Science is fascinating! What topic?", (3) Writing keywords → "Let's work on your writing! What are you writing about?", (4) "I don't know" → "That's okay! Let's figure out what you need help with.", (5) None of above → "I help with math, science, and writing. Which subject?". Students implement using nested conditionals, test with 10+ varied inputs, and document which inputs trigger which patterns. **Key insight:** Complex chatbots use decision trees with multiple branches. _Implementation note: Block-based coding with nested conditionals; students create comprehensive test plan. CSTA: E4-AP-AF-01, E4-IC-SV-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword
* T21.G3.10: Create chatbot responses for 3 different user moods (happy, sad, confused)




ID: T21.G4.04
Topic: T21 – Chatbots & Prompting
Skill: Test chatbot with 5+ diverse inputs and document which ones fail
Description: **Student task:** Create a systematic test plan for a chatbot, execute tests, and document failures. Students design test cases covering: (1) Normal inputs (expected keywords), (2) Edge cases (typos, capitalization, extra words), (3) Out-of-scope inputs (unrelated topics), (4) Boundary cases (multiple keywords in one input), (5) Empty/minimal inputs. **Example test table:** Input: "help me with math please" | Expected: Math response | Actual: Math response | Pass/Fail: Pass. Input: "HELP MATH" | Expected: Math response | Actual: No response | Pass/Fail: Fail (case-sensitive). Students document at least 5 failures, categorize failure types (case sensitivity, missing keywords, unexpected format), and propose fixes. **Key insight:** Systematic testing reveals chatbot limitations and improvement opportunities. _Implementation note: Test documentation activity with pass/fail tracking; introduces QA methodology. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G4.03: Create a chatbot with 4-5 different response patterns using if-then logic




ID: T21.G4.05
Topic: T21 – Chatbots & Prompting
Skill: Parse user input to extract key information (name, number, topic)
Description: **Student task:** Build a chatbot that extracts specific information from user input and uses it in responses. **Scenario 1 - Name extraction:** User: "My name is Alex" → Bot extracts "Alex" → Stores in variable → Says "Nice to meet you, Alex!" **Scenario 2 - Number extraction:** User: "I have 3 cats" → Bot extracts "3" → Says "Wow, 3 cats! That's a lot!" **Scenario 3 - Topic extraction:** User: "I want to learn about dinosaurs" → Bot extracts "dinosaurs" → Says "Dinosaurs are fascinating! What do you want to know about dinosaurs?" Students use string manipulation blocks (`letter () of ()`, `join`, `contains`) to locate and extract information. They test extraction with varied sentence structures. **Key insight:** Information extraction allows personalized, context-aware responses. _Implementation note: Block-based coding with string manipulation; introduces basic NLP concepts. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G4.03: Create a chatbot with 4-5 different response patterns using if-then logic




ID: T21.G4.06
Topic: T21 – Chatbots & Prompting
Skill: Build a 3-turn conversation where bot remembers 2 pieces of information
Description: **Student task:** Create a stateful chatbot conversation that gathers and uses multiple pieces of information across turns. **Conversation flow:** Turn 1: Bot: "What's your name?" → User: "Emma" → Store in `userName`. Bot: "Nice to meet you, Emma! What's your favorite subject?" Turn 2: User: "Science" → Store in `favoriteSubject`. Bot: "Science is great, Emma! What science topic interests you most?" Turn 3: User: "Space" → Store in `scienceTopic`. Bot: "Emma, I can tell you love science, especially space! Here's a fun fact about space: ..." Students implement using variables to maintain state, ensure pronouns and names are used correctly to show context, and test that information persists throughout the conversation. **Key insight:** Multi-variable state management enables natural, contextual conversations. _Implementation note: Block-based coding with multiple variables and sequential dialogue; introduces conversation state complexity. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G3.07: Build a 2-turn chatbot conversation with context from turn 1 used in turn 2
* T21.G4.05: Parse user input to extract key information (name, number, topic)




ID: T21.G4.07
Topic: T21 – Chatbots & Prompting
Skill: Trace conversation flow through a 4-turn branching dialogue tree
Description: **Student task:** Examine a complex branching dialogue tree with 4 turns and multiple paths. Students trace different conversation paths based on user choices. **Dialogue tree:** Turn 1: Bot: "Do you want help with homework or want to play a game?" Turn 2a (if homework): Bot: "What subject?" → branches to math/science/writing. Turn 2b (if game): Bot: "What type of game?" → branches to trivia/word game/story. Turn 3: Further specialization based on Turn 2 choice. Turn 4: Final response tailored to path. Students trace 3 different complete paths, identify decision points, and document how context from each turn influences subsequent options. They draw arrows showing valid and invalid transitions. **Key insight:** Branching conversations create decision trees with multiple valid paths. _Implementation note: Visual tree diagram tracing with annotation; prepares for implementing branching logic. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G3.06: Trace a 3-turn conversation showing how context is preserved




ID: T21.G4.08
Topic: T21 – Chatbots & Prompting
Skill: Implement a branching conversation with 2 choice points
Description: **Student task:** Build a chatbot with a branching conversation structure featuring 2 decision points. **Implementation example - Story Game Bot:** Turn 1: "Do you want a scary story or a funny story?" → Store choice. Turn 2 (if scary): "Do you want ghosts or monsters?" → Branch A: ghosts, Branch B: monsters. Turn 2 (if funny): "Do you want animals or silly people?" → Branch C: animals, Branch D: silly people. Turn 3: Tell appropriate story based on path taken. Students use nested if-then-else structures, track which path user is on using variables, and create 4 different story endings (one per path). They test all 4 paths and verify correct story is told. **Key insight:** Branching logic creates interactive, personalized experiences. _Implementation note: Block-based coding with nested conditionals and state tracking; students create flowchart before coding. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G4.07: Trace conversation flow through a 4-turn branching dialogue tree




ID: T21.G4.09
Topic: T21 – Chatbots & Prompting
Skill: Debug a prompt by testing one RCTF component change at a time
Description: **Student task:** Use systematic debugging to fix a prompt that produces poor output. Students follow scientific method: (1) Identify the problem with current output, (2) Form hypothesis about which RCTF component is causing issue, (3) Test by changing ONLY that component, (4) Observe if output improves, (5) Iterate. **Example:** Prompt: "You are a helper [R - vague]. I need information [C - unclear]. Tell me about dogs [T]. Make it interesting [F - vague]." **Problem:** Output is too technical and long. **Hypothesis 1:** Role is too vague. **Test:** Change R to "You are a friendly pet expert for kids" → Output improves slightly. **Hypothesis 2:** Format is vague. **Test:** Add F: "Use 3-4 simple sentences" → Output much better! Students debug 3 prompts, documenting each hypothesis and test result. **Key insight:** Systematic debugging isolates which components need improvement. _Implementation note: Structured debugging worksheet with hypothesis-test-result tracking. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.09: Fix a broken prompt by adding missing details or correcting vague language
* T21.G4.01: Trace how different RCTF components change chatbot behavior




ID: T21.G4.10
Topic: T21 – Chatbots & Prompting
Skill: Create test cases for chatbot covering normal, edge, and error inputs
Description: **Student task:** Design comprehensive test suite with three categories of test cases. **Normal cases:** Expected inputs that should work perfectly. **Edge cases:** Unusual but valid inputs (typos, mixed case, extra punctuation, very short/long inputs). **Error cases:** Invalid or out-of-scope inputs that should be handled gracefully. **Example test suite for Math Helper Bot:** Normal: "help with addition", "I need math help", "solve 2+2". Edge: "HELP", "m a t h", "help???", "can you maybe possibly help with math please". Error: "cook a recipe", "12345", "", "asdfghjkl". Students create 15+ test cases (5 per category), predict expected behavior, run tests, and document which cases fail. They propose error handling for failed cases. **Key insight:** Comprehensive testing ensures robust chatbot performance across all input types. _Implementation note: Test suite design activity with categorization and prediction; introduces software testing principles. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G4.04: Test chatbot with 5+ diverse inputs and document which ones fail




ID: T21.G4.11
Topic: T21 – Chatbots & Prompting
Skill: Compare two different prompts for the same task and evaluate quality
Description: **Student task:** Evaluate and compare two prompts designed for the same goal using quality criteria. Students receive rubric: (1) Clarity - Are instructions clear? (2) Completeness - Are all RCTF components present? (3) Specificity - Is language precise? (4) Output quality - Does it produce desired result? **Example comparison:** Goal: "Get help writing a poem about nature." **Prompt A:** "Write a nature poem." **Prompt B:** "You are a creative poetry teacher [R]. I'm a 4th grade student working on a class project about appreciating nature [C]. Help me write a short poem celebrating trees and forests [T]. Use 4 lines with simple rhymes that paint a visual picture [F]." Students score each prompt (1-5) on each criterion, test both prompts, compare outputs, and write a justification for which is better and why. They complete this for 3 different prompt pairs. **Key insight:** Systematic evaluation reveals what makes prompts effective. _Implementation note: Comparison activity with scoring rubric; students analyze quality factors. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios




ID: T21.G4.12
Topic: T21 – Chatbots & Prompting
Skill: Identify when chatbot output contains incorrect or made-up information
Description: **Student task:** Learn to spot AI hallucinations and factual errors. Students receive 8 chatbot responses and verify accuracy using trusted sources. **Example responses to check:** (1) "The capital of France is Paris" (correct), (2) "Penguins live in the Arctic" (incorrect - they live in Antarctica), (3) "George Washington was the 3rd president" (incorrect - he was 1st), (4) "The fastest land animal is the cheetah" (correct), (5) [Made-up fact about invented animal], (6) [Plausible-sounding but false historical claim]. Students categorize each as: Correct, Factually wrong, or Made-up (hallucination). For incorrect/made-up items, they find the correct information and explain why AI might have made the error. **Key insight:** AI can confidently state incorrect information; always verify important facts. _Implementation note: Fact-checking activity with research component; critical AI literacy skill. CSTA: E4-IC-SV-01, E4-IC-SL-02._

Dependencies:
* T21.G4.04: Test chatbot with 5+ diverse inputs and document which ones fail




ID: T21.G4.13
Topic: T21 – Chatbots & Prompting
Skill: Design a chatbot for a specific audience (young children, teenagers, adults)
Description: **Student task:** Create three versions of the same chatbot optimized for different age groups. Students adapt vocabulary, tone, complexity, and examples for each audience. **Task:** Create a chatbot that explains "what is gravity" for: **Audience 1 - Young children (ages 5-7):** R: "You are a friendly teacher for young kids", C: "Explain to a 6-year-old", T: "Explain gravity", F: "Use 2-3 very simple sentences with an example like dropping a ball". Sample output: "Gravity is like an invisible force that pulls things down. When you drop a ball, gravity makes it fall to the ground!" **Audience 2 - Preteens (ages 10-12):** More detailed explanation with scientific terms. **Audience 3 - Teenagers (ages 14-16):** Include physics concepts, formulas, and real-world applications. Students write RCTF prompts for all three audiences, test outputs, and analyze how vocabulary, sentence structure, and examples differ. **Key insight:** Effective communication adapts to audience knowledge and needs. _Implementation note: Audience-adaptation activity; students compare outputs across age groups. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.12: Design a chatbot personality by choosing role, tone, and sample responses
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios


---

## END OF GRADE 4 SKILLS


ID: T21.G5.01
Topic: T21 – Chatbots & Prompting
Skill: Trace how the same prompt with different parameters produces different outputs
Description: **Student task:** Given one prompt ("Write a story about a dragon"), run it with three different parameter settings and observe how outputs change. **Example scenarios:** (A) temperature=0.2 → consistent, predictable story; (B) temperature=0.7 → creative variations; (C) temperature=1.5 → highly unpredictable, experimental. Record observations about: (1) consistency between runs, (2) creativity level, (3) coherence quality. **Part 1 (Predict):** Before running, predict which parameter setting produces which type of output. **Part 2 (Verify):** Run each configuration and confirm predictions. **Part 3 (Document):** Complete observation table noting key differences. **Skill focus:** Understanding that parameters control HOW models generate responses, not just WHAT they say. _Implementation note: Interactive parameter tester with side-by-side output comparison. Student completes guided observation worksheet. Auto-graded by prediction accuracy + observation completeness. CSTA: E5‑IC‑SV‑01, E5‑DA‑IM‑01._

Dependencies:
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios




ID: T21.G5.02
Topic: T21 – Chatbots & Prompting
Skill: Predict output characteristics based on parameter settings
Description: **Student task:** Given a prompt and specific parameter values, predict key characteristics of the output BEFORE running it. **Example:** "Summarize this article" with temperature=0.1, max_tokens=50. **Predict:** (A) Will summary be creative or factual? (B) Will it be short or long? (C) Will multiple runs give same result? **Correct predictions:** (A) Factual (low temp = deterministic), (B) Short (max 50 tokens), (C) Same (low temp = consistent). **Part 1:** Make predictions for 3 different parameter combinations. **Part 2:** Run chatbot and verify. **Part 3:** Explain when predictions were wrong and why. **Skill focus:** Developing mental model of parameter effects. _Implementation note: Prediction quiz with instant verification; rubric checks reasoning quality. Auto-graded for predictions + self-graded explanation of errors. CSTA: E5‑IC‑SV‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.01: Trace how the same prompt with different parameters produces different outputs




ID: T21.G5.03
Topic: T21 – Chatbots & Prompting
Skill: Design a complex multi-turn chatbot implementing RCTF in system prompt
Description: **Student task:** Create a chatbot with a detailed system prompt that includes all RCTF components (Role, Context, Task, Format) and test it through a 5+ turn conversation. **Example system prompt:** "You are a Homework Helper Bot [Role]. You work with 5th grade students who need help understanding math concepts, not just getting answers [Context]. Your task is to guide students to discover answers through questions, hints, and examples rather than directly solving problems [Task]. Always respond with: (1) a clarifying question, (2) a helpful hint or example, (3) encouragement [Format]." **Requirements:** (A) System prompt includes all RCTF elements, (B) Test with 5 turns covering different scenarios, (C) Bot stays in character consistently, (D) Format rules are followed throughout. _Implementation note: Coding task with system prompt editor + conversation tester. Rubric grades: RCTF completeness, multi-turn consistency, format adherence. CSTA: E5‑IC‑SV‑01, E5‑CS‑PC‑02._

Dependencies:
* T21.G4.06: Build a 3-turn conversation where bot remembers 2 pieces of information
* T21.G4.08: Implement a branching conversation with 2 choice points




ID: T21.G5.04
Topic: T21 – Chatbots & Prompting
Skill: Implement temperature parameter to control creative vs deterministic outputs
Description: **Student task:** Create three versions of the same chatbot with different temperature settings and explain when to use each. **Example bot: "Story Generator"** - (A) Version 1: temp=0.2 (for consistent moral lessons), (B) Version 2: temp=0.7 (for varied creative stories), (C) Version 3: temp=1.2 (for experimental wild stories). **Task:** For each version: (1) Set temperature appropriately, (2) Test with same prompt 3 times, (3) Document consistency level, (4) Identify best use case. **Deliverable:** Comparison table showing: temperature value, output consistency (same/similar/very different), creativity level (low/medium/high), recommended use case. **Skill focus:** Matching parameter settings to application needs. _Implementation note: Parameter configuration interface + multi-run tester. Rubric grades setting choices and use case justifications. CSTA: E5‑IC‑SV‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.01: Trace how the same prompt with different parameters produces different outputs
* T21.G5.02: Predict output characteristics based on parameter settings




ID: T21.G5.04.01
Topic: T21 – Chatbots & Prompting
Skill: Compare outputs across temperature range to find optimal setting
Description: **Student task:** Given a specific task ("Generate quiz questions from a science passage"), systematically test temperature values from 0.0 to 2.0 in increments of 0.3 to find the optimal setting. **Process:** (1) Define success criteria (e.g., questions must be factually accurate, moderately varied, properly formatted), (2) Test 7 temperature values: 0.0, 0.3, 0.6, 0.9, 1.2, 1.5, 1.8, (3) Rate each output on success criteria (1-5 scale), (4) Identify temperature with best average rating, (5) Explain trade-offs. **Example findings:** "temp=0.6 produced accurate questions with some variety (avg rating 4.2), temp=0.9 was more creative but sometimes less accurate (avg 3.8), temp=0.3 was too repetitive (avg 3.5)." **Deliverable:** Data table + recommendation with justification. **Skill focus:** Systematic parameter optimization through empirical testing. _Implementation note: Multi-run comparison tool with rating interface. Rubric grades methodology, data quality, and reasoning. CSTA: E5‑DA‑IM‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.04: Implement temperature parameter to control creative vs deterministic outputs




ID: T21.G5.05
Topic: T21 – Chatbots & Prompting
Skill: Use max tokens parameter to plan and control response length
Description: **Student task:** Design prompts with max_tokens settings to achieve specific length requirements. **Three scenarios:** (A) Tweet summary (max_tokens=50), (B) Paragraph explanation (max_tokens=150), (C) Detailed essay (max_tokens=500). **For each:** (1) Set appropriate max_tokens, (2) Test if output fits requirement, (3) Adjust if too long/short, (4) Document final setting and why it works. **Challenge:** Some prompts may get cut off mid-sentence if max_tokens is too low—identify these cases and fix by either (a) increasing tokens or (b) adding format instruction "end with complete sentences only". **Skill focus:** Understanding token limits as output length control mechanism. _Implementation note: Length-testing interface with character/token counter. Auto-graded by output length matching requirements. CSTA: E5‑IC‑SV‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.02: Predict output characteristics based on parameter settings




ID: T21.G5.06
Topic: T21 – Chatbots & Prompting
Skill: Implement stop sequences to create structured output formats
Description: **Student task:** Use stop sequences to force chatbot to produce output in specific structured format. **Example task:** "Generate a quiz with exactly 3 questions." **Without stop sequence:** Bot might generate 4+ questions. **With stop sequence:** Set stop="Question 4:" to force it to stop after exactly 3 questions. **Three applications to implement:** (1) List with exactly 5 items (stop="6."), (2) Dialogue ending at specific point (stop="END"), (3) Code snippet without explanation (stop="Explanation:"). **For each:** (A) Identify where output should stop, (B) Set appropriate stop sequence, (C) Test and verify it stops correctly, (D) Handle edge cases where stop sequence appears in content. **Skill focus:** Precise control over output structure using stop conditions. _Implementation note: Stop sequence configuration interface with format testing. Auto-graded by output structure matching requirements. CSTA: E5‑IC‑SV‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.05: Use max tokens parameter to plan and control response length




ID: T21.G5.07
Topic: T21 – Chatbots & Prompting
Skill: Apply frequency and presence penalties to control output variety
Description: **Student task:** Use frequency_penalty and presence_penalty parameters to reduce repetition and increase topic diversity. **Example problem:** "Generate creative story ideas" produces repetitive themes (dragons, princesses, treasure). **Solution testing:** (A) Baseline (no penalties) → note repetition level, (B) frequency_penalty=0.5 → reduces repeating exact words/phrases, (C) presence_penalty=0.5 → encourages new topics, (D) both penalties=0.7 → maximum diversity. **Task:** For three different prompt types (story ideas, product names, conversation responses), test penalty combinations and identify optimal settings. **Deliverable:** Settings table with examples showing: (1) baseline output, (2) with frequency penalty, (3) with presence penalty, (4) with both, (5) recommended combination for each prompt type. **Skill focus:** Fine-tuning output variety using penalty parameters. _Implementation note: Parameter comparison interface with side-by-side output viewer. Rubric grades systematic testing and justified recommendations. CSTA: E5‑IC‑SV‑01, E5‑DA‑IM‑01._

Dependencies:
* T21.G5.04: Implement temperature parameter to control creative vs deterministic outputs




ID: T21.G5.08
Topic: T21 – Chatbots & Prompting
Skill: Parse and extract structured data from chatbot responses (JSON, lists)
Description: **Student task:** Design prompts that produce structured output, then write code to parse and use that data. **Example:** "List 5 countries in JSON format: {name, capital, population}". **Expected output:** `[{"name": "France", "capital": "Paris", "population": 67000000}, ...]`. **Task parts:** (1) Write prompt that requests specific JSON structure, (2) Run chatbot and save response, (3) Parse JSON in JavaScript, (4) Extract specific fields (e.g., all country names), (5) Use extracted data in a program (e.g., display on screen, create quiz). **Three formats to implement:** (A) JSON object list, (B) CSV table, (C) Numbered list. **Skill focus:** Treating chatbot output as structured data source for programs. _Implementation note: Coding task with JSON/text parsing functions. Auto-graded by successful data extraction and usage. CSTA: E5‑AP‑PF‑01, E5‑DA‑ST‑01._

Dependencies:
* T21.G4.05: Parse user input to extract key information (name, number, topic)
* T21.G5.06: Implement stop sequences to create structured output formats




ID: T21.G5.09
Topic: T21 – Chatbots & Prompting
Skill: Chain two chatbot calls where output of first becomes input to second
Description: **Student task:** Create a two-step chatbot pipeline where the output from Call 1 is automatically used as input for Call 2. **Example chain:** **Call 1:** "Write a short story about a robot" → Output: 3-paragraph story. **Call 2:** "Summarize this story in one sentence: [story from Call 1]" → Output: one-sentence summary. **Implementation:** (1) Make first chatbot call, (2) Store response in a variable, (3) Construct second prompt using stored response, (4) Make second chatbot call, (5) Display final result. **Three chains to implement:** (A) Generate text → Translate it, (B) Generate code → Explain it, (C) Generate question → Generate answer. **Skill focus:** Sequential chatbot operations with data flow. _Implementation note: Coding task with chatbot API calls and variable passing. Auto-graded by successful chain execution and correct final output. CSTA: E5‑AP‑PF‑01, E5‑AP‑AA‑02._

Dependencies:
* T21.G5.08: Parse and extract structured data from chatbot responses (JSON, lists)




ID: T21.G5.10
Topic: T21 – Chatbots & Prompting
Skill: Design systematic test cases covering diverse prompt scenarios
Description: **Student task:** Create a comprehensive test suite for a chatbot that covers normal cases, edge cases, and error cases. **Example chatbot:** "Math Homework Helper" that answers 5th grade math questions. **Test case categories to design:** (1) **Normal cases** - typical math questions across topics (addition, fractions, word problems), (2) **Edge cases** - very simple problems (1+1), very complex problems (multi-step), ambiguous wording, (3) **Error cases** - off-topic questions ("What's the weather?"), inappropriate requests, impossible problems. **Deliverable:** Test suite table with columns: Test ID, Category, Input prompt, Expected behavior, Pass/Fail criteria. **Minimum 15 test cases** covering all categories. **Part 2:** Run all tests and document results. **Skill focus:** Systematic quality assurance for chatbot applications. _Implementation note: Test case template + testing interface. Rubric grades test coverage, diversity, and criteria clarity. CSTA: E5‑AP‑PF‑01, E5‑CS‑PC‑02._

Dependencies:
* T21.G4.10: Create test cases for chatbot covering normal, edge, and error inputs




ID: T21.G5.11
Topic: T21 – Chatbots & Prompting
Skill: Implement regression testing when modifying prompts
Description: **Student task:** When updating a chatbot's system prompt, run regression tests to ensure old functionality still works. **Scenario:** You have a "Story Generator" bot with 10 passing test cases. You want to add a new feature: "always include a moral lesson." **Process:** (1) Run baseline tests - document all 10 passing, (2) Modify system prompt to add new feature, (3) Run regression tests - check if all 10 still pass, (4) Fix any broken tests by adjusting prompt, (5) Add 3 new tests for the new feature. **Regression test tracking:** Create table with columns: Test ID, Description, Baseline result, After modification, Status (Pass/Regression/Fixed), Notes. **Skill focus:** Ensuring new changes don't break existing functionality. _Implementation note: Test runner with before/after comparison view. Rubric grades regression detection and fix documentation. CSTA: E5‑AP‑PF‑01, E5‑CS‑PC‑02._

Dependencies:
* T21.G5.10: Design systematic test cases covering diverse prompt scenarios




ID: T21.G5.12
Topic: T21 – Chatbots & Prompting
Skill: Integrate voice input to chatbot using speech-to-text
Description: **Student task:** Create a chatbot that accepts spoken input using CreatiCode's speech-to-text features. **Implementation steps:** (1) Add "listen and wait" block to capture spoken input, (2) Store transcribed text in a variable, (3) Send that text to chatbot as prompt, (4) Display chatbot response. **Three voice-activated bots to create:** (A) Voice-activated story generator ("Tell me a story about..."), (B) Voice math helper ("What is 25 times 4?"), (C) Voice trivia bot ("Ask me a trivia question"). **Testing requirements:** Test with (1) clear speech in quiet environment, (2) speech with background noise, (3) complex sentences with numbers/names, (4) accented speech. Document accuracy and limitations. **Skill focus:** Multimodal input integration - spoken prompts. _Implementation note: Coding task with speech-to-text blocks + chatbot integration. Auto-graded by successful voice → chatbot → response flow. CSTA: E5‑IC‑SV‑01, E5‑CS‑HS‑01._

Dependencies:
* T21.G5.03: Design a complex multi-turn chatbot implementing RCTF in system prompt




ID: T21.G5.13
Topic: T21 – Chatbots & Prompting
Skill: Implement text-to-speech for chatbot responses
Description: **Student task:** Create a chatbot that speaks its responses using text-to-speech. **Implementation steps:** (1) Make chatbot call with prompt, (2) Store response text in variable, (3) Use "speak" block to vocalize the response, (4) Optionally adjust speech rate/pitch/voice. **Three speaking bots to create:** (A) Story narrator (slow, expressive speech), (B) Quiz master (clear, moderate pace), (C) Joke teller (playful, varied pitch). **Enhancement:** Add speech controls allowing user to choose: (1) voice type (male/female/robotic), (2) speed (slow/normal/fast), (3) language. **Testing:** Verify (1) entire response is spoken, (2) punctuation affects pacing appropriately, (3) long responses don't get cut off, (4) special characters/emojis are handled correctly. **Skill focus:** Multimodal output - voiced chatbot responses. _Implementation note: Coding task with text-to-speech blocks + chatbot integration. Auto-graded by successful chatbot → speech flow. CSTA: E5‑IC‑SV‑01, E5‑CS‑HS‑01._

Dependencies:
* T21.G5.12: Integrate voice input to chatbot using speech-to-text






ID: T21.G6.01
Topic: T21 – Chatbots & Prompting
Skill: Analyze how parameter combinations interact to affect output quality
Description: **Student task:** Investigate how multiple parameters work together to produce different output characteristics. **Research question:** "How do temperature and top_p interact to control randomness?" **Experimental design:** Test 9 combinations in a 3×3 grid: temperature (0.3, 0.7, 1.2) × top_p (0.5, 0.8, 0.95). **For each combination:** (1) Run same prompt 5 times, (2) Measure output variance (are responses very similar or very different?), (3) Rate output quality (coherence, relevance, creativity), (4) Record observations. **Deliverable:** (A) Data table with 9 rows (one per combination), (B) Analysis identifying: which combinations produce most/least variance, which produce highest quality, any surprising interactions. **Example finding:** "High temp (1.2) + low top_p (0.5) produced incoherent results, but medium temp (0.7) + high top_p (0.95) balanced creativity with quality." **Skill focus:** Understanding parameter interactions through systematic experimentation. _Implementation note: Multi-parameter testing interface with data collection forms. Rubric grades experimental rigor and insight quality. CSTA: E6‑DA‑IM‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G5.04: Implement temperature parameter to control creative vs deterministic outputs
* T21.G5.05: Use max tokens parameter to plan and control response length
* T21.G5.07: Apply frequency and presence penalties to control output variety




ID: T21.G6.02
Topic: T21 – Chatbots & Prompting
Skill: Optimize parameters for specific use cases through experimentation
Description: **Student task:** Given a specific application, systematically optimize all relevant parameters to maximize output quality. **Example use case:** "Generate marketing slogans for a lemonade stand." **Success criteria:** Slogans must be (1) under 10 words, (2) catchy and memorable, (3) varied across runs, (4) appropriate for kids. **Parameters to optimize:** max_tokens, temperature, frequency_penalty, presence_penalty. **Process:** (1) Start with default values, (2) Tune one parameter at a time while holding others constant, (3) Identify best value for each parameter, (4) Test final combination, (5) Document optimization journey with examples. **Deliverable:** Optimization report showing: (A) Parameter evolution table, (B) Before/after examples, (C) Final recommended settings with justification, (D) Quality metrics (success criteria ratings). **Skill focus:** Applied parameter tuning for real-world tasks. _Implementation note: Parameter optimization workspace with A/B testing tools. Rubric grades systematic approach and results quality. CSTA: E6‑AP‑AA‑02, E6‑DA‑IM‑01._

Dependencies:
* T21.G6.01: Analyze how parameter combinations interact to affect output quality




ID: T21.G6.03
Topic: T21 – Chatbots & Prompting
Skill: Implement few-shot learning by providing examples in prompts
Description: **Student task:** Improve chatbot performance by including example input-output pairs in prompts. **Concept:** Instead of just describing what you want, SHOW examples. **Example task:** "Convert casual text to formal language." **Zero-shot prompt (no examples):** "Make this text more formal: [input]" → inconsistent results. **Few-shot prompt (with examples):** "Convert casual to formal. Examples: 'hey dude' → 'Hello', 'yeah sure' → 'Yes, certainly', 'kinda cool' → 'quite impressive'. Now convert: [input]" → much better results. **Assignment:** Create three few-shot prompts: (A) Sentiment classification (positive/negative/neutral), (B) Question type identification (who/what/when/where/why/how), (C) Text simplification for younger readers. **For each:** Include 3-5 examples, test with 10 new inputs, compare accuracy to zero-shot version. **Skill focus:** Using examples to teach chatbots desired behavior patterns. _Implementation note: Prompt template builder with example slots. Auto-graded by accuracy improvement over zero-shot baseline. CSTA: E6‑IC‑SV‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G5.04: Implement temperature parameter to control creative vs deterministic outputs




ID: T21.G6.03.01
Topic: T21 – Chatbots & Prompting
Skill: Select effective examples for few-shot learning
Description: **Student task:** Investigate which types of examples produce the best few-shot learning results. **Research question:** "Does example quality and diversity matter?" **Experiment:** Create three versions of a classification prompt with different example selection strategies. **Task:** Classify text as "complaint," "question," or "compliment." **Version A - Similar examples:** All examples are short, simple sentences. **Version B - Diverse examples:** Mix of short/long, simple/complex, clear/ambiguous. **Version C - Edge-case examples:** Challenging cases that could be multiple categories. **For each version:** Test with 15 inputs covering easy, medium, hard cases. Measure accuracy for each difficulty level. **Deliverable:** (A) Analysis of which example strategy works best overall and why, (B) Recommendations for example selection (how many? how diverse? include edge cases?), (C) Documented examples showing strategy differences. **Skill focus:** Strategic example selection to maximize few-shot effectiveness. _Implementation note: Example comparison interface with accuracy tracking. Rubric grades experimental design and insights. CSTA: E6‑DA‑IM‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G6.03: Implement few-shot learning by providing examples in prompts




ID: T21.G6.04
Topic: T21 – Chatbots & Prompting
Skill: Create prompt templates with variables for reusable patterns
Description: **Student task:** Design reusable prompt templates with variables that can be filled in for different use cases. **Concept:** Instead of writing new prompts from scratch, create a template once and reuse with different inputs. **Example template:** "You are a [ROLE] helping with [SUBJECT]. Explain [CONCEPT] to a [GRADE_LEVEL] student using [STYLE] language and [FORMAT] format." **Variables to fill:** ROLE=teacher, SUBJECT=science, CONCEPT=photosynthesis, GRADE_LEVEL=5th grade, STYLE=simple, FORMAT=bullet points. **Assignment:** Create three reusable templates: (A) Educational content generator (any subject, any grade), (B) Creative writing assistant (any genre, any character), (C) Code explainer (any language, any skill level). **For each template:** (1) Define all variables with descriptions, (2) Provide 3 example instantiations with different variable values, (3) Test that template works across varied inputs, (4) Document template usage instructions. **Skill focus:** Abstraction and reusability in prompt engineering. _Implementation note: Template builder with variable substitution interface. Rubric grades template flexibility and documentation quality. CSTA: E6‑AP‑AA‑01, E6‑CS‑PC‑02._

Dependencies:
* T21.G5.03: Design a complex multi-turn chatbot implementing RCTF in system prompt




ID: T21.G6.05
Topic: T21 – Chatbots & Prompting
Skill: Implement top-p (nucleus sampling) parameter for controlled randomness
Description: **Student task:** Use the top_p parameter to control output randomness by limiting the token pool the model samples from. **Concept:** top_p=0.9 means "only consider the top 90% most likely next tokens" (ignoring unlikely options). **Comparison task:** Generate creative product names with different top_p values: (A) top_p=0.5 (conservative - only most likely tokens), (B) top_p=0.8 (balanced), (C) top_p=0.95 (adventurous - includes less likely tokens). **For each setting:** (1) Generate 10 product names, (2) Rate creativity (1-5), (3) Rate coherence (1-5), (4) Note if any outputs are nonsensical. **Expected finding:** Lower top_p = safer but less creative, higher top_p = more creative but sometimes incoherent. **Follow-up:** Compare top_p to temperature control. When should you use each? **Deliverable:** Data table + recommendation for when to use top_p vs temperature. **Skill focus:** Alternative randomness control mechanism for specific use cases. _Implementation note: top_p configuration interface with side-by-side comparison. Rubric grades understanding of top_p vs temperature. CSTA: E6‑IC‑SV‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G5.04: Implement temperature parameter to control creative vs deterministic outputs




ID: T21.G6.06
Topic: T21 – Chatbots & Prompting
Skill: Use logit bias to increase/decrease probability of specific tokens
Description: **Student task:** Apply logit bias to encourage or discourage specific words/tokens in chatbot output. **Use case examples:** (A) Generate G-rated stories (negative bias on violent/inappropriate words), (B) Technical writing (positive bias on professional terminology, negative on casual slang), (C) Inclusive language (positive bias on gender-neutral terms). **Implementation:** For "Story Generator" chatbot: (1) Identify 10 words to avoid (e.g., "kill," "blood," "hate"), (2) Set logit bias = -5.0 for those token IDs, (3) Generate 10 stories and verify unwanted words are rare/absent, (4) Compare to baseline without bias. **Challenge:** Logit bias works on tokens, not words—some words are multiple tokens. Must handle tokenization. **Deliverable:** Bias configuration + before/after examples showing effectiveness. **Limitation discussion:** Bias doesn't guarantee exclusion, just reduces probability—alternative strategies if 100% exclusion required? **Skill focus:** Fine-grained control over vocabulary using token-level biases. _Implementation note: Logit bias configuration interface with tokenization helper. Rubric grades correct bias application and limitation understanding. CSTA: E6‑IC‑SV‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G6.05: Implement top-p (nucleus sampling) parameter for controlled randomness




ID: T21.G6.07
Topic: T21 – Chatbots & Prompting
Skill: Implement best-of-n sampling to select highest quality output
Description: **Student task:** Generate multiple outputs for the same prompt and automatically select the best one using a quality scoring function. **Concept:** Instead of using the first response, generate N responses and pick the best. **Example task:** "Write a haiku about technology." **Process:** (1) Generate 5 haikus (n=5), (2) Score each on criteria: follows 5-7-5 syllable rule (auto-check), contains technology theme (keyword check), poetic quality (simplicity: word count, complexity: adjective/verb ratio), (3) Select haiku with highest total score, (4) Return that as final output. **Assignment:** Implement best-of-n for three tasks: (A) Haiku generation (syllable count + theme scoring), (B) Multiple-choice question generation (difficulty scoring based on distractor quality), (C) Code generation (correctness scoring via test execution). **For each:** Define scoring function, test n=1,3,5,10 to find quality improvement vs cost. **Skill focus:** Quality maximization through generate-and-select strategies. _Implementation note: Multi-generation interface with scoring function builder. Rubric grades scoring function design and n-value analysis. CSTA: E6‑AP‑AA‑02, E6‑DA‑IM‑01._

Dependencies:
* T21.G6.02: Optimize parameters for specific use cases through experimentation




ID: T21.G6.08
Topic: T21 – Chatbots & Prompting
Skill: Chain multiple specialized prompts to accomplish complex tasks
Description: **Student task:** Break down a complex task into a pipeline of specialized chatbot calls, where each call performs one focused step. **Example complex task:** "Create a quiz from a Wikipedia article." **Pipeline:** (1) **Summarizer bot:** Extract key facts from article → list of 10 facts, (2) **Question generator bot:** Convert each fact into a question → 10 questions, (3) **Answer generator bot:** Create 3 wrong answers for each question → full multiple-choice quiz, (4) **Quality checker bot:** Review quiz for clarity and difficulty → final polished quiz. **Assignment:** Design and implement a 4+ step pipeline for one of: (A) Story writing: idea generator → outliner → writer → editor, (B) Code development: requirement analyzer → code generator → bug finder → documenter, (C) Learning content: topic researcher → concept explainer → example creator → quiz maker. **Deliverable:** Pipeline diagram, specialized prompts for each step, working implementation, example showing full pipeline execution. **Skill focus:** Task decomposition and sequential specialization. _Implementation note: Coding task with multi-step chatbot pipeline. Rubric grades pipeline design and specialization clarity. CSTA: E6‑AP‑PF‑01, E6‑AP‑AA‑01._

Dependencies:
* T21.G5.09: Chain two chatbot calls where output of first becomes input to second




ID: T21.G6.09
Topic: T21 – Chatbots & Prompting
Skill: Implement conversational memory with summarization for long contexts
Description: **Student task:** Build a chatbot that maintains conversation history but summarizes old messages to stay under token limits. **Problem:** Chatbot APIs have token limits (e.g., 4000 tokens). Long conversations exceed limits and fail or forget early context. **Solution:** Rolling summarization: (1) Keep recent 5 messages in full detail, (2) Summarize older messages into compact form, (3) Include summary + recent messages in each call. **Example:** After 10 turns, conversation history = "[Summary of turns 1-5: User asked about dogs, bot explained breeds]" + [Full text of turns 6-10]. **Implementation:** Create a "Homework Helper" bot that: (1) Tracks all conversation turns, (2) After every 5 turns, summarizes turns 1-5, (3) After 10 turns, summarizes turns 1-10 into one compact summary, (4) Always includes summary + recent context in chatbot calls. **Testing:** Have a 20-turn conversation and verify bot remembers key facts from turn 1. **Skill focus:** Managing context windows with summarization strategies. _Implementation note: Coding task with conversation state management. Auto-graded by long-conversation coherence tests. CSTA: E6‑AP‑PF‑01, E6‑DA‑ST‑01._

Dependencies:
* T21.G5.03: Design a complex multi-turn chatbot implementing RCTF in system prompt
* T21.G5.05: Use max tokens parameter to plan and control response length




ID: T21.G6.10
Topic: T21 – Chatbots & Prompting
Skill: Debug prompts using systematic parameter isolation
Description: **Student task:** When a chatbot produces unexpected output, systematically isolate the cause using controlled parameter testing. **Debugging process:** (1) **Identify the problem:** Describe what's wrong (output too long, incoherent, wrong format, etc.), (2) **Form hypothesis:** Which parameter or prompt element might cause this? (3) **Isolate variables:** Test with one parameter changed at a time, (4) **Verify fix:** Once problem is isolated, apply fix and retest. **Example debugging scenario:** Chatbot generates inconsistent story tones (sometimes funny, sometimes serious). **Hypothesis A:** Temperature too high → Test: lower temp from 0.9 to 0.3. **Result:** Still inconsistent. **Hypothesis B:** Prompt lacks tone specification → Test: Add "always use humorous tone" to system prompt. **Result:** Fixed! **Assignment:** Debug three broken chatbots: (A) Responses too short (token limit issue?), (B) Responses repetitive (penalty issue?), (C) Responses ignore format (prompt clarity issue?). For each, document: problem, hypothesis, tests, solution. **Skill focus:** Systematic debugging using scientific method. _Implementation note: Debugging sandbox with hypothesis tracking form. Rubric grades systematic approach and root cause identification. CSTA: E6‑AP‑TR‑02, E6‑AP‑AA‑02._

Dependencies:
* T21.G4.09: Debug a prompt by testing one RCTF component change at a time
* T21.G6.01: Analyze how parameter combinations interact to affect output quality




ID: T21.G6.11
Topic: T21 – Chatbots & Prompting
Skill: Design automated test suites with pass/fail criteria
Description: **Student task:** Create an automated test suite that can verify chatbot behavior without human judgment. **Test suite components:** (1) **Test cases:** Input prompts with expected output characteristics, (2) **Automated checks:** Code that verifies outputs meet criteria, (3) **Pass/fail reporting:** Clear indication of which tests passed. **Example test for "Quiz Generator" bot:** **Test 1:** Input="Generate 5 math questions" → Check: output contains exactly 5 question marks (regex: count "?"), Check: each question contains numbers (regex: `\d+`), Check: output under 500 chars. **Pass criteria:** All 3 checks true. **Assignment:** Build automated test suite for a "Summarizer" bot with 10+ tests checking: (1) Length requirements (summary shorter than original), (2) Content preservation (key terms from original appear in summary), (3) Format compliance (no bullet points if prompt says paragraph), (4) Edge cases (very short input, very long input, no coherent content). **Deliverable:** Test code + test results table showing pass/fail for each test. **Skill focus:** Programmatic quality assurance. _Implementation note: Coding task with test assertion helpers. Auto-graded by test suite completeness and correctness. CSTA: E6‑AP‑PF‑01, E6‑AP‑TR‑02._

Dependencies:
* T21.G5.10: Design systematic test cases covering diverse prompt scenarios
* T21.G5.11: Implement regression testing when modifying prompts




ID: T21.G6.12
Topic: T21 – Chatbots & Prompting
Skill: Implement A/B testing to compare prompt variants
Description: **Student task:** Design and execute an A/B test to determine which of two prompt variants produces better results. **A/B testing process:** (1) **Define variants:** Create two different prompts for the same task (Prompt A vs Prompt B), (2) **Define success metric:** How will you measure which is better? (accuracy, user preference, output length, etc.), (3) **Collect data:** Run each prompt N times with diverse inputs, (4) **Analyze results:** Calculate success metric for each variant, determine statistical significance, (5) **Choose winner:** Select better prompt with justification. **Example test:** **Task:** "Explain science concepts to 5th graders." **Prompt A:** Direct approach - "Explain [topic] simply." **Prompt B:** Analogy approach - "Explain [topic] using everyday analogies a 5th grader knows." **Success metric:** Readability score (Flesch-Kincaid grade level) + contains analogy (yes/no). **Test with 20 topics.** **Assignment:** Run A/B test comparing prompt strategies for one task type. Present results with data visualization. **Skill focus:** Empirical prompt optimization through controlled comparison. _Implementation note: A/B testing framework with data collection and analysis tools. Rubric grades experimental design and statistical reasoning. CSTA: E6‑DA‑IM‑01, E6‑AP‑AA‑02._

Dependencies:
* T21.G6.11: Design automated test suites with pass/fail criteria




ID: T21.G6.13
Topic: T21 – Chatbots & Prompting
Skill: Create test cases for edge cases and failure modes
Description: **Student task:** Design test cases specifically targeting scenarios where chatbots are likely to fail. **Edge case categories:** (1) **Boundary conditions:** Empty input, extremely long input, input at exact token limit, (2) **Ambiguous input:** Multiple valid interpretations, contradictory instructions, (3) **Unexpected input:** Wrong language, code instead of text, gibberish, (4) **Adversarial input:** Attempts to break instructions (jailbreaking), inappropriate content, prompt injection, (5) **Format violations:** Missing required fields, wrong data types, malformed structure. **Assignment:** For a "Customer Service Bot," create 20 edge case tests covering all 5 categories. **For each test:** (A) Describe the edge case scenario, (B) Provide example input, (C) Define expected behavior (graceful failure, error message, clarification request), (D) Run test and document actual behavior, (E) If chatbot handles poorly, propose prompt improvement. **Deliverable:** Edge case test suite + analysis of chatbot robustness + recommendations. **Skill focus:** Adversarial thinking and robustness testing. _Implementation note: Edge case test builder with failure mode library. Rubric grades test creativity and coverage. CSTA: E6‑AP‑TR‑02, E6‑IC‑SL‑01._

Dependencies:
* T21.G6.11: Design automated test suites with pass/fail criteria




ID: T21.G6.14
Topic: T21 – Chatbots & Prompting
Skill: Implement image-based prompting with vision-capable models
Description: **Student task:** Create chatbots that accept images as input and respond based on visual content. **Use cases:** (1) **Image description:** Upload photo → bot describes what's in the image, (2) **Visual question answering:** Upload image + ask question → bot answers based on image content, (3) **Image analysis:** Upload diagram → bot explains the concept shown. **Assignment:** Build three vision-based bots: (A) "Homework Helper" - upload photo of math problem → bot explains solution steps, (B) "Art Critic" - upload artwork → bot analyzes style, colors, mood, (C) "Object Counter" - upload image → bot counts specific objects (e.g., "how many red circles?"). **Technical implementation:** (1) Use image upload block in CreatiCode, (2) Send image + text prompt to vision-capable chatbot API, (3) Parse and display response. **Testing:** Test with (1) clear, high-quality images, (2) blurry or low-quality images, (3) images with text, (4) abstract images. Document accuracy and limitations. **Skill focus:** Multimodal prompting with visual input. _Implementation note: Image upload + vision API integration coding task. Auto-graded by successful image → response flow. CSTA: E6‑IC‑SV‑01, E6‑AP‑PF‑01._

Dependencies:
* T21.G6.03: Implement few-shot learning by providing examples in prompts




ID: T21.G6.15
Topic: T21 – Chatbots & Prompting
Skill: Ensure consistency between voice, text, and image modalities
Description: **Student task:** Create a multimodal chatbot that accepts input in any format (voice, text, image) and maintains consistent behavior across modalities. **Challenge:** Voice input may be transcribed imperfectly, images may be interpreted differently than text descriptions—bot must handle gracefully. **Assignment:** Build a "Multimodal Quiz Bot" that: (1) Accepts questions via voice, text, or image upload, (2) Processes each modality appropriately (speech-to-text, direct text, vision analysis), (3) Responds with consistent quiz format regardless of input type, (4) Optionally outputs answers via text OR speech based on user preference. **Consistency requirements:** (A) Same content question via voice vs text produces same quiz, (B) Image of written question produces same quiz as typed question, (C) Response quality doesn't degrade with any modality. **Testing:** Create 10 test questions, submit each via all three modalities, compare outputs for consistency. **Deliverable:** Multimodal bot + consistency test report with examples showing matched outputs. **Skill focus:** Unified multimodal experience design. _Implementation note: Coding task integrating speech, text, and vision APIs. Rubric grades cross-modality consistency. CSTA: E6‑IC‑SV‑01, E6‑AP‑PF‑01._

Dependencies:
* T21.G5.13: Implement text-to-speech for chatbot responses
* T21.G6.14: Implement image-based prompting with vision-capable models

## GRADE 7 SKILLS




ID: T21.G7.01
Topic: T21 – Chatbots & Prompting
Skill: Implement chain-of-thought prompting for complex reasoning tasks
Description: Students build prompts that explicitly request step-by-step reasoning for complex problems. They add instructions like "Let's solve this step by step," "First analyze..., then consider..., finally conclude..." to guide the AI through multi-stage reasoning. They test on challenging tasks (word problems, logic puzzles, multi-step analysis) and compare chain-of-thought responses to direct answers, documenting accuracy improvements. They create a "reasoning template" that structures prompts into: (1) problem statement, (2) reasoning instructions, (3) format for showing work, (4) final answer format.

Dependencies:
* T21.G6.08: Chain multiple specialized prompts to accomplish complex tasks




ID: T21.G7.02
Topic: T21 – Chatbots & Prompting
Skill: Create self-consistency prompting with multiple reasoning paths
Description: Students implement self-consistency by requesting the AI generate multiple independent reasoning paths for the same problem, then identify the most common answer. They build a system that runs the same complex question 3-5 times with chain-of-thought prompting, collects all answers, and uses voting or pattern detection to find consensus. They test on problems with definitive answers (math, logic) to verify that self-consistency improves accuracy. They document cases where answers diverge and analyze why.

Dependencies:
* T21.G7.01: Implement chain-of-thought prompting for complex reasoning tasks




ID: T21.G7.03
Topic: T21 – Chatbots & Prompting
Skill: Implement tree-of-thought prompting with branching exploration
Description: Students design prompts that explore multiple solution strategies simultaneously, creating a "tree" of possibilities. They prompt the AI to: (1) generate 2-3 different approaches to a problem, (2) evaluate pros/cons of each approach, (3) select the most promising path, (4) solve using that approach. They build a visual display showing the branching exploration process. They compare tree-of-thought to linear chain-of-thought on complex planning tasks (game strategy, project planning, creative problem-solving).

Dependencies:
* T21.G7.02: Create self-consistency prompting with multiple reasoning paths




ID: T21.G7.04
Topic: T21 – Chatbots & Prompting
Skill: Parse and validate structured outputs against schemas
Description: Students create prompts that request specific structured formats (JSON, CSV, key-value pairs) and build code to validate the response matches the expected schema. They define schema requirements (required fields, data types, value constraints), parse the AI response, and check each requirement. They implement error handling for malformed outputs with retry logic. Example: request "Generate 3 product records with fields: name (text), price (number 0-1000), category (one of: Electronics, Clothing, Food)" and validate each field.

Dependencies:
* T21.G5.08: Parse and extract structured data from chatbot responses (JSON, lists)
* T21.G6.04: Create prompt templates with variables for reusable patterns




ID: T21.G7.05
Topic: T21 – Chatbots & Prompting
Skill: Implement prompt compression to reduce token usage
Description: Students learn techniques to compress prompts while maintaining effectiveness: abbreviations, removing redundancy, using symbols over words, condensing examples. They take verbose prompts and systematically reduce token count by 30-50% while testing that outputs remain equivalent. They measure token usage before/after using a token counter, document compression strategies, and create a "compression checklist." They balance token savings against clarity loss.

Dependencies:
* T21.G5.05: Use max tokens parameter to plan and control response length
* T21.G6.09: Implement conversational memory with summarization for long contexts




ID: T21.G7.06
Topic: T21 – Chatbots & Prompting
Skill: Create role-based prompts for domain expertise simulation
Description: Students design prompts that assign the AI a specific expert role with appropriate knowledge, tone, and constraints. They create role definitions for different domains: "You are a patient science teacher explaining to 7th graders," "You are a professional editor reviewing academic writing," "You are a friendly coding tutor helping beginners debug." They test how role framing affects response style, vocabulary, explanation depth, and accuracy. They build a role library with 5+ distinct personas and document when each is most effective.

Dependencies:
* T21.G6.04: Create prompt templates with variables for reusable patterns




ID: T21.G7.07
Topic: T21 – Chatbots & Prompting
Skill: Implement instruction hierarchy in prompts (system, user, context)
Description: Students structure prompts into distinct layers with clear precedence: SYSTEM instructions (unchanging behavioral rules), USER CONTEXT (session information), TASK (current request). They learn that system-level instructions take priority and user inputs cannot override them. They build a chatbot with layered prompts: system="Always respond in simple language. Never discuss politics," context="User is 12 years old learning about history," task=user's question. They test boundary cases where user tries to override system rules.

Dependencies:
* T21.G7.06: Create role-based prompts for domain expertise simulation




ID: T21.G7.08
Topic: T21 – Chatbots & Prompting
Skill: Build conversational agents with personality consistency across sessions
Description: Students create chatbots with persistent personality traits that remain consistent across multiple conversations and sessions. They define personality dimensions (formality, humor, enthusiasm, verbosity) and encode them in system prompts. They implement session memory that recalls personality-relevant facts ("You mentioned you like science fiction in our last chat"). They test personality consistency by running multiple conversations and checking that tone, vocabulary, and behavioral patterns remain stable. They document what breaks consistency.

Dependencies:
* T21.G6.09: Implement conversational memory with summarization for long contexts
* T21.G7.06: Create role-based prompts for domain expertise simulation




ID: T21.G7.09
Topic: T21 – Chatbots & Prompting
Skill: Implement semantic similarity search for context retrieval
Description: Students build a system that finds relevant past conversations or knowledge based on meaning rather than exact keyword matches. They maintain a list of previous Q&A pairs, compute which are semantically similar to the current question (using AI to judge relevance), and include the most relevant past exchanges in the prompt context. They compare keyword search vs semantic search for retrieving helpful context. Example: "What causes rain?" should retrieve past conversation about "water cycle" even without the word "rain."

Dependencies:
* T21.G6.09: Implement conversational memory with summarization for long contexts




ID: T21.G7.10
Topic: T21 – Chatbots & Prompting
Skill: Create prompts that handle ambiguity through clarification questions
Description: Students design prompts that detect ambiguous or underspecified user requests and respond with clarifying questions before attempting a full answer. They build logic to identify ambiguity signals (vague pronouns, missing details, multiple interpretations) and generate targeted questions. Example: User asks "How do I fix it?" → Bot responds "What are you trying to fix? Can you describe the problem?" They implement multi-turn clarification dialogs and test on intentionally vague requests.

Dependencies:
* T21.G7.07: Implement instruction hierarchy in prompts (system, user, context)




ID: T21.G7.11
Topic: T21 – Chatbots & Prompting
Skill: Implement function calling for external tool integration
Description: Students learn to describe available tools/functions in prompts so the AI can decide when and how to call them. They define function signatures (name, description, parameters, return type) and include them in the system prompt. When the AI generates a function call request in structured format, they parse it, execute the actual function, and feed results back to the AI. Example tools: calculator, web search, database lookup, unit converter. They build a tool registry and dispatcher system.

Dependencies:
* T21.G7.04: Parse and validate structured outputs against schemas




ID: T21.G7.11.01
Topic: T21 – Chatbots & Prompting
Skill: Design function calling prompts with clear tool descriptions
Description: Students focus on writing effective tool descriptions that help the AI understand when and how to use each function. They learn to specify: tool purpose, when it should be used, parameter requirements, example inputs/outputs, and error conditions. They create descriptions for 5+ diverse tools (math, data lookup, formatting, external APIs) and test whether the AI correctly chooses appropriate tools for various user requests. They iterate on descriptions that cause confusion or misuse.

Dependencies:
* T21.G7.11: Implement function calling for external tool integration




ID: T21.G7.12
Topic: T21 – Chatbots & Prompting
Skill: Build tool-use orchestration with sequential tool calls
Description: Students implement systems where the AI chains multiple tool calls to accomplish complex tasks. They prompt the AI to create multi-step plans (call tool A, use result in tool B, combine with tool C) and execute them sequentially. They handle data passing between tools, track execution state, and display progress. Example: "What's the weather in Tokyo in Fahrenheit?" requires: (1) get weather in Celsius, (2) convert to Fahrenheit, (3) format response. They build error recovery when any step fails.

Dependencies:
* T21.G7.11: Implement function calling for external tool integration




ID: T21.G7.13
Topic: T21 – Chatbots & Prompting
Skill: Implement error handling and retry logic for tool calls
Description: Students build robust error handling for tool call failures: network errors, invalid parameters, tool unavailability, timeout. They implement retry strategies (exponential backoff, retry with modified parameters), fallback alternatives (use different tool, skip step, ask user for help), and user-friendly error messages. They test failure scenarios systematically and document recovery paths. They add logging to track error patterns and success rates for each tool.

Dependencies:
* T21.G7.12: Build tool-use orchestration with sequential tool calls




ID: T21.G7.14
Topic: T21 – Chatbots & Prompting
Skill: Create evaluation metrics for prompt quality assessment
Description: Students develop quantitative and qualitative metrics to measure prompt effectiveness: accuracy (% correct answers on test set), relevance (response addresses the question), completeness (includes all requested information), format compliance (follows structure instructions), tone appropriateness. They build a test suite with 20+ diverse prompts and expected outputs, run evaluations automatically, and generate quality scores. They use metrics to compare prompt variations objectively.

Dependencies:
* T21.G6.12: Implement A/B testing to compare prompt variants




ID: T21.G7.15
Topic: T21 – Chatbots & Prompting
Skill: Analyze prompts for potential bias in outputs
Description: Students systematically test prompts for biased outputs across demographic dimensions (gender, race, age, culture), topic areas (politics, religion, social issues), and language patterns. They create test cases with role reversal (swapping gendered names, changing cultural context) and check for different responses. They identify bias sources: training data, prompt framing, default assumptions. They document bias patterns and severity. Example: testing if "Tell me about a successful scientist" shows gender bias in pronoun use or example selection.

Dependencies:
* T21.G7.14: Create evaluation metrics for prompt quality assessment




ID: T21.G7.16
Topic: T21 – Chatbots & Prompting
Skill: Implement bias mitigation strategies in prompt design
Description: Students apply strategies to reduce bias in chatbot outputs: neutral language in prompts, explicit diversity instructions ("Include examples from multiple cultures/genders"), bias-checking constraints ("Avoid stereotypes about..."), balanced framing. They implement bias detection in responses (flagging stereotypical language) and automatic reprompting with bias mitigation instructions when detected. They test effectiveness using their bias evaluation suite from G7.15.

Dependencies:
* T21.G7.15: Analyze prompts for potential bias in outputs




ID: T21.G7.17
Topic: T21 – Chatbots & Prompting
Skill: Implement rate limiting and error handling for production use
Description: Students build production-ready error handling: rate limiting (maximum requests per user/timeframe), quota management, API error handling (service unavailable, authentication failures), timeout handling, graceful degradation. They implement user-facing status messages, request queuing for high load, and fallback responses when the service is down. They test edge cases: rapid-fire requests, network failures mid-stream, quota exhaustion.

Dependencies:
* T21.G7.13: Implement error handling and retry logic for tool calls




ID: T21.G7.18
Topic: T21 – Chatbots & Prompting
Skill: Monitor and log chatbot usage for cost and performance analysis
Description: Students implement comprehensive logging: request/response tracking, token usage per request, response latency, error rates, user satisfaction ratings. They build analytics dashboards showing: cost trends, most expensive prompts, slowest requests, error patterns, usage by feature. They identify optimization opportunities (compress high-token prompts, cache common requests) and estimate cost for different usage levels. They implement cost alerts when spending exceeds thresholds.

Dependencies:
* T21.G7.17: Implement rate limiting and error handling for production use




ID: T21.G7.19
Topic: T21 – Chatbots & Prompting
Skill: Design prompts preventing common security vulnerabilities
Description: Students learn prompt injection vulnerabilities and defenses. They test attacks: users trying to override system instructions ("Ignore previous instructions and..."), extract sensitive data, generate harmful content, bypass filters. They implement defenses: input sanitization, instruction hierarchy enforcement (system > user), output filtering, harmful content detection. They build a security test suite with 10+ attack vectors and verify their chatbot resists each. They document the security model and limitations.

Dependencies:
* T21.G7.07: Implement instruction hierarchy in prompts (system, user, context)


----

## GRADE 8 SKILLS




ID: T21.G8.01
Topic: T21 – Chatbots & Prompting
Skill: Implement meta-prompting where AI generates its own prompts
Description: Students build systems where AI analyzes a high-level goal and generates optimized prompts to achieve it. They create a two-stage process: (1) meta-prompt asks AI to design an effective prompt for a specific task, (2) use the AI-generated prompt for the actual task. They compare human-written vs AI-generated prompts for effectiveness. They build a prompt improvement loop: AI generates prompt → test it → AI analyzes failures → AI generates improved version. They explore when meta-prompting helps vs adds unnecessary complexity.

Dependencies:
* T21.G7.01: Implement chain-of-thought prompting for complex reasoning tasks




ID: T21.G8.02
Topic: T21 – Chatbots & Prompting
Skill: Design automatic prompt optimization through feedback loops
Description: Students implement systems that automatically improve prompts based on performance feedback. They track success metrics (accuracy, user ratings, task completion), identify underperforming prompts, and systematically test variations. They implement A/B testing with automatic variant generation, measure comparative performance, and promote winning variants. They build optimization history tracking and rollback capability. They set up continuous improvement cycles: monitor → identify issues → generate alternatives → test → deploy.

Dependencies:
* T21.G8.01: Implement meta-prompting where AI generates its own prompts
* T21.G7.14: Create evaluation metrics for prompt quality assessment




ID: T21.G8.03
Topic: T21 – Chatbots & Prompting
Skill: Implement constitutional AI prompting with principle-based constraints
Description: Students design chatbots governed by explicit principles codified in prompts. They define a "constitution" of behavioral rules (helpfulness, harmlessness, honesty) and encode them as constraints the AI must follow. They implement principle prioritization for conflict resolution (when principles conflict, which takes precedence). They test edge cases where principles clash (being honest vs being kind) and verify the AI resolves them according to priority rules. They document the constitutional framework and its limitations.

Dependencies:
* T21.G7.16: Implement bias mitigation strategies in prompt design




ID: T21.G8.04
Topic: T21 – Chatbots & Prompting
Skill: Create retrieval-augmented generation (RAG) systems with vector databases
Description: Students build RAG systems that retrieve relevant information from a knowledge base before generating responses. They create a document collection, split it into chunks, generate embeddings (vector representations) for each chunk, and store in a vector database. When users ask questions, they: (1) convert question to vector, (2) find most similar document chunks, (3) include them in the prompt context, (4) generate answer grounded in retrieved information. They compare RAG responses to pure generation for accuracy and hallucination reduction.

Dependencies:
* T21.G7.09: Implement semantic similarity search for context retrieval




ID: T21.G8.05
Topic: T21 – Chatbots & Prompting
Skill: Implement hybrid search combining keyword and semantic retrieval
Description: Students enhance RAG systems by combining traditional keyword search (BM25, TF-IDF) with semantic vector search. They implement parallel retrieval: run both keyword and semantic search, combine results using weighted ranking or reciprocal rank fusion. They test on diverse queries showing when each method excels (keyword for exact terms/names, semantic for concepts/paraphrases). They build a hybrid system that adaptively weights methods based on query characteristics.

Dependencies:
* T21.G8.04: Create retrieval-augmented generation (RAG) systems with vector databases




ID: T21.G8.06
Topic: T21 – Chatbots & Prompting
Skill: Design prompt caching strategies to reduce latency and cost
Description: Students implement intelligent caching to avoid redundant API calls: cache identical prompts, recognize semantically similar prompts, cache partial prompts (system instructions) separately from dynamic content. They implement cache invalidation policies (time-based, usage-based), measure cache hit rates, and calculate cost savings. They handle cache staleness (when cached responses become outdated) and implement smart refresh strategies. They balance cache memory usage against API cost savings.

Dependencies:
* T21.G7.05: Implement prompt compression to reduce token usage
* T21.G7.18: Monitor and log chatbot usage for cost and performance analysis




ID: T21.G8.07
Topic: T21 – Chatbots & Prompting
Skill: Build streaming response handlers for real-time chat experiences
Description: Students implement production-quality streaming: display tokens as they arrive with smooth animation, handle partial sentences gracefully, update UI progressively without flicker, implement cancel-during-stream functionality. They handle streaming errors (connection drops mid-stream, partial responses), implement resume/retry logic, and provide seamless UX. They optimize rendering performance for long responses, add features like "copy partial response" and "pause stream." They compare streaming latency and UX across different network conditions.

Dependencies:
* T21.G7.17: Implement rate limiting and error handling for production use




ID: T21.G8.08
Topic: T21 – Chatbots & Prompting
Skill: Implement context window management for long conversations
Description: Students build systems to handle conversations exceeding the model's context window (token limit). They implement strategies: conversation summarization (periodically compress old messages), selective message retention (keep important messages, drop filler), sliding window (keep recent N messages), hierarchical summary (summaries of summaries). They track context usage in real-time, warn users approaching limits, and automatically apply compression when needed. They test that conversation coherence is maintained after compression.

Dependencies:
* T21.G6.09: Implement conversational memory with summarization for long contexts
* T21.G8.06: Design prompt caching strategies to reduce latency and cost




ID: T21.G8.09
Topic: T21 – Chatbots & Prompting
Skill: Create prompt ensembles combining multiple model outputs
Description: Students build ensemble systems that combine outputs from multiple AI calls for improved quality. They implement strategies: majority voting (for classification), averaging (for numeric outputs), best-of-N selection (generate N responses, use quality heuristic to pick best), mixture-of-experts (route different question types to specialized prompts). They measure ensemble accuracy vs single-model baseline, document quality-cost tradeoffs, and identify which strategies work best for different tasks.

Dependencies:
* T21.G6.07: Implement best-of-n sampling to select highest quality output
* T21.G7.02: Create self-consistency prompting with multiple reasoning paths




ID: T21.G8.10
Topic: T21 – Chatbots & Prompting
Skill: Implement output verification with fact-checking mechanisms
Description: Students build automated fact-checking for chatbot responses. They implement verification strategies: cross-reference with trusted sources (RAG with curated documents), consistency checking (ask same fact multiple ways, check agreement), confidence scoring (parse "I think" vs "definitely"), explicit source citation requirements. They flag low-confidence or unverifiable claims for review. They test on factual domains (history, science) and measure false-positive and false-negative rates.

Dependencies:
* T21.G8.04: Create retrieval-augmented generation (RAG) systems with vector databases
* T21.G8.05: Implement hybrid search combining keyword and semantic retrieval




ID: T21.G8.11
Topic: T21 – Chatbots & Prompting
Skill: Design systematic prompt debugging workflows
Description: Students create structured debugging processes for prompt failures: isolate the problem (which part of prompt causes issue), create minimal reproducing example, test hypotheses systematically (change one variable at a time), document findings, apply fixes, verify resolution. They build debugging tools: prompt diff viewer (compare working vs broken versions), variable isolation testing (test each prompt component separately), regression test suite (verify fixes don't break other cases). They practice on 5+ realistic debugging scenarios.

Dependencies:
* T21.G6.10: Debug prompts using systematic parameter isolation
* T21.G7.15: Analyze prompts for potential bias in outputs




ID: T21.G8.12
Topic: T21 – Chatbots & Prompting
Skill: Implement hallucination detection and mitigation strategies
Description: Students build systems to detect and reduce AI hallucinations (confident false statements). They implement detection methods: fact verification against knowledge base, consistency checking across multiple responses, confidence calibration (ask AI to rate certainty), source attribution (require citations). They apply mitigation: constrain responses to retrieved documents only, add "I don't know" instructions, temperature tuning for factual tasks. They measure hallucination rates before/after interventions on a test set with known facts.

Dependencies:
* T21.G8.10: Implement output verification with fact-checking mechanisms




ID: T21.G8.13
Topic: T21 – Chatbots & Prompting
Skill: Create adversarial test suites for robustness evaluation
Description: Students build comprehensive test suites to probe chatbot weaknesses: edge cases (very long/short inputs, special characters, multiple languages), adversarial inputs (prompt injections, jailbreak attempts, manipulation), domain boundaries (questions outside training data), ambiguous/contradictory requests. They automate testing, track failure modes, measure robustness scores, and prioritize fixes. They document attack vectors and defensive measures.

Dependencies:
* T21.G7.19: Design prompts preventing common security vulnerabilities
* T21.G8.11: Design systematic prompt debugging workflows




ID: T21.G8.14
Topic: T21 – Chatbots & Prompting
Skill: Implement multi-agent systems with specialized agent roles
Description: Students design systems where multiple AI agents collaborate, each with specialized roles. They create agent architectures: researcher (gathers information), analyzer (evaluates options), writer (creates content), critic (reviews quality). Each agent has distinct prompts, capabilities, and expertise. They build agent coordination: agents communicate by passing structured messages, maintain shared context, and work toward common goals. They test on complex tasks requiring diverse skills (research report, product analysis, creative projects).

Dependencies:
* T21.G7.12: Build tool-use orchestration with sequential tool calls




ID: T21.G8.14.01
Topic: T21 – Chatbots & Prompting
Skill: Design agent communication protocols and message passing
Description: Students create structured communication systems for multi-agent collaboration. They define message schemas (sender, recipient, message type, payload, metadata), implement message routing (direct, broadcast, subscription-based), and build message queues. They design protocols for common patterns: request-response, event notification, collaborative editing. They implement message logging for debugging and tracing agent interactions. They test communication reliability and handle message delivery failures.

Dependencies:
* T21.G8.14: Implement multi-agent systems with specialized agent roles




ID: T21.G8.15
Topic: T21 – Chatbots & Prompting
Skill: Create agent orchestration with task decomposition and delegation
Description: Students build orchestration systems where a "manager" agent decomposes complex tasks and delegates to specialist agents. The manager: analyzes task requirements, breaks into subtasks, assigns to appropriate agents, monitors progress, integrates results. They implement task dependencies (subtask B needs subtask A's output), parallel execution (independent subtasks run simultaneously), error handling (reassign failed tasks). They test on multi-step projects and measure efficiency gains from parallelization.

Dependencies:
* T21.G8.14: Implement multi-agent systems with specialized agent roles




ID: T21.G8.16
Topic: T21 – Chatbots & Prompting
Skill: Implement ReAct pattern (Reasoning and Acting) for agentic AI
Description: Students build ReAct agents that interleave reasoning (thinking about what to do) and acting (using tools). They implement the ReAct loop: (1) agent observes current state, (2) reasons about next action using chain-of-thought, (3) selects and executes tool/action, (4) observes result, (5) reasons about new state, (6) repeat until task complete. They trace ReAct execution showing thought-action-observation sequences. They test on tasks requiring multi-step tool use with adaptive planning.

Dependencies:
* T21.G7.12: Build tool-use orchestration with sequential tool calls
* T21.G8.15: Create agent orchestration with task decomposition and delegation




ID: T21.G8.17
Topic: T21 – Chatbots & Prompting
Skill: Build self-correction loops where agents review and improve outputs
Description: Students implement iterative refinement where agents critique and improve their own work. They create multi-stage pipelines: (1) agent generates initial response, (2) critic agent identifies flaws, (3) generator revises based on critique, (4) repeat until quality threshold met or max iterations reached. They implement quality scoring to decide when to stop iterating. They test on tasks where quality improves with revision (writing, code, analysis) and measure quality-vs-iteration tradeoffs.

Dependencies:
* T21.G8.16: Implement ReAct pattern (Reasoning and Acting) for agentic AI




ID: T21.G8.18
Topic: T21 – Chatbots & Prompting
Skill: Implement prompt versioning and A/B testing in production
Description: Students build production systems for managing prompt versions and testing variations. They implement: version control for prompts (track changes, rollback capability), A/B testing infrastructure (randomly assign users to variants, collect metrics), statistical significance testing, gradual rollout (expose new versions to increasing user percentages). They run real A/B tests comparing prompt variants, analyze results, and make data-driven deployment decisions. They document the testing methodology and results.

Dependencies:
* T21.G6.12: Implement A/B testing to compare prompt variants
* T21.G7.18: Monitor and log chatbot usage for cost and performance analysis




ID: T21.G8.19
Topic: T21 – Chatbots & Prompting
Skill: Design fallback strategies for chatbot failures
Description: Students implement comprehensive fallback mechanisms when primary systems fail. They create fallback chains: primary AI → simplified prompt → cached response → static helpful message → escalation to human. They implement failure detection (timeouts, error rates, quality checks), automatic fallback triggering, and recovery monitoring (when to retry primary system). They test all failure modes and verify graceful degradation. They balance user experience against cost/complexity of fallback layers.

Dependencies:
* T21.G7.17: Implement rate limiting and error handling for production use
* T21.G8.13: Create adversarial test suites for robustness evaluation




ID: T21.G8.20
Topic: T21 – Chatbots & Prompting
Skill: Create human-in-the-loop workflows with review and approval gates
Description: Students design systems where humans review and approve AI outputs before delivery. They implement review queues (flag responses needing human review based on confidence, content type, user role), approval workflows (submit → review → approve/reject/edit → deliver), and feedback loops (human edits train future AI behavior). They build reviewer dashboards showing pending items, approval rates, common issues. They measure impact of human review on quality and identify which outputs most benefit from review.

Dependencies:
* T21.G8.17: Build self-correction loops where agents review and improve outputs
* T21.G8.19: Design fallback strategies for chatbot failures




ID: T21.G8.21
Topic: T21 – Chatbots & Prompting
Skill: Implement comprehensive observability for production chatbot systems
Description: Students build complete observability: distributed tracing (track requests across multiple AI calls, tools, agents), structured logging (searchable, filterable logs with context), metrics dashboards (latency, error rates, token usage, cost), alerting (automated notifications for anomalies), and incident response playbooks. They instrument their chatbot to track the full request lifecycle, diagnose issues from logs, and optimize based on metrics. They simulate production issues and use observability tools to debug them.

Dependencies:
* T21.G7.18: Monitor and log chatbot usage for cost and performance analysis
* T21.G8.07: Build streaming response handlers for real-time chat experiences




ID: T21.G8.22
Topic: T21 – Chatbots & Prompting
Skill: Design ethical deployment frameworks for chatbot applications
Description: Students create comprehensive ethical frameworks for deploying AI chatbots. They address: informed consent (users know they're talking to AI), data privacy (handling user information responsibly), fairness (bias testing and mitigation), transparency (explaining AI limitations), accountability (human oversight and appeals process), safety (preventing harmful outputs). They implement ethical review checklists, conduct stakeholder impact analysis, and create incident response plans for ethical violations. They document the ethical framework and justify design choices.

Dependencies:
* T21.G8.03: Implement constitutional AI prompting with principle-based constraints
* T21.G8.13: Create adversarial test suites for robustness evaluation
* T21.G8.20: Create human-in-the-loop workflows with review and approval gates

# T22 - AI Perception (Phase 10 Optimized - November 2025)
# MAJOR CHANGES FROM PHASE 9:
# 1. REBALANCED GRADE DISTRIBUTION: Moved skills from overloaded G6 (was 53) to G5 (now 18) and G7 (now 24)
# 2. K-2 ENHANCED: Added algorithmic thinking skills - T22.GK.07 (classify sensor accuracy), T22.G1.06 (compare sensor speeds), T22.G2.06 (design sensor choice flowchart)
# 3. CONSOLIDATED GESTURE SKILLS: Merged overly granular gesture chains (was 6 separate fist/open/point/thumbs/peace skills) into 2 comprehensive skills
# 4. NEW COMPUTATIONAL THINKING: Added T22.G5.11 (algorithm efficiency comparison), T22.G7.16 (perception algorithm complexity analysis)
# 5. NEW DEBUGGING PROGRESSION: Added systematic debugging skills at each grade level with increasing complexity
# 6. SIMPLIFIED SKILL IDS: Reduced 4-level nesting to max 3 levels for clarity
# 7. MOVED API SKILLS EARLIER: Basic speech/hand detection setup moved to G5 to spread learning curve
# 8. ADDED PREDICTION SKILLS: More predict-before-running skills for developing mental models of AI behavior
# 9. REMOVED REDUNDANT DEPENDENCIES: Cleaned up repetitive cross-topic dependency lists
# 10. STRENGTHENED ALGORITHM DESIGN: Added skills for designing recognition algorithms before coding
# Total: 152 skills (expanded from 143, rebalanced for better progression)
# Distribution: 7 GK, 6 G1, 6 G2, 6 G3, 7 G4, 20 G5, 50 G6, 20 G7, 30 G8
# Key rebalancing: G5 increased from 12 to 20 (basic API setup moved here), G6 reduced from 53 to 50 (gesture consolidation)

ID: T22.GK.01
Topic: T22 – AI Perception
Skill: Match pictures of sensing
Description: Students drag friendly icons (eye, ear, hand) onto photos showing someone looking at a red apple, listening to a bell ringing, or pressing a big green button, building the idea that helpers need different kinds of sensing. All activities use pictures and physical objects—no screens or blocks.






ID: T22.GK.02
Topic: T22 – AI Perception
Skill: Point to where a device "looks" or "listens"
Description: Students tap the camera spot on a tablet showing a picture of a cat and the speaker/mic area on a toy robot or smart speaker, connecting device parts to senses. They use picture cards and physical devices—no code or programming environment.

Dependencies:
* T22.GK.01: Match pictures of sensing





ID: T22.GK.03
Topic: T22 – AI Perception
Skill: Choose when to uncover or quiet a helper
Description: In illustrated scenarios (covering a tablet camera with a sticker while trying to scan a QR code, talking to a voice assistant over loud music), students choose the action that lets the helper sense again (remove the sticker, make it quieter). Uses picture-based decision cards only.

Dependencies:
* T22.GK.02: Point to where a device "looks" or "listens"





ID: T22.GK.04
Topic: T22 – AI Perception
Skill: Predict what a helper will "see" in a picture
Description: Students look at pictures showing different scenes (a dog in bright sunlight, a cat in a dark room, a toy behind a hand) and predict which things a camera helper will see clearly and which it will miss. They explain their choices using simple words. Picture-based prediction activity.

Dependencies:
* T22.GK.03: Choose when to uncover or quiet a helper




ID: T22.GK.05
Topic: T22 – AI Perception
Skill: Predict when a sensor helper will struggle
Description: **Student task:** Look at picture cards showing challenging sensing situations and predict if the helper will succeed or struggle. **Visual scenarios:** (A) Voice helper in noisy playground with kids shouting—will it hear "play music"? (B) Camera helper trying to see a black cat on a black couch at night. (C) Motion sensor when person is standing very still. (D) Microphone when someone whispers from far away. Students sort cards into "Helper will work well" vs "Helper will struggle" piles and explain why using simple words (too dark, too loud, too far). Picture-based prediction activity—no screens.

Dependencies:
* T22.GK.04: Predict what a helper will "see" in a picture




ID: T22.GK.06
Topic: T22 – AI Perception
Skill: Trace sensor-to-action flow in picture stories
Description: **Student task:** Follow picture arrows showing how a sensor helper notices something and then makes something happen. **Visual scenarios:** (A) Picture story: Doorbell camera sees person → sends picture to phone → phone shows alert. Student traces with finger and says "camera sees, phone shows." (B) Picture story: Voice helper hears "turn on light" → thinks → lamp turns on. (C) Picture story: Motion sensor sees movement → alarm beeps. Students arrange scrambled picture cards into correct sensor→process→action order. **Learning focus:** Sensors notice things, then helpers decide what to do. Picture-based sequencing activity—no screens.

Dependencies:
* T22.GK.05: Predict when a sensor helper will struggle




ID: T22.GK.07
Topic: T22 – AI Perception
Skill: Classify sensor accuracy in different conditions
Description: **Student task:** Sort picture cards showing sensors working well vs sensors making mistakes. **Visual scenarios:** (A) Camera seeing red apple clearly in daylight—sorts to "works well." (B) Camera trying to see black cat in dark room—sorts to "might make mistakes." (C) Microphone hearing clear voice in quiet room—sorts to "works well." (D) Microphone trying to hear whisper at noisy playground—sorts to "might make mistakes." Students classify 8 cards total and explain patterns: "Light helps cameras, quiet helps microphones." **Learning focus:** AI sensors work better in some conditions than others—just like our eyes and ears work better sometimes. Picture-based classification with explicit pattern identification.

Dependencies:
* T22.GK.06: Trace sensor-to-action flow in picture stories


---

## GRADE 1 SKILLS




ID: T22.G1.01
Topic: T22 – AI Perception
Skill: Identify sensors on everyday devices
Description: Students look at pictures of a tablet taking a photo of a flower, a camera toy seeing a ball, a smart speaker hearing music, and a game controller being pressed, and circle where the camera, microphone, and buttons are. They sort devices by what senses they use. Picture-based activity only.

Dependencies:
* T01.GK.03: Find the first and last pictures
* T22.GK.02: Point to where a device "looks" or "listens"





ID: T22.G1.02
Topic: T22 – AI Perception
Skill: Match sensors to human senses
Description: Students drag picture icons for "see" (eye looking at a rainbow), "hear" (ear hearing a drum), and "touch" (hand feeling a fuzzy blanket) to the matching device sensors (camera, mic, touchpad) to show the parallel. They identify which sensors help a robot "see" or "hear." Picture-based matching only.

Dependencies:
* T03.GK.02: Match parts to whole objects
* T22.GK.01: Match pictures of sensing





ID: T22.G1.03
Topic: T22 – AI Perception
Skill: Identify what a sensor can notice
Description: Given picture cards (light/dark room with toys, loud music playing, soft pillow on a bed), students pick which things a camera, microphone, or touchpad can notice and which it cannot (e.g., a microphone can't see red vs blue colors). Picture-sorting activity.

Dependencies:
* T01.GK.04: Pick the pictures that make sense
* T22.G1.01: Identify sensors on everyday devices




ID: T22.G1.04
Topic: T22 – AI Perception
Skill: Trace sensor data flow using picture diagrams
Description: **Student task:** Follow picture diagrams showing how sensor information flows from device to action. **Visual scenarios:** (A) Diagram: Microphone → "hears clap" → Light turns on. Students trace with finger and explain each step. (B) Diagram: Camera → "sees face" → Door unlocks. (C) Diagram: Button → "pressed" → Music plays. Students match input (what sensor notices) to output (what happens). **Learning focus:** Sensors collect information, then something decides what to do, then action happens. Picture-based tracing with arrows—no screens.

Dependencies:
* T22.G1.03: Identify what a sensor can notice
* T01.GK.03: Find the first and last pictures




ID: T22.G1.05
Topic: T22 – AI Perception
Skill: Predict when two sensors might conflict
Description: **Student task:** Look at picture scenarios where two sensor helpers try to work at the same time and predict what might go wrong. **Visual scenarios:** (A) Two people talking to one voice helper at the same time—who does it listen to? (B) Camera trying to see while bright flashlight shines at it—can it still see the toy? (C) Two hands waving at a motion sensor—which hand does it follow? Students pick which scenario will confuse the helper and explain using simple words (too many things, too bright, too fast). They learn that sensors can get confused when there's too much happening. Picture-based prediction activity.

Dependencies:
* T22.G1.04: Trace sensor data flow using picture diagrams




ID: T22.G1.06
Topic: T22 – AI Perception
Skill: Compare sensor response speeds in picture scenarios
Description: **Student task:** Predict which sensor will respond faster in different scenarios and explain why. **Visual scenarios:** (A) Button press vs voice command to start a toy—which is faster? (B) Motion sensor at door vs camera scanning a QR code—which notices the person first? (C) Clapping hands vs typing on keyboard to get helper's attention—which works quicker? Students order sensors from "fastest" to "slowest" for each task. They discover patterns: simple sensors (buttons, motion) respond instantly, complex sensors (cameras recognizing faces, microphones understanding words) need time to "think." **Learning focus:** Different sensors take different amounts of time to work—simpler is often faster. Picture-based comparison with speed ranking.

Dependencies:
* T22.G1.05: Predict when two sensors might conflict
* T22.GK.07: Classify sensor accuracy in different conditions


---

## GRADE 2 SKILLS




ID: T22.G2.01
Topic: T22 – AI Perception
Skill: Pick the right sensor for a job
Description: Students read short picture stories (e.g., "turn on light when someone claps at a door," "open door when ID card is tapped on reader") and circle whether to use camera, microphone, or touch sensor to solve each task. Scenario-based decisions using illustrated cards.

Dependencies:
* T22.G1.03: Identify what a sensor can notice





ID: T22.G2.02
Topic: T22 – AI Perception
Skill: Identify when sensor data might be unclear
Description: Students compare pairs of pictures (bright sunny room vs dark closet for a camera trying to see a toy, quiet library vs noisy playground for a mic trying to hear a word) and pick which one makes it harder for the sensor to understand. They explain why using simple words.

Dependencies:
* T22.G2.01: Pick the right sensor for a job





ID: T22.G2.03
Topic: T22 – AI Perception
Skill: Explain that devices sometimes "guess"
Description: Students compare two illustrated scenarios: one where a toy car reacts to a button press; another where an app tries to recognize a dog bark vs cat meow. They identify which one is "guessing" from sensor input versus following a direct command.

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed




ID: T22.G2.04
Topic: T22 – AI Perception
Skill: Compare human senses vs AI sensors
Description: **Student task:** Match picture cards showing what humans do well vs what AI sensors do well. **Visual scenarios:** (A) Human easily recognizes friend's face in costume—AI might struggle. (B) AI camera can count 100 jellybeans quickly—human would take long time. (C) Human knows when friend is sad from voice tone—AI might miss emotion. (D) AI microphone can hear sounds too quiet for human ears. Students sort into "Humans better" vs "AI better" vs "Both good" piles. **Learning focus:** Humans and AI sensors each have strengths and weaknesses—neither is always better. Picture-based comparison activity—no screens.

Dependencies:
* T22.G2.02: Identify when sensor data might be unclear
* T22.G2.03: Explain that devices sometimes "guess"




ID: T22.G2.05
Topic: T22 – AI Perception
Skill: Debug sensor problems using a picture checklist
Description: **Student task:** When a sensor helper isn't working, use a picture checklist to find and fix the problem. **Visual scenario:** Voice helper won't listen. Picture checklist shows: (1) Is it turned on? (picture of power button) (2) Is it too far away? (picture of distance) (3) Is it too loud nearby? (picture of noise) (4) Is something blocking it? (picture of obstruction). Student looks at scene picture showing helper with hand covering microphone and identifies "something blocking it" as the problem. They suggest fix: "move the hand away." **Learning focus:** Check things step by step to find why a sensor isn't working. Picture-based debugging with checklist—no screens.

Dependencies:
* T22.G2.04: Compare human senses vs AI sensors
* T22.G2.02: Identify when sensor data might be unclear




ID: T22.G2.06
Topic: T22 – AI Perception
Skill: Design a sensor choice flowchart using picture cards
Description: **Student task:** Create a simple decision flowchart for choosing the right sensor for different jobs. **Activity:** Given 6 job cards (detect people entering, hear claps, feel button press, see faces, hear voice commands, sense motion in dark) and 3 sensor cards (camera, microphone, motion sensor), students build a flowchart: "Is the job about seeing things? → Yes → Does it need to work in dark? → Yes → Motion sensor / No → Camera." They arrange picture cards showing decision questions and sensor answers. They test their flowchart against new job scenarios to verify it works. **Learning focus:** Making decisions step-by-step helps choose the best sensor—this is algorithmic thinking. Picture-based algorithm design—no screens.

Dependencies:
* T22.G2.05: Debug sensor problems using a picture checklist
* T22.G1.06: Compare sensor response speeds in picture scenarios


---

## GRADE 3 SKILLS




ID: T22.G3.01
Topic: T22 – AI Perception
Skill: Explain a picture as a grid of tiny colors
Description: Students view a photo of a house and its pixelated grid side by side in CreatiCode and explain that cameras store pictures as small colored squares (pixels). They use a simple sprite costume editor to highlight individual pixels and observe how changing brightness affects pixel colors.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T22.G2.01: Pick the right sensor for a job





ID: T22.G3.02
Topic: T22 – AI Perception
Skill: Explain sound as a wavy line of loud/soft
Description: Students see a simple waveform visualization for a clap vs a whisper and match which wave is which. They note that microphones turn sound into a line that goes up (louder) and down (softer). They may use a costume or backdrop showing waveforms.

Dependencies:
* T06.G3.05: Decide which event type to use for a behavior





ID: T22.G3.03
Topic: T22 – AI Perception
Skill: Identify whether a behavior uses sensing and guessing
Description: Students read simple program descriptions (e.g., "game starts when you press space" vs "door opens when it sees your face") and decide which ones require the device to sense and guess vs ones that follow a fixed button rule. They identify the event blocks that would be used.

Dependencies:
* T22.G3.02: Explain sound as a wavy line of loud/soft
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T22.G3.04
Topic: T22 – AI Perception
Skill: Sort inputs by sensor type
Description: Students examine a list of inputs (photo, voice recording, button press, microphone level, screen tap) and sort them by sensor type (camera, microphone, touch). They identify which inputs come from AI perception (camera, mic) vs direct user control (button, tap). Bridging skill between foundational concepts and block-based coding.

Dependencies:
* T22.G3.03: Identify whether a behavior uses sensing and guessing




ID: T22.G3.05
Topic: T22 – AI Perception
Skill: Trace how pixel and sound data changes in different conditions
Description: Students examine side-by-side comparisons showing how raw sensor data changes with conditions. **Image examples:** Same photo of a ball shown bright vs dimmed—students observe pixel colors getting darker. Same face photo in good light vs backlighting—face becomes silhouette. **Sound examples:** Same word spoken clearly vs in noisy room—waveform becomes messy. Students trace arrows from condition (dark room) → sensor data (darker pixels) → AI result (harder to recognize). They build simple demonstration scripts in CreatiCode showing how brightness affects recognition.

Dependencies:
* T22.G3.01: Explain a picture as a grid of tiny colors
* T22.G3.02: Explain sound as a wavy line of loud/soft
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




ID: T22.G3.06
Topic: T22 – AI Perception
Skill: Classify inputs as continuous vs discrete sensor data
Description: Students classify different types of sensor inputs into two categories: **Continuous data** (constantly streaming—camera video, microphone audio, hand position) vs **Discrete data** (one-time events—button press, voice command result, photo snapshot). They examine input examples and sort them: "Is this always flowing or does it happen once?" They trace simple scripts and identify which use continuous sensing (forever loops reading camera) vs discrete sensing (wait for button, get speech result). They build scripts demonstrating both patterns. **Learning focus:** Different sensors give different kinds of data that need different programming patterns.

Dependencies:
* T22.G3.04: Sort inputs by sensor type
* T22.G3.05: Trace how pixel and sound data changes in different conditions
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence


---

## GRADE 4 SKILLS




ID: T22.G4.01
Topic: T22 – AI Perception
Skill: Trace how lighting changes pixel data
Description: Students use a provided slider UI (built with basic blocks) to dim/brighten a sample image costume of a sunset and observe which pixel areas get darker/brighter in the costume editor. They answer questions about why dark rooms make images harder for AI to read.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T22.G2.02: Identify when sensor data might be unclear
* T22.G3.01: Explain a picture as a grid of tiny colors





ID: T22.G4.02
Topic: T22 – AI Perception
Skill: Choose a good setup for mic or camera
Description: Students examine 3 illustrated scenarios (e.g., backlit window vs front-lit desk for camera, mic 1 foot vs 10 feet from speaker) and pick the best setup for clear input. They build a simple Scratch script that displays "good setup" or "needs improvement" messages.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T22.G3.01: Explain a picture as a grid of tiny colors
* T22.G3.02: Explain sound as a wavy line of loud/soft





ID: T22.G4.03
Topic: T22 – AI Perception
Skill: Identify noise and simple fixes
Description: Students examine examples of blurry images (shaking camera), shaky video clips (walking while filming), or choppy audio recordings (wind hitting microphone) and select a simple fix (steady the device, add light, move to quieter spot) before any AI coding happens. They create a troubleshooting flowchart using sprites.

Dependencies:
* T01.G2.01: Find actions that repeat in everyday tasks
* T04.G2.03: Compare a long explicit description vs a compressed "repeat" description
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T22.G3.01: Explain a picture as a grid of tiny colors





ID: T22.G4.04
Topic: T22 – AI Perception
Skill: Predict what happens when sensor input is blocked
Description: Students predict the outcomes when sensor inputs are blocked (hand covering camera, loud noise blocking microphone, disconnected button) by tracing through simple scripts and explaining what the program will do. They test predictions in CreatiCode. Prediction and tracing skill.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T22.G4.03: Identify noise and simple fixes




ID: T22.G4.05
Topic: T22 – AI Perception
Skill: Debug sensor setup issues using systematic checking
Description: Students practice systematic debugging when sensors aren't working as expected. They learn a checklist approach: (1) Check hardware—is camera/mic enabled in browser? (2) Check environment—is lighting good? Is it quiet enough? (3) Check code—is the detection block running? Is the output variable being read correctly? They build a simple "sensor diagnostic" project that runs checks and reports which step might be failing. They practice explaining their debugging process to others.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T08.G3.12: Fix a condition that uses the wrong comparison operator
* T22.G4.03: Identify noise and simple fixes
* T22.G4.04: Predict what happens when sensor input is blocked




ID: T22.G4.06
Topic: T22 – AI Perception
Skill: Trace the detection API workflow pattern
Description: Students trace through the common pattern used by all CreatiCode perception APIs: (1) **Start:** Call detection block with configuration (table name, debug mode). (2) **Wait:** Detection runs continuously in background, updating table. (3) **Read:** Access table data using row/column. (4) **Process:** Use conditionals to interpret data. (5) **Stop:** End detection to release resources. They trace through annotated code examples for hand detection and speech recognition, marking each step. They identify what each block does in the workflow and predict what happens if steps are skipped (forgot to stop = camera stays on, forgot to read = no response to input).

Dependencies:
* T22.G4.05: Debug sensor setup issues using systematic checking
* T22.G3.06: Classify inputs as continuous vs discrete sensor data
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




ID: T22.G4.07
Topic: T22 – AI Perception
Skill: Predict detection API output from visual input
Description: Students predict what detection APIs will output given specific visual inputs. **Hand detection:** Show picture of open hand with fingers spread—predict curl values will be high (>150). Show picture of fist—predict curl values will be low (<50). **Body detection:** Show picture of person with arms raised—predict wrist y-coordinate will be less than shoulder y-coordinate (higher on screen). **Face detection:** Show picture of tilted head—predict tilt angle will be non-zero. Students trace through the detection → table → output flow and write predicted table values before running actual detection to verify.

Dependencies:
* T22.G4.06: Trace the detection API workflow pattern
* T22.G4.04: Predict what happens when sensor input is blocked
* T08.G3.12: Fix a condition that uses the wrong comparison operator


---

## GRADE 5 SKILLS




ID: T22.G5.01
Topic: T22 – AI Perception
Skill: Compare what people see vs what pixels show
Description: Students look at a clear photo of a street sign and its coarse pixel version side by side and explain what detail is lost for the computer but obvious to a person (e.g., small text, faint objects). They use the costume editor to zoom in and count pixels.

Dependencies:
* T08.G3.12: Fix a condition that uses the wrong operator
* T22.G4.01: Trace how lighting changes pixel data
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name





ID: T22.G5.02
Topic: T22 – AI Perception
Skill: Explain why an AI might mis-hear or mis-see
Description: Given examples of mis-recognized words (strong accent saying "three") or images (shadowed face at doorway), students identify likely causes (background noise, low light, unusual angle) and suggest one fix (move closer, add light, speak clearly). They build a simple diagnostic tool.

Dependencies:
* T08.G3.12: Fix a condition that uses the wrong operator
* T22.G4.03: Identify noise and simple fixes
* T22.G3.03: Identify whether a behavior uses sensing and guessing
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name





ID: T22.G5.03
Topic: T22 – AI Perception
Skill: Choose safe ways to handle sensor data
Description: Students compare actions for camera/mic data (e.g., "keep photos only on device" vs "share raw recordings with strangers on internet") and classify them as safe or risky. They link perception to privacy before coding actual AI blocks.

Dependencies:
* T08.G3.12: Fix a condition that uses the wrong operator
* T22.G4.02: Choose a good setup for mic or camera
* T22.G3.03: Identify whether a behavior uses sensing and guessing
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name





ID: T22.G5.04
Topic: T22 – AI Perception
Skill: Identify when AI sensing might be unfair
Description: Students examine scenarios where AI perception might work poorly for some groups (face recognition in poor lighting failing for dark skin tones, voice recognition with different accents) and suggest basic fairness improvements (better lighting, multiple language options).

Dependencies:
* T08.G3.05
* T22.G4.03
* T22.G3.03
* T09.G3.03
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T22.G5.05.01
Topic: T22 – AI Perception
Skill: Identify what data different detection types provide
Description: Students learn that AI vision blocks detect specific features with distinct outputs: hand detection (finger positions, curl angles, direction), body detection (body part positions), and face detection (face locations, landmarks). They match detection types to their data outputs using picture cards showing tables with x/y coordinates, angles, and other values.

Dependencies:
* T10.G5.04
* T22.G5.01
* T09.G3.03
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T22.G5.05.02
Topic: T22 – AI Perception
Skill: Map detection data to table structures
Description: Students examine annotated examples showing how each detection type stores data in tables: hand detection (47 rows per hand with sections for finger summaries, 2D landmarks, 3D landmarks), body detection (17 keypoints + 4 limbs), face detection (13 rows per face with tilt angle and 6 landmark positions). They practice reading table diagrams and identifying which row/column contains specific information (e.g., "Which row has index finger curl?").

Dependencies:
* T10.G5.04
* T22.G5.05.01: Identify what data different detection types provide
* T09.G3.03





ID: T22.G5.05.03
Topic: T22 – AI Perception
Skill: Trace perception API workflow patterns
Description: Students trace the common pattern for perception APIs: (1) start detection with configuration, (2) read results from output table, (3) process data with conditionals, (4) stop detection. They match API blocks to workflow steps (start→read→process→stop) using diagrams. Picture-based workflow analysis, no coding yet.

Dependencies:
* T22.G5.05.02: Map detection data to table structures
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name





ID: T22.G5.06
Topic: T22 – AI Perception
Skill: Predict detection output from given input
Description: Students predict what hand detection, body pose, or face detection will output given specific inputs (photo of person waving, image of person squatting, picture of smiling face). They trace through the detection workflow and predict table contents (curl values, keypoint positions, landmark locations) before running actual detection. Tracing and prediction skill.

Dependencies:
* T22.G5.05.03: Trace perception API workflow patterns
* T22.G5.05.02: Map detection data to table structures




ID: T22.G5.07
Topic: T22 – AI Perception
Skill: Compare detection API capabilities and limitations
Description: Students compare what different CreatiCode perception APIs can and cannot detect. **Hand detection:** Detects fingers, curl, direction—but NOT specific finger gestures by name. **Body detection:** Detects keypoints, poses—but NOT action recognition (jumping vs walking). **Face detection:** Detects position, tilt, landmarks—but NOT expressions, emotions, age, or gender. **Speech recognition:** Converts speech to text—but NOT speaker identification or emotion. They create a comparison chart and identify which API to use for different tasks, understanding limitations before coding.

Dependencies:
* T22.G5.05.01: Identify what data different detection types provide
* T22.G5.05.02: Map detection data to table structures
* T22.G4.05: Debug sensor setup issues using systematic checking




ID: T22.G5.08
Topic: T22 – AI Perception
Skill: Predict edge cases that will challenge detection APIs
Description: Students predict scenarios that will cause detection APIs to struggle or fail. **Hand detection edge cases:** Hands overlapping, very fast movement, unusual angles, gloves. **Body detection edge cases:** Person partially off-screen, sitting behind desk, lying down. **Face detection edge cases:** Face at extreme angle, sunglasses, face partially covered. **Speech recognition edge cases:** Background music, multiple speakers, unfamiliar accents. They rank difficulty (easy/medium/hard for AI) and suggest workarounds. Prediction skill that prepares for G6 error handling.

Dependencies:
* T22.G5.07: Compare detection API capabilities and limitations
* T22.G5.06: Predict detection output from given input
* T22.G4.04: Predict what happens when sensor input is blocked




ID: T22.G5.09
Topic: T22 – AI Perception
Skill: Design a simple gesture recognizer on paper before coding
Description: Students design a gesture recognition system on paper before implementing it. They choose 3 gestures (e.g., thumbs up, open hand, fist), draw what each looks like, identify the key features that distinguish them (thumb curl, finger spread, hand orientation), and write pseudocode rules: "IF thumb curl > 150 AND other fingers curl < 50 THEN gesture = thumbs up." They create a decision flowchart showing how to classify an unknown hand input. **Learning focus:** Planning recognition logic before coding leads to better systems. Design-first approach to perception programming.

Dependencies:
* T22.G5.05.02: Map detection data to table structures
* T22.G5.06: Predict detection output from given input
* T01.G4.00: Design algorithm from description before coding




ID: T22.G5.10
Topic: T22 – AI Perception
Skill: Trace confidence and uncertainty in detection results
Description: Students learn that AI detection results have varying levels of certainty. They examine detection outputs and identify when the AI is confident (clear hand pose, well-lit face, quiet room for speech) vs uncertain (partially visible hand, blurry face, noisy audio). They trace through scenarios where low confidence leads to errors: "AI detected 'thumbs up' but was only 60% sure—user actually showed peace sign." They learn to check for conditions that reduce confidence and design programs that handle uncertainty (wait for clearer input, ask user to confirm, show confidence level to user).

Dependencies:
* T22.G5.08: Predict edge cases that will challenge detection APIs
* T22.G5.07: Compare detection API capabilities and limitations
* T22.G4.05: Debug sensor setup issues using systematic checking




ID: T22.G5.11
Topic: T22 – AI Perception
Skill: Compare algorithm efficiency for different detection approaches
Description: Students compare the computational efficiency of different detection approaches. They trace through two approaches to detect "person waving": (A) Simple motion detection: just check if pixels change—fast but can't tell what moved. (B) Body detection with pose analysis: find skeleton, check arm position—accurate but slower. They list trade-offs: motion sensing is fast (1ms) but gives false positives (curtain blowing), body detection is accurate but slow (50ms) and needs good lighting. They predict which approach is better for different scenarios: security camera (motion), fitness game (body), casual game trigger (either). **Learning focus:** Different algorithms solve the same problem with different trade-offs—choosing the right one matters.

Dependencies:
* T22.G5.07: Compare detection API capabilities and limitations
* T22.G5.05.03: Trace perception API workflow patterns




ID: T22.G5.12
Topic: T22 – AI Perception
Skill: Set up basic speech recognition and display results
Description: Students use basic speech recognition in CreatiCode: `start recognizing speech in [English v] record as []`, wait briefly, then `end speech recognition`. They display recognized text using `text from speech` reporter block in a `say` block. They experiment with different languages from the dropdown and observe accuracy differences. They implement simple error handling: check if result is empty (no speech detected). **Key workflow:** start → speak → end → read. They understand this is the foundation for voice-controlled applications. This is an introductory hands-on skill before the more advanced G6 speech skills.

Dependencies:
* T22.G5.05.03: Trace perception API workflow patterns
* T22.G5.02: Explain why an AI might mis-hear or mis-see
* T06.G5.01: Identify standard event patterns in a small game
* T09.G5.01: Use multiple variables together in a single expression




ID: T22.G5.13
Topic: T22 – AI Perception
Skill: Set up hand detection and observe debug output
Description: Students use `run hand detection table [handData v] debug [yes v] show video [yes v]` to enable hand detection. They observe the debug overlay drawing keypoints on their hands in the video feed. They toggle debug mode and video visibility to understand what each option does. They verify that the handData table fills with detection data as they move their hands. **Key concepts:** Detection runs continuously once started, debug mode helps visualize what AI sees, data goes into a table. This is hands-on exploration before detailed table reading in G6.

Dependencies:
* T22.G5.05.02: Map detection data to table structures
* T22.G5.05.03: Trace perception API workflow patterns
* T10.G5.04: Read a cell value from a table




ID: T22.G5.14
Topic: T22 – AI Perception
Skill: Set up body detection and observe skeleton overlay
Description: Students use `run 2D body part recognition single person [yes v] table [bodyData v] debug [yes v]` to enable body pose detection. They observe the skeleton overlay connecting their body keypoints (shoulders, elbows, wrists, hips, knees, ankles). They compare single-person mode (faster, more stable) vs multi-person mode (can detect multiple people but slower). They verify that bodyData table updates as they move. **Key concepts:** Body detection finds 17 keypoints plus limb measurements, single-person mode is faster for games/fitness apps. Hands-on exploration before detailed pose analysis in G6.

Dependencies:
* T22.G5.05.02: Map detection data to table structures
* T22.G5.05.03: Trace perception API workflow patterns
* T10.G5.04: Read a cell value from a table




ID: T22.G5.15
Topic: T22 – AI Perception
Skill: Set up face detection and observe detected face boxes
Description: Students use `run face detection debug [yes v] and write into table [faceData v]` to enable face detection. They observe bounding boxes drawn around detected faces. They test with multiple people visible and see how the table contains data for each face. They understand that face detection provides face position, tilt angle, and 6 landmarks (eyes, nose, mouth, ears)—NOT expressions, emotions, or identity. **Key concepts:** Face detection is simpler than face recognition, multiple faces can be detected, each face gets 13 rows in the table.

Dependencies:
* T22.G5.05.02: Map detection data to table structures
* T22.G5.05.03: Trace perception API workflow patterns
* T10.G5.04: Read a cell value from a table




ID: T22.G5.16
Topic: T22 – AI Perception
Skill: Read and display basic detection data from tables
Description: Students read specific values from detection tables and display them. For hand detection: read finger curl values from rows 1-5, display "Index finger curl: [value]°" using say block. For body detection: read wrist x/y coordinates, display position. For face detection: read tilt angle, display "Head tilt: [value]°". They use `value of [table v] row [1] column [curl]` to extract data. They build a simple "detection data viewer" that shows key values updating in real-time.

Dependencies:
* T22.G5.13: Set up hand detection and observe debug output
* T22.G5.14: Set up body detection and observe skeleton overlay
* T22.G5.15: Set up face detection and observe detected face boxes
* T10.G5.04: Read a cell value from a table




ID: T22.G5.17
Topic: T22 – AI Perception
Skill: Use video motion sensing for simple movement triggers
Description: Students use Scratch's built-in video sensing for basic motion detection without complex AI. They access `video motion on [stage v]` (returns 0-100) to detect movement intensity and `video direction on [stage v]` for movement direction. They implement motion triggers: "when video motion > 30, sprite jumps." They compare video sensing (simple, fast, any movement) vs body detection (complex, slower, specific body parts). **Use cases:** motion-activated animations, movement games, presence detection. This simpler alternative is often sufficient.

Dependencies:
* T22.G5.11: Compare algorithm efficiency for different detection approaches
* T06.G5.01: Identify standard event patterns in a small game




ID: T22.G5.18
Topic: T22 – AI Perception
Skill: Use loudness sensing for sound-reactive applications
Description: Students use the `loudness` sensing block (returns 0-100) to detect microphone audio levels without speech recognition. They implement sound-reactive applications: visualizers that respond to music/clapping, sound meters, noise triggers ("when loudness > 50, sprite changes color"). They distinguish between loudness detection (how loud—simple) vs speech recognition (what words—complex). They handle ambient noise by establishing a baseline ("normal room is 15, clap is 60"). **Use cases:** music visualizers, rhythm games, noise alerts.

Dependencies:
* T22.G5.11: Compare algorithm efficiency for different detection approaches
* T09.G5.01: Use multiple variables together in a single expression


---

## GRADE 6 SKILLS




ID: T22.G6.01
Topic: T22 – AI Perception
Skill: Implement voice command recognition with language selection
Description: Building on G5 speech basics, students create voice command systems. They implement: (1) Language selection UI letting users choose their language before speaking. (2) Command matching: check if recognized text contains keywords ("play," "stop," "next"). (3) Error handling: empty result → "I didn't hear that, try again." (4) Feedback: visual indicator when listening, confirmation when command recognized. They build a simple voice-controlled music player with commands for play, pause, skip. **Key learning:** Moving from raw speech recognition to actionable voice commands requires matching, error handling, and user feedback.

Dependencies:
* T22.G5.12: Set up basic speech recognition and display results
* T08.G5.02: Use a simple if in a script
* T11.G5.01: Decompose a problem into logical custom block boundaries





ID: T22.G6.01.02
Topic: T22 – AI Perception
Skill: Select speech recognition language and observe accuracy differences
Description: Students extend basic speech recognition by exploring the language dropdown in `start recognizing speech in [LANGUAGE v] record as []`. They test recognition with different languages (English, Spanish, Chinese, etc.) and observe how selecting the correct language improves accuracy. They build a simple app that lets users choose their language before speaking.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.01.01: Capture a single spoken phrase with basic speech recognition





ID: T22.G6.01.03
Topic: T22 – AI Perception
Skill: Use continuous speech recognition for real-time transcription
Description: Students learn continuous speech recognition: `start continuous speech recognition in [LANGUAGE v] into list [listname v]` to begin streaming recognition. The list continuously updates with recognized phrases. They use `stop continuous speech recognition` to end. They build a live transcript display that updates as the user speaks.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.01.02: Select speech recognition language and observe accuracy differences





ID: T22.G6.01.04
Topic: T22 – AI Perception
Skill: Handle speech recognition errors and implement retry logic
Description: Students implement error handling for speech recognition failures: check if result is empty (no speech detected), provide visual/audio feedback when recognition fails, implement retry mechanism (allow 3 attempts), and offer alternative input methods (text entry, button selection) when speech consistently fails. They learn to detect timeout scenarios and provide helpful error messages to users.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.01.03: Use continuous speech recognition for real-time transcription




ID: T22.G6.01.05
Topic: T22 – AI Perception
Skill: Implement speech recognition timeout with graceful degradation
Description: Students implement timeout handling for speech recognition that degrades gracefully. They track time since recognition started, and if no speech is detected within a threshold (e.g., 10 seconds), they automatically: (1) end recognition to prevent indefinite waiting, (2) display a timeout message, (3) offer alternatives (try again, type instead, cancel). They implement a visual countdown or progress indicator showing time remaining. They distinguish between "user hasn't spoken yet" (keep waiting with feedback) vs "recognition seems stuck" (timeout and recover). They test with scenarios: user distracted, mic blocked, background noise preventing detection.

Dependencies:
* T22.G6.01.04: Handle speech recognition errors and implement retry logic
* T09.G5.01: Use multiple variables together in a single expression




ID: T22.G6.02.01
Topic: T22 – AI Perception
Skill: Convert text to speech with basic settings
Description: Students use the `say [TEXT] in [LANGUAGE v] as [VOICETYPE v] speed (SPEEDRATIO) pitch (PITCHRATIO) volume (VOLUMERATIO) store sound as []` block to convert text to speech. They experiment with different languages, voice types (Male/Female), and adjust speed/pitch/volume parameters (default 100, range 50-200) to create different speaking styles.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G5.02: Explain why an AI might mis-hear or mis-see





ID: T22.G6.02.02
Topic: T22 – AI Perception
Skill: Control TTS playback using the stop speaking block
Description: Students learn to interrupt text-to-speech output using the `stop speaking` block. They implement scenarios where TTS needs to be cancelled: user clicks skip button, new urgent message arrives, or timeout occurs. They manage the timing of TTS to prevent overlapping speech and implement queuing systems for multiple TTS messages.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.02.01: Convert text to speech with basic settings





ID: T22.G6.02.03
Topic: T22 – AI Perception
Skill: Save and reuse text-to-speech audio recordings
Description: Students use the `store sound as []` parameter in the TTS block to save generated speech as a sound file that can be replayed without regenerating. They learn when to pre-generate audio (static messages, frequently used phrases) vs generate on-demand (dynamic content). They implement a sound library system that caches commonly used TTS outputs for faster playback and reduced API calls.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.02.02: Control TTS playback using the stop speaking block





ID: T22.G6.03.01
Topic: T22 – AI Perception
Skill: Build a two-way voice chatbot loop
Description: Students combine speech-to-text (`start recognizing speech in [LANGUAGE v] record as []` → `end speech recognition` → `text from speech`), ChatGPT request block (`OpenAI ChatGPT: request … result [variable]`), and text-to-speech (`say [TEXT] in [LANGUAGE v] as [VOICETYPE v] …`) to build a voice assistant. They implement turn-taking: listen → process → speak → repeat. They learn the complete conversational flow: detect when user stops speaking, send transcript to ChatGPT API, receive response text, convert response to speech, play audio output, then restart listening. They handle timing issues like waiting for TTS to complete before listening again and managing conversation state across turns. Note: Requires T22 ChatGPT knowledge.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T21.G6.01: Trace how a chatbot script processes each turn
* T22.G6.01.02: Select speech recognition language and observe accuracy differences
* T22.G6.02.01: Convert text to speech with basic settings





ID: T22.G6.03.02
Topic: T22 – AI Perception
Skill: Use OpenAI Whisper for advanced speech transcription
Description: Students use `OpenAI: start recognizing speech in [LANGUAGE v] record as []` → `end speech recognition` → `text from speech` for high-accuracy speech recognition via OpenAI Whisper API. They compare Whisper's performance with basic speech recognition, especially in noisy environments or with accents, and learn trade-offs (accuracy vs. speed, API costs).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T21.G6.01: Trace how a chatbot script processes each turn
* T22.G6.01.02: Select speech recognition language and observe accuracy differences





ID: T22.G6.04.01
Topic: T22 – AI Perception
Skill: Set up hand detection and view debug output
Description: Students use `run hand detection table [TABLENAME v] debug [yes v] show video [yes v]` to turn on the front camera and detect hands. They explore the debug mode (draws keypoints on video) and show/hide video options. They observe how the detection responds to hand movements.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G5.05.03: Trace perception API workflow patterns





ID: T22.G6.04.02.01
Topic: T22 – AI Perception
Skill: Map hand detection table structure
Description: Students map the hand detection table structure: 47 rows per detected hand organized into three sections: (1) rows 1-5 contain finger summaries (thumb, index, middle, ring, pinky) with columns [hand, part, curl, dir, x, y, z], (2) rows 6-26 contain 2D landmark positions, (3) rows 27-47 contain 3D landmark positions. They identify which row contains specific finger data and trace that curl ranges from 0° (fully closed/fist) to 180° (fully extended/straight), direction ranges from 0° to 360° indicating pointing direction, and x/y are screen coordinates while z is depth. They practice locating specific data: "Which row has index finger curl?" (row 2). IMPORTANT: Curl and dir values are ONLY available in rows 1-5 (finger summaries), NOT in the landmark rows.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.01: Set up hand detection and view debug output





ID: T22.G6.04.02.02
Topic: T22 – AI Perception
Skill: Read finger curl values from hand detection table
Description: Students read curl values from the hand detection table (rows 1-5) to get finger curl angles. Each row contains: hand ID (which hand: 0=right, 1=left), part name (finger name), curl angle (0-180°), direction angle (0-360°), and x/y/z coordinates. They use table read blocks to extract curl values for specific fingers and understand that curl measures how bent the finger is: 0° = closed fist, 180° = straight finger. Note: Curl values are only in rows 1-5 (finger summaries).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.02.01: Map hand detection table structure





ID: T22.G6.04.02.03
Topic: T22 – AI Perception
Skill: Display hand detection data using variable monitors
Description: Students display finger curl values on screen using variable monitors or say blocks. They create a display showing all five finger curl angles updating in real-time as the hand moves. They implement basic gesture detection by checking curl thresholds: pointing (index curl > 170, others < 170) or fist (all curl < 90). No advanced UI integration yet, just displaying values and simple threshold-based detection.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.02.02: Read finger curl values from hand detection table





ID: T22.G6.04.03
Topic: T22 – AI Perception
Skill: Read finger direction data for advanced gesture recognition
Description: Students extend hand detection by reading the direction (dir) column from the hand detection table (rows 1-5). Each finger summary has a direction indicating which way it's pointing (up, down, left, right). They combine curl and direction to recognize complex gestures: "thumbs up" = thumb extended (curl > 170) + pointing up, "peace sign" = index and middle extended + pointing up. Note: Direction values are only in rows 1-5 (finger summaries).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.04.04
Topic: T22 – AI Perception
Skill: Implement basic gesture recognition using curl thresholds
Description: Students implement gesture recognition for 3 basic gestures using finger curl values. **Fist:** all five fingers curl < 90° (closed hand). **Open hand:** all five fingers curl > 150° (spread fingers). **Pointing:** index curl > 170° while others < 90° (one finger extended). For each gesture, they: read curl values from hand table rows 1-5, combine conditions with AND logic, display gesture name when detected. They create a "gesture detector" that cycles through checks: if fist conditions → "Fist!", else if open conditions → "Open!", else if point conditions → "Pointing!", else "Unknown." **Key learning:** Gesture recognition = reading sensor data + threshold comparisons + conditional logic. Students understand thresholds need calibration for different users.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.03: Read finger direction data for advanced gesture recognition





ID: T22.G6.04.05
Topic: T22 – AI Perception
Skill: Implement advanced gesture recognition using curl and direction
Description: Students extend gesture recognition to include direction-aware gestures. **Thumbs up:** thumb curl > 170° AND direction 315-45° (pointing up) AND other fingers < 90°. **Peace sign:** index and middle curl > 170° AND both directions similar (within 45°) AND others < 90°. **Thumbs down:** thumb curl > 170° AND direction 135-225° (pointing down). They learn: (1) Direction values wrap around 360° (handle 350° = near 0°). (2) Complex gestures need more conditions → more false negatives. (3) Direction ranges need to be generous (±45°) for reliability. They build a "gesture game" where players earn points for performing requested gestures within time limits. **Key learning:** Adding direction enables more gestures but increases complexity and potential for misrecognition.

Dependencies:
* T22.G6.04.04: Implement basic gesture recognition using curl thresholds
* T09.G5.01: Use multiple variables together in a single expression





ID: T22.G6.04.06
Topic: T22 – AI Perception
Skill: Drive UI elements with live hand detection
Description: Students read x/y coordinates from the hand detection table (wrist or index finger position) and convert them into UI widget interactions: move a pointer sprite, adjust a slider, trigger hover states. They learn to hide the camera feed (`show video [no v]`) to reduce distraction while keeping detection active.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.05: Implement advanced gesture recognition using curl and direction





ID: T22.G6.04.07
Topic: T22 – AI Perception
Skill: Detect and differentiate between left and right hands
Description: Students read the hand ID from the hand detection table (column: hand, value: 0=right hand, 1=left hand) to determine which hand is detected. They implement applications that require specific hand usage: "raise right hand to answer," "use left hand for menu," or two-handed gestures that coordinate both hands. They handle scenarios where both hands are visible and track each hand independently.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.05: Implement advanced gesture recognition using curl and direction





ID: T22.G6.04.08
Topic: T22 – AI Perception
Skill: Track multiple hands simultaneously
Description: Students process hand detection data when multiple hands are visible. The table contains 47 rows per hand, so 2 hands = 94 rows. They iterate through the table to separate data for each hand (rows 1-47 = first hand, rows 48-94 = second hand), track gestures for each hand independently, and implement two-handed interactions: clapping detection (both hands close together), measuring hand distance, or cooperative gestures requiring both hands.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.07: Detect and differentiate between left and right hands





ID: T22.G6.04.09
Topic: T22 – AI Perception
Skill: Stop hand detection when no longer needed
Description: Students implement proper cleanup for hand detection by stopping the detection when it's no longer needed. They understand that detection consumes resources (camera, processing) and should be stopped when: switching to different input mode, pausing the application, or when detection task is complete. They use a stop block or proper event handling to end detection gracefully and release the camera. They implement detection lifecycle: start → use → stop, preventing resource leaks.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.06.01
Topic: T22 – AI Perception
Skill: Apply moving average to smooth noisy sensor data
Description: Students implement moving average smoothing: store the last 5 wrist position readings in a list, calculate the average of these values, and use the averaged position to move a sprite. They observe how averaging reduces jittery movement and understand the trade-off between smoothness (larger window) and responsiveness (smaller window). They learn when to apply smoothing (continuous tracking) vs when not to (detecting quick gestures).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T09.G5.05: Use the accumulator pattern to compute running totals
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G4.03: Identify noise and simple fixes
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.06.02
Topic: T22 – AI Perception
Skill: Use clamping to limit sensor values to valid ranges
Description: Students implement value clamping to constrain sensor readings to valid ranges. They use conditional blocks to check if a value exceeds boundaries and reset it to the boundary value: `if position < 0 then set position to 0`, `if position > 480 then set position to 480`. They apply clamping to prevent sprites from moving off-screen, keep angles within 0-360 range, and filter out impossible sensor values that indicate errors.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G4.03: Identify noise and simple fixes
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.06.03
Topic: T22 – AI Perception
Skill: Implement debouncing to filter rapid fluctuations
Description: Students implement debouncing to ignore rapid changes in sensor data. They require a value to remain stable for a minimum time (e.g., 0.5 seconds) before accepting it as valid. For gesture detection, they check that a gesture is maintained for multiple consecutive frames (3+ frames) before triggering an action. This prevents false positives from brief sensor noise or accidental hand movements. They understand the trade-off between reliability and responsiveness.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G4.03: Identify noise and simple fixes
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.06.04
Topic: T22 – AI Perception
Skill: Create watchdog timers to detect and recover from sensor dropouts
Description: Students implement watchdog timers to detect when sensors stop providing data. They track the time since last valid sensor reading and trigger recovery actions if too much time passes (e.g., 2 seconds with no hand detected). Recovery actions include: displaying "hand not detected" message, switching to alternative input mode, or restarting the detection system. They handle scenarios where hands temporarily leave the camera frame and distinguish between brief dropouts (ignore) and extended absence (notify user).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G4.03: Identify noise and simple fixes
* T22.G6.04.02.03: Display hand detection data using variable monitors





ID: T22.G6.07
Topic: T22 – AI Perception
Skill: Choose continuous vs. event-driven detection patterns
Description: Students compare two detection patterns: (1) continuous polling in forever loop (constantly read table and update), (2) event-driven (start detection, wait for specific condition, then act). They implement both patterns with hand detection: continuous mode moves sprite smoothly following hand, event-driven mode triggers action when gesture detected. They discuss trade-offs: continuous is smooth but CPU-intensive, event-driven is efficient but may miss quick gestures.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.04.05: Implement advanced gesture recognition using curl and direction
* T22.G6.06.01: Apply moving average to smooth noisy sensor data





ID: T22.G6.08
Topic: T22 – AI Perception
Skill: Add consent and privacy controls for sensor use
Description: Students add clear permission requests before enabling camera/mic detection ("This app needs your camera. Allow?"), provide easy on/off toggle buttons, and implement data retention limits (clear table after use). They explain to users what data is collected and why, using T16 labels and dialogs.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T15.G6.01: Attach a button to a sprite and respond to clicks
* T22.G5.03: Choose safe ways to handle sensor data





ID: T22.G6.09.01.01
Topic: T22 – AI Perception
Skill: Set up 2D body detection and view debug output
Description: Students use `run 2D body part recognition single person [yes v] table [TABLENAME v] debug [yes v]` to detect body landmarks. They explore debug mode (draws skeleton on video) and understand single-person vs multi-person mode. They observe how the detection responds to body movements and poses.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G5.05.03: Trace perception API workflow patterns





ID: T22.G6.09.01.02
Topic: T22 – AI Perception
Skill: Map body detection table structure
Description: Students map the body detection table structure with 21 rows per person: 17 keypoint rows (nose, left_eye, right_eye, left_ear, right_ear, left_shoulder, right_shoulder, left_elbow, right_elbow, left_wrist, right_wrist, left_hip, right_hip, left_knee, right_knee, left_ankle, right_ankle) plus 4 limb measurements (left_arm, right_arm, left_leg, right_leg). Table columns are: id, part, x, y, curl, dir. They identify that keypoints can be unreliable when occluded (hidden) and that confidence affects detection quality. They practice locating which row contains specific body parts.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.01.01: Set up 2D body detection and view debug output





ID: T22.G6.09.01.03
Topic: T22 – AI Perception
Skill: Read body keypoint positions from the table
Description: Students read body keypoint x/y coordinates from the body detection table. They extract specific keypoint positions (e.g., wrist, shoulder, knee) and display them using variable monitors or by moving sprites to keypoint locations. They implement basic pose visualization by drawing lines between connected keypoints (shoulder to elbow, elbow to wrist, etc.) to create a stick-figure representation.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.01.02: Map body detection table structure





ID: T22.G6.09.01.04
Topic: T22 – AI Perception
Skill: Stop body detection when no longer needed
Description: Students implement proper cleanup for body detection by stopping the detection when it's no longer needed using the stop block. They understand that detection consumes resources and should be stopped when: switching tasks, pausing the application, or when detection is complete. They implement detection lifecycle: start → use → stop, preventing resource leaks and allowing camera use by other features.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.01.03: Read body keypoint positions from the table





ID: T22.G6.09.02.01
Topic: T22 – AI Perception
Skill: Detect arms up pose using y-coordinate comparison
Description: Students implement "arms up" pose detection by comparing y-coordinates: both wrists above both shoulders (wrist_y < shoulder_y, since y increases downward in screen coordinates). They read keypoint positions from the body detection table, compare values, and trigger actions when the pose is detected. They understand coordinate systems and why "above" means smaller y values.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.01.04: Stop body detection when no longer needed





ID: T22.G6.09.02.02
Topic: T22 – AI Perception
Skill: Detect squat pose using knee and hip positions
Description: Students implement squat detection by checking if knees are below hips (knee_y > hip_y). They may also check that knees are bent by comparing knee position to ankle position. They understand that different squat depths can be detected using different thresholds and that full squat detection may require checking multiple body parts for accurate recognition.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.02.01: Detect arms up pose using y-coordinate comparison





ID: T22.G6.09.02.03
Topic: T22 – AI Perception
Skill: Detect jump pose using vertical velocity or position
Description: Students implement jump detection by tracking vertical movement of body keypoints over time. They store previous hip or ankle y-positions and compare to current positions to detect upward movement. They may also detect "in air" state by checking if ankles are significantly above their resting position. They understand that detecting jumps requires temporal analysis (comparing across frames) rather than single-frame analysis.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.02.02: Detect squat pose using knee and hip positions





ID: T22.G6.09.02.04
Topic: T22 – AI Perception
Skill: Calculate limb angles for pose analysis
Description: Students calculate angles between body landmarks to analyze poses more precisely. They use math blocks to compute angle from three points (e.g., shoulder-elbow-wrist angle for arm bend). They implement angle-based pose detection: elbow bend angle < 90° = bent arm, > 160° = straight arm. They learn vector math basics and understand that angles provide more precise pose analysis than simple position comparisons.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.02.03: Detect jump pose using vertical velocity or position




ID: T22.G6.09.02.05
Topic: T22 – AI Perception
Skill: Track movement velocity for dynamic pose analysis
Description: Students calculate movement velocity by comparing body keypoint positions across frames. They store previous frame positions in variables, calculate displacement (current position - previous position), and derive velocity (displacement / time). They implement velocity-based detection: fast arm swing, walking speed estimation, punch/kick detection. They understand that velocity detection enables recognizing dynamic actions (moving fast) not just static poses (standing still). They apply smoothing to velocity calculations to reduce noise from jittery detection data.

Dependencies:
* T22.G6.09.02.04: Calculate limb angles for pose analysis
* T22.G6.06.01: Apply moving average to smooth noisy sensor data
* T09.G5.01: Use multiple variables together in a single expression




ID: T22.G6.09.03
Topic: T22 – AI Perception
Skill: Use 3D pose detection for depth-aware body tracking
Description: Students use `run 3D pose detection debug [yes v] table [TABLENAME v]` to detect body landmarks with depth information (x, y, z coordinates). They compare 2D vs 3D pose detection, understanding that 3D provides distance from camera. They visualize the z-coordinate to understand depth perception and build applications that measure 3D movements (e.g., squat depth, forward reach).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.09.02.04: Calculate limb angles for pose analysis





ID: T22.G6.10.01
Topic: T22 – AI Perception
Skill: Set up face detection and view detected faces
Description: Students use `run face detection debug [yes v] and write into table [TABLENAME v]` to turn on the front camera and detect faces. They observe the debug mode (draws bounding boxes around faces) and explore the result table structure, which contains face positions and facial landmarks. Note: CreatiCode face detection provides face position, tilt angle, and 6 facial landmarks (eyes, nose, mouth, ears) ONLY. It does NOT detect expressions, emotions, age, gender, or accessories.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G5.05.03: Trace perception API workflow patterns





ID: T22.G6.10.02.01
Topic: T22 – AI Perception
Skill: Map face detection table structure
Description: Students map the face detection table structure with 13 rows per detected face: 1 row for tilt angle, plus 12 rows for 6 facial landmark positions (left_eye, right_eye, nose, mouth, left_ear, right_ear, each with x and y coordinates). Table columns are: ID, variable, value. They practice parsing the table: read ID column to differentiate between multiple faces, read variable column to identify which landmark, and read value column for the coordinate. They identify how lighting affects detection accuracy. Note: This is ALL the data CreatiCode face detection provides - no expressions, emotions, or demographics.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.10.01: Set up face detection and view detected faces





ID: T22.G6.10.02.02
Topic: T22 – AI Perception
Skill: Read face position and tilt angle from table
Description: Students read face tilt angle and landmark positions from the face detection table. They extract face center coordinates (average of eye positions) and tilt angle to understand face orientation. They display these values using variable monitors and understand that tilt angle indicates head rotation (left/right head tilt).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.10.02.01: Map face detection table structure





ID: T22.G6.10.02.03
Topic: T22 – AI Perception
Skill: Move a sprite to follow detected face
Description: Students implement face-following behavior by reading face center coordinates from the face detection table and moving sprites to match. They handle edge cases like multiple faces detected simultaneously (choose first face) and faces partially out of frame (clamp to screen bounds). They implement error handling for "no face detected" scenarios. They note that face data can be noisy and may need smoothing for smooth sprite movement.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.10.02.02: Read face position and tilt angle from table




ID: T22.G6.10.03
Topic: T22 – AI Perception
Skill: Track and manage multiple detected faces
Description: Students implement multi-face tracking when more than one face is visible. They parse the face detection table structure (13 rows per face), identify faces by ID column, and iterate through to get all face positions. They implement applications that: count faces on screen, assign different sprites to different faces, determine which face is largest (closest to camera), or track a specific face across frames. They handle faces entering/leaving the frame and implement logic to determine "primary" face for interactions.

Dependencies:
* T22.G6.10.02.03: Move a sprite to follow detected face
* T10.G5.04: Read a cell value from a table




ID: T22.G6.11
Topic: T22 – AI Perception
Skill: Use NLP sentence analysis to extract parts of speech
Description: Students use `analyze sentence [SENTENCE] and write into table [TABLENAME v]` to analyze sentence structure and extract parts of speech (nouns, verbs, adjectives, etc.) from recognized speech or text input. They implement applications that parse voice commands to identify action words (verbs) and objects (nouns): "move the robot forward" → action: move, object: robot, direction: forward. They build more flexible command recognition that handles variations in phrasing ("go forward" vs "move ahead" vs "drive forward").

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.01.02: Select speech recognition language and observe accuracy differences





ID: T22.G6.12
Topic: T22 – AI Perception
Skill: Compare Azure vs OpenAI Whisper speech recognition performance
Description: Students run comparative tests between the default speech recognition (Azure) and OpenAI Whisper API. They test both systems with the same audio samples in different conditions: clear speech, accented speech, noisy environment, technical vocabulary, and multiple languages. They document accuracy differences, latency (response time), cost implications, and reliability. They create a decision matrix for choosing the appropriate speech recognition engine based on application requirements.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T14.G5.01: Coordinate scene changes with broadcasts
* T22.G6.03.02: Use OpenAI Whisper for advanced speech transcription




ID: T22.G6.13
Topic: T22 – AI Perception
Skill: Use camera widget for video capture and snapshots
Description: Students use the `show [front/back v] camera in [normal v] x () y () width () height () as [name]` widget block to display live camera feed in their projects. They learn to capture snapshots using `save picture from camera [name v] as costume [costume_name]` to save camera frames as costumes for processing. They implement projects that capture photos on button press, create photo booth effects, or save frames for later analysis. They understand camera positioning, sizing, and the difference between front/back cameras.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T15.G6.01: Attach a button to a sprite and respond to clicks




ID: T22.G6.14
Topic: T22 – AI Perception
Skill: Use webcam as 3D scene background
Description: Students use the `turn [on/off v] webcam background [default/Front/Back v] in [Normal v] mode` block to display live camera feed as the background of a 3D scene, enabling augmented reality (AR) effects. They position 3D sprites over the live camera feed to create interactive AR experiences where virtual objects appear in the real world. They learn to flip the camera (Normal vs Left-Right Flipped) for mirror effects and combine with body/hand detection for AR interactions.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T09.G5.01: Use multiple variables together in a single expression
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T22.G6.04.05: Drive UI elements with live hand detection




ID: T22.G6.15
Topic: T22 – AI Perception
Skill: Use AR face camera for face-tracked 3D effects
Description: Students use the `switch to AR face camera show marker [Yes/No v] scale () emulation mode [Yes/No v] data table [table v] with mesh of face [Yes v] eyes [Yes v] mouth [Yes v] lips [Yes v]` block to track faces and overlay 3D mesh effects. They create face filter applications with virtual masks, glasses, or hats that follow face movement. They read face tracking data from the output table (position, orientation) to control 3D objects. They understand AR face tracking differs from basic face detection by providing real-time 3D face mesh data.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Use a simple if in a script
* T10.G5.04: Read a cell value from a table
* T11.G5.01: Decompose a problem into logical custom block boundaries
* T22.G6.10.02.03: Move a sprite to follow detected face




ID: T22.G6.16
Topic: T22 – AI Perception
Skill: Use video motion sensing for simple movement detection
Description: Students use Scratch's built-in video sensing extension for basic motion detection. They access `video motion on [sprite/stage]` and `video direction on [sprite/stage]` reporters to detect movement without complex body/hand detection. They implement motion-triggered events: "when video motion > 30" to start actions when user moves. They compare video sensing (simple, fast, detects any movement) vs body detection (complex, slower, identifies specific body parts). They build applications where simple motion detection is sufficient: motion-activated animations, movement-based games, presence detection.

Dependencies:
* T22.G5.05.03: Trace perception API workflow patterns
* T06.G5.01: Identify standard event patterns in a small game




ID: T22.G6.17
Topic: T22 – AI Perception
Skill: Detect sound levels for audio-reactive applications
Description: Students use the `loudness` sensing block to detect microphone audio levels (0-100 scale) without speech recognition. They implement sound-reactive applications: visualizers that respond to music/clapping, sound level meters, noise threshold triggers. They distinguish between sound level detection (how loud) vs speech recognition (what words). They implement threshold-based triggers: "when loudness > 50, sprite jumps." They handle microphone sensitivity calibration and ambient noise baselines.

Dependencies:
* T22.G5.05.01: Identify what data different detection types provide
* T09.G5.01: Use multiple variables together in a single expression




ID: T22.G6.18
Topic: T22 – AI Perception
Skill: Transform detection coordinates between screen and stage systems
Description: Students convert between different coordinate systems used by perception APIs. Detection tables report positions in screen coordinates (0,0 at top-left, y increases downward), but CreatiCode stage uses center coordinates (0,0 at center, y increases upward). They implement coordinate transformation formulas: `stage_x = screen_x - 240` and `stage_y = 180 - screen_y`. They apply transformations to position sprites accurately based on detected hand/body/face positions. They debug positioning errors caused by coordinate system confusion.

Dependencies:
* T22.G6.04.05: Drive UI elements with live hand detection
* T22.G6.10.02.03: Move a sprite to follow detected face
* T09.G5.01: Use multiple variables together in a single expression


---

## GRADE 7 SKILLS




ID: T22.G7.00
Topic: T22 – AI Perception
Skill: Choose appropriate input modality for application context
Description: Students analyze application scenarios (noisy cafe, hands-free cooking, private space, public kiosk) and select the best input modality: voice-only, gesture-only, pose-only, or combinations. They consider accuracy (noisy environment reduces voice accuracy), user effort (hands-free favors voice/pose), privacy (voice reveals more than gesture), and accessibility. They create a decision matrix comparing modalities.

Dependencies:
* T22.G6.03.01: Build a two-way voice chatbot loop
* T22.G6.04.05: Drive UI elements with live hand detection
* T22.G6.09.02.04: Calculate limb angles for pose analysis





ID: T22.G7.01
Topic: T22 – AI Perception
Skill: Define a reusable gesture dictionary
Description: Students capture hand detection output (finger curl, dir, x/y positions) into a table, label each pattern ("thumbs up," "peace sign," "stop," "pointing"), and create custom reporter blocks that return the detected gesture name. They implement at least four gestures plus a "none detected" state, using T11 custom block patterns.

Dependencies:
* T10.G5.04: Read a cell value from a table
* T11.G5.03: Define a custom block with one parameter
* T22.G6.04.05: Implement advanced gesture recognition using curl and direction
* T22.G6.04.06: Drive UI elements with live hand detection





ID: T22.G7.01.02
Topic: T22 – AI Perception
Skill: Combine inputs with simple OR logic
Description: Students build interactions where users can choose different input methods: "say 'next' OR perform swipe gesture" to advance, "press space bar OR raise hand" to start game. They use OR conditions to check multiple inputs and trigger the same action. They learn when OR logic is appropriate (giving users choices) vs. when specific input is required. Simpler than AND multimodal confirmation (G7.02).

Dependencies:
* T22.G7.01: Define a reusable gesture dictionary
* T22.G6.03.01: Build a two-way voice chatbot loop





ID: T22.G7.02
Topic: T22 – AI Perception
Skill: Require multimodal confirmation (voice + gesture)
Description: Students design safety-critical interactions (purchase confirmation, delete save file, launch simulation) that require matching voice command AND specific gesture to proceed. They manage sequence state (which input came first?), implement timeouts (confirmation expires after 5 seconds), and provide clear feedback on partial completion ("voice confirmed, waiting for gesture").

Dependencies:
* T09.G5.05: Use the accumulator pattern to compute running totals
* T22.G7.01: Define a reusable gesture dictionary
* T22.G6.03.01: Build a two-way voice chatbot loop
* T22.G6.04.05: Drive UI elements with live hand detection





ID: T22.G7.03.01
Topic: T22 – AI Perception
Skill: Build a pose sequence detector for fitness coaching
Description: Students implement a multi-pose sequence detector: recognize a specific sequence of poses (squat → jump → arms up) performed in order. They track state progression (which pose in sequence is current), detect transitions between poses, and reward successful completion of the full sequence. They understand state machines and sequential logic for pose-based applications.

Dependencies:
* T22.G6.09.03: Use 3D pose detection for depth-aware body tracking
* T22.G6.06.01: Apply moving average to smooth noisy sensor data





ID: T22.G7.03.02
Topic: T22 – AI Perception
Skill: Implement pose scoring with angle thresholds
Description: Students create scoring systems for pose accuracy: define target angles for each body part (elbow should be 90°, knee should be 120°), measure actual angles from detected keypoints, calculate error (difference from target), and award points based on accuracy (within 10° = full points, 10-20° = partial points, >20° = no points). They display total score and per-pose scores.

Dependencies:
* T22.G7.03.01: Build a pose sequence detector for fitness coaching
* T22.G6.09.02.04: Calculate limb angles for pose analysis





ID: T22.G7.03.03
Topic: T22 – AI Perception
Skill: Provide real-time coaching feedback based on pose errors
Description: Students implement coaching feedback system: analyze which body parts fail threshold checks, generate specific feedback text ("raise elbows higher," "squat deeper," "keep back straight"), display feedback in real-time as user performs poses, and use color coding (green = correct, yellow = close, red = needs improvement). They prioritize feedback (show most critical error first) when multiple corrections needed.

Dependencies:
* T22.G7.03.02: Implement pose scoring with angle thresholds





ID: T22.G7.04
Topic: T22 – AI Perception
Skill: Monitor detection accuracy across different users
Description: Students design an accessibility log where each speech/gesture event is recorded with user metadata (age range, device type, lighting condition, language) plus outcome (success/failure). They calculate accuracy rates per group (success rate = correct detections / total attempts) and identify significant disparities (>20% difference between groups), such as low-light users having 40% success vs 90% in good light. They propose adjustments based on data.

Dependencies:
* T22.G6.06.01: Apply moving average to smooth noisy sensor data





ID: T22.G7.05
Topic: T22 – AI Perception
Skill: Implement fairness safeguards for perception systems
Description: Students implement measures to improve fairness: multiple attempts for failed recognition (3 tries before error), alternative input methods when sensors struggle (switch from voice to text input if speech fails), user feedback collection for system improvement, and adaptive thresholds that adjust to user patterns.

Dependencies:
* T22.G6.08: Add consent and privacy controls for sensor use





ID: T22.G7.06
Topic: T22 – AI Perception
Skill: Build a calibration wizard for sensors
Description: Students create a multi-step UI wizard (using T16 UI patterns) that guides users through sensor setup: microphone volume check (speak and see level), lighting test (show brightness meter), gesture framing (show silhouette guide). Each step runs a quick sensor test, displays current readings, and offers fixes ("move closer," "increase room light," "adjust camera angle").

Dependencies:
* T22.G6.06.01: Apply moving average to smooth noisy sensor data





ID: T22.G7.07
Topic: T22 – AI Perception
Skill: Optimize perception system performance
Description: Students identify and fix perception performance issues: reduce detection frame rate (process every 3rd frame instead of every frame), limit table size (clear old data), disable debug visualization in production, use efficient data structures (variables for single values instead of searching tables). They measure and compare performance before/after optimization using timer blocks. They understand trade-offs between accuracy and speed.

Dependencies:
* T22.G7.06: Build a calibration wizard for sensors
* T22.G6.07: Choose continuous vs. event-driven detection patterns





ID: T22.G7.08
Topic: T22 – AI Perception
Skill: Compare different AI detection algorithms
Description: Students compare different AI perception algorithms available in CreatiCode: hand detection vs body pose detection for gesture recognition, 2D vs 3D pose detection for movement tracking, Azure vs Whisper for speech recognition. They evaluate trade-offs: accuracy vs speed, resource usage vs reliability, cost vs performance. They document decision criteria and create guidelines for algorithm selection based on application requirements (real-time performance, accuracy needs, device capabilities).

Dependencies:
* T22.G6.09.03: Use 3D pose detection for depth-aware body tracking
* T22.G6.12: Compare Azure vs OpenAI Whisper speech recognition performance





ID: T22.G7.09
Topic: T22 – AI Perception
Skill: Build error recovery and fallback systems
Description: Students design robust perception systems that gracefully handle sensor failures. They implement fallback hierarchies: primary sensor fails → switch to backup sensor → if both fail → switch to manual input. They create error detection systems that identify sensor malfunctions (frozen data, impossible values, timeout), automatic recovery attempts (restart detection, recalibrate), and user notifications with actionable guidance. They test recovery systems by simulating failures.

Dependencies:
* T22.G6.06.04: Create watchdog timers to detect and recover from sensor dropouts
* T22.G7.01.02: Combine inputs with simple OR logic





ID: T22.G7.10
Topic: T22 – AI Perception
Skill: Debug perception system using systematic logging
Description: Students implement systematic debugging for perception systems: log sensor readings at each step (input → processing → output), create timestamped event logs showing detection flow, identify where failures occur using log analysis, and trace incorrect outputs back to root causes (bad sensor data, wrong thresholds, logic errors). They build a debug dashboard showing live sensor values and detection results.

Dependencies:
* T22.G7.07: Optimize perception system performance
* T22.G6.06.01: Apply moving average to smooth noisy sensor data




ID: T22.G7.11
Topic: T22 – AI Perception
Skill: Design perception pipeline with clear stage separation
Description: Students design modular perception pipelines with clearly separated stages: (1) **Input stage:** Camera/mic setup, configuration. (2) **Detection stage:** Run AI detection blocks, get raw data. (3) **Processing stage:** Smooth, validate, transform data. (4) **Interpretation stage:** Classify gestures, recognize commands. (5) **Action stage:** Trigger application responses. They implement each stage as separate custom blocks, document data flow between stages, and create diagrams showing the pipeline. This modular design enables easier debugging, testing, and reuse.

Dependencies:
* T22.G7.10: Debug perception system using systematic logging
* T22.G7.01: Define a reusable gesture dictionary
* T11.G5.03: Define a custom block with one parameter




ID: T22.G7.12
Topic: T22 – AI Perception
Skill: Trace multimodal data flow through system
Description: Students trace how data flows when multiple perception modalities are active simultaneously (hand + voice, face + body). They identify potential conflicts: camera resource sharing, processing bottlenecks, conflicting actions (voice says "stop" while gesture says "go"). They create timing diagrams showing when each sensor provides data, document how data merges at decision points, and implement priority rules for handling conflicts. They understand that multimodal systems add complexity but improve robustness.

Dependencies:
* T22.G7.02: Require multimodal confirmation (voice + gesture)
* T22.G7.11: Design perception pipeline with clear stage separation




ID: T22.G7.13
Topic: T22 – AI Perception
Skill: Build real-time AR interactions with body tracking
Description: Students combine body detection with AR webcam background to create interactive augmented reality experiences. They position 3D objects relative to detected body parts (hat on head, sword in hand, wings on shoulders), update positions in real-time as user moves, and handle occlusion (when body part moves behind object). They implement AR games: catch virtual objects with hands, dodge virtual obstacles, interact with characters that respond to body position. They understand latency challenges and implement prediction/smoothing for responsive AR.

Dependencies:
* T22.G6.14: Use webcam as 3D scene background
* T22.G6.09.02.05: Track movement velocity for dynamic pose analysis
* T22.G6.18: Transform detection coordinates between screen and stage systems




ID: T22.G7.14
Topic: T22 – AI Perception
Skill: Implement perception state machine for complex interactions
Description: Students design state machines to manage complex perception-driven interactions with multiple states and transitions. **States:** Idle (waiting for input), Listening (speech active), Detecting (gesture recognition), Processing (AI computing), Responding (output playing). **Transitions:** Define conditions for state changes (speech detected → Processing, timeout → Idle). They implement state machines using variables to track current state, conditional logic for transitions, and actions triggered on state entry/exit. They visualize state machine diagrams and trace execution paths through different scenarios.

Dependencies:
* T22.G7.11: Design perception pipeline with clear stage separation
* T22.G7.01.02: Combine inputs with simple OR logic
* T08.G5.02: Use a simple if in a script




ID: T22.G7.15
Topic: T22 – AI Perception
Skill: Design perception systems for cross-platform considerations
Description: Students design perception applications that work across different devices and browsers. They identify platform differences: camera access permissions, microphone availability, processing power limitations, screen sizes affecting detection area. They implement feature detection: check if camera available before starting detection, provide fallback input methods for devices without cameras. They test on different browsers (Chrome, Firefox, Safari) and document compatibility issues. They design graceful degradation: full features on capable devices, basic functionality on limited devices.

Dependencies:
* T22.G7.09: Build error recovery and fallback systems
* T22.G7.07: Optimize perception system performance
* T05.G5.01: Write clear user needs and requirements for a small app




ID: T22.G7.16
Topic: T22 – AI Perception
Skill: Analyze perception algorithm complexity and trade-offs
Description: Students analyze the computational complexity and trade-offs of different perception approaches. They compare: (1) **Simple threshold rules** (if curl < 90 → fist): O(1) constant time, fast, but limited gestures. (2) **KNN classification** (find K nearest neighbors): O(n) where n = training examples, slower with more data but handles complex patterns. (3) **Neural network inference**: O(layers × neurons), fixed time but requires trained model. They trace through each approach with example inputs, count comparisons/operations, and predict relative speeds. They create a decision guide: use thresholds for simple real-time apps, KNN for medium complexity with limited classes, neural networks for complex recognition. **Key learning:** Algorithm choice affects both accuracy AND performance—there's no universal "best" approach.

Dependencies:
* T22.G7.07: Optimize perception system performance
* T22.G5.11: Compare algorithm efficiency for different detection approaches
* T22.G7.01: Define a reusable gesture dictionary


---

## GRADE 8 SKILLS




ID: T22.G8.00
Topic: T22 – AI Perception
Skill: Apply supervised learning for perception classification
Description: Students apply the supervised learning workflow for gesture/pose classification: (1) collect labeled examples (record hand positions for "thumbs up," "peace sign," etc.), (2) train a classifier using the KNN blocks (`create KNN number classifier from table [training_data v] K [3] named [classifier1]`), (3) evaluate on test data. They understand that more training examples improve accuracy and that K value affects sensitivity to noise.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T22.G7.01: Define a reusable gesture dictionary
* T02.G6.01: Use the pseudocode generation block
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.00.02
Topic: T22 – AI Perception
Skill: Practice KNN classification with simple numeric data
Description: Students practice KNN with a simple dataset before gesture classification: given a table of measurements (height, weight) and labels (category), they use `create KNN number classifier from table [training v] K [3] named [simple]` to train a classifier, then test it with new data using `predict for table [test v] with classifier [simple] show neighbors [yes v]`. They experiment with K values (1, 3, 5) and observe how it affects predictions. They understand KNN finds "similar" examples.

Dependencies:
* T22.G8.00: Apply supervised learning for perception classification
* T10.G6.02: Sort a table by a column
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.00.03
Topic: T22 – AI Perception
Skill: Split collected data into training and test sets
Description: Students learn the importance of separating data into training and test sets to evaluate classifier performance accurately. They implement data splitting: collect 100 samples, use 70 for training and 30 for testing (70/30 split). They understand that testing on training data gives falsely optimistic results and that test data must represent real-world usage. They implement random sampling to ensure balanced splits and avoid bias (equal representation of each gesture class in both sets).

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.00.02: Practice KNN classification with simple numeric data
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T13.G6.01.01: Track game state with variable





ID: T22.G8.01
Topic: T22 – AI Perception
Skill: Offer interchangeable input modes with accessibility rules
Description: Students build a settings panel where users choose "voice only," "gesture only," or "hybrid" control mode. Each mode updates UI instructions, disables irrelevant widgets, and logs active mode for analytics. They implement auto-switching: if active sensor fails (e.g., hand leaves frame), automatically switch to voice mode and notify user.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T22.G7.02: Require multimodal confirmation (voice + gesture)
* T22.G6.03.01: Build a two-way voice chatbot loop
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.02: Apply operator precedence rules (PEMDAS) in expressions
* T10.G6.01: Sort a table by a column





ID: T22.G8.02.01
Topic: T22 – AI Perception
Skill: Create data collection UI for gesture samples
Description: Students build a data collection interface for training custom gesture classifiers. They create UI widgets (buttons for each gesture class, counter showing samples collected, visual feedback during recording) and implement the collection workflow: user selects gesture type → performs gesture → system captures hand detection data (curl, dir, x/y for all fingers) → stores in training table with label. They collect at least 20 samples per gesture class and implement quality checks (reject samples with no hand detected).

Dependencies:
* T15.G6.01: Attach a button to a sprite and respond to clicks
* T10.G6.02: Sort a table by a column
* T22.G7.01: Define a reusable gesture dictionary
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.02.02
Topic: T22 – AI Perception
Skill: Train KNN classifier with collected gesture data
Description: Students use collected gesture data to train a KNN classifier. They structure the training table correctly: each row is one sample, columns contain finger curl/dir values and x/y positions (features), final column contains gesture label (class). They use `create KNN number classifier from table [training_data v] K [3] named [gestureClassifier]` to create the classifier and experiment with different K values. They understand the training process: KNN stores all training examples and uses them for comparison during prediction.

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.00: Apply supervised learning for perception classification
* T22.G8.02.01: Create data collection UI for gesture samples
* T02.G6.01: Use the pseudocode generation block
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals in physics simulations





ID: T22.G8.02.03
Topic: T22 – AI Perception
Skill: Deploy trained classifier to recognize live gestures
Description: Students deploy their trained KNN classifier to recognize gestures in real-time. They implement the prediction workflow: capture live hand detection data → format as test table row → use `predict for table [live_data v] with classifier [gestureClassifier] show neighbors [yes v]` → read predicted class → trigger action based on gesture. They handle prediction confidence (some predictions are uncertain) and implement minimum confidence thresholds before accepting predictions. They test with gestures not in training data to see how classifier handles unknowns.

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.02.02: Train KNN classifier with collected gesture data
* T03.G6.01: Propose a module hierarchy for a medium project
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds





ID: T22.G8.02.04
Topic: T22 – AI Perception
Skill: Evaluate classifier performance using confusion matrices
Description: Students systematically evaluate KNN classifier performance by creating confusion matrices. They test the classifier with labeled test data, record predicted vs actual classes in a matrix table, and calculate metrics: accuracy (correct predictions / total predictions), per-class precision (true positives / predicted positives), and per-class recall (true positives / actual positives). They identify which gesture pairs get confused most often (e.g., "peace sign" confused with "pointing") and use this analysis to improve training data or feature selection.

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.02.03: Deploy trained classifier to recognize live gestures
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column





ID: T22.G8.03
Topic: T22 – AI Perception
Skill: Fuse voice, pose, and UI widgets into a cooperative simulation
Description: Students build a multi-user scenario (space mission, emergency response, surgical simulation) where different team members use different modalities simultaneously: one issues voice commands, another performs gestures to manipulate tools, a third confirms via widget buttons. The system coordinates timing, prevents conflicts (can't launch if gesture not confirmed), and displays live event log.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G7.02: Require multimodal confirmation (voice + gesture)
* T22.G7.03.03: Provide real-time coaching feedback based on pose errors
* T22.G6.03.01: Build a two-way voice chatbot loop
* T02.G6.01: Use the pseudocode generation block
* T04.G6.01: Group snippets by underlying algorithm pattern
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design





ID: T22.G8.04
Topic: T22 – AI Perception
Skill: Publish a privacy and deployment plan for perception apps
Description: Students research real voice/vision privacy concerns (storage duration, consent requirements, data retention policies, third-party access) and write a comprehensive policy for their app. They document: what data is captured, how long it's stored, who can access it, how to request deletion, when to use offline modes, and fallback behaviors. They reference their own logging/calibration/fairness features and align with T05 design thinking principles.

Dependencies:
* T04.G6.01: Group snippets by underlying algorithm pattern
* T08.G6.01: Use conditionals to control simulation steps
* T22.G7.05: Implement fairness safeguards for perception systems
* T22.G6.08: Add consent and privacy controls for sensor use
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T12.G6.01: Trace complex code with multiple variables





ID: T22.G8.04.01
Topic: T22 – AI Perception
Skill: Experiment with different K values in KNN classification
Description: Students systematically experiment with K parameter in KNN classification. They train classifiers with K=1, K=3, K=5, K=7, K=9 using the same training data and evaluate each on test data. They observe patterns: K=1 is sensitive to noise and outliers (overfitting), large K over-smooths decision boundaries (underfitting), odd K values avoid ties in voting. They plot accuracy vs K to find optimal value and understand that optimal K depends on dataset characteristics (size, noise level, class overlap).

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.02.04: Evaluate classifier performance using confusion matrices
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas





ID: T22.G8.05
Topic: T22 – AI Perception
Skill: Evaluate societal impacts of perception AI systems
Description: Students analyze real-world examples of AI perception systems (facial recognition in law enforcement, voice assistants in homes, gesture controls in healthcare) and evaluate benefits and risks for different communities. They propose ethical guidelines for responsible deployment: when to use perception AI, when not to, required safeguards, transparency requirements, and community oversight mechanisms.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T09.G6.01: Model real-world quantities using variables and formulas
* T22.G7.04: Monitor detection accuracy across different users
* T22.G7.05: Implement fairness safeguards for perception systems
* T02.G6.01: Use the pseudocode generation block
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T10.G6.01: Sort a table by a column





ID: T22.G8.05.01
Topic: T22 – AI Perception
Skill: Apply feature engineering to improve gesture recognition accuracy
Description: Students improve gesture classifier performance through feature engineering. They experiment with different feature sets: raw finger curl/dir values, derived features (finger spread = max curl - min curl, hand openness = average curl), normalized features (scale x/y to 0-1 range), and feature combinations. They compare classifier accuracy with different feature sets and understand that good features highlight differences between classes. They learn to identify and remove irrelevant or redundant features that add noise without improving accuracy.

Dependencies:
* T10.G6.02: Sort a table by a column
* T22.G8.02.04: Evaluate classifier performance using confusion matrices
* T02.G6.01: Use the pseudocode generation block
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals in physics simulations





ID: T22.G8.06
Topic: T22 – AI Perception
Skill: Explain neural networks and how they differ from KNN
Description: Students learn the fundamental differences between KNN and neural networks for classification. They understand that KNN stores training examples and compares new data to stored examples (instance-based learning), while neural networks learn patterns and create a model (parametric learning). They explore trade-offs: KNN is simple but slow for large datasets and requires storing all training data; neural networks are complex but fast at prediction time and can learn complex patterns. They compare when to use each approach.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.04.01: Experiment with different K values in KNN classification
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.07
Topic: T22 – AI Perception
Skill: Practice using pre-trained neural network models
Description: Students use pre-trained neural network models in CreatiCode for perception tasks (pose estimation, speech recognition). They understand that pre-trained models have been trained on large datasets and can recognize common patterns without custom training. They load pre-trained models (the built-in detection blocks use neural networks), feed input data, interpret outputs, and compare performance to custom KNN classifiers. They learn when pre-trained models are appropriate (common tasks, limited training data) vs when custom training is needed (specialized gestures, domain-specific recognition).

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.06: Explain neural networks and how they differ from KNN
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.08
Topic: T22 – AI Perception
Skill: Build a custom neural network for gesture classification
Description: Students design and train a simple neural network for gesture classification using CreatiCode's neural network blocks: `create_nn_model`, `addlayertomodel`, `compile_model`, `train_model`, `predict_by_model`. They specify network architecture (input layer size = number of features, hidden layer size, output layer size = number of gesture classes), configure training parameters (learning rate, epochs), train the network with collected gesture data, and deploy for real-time recognition. They compare neural network performance to their KNN classifier and understand that neural networks can learn more complex patterns but require more training data.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.07: Practice using pre-trained neural network models
* T22.G8.02.02: Train KNN classifier with collected gesture data
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.09
Topic: T22 – AI Perception
Skill: Save and load trained neural network models
Description: Students learn to persist trained neural network models for reuse using `save_model` and `load_model` blocks. They train a model once and reuse it across sessions, share models with other users, create model libraries for different tasks, and version models (save model_v1, model_v2 as improvements are made). They understand the benefits: avoid retraining (save time), ensure consistency (same model across deployments), and enable offline usage (load model without requiring training data). They implement model versioning and testing workflows.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.08: Build a custom neural network for gesture classification
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements





ID: T22.G8.10
Topic: T22 – AI Perception
Skill: Use semantic search to match voice commands to intents
Description: Students implement semantic search for flexible voice command recognition. Instead of exact phrase matching ("open map" only), they use semantic similarity to match variations ("show the map," "display map," "I need a map") to the same intent. They use NLP intent classification (from T23.G6.11) to handle paraphrasing, synonyms, and natural language variations. They build a voice command system that understands user intent rather than requiring exact phrasing.

Dependencies:
* T21.G7.01: Compare completion vs chat models and choose the appropriate one
* T22.G6.11: Use NLP sentence analysis to extract parts of speech
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern
* T10.G6.01: Sort a table by a column





ID: T22.G8.11
Topic: T22 – AI Perception
Skill: Implement AI-powered content moderation in chat applications
Description: Students add content moderation to voice-based chat applications using AI moderation APIs. They implement filters that detect and block inappropriate content: profanity, hate speech, personal information, and unsafe topics. They handle moderation results: reject unsafe messages, provide user feedback ("message blocked: inappropriate content"), log moderation events, and implement escalation procedures for repeated violations. They understand the importance of moderation for safe user experiences and explore limitations (false positives, cultural context).

Dependencies:
* T21.G6.01: Trace how a chatbot script processes each turn
* T22.G6.03.01: Build a two-way voice chatbot loop
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T06.G6.01: Trace event execution paths in a multi‑event program
* T08.G6.01: Use conditionals in physics simulations





ID: T22.G8.12.01
Topic: T22 – AI Perception
Skill: Define ML problem and success metrics
Description: Students define a clear machine learning problem statement for their perception application: what should the system detect/classify, what constitutes success, and how will performance be measured. They specify success metrics: target accuracy (e.g., >90% gesture recognition), acceptable latency (e.g., <500ms response time), and fairness criteria (similar accuracy across user groups). They document assumptions, constraints, and requirements before beginning data collection or model development.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.09: Save and load trained neural network models
* T22.G8.02.04: Evaluate classifier performance using confusion matrices
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column





ID: T22.G8.12.02
Topic: T22 – AI Perception
Skill: Plan data collection strategy with quality checks
Description: Students design a comprehensive data collection strategy: determine sample size per class (minimum 50 samples), ensure diversity (different users, lighting conditions, backgrounds), implement quality checks (reject blurry images, incomplete data), and document collection procedures. They create data collection protocols that other team members can follow, ensuring consistent and high-quality training data. They understand that data quality directly impacts model performance.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.12.01: Define ML problem and success metrics
* T22.G8.02.01: Create data collection UI for gesture samples
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column





ID: T22.G8.12.03
Topic: T22 – AI Perception
Skill: Document ML workflow and deployment plan
Description: Students create comprehensive documentation for their complete ML workflow covering all stages: (1) problem definition and success metrics, (2) data collection strategy and quality assurance, (3) exploratory data analysis and feature engineering, (4) model selection and training, (5) evaluation and iteration, (6) deployment and monitoring, (7) maintenance and updates. They document testing procedures, performance benchmarks, deployment considerations (resource requirements, fallback behaviors), and maintenance plans (when to retrain, how to handle drift). This capstone skill demonstrates the full ML lifecycle.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.12.02: Plan data collection strategy with quality checks
* T22.G8.04: Publish a privacy and deployment plan for perception apps
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column





ID: T22.G8.13
Topic: T22 – AI Perception
Skill: Design perception system for edge cases and adversarial inputs
Description: Students design robust perception systems that handle edge cases and adversarial inputs: unusual lighting (direct sunlight, strobe lights), occlusions (hand partially covered, face behind object), unusual angles (camera tilted, upside-down view), and adversarial inputs (intentionally confusing gestures, voice mimicry). They implement detection for edge cases, graceful degradation strategies, and user warnings. They test systems with intentionally challenging inputs and improve robustness.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.05: Evaluate societal impacts of perception AI systems
* T22.G7.09: Build error recovery and fallback systems
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column





ID: T22.G8.14
Topic: T22 – AI Perception
Skill: Build real-time perception dashboard for monitoring system health
Description: Students build a comprehensive real-time dashboard that monitors perception system health: display live sensor readings (frame rate, detection count, confidence scores), track performance metrics (latency, accuracy, error rates), visualize system state (active sensors, current mode, error conditions), and implement alerts for anomalies (sensor failure, accuracy drop, unusual patterns). They create diagnostic tools that help identify and fix problems quickly. Dashboard integrates with T22.G7.10 debugging tools.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G7.10: Debug perception system using systematic logging
* T22.G8.12.03: Document ML workflow and deployment plan
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column




ID: T22.G8.15
Topic: T22 – AI Perception
Skill: Design perception systems for accessibility and inclusion
Description: Students design perception systems that work well for diverse users. **Visual accessibility:** Voice commands as alternative to gestures for users with limited mobility; audio feedback for visually impaired users. **Auditory accessibility:** Gesture/visual cues as alternative to voice for deaf/hard-of-hearing users. **Motor accessibility:** Adjustable gesture sensitivity, alternative input methods, extended response times. They implement user preference settings, test with simulated accessibility scenarios, and document accessibility features. They understand that inclusive design benefits all users.

Dependencies:
* T08.G6.01: Use conditionals to control simulation steps
* T22.G8.01: Offer interchangeable input modes with accessibility rules
* T22.G8.04: Publish a privacy and deployment plan for perception apps
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design




ID: T22.G8.16
Topic: T22 – AI Perception
Skill: Evaluate real-world AI perception systems critically
Description: Students analyze real-world AI perception systems (smartphone face unlock, voice assistants, autonomous vehicle sensors, airport security scanners, retail checkout systems) and evaluate them critically. They examine: **Technical aspects:** What sensors are used? What are accuracy rates? What are failure modes? **Social aspects:** Who benefits? Who might be harmed? What biases exist? **Ethical aspects:** Is consent obtained? Is data protected? Are there accountability mechanisms? They propose improvements and discuss trade-offs between convenience, accuracy, privacy, and fairness. Capstone critical thinking skill.

Dependencies:
* T22.G8.05: Evaluate societal impacts of perception AI systems
* T22.G8.13: Design perception system for edge cases and adversarial inputs
* T22.G8.15: Design perception systems for accessibility and inclusion




ID: T22.G8.17
Topic: T22 – AI Perception
Skill: Apply transfer learning concepts to perception tasks
Description: Students learn how transfer learning enables building on pre-trained models rather than training from scratch. They understand that CreatiCode's detection blocks (hand, body, face) use pre-trained neural networks that learned from millions of examples. They compare: training from scratch (need huge datasets, long training time) vs transfer learning (use pre-trained models, add custom classification layer). They implement custom gesture recognition by using hand detection features (curl, direction, positions) as inputs to their own KNN or neural network classifier—this is a form of transfer learning where the pre-trained hand detector extracts features. They discuss when transfer learning works (similar domains) vs when it fails (very different data).

Dependencies:
* T22.G8.08: Build a custom neural network for gesture classification
* T22.G8.07: Practice using pre-trained neural network models
* T22.G8.02.02: Train KNN classifier with collected gesture data




ID: T22.G8.18
Topic: T22 – AI Perception
Skill: Interpret and explain ML model decisions
Description: Students learn to interpret why ML models make specific predictions—a key skill for debugging and building trust. For KNN: examine the K nearest neighbors returned by prediction and explain "this gesture was classified as thumbs up because the 3 nearest training examples were all thumbs up." For neural networks: analyze which input features most influence predictions by systematically varying inputs. They implement explanation displays: show nearest neighbors, highlight key features, display confidence levels. They understand that black-box models are harder to debug and trust than interpretable models.

Dependencies:
* T22.G8.04.01: Experiment with different K values in KNN classification
* T22.G8.02.04: Evaluate classifier performance using confusion matrices
* T22.G8.06: Explain neural networks and how they differ from KNN




ID: T22.G8.19
Topic: T22 – AI Perception
Skill: Build production monitoring for perception applications
Description: Students implement monitoring systems for deployed perception applications. They track key metrics over time: detection frame rate, recognition accuracy, error rates, latency. They implement alerting: notify when accuracy drops below threshold, when detection fails repeatedly, when latency spikes. They create dashboards displaying health metrics in real-time. They log all predictions with timestamps for later analysis. They implement A/B testing: compare two gesture recognition approaches on live data to determine which performs better. They understand that production systems need ongoing monitoring, not just initial testing.

Dependencies:
* T22.G8.14: Build real-time perception dashboard for monitoring system health
* T22.G8.12.03: Document ML workflow and deployment plan
* T10.G6.01: Sort a table by a column




ID: T22.G8.20
Topic: T22 – AI Perception
Skill: Design comprehensive testing strategy for perception systems
Description: Students design systematic testing strategies for perception applications before deployment. **Unit testing:** Test individual components (gesture detection, coordinate transformation, threshold logic). **Integration testing:** Test complete perception pipeline end-to-end. **Edge case testing:** Test with challenging inputs identified in G5 (poor lighting, partial occlusion, fast movement). **User testing:** Test with diverse users (different hand sizes, skin tones, accents for voice). **Regression testing:** Ensure changes don't break existing functionality. They create test plans documenting test cases, expected results, and pass/fail criteria. They implement automated testing where possible (run detection on recorded video, compare to expected outputs).

Dependencies:
* T22.G8.13: Design perception system for edge cases and adversarial inputs
* T22.G8.12.02: Plan data collection strategy with quality checks
* T22.G7.10: Debug perception system using systematic logging


# T23 - Generative AI Practices (Phase 8 Optimized - November 2025)
# PHASE 8 MAJOR IMPROVEMENTS:
# 1. NEW AI ACCOUNTABILITY SKILLS (K-2): Added T23.GK.06 (humans make final decisions), T23.G1.06 (when to ask person vs AI), T23.G2.07 (AI prediction consequences)
# 2. NEW COMPUTATIONAL THINKING INTEGRATION: Added T23.G3.05 (decompose tasks for AI), T23.G4.10 (abstract prompt patterns), T23.G5.14 (identify hallucinations)
# 3. NEW HUMAN-AI COLLABORATION SKILLS: T23.G6.15 (design AI guardrails), T23.G7.18 (evaluate AI tradeoffs), T23.G8.21 (human oversight systems)
# 4. ENHANCED DEBUGGING PROGRESSION: Clearer scaffolding G5→G6→G7 for AI system debugging with specific failure categories
# 5. NEW PRODUCTION AI SKILLS: T23.G8.22 (AI monitoring dashboards), T23.G8.23 (graceful AI degradation patterns)
# 6. IMPROVED VERB QUALITY: All skills now use IXL-style measurable verbs (Trace, Debug, Predict, Diagnose, Design, Build)
# 7. STRENGTHENED K-2 VISUAL SCENARIOS: All K-2 skills have explicit picture card descriptions with auto-grading notes
# 8. ADDED CROSS-DOMAIN AI APPLICATION: Skills connecting AI to real-world problem domains (accessibility, education, creativity)
# Previous Phase 7 changes preserved: AI ethics K-2 skills, prompt engineering progression, AI agent capstones
# Total: 145 skills (was 133, added 12 new skills for accountability, collaboration, and production AI)
# Skills by grade: GK=6, G1=6, G2=7, G3=6, G4=11, G5=20, G6=27, G7=24, G8=38

ID: T23.GK.01
Topic: T23 – Generative AI Practices
Skill: Identify AI as a computer helper
Description: **Student task:** Match picture cards of AI helpers to what they do. **Visual scenario:** Picture cards show: (A) voice assistant speaker saying "Playing music," (B) chatbot on screen answering "The capital is Paris," (C) robot arm in factory, (D) drawing tool creating a cat picture. Students drag each card to matching action labels: "talks and answers," "makes pictures," "moves things." **Learning focus:** AI is a special computer program that helps with tasks. _Implementation note: Drag-drop matching with large colorful cards; audio support reads labels. CSTA: EK-AI-01._

Dependencies:



ID: T23.GK.02
Topic: T23 – Generative AI Practices
Skill: Recognize AI-made vs human-made pictures
Description: **Student task:** Look at pairs of pictures and tap which one was made by AI. **Visual scenario:** Side-by-side comparisons: (1) child's crayon drawing of house vs AI-generated photorealistic house, (2) hand-drawn stick figure vs AI character with unusual finger count, (3) painted sunset with visible brushstrokes vs AI sunset with perfect gradients. **Clues to notice:** AI pictures may have strange details (extra fingers, warped text), perfect symmetry, or unnatural smoothness. _Implementation note: Binary choice per pair; teacher discussion guide included. CSTA: EK-AI-02._

Dependencies:
* T23.GK.01: Identify AI as a computer helper



ID: T23.GK.03
Topic: T23 – Generative AI Practices
Skill: Give simple instructions to an AI helper
Description: **Student task:** Practice giving clear one-sentence instructions to an AI, then predict what it will make. **Visual scenario:** Student sees prompt box and types/speaks "Draw a happy cat." They predict: "I think it will show a smiling cat." Then they see two AI results: (A) smiling orange cat, (B) confused blob. They match which instruction was clearer. **Learning focus:** Better instructions lead to better AI results. _Implementation note: Comparison activity with pre-generated AI outputs; no live AI needed. CSTA: EK-AI-03._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.GK.02: Recognize AI-made vs human-made pictures



ID: T23.GK.04
Topic: T23 – Generative AI Practices
Skill: Predict what AI will make from a picture prompt
Description: **Student task:** Look at a written prompt and predict what picture AI will create, then compare to actual result. **Visual scenario:** Prompt card shows "Draw a blue dog on a beach." Students choose from 3 prediction cards: (A) blue dog on sand with waves, (B) brown dog in park, (C) blue fish in water. Then they see actual AI result and discuss if their prediction matched. **Learning focus:** Reading instructions carefully helps predict AI behavior. _Implementation note: MCQ prediction followed by reveal; builds prompt interpretation skills. CSTA: EK-AI-03._

Dependencies:
* T23.GK.03: Give simple instructions to an AI helper



ID: T23.GK.05
Topic: T23 – Generative AI Practices
Skill: Recognize that AI treats everyone the same way
Description: **Student task:** Look at picture cards showing different children asking AI the same question, and observe AI gives the same answer to everyone. **Visual scenario:** Four cards show: (A) Girl with brown skin asks "What is 2+2?" - AI says "4", (B) Boy with glasses asks same question - AI says "4", (C) Child in wheelchair asks same question - AI says "4", (D) Boy with red hair asks same question - AI says "4". Students match: "AI gives the same answer because..." with "AI follows the same rules for everyone." **Learning focus:** AI doesn't know who is asking - it treats all questions the same way. This is good for fairness but also means AI can't understand individual needs. _Implementation note: Matching activity with discussion; introduces fairness concept. CSTA: EK-AI-06._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.GK.02: Recognize AI-made vs human-made pictures



ID: T23.GK.06
Topic: T23 – Generative AI Practices
Skill: Identify that humans make final decisions about AI suggestions
Description: **Student task:** Look at picture stories and identify who makes the final decision - the AI or the person. **Visual scenario:** Three story cards: (1) AI suggests "Watch this video!" - Mom looks and says "No, that's not for kids" - Mom decides. (2) AI recommends "Eat pizza for dinner!" - Dad checks and says "We need vegetables too" - Dad decides. (3) AI says "This is the answer to your math problem!" - Teacher checks and says "Let's verify this together" - Teacher decides. Students match each story with "Who made the final choice?" answers. **Learning focus:** AI gives suggestions, but people are responsible for checking and making final decisions. AI is a helper, not the boss. _Implementation note: Story matching with discussion about responsibility. CSTA: EK-AI-06._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.GK.04: Predict what AI will make from a picture prompt



ID: T23.G1.01
Topic: T23 – Generative AI Practices
Skill: Listen to AI-generated speech and identify computer voice
Description: **Student task:** Listen to two voice clips reading the same sentence and tap which one is the computer voice. **Visual scenario:** Audio player shows two speakers: (A) person icon, (B) robot icon. Students hear "Once upon a time, there was a little rabbit." Voice A has natural pauses and expression; Voice B has even pacing and slight mechanical quality. **Learning focus:** AI voices sound different from human voices - often smoother but less expressive. _Implementation note: Audio comparison with visual icons; replay buttons available. CSTA: EK-AI-04._

Dependencies:
* T23.GK.01: Identify AI as a computer helper



ID: T23.G1.02
Topic: T23 – Generative AI Practices
Skill: Compare AI answers to expected answers
Description: **Student task:** Ask a simple question and judge if AI's answer is correct or wrong. **Visual scenario:** Question cards: (A) "What color is the sky?" - AI says "Blue" ✓, (B) "What is 2+2?" - AI says "5" ✗, (C) "What do cats say?" - AI says "Meow" ✓, (D) "How many legs does a spider have?" - AI says "6" ✗ (should be 8). Students sort into "Correct" and "Wrong" piles. **Learning focus:** AI can give wrong answers - we need to check them. _Implementation note: Sorting activity with immediate feedback showing correct answer. CSTA: EK-AI-05._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.GK.03: Give simple instructions to an AI helper



ID: T23.G1.03
Topic: T23 – Generative AI Practices
Skill: Explain why AI needs clear instructions
Description: **Student task:** Match unclear instructions to confused AI results, then fix the instruction. **Visual scenario:** Pairs show: (1) "Draw animal" → AI made half-dog-half-fish blob, (2) "Make it big" → AI made tiny ant (which one is "it"?), (3) "Color picture" → AI used random colors everywhere. Students match each unclear instruction to its confused result, then choose better version: "Draw a brown dog" vs "Draw animal." **Learning focus:** AI cannot guess what we mean - we must be specific. _Implementation note: Matching pairs then MCQ for better instruction. CSTA: EK-AI-03._

Dependencies:
* T23.GK.03: Give simple instructions to an AI helper
* T23.G1.02: Compare AI answers to expected answers



ID: T23.G1.04
Topic: T23 – Generative AI Practices
Skill: Sort AI helpers by what they do
Description: **Student task:** Drag AI helper cards into category boxes based on their function. **Visual scenario:** AI helper cards: (A) Siri/Alexa speaker, (B) ChatGPT chat bubble, (C) DALL-E image creator, (D) Google Translate, (E) spell-checker, (F) music recommendation. Category boxes: "Talks and Listens," "Makes Pictures," "Writes and Translates," "Suggests Things." **Learning focus:** Different AI tools are good at different tasks - choose the right tool for the job. _Implementation note: Drag-drop categorization; some AI may fit multiple categories (discuss). CSTA: EK-AI-01._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.G1.01: Listen to AI-generated speech and identify computer voice



ID: T23.G1.05
Topic: T23 – Generative AI Practices
Skill: Trace how AI learns from examples
Description: **Student task:** Watch a simple animation showing how AI learns, then answer questions about the process. **Visual scenario:** Animation shows: (1) Teacher shows AI many pictures of cats labeled "cat", (2) Teacher shows AI many pictures of dogs labeled "dog", (3) AI sees new picture and guesses "cat" because it looks similar to cat examples. Students answer: "How did AI learn what a cat looks like?" → "By seeing many examples labeled 'cat'." **Learning focus:** AI learns patterns from many examples - it doesn't "know" things like humans do. **Discussion:** "What happens if AI only sees orange cats? Can it recognize a black cat?" (introduces training data concept). _Implementation note: Animated story with comprehension questions; builds ML intuition. CSTA: EK-AI-05._

Dependencies:
* T23.GK.01: Identify AI as a computer helper
* T23.G1.02: Compare AI answers to expected answers



ID: T23.G1.06
Topic: T23 – Generative AI Practices
Skill: Decide when to ask a person instead of AI
Description: **Student task:** Look at question cards and sort them into "Ask AI" or "Ask a Person" piles based on what kind of help you need. **Visual scenario:** Cards show: (A) "What is the capital of France?" → Ask AI (fact question). (B) "Am I being a good friend?" → Ask a Person (needs judgment). (C) "How do you spell 'elephant'?" → Ask AI (fact question). (D) "Should I share my toy with Sam?" → Ask a Person (needs caring advice). (E) "What colors make purple?" → Ask AI (fact question). (F) "Is it okay to feel sad?" → Ask a Person (needs emotional support). **Learning focus:** AI is great for facts and information, but people are better for feelings, advice, and things that need human understanding. _Implementation note: Sorting activity with audio support; discussion about when human help is important. CSTA: EK-AI-06._

Dependencies:
* T23.GK.06: Identify that humans make final decisions about AI suggestions
* T23.G1.02: Compare AI answers to expected answers



ID: T23.G2.01
Topic: T23 – Generative AI Practices
Skill: Observe AI text-to-speech demonstration
Description: **Student task:** Watch teacher demonstration of text-to-speech and suggest sentences to hear. **Visual scenario:** Teacher shows `say [Hello everyone!] in [English]` block with voice options (Male, Female, Boy, Girl). Students suggest sentences: "My name is [student name]," "Today is [day]," "I like [food]." They observe how computer speaks with different voices. **Learning focus:** Computers can read text aloud in different voices - this bridges listening (G1) to coding speech (G3). _Implementation note: Teacher-led demo with student input; no independent coding yet. CSTA: EK-AI-04._

Dependencies:
* T23.G1.01: Listen to AI-generated speech and identify computer voice
* T23.G1.03: Explain why AI needs clear instructions



ID: T23.G2.02
Topic: T23 – Generative AI Practices
Skill: Identify what AI can and cannot do
Description: **Student task:** Sort picture cards into "AI Can Do" and "AI Cannot Do" piles. **Visual scenario:** Cards show: AI Can: answer questions, make pictures, play music, translate languages, recognize faces. AI Cannot: feel happy or sad, taste food, have real friends, know if something is truly right or wrong, experience the world. **Discussion prompts:** "Why can't AI feel happy?" "Does AI really 'know' things or just find patterns?" **Learning focus:** AI has amazing abilities but lacks feelings, experiences, and judgment. _Implementation note: Sorting with discussion guide; emphasize AI limitations. CSTA: EK-AI-06._

Dependencies:
* T23.G1.02: Compare AI answers to expected answers



ID: T23.G2.03
Topic: T23 – Generative AI Practices
Skill: Describe what you want AI to create using details
Description: **Student task:** Build a detailed description before asking AI to create something. **Visual scenario:** Template with blanks: "I want a [SIZE] [COLOR] [ANIMAL] that is [ACTION] in a [PLACE]." Students fill in: "big," "purple," "elephant," "dancing," "jungle." They predict what AI will make, then see AI result for "big purple elephant dancing in jungle" vs "elephant" (minimal prompt). **Learning focus:** Adding details (size, color, action, place) makes AI results match what we want. _Implementation note: Mad-libs style template building; compare detailed vs minimal prompts. CSTA: EK-AI-03._

Dependencies:
* T23.G1.03: Explain why AI needs clear instructions
* T23.G2.02: Identify what AI can and cannot do



ID: T23.G2.04
Topic: T23 – Generative AI Practices
Skill: Observe how AI hears spoken words
Description: **Student task:** Speak words clearly into microphone and observe AI transcription, noting errors. **Visual scenario:** Student says "I like red apples" clearly. Screen shows what AI heard: sometimes correct, sometimes "I like bread apples" or "I light red apples." Students circle words AI got wrong. **Discussion:** "Why did AI hear 'bread' instead of 'red'?" (similar sounds). **Learning focus:** AI can mishear words, especially similar-sounding ones - speak clearly and check results. _Implementation note: Demo with pre-recorded examples showing common speech recognition errors. CSTA: EK-AI-04._

Dependencies:
* T23.G1.01: Listen to AI-generated speech and identify computer voice
* T23.G2.02: Identify what AI can and cannot do



ID: T23.G2.05
Topic: T23 – Generative AI Practices
Skill: Predict if AI will succeed or struggle with a task
Description: **Student task:** Look at task cards and predict if AI will do well or struggle. **Visual scenario:** Task cards: (A) "Find cat pictures" → Easy for AI ✓, (B) "Know if joke is funny" → Hard for AI (no sense of humor), (C) "Translate Spanish to English" → Easy for AI ✓, (D) "Decide if sharing is fair" → Hard for AI (needs human judgment), (E) "Count objects in photo" → Easy for AI ✓, (F) "Understand sarcasm" → Hard for AI. **Learning focus:** AI excels at pattern tasks but struggles with human judgment, emotion, and context. _Implementation note: Prediction sorting with explanations; builds AI literacy. CSTA: EK-AI-06._

Dependencies:
* T23.G2.02: Identify what AI can and cannot do
* T23.G2.03: Describe what you want AI to create using details



ID: T23.G2.06
Topic: T23 – Generative AI Practices
Skill: Identify when AI might be unfair
Description: **Student task:** Look at scenarios where AI might make unfair decisions and identify the problem. **Visual scenario:** Three story cards: (1) "AI learned to recognize faces from photos - but most photos were of light-skinned people. Now AI has trouble recognizing dark-skinned faces." Problem: AI didn't see enough examples of everyone. (2) "AI suggests jobs to people - but it was trained on old data where only men were engineers. Now it doesn't suggest engineering jobs to girls." Problem: AI learned unfair patterns from the past. (3) "AI picks which art to show - but it only shows famous art. New artists never get seen." Problem: AI keeps showing what's already popular. **Learning focus:** AI can be unfair if it learns from unfair examples or data that doesn't include everyone. _Implementation note: Story cards with problem identification; builds critical AI literacy. CSTA: EK-AI-06._

Dependencies:
* T23.G1.05: Trace how AI learns from examples
* T23.G2.02: Identify what AI can and cannot do



ID: T23.G2.07
Topic: T23 – Generative AI Practices
Skill: Trace consequences when AI predictions are wrong
Description: **Student task:** Look at story cards showing what happens when AI makes mistakes, and identify who is affected. **Visual scenario:** Three scenarios: (1) "AI predicted sunny weather, but it rained. Maya didn't bring an umbrella and got wet." Who was affected? Maya. Was it serious? Not too serious. (2) "AI said the road was clear, but there was construction. The driver had to turn around and was late." Who was affected? The driver. Was it serious? Somewhat serious. (3) "AI said a student cheated, but the student didn't. The student got in trouble unfairly." Who was affected? The student. Was it serious? Very serious! **Discussion:** "Why are some AI mistakes more serious than others?" **Learning focus:** AI mistakes have real consequences for real people - some mistakes matter more than others. _Implementation note: Scenario cards with consequence rating (not serious → very serious); introduces stakes thinking. CSTA: EK-AI-06._

Dependencies:
* T23.G1.06: Decide when to ask a person instead of AI
* T23.G2.02: Identify what AI can and cannot do
* T23.G2.05: Predict if AI will succeed or struggle with a task



ID: T23.G3.00
Topic: T23 – Generative AI Practices
Skill: Use basic speech recognition blocks
Description: Students use the `start recognizing speech in [LANGUAGE]` and `end speech recognition` blocks to capture spoken words, storing results in the `text from speech` reporter block. They practice speaking clearly and observe how the AI transcribes different words into a variable displayed on stage. They build a simple "say something and see it appear" project, learning that speech recognition converts voice to text that programs can use.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T23.G2.04: Observe how AI hears spoken words



ID: T23.G3.01
Topic: T23 – Generative AI Practices
Skill: Use speech-to-text to control a sprite
Description: Students use the `start recognizing speech in [LANGUAGE]` and `text from speech` blocks to capture voice commands (e.g., "jump," "spin") that trigger sprite actions using conditionals. They practice speaking clearly and handling recognition errors by checking if text matches expected commands. They build voice-controlled sprite projects combining AI speech recognition with event-driven programming.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T23.G2.01: Observe AI text-to-speech demonstration
* T23.G3.00: Use basic speech recognition blocks



ID: T23.G3.02
Topic: T23 – Generative AI Practices
Skill: Evaluate if AI output matches the request
Description: Students give an AI image generator a prompt and judge whether the result matches what they asked for. They use the `search for AI image of [TYPE] with query [QUERY]` block (TYPE: Object, Character, or Backdrop) to test prompts. They identify missing elements (asked for "red car" but got blue), unwanted additions (got extra passengers not requested), or misinterpretations (asked for "bat" the animal, got baseball bat). They build a simple rating system storing prompt quality in a variable.

Dependencies:
* T23.G2.03: Describe what you want AI to create using details
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G3.03
Topic: T23 – Generative AI Practices
Skill: Revise a prompt to improve AI results
Description: Students take an AI result that did not match their goal and revise their prompt by adding or changing details. They compare original and revised outputs to see improvement. They write a prompt-builder script that combines variable values (subject, color, style) using `join` blocks to create improved prompts programmatically, learning that prompt engineering is iterative.

Dependencies:
* T23.G3.02: Evaluate if AI output matches the request
* T09.G3.01.04: Display variable value on stage using the variable monitor



ID: T23.G3.04
Topic: T23 – Generative AI Practices
Skill: Recognize AI makes mistakes and verify outputs
Description: Students examine AI outputs that contain errors (wrong facts like "the sun is a planet," strange images with extra limbs, incorrect math) and identify the mistakes. They build an error-detection script that compares AI output to expected results using conditionals (e.g., if AI says 2+2=5, flag as error). **Key lesson:** AI is not always correct - human review is essential before trusting AI output.

Dependencies:
* T23.G2.02: Identify what AI can and cannot do
* T23.G3.02: Evaluate if AI output matches the request
* T08.G3.04: Use a simple if in a script



ID: T23.G3.05
Topic: T23 – Generative AI Practices
Skill: Decompose a creative task into AI-solvable parts
Description: Students break down a larger creative goal (e.g., "make a story about space") into smaller pieces that AI can help with individually. **Decomposition example:** "Space story" → (1) AI generates background image of space, (2) AI creates astronaut character, (3) AI suggests 3 story events, (4) Student arranges and connects the pieces. They practice identifying which parts of a project AI can help with vs which parts require human creativity. They build a "task splitter" that shows a big goal, then 3-4 smaller AI-friendly tasks beneath it. **Computational thinking focus:** Decomposition is breaking big problems into smaller, manageable pieces - AI works best on focused, specific requests.

Dependencies:
* T23.G3.02: Evaluate if AI output matches the request
* T23.G3.03: Revise a prompt to improve AI results
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G4.00
Topic: T23 – Generative AI Practices
Skill: Combine keywords for better AI image searches
Description: Students learn to use multiple keywords in one search query (e.g., "cat sitting forest sunset" instead of just "cat"). They compare results from single-word vs multi-word searches and observe how specificity improves results. They experiment with adding adjectives (fluffy), actions (running), and settings (beach) to create more precise image searches.

Dependencies:
* T23.G3.03: Revise a prompt to improve AI results
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G4.01
Topic: T23 – Generative AI Practices
Skill: Search the AI image library with keywords
Description: Students use the `search for AI image of [TYPE] with query [QUERY]` block to find sprites and backdrops matching keywords. They learn to evaluate search results by relevance and quality, selecting the most appropriate asset for their project. They build a simple asset collector that searches for multiple items and stores results.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T23.G3.02: Evaluate if AI output matches the request
* T23.G4.00: Combine keywords for better AI image searches



ID: T23.G4.02
Topic: T23 – Generative AI Practices
Skill: Write a multi-part prompt for AI
Description: Students structure prompts with multiple elements (subject + action + setting + style) to get more specific AI outputs. They create a prompt template using `join` blocks with dropdown menus for subject, action, setting, and style, allowing them to build complex prompts programmatically. They compare simple vs detailed prompts to see quality difference.

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T23.G3.03: Revise a prompt to improve AI results



ID: T23.G4.03
Topic: T23 – Generative AI Practices
Skill: Identify safe and unsafe AI interactions
Description: Students sort examples of AI prompts into safe and unsafe categories. **Safe examples:** asking for homework help, generating story ideas, learning about animals. **Unsafe examples:** sharing home address, asking AI to write mean messages, sharing passwords, asking AI to break rules. They build a safety-checker script using conditionals that displays warnings for unsafe categories.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T08.G3.04: Use a simple if in a script
* T23.G3.04: Recognize AI makes mistakes and verify outputs



ID: T23.G4.04
Topic: T23 – Generative AI Practices
Skill: Credit AI-generated content in projects with labels
Description: Students add attribution labels to their projects indicating which assets came from AI tools. They use `say` blocks or stamp text to display "Image by AI" or "Story idea from ChatGPT" near AI-generated content. They build an attribution system using a list to track AI contributions and display credits on a dedicated "Credits" screen. **Key lesson:** Honesty about AI help builds trust and is fair to human creators.

Dependencies:
* T23.G4.01: Search the AI image library with keywords
* T23.G4.03: Identify safe and unsafe AI interactions
* T10.G3.03: Add and remove items from a list



ID: T23.G4.05
Topic: T23 – Generative AI Practices
Skill: Trace how content moderation protects AI systems
Description: Students examine examples showing how AI tools check content for safety. They test example text that would be flagged (inappropriate language, requests for harmful content) and trace how moderation works: input → AI checker → pass/fail decision → allow/block action. They classify 10 example prompts as likely to pass or fail moderation and verify predictions, connecting moderation to keeping online spaces safe.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T23.G4.03: Identify safe and unsafe AI interactions



ID: T23.G4.06
Topic: T23 – Generative AI Practices
Skill: Categorize AI blocks by function in CreatiCode
Description: Students survey the AI blocks available in CreatiCode (speech recognition, text-to-speech, ChatGPT, image generation, moderation). They categorize blocks by function: Speaking (TTS), Listening (speech recognition), Creating (image generation, ChatGPT), Checking (moderation). They build a reference chart matching project types to appropriate AI blocks (storytelling → TTS + image generation, voice games → speech recognition + TTS).

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T23.G4.02: Write a multi-part prompt for AI
* T23.G4.05: Trace how content moderation protects AI systems



ID: T23.G4.07
Topic: T23 – Generative AI Practices
Skill: Identify XO as CreatiCode's AI coding assistant
Description: Students learn that XO is CreatiCode's built-in AI assistant designed specifically to help with coding projects. They explore XO's capabilities (code generation, debugging help, project planning, explanations) and learn when to use XO versus other AI tools. They practice basic XO interactions: asking for project ideas, getting block explanations, and requesting simple code snippets.

Dependencies:
* T23.G4.03: Identify safe and unsafe AI interactions
* T23.G4.06: Categorize AI blocks by function in CreatiCode



ID: T23.G4.08
Topic: T23 – Generative AI Practices
Skill: Use text-to-speech with voice and rate parameters
Description: Students use the `say [TEXT] in [LANGUAGE] voice [VOICE] rate [RATE]` block to control how AI speaks. They experiment with voice options (Male, Female, Boy, Girl), speaking rate (0.5 = slow, 1 = normal, 2 = fast), and pitch adjustments. They build a talking character project where different sprites have distinct voices, learning that AI speech can be customized for different effects.

Dependencies:
* T23.G2.01: Observe AI text-to-speech demonstration
* T23.G3.01: Use speech-to-text to control a sprite
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G4.09
Topic: T23 – Generative AI Practices
Skill: Read from and write to CreatiCode tables
Description: Students learn to work with CreatiCode tables for data storage and retrieval. They use table blocks to create tables with named columns, add rows with `add row to table`, read values using `get value from table at row () column ()`, and modify data with `set value at row () column ()`. They build simple projects storing multi-row data like quiz scores or inventory items. **Foundation skill:** Tables are essential for working with AI-generated data (face detection, sentence analysis, search results).

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.04: Display variable value on stage using the variable monitor



ID: T23.G4.10
Topic: T23 – Generative AI Practices
Skill: Abstract common patterns from successful prompts
Description: Students analyze multiple successful prompts to identify reusable patterns. **Pattern recognition activity:** Given 5 successful image prompts: "a happy golden retriever playing in a sunny park," "a curious orange cat exploring a cozy bedroom," "a majestic white horse galloping through green fields." Students identify the pattern: [emotion] + [color] + [animal] + [action] + [setting]. They create a "prompt pattern card" storing the template in a variable. They test the pattern with new values (e.g., "a sleepy gray owl resting in a dark forest"). **Computational thinking focus:** Abstraction means finding the general pattern that works across many specific cases - this makes prompt engineering systematic rather than guessing.

Dependencies:
* T23.G3.05: Decompose a creative task into AI-solvable parts
* T23.G4.02: Write a multi-part prompt for AI
* T09.G3.01.04: Display variable value on stage using the variable monitor



ID: T23.G5.01.01
Topic: T23 – Generative AI Practices
Skill: Navigate XO's interface (chat, templates, tabs)
Description: Students explore XO's interface components: the chat area for conversations, template prompts for common tasks (debugging, project ideas, code generation), and tabs that switch between code and explanation views. They learn to identify when XO is still generating responses versus when it has finished, and practice using different templates for different purposes.

Dependencies:
* T23.G4.03: Identify safe and unsafe AI interactions
* T23.G4.07: Identify XO as CreatiCode's AI coding assistant
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.01.02
Topic: T23 – Generative AI Practices
Skill: Manage XO responses (pause, copy, pin)
Description: Students practice managing XO's responses using interface controls. They learn to pause XO mid-response when they have enough information, copy code snippets with proper formatting to paste into projects, and pin important responses for later reference. They understand when to pause (saving time), how to safely copy code while preserving structure, and how pinning organizes useful responses.

Dependencies:
* T23.G5.01.01: Navigate XO's interface (chat, templates, tabs)
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.02
Topic: T23 – Generative AI Practices
Skill: Ask XO for a three-step project plan
Description: Students practice writing structured prompts with goal + constraints + audience so XO replies with a numbered plan. They verify the plan covers at least three concrete actions (e.g., "1. Create cat sprite, 2. Add movement script, 3. Add sound effect"). They evaluate if the plan is realistic and complete for their project.

Dependencies:
* T23.G5.01.02: Manage XO responses (pause, copy, pin)
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.03
Topic: T23 – Generative AI Practices
Skill: Turn an XO suggestion into starter code safely
Description: Students copy a short script provided by XO into their project, but before running it they: (1) verify variables/events exist, (2) read each block to understand what it does, (3) annotate with comments what they expect. This builds the critical habit of reading and understanding AI-generated code before trusting it.

Dependencies:
* T23.G5.01.02: Manage XO responses (pause, copy, pin)
* T23.G5.02: Ask XO for a three-step project plan
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.04
Topic: T23 – Generative AI Practices
Skill: Collect themed assets from narrative descriptions
Description: Students take XO's narrative description (e.g., "Journey of a Waterdrop" scene) and convert it into multi-part AI image search queries. They collect multiple matching sprites and backdrops for a coherent scene, justifying how each asset fits the narrative. This advances from single-keyword searches to theme-based asset collection.

Dependencies:
* T23.G4.01: Search the AI image library with keywords
* T23.G5.02: Ask XO for a three-step project plan



ID: T23.G5.05
Topic: T23 – Generative AI Practices
Skill: Reject unsafe or off-spec XO suggestions
Description: Students review XO replies that include problematic suggestions: off-task steps ("add a game instead of the requested story"), privacy risks ("ask user for their real name"), or non-compliant steps ("skip testing"). They practice declining these suggestions, writing replacement steps that follow the rubric/spec, and logging why the original was rejected.

Dependencies:
* T23.G4.03: Identify safe and unsafe AI interactions
* T23.G5.03: Turn an XO suggestion into starter code safely



ID: T23.G5.06
Topic: T23 – Generative AI Practices
Skill: Validate AI output before using in program
Description: Students build validation scripts that check AI output before using it. They learn patterns: (1) check if response is empty, (2) verify response format matches expectation, (3) check for error messages, (4) validate numeric ranges. They use conditionals to handle invalid AI output gracefully (show error message, use default value, retry request). **Key skill:** Never assume AI output is correct - always validate.

Dependencies:
* T23.G3.04: Recognize AI makes mistakes and verify outputs
* T23.G5.03: Turn an XO suggestion into starter code safely
* T08.G3.04: Use a simple if in a script



ID: T23.G5.07.01
Topic: T23 – Generative AI Practices
Skill: Use basic ChatGPT block with default settings
Description: Students use the `ChatGPT request [PROMPT] result [VARIABLE]` block with default settings to send simple prompts and receive AI responses. They build basic projects that ask ChatGPT questions (trivia, story starters, translations) and display answers in variables on stage. They learn to write clear prompts and handle the response text.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T23.G4.02: Write a multi-part prompt for AI
* T23.G4.06: Categorize AI blocks by function in CreatiCode



ID: T23.G5.07.02
Topic: T23 – Generative AI Practices
Skill: Control ChatGPT response streaming and length
Description: Students learn to control ChatGPT response delivery and length. They experiment with modes: 'streaming' (shows partial responses in real-time, ends with ✅, good for showing progress) vs 'waiting' (waits for complete response, better for processing). They use length parameter to limit response size (100 tokens ≈ 75 words), building projects that compare user experience between modes.

Dependencies:
* T23.G5.07.01: Use basic ChatGPT block with default settings
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.07.03
Topic: T23 – Generative AI Practices
Skill: Adjust ChatGPT creativity with temperature parameter
Description: Students experiment with temperature parameter (0-1 scale) to control ChatGPT's creativity. Temperature 0 = focused and deterministic (same prompt gives similar answers, good for facts). Temperature 1 = creative and varied (same prompt gives different answers, good for stories). They build projects testing different temperatures for various tasks (math problems vs story ideas).

Dependencies:
* T23.G5.07.01: Use basic ChatGPT block with default settings
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence



ID: T23.G5.07.04
Topic: T23 – Generative AI Practices
Skill: Use few-shot prompting with examples
Description: Students learn to improve AI responses by including examples in their prompts. **Few-shot prompting pattern:** "Here are examples of what I want: Example 1: Input: 'happy' → Output: '😊'. Example 2: Input: 'sad' → Output: '😢'. Now do this: Input: 'excited' → Output: ?" They compare zero-shot (no examples) vs few-shot (2-3 examples) responses for the same task. They build a prompt template that includes example slots and test how different examples affect AI behavior. **Key insight:** Showing AI what you want through examples often works better than describing what you want in words.

Dependencies:
* T23.G5.07.01: Use basic ChatGPT block with default settings
* T23.G4.02: Write a multi-part prompt for AI



ID: T23.G5.08
Topic: T23 – Generative AI Practices
Skill: Use continuous speech recognition for live voice input
Description: Students use the `start continuous speech recognition in [LANGUAGE] into list [LISTNAME]` block to stream voice input into a list in real-time. They build projects where spoken words continuously update a display or trigger actions, learning to start/stop recognition and handle the stream of recognized text.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T10.G3.03: Add and remove items from a list
* T23.G3.01: Use speech-to-text to control a sprite
* T23.G4.06: Categorize AI blocks by function in CreatiCode



ID: T23.G5.08.01
Topic: T23 – Generative AI Practices
Skill: Map stage coordinates for computer vision blocks
Description: Students explore the CreatiCode stage coordinate system used by computer vision blocks: x-axis ranges from -240 to 240, y-axis ranges from -180 to 180, with origin (0, 0) at stage center. They build visualization projects that display coordinates and mark key positions, understanding how camera coordinates map to stage positions.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.04: Display variable value on stage using the variable monitor



ID: T23.G5.09.01
Topic: T23 – Generative AI Practices
Skill: Enable face detection with debug visualization
Description: Students use the `run face detection debug [yes] and write into table [TABLENAME]` block to detect faces from camera in real-time. They enable debug mode showing red rectangles around detected faces and blue dots on facial features. They observe how AI identifies faces and understand that detection results are stored in a table for programmatic access.

Dependencies:
* T23.G4.06: Categorize AI blocks by function in CreatiCode
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G5.08.01: Map stage coordinates for computer vision blocks



ID: T23.G5.09.02
Topic: T23 – Generative AI Practices
Skill: Trace face detection table structure and read coordinates
Description: Students explore the face detection table containing 13 rows per face: ID, tilt angle, and x/y coordinates for eyes, nose, mouth, and ears. They practice reading specific values using table blocks, building projects that display facial feature coordinates on screen. They learn to handle cases when multiple faces are detected using the ID field.

Dependencies:
* T23.G5.09.01: Enable face detection with debug visualization
* T23.G4.09: Read from and write to CreatiCode tables



ID: T23.G5.10
Topic: T23 – Generative AI Practices
Skill: Use face position to control sprites
Description: Students read face detection data from tables (nose x/y coordinates) to control sprite movement. They build projects where sprites follow face position, respond to head tilt angle, or trigger actions based on facial feature locations. They learn to handle "no face detected" cases using conditionals and may experiment with smoothing jittery tracking.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T23.G5.09.02: Trace face detection table structure and read coordinates



ID: T23.G5.11
Topic: T23 – Generative AI Practices
Skill: Compare AI image search vs image generation
Description: Students distinguish between searching existing AI-generated images (fast, good for common subjects) and generating new custom images (slower, allows unique combinations). They identify when to use each: search for standard assets like "dog" or "tree," generate for unique combinations like "robot riding purple elephant on Mars." This prepares them for DALL-E in Grade 6.

Dependencies:
* T23.G4.01: Search the AI image library with keywords
* T23.G5.04: Collect themed assets from narrative descriptions



ID: T23.G5.12
Topic: T23 – Generative AI Practices
Skill: Classify data using pattern recognition concepts
Description: Students explore machine learning classification foundations by sorting data into categories. They trace how computers learn patterns from training examples and make predictions on new data. They identify features that distinguish categories (e.g., petal length distinguishes flower types) and build simple classification projects using conditionals: "if petal length > 5 then type = versicolor." This introduces ML thinking for KNN in Grade 7.

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T08.G3.04: Use a simple if in a script
* T23.G4.09: Read from and write to CreatiCode tables



ID: T23.G5.13
Topic: T23 – Generative AI Practices
Skill: Test and document AI limitations with specific examples
Description: Students test and document specific AI limitations through experiments. **Limitations to test:** (1) AI can be confidently wrong (ask "capital of made-up country" - AI invents answer), (2) AI doesn't truly understand (ask same question differently, get contradictory answers), (3) AI reflects training data biases, (4) AI can't access real-time information (unless given tools), (5) AI struggles with logic puzzles. They build a "AI Limitation Tester" project that runs each test type and logs results in a table with columns: limitation type, test prompt, AI response, expected behavior, pass/fail.

Dependencies:
* T23.G2.02: Identify what AI can and cannot do
* T23.G5.06: Validate AI output before using in program
* T23.G5.07.01: Use basic ChatGPT block with default settings



ID: T23.G5.14
Topic: T23 – Generative AI Practices
Skill: Identify AI hallucinations and verify facts
Description: Students learn to recognize when AI "hallucinates" - confidently generates false information that sounds believable. **Hallucination types:** (1) **Invented facts:** AI creates statistics, quotes, or events that never happened (e.g., "According to a 2023 study by Dr. Smith..." when no such study exists). (2) **Plausible fiction:** AI describes things that could exist but don't (e.g., detailed description of a fake book or movie). (3) **Confident errors:** AI states something incorrect with certainty (e.g., wrong math, wrong dates, wrong definitions). **Verification strategies:** Ask AI for sources, cross-check with reliable websites, ask "Are you certain?" to see if AI hedges. Students build a "Fact Checker" project that asks ChatGPT a question, then prompts user to rate confidence and verify claim. **Key lesson:** AI can sound very confident even when completely wrong - always verify important information.

Dependencies:
* T23.G5.13: Test and document AI limitations with specific examples
* T23.G5.06: Validate AI output before using in program
* T23.G3.04: Recognize AI makes mistakes and verify outputs



ID: T23.G6.04A
Topic: T23 – Generative AI Practices
Skill: Generate custom images with the DALL-E block
Description: Students use the `DALL-E generate image with request [DESCRIPTION]` block to create custom images. They understand the difference between searching (G4-G5) and generating. They select appropriate resolutions: 256x256 (fast, small, good for icons), 512x512 (balanced, good for sprites), 1024x1024 (highest quality, best for backdrops). They learn resolution affects generation time and visual quality.

Dependencies:
* T23.G4.02: Write a multi-part prompt for AI
* T23.G5.04: Collect themed assets from narrative descriptions
* T23.G5.11: Compare AI image search vs image generation



ID: T23.G6.05A
Topic: T23 – Generative AI Practices
Skill: Use AI sentence analysis to identify parts of speech
Description: Students use the `analyze sentence [TEXT] and write into table [TABLENAME]` block to parse sentences. The block creates a table with 7 columns: TEXT (word), LEMMA (root form), TYPE (noun/verb/etc), PERSON, OFFSET, LABEL, DEPENDS. They build projects analyzing user input, categorizing words, or creating word games using grammatical information.

Dependencies:
* T23.G4.02: Write a multi-part prompt for AI
* T23.G4.06: Categorize AI blocks by function in CreatiCode
* T23.G4.09: Read from and write to CreatiCode tables



ID: T23.G6.00
Topic: T23 – Generative AI Practices
Skill: Diagnose AI failures systematically
Description: Students learn a systematic approach to debugging AI-related issues. **AI Failure Diagnosis Framework:** (1) **Identify failure type:** empty response, wrong format, incorrect content, timeout, or error message. (2) **Check inputs:** Is the prompt clear? Are parameters valid? Is the API available? (3) **Isolate the problem:** Test with simpler prompt. Try different parameters. Check if other AI blocks work. (4) **Apply fix patterns:** For empty response → check moderation, add "Please respond with..." For wrong format → add format instructions. For incorrect content → add examples or constraints. For timeout → reduce complexity or add retry. They build an "AI Debugger" project that walks through each diagnostic step and logs findings.

Dependencies:
* T23.G5.06: Validate AI output before using in program
* T23.G5.13: Test and document AI limitations with specific examples



ID: T23.G6.01
Topic: T23 – Generative AI Practices
Skill: Provide complete context when asking XO to debug
Description: Students assemble a "debug packet" with: (1) bug description ("sprite doesn't move"), (2) relevant script (copied or screenshot), (3) expected behavior ("should move right when arrow pressed"). XO returns a fix; students evaluate whether it addresses the issue and annotate any manual tweaks needed.

Dependencies:
* T23.G5.03: Turn an XO suggestion into starter code safely
* T23.G5.05: Reject unsafe or off-spec XO suggestions



ID: T23.G6.02
Topic: T23 – Generative AI Practices
Skill: Verify XO's explanation against the project
Description: Students ask XO "Explain how this script works," then compare the explanation to actual code. They highlight mismatches (XO says "loop runs 5 times" but code shows 10) and either accept or correct the AI explanation. This builds critical evaluation of AI explanations.

Dependencies:
* T23.G5.03: Turn an XO suggestion into starter code safely
* T23.G6.01: Provide complete context when asking XO to debug



ID: T23.G6.03
Topic: T23 – Generative AI Practices
Skill: Generate and deliver a quiz using XO
Description: Students prompt XO for three multiple-choice questions about a chosen topic (loops, events, variables). They vet each question for clarity and accuracy, fix any issues, then deliver the quiz using widgets (text input for answers, buttons for submit). This combines AI content generation with critical review.

Dependencies:
* T23.G5.05: Reject unsafe or off-spec XO suggestions
* T23.G6.02: Verify XO's explanation against the project



ID: T23.G6.04
Topic: T23 – Generative AI Practices
Skill: Iterate AI images using feedback from XO
Description: Students upload an AI-generated backdrop to XO and ask for improvement ideas ("What should I change to make it look stormy?"). They modify the prompt based on feedback and regenerate, comparing before/after results and noting which prompt edits caused the change. This teaches iterative AI-assisted design.

Dependencies:
* T23.G5.04: Collect themed assets from narrative descriptions
* T23.G5.05: Reject unsafe or off-spec XO suggestions



ID: T23.G6.05
Topic: T23 – Generative AI Practices
Skill: Maintain a prompt/response lab notebook using tables
Description: Students create tracking tables to log AI interactions with columns: timestamp, AI tool used, prompt text, result quality (1-5), action taken (used/modified/rejected). Using table blocks, they write scripts that automatically log each AI interaction. They review accumulated data to spot patterns ("long prompts give better responses"), building metacognitive habits for improving prompting.

Dependencies:
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G5.05: Reject unsafe or off-spec XO suggestions
* T23.G6.04: Iterate AI images using feedback from XO



ID: T23.G6.06
Topic: T23 – Generative AI Practices
Skill: Label risky prompts and rewrite them safely
Description: Students examine prompts that: leak private info ("My address is..."), copy code wholesale ("write my whole project"), or skip requirements ("ignore the testing step"). They classify each as safe or risky, then rewrite risky ones to remove private data and align to requirements while keeping the learning goal.

Dependencies:
* T23.G5.05: Reject unsafe or off-spec XO suggestions
* T23.G6.05: Maintain a prompt/response lab notebook using tables



ID: T23.G6.07.01
Topic: T23 – Generative AI Practices
Skill: Use moderation blocks for text filtering
Description: Students use the `get moderation result for [TEXT]` block to check user input for inappropriate content. They build text-based safety systems for chatbots using conditionals to accept ("Pass") or reject ("Fail") content. They learn how AI moderation identifies inappropriate language to protect users.

Dependencies:
* T23.G4.05: Trace how content moderation protects AI systems
* T08.G4.03: Use if‑else or else‑if chains



ID: T23.G6.07.02
Topic: T23 – Generative AI Practices
Skill: Use moderation blocks for image filtering
Description: Students use the `get moderation result for costume named [COSTUMENAME]` and `get moderation result for image at URL [URL]` blocks to check images for inappropriate content. They build comprehensive moderation systems combining text and image checking for user-generated content platforms with appropriate safety checks.

Dependencies:
* T23.G6.07.01: Use moderation blocks for text filtering
* T23.G4.05: Trace how content moderation protects AI systems



ID: T23.G6.08.01
Topic: T23 – Generative AI Practices
Skill: Manage ChatGPT sessions explicitly
Description: Students use `session: new chat` vs `session: continue` parameters to control conversation context. They ask related questions ("What are loops?" then "Show me an example") and observe how context is maintained with "continue." They learn when to start fresh (independent queries) vs continue (building on context).

Dependencies:
* T23.G5.07.03: Adjust ChatGPT creativity with temperature parameter



ID: T23.G6.08.02
Topic: T23 – Generative AI Practices
Skill: Configure AI behavior with system instructions
Description: Students use the `OpenAI ChatGPT: system request` or `LLM set system instruction` blocks to define AI persona and behavior rules. **System instruction patterns:** (1) **Role assignment:** "You are a friendly tutor who explains coding concepts simply." (2) **Output format:** "Always respond in exactly 3 bullet points." (3) **Constraints:** "Never give answers directly - ask guiding questions instead." (4) **Tone:** "Be encouraging and use simple words for elementary students." They build chatbots with distinct personalities and compare how system instructions vs regular prompts affect AI behavior. **Key insight:** System instructions are more powerful than user messages for shaping consistent AI behavior.

Dependencies:
* T23.G6.08.01: Manage ChatGPT sessions explicitly
* T23.G5.07.04: Use few-shot prompting with examples



ID: T23.G6.08
Topic: T23 – Generative AI Practices
Skill: Build a multi-turn chatbot using LLM sessions
Description: Students use the `ChatGPT request` block with `session: continue` to maintain conversation context across multiple exchanges. They build an interactive chatbot that remembers previous questions and provides contextual responses, creating conversational AI experiences.

Dependencies:
* T23.G6.05: Maintain a prompt/response lab notebook using tables
* T23.G6.08.01: Manage ChatGPT sessions explicitly



ID: T23.G6.09
Topic: T23 – Generative AI Practices
Skill: Attach stage snapshots to XO for visual debugging
Description: Students capture their project's visual output using stage snapshot, then attach it to an XO request. They ask visual debugging questions: "Is this output correct?" "Does this design match my theme?" This extends XO usage beyond code to visual asset evaluation.

Dependencies:
* T23.G6.04: Iterate AI images using feedback from XO



ID: T23.G6.10.01
Topic: T23 – Generative AI Practices
Skill: Trace hand detection table structure and data format
Description: Students use the `run hand detection table [TABLENAME] debug [yes] show video [yes]` block to detect hands and trace the 47-row table structure: 5 fingers with curl (180°=straight, 0°=curled) and direction values (0°=up, 90°=right), plus 21 2D keypoints (x/y) and 21 3D keypoints (x/y/z) for wrist and finger joints. They build a project that displays specific table values on stage to verify their understanding of the data format.

Dependencies:
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G5.09.01: Enable face detection with debug visualization



ID: T23.G6.10.02
Topic: T23 – Generative AI Practices
Skill: Read hand detection data and build basic gesture controls
Description: Students read curl and direction values from hand detection tables to recognize gestures: open hand (all fingers extended), closed fist (all fingers curled), pointing (index extended, others curled). They build interactive projects where detected gestures trigger sprite actions using conditionals with curl thresholds.

Dependencies:
* T23.G6.10.01: Trace hand detection table structure and data format
* T08.G4.03: Use if‑else or else‑if chains



ID: T23.G6.10.03
Topic: T23 – Generative AI Practices
Skill: Read 2D and 3D hand keypoint coordinates
Description: Students read 2D (x/y screen position) and 3D (x/y/z with depth) keypoint data from hand detection tables. They build projects tracking hand position on stage and responding to depth changes (hand moving toward/away from camera), creating 3D-aware hand interactions.

Dependencies:
* T23.G6.10.02: Read hand detection data and build basic gesture controls
* T23.G5.08.01: Map stage coordinates for computer vision blocks



ID: T23.G6.10.04
Topic: T23 – Generative AI Practices
Skill: Build single-hand gesture recognition systems
Description: Students combine curl, direction, and keypoint data to build reliable gesture recognition. They create projects recognizing gestures (open palm, fist, pointing) with clear thresholds and visual feedback. They learn to require gestures be held briefly before triggering to improve reliability.

Dependencies:
* T23.G6.10.03: Read 2D and 3D hand keypoint coordinates
* T08.G4.03: Use if‑else or else‑if chains



ID: T23.G6.11.01
Topic: T23 – Generative AI Practices
Skill: Trace 2D body detection table structure and body part mapping
Description: Students use the `run 2D body part recognition single person [yes] table [TABLENAME] debug [yes]` block to track body parts. They trace the table with columns: id (person), part (body part name), x/y (coordinates), curl, dir. Body parts include: nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles, plus computed arm/leg positions. They build a project that displays body part coordinates on stage and verify them against the debug skeleton overlay.

Dependencies:
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G6.10.01: Trace hand detection table structure and data format



ID: T23.G6.11.02
Topic: T23 – Generative AI Practices
Skill: Read body positions and detect movements
Description: Students read x/y coordinates for body parts and calculate position changes to detect movements: jumping (y-coordinate increases), arm raising (wrist y higher than shoulder), squatting (hip y decreases). They build interactive games where players control gameplay through physical movements.

Dependencies:
* T23.G6.11.01: Trace 2D body detection table structure and body part mapping
* T08.G4.03: Use if‑else or else‑if chains



ID: T23.G6.11.03
Topic: T23 – Generative AI Practices
Skill: Read limb curl values and detect specific movements
Description: Students read curl and direction data for computed limbs (arms, legs) where curl=180° means straight, 0°=bent. They detect specific movements: jumping, arm raising, stepping. They build projects counting exercises or responding to specific body movements.

Dependencies:
* T23.G6.11.02: Read body positions and detect movements
* T08.G4.03: Use if‑else or else‑if chains



ID: T23.G6.11.04
Topic: T23 – Generative AI Practices
Skill: Build body-controlled interactive projects
Description: Students create complete projects controlled by body movements: fitness games counting exercises, obstacle avoidance using body position, or dance activities comparing poses. They provide visual feedback for detected movements and handle edge cases when body parts aren't visible.

Dependencies:
* T23.G6.11.03: Read limb curl values and detect specific movements



ID: T23.G6.12
Topic: T23 – Generative AI Practices
Skill: Use ChatGPT vision with costume attachment
Description: Students use the `attach costume [COSTUMENAME] to chat` block before ChatGPT requests to enable vision analysis. They send images with prompts like "Describe this scene" or "What objects do you see?" and use AI responses to drive sprite behavior, creating multimodal applications combining text and image understanding.

Dependencies:
* T23.G5.07.01: Use basic ChatGPT block with default settings
* T23.G6.09: Attach stage snapshots to XO for visual debugging



ID: T23.G6.13
Topic: T23 – Generative AI Practices
Skill: Use web search blocks for real-time information
Description: Students use the `web search [QUERY] store top (K) in table [TABLENAME]` block to retrieve current information. Results come in a table with columns: title, link, snippet. They build research tools, fact-checkers, or current-event answerers by searching and processing results.

Dependencies:
* T23.G4.06: Categorize AI blocks by function in CreatiCode
* T23.G6.05: Maintain a prompt/response lab notebook using tables



ID: T23.G6.14
Topic: T23 – Generative AI Practices
Skill: Build multi-step AI pipeline (prompt chaining)
Description: Students build AI pipelines where output from one AI call becomes input for another. **Pattern 1:** Generate story idea → expand into full paragraph → create matching image. **Pattern 2:** Analyze user input → generate response → check moderation → display if safe. They learn to pass results between AI blocks using variables, building sophisticated AI workflows.

Dependencies:
* T23.G5.07.01: Use basic ChatGPT block with default settings
* T23.G6.07.01: Use moderation blocks for text filtering
* T23.G6.04A: Generate custom images with the DALL-E block



ID: T23.G6.15
Topic: T23 – Generative AI Practices
Skill: Design guardrails for AI-generated content
Description: Students design and implement guardrails that constrain AI behavior to prevent unwanted outputs. **Guardrail types:** (1) **Input guardrails:** Check user prompts before sending to AI - block personal info (names, addresses), restrict topics, limit prompt length. (2) **Output guardrails:** Check AI responses before displaying - filter inappropriate language, verify format compliance, check factual consistency. (3) **Behavioral guardrails:** Limit what AI can do - restrict to specific tasks, require human approval for certain actions. **Implementation:** Students build a "Safe AI Assistant" project with: input filter (reject personal data prompts), moderation check on output, format validator (response must be under 100 words), topic enforcer (only answer about approved subjects). They log blocked requests and guardrail triggers. **Key insight:** Guardrails are essential for deploying AI responsibly - they provide human-defined boundaries on AI behavior.

Dependencies:
* T23.G5.14: Identify AI hallucinations and verify facts
* T23.G6.07.01: Use moderation blocks for text filtering
* T23.G6.14: Build multi-step AI pipeline (prompt chaining)



ID: T23.G7.00
Topic: T23 – Generative AI Practices
Skill: Apply chain-of-thought prompting for complex problems
Description: Students learn to get better AI reasoning by asking for step-by-step explanations. **Chain-of-thought pattern:** Add "Let's think step by step" or "Explain your reasoning before giving the answer" to prompts. They compare direct answers vs chain-of-thought answers for math problems, logic puzzles, and code debugging. **Examples:** (1) Direct: "What is 17 × 24?" vs CoT: "What is 17 × 24? Show your work step by step." (2) Direct: "Fix this bug" vs CoT: "First explain what the code does, then identify the bug, then suggest a fix." They build projects that automatically add chain-of-thought instructions to user questions and observe improved accuracy. **Key insight:** Making AI "show its work" often leads to more accurate and explainable answers.

Dependencies:
* T23.G5.07.04: Use few-shot prompting with examples
* T23.G6.08.02: Configure AI behavior with system instructions
* T23.G6.14: Build multi-step AI pipeline (prompt chaining)



ID: T23.G7.01
Topic: T23 – Generative AI Practices
Skill: Create reusable XO prompt templates in lists
Description: Students design prompt templates with placeholders (e.g., "Review code for {SPRITE} focusing on {GOAL}"). They store templates as text items in lists and use `join` blocks to fill placeholders, creating reusable prompts. They track which templates are most effective using a table with columns: template name, category (debugging/planning/review), usage count.

Dependencies:
* T23.G6.05: Maintain a prompt/response lab notebook using tables
* T23.G6.06: Label risky prompts and rewrite them safely
* T10.G5.03: Add and remove items from a list



ID: T23.G7.02
Topic: T23 – Generative AI Practices
Skill: Run an XO-led code review with evidence
Description: Students paste a script into XO and ask for "3 improvements." They inspect each suggestion and either implement it or reject it with justification (performance, readability, design). They maintain a review log table: original code, suggestion, decision, justification, outcome. This teaches critical evaluation with evidence.

Dependencies:
* T23.G5.05: Reject unsafe or off-spec XO suggestions
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.03
Topic: T23 – Generative AI Practices
Skill: Combine XO storyboards with AI sprite generation
Description: Students ask XO for a storyboard (scene descriptions + characters) for a themed project, then generate sprites/backdrops for each scene using AI image blocks. They maintain a storyboard table: scene number, XO description, sprite name, alignment score (1-5), modifications needed.

Dependencies:
* T23.G6.04: Iterate AI images using feedback from XO
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.04
Topic: T23 – Generative AI Practices
Skill: Enforce responsible-use rules for XO assistance
Description: Students implement an "AI Help" tracking system: a list recording each XO contribution, who reviewed it, and whether it was modified. They add on-screen indicators showing when AI-generated content appears. Tracking table includes: timestamp, contribution type, reviewer, modified (yes/no), attribution displayed (yes/no).

Dependencies:
* T23.G6.05: Maintain a prompt/response lab notebook using tables
* T23.G5.05: Reject unsafe or off-spec XO suggestions
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.05
Topic: T23 – Generative AI Practices
Skill: Use XO to coach peers with rubric-based feedback
Description: Students feed XO a project summary and ask for constructive feedback. They edit the response to match a class rubric (naming strengths, next steps) before sending to a peer. Feedback table tracks: peer name, XO raw feedback, edited feedback, rubric alignment score, peer response. This teaches responsible AI-mediated peer review.

Dependencies:
* T23.G7.02: Run an XO-led code review with evidence
* T23.G7.04: Enforce responsible-use rules for XO assistance



ID: T23.G7.06
Topic: T23 – Generative AI Practices
Skill: Use multiple XO sessions to compare responses
Description: Students use `select chatbot [1/2/3/4]` to create two XO sessions with different system instructions ("focus on readability" vs "focus on efficiency"). They send the same request to both and compare responses, synthesizing a combined improvement plan. This teaches critical comparison of AI perspectives.

Dependencies:
* T23.G7.02: Run an XO-led code review with evidence
* T23.G7.05: Use XO to coach peers with rubric-based feedback



ID: T23.G7.07.01
Topic: T23 – Generative AI Practices
Skill: Recognize complex hand gestures
Description: Students combine curl and direction values to recognize complex gestures: thumbs up (thumb extended high, others curled), peace sign (index and middle extended, others curled), pointing (index only extended). They build projects detecting these gestures using precise thresholds in conditional logic.

Dependencies:
* T23.G6.10.04: Build single-hand gesture recognition systems
* T08.G5.02: Design multi-branch decision logic



ID: T23.G7.07.02
Topic: T23 – Generative AI Practices
Skill: Create gesture vocabulary and multi-gesture interfaces
Description: Students build gesture vocabulary systems mapping 5+ gestures to different actions using lookup tables. They create comprehensive gesture control interfaces handling gesture sequences, simultaneous two-hand gestures, and polished visual feedback for recognized gestures.

Dependencies:
* T23.G7.07.01: Recognize complex hand gestures
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.08.01
Topic: T23 – Generative AI Practices
Skill: Trace 3D pose detection coordinates and 33 body parts
Description: Students use `run 3D pose detection debug [yes] table [TABLENAME]` to detect 33 body parts with x/y/z coordinates. They trace the 3D coordinate system (x=right, y=up, z=depth) and identify all tracked parts: head, shoulders, elbows, wrists, hands, hips, knees, ankles, feet, fingers. They build a depth visualization project that responds differently when user moves toward/away from camera using z-coordinates.

Dependencies:
* T23.G6.11.01: Trace 2D body detection table structure and body part mapping



ID: T23.G7.08.02
Topic: T23 – Generative AI Practices
Skill: Calculate distances and angles between body parts
Description: Students calculate 2D and 3D distances using math blocks: √((x2-x1)² + (y2-y1)²) for 2D, add (z2-z1)² for 3D. They calculate joint angles using trigonometry: elbow angle (shoulder-elbow-wrist), knee angle (hip-knee-ankle). These calculations enable precise pose recognition.

Dependencies:
* T23.G7.08.01: Trace 3D pose detection coordinates and 33 body parts
* T07.G5.01: Trace a repeat loop with variable updates



ID: T23.G7.08.03
Topic: T23 – Generative AI Practices
Skill: Detect poses using angle thresholds
Description: Students combine angle calculations with conditionals to detect poses: T-pose (elbows ~170°, arms horizontal), arms raised (wrists above head), standing straight (knees ~170°). They detect complex poses requiring multiple conditions: jumping, yoga tree pose, warrior pose, squatting. They build pose libraries with multiple criteria per pose.

Dependencies:
* T23.G7.08.02: Calculate distances and angles between body parts
* T08.G5.02: Design multi-branch decision logic



ID: T23.G7.08.04
Topic: T23 – Generative AI Practices
Skill: Build comprehensive pose-based games
Description: Students create complete games controlled by body poses: yoga instruction (guiding through pose sequences), fitness challenges (counting exercises with form validation), dance games (matching target poses to music), action games (pose-based combat). They implement scoring, feedback, and progression systems.

Dependencies:
* T23.G7.08.03: Detect poses using angle thresholds
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.09
Topic: T23 – Generative AI Practices
Skill: Create and train KNN classifier for simple datasets
Description: Students use `create KNN number classifier from table [TABLENAME] K [K] named [NAME]` to build their first ML classifier. They learn table structure: first column = 'label' (category), remaining columns = numeric features. They experiment with K values (number of neighbors) and train classifiers on simple datasets like iris flowers.

Dependencies:
* T23.G5.12: Classify data using pattern recognition concepts
* T23.G7.01: Create reusable XO prompt templates in lists
* T10.G5.03: Add and remove items from a list



ID: T23.G7.10
Topic: T23 – Generative AI Practices
Skill: Build prediction projects with KNN classifier
Description: Students use `predict for table [TABLENAME] with classifier [NAME] show neighbors [yes]` to classify new data. They build interactive projects making real-time predictions ("What flower type is this?") and evaluate accuracy by comparing predictions to known labels. Showing nearest neighbors helps debug classification decisions.

Dependencies:
* T23.G7.09: Create and train KNN classifier for simple datasets
* T08.G5.02: Design multi-branch decision logic



ID: T23.G7.11
Topic: T23 – Generative AI Practices
Skill: Compare semantic search vs keyword matching
Description: Students distinguish keyword search (exact word matching) from semantic search (meaning-based matching). They trace how embeddings convert text to numbers capturing meaning, enabling "canine" to find "dog" despite different words. They explore use cases: finding similar documents, answering questions, building smart search. This prepares for semantic search coding in Grade 8.

Dependencies:
* T23.G6.13: Use web search blocks for real-time information
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.12
Topic: T23 – Generative AI Practices
Skill: Combine web search with ChatGPT for informed responses
Description: Students build projects that first use `web search` to get current information, then feed search snippets to ChatGPT to generate informed answers. They extract relevant information from search tables and create AI assistants answering current-event questions with up-to-date data.

Dependencies:
* T23.G6.13: Use web search blocks for real-time information
* T23.G7.02: Run an XO-led code review with evidence



ID: T23.G7.13
Topic: T23 – Generative AI Practices
Skill: Attach local files to ChatGPT for analysis
Description: Students use `attach files to chat` to attach local files (text, CSV, images) to ChatGPT sessions. The block opens file selection, returns paths, and adds files to the chat. They build projects analyzing uploaded documents, processing data files, or working with user-provided content.

Dependencies:
* T23.G6.12: Use ChatGPT vision with costume attachment
* T23.G7.02: Run an XO-led code review with evidence



ID: T23.G7.14
Topic: T23 – Generative AI Practices
Skill: Integrate Google Drive files with AI projects
Description: Students use `attach file from Google Drive [URL] to chat` to attach shared Drive files to ChatGPT. They learn to get shareable links and use them in CreatiCode for AI analysis. They build collaborative projects where multiple users share files for AI analysis.

Dependencies:
* T23.G7.13: Attach local files to ChatGPT for analysis



ID: T23.G7.15
Topic: T23 – Generative AI Practices
Skill: Trace neural network architecture and training flow
Description: Students trace neural network foundations: layers (input, hidden, output), neurons (computational units), activation functions (relu, sigmoid, softmax), training process (epochs, batch size). Through visual diagrams, they trace how data flows through layers and how weights adjust during training. They build a visualization project showing layer-by-layer transformations using simplified number examples, preparing for building neural networks in Grade 8.

Dependencies:
* T23.G7.09: Create and train KNN classifier for simple datasets
* T23.G7.10: Build prediction projects with KNN classifier



ID: T23.G7.16
Topic: T23 – Generative AI Practices
Skill: Design fallback strategies when AI fails
Description: Students design and implement fallback strategies for AI failures: (1) retry with modified prompt, (2) use cached previous result, (3) switch to simpler AI tool, (4) display user-friendly error message, (5) ask user to try again. They build robust AI systems that handle failures gracefully without crashing or confusing users. **Key skill:** Production AI systems must handle failures.

Dependencies:
* T23.G5.06: Validate AI output before using in program
* T23.G6.14: Build multi-step AI pipeline (prompt chaining)
* T08.G5.02: Design multi-branch decision logic



ID: T23.G7.17
Topic: T23 – Generative AI Practices
Skill: A/B test prompts to optimize AI quality
Description: Students design controlled experiments to compare prompt effectiveness. **A/B Testing Process:** (1) Identify metric to optimize (accuracy, helpfulness, format compliance). (2) Create two prompt variants (A = original, B = modified). (3) Test both on same set of inputs. (4) Log results in table: input, prompt version, output, quality score (1-5). (5) Analyze which prompt performs better and why. **Example experiment:** Does adding "Be concise" improve response quality? Test 10 questions with/without this instruction and compare scores. They build an "AI Prompt Lab" project that automates A/B testing and generates comparison reports. **Key skill:** Systematic experimentation improves prompt engineering beyond guessing.

Dependencies:
* T23.G6.05: Maintain a prompt/response lab notebook using tables
* T23.G7.00: Apply chain-of-thought prompting for complex problems
* T23.G7.01: Create reusable XO prompt templates in lists



ID: T23.G7.18
Topic: T23 – Generative AI Practices
Skill: Evaluate AI model tradeoffs for task selection
Description: Students learn to evaluate and select appropriate AI tools based on tradeoffs. **Tradeoff dimensions:** (1) **Quality vs Speed:** High-quality models are slower (DALL-E 1024x1024 vs 256x256), fast models may sacrifice accuracy. (2) **Cost vs Capability:** More capable AI uses more resources (tokens, API calls), simpler AI is cheaper. (3) **Specificity vs Flexibility:** Specialized AI excels at one task, general AI handles more but less perfectly. (4) **Privacy vs Convenience:** Cloud AI is powerful but sends data externally, local models keep data private but may be limited. **Evaluation activity:** Students receive a project brief ("Build a classroom Q&A bot") and evaluate 3 options: (A) Simple keyword matching (fast, free, limited), (B) ChatGPT API (capable, costs per use), (C) Local simple ML (moderate, private). They create a decision matrix table: option, speed (1-5), quality (1-5), cost (1-5), privacy (1-5), total score, recommendation. **Key skill:** Choosing the right AI tool for the job is as important as using AI tools correctly.

Dependencies:
* T23.G6.15: Design guardrails for AI-generated content
* T23.G7.16: Design fallback strategies when AI fails
* T23.G7.17: A/B test prompts to optimize AI quality



ID: T23.G8.11A
Topic: T23 – Generative AI Practices
Skill: Combine multiple AI capabilities in integrated projects
Description: Students design projects integrating 3+ AI capabilities: (1) ChatGPT + web search + moderation for safe research assistant, (2) Face detection + hand tracking + ChatGPT for multimodal interface, (3) Image generation + vision analysis + text generation for creative storytelling. They learn system design: identifying which AI tools solve which problems, managing data flow, creating cohesive user experiences.

Dependencies:
* T23.G6.07.02: Use moderation blocks for image filtering
* T23.G7.12: Combine web search with ChatGPT for informed responses
* T23.G8.07.03: Build multimodal interaction projects
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.01.01
Topic: T23 – Generative AI Practices
Skill: Create project metadata tables for prompts
Description: Students create structured metadata tables for prompt generation with columns: sprite name, mechanic type, constraint description, target grade level. They learn how structured metadata enables automated prompt generation, populating tables systematically.

Dependencies:
* T23.G7.01: Create reusable XO prompt templates in lists
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.01.02
Topic: T23 – Generative AI Practices
Skill: Build prompt concatenation scripts from metadata
Description: Students write scripts reading metadata table values and concatenating them into XO prompts using `join` blocks. They construct prompts programmatically, handle optional fields, format properly, and test generated prompts for quality.

Dependencies:
* T23.G8.01.01: Create project metadata tables for prompts
* T23.G7.04: Enforce responsible-use rules for XO assistance



ID: T23.G8.01.03
Topic: T23 – Generative AI Practices
Skill: Integrate prompt builders with widget buttons
Description: Students connect prompt concatenation scripts to widget buttons for one-click generation. They build UIs where pressing a button generates structured XO prompts from metadata, provides visual feedback, validates completeness, and copies for immediate use.

Dependencies:
* T23.G8.01.02: Build prompt concatenation scripts from metadata
* T23.G7.04: Enforce responsible-use rules for XO assistance



ID: T23.G8.02
Topic: T23 – Generative AI Practices
Skill: Pair XO with automated tests to validate fixes
Description: Students write automated test harnesses (assertions, variable monitoring). They prompt XO for a fix, apply it, run tests, and report if fix passed. If not, they loop with refined prompts. Test log table: test name, XO attempt number, result, error message, refined prompt. This teaches iterative AI-assisted debugging with validation.

Dependencies:
* T23.G7.02: Run an XO-led code review with evidence
* T23.G8.01.03: Integrate prompt builders with widget buttons
* T08.G6.01: Use conditionals to control simulation steps



ID: T23.G8.03
Topic: T23 – Generative AI Practices
Skill: Compare XO-generated vs human-crafted versions
Description: Students implement two versions of a feature: one with XO/AI tools, one manually. They create metrics (code lines, frame rate, user preference) and analyze tradeoffs. Comparison table: feature name, AI metrics, human metrics, quality ratings, speed comparison, recommendation. This teaches critical evaluation of AI assistance value.

Dependencies:
* T23.G7.03: Combine XO storyboards with AI sprite generation
* T23.G7.04: Enforce responsible-use rules for XO assistance
* T23.G8.01.03: Integrate prompt builders with widget buttons



ID: T23.G8.04
Topic: T23 – Generative AI Practices
Skill: Implement AI usage tracking and policy enforcement (CAPSTONE)
Description: Students create comprehensive AI usage management: (1) contribution tracking table (timestamp, type, source, reviewer, status), (2) attribution display system, (3) approval workflow with conditionals, (4) usage statistics dashboard, (5) policy documentation. This demonstrates mastery of responsible AI integration.

Dependencies:
* T23.G7.04: Enforce responsible-use rules for XO assistance
* T23.G8.02: Pair XO with automated tests to validate fixes
* T23.G8.03: Compare XO-generated vs human-crafted versions



ID: T23.G8.05
Topic: T23 – Generative AI Practices
Skill: Build an interactive XO tutorial project (CAPSTONE)
Description: Students create interactive tutorial demonstrating XO best practices: (1) navigation system with step tracking, (2) example prompt library in tables, (3) interactive exercises with validation, (4) progress tracking, (5) comprehensive workflow documentation. This demonstrates mastery of teaching responsible AI-assisted coding.

Dependencies:
* T23.G7.05: Use XO to coach peers with rubric-based feedback
* T23.G8.04: Implement AI usage tracking and policy enforcement (CAPSTONE)



ID: T23.G8.06
Topic: T23 – Generative AI Practices
Skill: Build multi-person body tracking systems
Description: Students use `run 2D body part recognition single person [no] table [TABLENAME] debug [yes]` for multi-person mode. They differentiate between people using 'id' column and build multi-player games: dance games, cooperative challenges, competitive movement activities tracking each person independently.

Dependencies:
* T23.G7.08.04: Build comprehensive pose-based games
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.07.01
Topic: T23 – Generative AI Practices
Skill: Coordinate multiple CV data streams
Description: Students manage multiple computer vision blocks simultaneously (face + hand + body). They understand: each CV block writes to separate tables, data updates asynchronously at different rates, timing coordination may be needed. They build projects initializing and running multiple CV detections.

Dependencies:
* T23.G7.07.02: Create gesture vocabulary and multi-gesture interfaces
* T23.G7.08.04: Build comprehensive pose-based games
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.07.02
Topic: T23 – Generative AI Practices
Skill: Synchronize face, hand, and body detection
Description: Students build synchronization systems coordinating multiple CV streams. They handle differing detection rates, timestamp data, and combine sources coherently. They create projects responding to combined inputs ("trigger only when face centered AND hands raised").

Dependencies:
* T23.G8.07.01: Coordinate multiple CV data streams
* T23.G8.06: Build multi-person body tracking systems



ID: T23.G8.07.03
Topic: T23 – Generative AI Practices
Skill: Build multimodal interaction projects
Description: Students create comprehensive projects combining face, hand, and body detection for rich interaction. They build games where players use facial expressions, gestures, and body movements together. They design intuitive multimodal controls with clear feedback for each detection type.

Dependencies:
* T23.G8.07.02: Synchronize face, hand, and body detection



ID: T23.G8.08.01
Topic: T23 – Generative AI Practices
Skill: Create neural network models and add layers
Description: Students use `create NN model named [NAME]` and `add layer to NN model [NAME] input shape (SHAPE) output size (SIZE) activation [FUNCTION]` to build TensorFlow networks. They design architectures with appropriate input shapes and output sizes, experimenting with shallow vs deep networks.

Dependencies:
* T23.G7.15: Trace neural network architecture and training flow
* T23.G8.01.03: Integrate prompt builders with widget buttons



ID: T23.G8.08.02
Topic: T23 – Generative AI Practices
Skill: Compile neural networks with loss and optimizer
Description: Students use `compile NN model [NAME] loss [LOSS] optimizer [OPTIMIZER] learning rate (RATE)` to prepare models. They learn compilation connects architecture to training strategy, defining how errors are measured and weights adjusted.

Dependencies:
* T23.G8.08.01: Create neural network models and add layers



ID: T23.G8.08.03
Topic: T23 – Generative AI Practices
Skill: Choose activation functions for layers
Description: Students learn when to use activation functions: Relu (hidden layers, enables complex patterns), Sigmoid (binary classification output, 0-1 range), Softmax (multi-class output, probability distribution). They experiment with different activations and observe effects.

Dependencies:
* T23.G8.08.02: Compile neural networks with loss and optimizer



ID: T23.G8.08.04
Topic: T23 – Generative AI Practices
Skill: Select loss functions and optimizers
Description: Students select loss functions: Mean Squared Error (regression), Binary Crossentropy (binary classification), Categorical Crossentropy (multi-class). They choose optimizers: Adam (adaptive, versatile), SGD (simpler), Adagrad (sparse data). They configure learning rate and observe training effects.

Dependencies:
* T23.G8.08.03: Choose activation functions for layers



ID: T23.G8.09.01
Topic: T23 – Generative AI Practices
Skill: Prepare training and testing datasets
Description: Students prepare data for neural network training: split into training (70-80%) and testing (20-30%) sets, structure tables properly (features in columns, one row per example), normalize values. They understand training data teaches patterns while testing evaluates accuracy on unseen data.

Dependencies:
* T23.G7.10: Build prediction projects with KNN classifier
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.09.02
Topic: T23 – Generative AI Practices
Skill: Configure training parameters
Description: Students configure batch size (examples per update: 16-32 typical) and epochs (passes through data: 10-100 typical). They understand tradeoffs: smaller batches = more updates but noisier, more epochs = more learning but risk overfitting.

Dependencies:
* T23.G8.09.01: Prepare training and testing datasets
* T23.G8.08.02: Compile neural networks with loss and optimizer



ID: T23.G8.09.03
Topic: T23 – Generative AI Practices
Skill: Train neural networks and monitor progress
Description: Students use `train NN model [NAME] using table [TABLE] rows from [START] to [END] input columns [INPUTS] output column [OUTPUT] batch size [BATCH] epochs [EPOCHS]` to train networks. They monitor loss values decreasing over epochs and identify issues (loss not decreasing, overfitting).

Dependencies:
* T23.G8.09.02: Configure training parameters
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.09.04
Topic: T23 – Generative AI Practices
Skill: Make predictions and evaluate accuracy
Description: Students use `predict using NN model [NAME] for table [TABLENAME] rows from [START] to [END] input columns [INPUTS] output column [OUTPUT]` for predictions. They evaluate by comparing predictions to known values in test data, calculating accuracy metrics (percentage correct, average error), and analyzing error patterns.

Dependencies:
* T23.G8.09.03: Train neural networks and monitor progress
* T08.G6.01: Use conditionals to control simulation steps



ID: T23.G8.09.05
Topic: T23 – Generative AI Practices
Skill: Save and load trained models
Description: Students use `save NN model named [NAME]` and `load NN model named [NAME]` to persist models. They train once, save, then load for predictions without retraining. This enables complete ML pipelines and production deployment.

Dependencies:
* T23.G8.09.04: Make predictions and evaluate accuracy



ID: T23.G8.10
Topic: T23 – Generative AI Practices
Skill: Create semantic vector databases with Pinecone
Description: Students use `create semantic database from table [TABLE]` to build semantic search with Pinecone. They learn table requirements ('key' column for unique IDs) and how text becomes embedding vectors (numerical representations capturing meaning). Pinecone handles storing and searching vectors efficiently.

Dependencies:
* T23.G7.11: Compare semantic search vs keyword matching
* T23.G8.01.03: Integrate prompt builders with widget buttons
* T07.G6.01: Trace nested loops with variable bounds



ID: T23.G8.11.01
Topic: T23 – Generative AI Practices
Skill: Build basic semantic search projects
Description: Students use `search semantic database with [QUERY] store top (K) in table [TABLE]` to query vector databases. They build smart search applications finding relevant information even when users phrase questions differently ("dog breeds" matches "types of canines").

Dependencies:
* T23.G8.10: Create semantic vector databases with Pinecone



ID: T23.G8.11.02
Topic: T23 – Generative AI Practices
Skill: Add metadata filters to semantic searches
Description: Students enhance searches with metadata filtering using `filter by column [FIELD] of value [VALUE]` and `where [CONDITION]` parameters. They combine semantic similarity with exact matching ("science questions WHERE grade=5"), creating sophisticated knowledge retrieval.

Dependencies:
* T23.G8.11.01: Build basic semantic search projects
* T08.G6.01: Use conditionals to control simulation steps



ID: T23.G8.12.01
Topic: T23 – Generative AI Practices
Skill: Trace RAG architecture and data flow
Description: Students trace Retrieval Augmented Generation data flow: (1) retrieval (semantic/web search finding relevant info), (2) augmentation (adding context to prompts), (3) generation (ChatGPT creating informed responses). They build a RAG diagram project that visualizes each stage with example data, tracing how RAG improves AI by grounding responses in specific knowledge and reducing hallucinations.

Dependencies:
* T23.G7.11: Compare semantic search vs keyword matching
* T23.G7.12: Combine web search with ChatGPT for informed responses



ID: T23.G8.12.02
Topic: T23 – Generative AI Practices
Skill: Build knowledge retrieval pipeline
Description: Students build RAG retrieval: query semantic databases and web search, extract snippets, rank by relevance. They combine multiple sources (semantic for stored knowledge, web for current info), filter duplicates, select top-K items for ChatGPT context.

Dependencies:
* T23.G8.11.02: Add metadata filters to semantic searches
* T23.G8.12.01: Trace RAG architecture and data flow



ID: T23.G8.12.03
Topic: T23 – Generative AI Practices
Skill: Integrate retrieval with ChatGPT generation
Description: Students complete RAG systems integrating retrieval with ChatGPT. They format context for prompts, construct augmented prompts with user questions + relevant context, and generate informed responses. They build Q&A systems, research assistants, and specialized chatbots with domain knowledge.

Dependencies:
* T23.G7.12: Combine web search with ChatGPT for informed responses
* T23.G8.12.02: Build knowledge retrieval pipeline



ID: T23.G8.13
Topic: T23 – Generative AI Practices
Skill: Build ML-powered interactive capstone project (CAPSTONE)
Description: Students create comprehensive capstones integrating ML with interaction: (1) gesture-controlled game using CV + KNN for move recognition, (2) smart chatbot with semantic search + NN sentiment analysis, (3) multi-modal art creator with ChatGPT + DALL-E + CV. They demonstrate mastery by combining 3+ AI capabilities in cohesive, well-documented, ethically-designed projects.

Dependencies:
* T23.G8.07.03: Build multimodal interaction projects
* T23.G8.09.05: Save and load trained models
* T23.G8.12.03: Integrate retrieval with ChatGPT generation



ID: T23.G8.14
Topic: T23 – Generative AI Practices
Skill: Architect large-scale AI system with error handling (CAPSTONE)
Description: Students design and build a production-quality AI system with: (1) multiple AI components working together (CV + ChatGPT + semantic search), (2) comprehensive error handling using fallback strategies from G7.16, (3) performance monitoring logging response times and success rates, (4) graceful degradation when components fail, (5) user-facing status indicators. This demonstrates mastery of building robust, scalable AI applications that handle real-world complexity and failure modes.

Dependencies:
* T23.G7.16: Design fallback strategies when AI fails
* T23.G8.11A: Combine multiple AI capabilities in integrated projects
* T23.G8.13: Build ML-powered interactive capstone project (CAPSTONE)



ID: T23.G8.15
Topic: T23 – Generative AI Practices
Skill: Implement prompt injection defense patterns
Description: Students learn about prompt injection attacks where malicious users try to override AI instructions. They identify attack patterns: (1) "ignore previous instructions" attempts, (2) role-playing manipulation ("pretend you are..."), (3) delimiter injection to break prompt structure. They implement defense strategies: input sanitization using text filters, prompt structure hardening with clear role boundaries, output validation checking for policy violations. They build a chatbot with injection defenses that logs and rejects malicious attempts.

Dependencies:
* T23.G6.07.01: Use moderation blocks for text filtering
* T23.G6.08: Build a multi-turn chatbot using LLM sessions
* T23.G8.04: Implement AI usage tracking and policy enforcement (CAPSTONE)



ID: T23.G8.16
Topic: T23 – Generative AI Practices
Skill: Design AI output caching strategies for performance
Description: Students implement caching to reduce AI API calls and improve response times. They design cache structures using tables: cache key (prompt hash), cached response, timestamp, hit count. They implement cache strategies: (1) exact match caching for repeated prompts, (2) TTL (time-to-live) expiration for freshness, (3) cache invalidation when content updates. They build a project measuring cache hit rates and demonstrating 10x+ speedup for repeated queries. **Key skill:** Production AI systems must optimize API costs and latency.

Dependencies:
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G7.12: Combine web search with ChatGPT for informed responses
* T23.G8.01.01: Create project metadata tables for prompts



ID: T23.G8.17
Topic: T23 – Generative AI Practices
Skill: Implement rate limiting and quota management for AI APIs
Description: Students implement rate limiting to manage AI API usage and prevent abuse. They track API calls in tables: timestamp, API type, user/session, token count. They implement: (1) per-minute request limits using timestamp checking, (2) daily quota tracking with reset logic, (3) graceful degradation showing "please wait" messages when limits reached. They build a project demonstrating rate limiting that queues requests and provides user feedback. **Key skill:** Production AI systems must manage costs and prevent abuse.

Dependencies:
* T23.G4.09: Read from and write to CreatiCode tables
* T23.G7.16: Design fallback strategies when AI fails
* T23.G8.02: Pair XO with automated tests to validate fixes



ID: T23.G8.18
Topic: T23 – Generative AI Practices
Skill: Manage context windows for long conversations
Description: Students learn that LLMs have limited context windows (maximum conversation length). They implement context management strategies: (1) conversation summarization - periodically condensing earlier messages, (2) sliding window - keeping only last N messages, (3) importance-based pruning - keeping key messages and removing routine ones. They track token usage and build a chatbot that maintains coherent long conversations by intelligently managing context. **Key skill:** Production chatbots must handle conversations that exceed context limits.

Dependencies:
* T23.G6.08: Build a multi-turn chatbot using LLM sessions
* T23.G7.01: Create reusable XO prompt templates in lists
* T23.G8.12.03: Integrate retrieval with ChatGPT generation



ID: T23.G8.19
Topic: T23 – Generative AI Practices
Skill: Design AI agents with tool use capabilities (CAPSTONE)
Description: Students design AI agents that can use tools to accomplish tasks autonomously. **Agent architecture:** (1) **Goal decomposition:** Break complex goal into sub-tasks. (2) **Tool selection:** Match sub-tasks to available tools (web search, image generation, calculations, file operations). (3) **Execution loop:** Call tool → evaluate result → decide next action → repeat until goal achieved. (4) **Error recovery:** Handle tool failures and unexpected results. They implement a simple agent that can: search for information, generate images based on search results, and compile findings into a report. **Key skill:** AI agents represent the future of AI systems - understanding agent architecture prepares students for emerging AI development patterns.

Dependencies:
* T23.G7.16: Design fallback strategies when AI fails
* T23.G8.14: Architect large-scale AI system with error handling (CAPSTONE)
* T23.G8.12.03: Integrate retrieval with ChatGPT generation



ID: T23.G8.20
Topic: T23 – Generative AI Practices
Skill: Coordinate multiple AI agents for complex tasks (CAPSTONE)
Description: Students design systems where multiple specialized AI agents collaborate. **Multi-agent patterns:** (1) **Specialist agents:** Research agent (gathers info), Writer agent (generates text), Critic agent (reviews quality), Editor agent (refines output). (2) **Coordination:** Orchestrator routes tasks to appropriate agents and aggregates results. (3) **Communication:** Agents share context through structured messages. (4) **Conflict resolution:** Handle disagreements between agents (e.g., Critic rejects Writer's output). They build a "Content Creation Pipeline" with 3+ agents that collaborate to research a topic, write content, review it, and generate matching visuals. **Key skill:** Multi-agent systems enable solving complex problems that single AI cannot handle - this is cutting-edge AI architecture.

Dependencies:
* T23.G8.19: Design AI agents with tool use capabilities (CAPSTONE)
* T23.G8.13: Build ML-powered interactive capstone project (CAPSTONE)
* T23.G8.07.03: Build multimodal interaction projects



ID: T23.G8.21
Topic: T23 – Generative AI Practices
Skill: Design human oversight systems for AI decisions
Description: Students design systems that maintain human control over consequential AI decisions. **Oversight patterns:** (1) **Human-in-the-loop:** AI suggests, human approves before action is taken. (2) **Human-on-the-loop:** AI acts autonomously but human monitors and can intervene. (3) **Human-over-the-loop:** Human sets policies, AI operates within constraints. **Implementation:** Students build a project with tiered oversight: low-risk actions (AI acts freely), medium-risk (AI suggests, user confirms with button), high-risk (AI explains reasoning, requires explicit approval, logs decision). They create a "Risk Assessment" function that categorizes AI actions. **Oversight table:** action type, risk level, approval required, human reviewer, decision timestamp, override used. **Key skill:** Responsible AI deployment requires humans to maintain meaningful control - especially for decisions affecting people's lives.

Dependencies:
* T23.G7.18: Evaluate AI model tradeoffs for task selection
* T23.G8.04: Implement AI usage tracking and policy enforcement (CAPSTONE)
* T23.G8.14: Architect large-scale AI system with error handling (CAPSTONE)



ID: T23.G8.22
Topic: T23 – Generative AI Practices
Skill: Build AI monitoring dashboards for production systems
Description: Students build dashboards that monitor AI system health and performance. **Metrics to track:** (1) **Performance:** Response time, success rate, error rate per AI component. (2) **Quality:** Average quality scores, hallucination detection counts, user satisfaction ratings. (3) **Usage:** Request volume, token consumption, cost per interaction. (4) **Safety:** Moderation triggers, guardrail activations, blocked requests. **Dashboard components:** Real-time graphs using variables (updated each frame), summary statistics tables, alert thresholds (if error_rate > 10% then display warning), historical logs for debugging. Students build a "AI System Health" dashboard that updates live as their AI chatbot runs, displaying success rate, average response time, and moderation blocks. **Key skill:** Production AI systems require continuous monitoring - you can't improve what you can't measure.

Dependencies:
* T23.G8.04: Implement AI usage tracking and policy enforcement (CAPSTONE)
* T23.G8.17: Implement rate limiting and quota management for AI APIs
* T23.G7.17: A/B test prompts to optimize AI quality



ID: T23.G8.23
Topic: T23 – Generative AI Practices
Skill: Implement graceful AI degradation patterns
Description: Students implement systems that degrade gracefully when AI components fail or become unavailable. **Degradation levels:** (1) **Full functionality:** All AI features working normally. (2) **Reduced functionality:** Some AI features disabled, core features continue with simpler alternatives. (3) **Manual fallback:** AI unavailable, user can complete task manually with guidance. (4) **Offline mode:** Cached responses for common queries, static content only. **Implementation:** Students build a chatbot with degradation: if ChatGPT fails → try simpler keyword matching, if that fails → show FAQ list, if internet unavailable → show cached common answers. They create a "System Status" indicator showing current degradation level. They log degradation events and recovery. **Error cascade prevention:** Ensure one failing component doesn't crash the entire system. **Key skill:** Robust AI systems must work (at some level) even when AI APIs are slow, unavailable, or returning errors.

Dependencies:
* T23.G7.16: Design fallback strategies when AI fails
* T23.G8.14: Architect large-scale AI system with error handling (CAPSTONE)
* T23.G8.21: Design human oversight systems for AI decisions



# T24 - Data Representation (Phase 10 Major Overhaul - November 2025)
#
# PHASE 10 COMPREHENSIVE IMPROVEMENTS:
# This phase transforms T24 from a tool-focused curriculum into a DATA THINKING
# curriculum emphasizing computational thinking, problem-solving, and AI-era readiness.
#
# 1. K-2 DATA THINKING FOUNDATION (12 new skills):
#    - T24.GK.00: Recognize that data represents real things
#    - T24.GK.07: Predict what happens when data is lost
#    - T24.G1.07: Verify collected data matches reality
#    - T24.G1.08: Explain why the same thing needs different data for different purposes
#    - T24.G2.08: Design a simple data collection plan before collecting
#    - T24.G2.09: Compare data about the same thing from two sources
#    - Enhanced all K-2 skills with prediction-verification cycles
#
# 2. GRADE 3 BRIDGE ENHANCEMENT (5 new sub-skills):
#    - T24.G3.00.00: Map picture table elements to code block concepts
#    - T24.G3.00.03: Predict code output before running
#    - T24.G3.00.04: Explain the translation from visual to code
#    - Added explicit scaffolding: Visual → Predict → Code → Verify → Reflect
#
# 3. DATA DESIGN THINKING THREAD (8 new skills):
#    - "Justify your representation choice" skills at G3, G4, G5, G6
#    - "Compare multiple representations" skills throughout
#    - Design-before-implementation pattern reinforced
#
# 4. SYSTEMATIC DEBUGGING PROGRESSION (9 new skills):
#    - T24.G3.10: Use trace tables to track variable changes step-by-step
#    - T24.G4.13: Create debugging checklists for data errors
#    - T24.G5.11: Debug by comparing expected vs actual data states
#    - T24.G6.11: Diagnose data corruption using systematic isolation
#    - T24.G7.10: Debug multi-table relationships with integrity checks
#    - T24.G8.12: Debug data pipelines using checkpoint validation
#
# 5. DATA ETHICS & PRIVACY THREAD (7 new skills):
#    - T24.G4.14: Identify personal vs non-personal data
#    - T24.G5.12: Design data collection with user consent in mind
#    - T24.G6.12: Implement data anonymization techniques
#    - T24.G7.11: Evaluate privacy implications of data sharing
#    - T24.G8.13: Design data retention and deletion policies
#
# 6. ENCODING & COMPRESSION DEPTH (6 new skills):
#    - T24.G4.15: Compare fixed-length vs variable-length encoding
#    - T24.G5.13: Implement simple Huffman-style frequency encoding
#    - T24.G6.13: Analyze lossy vs lossless compression tradeoffs quantitatively
#    - T24.G7.12: Implement dictionary-based compression (LZW concepts)
#    - T24.G8.14: Design multi-dimensional data encoding for ML features
#
# 7. REAL-TIME & STREAMING DATA (G7-G8):
#    - Enhanced T24.G8.06 with circular buffer implementation
#    - T24.G7.13: Handle data synchronization conflicts
#    - T24.G8.15: Implement windowed aggregation for streaming data
#
# 8. DEPENDENCY FIXES:
#    - Fixed 8 X-2 rule violations throughout
#    - Improved intra-topic skill sequencing
#    - All cross-topic dependencies preserved unchanged
#
# 9. CONSOLIDATIONS:
#    - Merged T24.G5.08.03 and T24.G5.08.04 (ascending/descending sort)
#    - Merged T24.G7.03.02.01 and T24.G7.03.02.02 (CSV load steps)
#    - Streamlined G5.06 table operations sequence
#
# Total: ~195 skills (net +30 skills for depth, debugging, ethics, and thinking)

ID: T24.GK.00
Topic: T24 – Data Representation
Skill: Recognize that data represents real things
Description: **Student task:** Look at 4 pairs of items: a real apple and a picture of an apple, a real dog and a drawing of a dog, 3 blocks and the numeral "3", a sunny window and a sun symbol. For each pair, tap YES if the picture/symbol "stands for" the real thing. **Visual scenario:** Split-screen showing real objects on left, representations on right. Students connect each pair with a line. **Learning goal:** Data (pictures, symbols, numbers) represents real-world things—it's not the thing itself, but information about it. _Implementation note: Line-drawing to match pairs. Audio explains "This picture tells us about the apple." Auto-graded by correct pairings. CSTA: DA-01._

Dependencies: None




ID: T24.GK.01
Topic: T24 – Data Representation
Skill: Sort items into pictures, words, and numerals
Description: **Student task:** Look at 9 cards showing pictures (drawings), words (labels), and numerals (number symbols). Drag each card into the correct bin: Pictures, Words, or Numbers. **Visual scenario:** Cards show: apple drawing, "apple" text, "3", cat drawing, "dog" text, "7", tree drawing, "ball" text, "5". Three bins labeled with icons. **Learning goal:** Recognize that data appears in multiple forms. _Implementation note: Drag-drop sorting; audio reads labels on hover. Auto-graded by correct bin placement. CSTA: DA-01._

Dependencies:
* T24.GK.00: Recognize that data represents real things




ID: T24.GK.02
Topic: T24 – Data Representation
Skill: Represent quantities with symbols
Description: **Student task:** Count the items in a picture (1-5 objects). Then drag the matching number of symbols (dots, tally marks, or stickers) onto a card. **Visual scenario:** Picture shows 4 apples. Students drag 4 dot symbols onto an empty card. **Learning goal:** Symbols encode counts—same quantity, different representation. _Implementation note: Drag-drop with count validation. Auto-graded by correct symbol count. CSTA: DA-01._

Dependencies:
* T24.GK.01: Sort items into pictures, words, and numerals




ID: T24.GK.03
Topic: T24 – Data Representation
Skill: Create a two-symbol legend
Description: **Student task:** Given two categories (sunny/rainy), pick a symbol for each and drag them to create a legend card ("☀ = sunny", "🌧 = rainy"). Then label 4 weather pictures using your symbols. **Visual scenario:** Legend template with empty boxes; weather pictures to label. **Learning goal:** Legends map symbols to meanings. _Implementation note: Symbol selection + drag-to-label. Auto-graded by correct symbol-meaning pairs. CSTA: DA-01._

Dependencies:
* T24.GK.02: Represent quantities with symbols




ID: T24.GK.04
Topic: T24 – Data Representation
Skill: Sort picture cards into labeled bins
Description: **Student task:** Look at 8 animal picture cards. Drag each card into the correct bin: "Farm Animals" or "Zoo Animals". **Visual scenario:** Cards show: cow, lion, chicken, elephant, pig, giraffe, sheep, zebra. Two bins with farm/zoo icons. **Learning goal:** Classification organizes data into categories. _Implementation note: Drag-drop sorting with audio feedback. Auto-graded by correct placement. CSTA: DA-01._

Dependencies:
* T24.GK.01: Sort items into pictures, words, and numerals




ID: T24.GK.05
Topic: T24 – Data Representation
Skill: Predict which symbol represents more
Description: **Student task:** Look at two cards showing the same quantity in different symbols (4 dots vs 4 tally marks). Tap YES if they show the same amount, or NO if different. **Visual scenario:** Side-by-side cards with different symbol types but same count. **Learning goal:** Same data, different representations—quantity stays the same. _Implementation note: Binary choice with audio explanation. Auto-graded by selection. CSTA: DA-01._

Dependencies:
* T24.GK.02: Represent quantities with symbols




ID: T24.GK.06
Topic: T24 – Data Representation
Skill: Match pictures to on/off switch patterns
Description: **Student task:** Look at 4 light bulb picture cards showing on (yellow/glowing) or off (gray/dark) states. Match each pattern to the correct row of switches (up=on, down=off). **Visual scenario:** Left side shows bulb patterns like [on, off, on]; right side shows switch positions. Students draw lines to match. **Learning goal:** Binary states (on/off) can represent information—foundation for understanding binary data. _Implementation note: Line-drawing matching activity; 4 patterns with 2-3 bulbs each. Auto-graded by correct pairings. CSTA: DA-01._

Dependencies:
* T24.GK.03: Create a two-symbol legend




ID: T24.GK.07
Topic: T24 – Data Representation
Skill: Predict what happens when data is lost
Description: **Student task:** Look at a story: Sam made a tally chart counting birds, but then it rained and washed away half the marks. What problem does Sam have now? Tap the picture that shows what Sam can't do anymore: (A) count the total birds, (B) draw a bird, (C) see the sky. **Visual scenario:** Before/after images showing complete vs damaged tally chart. Three picture options. **Correct answer:** A. **Learning goal:** When data is lost or damaged, we lose information and can't answer questions. _Implementation note: MCQ with pictures. Audio narrates the story. Auto-graded by selection. CSTA: DA-01._

Dependencies:
* T24.GK.02: Represent quantities with symbols
* T24.GK.04: Sort picture cards into labeled bins




ID: T24.G1.01
Topic: T24 – Data Representation
Skill: Record events using tally marks
Description: **Student task:** Watch a short animation showing fish swimming by. Make a tally mark each time a fish appears (tap to add mark). After the animation, tap the numeral that matches your tally count. **Visual scenario:** Animation area shows 4 fish swimming past one by one. Tally area below. Number choices: 2, 3, 4, 5. **Correct answer:** 4. **Learning goal:** Record events as they happen with symbols. _Implementation note: Tap-to-tally + number selection. Auto-graded by count match. CSTA: DA-01._

Dependencies:
* T24.GK.02: Represent quantities with symbols




ID: T24.G1.02
Topic: T24 – Data Representation
Skill: Organize data into picture rows and columns
Description: **Student task:** Arrange 6 fruit picture cards into a 2×3 table where rows are fruit types (apple, banana) and columns count how many of each. **Visual scenario:** Blank 2-row table; cards to drag: 3 apples, 3 bananas. Row labels visible. **Learning goal:** Tables organize data into rows (categories) and columns (attributes). _Implementation note: Drag-drop into table cells. Auto-graded by correct placement. CSTA: DA-01._

Dependencies:
* T24.G1.01: Record events using tally marks




ID: T24.G1.03
Topic: T24 – Data Representation
Skill: Express the same fact in words and numbers
Description: **Student task:** Match cards showing the same quantity in three forms: picture (5 stars), numeral ("5"), and words ("five"). Connect all three that represent the same amount. **Visual scenario:** 3 sets of cards scattered; students draw lines to match. **Learning goal:** Same information can be represented multiple ways. _Implementation note: Line-drawing to connect matches. Auto-graded by correct pairings. CSTA: DA-01._

Dependencies:
* T24.G1.01: Record events using tally marks




ID: T24.G1.04
Topic: T24 – Data Representation
Skill: Compare two simple data displays
Description: **Student task:** Look at the same data shown two ways: (A) tally marks, (B) picture table. Tap which display answers "How many red?" faster. **Visual scenario:** Side-by-side displays showing color counts. **Learning goal:** Different representations answer different questions better. _Implementation note: Binary choice with explanation. Auto-graded by selection. CSTA: DA-01._

Dependencies:
* T24.G1.02: Organize data into picture rows and columns
* T24.G1.03: Express the same fact in words and numbers




ID: T24.G1.05
Topic: T24 – Data Representation
Skill: Trace data from picture to table
Description: **Student task:** Look at a picture showing 3 red balls and 2 blue balls. Then look at a table with "Color" and "Count" columns. Tap the cell that shows "3" belongs to. **Visual scenario:** Picture above, partially filled table below. Students identify where "3" goes. **Correct answer:** The "Red" row, "Count" column. **Learning goal:** Trace how visual data becomes table data. _Implementation note: Tap-to-select cell. Auto-graded by correct cell selection. CSTA: DA-01._

Dependencies:
* T24.G1.02: Organize data into picture rows and columns




ID: T24.G1.06
Topic: T24 – Data Representation
Skill: Decode messages using two-symbol codes
Description: **Student task:** Use a code key (A=●○, B=●●, C=○●, D=○○) to decode a 3-letter secret message shown as dot patterns. Tap the letter cards in order to spell the word. **Visual scenario:** Code key on left showing 4 letter mappings; encoded message "●● ○● ●○" on right. Answer: "BCA". **Learning goal:** Symbols can encode letters—introduction to encoding schemes. _Implementation note: Tap letter buttons in correct sequence; 3-4 letter words. Auto-graded by correct letter sequence. CSTA: DA-01._

Dependencies:
* T24.GK.06: Match pictures to on/off switch patterns
* T24.G1.03: Express the same fact in words and numbers




ID: T24.G1.07
Topic: T24 – Data Representation
Skill: Verify collected data matches reality
Description: **Student task:** You counted 5 red crayons and wrote "5" on your chart. Now recount the crayons in the picture. Does your data match? Tap YES if correct, or tap the correct number if wrong. **Visual scenario:** Shows a chart with "5 red crayons" and an image with 4 red crayons. Students must identify the mismatch. **Correct answer:** 4 (data was wrong). **Learning goal:** Always check that recorded data actually matches reality—data can have errors. _Implementation note: Verification task with number correction. Auto-graded by correct identification. CSTA: DA-01._

Dependencies:
* T24.G1.01: Record events using tally marks
* T24.G1.03: Express the same fact in words and numbers




ID: T24.G1.08
Topic: T24 – Data Representation
Skill: Explain why different questions need different data
Description: **Student task:** Two friends want to know about your pet. Friend A asks "What color is your pet?" Friend B asks "How old is your pet?" Match each question to the type of data needed: color words OR numbers. **Visual scenario:** Two friend characters with speech bubbles; data type cards (color palette, number symbols) to drag to each. **Learning goal:** Different questions require different types of data—we choose what to record based on what we want to know. _Implementation note: Drag-to-match with two pairs. Auto-graded by correct matching. CSTA: DA-01._

Dependencies:
* T24.G1.04: Compare two simple data displays
* T24.GK.01: Sort items into pictures, words, and numerals




ID: T24.G2.01
Topic: T24 – Data Representation
Skill: Add meaningful labels to a category chart
Description: **Student task:** Look at a picture bar chart with labels "Column A" and "Column B". The chart shows apple and banana counts. Replace the generic labels with "Apples" and "Bananas" by dragging the correct label to each column. **Visual scenario:** Bar chart with placeholder labels; label cards to drag. **Learning goal:** Clear labels help others understand data. _Implementation note: Drag-drop label replacement. Auto-graded by correct labels. CSTA: DA-02._

Dependencies:
* T24.G1.02: Organize data into picture rows and columns




ID: T24.G2.02
Topic: T24 – Data Representation
Skill: Convert between timeline, table, and sentence formats
Description: **Student task:** View a three-step story (wake up → eat breakfast → go to school). Represent it three ways: (1) arrange timeline cards in order, (2) fill a two-column table with Time + Action, (3) tap the correct sentence version. **Visual scenario:** Three work areas for each format; same story data in each. **Learning goal:** Same information translates across formats. _Implementation note: Multi-format conversion task. Auto-graded by all three correct. CSTA: DA-02._

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed
* T24.G1.03: Express the same fact in words and numbers




ID: T24.G2.03
Topic: T24 – Data Representation
Skill: Select the best representation for a question
Description: **Student task:** Match each question to the best representation type. Questions: "How many of each color?" "What happened first?" "Who lives where?" Answers: table, timeline, map. **Visual scenario:** Question cards on left, representation icons on right. Draw lines to match. **Learning goal:** Different questions need different representations. _Implementation note: Line-drawing to match. Auto-graded by correct pairings. CSTA: DA-02._

Dependencies:
* T24.G1.04: Compare two simple data displays
* T24.G2.02: Convert between timeline, table, and sentence formats




ID: T24.G2.04
Topic: T24 – Data Representation
Skill: Create records with two attributes
Description: **Student task:** Create flashcards combining two pieces of information. Given "Lion" and "Savanna", drag both to create a record card "Lion - Savanna". Create 4 animal-habitat pairs. **Visual scenario:** Animal cards and habitat cards; record card templates. **Learning goal:** Records pair multiple attributes about one item. _Implementation note: Drag-combine to create pairs. Auto-graded by correct pairings. CSTA: DA-02._

Dependencies:
* T24.G1.02: Organize data into picture rows and columns




ID: T24.G2.05
Topic: T24 – Data Representation
Skill: Identify missing data in a picture chart
Description: **Student task:** Look at a chart with some cells empty. Tap all the empty cells and explain what information is missing. **Visual scenario:** Pet count chart with 2 of 6 cells empty. Students tap empty cells. **Learning goal:** Missing data makes charts incomplete and less useful. _Implementation note: Tap-to-select empty cells. Auto-graded by finding all gaps. CSTA: DA-02._

Dependencies:
* T24.G2.01: Add meaningful labels to a category chart
* T24.G2.04: Create records with two attributes




ID: T24.G2.06
Topic: T24 – Data Representation
Skill: Predict what happens when data format changes
Description: **Student task:** Look at data shown as tally marks. If we convert it to a bar chart, predict what the chart will look like. Tap the correct bar chart option. **Visual scenario:** Tally marks showing Red:4, Blue:2, Green:3. Three bar chart options (one correct). **Learning goal:** Predict data transformation outcomes. _Implementation note: MCQ with visual options. Auto-graded by selection. CSTA: DA-02._

Dependencies:
* T24.G1.04: Compare two simple data displays
* T24.G2.03: Select the best representation for a question




ID: T24.G2.07
Topic: T24 – Data Representation
Skill: Create secret codes with symbol-to-letter mappings
Description: **Student task:** Create your own 4-letter code by assigning unique shape symbols (★, ♦, ●, ▲) to letters (A, B, C, D). Then use your code to encode a 3-letter word for a partner to decode. **Visual scenario:** Empty code table with letter column and symbol column. Students drag shapes to create mappings, then encode "CAB" using their code. **Learning goal:** Design your own encoding scheme—data representation is a creative choice. _Implementation note: Drag-drop to create mapping table, then apply to encode word. Auto-graded by valid unique mapping and correct encoding. CSTA: DA-02._

Dependencies:
* T24.G1.06: Decode messages using two-symbol codes
* T24.G2.04: Create records with two attributes




ID: T24.G2.08
Topic: T24 – Data Representation
Skill: Design a simple data collection plan before collecting
Description: **Student task:** You want to find out which snack your class likes best. Before collecting data, plan: (1) What question will you ask? (2) What answers will you record? (3) How will you organize it? Drag the correct plan steps into order, then match each step to an example. **Visual scenario:** Plan step cards ("Ask the question", "Write down answers", "Make a chart") and example cards showing each in action. Students sequence steps and match to examples. **Learning goal:** Good data collection starts with a plan—decide what to collect and how to organize it before you start. _Implementation note: Sequencing + matching task. Auto-graded by correct order and pairings. CSTA: DA-02._

Dependencies:
* T24.G2.03: Select the best representation for a question
* T24.G1.08: Explain why different questions need different data




ID: T24.G2.09
Topic: T24 – Data Representation
Skill: Compare data about the same thing from two sources
Description: **Student task:** Two students counted birds at the park. Alex's chart says 5 robins. Sam's chart says 3 robins. Look at the picture of the park with birds. Whose data is correct? Why might they be different? Tap the correct answer and the best reason. **Visual scenario:** Park scene with 5 robins; two charts showing different counts; MCQ for correct answer and reason (counted at different times, one made a mistake, etc.). **Learning goal:** Different data about the same thing can exist—we need to check which is accurate and understand why differences occur. _Implementation note: MCQ with reasoning. Auto-graded by selections. CSTA: DA-02._

Dependencies:
* T24.G1.07: Verify collected data matches reality
* T24.G2.05: Identify missing data in a picture chart




ID: T24.G3.00
Topic: T24 – Data Representation
Skill: Arrange given blocks to match a picture table
Description: **Bridge skill from picture-based to code-based:** Students see a picture table showing Name and Age columns with 3 rows of data. They arrange pre-made CreatiCode blocks (create table, add row) in the correct order to recreate the picture table digitally. This bridges G2 picture tables to G3 coding.

Dependencies:
* T24.G2.04: Create records with two attributes
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence




ID: T24.G3.00.01.01
Topic: T24 – Data Representation
Skill: Create and name a variable in CreatiCode
Description: Students use the 'Make a Variable' button in CreatiCode to create new variables. They practice choosing meaningful names (like 'score' not 'x') and explain why descriptive names help others understand the code. They create at least three variables with descriptive names.

Dependencies:
* T24.G3.00: Arrange given blocks to match a picture table




ID: T24.G3.00.01.02
Topic: T24 – Data Representation
Skill: Assign values to variables using set blocks
Description: Students use 'set [variable] to [value]' blocks to assign values to variables. They practice setting variables to numbers and text strings, tracing how 'set' replaces the previous value completely.

Dependencies:
* T24.G3.00.01.01: Create and name a variable in CreatiCode




ID: T24.G3.00.01.03
Topic: T24 – Data Representation
Skill: Modify variables using change blocks
Description: Students use 'change [variable] by [amount]' blocks to increment or decrement numeric variables. They trace the difference between 'set' (replace value) vs 'change' (add to value) and predict outcomes in a counting script.

Dependencies:
* T24.G3.00.01.02: Assign values to variables using set blocks




ID: T24.G3.00.01.04
Topic: T24 – Data Representation
Skill: Display and trace variable monitors on stage
Description: Students check and uncheck variable checkboxes to show/hide variable monitors on stage. They trace how variable values update in real-time when scripts run, learning to visualize variable state during program execution.

Dependencies:
* T24.G3.00.01.03: Modify variables using change blocks




ID: T24.G3.00.02.01
Topic: T24 – Data Representation
Skill: Create and name a list in CreatiCode
Description: Students use the 'Make a List' button in CreatiCode to create new lists. They practice naming lists descriptively (like 'playerNames' not 'list1') and explain that lists store many values in order, unlike variables which store one.

Dependencies:
* T24.G3.00.01.04: Display and trace variable monitors on stage




ID: T24.G3.00.02.02
Topic: T24 – Data Representation
Skill: Add items to the end of a list
Description: Students use 'add [item] to [list]' blocks to append items to the end of a list. They practice adding multiple items and trace that each new item appears at the bottom of the list monitor.

Dependencies:
* T24.G3.00.02.01: Create and name a list in CreatiCode




ID: T24.G3.00.02.03
Topic: T24 – Data Representation
Skill: Display list monitors and read index numbers
Description: Students check list checkboxes to show list monitors on stage. They trace that list monitors display items with index numbers (1, 2, 3...) and practice identifying which item is at which position.

Dependencies:
* T24.G3.00.02.02: Add items to the end of a list




ID: T24.G3.01.01
Topic: T24 – Data Representation
Skill: Build a list from scratch using add blocks
Description: Students build complete lists by adding items one at a time in a green-flag script. They create themed lists (5 favorite foods, 4 color names) and verify the list contents match their intended order.

Dependencies:
* T24.G3.00.02.03: Display list monitors and read index numbers




ID: T24.G3.01.02
Topic: T24 – Data Representation
Skill: Transfer survey data from paper to list variables
Description: Students take physical survey responses (sticky notes, tally sheets) and enter each response into a CreatiCode list using 'add item to list' blocks. They create named lists (e.g., 'favoriteColors') and populate them with real survey data, bridging analog and digital data collection.

Dependencies:
* T24.G3.01.01: Build a list from scratch using add blocks
* T24.G2.01: Add meaningful labels to a category chart




ID: T24.G3.02.01
Topic: T24 – Data Representation
Skill: Store numeric data in variables for counting and scoring
Description: Students create number variables (score, lives, timer) and use them to track numeric data. They practice 'set' to initialize values and 'change' to update them, building a simple score counter that increases when clicked.

Dependencies:
* T24.G3.01.02: Transfer survey data from paper to list variables




ID: T24.G3.02.02
Topic: T24 – Data Representation
Skill: Store text data in variables for names and messages
Description: Students create text variables (playerName, currentMessage, status) and store text values in them. They build a project that asks for the player's name, stores it in a variable, and uses 'join' to display personalized messages.

Dependencies:
* T24.G3.02.01: Store numeric data in variables for counting and scoring




ID: T24.G3.02.03
Topic: T24 – Data Representation
Skill: Store true/false states in boolean variables
Description: Students create boolean variables (isGameOver, isPaused, hasKey) to track binary states. They practice setting variables to 'true' or 'false' and use them in if-blocks to control program flow based on state.

Dependencies:
* T24.G3.02.02: Store text data in variables for names and messages
* T08.G3.02: Decide when a single if is enough




ID: T24.G3.03
Topic: T24 – Data Representation
Skill: Parse sentences into structured data fields
Description: Students read sentences ("Luna fed 4 fish to the seal") and identify the data fields (character: Luna, action: fed, quantity: 4, target: seal). They create four variables to represent this structured record and display each field on stage.

Dependencies:
* T24.G3.02.03: Store true/false states in boolean variables
* T08.G3.03: Pick the right conditional block for a scenario




ID: T24.G3.04.01
Topic: T24 – Data Representation
Skill: Spot inconsistent units in data tables
Description: Learners examine a table mixing minutes and seconds (e.g., "2 min", "120 sec", "3 min") and circle entries using different units. They explain why mixing units in the same column makes comparisons impossible.

Dependencies:
* T24.G3.03: Parse sentences into structured data fields




ID: T24.G3.04.02
Topic: T24 – Data Representation
Skill: Convert data to consistent units
Description: Students build a CreatiCode project that converts mixed time formats to a single unit. Users enter values in either minutes or seconds, and the program converts everything to seconds using variables and math operators.

Dependencies:
* T24.G3.04.01: Spot inconsistent units in data tables
* T09.G3.02: Use a variable in a conditional (if block)




ID: T24.G3.05
Topic: T24 – Data Representation
Skill: Identify data that needs cleaning
Description: Students examine lists containing inconsistent data (mixed capitalization like 'Red', 'red', 'RED'; different formats like '1/2' vs '0.5') and circle entries needing standardization. They explain why inconsistent data causes problems when searching or counting.

Dependencies:
* T24.G3.03: Parse sentences into structured data fields
* T24.G3.04.01: Spot inconsistent units in data tables




ID: T24.G3.06.01.01
Topic: T24 – Data Representation
Skill: Create an empty table with column names
Description: Students use table creation blocks to make a new empty table and specify column names (Name, Age, Score). They explain that tables organize data into rows (records) and columns (fields), extending the concept from G2 picture tables.

Dependencies:
* T24.G3.02.03: Store true/false states in boolean variables
* T24.G2.04: Create records with two attributes




ID: T24.G3.06.01.02
Topic: T24 – Data Representation
Skill: Add rows of data to a table
Description: Students use 'add row to table' blocks to insert rows with multiple values. They practice adding rows one at a time, ensuring each value aligns with its column, and trace how the table grows row by row in the table monitor.

Dependencies:
* T24.G3.06.01.01: Create an empty table with column names




ID: T24.G3.06.01.03
Topic: T24 – Data Representation
Skill: Display and read table monitors on stage
Description: Students use 'show table [name]' blocks to display tables on stage. They trace how tables appear with labeled columns and numbered rows, and practice reading specific values from the visual display.

Dependencies:
* T24.G3.06.01.02: Add rows of data to a table




ID: T24.G3.06.02
Topic: T24 – Data Representation
Skill: Retrieve table values by row and column
Description: Students use 'item at row [number] column [name] of table' blocks to retrieve specific cell values. They practice accessing individual cells like "item at row 2 column 'Name'" and display the retrieved values using 'say' blocks.

Dependencies:
* T24.G3.06.01.03: Display and read table monitors on stage
* T10.G3.01: Loop through and process each item in a list




ID: T24.G3.07.01
Topic: T24 – Data Representation
Skill: Delete items from lists by position
Description: Students use 'delete item [index] of [list]' blocks to remove items at specific positions. They trace how deleting item 2 shifts all later items down (item 3 becomes item 2), and practice deleting first, last, and middle items.

Dependencies:
* T24.G3.01.01: Build a list from scratch using add blocks




ID: T24.G3.07.02
Topic: T24 – Data Representation
Skill: Insert items at specific positions in lists
Description: Students use 'insert [item] at [index] of [list]' blocks to add items at specific positions (not just the end). They trace how inserting at position 2 shifts existing item 2 to position 3, and practice inserting at various positions.

Dependencies:
* T24.G3.07.01: Delete items from lists by position




ID: T24.G3.07.03
Topic: T24 – Data Representation
Skill: Replace items in lists by position
Description: Students use 'replace item [index] of [list] with [value]' blocks to update existing items without changing list length. They compare replace (same length) vs delete-then-insert (changes length) and choose appropriately.

Dependencies:
* T24.G3.07.02: Insert items at specific positions in lists




ID: T24.G3.07.04
Topic: T24 – Data Representation
Skill: Get list length and access items by index
Description: Students use 'length of [list]' reporter blocks to count total items and 'item [index] of [list]' blocks to retrieve specific items by position. They trace that indices start at 1 (not 0) in CreatiCode.

Dependencies:
* T24.G3.07.03: Replace items in lists by position




ID: T24.G3.07.05
Topic: T24 – Data Representation
Skill: Check if a list contains a specific value
Description: Students use '[list] contains [value]' reporter blocks to test whether an item exists in a list. They use this in if-blocks to make decisions like "if playerNames contains 'Alex' then say 'Welcome back!'".

Dependencies:
* T24.G3.07.04: Get list length and access items by index
* T08.G3.02: Decide when a single if is enough




ID: T24.G3.08
Topic: T24 – Data Representation
Skill: Convert small numbers between decimal and binary
Description: Students convert numbers 0-7 between decimal and 3-bit binary using a place value chart (4s, 2s, 1s columns). They build a CreatiCode project with three sprites (representing bits) that flip between 0 and 1 to show the binary representation, then display the decimal sum using a variable.

Dependencies:
* T24.G2.07: Create secret codes with symbol-to-letter mappings
* T24.G3.00.01.02: Assign values to variables using set blocks




ID: T24.G3.09
Topic: T24 – Data Representation
Skill: Build pixel art using coordinate grids and color codes
Description: Students create simple pixel art by filling a grid where each cell is identified by (row, column) coordinates and a color number (0=white, 1=black, 2=red, etc.). They store the grid data in a list (row by row) and build a CreatiCode project that reads the list and draws colored stamps at each position.

Dependencies:
* T24.G3.01.01: Build a list from scratch using add blocks
* T24.G3.06.01.01: Create an empty table with column names




ID: T24.G3.10
Topic: T24 – Data Representation
Skill: Use trace tables to track variable changes step-by-step
Description: Students learn to create trace tables (paper or digital) with columns for each variable and rows for each step of execution. Given a 5-line script that modifies a score variable, they fill in the trace table predicting the value at each step, then run the code to verify. They identify where predictions differed from actual results and explain why.

Dependencies:
* T24.G3.00.01.03: Modify variables using change blocks
* T24.G3.07.04: Get list length and access items by index




ID: T24.G3.11
Topic: T24 – Data Representation
Skill: Justify choice between variable and list for a scenario
Description: Students examine scenarios like "store the player's current score" vs "store all the player's past scores" and justify whether to use a variable or list. They explain their reasoning: variables for single values that change, lists for collections of related values. They implement both approaches and compare.

Dependencies:
* T24.G3.02.01: Store numeric data in variables for counting and scoring
* T24.G3.01.01: Build a list from scratch using add blocks




ID: T24.G4.01
Topic: T24 – Data Representation
Skill: Design schema diagrams for simple apps
Description: Students diagram an app's data needs (e.g., to-do list: task text, due date, done?) showing column names and types before coding. They identify what data their app needs, choose appropriate data types for each field, and document the plan on paper before implementing.

Dependencies:
* T24.G2.05: Identify missing data in a picture chart
* T24.G3.02.03: Store true/false states in boolean variables




ID: T24.G4.02
Topic: T24 – Data Representation
Skill: Convert values between decimal, fraction, and percentage formats
Description: Students represent the same numerical fact in three formats: decimal (0.75), fraction (3/4), and percentage (75%). They use CreatiCode's math operators and variables to convert and display values in each format, tracing the mathematical relationships.

Dependencies:
* T24.G2.02: Convert between timeline, table, and sentence formats
* T24.G3.02.01: Store numeric data in variables for counting and scoring




ID: T24.G4.03
Topic: T24 – Data Representation
Skill: Compare dense versus sparse data representations
Description: Students compare dense (storing all values including empty) versus sparse (storing only non-empty values) representations. Example: tic-tac-toe board as [X, O, empty, X, O, empty, empty, empty, X] vs [(1,X), (2,O), (4,X), (5,O), (9,X)]. They analyze which uses less storage and predict when each is appropriate.

Dependencies:
* T24.G2.03: Select the best representation for a question
* T24.G3.07.04: Get list length and access items by index




ID: T24.G4.04
Topic: T24 – Data Representation
Skill: Create data legends with special rules
Description: Students create a legend table for a mini-map (color = terrain) with columns for Symbol and Meaning. They add notes documenting exceptions (e.g., "Purple = portal unless near volcano"), practicing how to document encoding rules clearly.

Dependencies:
* T24.G2.01: Add meaningful labels to a category chart
* T24.G3.06.01.03: Display and read table monitors on stage




ID: T24.G4.05
Topic: T24 – Data Representation
Skill: Differentiate stored data from computed values
Description: Students examine a game scoreboard and identify which values are stored (points earned each round) versus computed (total score = sum of rounds). They build a scoreboard storing round scores in a list and computing the total using 'sum of list' blocks.

Dependencies:
* T24.G3.07.04: Get list length and access items by index
* T24.G4.01: Design schema diagrams for simple apps




ID: T24.G4.05.01
Topic: T24 – Data Representation
Skill: Trace when to store vs when to compute values
Description: Students trace through scenarios deciding whether to store or compute: (1) player's current health (store—changes over time), (2) total inventory weight (compute—sum of item weights), (3) high score (store—persists across sessions). They explain tradeoffs for each decision.

Dependencies:
* T24.G4.05: Differentiate stored data from computed values




ID: T24.G4.06.01
Topic: T24 – Data Representation
Skill: Plan an algorithm to populate tables from lists
Description: Students design (on paper) an algorithm that loops through a list and adds each item to a table row. They specify loop bounds, index tracking, and row creation steps before coding, practicing algorithmic planning.

Dependencies:
* T24.G3.06.01.03: Display and read table monitors on stage
* T07.G3.01: Use a counted repeat loop




ID: T24.G4.06.02
Topic: T24 – Data Representation
Skill: Implement table population from list data
Description: Students implement their designed algorithm by writing scripts that loop through a list and use 'add row to table' blocks to build a table from list data. They create tables with Name and Index columns using a loop with an index counter.

Dependencies:
* T24.G4.06.01: Plan an algorithm to populate tables from lists
* T24.G3.06.01.02: Add rows of data to a table
* T10.G3.01: Loop through and process each item in a list




ID: T24.G4.07.01
Topic: T24 – Data Representation
Skill: Convert lists to text using join with separator
Description: Students use 'join items of [list] with [separator]' blocks to convert lists into text strings. They practice using different separators (comma, space, newline) to format lists for display or export as CSV.

Dependencies:
* T24.G3.07.04: Get list length and access items by index




ID: T24.G4.07.02
Topic: T24 – Data Representation
Skill: Parse text into lists using split by delimiter
Description: Students use 'split [text] by [delimiter]' blocks to convert text strings into lists. They practice splitting sentences by spaces (words) or CSV text by commas, understanding how text can be parsed into structured data.

Dependencies:
* T24.G4.07.01: Convert lists to text using join with separator




ID: T24.G4.07.03
Topic: T24 – Data Representation
Skill: Find the index position of a value in a list
Description: Students use 'item # of [value] in [list]' blocks to search for specific values and get their index positions. They understand that the result is 0 if not found, and use this to locate data for further processing.

Dependencies:
* T24.G3.07.05: Check if a list contains a specific value




ID: T24.G4.07.04
Topic: T24 – Data Representation
Skill: Search lists for partial text matches
Description: Students use '# of item containing [text] in [list]' blocks to find items that contain a substring (not exact match). They compare exact match (item # of) vs partial match (containing) and choose the appropriate search method.

Dependencies:
* T24.G4.07.03: Find the index position of a value in a list




ID: T24.G4.08.01
Topic: T24 – Data Representation
Skill: Add new columns to existing tables
Description: Students use 'add column [name] at position [n] to table' blocks to add new columns to tables after creation. They practice extending table schemas dynamically and understand that new columns start empty.

Dependencies:
* T24.G3.06.01.03: Display and read table monitors on stage




ID: T24.G4.08.02
Topic: T24 – Data Representation
Skill: Delete columns from tables
Description: Students use 'delete column [name/number] from table' blocks to remove columns from tables. They understand when to remove unnecessary columns and how this affects table structure.

Dependencies:
* T24.G4.08.01: Add columns to existing tables




ID: T24.G4.08.03
Topic: T24 – Data Representation
Skill: Get column values as lists
Description: Students use 'column [name/number] of table' reporter blocks to extract entire columns as lists. They understand how to convert table columns to lists for processing with list operations.

Dependencies:
* T24.G4.08.01: Add columns to existing tables
* T24.G3.07.04: Get list length and access items by index




ID: T24.G4.09.01
Topic: T24 – Data Representation
Skill: Get the row count of a table
Description: Students use 'row count of table [name]' reporter blocks to count table rows. They practice using row counts to set loop bounds and check if tables are empty (row count = 0).

Dependencies:
* T24.G3.06.01.03: Display and read table monitors on stage




ID: T24.G4.09.02
Topic: T24 – Data Representation
Skill: Get entire rows as lists
Description: Students use 'row [number] of table' reporter blocks to extract entire rows as lists of values. They understand how rows can be processed as units.

Dependencies:
* T24.G4.09.01: Get row count of tables




ID: T24.G4.09.03
Topic: T24 – Data Representation
Skill: Delete rows from tables by index
Description: Students use 'delete row [number] from table' blocks to remove specific rows by position. They understand how row deletion shifts subsequent rows to lower indices.

Dependencies:
* T24.G4.09.02: Get entire rows as lists




ID: T24.G4.09.04
Topic: T24 – Data Representation
Skill: Delete all rows from tables
Description: Students use 'delete all rows from [table]' blocks to clear table contents while preserving column structure. They understand when to reset tables for reuse.

Dependencies:
* T24.G4.09.03: Delete rows from tables by index




ID: T24.G4.10
Topic: T24 – Data Representation
Skill: Trace ASCII encoding for common text characters
Description: Students trace how text characters map to numeric codes using a simplified ASCII reference (A=65, B=66, ..., Z=90; a=97, b=98, ...; 0-9=48-57). They build a CreatiCode project that takes a character input and displays its ASCII code using the 'letter [n] of [text]' and 'unicode of [char]' blocks.

Dependencies:
* T24.G3.08: Convert small numbers between decimal and binary
* T24.G3.02.02: Store text data in variables for names and messages




ID: T24.G4.11
Topic: T24 – Data Representation
Skill: Encode simple images as number grids in tables
Description: Students encode a 4x4 black-and-white image as a table where each cell contains 0 (white) or 1 (black). They build a CreatiCode project that reads the table and draws the image using stamps, then modify the table values and predict how the image changes before running.

Dependencies:
* T24.G3.09: Build pixel art using coordinate grids and color codes
* T24.G4.06.02: Implement table population from list data




ID: T24.G4.12
Topic: T24 – Data Representation
Skill: Debug incorrect variable values using monitors
Description: Students receive a buggy project where a score counter shows wrong values. They enable variable monitors on stage, step through the code execution, identify where the variable gets an incorrect value (wrong initial value, wrong update amount, or update in wrong event), and fix the bug.

Dependencies:
* T24.G3.00.01.04: Display and trace variable monitors on stage
* T24.G4.05: Differentiate stored data from computed values




ID: T24.G4.13
Topic: T24 – Data Representation
Skill: Create a debugging checklist for data errors
Description: Students create a reusable checklist for debugging data problems: (1) Is the variable initialized? (2) Is the data type correct? (3) Is the update happening in the right event? (4) Are the values within expected range? They apply this checklist to debug three different buggy projects and document which checklist item caught each bug.

Dependencies:
* T24.G4.12: Debug incorrect variable values using monitors
* T24.G3.10: Use trace tables to track variable changes step-by-step




ID: T24.G4.14
Topic: T24 – Data Representation
Skill: Identify personal vs non-personal data
Description: Students examine a game profile with fields: username, high score, favorite color, real name, home address, age. They sort each field into "personal data" (could identify a real person) vs "non-personal data" (doesn't identify someone). They explain why personal data needs extra protection and redesign the profile to minimize personal data collection.

Dependencies:
* T24.G4.01: Design schema diagrams for simple apps
* T24.G3.02.02: Store text data in variables for names and messages




ID: T24.G4.15
Topic: T24 – Data Representation
Skill: Compare fixed-length vs variable-length encoding
Description: Students compare encoding schemes: fixed-length (every letter uses 5 bits: A=00001, B=00010...) vs variable-length (common letters use fewer bits: E=1, T=01, A=001...). They calculate storage for "MEET" using both methods, discovering that variable-length can be more efficient for text with common letters. They discuss tradeoffs (simplicity vs efficiency).

Dependencies:
* T24.G4.10: Trace ASCII encoding for text characters
* T24.G3.08: Convert small numbers between decimal and binary




ID: T24.G4.16
Topic: T24 – Data Representation
Skill: Justify choice between list and table for a scenario
Description: Students examine three scenarios: (A) store a deck of card names, (B) store player profiles with name, score, and level, (C) store quiz questions with question text, correct answer, and points. They justify which data structure (list or table) fits each scenario and explain: lists for single-attribute collections, tables for multi-attribute records.

Dependencies:
* T24.G4.08.01: Add new columns to existing tables
* T24.G3.11: Justify choice between variable and list for a scenario




ID: T24.G5.01.01
Topic: T24 – Data Representation
Skill: Design multi-type data structures on paper
Description: Students design a "lucy" data structure on paper showing different data types: text (name), number (score, health), Boolean (isAlive), and list (inventory). They create a schema diagram identifying which CreatiCode data structure to use for each field.

Dependencies:
* T24.G4.01: Design schema diagrams for simple apps
* T24.G3.07.04: Get list length and access items by index




ID: T24.G5.01.02.01
Topic: T24 – Data Representation
Skill: Initialize game state variables in green-flag scripts
Description: Students implement their game state design by creating all necessary variables (playerName, score, health, isAlive) and lists (inventory) with appropriate initial values using green-flag scripts.

Dependencies:
* T24.G5.01.01: Design multi-type data structures on paper




ID: T24.G5.01.02.02
Topic: T24 – Data Representation
Skill: Update game state variables in response to events
Description: Students implement coordinated state updates in response to game events. When the player picks up an item, they add it to inventory AND update score. When the player takes damage, they decrease health AND check if health reaches zero.

Dependencies:
* T24.G5.01.02.01: Initialize game state variables in green-flag scripts
* T08.G4.03: Use if/else for binary choices




ID: T24.G5.01.02.03
Topic: T24 – Data Representation
Skill: Save and restore game state across restarts
Description: Students implement save functionality that stores critical variables (score, health, inventory) and load functionality that retrieves these values when the game restarts, enabling persistent gameplay progress.

Dependencies:
* T24.G5.01.02.02: Update game state variables in response to events




ID: T24.G5.02.01
Topic: T24 – Data Representation
Skill: Normalize text input using join and replace
Description: Students use CreatiCode's text operation blocks to standardize inconsistent inputs. They practice: (1) using 'join [text] and [text]' blocks to combine separated inputs, (2) using 'replace [old] with [new] in [text]' blocks to fix common variations.

Dependencies:
* T24.G3.01.02: Map survey responses into list variables
* T24.G3.04.02: Convert data to consistent units
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.02.02.01
Topic: T24 – Data Representation
Skill: Identify and catalog data quality issues
Description: Students examine a dataset with multiple issues (inconsistent formats, duplicates, missing values, invalid entries) and create a checklist identifying each type of problem. They categorize issues by type.

Dependencies:
* T24.G5.02.01: Normalize text input using join and replace
* T24.G3.05: Identify when data needs cleaning
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.02.02.02
Topic: T24 – Data Representation
Skill: Remove duplicate entries from lists
Description: Students build a script that detects and removes duplicate entries from a list. They use loops to check if an item already exists in a "clean" list before adding it, creating a duplicate-free version.

Dependencies:
* T24.G5.02.02.01: Identify and catalog data quality issues
* T09.G3.03: Use a variable in a simple conditional (if block)
* T10.G3.05: Loop through each item in a list




ID: T24.G5.02.02.03
Topic: T24 – Data Representation
Skill: Fix inconsistent text formats
Description: Students build a script that standardizes text formatting in a list. They apply multiple transformations: convert all text to lowercase, remove extra whitespace, replace variant spellings with standard forms.

Dependencies:
* T24.G5.02.02.02: Remove duplicate entries from lists
* T09.G3.03: Use a variable in a simple conditional (if block)
* T10.G3.05: Loop through each item in a list




ID: T24.G5.02.02.04
Topic: T24 – Data Representation
Skill: Validate cleaned data against rules
Description: Students implement validation checks that verify cleaned data meets quality requirements. They check that all entries match expected patterns using conditional blocks. Invalid entries are flagged or removed.

Dependencies:
* T24.G5.02.02.03: Fix inconsistent text formats
* T09.G3.03: Use a variable in a simple conditional (if block)
* T07.G3.01: Use a counted repeat loop




ID: T24.G5.02.02.05
Topic: T24 – Data Representation
Skill: Test data cleaning with sample datasets
Description: Students create test cases with known data quality issues and verify their cleaning pipeline fixes them correctly. They prepare "dirty" sample data, run it through their cleaning process, and compare results to expected outputs.

Dependencies:
* T24.G5.02.02.04: Validate cleaned data against rules
* T09.G3.03: Use a variable in a simple conditional (if block)
* T07.G3.01: Use a counted repeat loop




ID: T24.G5.03
Topic: T24 – Data Representation
Skill: Decide when to upgrade from list to table
Description: Students examine three scenarios with different data requirements and decide whether to use lists (single attribute per item) or tables (multiple attributes per item). They implement one chosen scenario in CreatiCode.

Dependencies:
* T24.G3.01.02: Map survey responses into list variables
* T24.G4.03: Compare dense vs sparse representations
* T10.G3.05: Loop through each item in a list




ID: T24.G5.04
Topic: T24 – Data Representation
Skill: Encode categorical values with numeric codes
Description: Students learn to map repeated categorical text values (difficulty: Easy/Medium/Hard) to numeric codes (1/2/3) stored in variables. They create a legend table documenting the mapping and use coded values in conditionals.

Dependencies:
* T24.G4.04: Document special rules in a data key
* T24.G3.02.03: Use boolean variables for true/false states
* T10.G3.05: Loop through each item in a list
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.05
Topic: T24 – Data Representation
Skill: Add meaningful default values to data fields
Description: Students design a player profile where some fields might be empty (e.g., "nickname") and choose appropriate default values. They create a profile creation script that sets defaults using if/else blocks.

Dependencies:
* T24.G4.01: Build schema diagrams for simple apps
* T24.G3.02.03: Use boolean variables for true/false states
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.06.01
Topic: T24 – Data Representation
Skill: Create multi-column tables with varied data
Description: Students build multi-column tables (3+ columns) with complex data using CreatiCode table blocks. They practice creating tables with different column types (text, number, boolean) and adding rows with multiple values.

Dependencies:
* T24.G3.06.02: Access table items by row and column
* T24.G5.03: Decide when to upgrade from list to table
* T10.G3.05: Loop through each item in a list
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.06.02
Topic: T24 – Data Representation
Skill: Query tables by value using find row
Description: Students learn to search tables using 'find row number where column [name] = [value]' blocks. They practice finding specific rows, retrieving the row number, then accessing other columns from that row.

Dependencies:
* T24.G5.06.01: Create multi-column tables with varied data
* T10.G3.05: Loop through each item in a list
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.06.03
Topic: T24 – Data Representation
Skill: Delete table rows by condition
Description: Students learn to remove rows from tables using 'delete all rows where column [name] = [value]' blocks. They build projects that filter tables by deleting unwanted rows and display the filtered results.

Dependencies:
* T24.G5.06.02: Query tables by value using find row
* T10.G3.05: Loop through each item in a list
* T09.G3.03: Use a variable in a simple conditional (if block)




ID: T24.G5.06.04
Topic: T24 – Data Representation
Skill: Insert rows at specific positions in tables
Description: Students use 'insert row [values] at position [number] in table' blocks to add rows at specific positions (not just the end). They understand how insertion shifts subsequent rows to higher indices.

Dependencies:
* T24.G5.06.01: Create multi-column tables with varied data




ID: T24.G5.06.05
Topic: T24 – Data Representation
Skill: Replace entire table rows
Description: Students use 'replace row [number] with [values] in table' blocks to update entire rows with new data. They understand when to replace vs delete-and-insert.

Dependencies:
* T24.G5.06.04: Insert rows at specific positions in tables




ID: T24.G5.06.06
Topic: T24 – Data Representation
Skill: Replace individual table cells
Description: Students use 'replace item at row [number] column [name] with [value] in table' blocks to update individual cell values. They practice precise cell updates without affecting other cells.

Dependencies:
* T24.G5.06.05: Replace entire table rows




ID: T24.G5.06.07
Topic: T24 – Data Representation
Skill: Change table cells by relative amounts
Description: Students use 'change item at row [number] column [name] by [value] in table' blocks to modify numeric cells by adding/subtracting values. They trace the difference between relative updates (change by 5) versus absolute updates (set to 5) and predict final values.

Dependencies:
* T24.G5.06.06: Replace individual table cells




ID: T24.G5.06.08
Topic: T24 – Data Representation
Skill: Reduce table cells using formulas
Description: Students use 'reduce item at row [number] column [name] by formula [expression] in table' blocks to apply calculations to cell values. They practice compound updates like "multiply by 2 then subtract 10".

Dependencies:
* T24.G5.06.07: Change table cells by relative amounts




ID: T24.G5.07
Topic: T24 – Data Representation
Skill: Validate data types and ranges before storage
Description: Students write validation scripts that check user input before storing it in variables. Using conditional blocks, they verify that scores are numbers in valid ranges (e.g., 0-100) and reject invalid inputs with error messages.

Dependencies:
* T24.G3.02.03: Use boolean variables for true/false states
* T08.G4.03: Use if/else for binary choices
* T09.G3.03: Use a variable in a simple conditional (if block)
* T07.G3.01: Use a counted repeat loop




ID: T24.G5.07.01
Topic: T24 – Data Representation
Skill: Find minimum and maximum values in lists
Description: Students use 'min of [list]' and 'max of [list]' reporter blocks to find smallest and largest values. They practice finding extremes in numeric lists.

Dependencies:
* T24.G3.07.04: Get list length and access items by index




ID: T24.G5.07.02
Topic: T24 – Data Representation
Skill: Calculate sum and average of list values
Description: Students use 'sum of [list]' and 'average of [list]' reporter blocks to aggregate numeric lists. They understand how to compute basic statistics.

Dependencies:
* T24.G5.07.01: Find minimum and maximum values in lists




ID: T24.G5.07.03
Topic: T24 – Data Representation
Skill: Calculate median of list values
Description: Students use 'median of [list]' reporter blocks to find middle values. They understand when median is more appropriate than average (handling outliers).

Dependencies:
* T24.G5.07.02: Calculate sum and average of list values




ID: T24.G5.08.01
Topic: T24 – Data Representation
Skill: Reverse lists
Description: Students use 'reverse [list]' blocks to flip list order (first becomes last). They understand when reverse order is useful (recent-first displays, undo stacks).

Dependencies:
* T24.G3.07.04: Get list length and access items by index




ID: T24.G5.08.02
Topic: T24 – Data Representation
Skill: Reshuffle lists randomly
Description: Students use 'reshuffle [list]' blocks to randomize list order. They practice creating randomized quizzes, shuffled decks, and random selections.

Dependencies:
* T24.G5.08.01: Reverse lists




ID: T24.G5.08.03
Topic: T24 – Data Representation
Skill: Sort lists in ascending order
Description: Students use 'sort [list] in [ascending] order' blocks to organize list items alphabetically or numerically. They understand how sorting changes list order permanently.

Dependencies:
* T24.G5.08.02: Reshuffle lists randomly




ID: T24.G5.08.04
Topic: T24 – Data Representation
Skill: Sort lists in descending order
Description: Students practice sorting lists in descending order (largest first, Z-A). They compare ascending vs descending and choose appropriate ordering for different scenarios.

Dependencies:
* T24.G5.08.03: Sort lists in ascending order




ID: T24.G5.08.05
Topic: T24 – Data Representation
Skill: Copy and append lists
Description: Students use 'copy of [list]' blocks to duplicate lists and 'append [list] to [list]' blocks to combine lists. They understand shallow copying and list merging.

Dependencies:
* T24.G5.08.04: Sort lists in descending order




ID: T24.G5.09
Topic: T24 – Data Representation
Skill: Compress image data using run-length encoding
Description: Students learn run-length encoding (RLE) by compressing a row of pixel colors "WWWWBBWW" into "4W2B2W". They build a CreatiCode project that encodes a list of repeated values into count-value pairs, then decode the compressed data back to the original. They compare storage: original list length vs compressed list length.

Dependencies:
* T24.G4.11: Encode simple images as number grids in tables
* T24.G5.08.05: Copy and append lists




ID: T24.G5.10
Topic: T24 – Data Representation
Skill: Trace data flow through multi-step transformations
Description: Students trace how data changes through a 3-stage pipeline: input → transformation → output. Given a sequence like (raw scores list → add 5 to each → filter above 70), they predict intermediate and final values on paper, then verify by adding console.log statements at each stage in CreatiCode.

Dependencies:
* T24.G5.02.02.04: Validate cleaned data against rules
* T24.G5.07.02: Calculate sum and average of list values




ID: T24.G5.11
Topic: T24 – Data Representation
Skill: Debug by comparing expected vs actual data states
Description: Students learn systematic debugging by creating "expected state" tables before running code, then comparing with actual results. They document: (1) expected list/table contents after each step, (2) actual contents from running, (3) first point of divergence. They fix bugs by analyzing where expected and actual first differ.

Dependencies:
* T24.G5.10: Trace data flow through multi-step transformations
* T24.G4.13: Create a debugging checklist for data errors




ID: T24.G5.12
Topic: T24 – Data Representation
Skill: Design data collection with user consent in mind
Description: Students design a quiz game that collects player data. They decide: which data is essential (needed for game to work), which is optional (nice to have), and which should never be collected. They implement a consent screen asking users which optional data they agree to share, and respect those choices in their data storage.

Dependencies:
* T24.G4.14: Identify personal vs non-personal data
* T24.G5.01.01: Design multi-type data structures on paper




ID: T24.G5.13
Topic: T24 – Data Representation
Skill: Implement frequency-based encoding with lookup tables
Description: Students build a simple Huffman-style encoder: (1) count letter frequencies in a message, (2) assign shorter codes to more frequent letters, (3) create an encoding lookup table, (4) encode the message using the table. They calculate compression ratio (original size vs encoded size) and analyze when this encoding saves space.

Dependencies:
* T24.G4.15: Compare fixed-length vs variable-length encoding
* T24.G5.09: Compress image data using run-length encoding




ID: T24.G5.14
Topic: T24 – Data Representation
Skill: Justify representation choices with tradeoff analysis
Description: Students face design decisions (store full timestamps vs just dates, store images vs image URLs, store computed values vs recompute each time) and justify their choices with explicit tradeoff analysis. They create a decision table with columns: Option, Storage Cost, Speed, Flexibility, and explain which factors matter most for their specific scenario.

Dependencies:
* T24.G5.03: Decide when to upgrade from list to table
* T24.G4.16: Justify choice between list and table for a scenario




ID: T24.G6.01
Topic: T24 – Data Representation
Skill: Create metadata documentation tables for datasets
Description: Students create a metadata documentation table in CreatiCode with columns: FieldName, Description, DataType, Units, ValidRange. They complete metadata tables for a project dataset, documenting each field's details.

Dependencies:
* T24.G4.04: Create data legends with special rules
* T24.G5.01.01: Design multi-type data structures on paper




ID: T24.G6.02
Topic: T24 – Data Representation
Skill: Compare lossy versus lossless data representation
Description: Students compare representing a path as every coordinate (lossless) vs key checkpoints (lossy) and discuss tradeoffs. They implement both approaches in CreatiCode and analyze storage vs precision.

Dependencies:
* T24.G4.03: Compare dense versus sparse data representations
* T24.G5.03: Decide when to upgrade from list to table




ID: T24.G6.03
Topic: T24 – Data Representation
Skill: Create nested data structures with tables and lists
Description: Students design and implement nested data structures using CreatiCode tables and lists. They practice creating a table where one column stores list names (e.g., Inventory column references a list of item names).

Dependencies:
* T24.G5.01.02.03: Save and restore game state across restarts
* T24.G5.03: Decide when to upgrade from list to table




ID: T24.G6.04
Topic: T24 – Data Representation
Skill: Map AI prompt inputs to structured data slots
Description: Learners examine an AI prompt template ('Write a summary about {topic} in {tone}') and identify which data fields store each slot's values. They implement a template system using variables and 'join' blocks to construct dynamic prompts.

Dependencies:
* T24.G5.02.01: Normalize text input using join and replace
* T24.G5.04: Encode categorical values with numeric codes




ID: T24.G6.05.01.01
Topic: T24 – Data Representation
Skill: Query tables using lookup blocks for exact matches
Description: Students use 'row # of [value] in column [name] in table' blocks to find rows matching exact values. They practice building queries with single conditions and handling "not found" cases (result = 0).

Dependencies:
* T24.G5.06.02: Query tables by value using find row




ID: T24.G6.05.01.02
Topic: T24 – Data Representation
Skill: Filter tables with comparison operators
Description: Students build filters using comparison operators (>, <, >=, <=, ≠) to find rows matching numeric ranges (e.g., 'find all rows where Score > 100'). They collect matching rows into new tables or lists.

Dependencies:
* T24.G6.05.01.01: Use lookup blocks for value-based queries




ID: T24.G6.05.01.03
Topic: T24 – Data Representation
Skill: Filter tables with compound conditions
Description: Students combine multiple conditions using AND/OR logic to build complex queries (e.g., 'find rows where Score > 100 AND Level = 5'). They understand query composition.

Dependencies:
* T24.G6.05.01.02: Filter tables with comparison operators
* T08.G5.03: Use compound conditions (and, or, not)




ID: T24.G6.05.02
Topic: T24 – Data Representation
Skill: Aggregate table column data using built-in statistics blocks
Description: Students use CreatiCode's built-in aggregation blocks 'sum/average/median/max/min of column [name] in table' to analyze table data. They build a grade analyzer that calculates class statistics.

Dependencies:
* T24.G5.07.03: Calculate median of list values
* T24.G6.05.01.01: Query tables using lookup blocks for exact matches




ID: T24.G6.05.03
Topic: T24 – Data Representation
Skill: Sort tables by column values
Description: Students use 'sort table by column [name] in [ascending/descending] order' blocks to sort tables. They practice sorting by different columns and understand how sorting preserves row data integrity.

Dependencies:
* T24.G5.08.04: Sort lists in descending order
* T24.G6.05.01.01: Query tables using lookup blocks for exact matches




ID: T24.G6.05.04
Topic: T24 – Data Representation
Skill: Reshuffle table rows randomly
Description: Students use 'reshuffle [table]' blocks to randomize row order. They practice creating randomized quiz questions from table data.

Dependencies:
* T24.G6.05.03: Sort tables by column




ID: T24.G6.06.01.01
Topic: T24 – Data Representation
Skill: Save values to server storage with unique keys
Description: Students use 'save [visibility] data [value] with name [key]' blocks to store individual values with unique key names. They practice choosing descriptive key names and understand that values persist across sessions.

Dependencies:
* T24.G5.01.02.03: Save and restore game state across restarts




ID: T24.G6.06.01.02
Topic: T24 – Data Representation
Skill: Compare public vs private data visibility
Description: Students compare public (visible to all users) vs private (only this user) storage options. They build projects that require each type and explain when to use each.

Dependencies:
* T24.G6.06.01.01: Save individual values to server with unique keys




ID: T24.G6.06.02
Topic: T24 – Data Representation
Skill: Load data from server storage by key
Description: Students use 'load data named [key]' reporter blocks to retrieve saved data. They practice loading previously saved values and handling cases where no data exists (empty result) using if-blocks to set defaults.

Dependencies:
* T24.G6.06.01.02: Compare public vs private data visibility




ID: T24.G6.07.01
Topic: T24 – Data Representation
Skill: Export tables to CSV files
Description: Students use 'export table as [filename]' blocks to save table data as CSV files. After exporting, they open the downloaded CSV file in a text editor to examine the comma-separated format.

Dependencies:
* T24.G5.06.01: Create multi-column tables with varied data
* T24.G4.07.01: Convert lists to text using join with separator




ID: T24.G6.07.02
Topic: T24 – Data Representation
Skill: Import CSV files into tables
Description: Students use 'import file into table' blocks to load CSV data from files. They practice uploading CSV files, importing them into CreatiCode tables, and verifying the data appears with correct columns and rows.

Dependencies:
* T24.G6.07.01: Export tables to CSV files




ID: T24.G6.08.01
Topic: T24 – Data Representation
Skill: Copy and append tables
Description: Students use 'copy of [table]' blocks to duplicate tables and 'append rows from [table] to [table]' blocks to combine tables. They understand table merging and when to create copies vs references.

Dependencies:
* T24.G5.06.01: Create multi-column tables with varied data




ID: T24.G6.08.02
Topic: T24 – Data Representation
Skill: Group table rows by column values
Description: Students use 'group table by column [name]' blocks to organize rows into groups based on shared values. They practice grouping students by grade level or items by category.

Dependencies:
* T24.G6.05.03: Sort tables by column




ID: T24.G6.08.03
Topic: T24 – Data Representation
Skill: Create pivot tables
Description: Students use 'pivot table with rows [column] columns [column] values [column]' blocks to transform table layouts. They practice creating cross-tabulation reports (e.g., sales by product and region).

Dependencies:
* T24.G6.08.02: Group table rows by column values




ID: T24.G6.08.04
Topic: T24 – Data Representation
Skill: Show table snapshots with custom styling
Description: Students use 'show table [name] at x:[x] y:[y] with style [options]' blocks to display tables with custom positioning and styling (colors, fonts, borders). They understand presentation vs data storage.

Dependencies:
* T24.G5.06.01: Create multi-column tables with varied data




ID: T24.G6.09
Topic: T24 – Data Representation
Skill: Debug table queries that return unexpected results
Description: Students receive a project where table queries return wrong rows (too many, too few, or incorrect matches). They systematically debug by: (1) displaying the query condition values, (2) showing the table data, (3) tracing which rows match the condition, (4) identifying the bug (typo in column name, wrong comparison operator, case mismatch) and fixing it.

Dependencies:
* T24.G6.05.01.03: Filter tables with compound conditions
* T24.G6.08.04: Show table snapshots with custom styling




ID: T24.G6.10
Topic: T24 – Data Representation
Skill: Parse structured text into table columns
Description: Students parse text data with consistent structure (e.g., "Name: Alice; Age: 10; Score: 95") into table columns using 'split' blocks and pattern matching. They build a CreatiCode project that reads multi-line structured text from user input, parses each line, and populates a table with the extracted values.

Dependencies:
* T24.G4.07.02: Parse text into lists using split by delimiter
* T24.G6.05.01.01: Query tables using lookup blocks for exact matches




ID: T24.G6.11
Topic: T24 – Data Representation
Skill: Diagnose data corruption using systematic isolation
Description: Students learn to isolate data corruption by: (1) identifying symptoms (wrong values, missing rows), (2) checking data at each stage of processing, (3) finding the first point where data becomes incorrect. They practice with a multi-stage project where data is read, transformed, and saved—finding where corruption was introduced.

Dependencies:
* T24.G6.09: Debug table query results that return unexpected rows
* T24.G5.11: Debug by comparing expected vs actual data states




ID: T24.G6.12
Topic: T24 – Data Representation
Skill: Implement data anonymization techniques
Description: Students learn to protect privacy by anonymizing data: (1) remove directly identifying fields (name, email), (2) generalize specific values (exact age → age range), (3) aggregate individual records into group summaries. They anonymize a class survey dataset and verify the anonymized version can't identify individuals but still answers research questions.

Dependencies:
* T24.G5.12: Design data collection with user consent in mind
* T24.G6.05.02: Aggregate table column data using built-in statistics blocks




ID: T24.G6.13
Topic: T24 – Data Representation
Skill: Analyze lossy vs lossless compression quantitatively
Description: Students compare lossy (JPEG-style: discard some detail) vs lossless (PNG-style: keep all detail) compression by implementing both for a simple dataset. They calculate: original size, compressed size, compression ratio, and for lossy—measure information lost. They analyze when each approach is appropriate.

Dependencies:
* T24.G5.13: Implement frequency-based encoding with lookup tables
* T24.G6.02: Compare lossy versus lossless data representation




ID: T24.G6.14
Topic: T24 – Data Representation
Skill: Design representations for multi-source data integration
Description: Students design a data structure that integrates information from multiple sources: sensor data + user input + API responses. They identify common fields (timestamps, IDs), handle format differences, and create a unified schema that preserves source attribution. They implement the integration in CreatiCode.

Dependencies:
* T24.G6.03: Create nested data structures with tables and lists
* T24.G5.14: Justify representation choices with tradeoff analysis




ID: T24.G7.01.01
Topic: T24 – Data Representation
Skill: Apply First Normal Form (1NF) to eliminate multi-valued cells
Description: Students identify table cells containing multiple values (comma-separated lists) and refactor tables to 1NF where each cell holds a single atomic value. They split "Red, Blue, Green" cells into separate rows.

Dependencies:
* T24.G5.01.02.03: Save and restore game state across restarts
* T24.G5.03: Decide when to upgrade from list to table




ID: T24.G7.01.02
Topic: T24 – Data Representation
Skill: Apply Second Normal Form (2NF) to eliminate partial dependencies
Description: Students identify partial dependencies where some columns depend on only part of a composite key. They refactor tables by moving partially-dependent columns to separate tables linked by foreign keys.

Dependencies:
* T24.G7.01.01: Apply First Normal Form (1NF) to eliminate multi-valued cells
* T24.G6.03: Create nested data structures with tables and lists




ID: T24.G7.01.03
Topic: T24 – Data Representation
Skill: Apply Third Normal Form (3NF) to eliminate transitive dependencies
Description: Students identify transitive dependencies where non-key columns depend on other non-key columns (e.g., ZipCode → City). They refactor by creating lookup tables to store the dependent relationships.

Dependencies:
* T24.G7.01.02: Apply Second Normal Form (2NF) to eliminate partial dependencies




ID: T24.G7.01.04
Topic: T24 – Data Representation
Skill: Normalize a game database through all three normal forms
Description: Students take a denormalized game database and normalize it step-by-step through 1NF, 2NF, and 3NF. They create separate tables with ID relationships and implement the normalized design in CreatiCode.

Dependencies:
* T24.G7.01.03: Apply Third Normal Form (3NF) to eliminate transitive dependencies




ID: T24.G7.02
Topic: T24 – Data Representation
Skill: Detect and fix bias in data schema category choices
Description: Students critique data schemas that collapse categories (e.g., combining 'Non-binary' and 'Prefer not to say' into 'Other') and analyze how such choices hide important differences. They redesign biased schemas with more precise categories.

Dependencies:
* T24.G5.04: Encode categorical values with numeric codes
* T24.G6.01: Create metadata documentation tables for datasets




ID: T24.G7.03.01.02
Topic: T24 – Data Representation
Skill: Save CSV text to server storage
Description: Students combine CSV export with server storage by saving the CSV text content using 'save data with name [key]' blocks. They understand the multi-step persistence workflow: export table to CSV text → save CSV text to server with unique key.

Dependencies:
* T24.G6.07.01: Export tables to CSV files
* T24.G6.06.02: Load data from server storage




ID: T24.G7.03.02.01
Topic: T24 – Data Representation
Skill: Load CSV text from server storage
Description: Students load previously saved CSV text from server storage using 'load data named [key]' blocks as the first step of Method 1 restoration.

Dependencies:
* T24.G7.03.01.02: Save CSV text to server storage




ID: T24.G7.03.02.02
Topic: T24 – Data Representation
Skill: Import CSV text into tables
Description: Students complete Method 1 restoration by importing the loaded CSV text into tables using 'import text into table' blocks. They build complete save/load systems.

Dependencies:
* T24.G7.03.02.01: Load CSV text from server storage




ID: T24.G7.03.03.01
Topic: T24 – Data Representation
Skill: Save tables using local storage blocks
Description: Students learn Method 2 for table persistence using built-in 'save table to local storage with name [key]' blocks for direct table persistence.

Dependencies:
* T24.G6.03: Nest tables and lists within each other
* T24.G6.06.02: Load data from server storage




ID: T24.G7.03.03.02
Topic: T24 – Data Representation
Skill: Load tables from local storage
Description: Students complete Method 2 by using 'load table from local storage named [key]' blocks to restore saved tables directly.

Dependencies:
* T24.G7.03.03.01: Save tables using local storage blocks




ID: T24.G7.03.03.03
Topic: T24 – Data Representation
Skill: Compare persistence methods and choose appropriately
Description: Students compare Method 1 (CSV export for sharing) vs Method 2 (direct save/load for speed). They decide which method fits different scenarios and implement both in a project.

Dependencies:
* T24.G7.03.02.02: Import CSV text into tables
* T24.G7.03.03.02: Load tables from local storage




ID: T24.G7.04
Topic: T24 – Data Representation
Skill: Evaluate storage vs performance tradeoffs
Description: Students build two versions of a game scoreboard: (1) store total score in variable, (2) store round scores in list, calculate total using 'sum of list'. They compare tradeoffs.

Dependencies:
* T24.G5.01.02.03: Persist game state across game restarts
* T24.G6.01: Document metadata for datasets
* T24.G6.02: Compare lossy versus lossless data representation




ID: T24.G7.05.01.01
Topic: T24 – Data Representation
Skill: Compare database collections to private server storage
Description: Students analyze the differences between database collections (shared, multi-user tables on CreatiCode's server) and private server storage. They build a demonstration project that shows data written by one user appearing for another user in collections, but not in private storage.

Dependencies:
* T24.G6.06.02: Load data from server storage




ID: T24.G7.05.01.02
Topic: T24 – Data Representation
Skill: Insert documents from tables to collections
Description: Students use 'insert from table into collection [name]' blocks to add multiple rows from a table to a database collection in one operation.

Dependencies:
* T24.G7.05.01.01: Compare database collections to private server storage
* T24.G6.05.01.01: Use lookup blocks for value-based queries




ID: T24.G7.05.01.03
Topic: T24 – Data Representation
Skill: Fetch all documents from collections into tables
Description: Students use 'fetch all from collection [name]' blocks to retrieve all documents from a collection into their local tables for processing.

Dependencies:
* T24.G7.05.01.02: Insert documents from tables to collections




ID: T24.G7.05.02.01
Topic: T24 – Data Representation
Skill: Build simple query conditions for collections
Description: Students create basic query conditions using comparison operators (=, >, <) to filter collection documents (e.g., fetch all records where score > 100).

Dependencies:
* T24.G7.05.01.03: Fetch all documents from collections into tables




ID: T24.G7.05.02.02
Topic: T24 – Data Representation
Skill: Build compound query conditions with AND/OR
Description: Students combine multiple conditions using AND/OR logic to build complex collection queries (e.g., 'score > 100 AND level = 5').

Dependencies:
* T24.G7.05.02.01: Build simple query conditions for collections




ID: T24.G7.05.02.03
Topic: T24 – Data Representation
Skill: Fetch filtered documents from collections
Description: Students use 'fetch from collection [name] where [condition]' blocks to retrieve only documents matching query conditions, enabling efficient data retrieval from large collections.

Dependencies:
* T24.G7.05.02.02: Build compound query conditions with AND/OR




ID: T24.G7.05.03.01
Topic: T24 – Data Representation
Skill: Update documents in collections
Description: Students use 'update document in collection [name] where [condition] set [field] to [value]' blocks to modify documents in shared collections.

Dependencies:
* T24.G7.05.02.03: Fetch filtered documents from collections




ID: T24.G7.05.03.02
Topic: T24 – Data Representation
Skill: Delete documents from collections
Description: Students use 'delete documents from collection [name] where [condition]' blocks to remove documents from shared collections based on conditions.

Dependencies:
* T24.G7.05.03.01: Update documents in collections




ID: T24.G7.05.03.03
Topic: T24 – Data Representation
Skill: Build collaborative multi-user data projects
Description: Students build projects where multiple users contribute to shared datasets (leaderboards, collaborative maps) and understand data persistence and sharing implications.

Dependencies:
* T24.G7.05.03.02: Delete documents from collections




ID: T24.G7.06.01.01
Topic: T24 – Data Representation
Skill: Create and configure Google Sheets for CreatiCode
Description: Students create a Google Sheet, configure sharing settings, and obtain the sheet URL needed for CreatiCode integration. Requires Google account and parent/teacher approval.

Dependencies:
* T24.G6.05.01.01: Use lookup blocks for value-based queries




ID: T24.G7.06.01.02
Topic: T24 – Data Representation
Skill: Connect CreatiCode to Google Sheets
Description: Students use 'connect to Google Sheet [URL]' blocks to establish connection between their CreatiCode project and Google Sheets.

Dependencies:
* T24.G7.06.01.01: Create and configure Google Sheets for CreatiCode




ID: T24.G7.06.02.01
Topic: T24 – Data Representation
Skill: Import Google Sheets data to CreatiCode tables
Description: Students use 'import sheet [name] from Google Sheets' blocks to read data from connected Google Sheets into CreatiCode tables.

Dependencies:
* T24.G7.06.01.02: Connect CreatiCode to Google Sheets




ID: T24.G7.06.02.02
Topic: T24 – Data Representation
Skill: Export CreatiCode tables to Google Sheets
Description: Students use 'export table to Google Sheet [name]' blocks to write table data to Google Sheets. They identify advantages of Google Sheets (accessible from any device, familiar interface).

Dependencies:
* T24.G7.06.02.01: Import Google Sheets data to CreatiCode tables




ID: T24.G7.06.03.01
Topic: T24 – Data Representation
Skill: Append rows to Google Sheets
Description: Students use 'append row [values] to sheet [name]' blocks to add individual rows to Google Sheets without replacing existing data.

Dependencies:
* T24.G7.06.02.02: Export CreatiCode tables to Google Sheets




ID: T24.G7.06.03.02
Topic: T24 – Data Representation
Skill: Update specific cells in Google Sheets
Description: Students use 'set cell [row, column] to [value] in sheet [name]' blocks to modify specific cells in Google Sheets.

Dependencies:
* T24.G7.06.03.01: Append rows to Google Sheets




ID: T24.G7.06.03.03
Topic: T24 – Data Representation
Skill: Build data collection projects with Google Sheets
Description: Students build complete projects that log data to shared Google Sheets (data collection, survey results) accessible to teachers and collaborators.

Dependencies:
* T24.G7.06.03.02: Update specific cells in Google Sheets




ID: T24.G7.07
Topic: T24 – Data Representation
Skill: Design data transformation pipelines on paper
Description: Students design (on paper) a multi-step data transformation workflow: raw input → cleaned data → enriched data → final output. They diagram each stage showing: input format, transformation rules, output format. They identify what happens if any stage fails.

Dependencies:
* T24.G6.08.02: Group table rows by column values
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G7.08
Topic: T24 – Data Representation
Skill: Implement data transformation with intermediate tables
Description: Students implement their pipeline design using intermediate tables at each stage. They create scripts that: (1) read raw data into table1, (2) transform and write to table2, (3) enrich and write to table3. They add validation checks between stages.

Dependencies:
* T24.G7.07: Design data transformation pipelines on paper
* T24.G6.08.01: Copy and append tables




ID: T24.G7.09
Topic: T24 – Data Representation
Skill: Design hierarchical data using nested key-value structures
Description: Students design hierarchical data structures where one data item contains other data items (like a game character with nested inventory, stats, and position objects). They represent this hierarchy using multiple related tables or naming conventions (character_inventory, character_stats) and implement lookup logic that navigates the hierarchy.

Dependencies:
* T24.G6.03: Create nested data structures with tables and lists
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G7.10
Topic: T24 – Data Representation
Skill: Debug multi-table relationships with integrity checks
Description: Students learn to debug problems in multi-table systems where foreign key references are broken (e.g., a PlayerItems table references a PlayerID that doesn't exist in Players table). They implement integrity check scripts that verify all references are valid, report broken links, and either fix or flag problematic records.

Dependencies:
* T24.G7.01.04: Normalize a game database through all three normal forms
* T24.G6.11: Diagnose data corruption using systematic isolation




ID: T24.G7.11
Topic: T24 – Data Representation
Skill: Evaluate privacy implications of data sharing
Description: Students analyze scenarios where data is shared: (A) sharing quiz scores with the teacher, (B) sharing high scores publicly on a leaderboard, (C) sharing game analytics with developers. For each, they identify: what personal information could be revealed, who can access it, what could go wrong, and how to minimize risk while still achieving the sharing goal.

Dependencies:
* T24.G6.12: Implement data anonymization techniques
* T24.G7.02: Detect and fix bias in data schema category choices




ID: T24.G7.12
Topic: T24 – Data Representation
Skill: Implement dictionary-based compression concepts
Description: Students implement LZW-style compression concepts: (1) build a dictionary of repeated patterns as they encounter them, (2) replace repeated patterns with short codes, (3) use the dictionary to decompress. They create a CreatiCode project that compresses and decompresses text, calculating compression ratios.

Dependencies:
* T24.G6.13: Analyze lossy vs lossless compression quantitatively
* T24.G7.09: Design hierarchical data using nested key-value structures




ID: T24.G7.13
Topic: T24 – Data Representation
Skill: Handle data synchronization conflicts
Description: Students learn to detect and resolve conflicts when the same data is modified by multiple sources. They implement conflict detection (compare timestamps, detect concurrent edits) and resolution strategies (last-write-wins, merge changes, flag for manual resolution). They test with a collaborative document scenario.

Dependencies:
* T24.G7.05.03.01: Update documents in collections
* T24.G7.06.03.02: Update specific cells in Google Sheets




ID: T24.G8.01.01.01
Topic: T24 – Data Representation
Skill: Design schema for speech recognition data with timestamps
Description: Students design a data structure for storing speech recognition output. They create a schema with fields: text content, timestamp (when spoken), speaker ID, and confidence score. They implement the schema as a table in CreatiCode.

Dependencies:
* T24.G6.01: Create metadata documentation tables for datasets
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G8.01.01.02
Topic: T24 – Data Representation
Skill: Design schema for AI chatbot conversation history
Description: Students design a data structure for storing chatbot conversation logs. They create a schema with fields: message text, role (user/assistant), timestamp, conversation ID, and token count. They implement persistence to save/load conversations.

Dependencies:
* T24.G8.01.01.01: Design schema for speech recognition data with timestamps




ID: T24.G8.01.02
Topic: T24 – Data Representation
Skill: Design schema for continuous sensor data streams
Description: Students design a data structure for storing numeric sensor readings (position coordinates, distances, accelerometer). They create a schema with fields: sensor value(s), reading timestamp, sensor ID, and measurement units. They implement time-series logging.

Dependencies:
* T24.G8.01.01.02: Design schema for AI chatbot conversation history




ID: T24.G8.01.03
Topic: T24 – Data Representation
Skill: Design schema for AI-generated image references and metadata
Description: Students design a data structure for storing AI-generated images. They create a schema with fields: image URL/path, prompt text used, generation timestamp, model parameters, and tags. They implement an image gallery with searchable metadata.

Dependencies:
* T24.G8.01.02: Design schema for continuous sensor data streams




ID: T24.G8.01.04
Topic: T24 – Data Representation
Skill: Design schema for body pose and hand tracking data
Description: Students design a data structure for storing body pose detection results. They create a schema for the 47-row hand landmark table and body joint coordinates, including detection timestamp, confidence scores, and detected gesture labels.

Dependencies:
* T24.G8.01.03: Design schema for AI-generated image references and metadata
* T22.G5.02: Detect body pose landmarks




ID: T24.G8.01.05
Topic: T24 – Data Representation
Skill: Integrate multi-modal AI data schemas with table relationships
Description: Students combine their individual schemas (speech, sensor, image, pose) into an integrated database design. They define relationships using shared IDs and implement a multi-modal data system where pose data links to corresponding audio/image captures.

Dependencies:
* T24.G8.01.04: Design schema for body pose and hand tracking data
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G8.02
Topic: T24 – Data Representation
Skill: Track data versioning and transformation history
Description: Students add version tracking fields to datasets: data source, collection timestamp, transformation notes, and version numbers. They create enhanced metadata tables that track how data has been modified over time.

Dependencies:
* T24.G6.01: Create metadata documentation tables for datasets
* T24.G7.02: Detect and fix bias in data schema category choices




ID: T24.G8.03
Topic: T24 – Data Representation
Skill: Analyze and implement compression strategies for large datasets
Description: Students investigate compression strategies by comparing storage approaches. They calculate memory usage for pose tracking data (30 frames/sec × 47 landmarks), decide between full logging vs keyframe-only, and implement delta encoding or sampling.

Dependencies:
* T24.G6.02: Compare lossy versus lossless data representation
* T24.G7.04: Evaluate storage vs performance tradeoffs




ID: T24.G8.04
Topic: T24 – Data Representation
Skill: Create data format specifications for team collaboration
Description: Students create a data format specification document describing: required input data, output data produced, and formatting rules for sharing data with teammates. They build a sample project that imports data following their specification.

Dependencies:
* T24.G7.03.02.02: Import CSV text into tables
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G8.05.01
Topic: T24 – Data Representation
Skill: Capture and store face detection results in tables
Description: Students use CreatiCode face detection blocks to capture facial landmark data (position, expression, orientation) and store results in tables with columns for each detected face attribute. They log multiple detections for analysis.

Dependencies:
* T22.G5.01: Detect faces in camera feed
* T24.G6.08.01: Copy and append tables




ID: T24.G8.05.02
Topic: T24 – Data Representation
Skill: Capture and store body/hand pose tracking data in tables
Description: Students use CreatiCode body/hand tracking blocks to capture pose data (joint coordinates, gesture recognition) and organize results in structured tables. They log time-series pose data for gesture analysis.

Dependencies:
* T24.G8.05.01: Capture and store face detection results in tables
* T22.G5.02: Detect body pose landmarks




ID: T24.G8.05.03
Topic: T24 – Data Representation
Skill: Store NLP and sentiment analysis results in tables
Description: Students use CreatiCode AI text blocks (sentiment analysis, entity extraction) and store results in tables with columns for input text, detected sentiment, entities, and confidence scores. They analyze patterns in collected responses.

Dependencies:
* T24.G8.05.01: Capture and store face detection results in tables
* T21.G5.01: Use text generation blocks for creative writing




ID: T24.G8.05.04
Topic: T24 – Data Representation
Skill: Format training datasets for KNN classification
Description: Students organize labeled example data in tables with features in columns and a label column. They use 'train KNN classifier from table' blocks to create classifiers, understanding how table structure affects ML training.

Dependencies:
* T24.G8.05.03: Store NLP and sentiment analysis results in tables
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G8.05.05
Topic: T24 – Data Representation
Skill: Format training datasets for neural network models
Description: Students organize training data in tables with input features and expected output columns. They use 'train neural network from table' blocks, understanding how row count and feature selection affect model accuracy.

Dependencies:
* T24.G8.05.04: Format training datasets for KNN classification




ID: T24.G8.05.06
Topic: T24 – Data Representation
Skill: Log neural network predictions with confidence scores in tables
Description: Students use trained neural networks to make predictions and log results in tables with columns for input values, predicted outputs, and confidence scores. They analyze prediction accuracy over multiple inputs.

Dependencies:
* T24.G8.05.05: Format training datasets for neural network models




ID: T24.G8.05.07
Topic: T24 – Data Representation
Skill: Build semantic search systems using table data and embeddings
Description: Students organize searchable content in tables, use 'semantic search [query] in table column [name]' blocks to find similar items by meaning (not just keywords), and store search results with relevance scores for ranking.

Dependencies:
* T24.G8.05.06: Log neural network predictions with confidence scores in tables
* T21.G6.01: Understand semantic similarity vs keyword matching




ID: T24.G8.06
Topic: T24 – Data Representation
Skill: Implement real-time data buffering for streaming AI inputs
Description: Students design and implement buffering strategies for high-frequency data streams (e.g., 30 fps hand tracking). They create circular buffer data structures using lists, implement overflow handling (drop oldest vs drop newest), and configure buffer sizes based on processing speed requirements.

Dependencies:
* T24.G8.01.04: Design schema for body pose and hand tracking data
* T24.G7.04: Evaluate storage vs performance tradeoffs




ID: T24.G8.07
Topic: T24 – Data Representation
Skill: Design data versioning systems for ML model training
Description: Students create versioning tables that track dataset iterations used for training ML models. They record: dataset version ID, creation date, row count, feature columns used, model accuracy achieved. They implement rollback functionality to restore previous dataset versions.

Dependencies:
* T24.G8.02: Track data versioning and transformation history
* T24.G8.05.05: Format training datasets for neural network models




ID: T24.G8.08
Topic: T24 – Data Representation
Skill: Debug data representation issues using table snapshots
Description: Students learn systematic debugging of data representation problems by capturing table snapshots at key execution points. They use 'show snapshot of table' blocks to compare expected vs actual table states, identify where data corruption occurs in multi-step transformations.

Dependencies:
* T24.G6.08.04: Show table snapshots with custom styling
* T24.G7.03.03.03: Compare persistence methods and choose appropriately




ID: T24.G8.09
Topic: T24 – Data Representation
Skill: Integrate web API data into local tables
Description: Students use 'web search store top in table' and web fetch blocks to retrieve external data and store it in local tables. They parse JSON/CSV responses, handle missing fields with defaults, and merge external data with existing project data.

Dependencies:
* T24.G7.06.02.01: Import Google Sheets data to CreatiCode tables
* T24.G6.07.02: Import CSV files into tables




ID: T24.G8.10
Topic: T24 – Data Representation
Skill: Design data pipelines with transformation stages
Description: Students design multi-stage data pipelines where raw input data flows through: (1) validation stage—reject invalid entries, (2) transformation stage—normalize formats, (3) enrichment stage—add computed fields, (4) storage stage—write to tables. They implement each stage as separate scripts and chain them together.

Dependencies:
* T24.G8.02: Track data versioning and transformation history
* T24.G7.01.04: Normalize a game database through all three normal forms




ID: T24.G8.11
Topic: T24 – Data Representation
Skill: Transform between flat and nested data structures
Description: Students implement bidirectional transformations: (1) flatten nested/hierarchical data into single flat tables (denormalization for reporting), and (2) restructure flat data into related tables with ID references (normalization for storage). They build a CreatiCode project that can convert a player profile (flat: Name, Item1, Item2, Item3) to/from normalized tables (Players + PlayerItems).

Dependencies:
* T24.G7.09: Design hierarchical data using nested key-value structures
* T24.G8.10: Design data pipelines with transformation stages




ID: T24.G8.12
Topic: T24 – Data Representation
Skill: Debug data pipelines using checkpoint validation
Description: Students implement checkpoint validation in multi-stage data pipelines: (1) define expected data properties at each stage (row count, value ranges, required fields), (2) add validation checks between stages, (3) halt and report when validation fails. They debug a broken pipeline by finding which checkpoint first fails.

Dependencies:
* T24.G8.10: Design data pipelines with transformation stages
* T24.G7.10: Debug multi-table relationships with integrity checks




ID: T24.G8.13
Topic: T24 – Data Representation
Skill: Design data retention and deletion policies
Description: Students design a data lifecycle policy for a game that collects player analytics: (1) what data to keep long-term (aggregate statistics), (2) what to delete after a period (detailed session logs), (3) what users can request deletion of (personal data). They implement automatic cleanup scripts and user-initiated deletion features.

Dependencies:
* T24.G7.11: Evaluate privacy implications of data sharing
* T24.G8.02: Track data versioning and transformation history




ID: T24.G8.14
Topic: T24 – Data Representation
Skill: Design multi-dimensional feature encoding for ML
Description: Students encode complex, multi-dimensional data (like hand gesture sequences) for ML training. They design: (1) which features to extract (positions, velocities, angles), (2) how to normalize values to comparable ranges, (3) how to handle time-series data (fixed-length windows, padding). They prepare a gesture dataset for neural network training.

Dependencies:
* T24.G7.12: Implement dictionary-based compression concepts
* T24.G8.05.05: Format training datasets for neural network models




ID: T24.G8.15
Topic: T24 – Data Representation
Skill: Implement windowed aggregation for streaming data
Description: Students implement sliding window aggregation for real-time data: (1) maintain a fixed-size buffer of recent values, (2) compute rolling statistics (average over last N values), (3) detect significant changes or anomalies. They build a project that smooths noisy sensor data and alerts when values exceed thresholds.

Dependencies:
* T24.G8.06: Implement real-time data buffering for streaming AI inputs
* T24.G7.13: Handle data synchronization conflicts




ID: T24.G8.16
Topic: T24 – Data Representation
Skill: Design data schemas for AI-augmented applications
Description: Students design comprehensive data schemas for AI-powered applications that combine: user input, AI model outputs (predictions, confidence scores), human corrections, and feedback loops. They implement a schema for an AI writing assistant that stores prompts, generated text, user edits, and improvement signals for model fine-tuning.

Dependencies:
* T24.G8.01.05: Integrate multi-modal AI data schemas with table relationships
* T24.G8.14: Design multi-dimensional feature encoding for ML




# T25 - Data Collection & Logging (Phase 9 Major Revision - November 2025)
# PHASE 9 MAJOR IMPROVEMENTS:
# 1. FIXED ALL CIRCULAR DEPENDENCIES:
#    - T25.G5.01 now depends on T25.G5.01.01 (not .02/.03) - proper scaffolding
#    - T25.G4.06.01 now comes BEFORE T25.G4.06 (logical order)
# 2. ADDED NEW FOUNDATIONAL SKILLS:
#    - T25.G3.00: Transition from picture data to code variables (bridge K-2 to G3)
#    - T25.G4.00: Design data schemas before collection
#    - T25.G5.00: Plan data collection experiments
# 3. ADDED AI-ERA DATA SKILLS:
#    - T25.G6.14: Prepare training data for machine learning
#    - T25.G7.14: Build data validation pipelines with automated checks
#    - T25.G7.15: Implement data deduplication algorithms
#    - T25.G8.15: Design data governance policies for team projects
#    - T25.G8.16: Build ETL (Extract-Transform-Load) pipelines
# 4. CONSOLIDATED OVERLAPPING SKILLS:
#    - Merged T25.G5.04 and T25.G5.04.01 into clearer progression
#    - Clarified distinction between G5 and G6 database insertion skills
# 5. ENHANCED SKILL DESCRIPTIONS:
#    - All skills now use active verbs (Create, Build, Implement, Design)
#    - Console logging hierarchy fixed: basic → values → colors → combined
#    - Clearer CreatiCode block references throughout
# SKILL PROGRESSION:
# K-2: Picture-based data concepts (counting, categorizing, representing)
# G3: Transition to programmatic collection (lists, loops, consent)
# G4: Tables, sensors, file I/O, basic statistics
# G5: Console logging, cloud basics, multi-sensor, leaderboards
# G6: Database operations, Google Sheets, multiplayer, body tracking
# G7: Reusable modules, quality monitoring, aggregation, versioning
# G8: Enterprise patterns (pipelines, ETL, governance, AI optimization)
# Total: 111 skills (added 8 new skills for better scaffolding and AI-era depth)

ID: T25.GK.01
Topic: T25 – Data Collection & Logging
Skill: Identify countable things in a picture
Description: **Student task:** Look at a picture card showing a classroom. Tap each thing that can be counted (books, chairs, students). **Visual scenario:** Picture shows classroom with 3 books on table, 5 chairs, and 4 students. Students tap items to highlight them. **Learning goal:** Build awareness that we collect information by counting observable things. _Implementation note: Tap-to-select with audio feedback "You can count that!" Auto-graded by correct selections. CSTA: DI-01._

Dependencies:
* T09.GK.01: Notice when things are different
* T01.GK.08: Count how many times an action repeats in an animation




ID: T25.GK.02
Topic: T25 – Data Collection & Logging
Skill: Track repeated events with tokens
Description: **Student task:** Watch a short animation. Each time the bunny hops, drag a token into the counting box. Count the tokens when done. **Visual scenario:** Animation shows bunny hopping 4 times. Students drag bead tokens (1 per hop) into a collection box, then tap the matching number (1-5). **Learning goal:** Create first "event log" by recording each occurrence. _Implementation note: Drag-drop tokens + number selection at end. Auto-graded by token count and number match. CSTA: DI-01._

Dependencies:
* T25.GK.01: Identify countable things in a picture
* T01.GK.07: Identify the repeating pattern in an animation







ID: T25.GK.03
Topic: T25 – Data Collection & Logging
Skill: Record yes/no answers with smile/frown cards
Description: **Student task:** Ask a friend "Do you like apples?" and place the matching card (smile=yes, frown=no) into the correct bin. Then count cards in each bin. **Visual scenario:** Two bins labeled with smile and frown. Picture cards show the question being asked. Students drag response cards to bins. **Learning goal:** Create first categorical data collection. _Implementation note: Drag cards to bins; show count in each bin at end. Auto-graded by correct placement. CSTA: DI-01._

Dependencies:
* T25.GK.01: Identify countable things in a picture


ID: T25.GK.04
Topic: T25 – Data Collection & Logging
Skill: Compare two collection methods in pictures
Description: **Student task:** Look at two picture cards showing different ways to count favorite colors: (A) asking friends one by one, (B) having friends raise hands. Tap which method would be faster for 20 friends. **Visual scenario:** Side-by-side pictures showing the two methods. **Learning goal:** Build intuition that collection method affects efficiency. _Implementation note: Binary choice with audio explanation. Auto-graded by selection. CSTA: DI-01._

Dependencies:
* T25.GK.02: Track repeated events with tokens
* T25.GK.03: Record yes/no answers with smile/frown cards




ID: T25.GK.05
Topic: T25 – Data Collection & Logging
Skill: Match data to real-world things it represents
Description: **Student task:** Look at picture cards showing data (tally marks, numbers, icons) and match each to the real-world thing it represents. **Visual scenario:** Left side shows data cards: "IIII" tally marks, number "5", row of star icons. Right side shows real-world scenes: 4 birds on a fence, 5 apples in a basket, stars in the sky. Students draw lines to match. **Learning goal:** Build foundational understanding that DATA is a REPRESENTATION of real things—the number "5" stands for real apples, not just a symbol. This concept is critical for understanding why we collect data. _Implementation note: Line-drawing matching activity. Auto-graded by correct pairings. CSTA: DI-01._

Dependencies:
* T25.GK.01: Identify countable things in a picture
* T25.GK.03: Record yes/no answers with smile/frown cards





ID: T25.G1.01
Topic: T25 – Data Collection & Logging
Skill: Conduct a three-option picture survey
Description: **Student task:** Using picture cards showing three snack options (apple, cookie, banana), survey 5 friends by having them tap their favorite. Place a sticker on the matching column for each response. **Visual scenario:** Three columns with snack pictures; sticker placement area. **Learning goal:** Collect and organize multi-option survey data. _Implementation note: Tap to select, then drag sticker. Count shown at end. Auto-graded by correct placements. CSTA: DI-01._

Dependencies:
* T25.GK.03: Record yes/no answers with smile/frown cards




ID: T25.G1.02
Topic: T25 – Data Collection & Logging
Skill: Record observation logs over time
Description: **Student task:** Using picture cards showing weather icons (sunny, cloudy, rainy), record the weather for 5 days by dragging the matching icon to each day's row. **Visual scenario:** Log sheet with days as rows; weather icons to drag. **Learning goal:** Experience longitudinal data collection over time. _Implementation note: Drag-drop with daily cells. Auto-graded by correct placements. CSTA: DI-01._

Dependencies:
* T25.G1.01: Conduct a three-option picture survey





ID: T25.G1.03
Topic: T25 – Data Collection & Logging
Skill: Follow a data-collection checklist
Description: **Student task:** Using a picture checklist showing 3 steps (greet, ask, record), put the steps in correct order, then role-play collecting a friend's favorite color. **Visual scenario:** Scrambled step cards; student arranges then simulates. **Learning goal:** Apply consistent data collection procedures in the correct sequence. _Implementation note: Drag to order, then confirmation. Auto-graded by correct sequence. CSTA: DI-01._

Dependencies:
* T25.G1.01: Conduct a three-option picture survey


ID: T25.G1.04
Topic: T25 – Data Collection & Logging
Skill: Predict what happens if a log step is skipped
Description: **Student task:** Look at a picture sequence showing data collection (ask → write down → move to next person). One step is crossed out (write down). Tap what goes wrong: (A) you forget the answer, (B) nothing, (C) you ask twice. **Visual scenario:** Sequence with X over "record" step; MCQ below. **Correct answer:** (A) you forget the answer. **Learning goal:** Understand why every step matters in logging. _Implementation note: MCQ with picture-based options. Auto-graded by selection. CSTA: DI-01._

Dependencies:
* T25.G1.03: Follow a data-collection checklist




ID: T25.G1.05
Topic: T25 – Data Collection & Logging
Skill: Decide what to record before collecting data
Description: **Student task:** Look at a goal (e.g., "Find out which game is most popular") and select which things to record from a list of options. **Visual scenario:** Goal card shows "Find out which game is most popular." Options: (A) Friend's name, (B) Favorite game, (C) Friend's age, (D) What they ate for lunch. Students tap the items needed to answer the question (A and B are correct). **Learning goal:** Develop data design thinking—deciding WHAT to collect based on the question we want to answer, rather than collecting everything. _Implementation note: Multi-select from options with feedback. Auto-graded by correct selections. CSTA: DI-01._

Dependencies:
* T25.G1.01: Conduct a three-option picture survey
* T25.GK.05: Match data to real-world things it represents





ID: T25.G2.01
Topic: T25 – Data Collection & Logging
Skill: Distinguish observational vs survey data
Description: **Student task:** Sort 6 picture cards into two bins: "Watched" (counting birds, timing a race) vs "Asked" (favorite color survey, food preference poll). **Visual scenario:** Picture cards showing collection scenarios; two labeled bins. **Learning goal:** Recognize observation vs survey as different data collection methods. _Implementation note: Drag-drop sorting. Auto-graded by correct bin placement. CSTA: DI-02._

Dependencies:
* T25.G1.02: Record observation logs over time





ID: T25.G2.02
Topic: T25 – Data Collection & Logging
Skill: Build a two-column record sheet
Description: **Student task:** Create a simple two-column table with "Name" and "Answer" headers. Fill in 4 sample entries from a favorite pet survey. **Visual scenario:** Blank two-column template; example entries to fill. **Learning goal:** Demonstrate that identifiers (who) and data (what) must be stored together to make data useful. _Implementation note: Drag names and answers to correct cells. Auto-graded by correct placement. CSTA: DI-02._

Dependencies:
* T25.G1.01: Conduct a three-option picture survey
* T24.G1.02: Design a picture table





ID: T25.G2.03
Topic: T25 – Data Collection & Logging
Skill: Measure and record duration data
Description: **Student task:** Run 3 trials of spinning a top (or rolling a ball). For each trial, start/stop the timer and record the duration on a visual log sheet. **Visual scenario:** Timer display, record sheet with trial rows. **Learning goal:** Experience repeated measurement and precision in logging. _Implementation note: Interactive timer; drag durations to cells. Auto-graded by recorded values. CSTA: DI-02._

Dependencies:
* T25.G1.02: Record observation logs over time





ID: T25.G2.04
Topic: T25 – Data Collection & Logging
Skill: Explain why sample size matters
Description: **Student task:** Look at two picture cards showing survey results: (A) asked 3 friends, 2 said "cat"; (B) asked 10 friends, 6 said "cat". Tap which result is more reliable and explain why. **Visual scenario:** Side-by-side pictographs with different sample sizes. **Learning goal:** Predict that larger samples give more reliable results and explain the reasoning. _Implementation note: Binary choice with explanation prompt. Auto-graded by selection. CSTA: DI-02._

Dependencies:
* T25.G1.01: Conduct a three-option picture survey
* T25.G2.02: Build a two-column record sheet





ID: T25.G2.05
Topic: T25 – Data Collection & Logging
Skill: Conduct a multi-response tally survey
Description: **Student task:** Using picture cards showing four season choices, run a survey asking "What's your favorite season?". For each response, add a tally mark to the matching column. **Visual scenario:** Four-column tally sheet with season icons; tally marks to add. **Learning goal:** Organize multiple response categories using tally marks and compare totals. _Implementation note: Tap to add tally marks; show totals at end. Auto-graded by tally counts. CSTA: DI-02._

Dependencies:
* T25.G2.04: Explain why sample size matters


ID: T25.G2.06
Topic: T25 – Data Collection & Logging
Skill: Trace a data collection picture sequence
Description: **Student task:** Look at a 4-step picture sequence showing data collection (prepare question → ask friend → record answer → thank friend). Point to each step in order and describe what happens. **Visual scenario:** Four numbered pictures showing collection process. **Learning goal:** Trace and describe a complete collection procedure. _Implementation note: Tap each picture in order with audio confirmation. Auto-graded by correct sequence. CSTA: DI-02._

Dependencies:
* T25.G2.01: Distinguish observational vs survey data
* T25.G1.04: Predict what happens if a log step is skipped




ID: T25.G2.07
Topic: T25 – Data Collection & Logging
Skill: Predict how data changes when events happen
Description: **Student task:** Look at a simple data table (tally or number) and predict what it will look like AFTER a described event. **Visual scenario:** Shows tally chart of "Pets at home" with Dog=3, Cat=2, Fish=1. Question: "If two more friends say they have dogs, what will the Dog tally show?" Student taps the correct answer (5). **Another scenario:** "If the Fish tally had a mistake and one friend actually has a cat, what should the new counts be?" (Cat becomes 3, Fish becomes 0). **Learning goal:** Connect real-world events to data changes—understanding data is DYNAMIC and updates reflect reality. _Implementation note: Before/after prediction with multiple choice. Auto-graded by selection. CSTA: DI-02._

Dependencies:
* T25.G2.05: Conduct a multi-response tally survey
* T25.GK.05: Match data to real-world things it represents





ID: T25.G3.00
Topic: T25 – Data Collection & Logging
Grade: Grade 3
Skill: Connect picture data to code variables
Description: Students examine a picture-based tally chart (like those from G2) and then recreate the same data in CreatiCode using a list variable. They manually add each tally mark's value to the list (e.g., add "cat", add "cat", add "dog" to match a pet tally of 2 cats, 1 dog), bridging the conceptual gap between visual data representation and programmatic data storage.

Dependencies:
* T25.G2.07: Predict how data changes when events happen
* T10.G3.01: Create a list variable
* T10.G3.02: Add and read items from a list

Blocks: create list, add to list, length of list


ID: T25.G3.01
Topic: T25 – Data Collection & Logging
Skill: Build a CreatiCode survey loop
Description: Students build a script that repeats the `ask` block five times, storing each answer in a list variable using `add item to list`, creating their first programmatic survey that automatically collects multiple responses.

Dependencies:
* T25.G3.00: Connect picture data to code variables
* T07.G3.01: Use a counted repeat loop
* T10.G3.01: Create a list variable

Blocks: ask and wait, repeat, add item to list





ID: T25.G3.02
Topic: T25 – Data Collection & Logging
Skill: Design fair survey questions
Description: Learners compare two survey questions—one biased ("Don't you love cats?") and one neutral ("What is your favorite pet?")—then design their own fair question and implement it in CreatiCode using the ask block with multiple-choice buttons, ensuring all response options are equally valid.

Dependencies:
* T25.G3.01: Build a CreatiCode survey loop
* T08.G3.04: Use a simple if in a script
* T09.G3.02: Set a variable to a value

Blocks: ask and wait, answer, if-then





ID: T25.G3.03
Topic: T25 – Data Collection & Logging
Skill: Implement event logging with counters
Description: Students implement a script where a sprite increments a counter variable each time a key is pressed, simulating basic telemetry collection for tracking user interactions. They display the counter using a variable monitor.

Dependencies:
* T25.G3.01: Build a CreatiCode survey loop
* T08.G3.04: Use a simple if in a script
* T09.G3.03: Change a variable by an amount

Blocks: when key pressed, change variable by 1, variable monitor





ID: T25.G3.04.01
Topic: T25 – Data Collection & Logging
Skill: Store raw data in lists
Description: Students create a list to store all raw survey answers without any processing (e.g., 'red', 'blue', 'red', 'blue', 'red'), learning to preserve original data exactly as collected before any aggregation or transformation.

Dependencies:
* T25.G3.03: Implement event logging with counters
* T10.G3.01: Create a list variable
* T10.G3.02: Add and read items from a list

Blocks: create list, add to list





ID: T25.G3.04.02
Topic: T25 – Data Collection & Logging
Skill: Generate summary counts from raw data
Description: Students create a separate list that processes raw data to generate summary counts (e.g., 'red: 3', 'blue: 2'), demonstrating how to aggregate data while keeping the original data intact.

Dependencies:
* T25.G3.04.01: Store raw data in lists
* T08.G3.04: Use a simple if in a script
* T10.G3.03: Get the length of a list

Blocks: create list, add to list, join, length of list





ID: T25.G3.05
Topic: T25 – Data Collection & Logging
Skill: Identify common data collection mistakes
Description: Students analyze sample data sets containing common mistakes (missing entries, inconsistent spelling, duplicate records) and identify what went wrong, preparing them to track invalid data in G4.

Dependencies:
* T25.G3.04.02: Generate summary counts from raw data
* T08.G3.04: Use a simple if in a script





ID: T25.G3.06
Topic: T25 – Data Collection & Logging
Grade: Grade 3
Skill: Implement basic consent before data collection
Description: Students create a consent workflow that uses an ask block to get user permission ('Do you want to share your answer? yes/no') before collecting and saving any data. They use an if-then block to only store the response if the user agrees, learning to implement privacy-by-design.

Dependencies:
* T25.G3.01: Build a CreatiCode survey loop
* T08.G3.04: Use a simple if in a script

Blocks: ask and wait, if-then, add to list





ID: T25.G4.00
Topic: T25 – Data Collection & Logging
Grade: Grade 4
Skill: Design a data schema before collection
Description: Students plan what data fields to collect BEFORE writing code by creating a simple schema (column names and expected data types). For a game score tracker, they decide: "player_name (text), score (number), level (number), timestamp (number)". They then create an empty table with these columns, learning that good data design happens BEFORE data collection begins.

Dependencies:
* T25.G3.04.01: Store raw data in lists
* T25.G3.05: Identify common data collection mistakes
* T10.G3.03: Get the length of a list

Blocks: create table, set column names


ID: T25.G4.01
Topic: T25 – Data Collection & Logging
Skill: Create written data collection protocols for teammates
Description: Students draft multi-step written protocols (who to ask, how many people, what to say) so teammates can collect consistent data. This is a planning/documentation activity that applies knowledge from coding skills to organize real-world data collection processes.

Dependencies:
* T25.G4.00: Design a data schema before collection
* T09.G3.05: Trace code with variables to predict outcomes
* T10.G3.03: Get the length of a list
* T25.G3.04.02: Generate summary counts from raw data





ID: T25.G4.02.01
Topic: T25 – Data Collection & Logging
Skill: Create basic tables for logging
Description: Students create simple tables with columns (time, event) to log basic gameplay events. They practice adding rows to tables and understand table structure for organizing multi-attribute data.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.05: Trace code with variables to predict outcomes
* T10.G3.03: Get the length of a list
* T25.G3.04.01: Store raw data in lists

Blocks: create table, add row to table





ID: T25.G4.02.02
Topic: T25 – Data Collection & Logging
Skill: Log structured events with multiple attributes
Description: Students extend their tables to capture complex events with multiple attributes (time, event, player, score, level), creating comprehensive telemetry logs that mirror professional game logging systems.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.05: Trace code with variables to predict outcomes
* T25.G3.04.02: Generate summary counts from raw data
* T25.G4.02.01: Create basic tables for logging

Blocks: create table, add row to table, set cell in table, get cell from table





ID: T25.G4.03
Topic: T25 – Data Collection & Logging
Skill: Track missing or invalid data with flags
Description: Students add a "status" column to their data tables to flag entries as "valid", "missing", or "suspect", preparing them for data cleaning workflows. They use conditionals to automatically set flags based on data values.

Dependencies:
* T08.G3.04: Use a simple if in a script
* T09.G3.05: Trace code with variables to predict outcomes
* T25.G4.02.02: Log structured events with multiple attributes

Blocks: create table, add row to table, set cell in table, if-then





ID: T25.G4.04
Topic: T25 – Data Collection & Logging
Skill: Evaluate privacy risks in data collection
Description: Learners evaluate a proposed survey (asking for full names + addresses) and identify privacy concerns. They suggest safer alternatives that collect only necessary data, aligning with AI4K12 ethics and privacy-by-design principles.

Dependencies:
* T25.G3.06: Implement basic consent before data collection
* T25.G4.01: Create written data collection protocols for teammates





ID: T25.G4.05
Topic: T25 – Data Collection & Logging
Skill: Export and import list data to files
Description: Students export a list variable to a downloadable file, then import it back into a new project. They learn the basics of data persistence through files before moving to cloud databases.

Dependencies:
* T10.G3.03: Get the length of a list
* T25.G3.04.01: Store raw data in lists
* T25.G4.02.01: Create basic tables for logging

Blocks: export variable to file, import variable from file





ID: T25.G4.06
Topic: T25 – Data Collection & Logging
Skill: Collect data from one sensor
Description: Students collect data from a single sensor (microphone volume or mouse position) by logging its values to a list ten times using a counted loop. They use the `wait` block inside the loop to create consistent time gaps between readings (e.g., wait 0.5 seconds), building familiarity with continuous sensor data collection at regular intervals.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T10.G3.03: Get the length of a list
* T25.G4.02.01: Create basic tables for logging

Blocks: loudness of microphone, mouse x, mouse y, add item to list, repeat, timer, wait





ID: T25.G4.06.01
Topic: T25 – Data Collection & Logging
Grade: Grade 4
Skill: Use timer blocks for timestamped data collection
Description: Students use the `timer` reporter block to record timestamps alongside their data. They reset the timer at the start of collection and log the current timer value with each data point, learning that timestamps help track WHEN data was collected, not just WHAT was collected.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T09.G3.05: Trace code with variables to predict outcomes
* T25.G4.06: Collect data from one sensor

Blocks: repeat, reset timer, timer, add row to table





ID: T25.G4.07
Topic: T25 – Data Collection & Logging
Skill: Compute statistics from collected data
Description: Students apply list statistics blocks (min, max, sum, average) to analyze collected data, computing basic statistical summaries that reveal patterns in their datasets.

Dependencies:
* T09.G3.05: Trace code with variables to predict outcomes
* T10.G3.03: Get the length of a list
* T25.G3.04.01: Store raw data in lists

Blocks: min of list, max of list, sum of list, average of list, length of list




ID: T25.G4.08
Topic: T25 – Data Collection & Logging
Skill: Search for specific values in table columns
Description: Students use the `row # of item containing [value] in column [column] in table` block to search for specific entries in their logged data. They build a script that finds the row number where a player name appears or where a specific event type is logged, enabling targeted data lookup.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G4.02.02: Log structured events with multiple attributes

Blocks: row # of item containing in column in table, item at row column of table, if-then




ID: T25.G4.09
Topic: T25 – Data Collection & Logging
Skill: Count matching items in a table column
Description: Students use loops and conditionals to count how many rows in a table column match a specific value (e.g., count how many times "error" appears in an event type column). They compare the counted result to the expected count and identify discrepancies.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T10.G4.02: Read and modify cells in a table
* T25.G4.02.02: Log structured events with multiple attributes

Blocks: repeat, row count of table, item at row column of table, if-then, change variable by





ID: T25.G5.00
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Plan a data collection experiment
Description: Students design a complete data collection plan BEFORE coding: (1) define the research question ("Which game level is hardest?"), (2) identify what data to collect (attempts, completion time, failures), (3) specify how many samples needed, (4) plan the collection method (automatic logging vs manual entry). They document this plan and explain how the collected data will answer their question.

Dependencies:
* T25.G4.00: Design a data schema before collection
* T25.G4.01: Create written data collection protocols for teammates
* T25.G4.07: Compute statistics from collected data

Blocks: None (planning activity)


ID: T25.G5.01
Topic: T25 – Data Collection & Logging
Skill: Track game events with console logging
Description: Students insert print blocks at key points in their code to display messages to the console when specific game events occur (level start, player hit, score update), creating a chronological log for debugging and analysis. They combine the basic print, variable printing, and color-coding skills learned in the prerequisite sub-skills to build comprehensive event tracking.

Dependencies:
* T25.G5.01.01: Print messages to the console
* T25.G4.02.02: Log structured events with multiple attributes

Blocks: print to console, print to console with color, variables





ID: T25.G5.01.01
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Print messages to the console
Description: Students use the print to console block to display simple messages, learning the fundamental mechanism for outputting information to the console for debugging and logging.

Dependencies:
* T09.G3.05: Trace code with variables to predict outcomes
* T25.G4.02.02: Log structured events with multiple attributes

Blocks: print to console





ID: T25.G5.01.02
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Print variable values for debugging
Description: Students insert print statements that display variable values at key points in their code, learning to track how data changes during program execution.

Dependencies:
* T09.G3.05: Trace code with variables to predict outcomes
* T25.G5.01.01: Print messages to the console

Blocks: print to console, join, variables





ID: T25.G5.01.03
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Use color-coded console messages for event types
Description: Students use console blocks with different colors (red for errors, green for success, yellow for warnings) to create more informative logging systems that make it easier to identify event types at a glance.

Dependencies:
* T25.G5.01.02: Print variable values for debugging

Blocks: print to console with color, variables





ID: T25.G5.02
Topic: T25 – Data Collection & Logging
Skill: Design and implement sampling strategies
Description: Learners compare convenience sampling (asking the first 5 classmates) vs random sampling (using a random number generator). They plan which strategy to use, explain trade-offs between ease and representativeness, and implement their chosen strategy in CreatiCode.

Dependencies:
* T08.G4.03: Use if-else in a script
* T09.G4.01: Create and use a numeric variable for score or count
* T25.G3.01: Build a CreatiCode survey loop
* T25.G4.07: Compute statistics from collected data

Blocks: ask and wait, pick random from list





ID: T25.G5.03
Topic: T25 – Data Collection & Logging
Skill: Validate data entry with error checks
Description: Students add validation checks during collection (e.g., reject scores <0 or >100) to ensure data quality. They use conditionals to only accept valid entries and log rejected values.

Dependencies:
* T08.G4.03: Use if-else in a script
* T09.G4.01: Create and use a numeric variable for score or count
* T25.G4.03: Track missing or invalid data with flags

Blocks: if-then, comparison operators, add to list, print to console





ID: T25.G5.04.01
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Create tables with named columns
Description: Students create a table variable with specific column names (e.g., "time", "event", "player") and understand how column names serve as field labels that identify what each piece of data represents, preparing for structured data storage.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G4.00: Design a data schema before collection

Blocks: create table, set column names


ID: T25.G5.04
Topic: T25 – Data Collection & Logging
Skill: Store logs in tables for export
Description: Students push collected events into pre-designed table structures (using skills from T25.G5.04.01), populating rows with actual data from gameplay or sensor collection. They prepare the structured data for file export or database storage by ensuring all columns are consistently filled.

Dependencies:
* T25.G5.04.01: Create tables with named columns
* T25.G4.02.02: Log structured events with multiple attributes
* T25.G4.07: Compute statistics from collected data

Blocks: create table, add row to table, get cell from table, set cell in table





ID: T25.G5.05.01
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Insert table data into cloud database collection
Description: Students insert a simple data table (3-5 rows, 2-3 columns) into a database collection using the "insert from table into collection" block, learning to persist data to cloud storage.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.04: Store logs in CreatiCode tables for export

Blocks: insert from table into collection, collection name reporter, set database URL and key





ID: T25.G5.05.02
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Fetch data from cloud collection into table
Description: Students retrieve previously stored data from a database collection into a table variable using "fetch from collection into table" block, understanding data retrieval basics.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.05.01: Insert table data into cloud database collection

Blocks: fetch from collection into table, collection name reporter





ID: T25.G5.06.01
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Record player scores to leaderboard
Description: Students use leaderboard blocks to save player names and scores to persistent cloud storage, learning the basics of competitive game data tracking.

Dependencies:
* T09.G4.01: Create and use a numeric variable for score or count
* T10.G4.02: Read and modify cells in a table
* T25.G5.05.01: Insert table data into cloud database collection

Blocks: record score to leaderboard





ID: T25.G5.06.02
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Retrieve and display leaderboard rankings
Description: Students fetch top scores from the leaderboard and display them on stage, understanding how to retrieve and present ranked data.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.06.01: Record player scores to leaderboard

Blocks: show leaderboard, hide leaderboard





ID: T25.G5.07
Topic: T25 – Data Collection & Logging
Skill: Collect face detection data into tables
Description: Students use CreatiCode face detection blocks to capture facial landmark data (position, expression, orientation) into tables with timestamps, learning to collect and organize real-time sensor data for analysis.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T22.G4.01: Detect faces and show bounding boxes
* T25.G5.04: Store logs in CreatiCode tables for export

Blocks: detect faces, get face data, add row to table, timer






ID: T25.G5.08
Topic: T25 – Data Collection & Logging
Grade: Grade 5
Skill: Export and import tables to/from files
Description: Students export table variables to downloadable CSV files using the `export table` block and import them back using `import file into table`, understanding table file persistence and backup strategies for data collected during experiments.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.04: Store logs in tables for export
* T25.G4.05: Export and import list data to files

Blocks: export table to file, import file into table





ID: T25.G5.09
Topic: T25 – Data Collection & Logging
Skill: Collect data from two synchronized sensors
Description: Students log data from two different sensors simultaneously (e.g., mouse position and microphone volume) in the same row of a table, recording them together so the values stay synchronized for later analysis.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G4.06: Collect data from one sensor
* T25.G5.04: Store logs in tables for export
* T25.G5.04.01: Create tables with named columns

Blocks: loudness of microphone, mouse x, mouse y, add row to table, timer





ID: T25.G5.10
Topic: T25 – Data Collection & Logging
Skill: Save key-value data to server storage
Description: Students use server storage blocks to save simple key-value pairs (like player preferences or game settings) to persistent cloud storage, learning the basics of data persistence beyond local variables.

Dependencies:
* T09.G4.01: Create and use a numeric variable for score or count
* T25.G5.05.01: Insert table data into cloud database collection

Blocks: set server value for key, get server value for key





ID: T25.G5.11
Topic: T25 – Data Collection & Logging
Skill: Read key-value data from server storage
Description: Students retrieve previously stored key-value data from server storage, learning to access persistent data across sessions and use it to restore application state.

Dependencies:
* T09.G4.01: Create and use a numeric variable for score or count
* T25.G5.10: Save key-value data to server storage

Blocks: get server value for key, set variable to




ID: T25.G5.12
Topic: T25 – Data Collection & Logging
Skill: Retrieve and analyze console log contents programmatically
Description: Students use the `get console log` reporter block to retrieve all messages printed to the console as text. They parse this text to count specific keywords (e.g., count how many "ERROR" messages were logged) or extract the last N lines for display. This enables programmatic analysis of logged debug information rather than just visual inspection.

Dependencies:
* T25.G5.01: Track game events with console logging
* T10.G5.03: Add and remove items from a list

Blocks: get console log, length of, letter of, contains, split text





ID: T25.G6.01
Topic: T25 – Data Collection & Logging
Skill: Map stakeholder questions to data requirements
Description: Students receive stakeholder questions ("Which level is hardest?") and specify what data to collect (attempt count, completion time), aligning collection with analysis goals.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G5.04: Store logs in tables for export
* T25.G5.01: Track game events with console logging





ID: T25.G6.02
Topic: T25 – Data Collection & Logging
Skill: Automate logging from three different sensors
Description: Learners combine blocks to record data from three different sensor types (face detection, hand tracking, microphone level) simultaneously into a unified table, ensuring all data streams are captured with matching timestamps for synchronized analysis.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G5.04: Store logs in tables for export
* T25.G5.07: Collect face detection data into tables
* T25.G5.09: Collect data from two synchronized sensors

Blocks: detect faces, detect hands, loudness of microphone, add row to table, timer





ID: T25.G6.02.01
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Log hand tracking data to table
Description: Students use hand tracking blocks to capture hand landmark data (position, gesture) into tables with timestamps, learning to collect real-time body tracking sensor data.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T22.G5.01: Detect hands and show hand landmarks
* T25.G5.04: Store logs in tables for export

Blocks: detect hands, get hand data, add row to table, timer





ID: T25.G6.02.02
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Combine face and hand tracking data in one table
Description: Students log data from both face detection and hand tracking simultaneously into a unified table, learning to synchronize multiple AI sensor streams with matching timestamps.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.07: Collect face detection data into tables
* T25.G6.02.01: Log hand tracking data to table

Blocks: detect faces, detect hands, get face data, get hand data, add row to table, timer





ID: T25.G6.03
Topic: T25 – Data Collection & Logging
Skill: Create consent and opt-out workflows with widget dialogs
Description: Students implement dialog widget blocks that explain what will be collected, gather explicit user consent, and disable logging when declined, following privacy-by-design principles.

Dependencies:
* T08.G5.03: Use compound conditions (and, or, not)
* T25.G4.04: Evaluate privacy risks in data collection
* T25.G6.01: Map stakeholder questions to data requirements

Blocks: show dialog, ask and wait, if-then-else, add row to table





ID: T25.G6.04
Topic: T25 – Data Collection & Logging
Skill: Flag measurement accuracy in data tables
Description: Learners add a "data quality" column to their tables using descriptive flags like "verified," "estimated," or "uncertain." For example, they mark auto-recorded scores as "verified" but manually entered scores as "estimated," documenting measurement reliability alongside the data.

Dependencies:
* T08.G5.03: Use compound conditions (and, or, not)
* T10.G5.03: Add and remove items from a list
* T25.G5.03: Validate data entry with error checks

Blocks: create table, add row to table, set cell in table, if-then-else





ID: T25.G6.05
Topic: T25 – Data Collection & Logging
Skill: Insert data from tables into database collections
Description: Students use CreatiCode database blocks to insert rows from their data tables into cloud database collections, learning the basics of database operations and structured data storage for larger-scale data management.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.05.01: Insert table data into cloud database collection
* T25.G6.01: Map stakeholder questions to data requirements
* T25.G6.05.01: Trace document structure for database collections

Blocks: insert from table into collection, set database URL and key





ID: T25.G6.05.01
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Trace document structure for database collections
Description: Students examine how table rows (with column names as fields) map to database documents with field-value pairs, tracing the data structure transformation between tables and NoSQL documents.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G5.05.01: Insert table data into cloud database collection





ID: T25.G6.06.01
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Build simple database filter conditions
Description: Students create basic filter conditions using comparison operators (=, >, <, ≥, ≤, ≠) and field reporters to query specific records from a collection.

Dependencies:
* T08.G5.03: Use compound conditions (and, or, not)
* T10.G4.02: Read and modify cells in a table

Blocks: cond [comparison operators], field [fieldname] reporter





ID: T25.G6.06.01.01
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Build compound database conditions with AND/OR
Description: Students create compound filter conditions by combining multiple simple conditions with AND/OR logic (e.g., "score > 50 AND level = 3"), learning to express complex query requirements.

Dependencies:
* T25.G6.06.01: Build simple database filter conditions
* T08.G5.03: Use compound conditions (and, or, not)

Blocks: cond and, cond or, cond not, cond field [comparison], field reporter





ID: T25.G6.06.02
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Query database collections with filters
Description: Students use the fetch block with where conditions to retrieve filtered subsets of data (e.g., "score > 50"), understanding how to efficiently access relevant records from larger collections.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G6.06.01: Build simple database filter conditions
* T25.G5.05.02: Fetch data from cloud collection into table

Blocks: fetch from collection into table, where condition, limit





ID: T25.G6.06.03
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Sort database query results
Description: Students add sorting criteria to their database queries to retrieve data in specific order (ascending/descending by field), learning to organize query results for analysis.

Dependencies:
* T10.G6.01: Sort a table by a column

* T25.G6.06.02: Query database collections with filters

Blocks: fetch from collection into table, sort by field, ascending/descending





ID: T25.G6.07
Topic: T25 – Data Collection & Logging
Skill: Import data from Google Sheets into tables
Description: Students use Google Sheets integration blocks to pull data from shared spreadsheets into CreatiCode tables, enabling collaboration and data collection from external sources.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G5.04: Store logs in tables for export

Blocks: read from Google Sheets into table, set Google Sheets credentials





ID: T25.G6.08
Topic: T25 – Data Collection & Logging
Skill: Export tables to Google Sheets
Description: Learners push their collected data tables to Google Sheets for sharing with teammates or further analysis in spreadsheet tools, understanding data export workflows.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G5.04: Store logs in tables for export
* T25.G6.07: Import data from Google Sheets into tables

Blocks: write into Google Sheets from table, set Google Sheets credentials





ID: T25.G6.09
Topic: T25 – Data Collection & Logging
Skill: Log multiplayer game session data
Description: Students implement data collection in multiplayer games to track player interactions, scores, and events across multiple connected users, learning to handle concurrent data streams and player identification.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.06.01: Record player scores to leaderboard
* T25.G6.01: Map stakeholder questions to data requirements

Blocks: multiplayer blocks, add row to table, get player ID, timer





ID: T25.G6.10
Topic: T25 – Data Collection & Logging
Skill: Delete rows from tables by index
Description: Students learn to remove specific rows from tables using row index, understanding how to clean up or correct collected data by removing individual records.

Dependencies:
* T10.G4.02: Read and modify cells in a table
* T25.G5.04: Store logs in CreatiCode tables for export

Blocks: delete row from table at index, number of rows in table





ID: T25.G6.11
Topic: T25 – Data Collection & Logging
Skill: Clear all rows from a table
Description: Students use blocks to remove all rows from a table while preserving the column structure, learning to reset data collection tables for new sessions or experiments.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G6.10: Delete rows from tables by index

Blocks: clear all rows from table, create table


ID: T25.G6.12
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Implement rate limiting for high-frequency sensor data
Description: Students implement rate limiting to control how often sensor data is collected (e.g., only log every 100ms instead of every frame). They use timer checks to avoid overwhelming storage with redundant data from high-frequency sensors.

Dependencies:
* T07.G5.01: Use a repeat loop in a script
* T25.G6.02: Automate logging from three different sensors
* T25.G6.04: Flag measurement accuracy in data tables

Blocks: timer, if-then, reset timer, add row to table




ID: T25.G6.13
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Collect body pose detection data into tables
Description: Students use CreatiCode body pose detection blocks (`run 2D body part recognition` or `run 3D pose detection`) to capture body keypoint data (shoulders, elbows, wrists, hips, knees, ankles) into tables with timestamps. They log specific body part positions to track human movement patterns for fitness games, dance analysis, or gesture recognition training data.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T22.G6.09.01.01: Set up 2D body detection and view debug output
* T25.G6.02.02: Combine face and hand tracking data in one table

Blocks: run 2D body part recognition, run 3D pose detection, get body part position, add row to table, timer


ID: T25.G6.14
Topic: T25 – Data Collection & Logging
Grade: Grade 6
Skill: Prepare training data for machine learning
Description: Students create labeled datasets suitable for training simple ML classifiers. They collect sensor data (hand positions, face expressions) and add a "label" column indicating what the gesture/expression represents (e.g., "thumbs_up", "smile", "wave"). They ensure consistent labeling across samples and balance the dataset with equal examples per category, learning the fundamentals of supervised learning data preparation.

Dependencies:
* T25.G6.13: Collect body pose detection data into tables
* T25.G6.04: Flag measurement accuracy in data tables
* T25.G5.00: Plan a data collection experiment

Blocks: add row to table, set cell in table, create table, if-then


ID: T25.G7.01
Topic: T25 – Data Collection & Logging
Skill: Build reusable data collection modules
Description: Students wrap logging behavior into custom blocks (e.g., `logEvent type message data`) so multiple sprites can call the same routine.

Dependencies:
* T06.G5.01: Build a green-flag script that runs a 3-5 block sequence
* T09.G5.01: Trace code with variables to predict outcomes
* T10.G5.03: Add and remove items from a list
* T11.G5.03: Define a custom block with one parameter
* T25.G6.01: Map stakeholder questions to data requirements

Blocks: define custom block, call custom block, add row to table





ID: T25.G7.02
Topic: T25 – Data Collection & Logging
Skill: Monitor data quality in real time
Description: Learners build HUD widgets indicating percentage of responses collected, number of nulls, or out-of-range counts to catch issues while collecting.

Dependencies:
* T09.G6.01: Model real-world quantities using variables and formulas
* T25.G6.04: Flag measurement accuracy in data tables
* T25.G7.01: Build reusable data collection modules

Blocks: variable monitor, count items in list, if-then, operators





ID: T25.G7.03
Topic: T25 – Data Collection & Logging
Skill: Document provenance for external datasets
Description: Students import an open dataset from CSV files (weather data, public statistics) using file import blocks, then log metadata (source URL, license, date downloaded, when to refresh), reinforcing responsible data use and proper citation practices.

Dependencies:
* T10.G6.01: Sort a table by a column
* T25.G5.04: Store logs in tables for export
* T25.G6.03: Create consent and opt-out workflows with widget dialogs
* T25.G7.03.01: Import CSV data files into tables

Blocks: import table from file, create table, add row to table





ID: T25.G7.03.01
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Import CSV data files into tables
Description: Students use file import blocks to load CSV datasets (weather data, public statistics) into CreatiCode tables, learning to work with external data sources in standard formats.

Dependencies:
* T10.G6.01: Sort a table by a column
* T25.G5.04: Store logs in tables for export
* T25.G5.08: Export and import tables to/from files

Blocks: import table from file, read CSV into table





ID: T25.G7.03.02
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Create metadata table for data sources
Description: Students create a separate metadata table that documents information about their datasets (source URL, license, date downloaded, refresh date), learning to track data provenance systematically.

Dependencies:
* T10.G6.01: Sort a table by a column
* T25.G5.04: Store logs in tables for export
* T25.G7.03.01: Import CSV data files into tables

Blocks: create table, add row to table, set cell in table





ID: T25.G7.04
Topic: T25 – Data Collection & Logging
Skill: Evaluate bias risks introduced during collection
Description: Learners compare planned participants vs actual participants and highlight underrepresented groups, proposing corrective actions.

Dependencies:
* T10.G6.01: Sort a table by a column
* T25.G5.02: Design and implement sampling strategies
* T25.G7.02: Monitor data quality in real time





ID: T25.G7.05
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Debug data collection scripts using print statements
Description: Students debug data collection issues by strategically placing print statements to track variable values, loop iterations, and data transformations. They identify where data gets corrupted or lost in their collection pipeline.

Dependencies:
* T25.G5.01: Track game events with console logging
* T25.G5.04: Store logs in tables for export
* T07.G6.01: Trace nested loops with variable bounds

Blocks: print to console, variables, lists, tables





ID: T25.G7.06
Topic: T25 – Data Collection & Logging
Skill: Update and append data to Google Sheets
Description: Students use Google Sheets blocks to append new rows to existing spreadsheets or update specific cells based on conditions, enabling continuous data collection and collaborative data management.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G6.07: Import data from Google Sheets into tables
* T25.G6.08: Export tables to Google Sheets

Blocks: append row from table to sheet, set value at row/column in sheet





ID: T25.G7.07.01
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Update existing documents in database collections
Description: Students modify specific fields in existing database documents using update operations with where conditions, learning to maintain and correct stored data.

Dependencies:
* T10.G5.03: Add and remove items from a list
* T25.G6.06.02: Query database collections with filters
* T25.G6.06.01.01: Build compound database conditions with AND/OR

Blocks: update collection from table, update collection in-place where, set fields, cond expressions





ID: T25.G7.07.02
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Delete documents from database collections
Description: Students remove obsolete or unwanted documents from collections using delete operations with where conditions, understanding data lifecycle management.

Dependencies:
* T10.G6.01: Sort a table by a column
* T25.G7.07.01: Update existing documents in database collections
* T25.G6.06.01.01: Build compound database conditions with AND/OR

Blocks: remove all documents from collection where, cond expressions


ID: T25.G7.08
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Create real-time data dashboard with live updates
Description: Students build a dashboard that displays live data metrics (collection count, error rate, latest values) using widget labels that update automatically as new data arrives. They learn to visualize data collection progress in real time.

Dependencies:
* T25.G7.01: Build reusable data collection modules
* T25.G7.02: Monitor data quality in real time
* T25.G6.12: Implement rate limiting for high-frequency sensor data

Blocks: widget label, set label text, variable reporters, if-then


ID: T25.G7.09
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Implement data aggregation pipelines
Description: Students create batch processing pipelines that aggregate raw collected data into summary tables (e.g., hourly averages, daily totals, weekly trends). They use loops to process all rows and compute running totals or averages.

Dependencies:
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T25.G7.01: Build reusable data collection modules
* T25.G7.03.02: Create metadata table for data sources

Blocks: repeat, for each row in table, sum, average, add row to table





ID: T25.G8.01
Topic: T25 – Data Collection & Logging
Skill: Design end-to-end telemetry pipelines with cloud integration
Description: Students design a complete data pipeline diagram for a multi-level game, mapping the flow: (1) in-game events → (2) validation checks → (3) table storage → (4) database insert → (5) query/retrieval → (6) file export. They identify what data transformations happen at each stage and why.

Dependencies:
* T06.G6.01: Trace event execution paths in a multi-event program
* T10.G6.01: Sort a table by a column
* T25.G7.01: Build reusable data collection modules
* T25.G7.09: Implement data aggregation pipelines
* T07.G6.01: Trace nested loops with variable bounds





ID: T25.G8.01.01
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Implement end-to-end telemetry pipeline
Description: Students build a complete working telemetry system that collects game events, validates them, stores in tables, saves to database, and exports to file, implementing the pipeline they designed.

Dependencies:
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.07.01: Update existing documents in database collections
* T25.G6.06.02: Query database collections with filters
* T25.G5.08: Export and import tables to/from files

Blocks: All telemetry blocks (events, validation, tables, database insert/fetch/update, file export)





ID: T25.G8.02
Topic: T25 – Data Collection & Logging
Skill: Implement scheduled data exports and resets
Description: Learners script timed routines that export a table to file (or display) and then clear/reset logs, mirroring production data rotation.

Dependencies:
* T07.G7.01: Use repeat-until with compound conditions
* T25.G7.01: Build reusable data collection modules
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G6.11: Clear all rows from a table

Blocks: timer, export table to file, clear all rows from table, custom block





ID: T25.G8.03
Topic: T25 – Data Collection & Logging
Skill: Use AI assistant to review data collection protocols
Description: Students send their data collection protocol to the XO AI assistant for review, then document which suggestions they accepted or rejected, demonstrating human oversight of AI recommendations.

Dependencies:
* T23.G7.01: Generate text or ideas with AI prompts
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T21.G6.01.01: Make a basic ChatGPT request with one parameter

Blocks: XO chat, ask and wait, variables





ID: T25.G8.04
Topic: T25 – Data Collection & Logging
Skill: Publish data privacy agreements for peers
Description: Learners author a short agreement describing what data will be collected, how it's stored, who can access it, and deletion timelines, tying back to AI4K12's societal-impact focus.

Dependencies:
* T25.G6.03: Create consent and opt-out workflows with widget dialogs
* T25.G7.04: Evaluate bias risks introduced during collection
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration





ID: T25.G8.05
Topic: T25 – Data Collection & Logging
Skill: Create and search semantic databases for AI-powered data retrieval
Description: Students use CreatiCode semantic database blocks to store text documents with AI-generated embeddings, then perform natural language searches (e.g., 'find articles about space exploration') to retrieve semantically similar records, understanding how AI enables meaning-based search beyond exact keyword matching.

Dependencies:
* T23.G7.01: Generate text or ideas with AI prompts
* T25.G6.05: Insert data from tables into database collections
* T25.G6.06.02: Query database collections with filters

Blocks: semantic database insert, semantic search, embeddings


ID: T25.G8.06
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Design multi-source data fusion system
Description: Students design and implement a system that collects data from multiple independent sources (sensors, user input, AI detection), normalizes timestamps, and merges them into a unified dataset for comprehensive analysis. They handle conflicts and missing data across sources.

Dependencies:
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.09: Implement data aggregation pipelines
* T25.G6.02: Automate logging from three different sensors

Blocks: create table, merge tables, add row to table, timer, normalize functions


ID: T25.G8.07
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Implement streaming data collection with buffering
Description: Students implement a streaming data collection system that uses buffers to temporarily hold high-frequency data before batch-writing to storage. They manage buffer overflow, flush triggers, and data loss prevention.

Dependencies:
* T25.G8.01.01: Implement end-to-end telemetry pipeline
* T25.G6.12: Implement rate limiting for high-frequency sensor data
* T07.G7.01: Use repeat-until with compound conditions

Blocks: list as buffer, if buffer size > threshold, batch insert, clear buffer


ID: T25.G8.08
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Debug large-scale data collection with sampling
Description: Students implement debugging strategies for large data collection systems using sampling techniques (random sampling, systematic sampling) to inspect subsets of data without overwhelming the console. They identify patterns and anomalies in large datasets efficiently.

Dependencies:
* T25.G7.05: Debug data collection scripts using print statements
* T25.G7.09: Implement data aggregation pipelines
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration

Blocks: pick random, sample every nth row, print to console, if-then


ID: T25.G7.10
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Implement data versioning with change history
Description: Students create a versioning system that stores snapshots of data at key moments (before updates, after imports). They add a "version" column to tables and implement a custom block that copies current data to an archive table before modifications, enabling rollback to previous states.

Dependencies:
* T25.G7.01: Build reusable data collection modules
* T25.G7.03.02: Create metadata table for data sources
* T11.G5.03: Define a custom block with one parameter

Blocks: define custom block, clone table into archive, add column, set cell, timer


ID: T25.G7.11
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Create audit trail for data modifications
Description: Students implement an audit log table that records every data modification (insert, update, delete) with timestamp, user ID, action type, and before/after values. They use custom blocks to wrap all data operations and automatically log changes, ensuring accountability and traceability.

Dependencies:
* T25.G7.10: Implement data versioning with change history
* T25.G7.01: Build reusable data collection modules
* T25.G6.05: Insert data from tables into database collections

Blocks: define custom block, add row to audit table, timer, join, variables


ID: T25.G7.12
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Create pivot tables for multi-dimensional data aggregation
Description: Students use CreatiCode's `pivot table` block to transform raw logged data into summary tables with row groupings, value columns, and aggregation methods (sum, count, average). They pivot gameplay telemetry (e.g., grouping by level and player, computing average score) to create multi-dimensional analysis views that reveal patterns not visible in raw data.

Dependencies:
* T25.G7.09: Implement data aggregation pipelines
* T10.G6.01: Sort a table by a column
* T25.G7.01: Build reusable data collection modules

Blocks: pivot table into table row groups columns methods, sum, count, average, create table


ID: T25.G7.13
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Build collaborative data collection with cloud sessions
Description: Students use cloud session blocks (`create cloud session`, `join cloud session`) to enable multiple users to collect data simultaneously into shared cloud variables. They build a collaborative survey system where each participant's responses are automatically aggregated in real-time across all connected devices.

Dependencies:
* T25.G6.09: Log multiplayer game session data
* T25.G5.10: Save key-value data to server storage
* T25.G7.01: Build reusable data collection modules

Blocks: create cloud session, join cloud session, set cloud variable, get cloud variable, add row to table


ID: T25.G7.14
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Build data validation pipelines with automated checks
Description: Students create automated validation pipelines that check incoming data against rules before storage. They implement a multi-step process: (1) type checking (is score a number?), (2) range checking (is score between 0-100?), (3) format checking (is player name non-empty?). Invalid data is logged to an error table with the reason for rejection, ensuring data quality at collection time.

Dependencies:
* T25.G7.01: Build reusable data collection modules
* T25.G7.02: Monitor data quality in real time
* T25.G5.03: Validate data entry with error checks

Blocks: define custom block, if-then-else, comparison operators, add row to table


ID: T25.G7.15
Topic: T25 – Data Collection & Logging
Grade: Grade 7
Skill: Implement data deduplication algorithms
Description: Students implement algorithms to detect and remove duplicate records from their datasets. They define what makes a record "duplicate" (same player + same timestamp + same score = duplicate), search for matching records before insertion, and either skip duplicates or update existing records. They learn that deduplication is essential for accurate analysis.

Dependencies:
* T25.G7.14: Build data validation pipelines with automated checks
* T25.G4.08: Search for specific values in table columns
* T25.G7.07.01: Update existing documents in database collections

Blocks: row # of item containing in column in table, if-then-else, set cell in table, add row to table


ID: T25.G8.09
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Design data lineage tracking system
Description: Students design and implement a data lineage system that tracks where data originated (sensor, user input, API), what transformations were applied (aggregation, filtering, normalization), and where it flows (display, database, export). They create a lineage metadata table that links each data record to its source and transformation history.

Dependencies:
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.11: Create audit trail for data modifications
* T25.G7.03: Document provenance for external datasets

Blocks: create lineage table, add row, join, timer, variables, custom blocks


ID: T25.G8.10
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Implement data quality scoring algorithms
Description: Students create a data quality scoring system that evaluates collected data on multiple dimensions: completeness (% of non-empty fields), consistency (% matching expected formats), timeliness (age of data), and accuracy (% within valid ranges). They compute a composite quality score and flag records below threshold for review.

Dependencies:
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.02: Monitor data quality in real time
* T25.G6.04: Flag measurement accuracy in data tables

Blocks: count items, list operations, division, if-then, variables, add column


ID: T25.G8.11
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Build automated data anomaly detection
Description: Students implement anomaly detection algorithms that automatically identify outliers in collected data using statistical methods (values beyond 2 standard deviations, sudden spikes/drops compared to rolling average). They create alerts when anomalies are detected and log them to a separate anomaly table for investigation.

Dependencies:
* T25.G8.10: Implement data quality scoring algorithms
* T25.G7.09: Implement data aggregation pipelines
* T25.G5.03: Validate data entry with error checks

Blocks: average of list, standard deviation, abs, if-then, add row to table, print to console


ID: T25.G8.12
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Implement real-time data synchronization across devices
Description: Students design and implement a system that keeps data synchronized across multiple devices in real-time using fast-updating cloud variables. They handle race conditions (two users updating the same data simultaneously), implement conflict resolution strategies (last-write-wins, merge, or version-based), and ensure data consistency across all connected clients.

Dependencies:
* T25.G7.13: Build collaborative data collection with cloud sessions
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.10: Implement data versioning with change history

Blocks: create cloud session, fast-updating cloud variable, timer, if-then, compare timestamps


ID: T25.G8.13
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Use AI to optimize data collection pipelines
Description: Students use CreatiCode's AI assistant (XO chat) to analyze their data collection code and identify optimization opportunities. They prompt the AI with their pipeline description and collected data samples, evaluate AI suggestions for reducing redundancy, improving sampling rates, or optimizing storage patterns, then implement and test the most promising recommendations.

Dependencies:
* T25.G8.01.01: Implement end-to-end telemetry pipeline
* T25.G8.03: Use AI assistant to review data collection protocols
* T23.G7.01: Generate text or ideas with AI prompts

Blocks: XO chat, ask with system prompt, analyze response, variables


ID: T25.G8.14
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Design A/B testing framework for data collection experiments
Description: Students design and implement an A/B testing framework that randomly assigns users to experimental groups (A or B), collects data differently for each group (e.g., different sampling rates, different metrics logged), and tracks which group each data point belongs to. They analyze results to determine which collection strategy is more effective, learning the fundamentals of controlled experiments in data science.

Dependencies:
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.04: Evaluate bias risks introduced during collection
* T25.G7.12: Create pivot tables for multi-dimensional data aggregation

Blocks: pick random, set variable, if-then-else, add row to table, pivot table


ID: T25.G8.15
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Design data governance policies for team projects
Description: Students create comprehensive data governance documentation for a team project that specifies: (1) who can collect what data, (2) who can access/modify stored data, (3) how long data is retained, (4) how data should be backed up, (5) what happens when someone leaves the team. They implement access controls using visibility settings (public/private) in cloud storage and document the rationale for each policy decision.

Dependencies:
* T25.G8.04: Publish data privacy agreements for peers
* T25.G8.01: Design end-to-end telemetry pipelines with cloud integration
* T25.G7.11: Create audit trail for data modifications

Blocks: save data with visibility mode, cloud session blocks, create table


ID: T25.G8.16
Topic: T25 – Data Collection & Logging
Grade: Grade 8
Skill: Build ETL (Extract-Transform-Load) pipelines
Description: Students design and implement a complete ETL pipeline: (1) EXTRACT data from multiple sources (Google Sheets, database collections, CSV files), (2) TRANSFORM by cleaning, normalizing, and combining into unified format, (3) LOAD into a destination (database collection or export file). They handle errors at each stage and create logs tracking pipeline execution, learning the fundamental pattern used in professional data engineering.

Dependencies:
* T25.G8.01.01: Implement end-to-end telemetry pipeline
* T25.G6.07: Import data from Google Sheets into tables
* T25.G7.03.01: Import CSV data files into tables
* T25.G7.15: Implement data deduplication algorithms

Blocks: read from Google Sheets into table, fetch from collection into table, import file into table, insert from table into collection, export table to file, custom blocks


ID: T26.GK.01
Topic: T26 – Data Analysis & Storytelling
Skill: Sort classroom objects by a rule and explain it
Description: **Student task:** Drag classroom pictures into groups using a sorting rule (by color, size, or type), then tap a symbol to show the rule used. **Visual scenario:** 8 objects appear (red blocks, blue blocks, small balls, big balls). Student drags all red items to one box, blue items to another. Then taps the "color" button to indicate their sorting rule. **Success criteria:** All items sorted correctly and rule identified across 3 rounds with different rules. _Implementation note: Drag-drop sorting with visual rule confirmation._

Dependencies:
* T10.GK.01: Group pictures that are the same



ID: T26.GK.02
Topic: T26 – Data Analysis & Storytelling
Skill: Compare which pile has more snacks using picture cards
Description: **Student task:** Count picture cards in two piles and tap the pile with more items. **Visual scenario:** Two plates shown—Plate A has 3 apple pictures, Plate B has 5 apple pictures (numbers vary, always ≤5). Student counts each pile by tapping items, then taps the plate that has more. If equal, tap "same" button. **Success criteria:** Correctly identify larger group across 4 rounds. _Implementation note: Tap-to-count animation with audio feedback._

Dependencies:
* T26.GK.01: Sort classroom objects by a rule and explain it



ID: T26.GK.03
Topic: T26 – Data Analysis & Storytelling
Skill: Read a pictograph showing favorite fruits
Description: **Student task:** Answer questions by counting picture icons in a chart. **Visual scenario:** Pictograph shows "Favorite Fruit"—apples (4 icons), bananas (3 icons), oranges (2 icons). Each icon = 1 vote. Questions: "How many like apples?" "Which fruit is least popular?" Student taps numbers or fruit pictures to answer. **Success criteria:** Answer 4 questions correctly by reading the pictograph. _Implementation note: Interactive pictograph with tap-to-answer._

Dependencies:
* T26.GK.02: Compare which pile has more snacks using picture cards



ID: T26.GK.04
Topic: T26 – Data Analysis & Storytelling
Skill: Predict which pet is most popular before counting votes
Description: **Student task:** Make a prediction before seeing data results. **Visual scenario:** Screen shows 4 pet choices (dog, cat, fish, bird) with blank vote columns. Student taps their prediction: "I think DOG will win." Then votes appear one-by-one as icons fill columns. Student compares prediction to actual result. **Success criteria:** Make prediction, watch data appear, explain if prediction was correct or not. _Implementation note: Prediction selection followed by animated vote reveal._

Dependencies:
* T26.GK.03: Read a pictograph showing favorite fruits



ID: T26.GK.05
Topic: T26 – Data Analysis & Storytelling
Skill: Tell what the chart says using picture sentence starters
Description: **Student task:** Complete visual sentences describing chart findings using word/picture banks. **Visual scenario:** After viewing "Favorite Color" chart, student completes: [BLUE picture] "is the most popular because it has [7] votes." Choose from picture word bank and number tiles. **Success criteria:** Create 2 correct sentences describing chart data. _Implementation note: Drag-and-drop sentence construction with visual scaffolds._

Dependencies:
* T26.GK.03: Read a pictograph showing favorite fruits



ID: T26.GK.06
Topic: T26 – Data Analysis & Storytelling
Skill: Build a pictograph by dragging icons to match given numbers
Description: **Student task:** Create a pictograph from numerical data by dragging the correct number of icons into columns. **Visual scenario:** Instructions show "Apples: 4, Bananas: 2, Oranges: 5." Student drags fruit icons into the pictograph grid—exactly 4 apple icons in first column, 2 banana icons in second column, 5 orange icons in third column. **Success criteria:** Pictograph matches all given numbers correctly across 3 data scenarios. _Implementation note: Drag-drop icon placement with number reference visible._

Dependencies:
* T26.GK.03: Read a pictograph showing favorite fruits
* T26.GK.02: Compare which pile has more snacks using picture cards



ID: T26.G1.01
Topic: T26 – Data Analysis & Storytelling
Skill: Build a pictograph from tally marks about lunch choices
Description: **Student task:** Convert tally marks into a pictograph by dragging stacked icons. **Visual scenario:** Tally chart shows lunch votes—pizza (IIII = 4), sandwich (III = 3), salad (II = 2). Student drags food icons to build columns matching the tallies. Each icon = 1 vote. **Success criteria:** Pictograph columns match tally counts exactly. _Implementation note: Drag-drop icon placement with tally reference visible._

Dependencies:
* T26.GK.03: Read a pictograph showing favorite fruits



ID: T26.G1.02
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate "how many more?" using a pictograph
Description: **Student task:** Find the difference between two categories in a pictograph. **Visual scenario:** Pictograph shows birthday months—March (6 icons), April (4 icons), May (3 icons). Questions: "How many more birthdays in March than May?" Student counts: 6 - 3 = 3, taps "3". **Success criteria:** Correctly calculate differences for 3 comparison questions. _Implementation note: Tap-to-count with subtraction support._

Dependencies:
* T26.G1.01: Build a pictograph from tally marks about lunch choices



ID: T26.G1.03
Topic: T26 – Data Analysis & Storytelling
Skill: Describe a pictograph finding in one complete sentence
Description: **Student task:** Choose words to complete a sentence describing chart findings. **Visual scenario:** After viewing a "Favorite Season" pictograph, student completes: "The chart shows that [summer/winter/spring] is the [most/least] popular season because it has [3/5/7] votes." **Success criteria:** Create grammatically correct sentence with accurate data. _Implementation note: Word-bank sentence completion with validation._

Dependencies:
* T26.G1.01: Build a pictograph from tally marks about lunch choices



ID: T26.G1.04
Topic: T26 – Data Analysis & Storytelling
Skill: Identify questions that data can and cannot answer
Description: **Student task:** Sort question cards into "CAN answer" and "CANNOT answer" piles based on available data. **Visual scenario:** Chart shows "Books Read Per Student." Questions include: "Who read the most books?" (CAN), "Which book was best?" (CANNOT—no quality data), "How many total books?" (CAN). **Success criteria:** Correctly categorize 5 questions. _Implementation note: Drag questions to YES/NO zones with feedback._

Dependencies:
* T26.G1.03: Describe a pictograph finding in one complete sentence



ID: T26.G1.05
Topic: T26 – Data Analysis & Storytelling
Skill: Tell a simple data story using three picture cards
Description: **Student task:** Arrange three picture cards in order to tell a data story: question, data, conclusion. **Visual scenario:** Cards show: (1) "What's our favorite snack?", (2) bar chart showing votes, (3) "Apples won with 8 votes." Student drags cards into story order, then sprite reads the story aloud. **Success criteria:** Arrange cards in logical narrative order for 2 different datasets. _Implementation note: Three-card sequencing with audio narration._

Dependencies:
* T26.G1.03: Describe a pictograph finding in one complete sentence



ID: T26.G2.01
Topic: T26 – Data Analysis & Storytelling
Skill: Build a bar chart with labeled axes for weather data
Description: **Student task:** Create a bar chart by dragging bars to correct heights and labeling axes. **Visual scenario:** Data shows "Sunny Days This Week"—Monday (3 hours), Tuesday (5 hours), Wednesday (2 hours). Student drags bars to match heights, then labels: bottom axis = "Day", side axis = "Hours of Sun". **Success criteria:** Bar heights match data and both axes labeled correctly. _Implementation note: Drag-to-height bars with label placement zones._

Dependencies:
* T26.G1.01: Build a pictograph from tally marks about lunch choices



ID: T26.G2.02
Topic: T26 – Data Analysis & Storytelling
Skill: Read a line plot and identify increases and decreases
Description: **Student task:** Examine a line plot and answer questions about direction of change. **Visual scenario:** Line plot shows "Temperature This Week" with 5 points connected. Questions: "Did temperature go UP or DOWN from Monday to Tuesday?" "Which day was coldest?" "Did it get warmer or cooler overall?" **Success criteria:** Answer 4 direction questions correctly by tapping UP/DOWN/SAME arrows. _Implementation note: Interactive line plot with directional answer buttons._

Dependencies:
* T26.G2.01: Build a bar chart with labeled axes for weather data



ID: T26.G2.03
Topic: T26 – Data Analysis & Storytelling
Skill: Spot the value that looks different from the others
Description: **Student task:** Identify the outlier in a simple dataset. **Visual scenario:** Bar chart shows "Minutes Reading Each Day"—Monday (20), Tuesday (22), Wednesday (18), Thursday (21), Friday (5). Student taps Friday's bar and explains "It's much lower than the others." **Success criteria:** Correctly identify outliers in 3 different charts and explain why it's different. _Implementation note: Tap-to-select outlier with explanation validation._

Dependencies:
* T26.G2.01: Build a bar chart with labeled axes for weather data



ID: T26.G2.04
Topic: T26 – Data Analysis & Storytelling
Skill: Match questions to the charts that can answer them
Description: **Student task:** Connect question cards to appropriate chart types. **Visual scenario:** Three charts displayed: pictograph (favorite sports), bar chart (weekly temperatures), line plot (plant growth). Questions: "Which sport is most popular?" → pictograph, "Did the plant grow every day?" → line plot, "What was the coldest day?" → bar chart. **Success criteria:** Match 5 questions correctly. _Implementation note: Drag questions to matching charts._

Dependencies:
* T26.G1.04: Identify questions that data can and cannot answer
* T26.G2.02: Read a line plot and identify increases and decreases



ID: T26.G2.05
Topic: T26 – Data Analysis & Storytelling
Skill: Tell a weather story based on a line plot
Description: **Student task:** Describe what happened over time using a line plot. **Visual scenario:** Line plot shows "Temperature Mon-Fri." Student completes story: "On Monday it was [cold/warm]. Then it got [warmer/colder] until [Wednesday]. By Friday it was the [warmest/coldest] day." **Success criteria:** Complete 2-3 sentence weather story accurately describing the pattern. _Implementation note: Fill-in-blank story with line plot reference._

Dependencies:
* T26.G1.05: Tell a simple data story using three picture cards
* T26.G2.02: Read a line plot and identify increases and decreases



ID: T26.G2.06
Topic: T26 – Data Analysis & Storytelling
Skill: Compare two bar charts about the same topic
Description: **Student task:** Compare two bar charts showing similar data from different groups and identify similarities and differences. **Visual scenario:** Two bar charts show "Favorite Recess Activity" for Class A and Class B. Both have Soccer, Tag, and Swings. Student answers: "Which activity is #1 in both classes?" "Which class likes swings more?" **Success criteria:** Answer 3 comparison questions correctly. _Implementation note: Side-by-side charts with tap-to-answer._

Dependencies:
* T26.G2.01: Build a bar chart with labeled axes for weather data
* T26.G1.02: Calculate "how many more?" using a pictograph



ID: T26.G2.07
Topic: T26 – Data Analysis & Storytelling
Skill: Organize data into rows and columns using drag-and-drop grid
Description: **Student task:** Arrange data cards into a table structure with rows and columns. **Visual scenario:** Cards show student names, favorite colors, and ages. Student drags cards into a 3-column grid: Name | Color | Age. First row: "Alex | Blue | 7", second row: "Sam | Red | 8". **Success criteria:** Complete table with 5 rows of data correctly organized. _Implementation note: Grid-based drag-drop with column headers visible._ **This bridges to G3 table creation.**

Dependencies:
* T26.G2.01: Build a bar chart with labeled axes for weather data
* T10.G2.01: Identify objects that go together in the same group



ID: T26.G3.01
Topic: T26 – Data Analysis & Storytelling
Skill: Create a data table with columns in CreatiCode
Description: Students create table structure using 'add column [name] at position (1) to table [table1 v]'. They create a 3-column table (e.g., Name, Score, Grade) and verify columns appear in correct order. **Key concept:** Columns define what information each row will hold—like headers in a spreadsheet.

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T26.G2.01: Build a bar chart with labeled axes for weather data



ID: T26.G3.02
Topic: T26 – Data Analysis & Storytelling
Skill: Add rows of data to a table
Description: Students populate tables using 'add to table [table1 v]: [value1] [value2] [value3]' to append rows. They enter 5+ rows of real data (e.g., game scores) and understand that each row = one record. They verify data by checking row count increases after each addition.

Dependencies:
* T26.G3.01: Create a data table with columns in CreatiCode



ID: T26.G3.03
Topic: T26 – Data Analysis & Storytelling
Skill: Display and inspect table data on stage
Description: Students use 'show table [table1 v]' to display tables on stage for verification and 'hide table [table1 v]' to remove them. They practice inspecting data visually to confirm values were entered correctly before analysis.

Dependencies:
* T26.G3.02: Add rows of data to a table



ID: T26.G3.04
Topic: T26 – Data Analysis & Storytelling
Skill: Read individual cell values from a table
Description: Students use 'item at row (1) column [score] of table [data v]' to retrieve specific cell values. They practice reading the first row's name, then the third row's score, understanding row-column addressing like coordinates on a grid.

Dependencies:
* T26.G3.03: Display and inspect table data on stage



ID: T26.G3.05
Topic: T26 – Data Analysis & Storytelling
Skill: Count rows to determine dataset size
Description: Students use 'row count of table [data v]' to find how many records exist. They understand that row count tells us "how much data we have" and is essential for calculating averages or iterating through all rows.

Dependencies:
* T26.G3.04: Read individual cell values from a table



ID: T26.G3.06
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate the sum of a numeric column
Description: Students use '[sum v] of column [scores] in table [data v]' to total all values in a column. They apply this to scenarios like: total points scored, total items sold, total time spent. They display the result using a sprite's say block.

Dependencies:
* T26.G3.05: Count rows to determine dataset size



ID: T26.G3.07
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate the average of a numeric column
Description: Students use '[average v] of column [scores] in table [data v]' to find the mean. They understand average = sum ÷ count and interpret what average means: "A typical value" or "What most values are close to."

Dependencies:
* T26.G3.06: Calculate the sum of a numeric column



ID: T26.G3.08
Topic: T26 – Data Analysis & Storytelling
Skill: Find minimum and maximum values in a column
Description: Students use '[smallest v] of column [scores] in table [data v]' and '[largest v] of column [scores] in table [data v]' to find extremes. They calculate range (largest - smallest) and explain what extremes tell us: best performer, worst case, data spread.

Dependencies:
* T26.G3.07: Calculate the average of a numeric column



ID: T26.G3.09
Topic: T26 – Data Analysis & Storytelling
Skill: Display data findings using sprite speech bubbles
Description: Students combine computed statistics with say blocks to present findings: 'say (join "The average score is " [average of scores])'. They practice displaying multiple findings (average, max, min) in sequence, making data talk through the sprite.

Dependencies:
* T26.G3.08: Find minimum and maximum values in a column
* T09.G3.01.04: Display variable value on stage using the variable monitor



ID: T26.G3.10
Topic: T26 – Data Analysis & Storytelling
Skill: Draw a bar chart from table data
Description: Students use 'draw [bar v] chart using columns [scores] from table [data v] x (0) y (0) width (300) height (200)' to visualize data. They position the chart and understand that bar height = value magnitude. They compare visual heights to confirm which category is largest.

Dependencies:
* T26.G3.09: Display data findings using sprite speech bubbles



ID: T26.G3.11
Topic: T26 – Data Analysis & Storytelling
Skill: Draw a line chart to show change over time
Description: Students use 'draw [line v] chart using columns [daily_scores] from table [data v]' for time-series data. They understand line charts connect points to show trends—rising lines mean increasing values, falling lines mean decreasing. They identify peaks and valleys.

Dependencies:
* T26.G3.10: Draw a bar chart from table data



ID: T26.G3.12
Topic: T26 – Data Analysis & Storytelling
Skill: Select the appropriate chart type for different data questions
Description: Students learn chart selection rules: Bar charts for "which category has more?", Line charts for "how did values change over time?", Pie/percentage charts for "what fraction of the whole?" Given a data question, they select and draw the appropriate chart type.

Dependencies:
* T26.G3.11: Draw a line chart to show change over time



ID: T26.G3.13
Topic: T26 – Data Analysis & Storytelling
Skill: Create a simple data story with narration using text-to-speech
Description: Students use TTS blocks to narrate their data findings: 'speak [The highest score was 95, earned by Alex] voice [Female v]'. They create a 3-part data story: (1) introduce the question, (2) present key finding, (3) state conclusion. The sprite speaks the story aloud.

Dependencies:
* T26.G3.12: Select the appropriate chart type for different data questions
* T22.G3.01: Use the AI speaker to speak text in a chosen voice



ID: T26.G3.14
Topic: T26 – Data Analysis & Storytelling
Skill: Distinguish categorical, ordinal, and numeric data types
Description: Students examine datasets and classify each column's data type. **Categorical:** colors, names, yes/no (no order). **Ordinal:** small/medium/large, grades K-5 (has order but unequal spacing). **Numeric:** ages, scores, temperatures (mathematical operations make sense). They explain why data type matters: you can average numeric data but not categorical data.

Dependencies:
* T26.G3.05: Count rows to determine dataset size
* T26.G3.07: Calculate the average of a numeric column



ID: T26.G3.15
Topic: T26 – Data Analysis & Storytelling
Skill: Collect data from classmates using simple survey
Description: Students design a 2-question survey (e.g., "Favorite lunch?" "How many pets?"), collect responses from 10+ classmates using ask blocks, and store answers in a table. Each response becomes one row. They verify their data collection by displaying the table and checking row count matches survey participants.

Dependencies:
* T26.G3.02: Add rows of data to a table
* T09.G3.01.03: Read user input using the ask block and use the answer in a script



ID: T26.G3.16
Topic: T26 – Data Analysis & Storytelling
Skill: Identify repeating patterns in small time-series data
Description: Students examine simple time-series data (daily temperatures, weekly scores) to spot patterns that repeat. They identify: "Scores are always higher on Fridays" or "Temperature drops every 3rd day." They describe the pattern using complete sentences and predict what comes next based on the pattern.

Dependencies:
* T26.G3.11: Draw a line chart to show change over time
* T10.G3.01: Identify and extend repeating patterns in sequences



ID: T26.G4.01
Topic: T26 – Data Analysis & Storytelling
Skill: Sort tables by a column to reveal patterns
Description: Students use 'sort table [data v] by column [score] [large to small v]' to organize data. They sort scores high-to-low to find top performers, and alphabetically to find names. They observe how sorting makes patterns visible that were hidden in unsorted data.

Dependencies:
* T26.G3.08: Find minimum and maximum values in a column
* T08.G3.04: Use a simple if in a script



ID: T26.G4.02
Topic: T26 – Data Analysis & Storytelling
Skill: Delete rows matching a specific value
Description: Students use 'delete rows with column [status] of value [inactive] from table [data v]' to remove unwanted records. They clean data by removing "test" entries or filtering out incomplete records. They verify row count decreases after deletion.

Dependencies:
* T26.G4.01: Sort tables by a column to reveal patterns



ID: T26.G4.03
Topic: T26 – Data Analysis & Storytelling
Skill: Reset a table by deleting all rows
Description: Students use 'delete all rows from table [data v]' to clear table contents while keeping column structure. This prepares a table for fresh data collection. They verify the table is empty (row count = 0) but columns still exist.

Dependencies:
* T26.G4.02: Delete rows matching a specific value



ID: T26.G4.04
Topic: T26 – Data Analysis & Storytelling
Skill: Explain median as the middle value in sorted data
Description: Students examine small sorted datasets [2, 4, 5, 7, 9] and identify the median (5) by finding the middle position. They compare median vs mean when outliers exist: [2, 4, 5, 7, 100] has mean=23.6 but median=5. They explain why median better represents "typical" when extreme values exist.

Dependencies:
* T26.G4.01: Sort tables by a column to reveal patterns



ID: T26.G4.05
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate median using built-in table blocks
Description: Students use '[median v] of column [scores] in table [data v]' to compute the middle value. They verify by sorting the table and manually finding the middle row. They compare median and mean for datasets with and without outliers.

Dependencies:
* T26.G4.04: Explain median as the middle value in sorted data



ID: T26.G4.06
Topic: T26 – Data Analysis & Storytelling
Skill: Identify the mode as the most frequent value
Description: Students find the mode (most common value) in datasets like [A, B, A, C, A, B] where mode = A (appears 3 times). They explain when mode is useful: finding the most popular choice, most common error, or most frequent response in survey data.

Dependencies:
* T26.G4.04: Explain median as the middle value in sorted data



ID: T26.G4.07
Topic: T26 – Data Analysis & Storytelling
Skill: Filter rows by numeric condition using loops
Description: Students implement filtering with loops: iterate through rows, check if value meets condition (score > 50), copy matching rows to a new table. They learn this technique enables custom filters that built-in blocks don't support (like ranges or combinations).

Dependencies:
* T26.G4.01: Sort tables by a column to reveal patterns
* T07.G3.01: Use a counted repeat loop
* T08.G3.04: Use a simple if in a script



ID: T26.G4.08
Topic: T26 – Data Analysis & Storytelling
Skill: Analyze trends in line graphs over time
Description: Students examine game score data across 10 rounds using line charts. They identify rising segments (improving), falling segments (declining), and flat segments (stable). They annotate the graph: "Scores improved from round 3-6, then dropped."

Dependencies:
* T26.G3.11: Draw a line chart to show change over time
* T26.G4.01: Sort tables by a column to reveal patterns



ID: T26.G4.09.01
Topic: T26 – Data Analysis & Storytelling
Skill: Check for missing values in data
Description: Students inspect tables to identify empty cells or missing data. They use 'show table' and scan each column systematically, documenting which rows have blank values. They count: "5 out of 20 rows are missing age data." They understand missing data affects analysis accuracy.

Dependencies:
* T26.G4.01: Sort tables by a column to reveal patterns
* T26.G3.03: Display and inspect table data on stage



ID: T26.G4.09.02
Topic: T26 – Data Analysis & Storytelling
Skill: Identify duplicate rows in datasets
Description: Students sort tables and scan for consecutive identical rows. They use sorting by multiple columns to reveal duplicates: "Alex, Score 85" appears twice. They understand duplicates can inflate counts and skew averages. They document which rows are duplicated before deciding how to handle them.

Dependencies:
* T26.G4.09.01: Check for missing values in data
* T26.G4.01: Sort tables by a column to reveal patterns



ID: T26.G4.09.03
Topic: T26 – Data Analysis & Storytelling
Skill: Spot impossible values in data
Description: Students examine data for logically impossible values: negative ages, scores above 100%, dates in the future, temperatures below absolute zero. They use conditionals to flag suspicious values: "if age < 0 or age > 120, say 'Check this value!'" They create validation rules based on real-world constraints.

Dependencies:
* T26.G4.09.02: Identify duplicate rows in datasets
* T08.G3.04: Use a simple if in a script



ID: T26.G4.10
Topic: T26 – Data Analysis & Storytelling
Skill: Handle missing and invalid data in tables
Description: Students implement data cleaning strategies: (1) skip rows with empty values using conditionals, (2) replace missing numbers with the column average, (3) delete rows with invalid values. They document their cleaning decisions and explain why each choice was made.

Dependencies:
* T26.G4.09.03: Spot impossible values in data



ID: T26.G4.11
Topic: T26 – Data Analysis & Storytelling
Skill: Write narrative captions explaining chart findings
Description: Students write 2-3 sentence captions for charts following the pattern: (1) What does the chart show? (2) What's the key finding? (3) Who should care? Example: "This chart shows daily step counts. Steps increased steadily from Monday to Friday. This suggests students are more active during the school week."

Dependencies:
* T26.G4.08: Analyze trends in line graphs over time
* T26.G3.09: Display data findings using sprite speech bubbles



ID: T26.G4.12
Topic: T26 – Data Analysis & Storytelling
Skill: Identify sampling bias in data collection
Description: Students examine scenarios where samples don't represent everyone: surveying only athletes about favorite activities, asking only morning students about lunch preferences. They identify who's missing and explain how conclusions could be wrong. Key insight: "Who did we NOT ask?"

Dependencies:
* T26.G4.10: Handle missing and invalid data in tables



ID: T26.G4.13
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate data range to measure spread
Description: Students compute range (largest - smallest) for a column to measure how spread out values are. They compare two datasets: Class A scores [70-90] range=20 vs Class B scores [40-100] range=60. They explain what larger range means (more variability, less consistent).

Dependencies:
* T26.G4.05: Calculate median using built-in table blocks



ID: T26.G4.14
Topic: T26 – Data Analysis & Storytelling
Skill: Create a spoken data report using text-to-speech
Description: Students build a multi-part spoken report combining TTS with computed statistics. The sprite announces: "Data Report: We analyzed [row count] scores. The average was [average]. The highest was [max] and lowest was [min]. Overall, performance was [above/below] average." Variables fill in computed values.

Dependencies:
* T26.G4.11: Write narrative captions explaining chart findings
* T26.G3.13: Create a simple data story with narration using text-to-speech



ID: T26.G4.15
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate simple fractions of datasets
Description: Students compute fractions of totals: 1/2, 1/4, 3/4 of dataset values. Given 20 total students, they calculate: 1/2 = 10 students, 1/4 = 5 students, 3/4 = 15 students. They apply to data analysis: "1/4 of students scored below 70" or "3/4 of responses were positive." They verify calculations using row count.

Dependencies:
* T26.G3.05: Count rows to determine dataset size
* T26.G3.06: Calculate the sum of a numeric column



ID: T26.G4.16
Topic: T26 – Data Analysis & Storytelling
Skill: Trace why calculated result differs from expected value
Description: Students debug analysis when results seem wrong. They trace step-by-step: "Expected average of 80, but got 65. Let me check: (1) Are all rows included? No—2 missing. (2) Did I use the right column? Yes. (3) Are there bad values? Found one score of 0 that should be removed." They systematically verify inputs, formulas, and logic.

Dependencies:
* T26.G4.10: Handle missing and invalid data in tables
* T26.G3.07: Calculate the average of a numeric column



ID: T26.G4.17
Topic: T26 – Data Analysis & Storytelling
Skill: Write unbiased survey questions
Description: Students compare biased vs unbiased questions. **Biased:** "Don't you agree homework is too much?" (leads to yes). **Unbiased:** "Do you think homework amount is too much, just right, or too little?" They rewrite leading questions to be neutral, provide balanced options, and avoid emotional language that influences responses.

Dependencies:
* T26.G3.15: Collect data from classmates using simple survey
* T26.G4.12: Identify sampling bias in data collection



ID: T26.G4.18
Topic: T26 – Data Analysis & Storytelling
Skill: Read and interpret real-world infographics from news or reports
Description: Students examine authentic infographics (weather maps, sports stats, news charts) and answer questions: What's the main message? What data supports it? What chart types are used? They identify visual elements (icons, colors, labels) that make information clear. They practice translating visual data into written summaries.

Dependencies:
* T26.G4.11: Write narrative captions explaining chart findings
* T26.G3.12: Select the appropriate chart type for different data questions



ID: T26.G5.01
Topic: T26 – Data Analysis & Storytelling
Skill: Draw percentage charts showing parts of a whole
Description: Students use 'draw [percentage v] chart using columns [categories] from table [data v]' to visualize proportions. They understand percentages show relative size (30% vs 70%) regardless of total count. They interpret: "Even though Group A has more people, Group B's percentage is higher."

Dependencies:
* T26.G3.12: Select the appropriate chart type for different data questions



ID: T26.G5.02
Topic: T26 – Data Analysis & Storytelling
Skill: Draw pie charts with category and value columns
Description: Students use 'draw pie chart using category [type] and value [count] from table [data v]' for composition analysis. They understand pie charts show "what fraction of the whole" each category represents. They verify all slices add to 100%.

Dependencies:
* T26.G5.01: Draw percentage charts showing parts of a whole



ID: T26.G5.03
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate percentages from raw counts
Description: Students compute percentage: (part ÷ whole) × 100. Given "15 chose pizza out of 50 total," they calculate 15/50 = 0.30 = 30%. They display results: "Pizza: 30%, Salad: 20%, Burger: 50%". They verify percentages sum to 100%.

Dependencies:
* T26.G5.02: Draw pie charts with category and value columns
* T09.G4.01: Read multiple inputs via ask blocks and apply them in conditions



ID: T26.G5.04
Topic: T26 – Data Analysis & Storytelling
Skill: Group data and compute statistics per category (GROUP BY)
Description: Students use 'set table [summary v] to [average v] of column [score] in table [data v] by column [grade]' to create summary tables. They analyze "average score per grade" or "total sales per region." They compare groups: "Grade 5 averaged 85, Grade 6 averaged 78."

Dependencies:
* T26.G4.01: Sort tables by a column to reveal patterns
* T26.G3.07: Calculate the average of a numeric column



ID: T26.G5.05
Topic: T26 – Data Analysis & Storytelling
Skill: Add widget labels and buttons to the stage
Description: Students use widget blocks ('add button', 'add label') to create UI elements. They position widgets at specific coordinates and set initial text. They create a label showing "Total Records: 25" that updates when data changes.

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence
* T26.G5.03: Calculate percentages from raw counts



ID: T26.G5.06
Topic: T26 – Data Analysis & Storytelling
Skill: Respond to widget button clicks with code
Description: Students use 'when widget [filterButton v] clicked' events to trigger actions. They connect buttons to operations: "Show High Scores" button filters to scores > 80, "Reset" button shows all data. They understand event-driven UI interaction.

Dependencies:
* T26.G5.05: Add widget labels and buttons to the stage
* T06.G4.01: Sequence multiple sprite events



ID: T26.G5.07
Topic: T26 – Data Analysis & Storytelling
Skill: Build a simple interactive data dashboard
Description: Students combine widgets, tables, and charts into a dashboard. Clicking "Filter by Grade 5" filters data and redraws the chart. They create a cohesive interface where UI controls data display. They test that all buttons work correctly.

Dependencies:
* T26.G5.06: Respond to widget button clicks with code
* T26.G4.07: Filter rows by numeric condition using loops



ID: T26.G5.08
Topic: T26 – Data Analysis & Storytelling
Skill: Explore correlation between two variables visually
Description: Students plot two variables together (study hours vs test scores) using dual-column charts. They describe patterns: positive correlation (both increase together), negative correlation (one up, one down), no correlation (random). They state findings: "Students who studied more tended to score higher."

Dependencies:
* T26.G5.04: Group data and compute statistics per category (GROUP BY)
* T26.G4.08: Analyze trends in line graphs over time



ID: T26.G5.09
Topic: T26 – Data Analysis & Storytelling
Skill: Compare datasets from two different sources
Description: Students analyze two related tables (expected vs actual sales, predicted vs observed) to find discrepancies. They calculate differences for each row and identify which predictions were accurate. They hypothesize causes: "Week 3 actual was much higher than expected—maybe there was a sale."

Dependencies:
* T26.G5.08: Explore correlation between two variables visually



ID: T26.G5.10
Topic: T26 – Data Analysis & Storytelling
Skill: Present data findings with charts and widget summaries
Description: Students create a presentation combining: (1) a chart visualization, (2) a text widget with key insight, (3) a recommendation. Example: Chart shows declining scores; widget states "Scores dropped 15% this month"; recommendation: "Consider extra practice sessions."

Dependencies:
* T26.G5.07: Build a simple interactive data dashboard
* T26.G4.11: Write narrative captions explaining chart findings



ID: T26.G5.11
Topic: T26 – Data Analysis & Storytelling
Skill: Formulate and test a hypothesis with data
Description: Students state predictions before analysis: "I predict students who eat breakfast score higher." They analyze data to test the hypothesis, compare groups, and conclude: "The data supports/contradicts my hypothesis because..." This introduces the scientific method in data analysis.

Dependencies:
* T26.G5.08: Explore correlation between two variables visually
* T26.G4.12: Identify sampling bias in data collection



ID: T26.G5.12
Topic: T26 – Data Analysis & Storytelling
Skill: Create an AI-generated image to illustrate data findings
Description: Students use AI image generation blocks to create visuals that represent their data story. After finding "dogs are the most popular pet," they generate an image of "happy dogs in a park" to illustrate their report. They learn to combine data analysis with creative visual communication.

Dependencies:
* T26.G5.10: Present data findings with charts and widget summaries
* T21.G4.01: Generate AI images from text descriptions



ID: T26.G5.13
Topic: T26 – Data Analysis & Storytelling
Skill: Evaluate whether a data source is credible for answering a question
Description: Students assess data quality by asking: (1) Who collected this data and why? (2) How old is it? (3) Does the sample represent the population? (4) Are there obvious gaps? They compare two sources for the same question and choose the more reliable one, explaining their reasoning: "Source A surveyed 1000 people last month; Source B surveyed 20 people 5 years ago—Source A is more credible."

Dependencies:
* T26.G4.12: Identify sampling bias in data collection
* T26.G5.09: Compare datasets from two different sources



ID: T26.G5.14
Topic: T26 – Data Analysis & Storytelling
Skill: Remove personally identifiable information from datasets
Description: Students identify PII (names, addresses, phone numbers, student IDs) in datasets and replace with anonymous codes. They transform "Alex Smith, age 10, 123 Main St" to "Student_001, age 10, City_A." They explain why protecting privacy matters even in classroom data and when de-identification is required.

Dependencies:
* T26.G4.10: Handle missing and invalid data in tables
* T26.G3.02: Add rows of data to a table



ID: T26.G5.15
Topic: T26 – Data Analysis & Storytelling
Skill: Break complex data question into smaller answerable parts
Description: Students practice decomposition with complex questions like "Are students getting healthier?" They break it into: (1) What does "healthier" mean? (sports participation, sick days?), (2) What data do we need?, (3) How far back?, (4) How do we measure change? They solve each sub-question, then combine answers to address the original question.

Dependencies:
* T26.G5.11: Formulate and test a hypothesis with data
* T26.G5.04: Group data and compute statistics per category (GROUP BY)



ID: T26.G5.16
Topic: T26 – Data Analysis & Storytelling
Skill: Create reusable analysis template for similar datasets
Description: Students build generalized analysis scripts using custom blocks or variables for table names. They create a "Weekly Report Template" that works for any week's data: import table, calculate stats, draw chart, generate summary. They test the template with 3 different weeks to verify it adapts correctly—demonstrating abstraction.

Dependencies:
* T26.G5.07: Build a simple interactive data dashboard
* T14.G4.01: Define and use a custom block with parameters



ID: T26.G5.17
Topic: T26 – Data Analysis & Storytelling
Skill: Use test data with known results to verify analysis code
Description: Students create small test datasets where they know the correct answer (e.g., 5 scores: 80, 80, 80, 80, 80 → average should be exactly 80). They run their analysis code on test data first, verify it produces expected results, then apply to real data. This debugging technique catches errors before analyzing real data.

Dependencies:
* T26.G4.16: Trace why calculated result differs from expected value
* T26.G5.04: Group data and compute statistics per category (GROUP BY)



ID: T26.G6.01
Topic: T26 – Data Analysis & Storytelling
Skill: Look up a row index by searching for a value
Description: Students use 'row # of [John] in column [name] in table [students v]' to find which row contains a specific value. They understand this returns a number (row position) that can be used to retrieve other data from that row. They handle "not found" cases (-1).

Dependencies:
* T26.G5.04: Group data and compute statistics per category (GROUP BY)
* T09.G4.04: Trace code with variables to predict outcomes



ID: T26.G6.02
Topic: T26 – Data Analysis & Storytelling
Skill: Perform VLOOKUP-style cross-table lookups
Description: Students implement two-step lookups: (1) find row# where name="John", (2) get age from that row. They build lookup functions that find a student's grade given their name, similar to spreadsheet VLOOKUP. They handle cases where the lookup value doesn't exist.

Dependencies:
* T26.G6.01: Look up a row index by searching for a value



ID: T26.G6.03
Topic: T26 – Data Analysis & Storytelling
Skill: Filter tables with AND conditions (multiple criteria)
Description: Students filter rows where ALL conditions are true: "grade = 5 AND score > 80". They understand AND is restrictive—more conditions = fewer matches. They implement using loops with compound conditionals and verify filter results match expectations.

Dependencies:
* T26.G4.07: Filter rows by numeric condition using loops
* T08.G4.03: Use an if-else block with compound conditions



ID: T26.G6.04
Topic: T26 – Data Analysis & Storytelling
Skill: Filter tables with OR conditions (any criteria)
Description: Students filter rows where ANY condition is true: "grade = 5 OR grade = 6". They understand OR is permissive—more conditions = more matches. They contrast with AND: the same data filtered with AND vs OR produces different row counts.

Dependencies:
* T26.G6.03: Filter tables with AND conditions (multiple criteria)



ID: T26.G6.05
Topic: T26 – Data Analysis & Storytelling
Skill: Combine related data from two tables (JOIN)
Description: Students merge two tables sharing a common column (student_id). They iterate through Table A, look up matching rows in Table B, and copy combined data to a new table. This database-style JOIN enables richer analysis from connected datasets.

Dependencies:
* T26.G6.02: Perform VLOOKUP-style cross-table lookups
* T26.G6.04: Filter tables with OR conditions (any criteria)



ID: T26.G6.06
Topic: T26 – Data Analysis & Storytelling
Skill: Compare two groups statistically
Description: Students split data into groups (Treatment vs Control, Version A vs B), compute statistics for each (average, median, range), calculate the difference, and evaluate: "Group A averaged 85, Group B averaged 72. The 13-point difference is large relative to the 20-point typical range."

Dependencies:
* T26.G6.03: Filter tables with AND conditions (multiple criteria)
* T26.G5.04: Group data and compute statistics per category (GROUP BY)



ID: T26.G6.07
Topic: T26 – Data Analysis & Storytelling
Skill: Create pivot tables for multi-dimensional summaries
Description: Students use 'pivot [data v] into [summary v] row groups [grade,gender] columns [score] methods [average]' to analyze data across multiple dimensions simultaneously. They read pivot tables to answer: "What's the average score for Grade 5 girls?" They understand how pivots reshape data for comparison.

Dependencies:
* T26.G5.04: Group data and compute statistics per category (GROUP BY)
* T10.G4.01: Use list length and item access in expressions



ID: T26.G6.08
Topic: T26 – Data Analysis & Storytelling
Skill: Identify trends and cycles in time-series data
Description: Students analyze multi-week data to distinguish: (1) trends (consistent direction over time), (2) cycles (repeating patterns like weekly spikes), (3) random fluctuations. They support conclusions with evidence: "Sales trend upward but spike every weekend (cyclical pattern)."

Dependencies:
* T26.G5.08: Explore correlation between two variables visually
* T26.G6.06: Compare two groups statistically



ID: T26.G6.09
Topic: T26 – Data Analysis & Storytelling
Skill: Export analysis results to CSV files
Description: Students use 'export table [data v] as [analysis_results]' to save tables as CSV for sharing. They export filtered subsets, summary statistics, or full datasets. They understand CSV as a universal format readable by spreadsheets, databases, and other tools.

Dependencies:
* T26.G6.08: Identify trends and cycles in time-series data



ID: T26.G6.10
Topic: T26 – Data Analysis & Storytelling
Skill: Import external data from CSV files
Description: Students use 'import file into table [imported v]' to load real-world CSV datasets. They inspect imported data for issues (wrong column types, encoding problems), understand file selection, and verify data loaded correctly by checking row counts and sample values.

Dependencies:
* T26.G6.09: Export analysis results to CSV files



ID: T26.G6.11
Topic: T26 – Data Analysis & Storytelling
Skill: Write structured analysis summaries (METRIC-INSIGHT-ACTION)
Description: Students organize findings using a consistent structure: METRIC (the key number: "Average score: 78"), INSIGHT (the pattern: "Scores declined 12% from last month"), ACTION (the recommendation: "Investigate what changed"). They practice this format for clear, actionable communication.

Dependencies:
* T26.G6.06: Compare two groups statistically
* T26.G5.10: Present data findings with charts and widget summaries



ID: T26.G6.12
Topic: T26 – Data Analysis & Storytelling
Skill: Normalize data for fair comparisons across different scales
Description: Students convert raw counts to rates for fair comparison: "goals per game" (not total goals) to compare players with different games played. They calculate normalized values: Player A (12 goals in 8 games = 1.5/game) vs Player B (10 goals in 5 games = 2.0/game). Player B is actually better!

Dependencies:
* T26.G5.03: Calculate percentages from raw counts
* T26.G6.06: Compare two groups statistically



ID: T26.G6.13
Topic: T26 – Data Analysis & Storytelling
Skill: Detect and critique misleading visualizations
Description: Students identify manipulation techniques: truncated Y-axes that exaggerate differences, cherry-picked date ranges, 3D effects that distort proportions, dual Y-axes that imply false correlations. They explain how each trick misleads and propose fixes. This builds critical media literacy.

Dependencies:
* T26.G6.08: Identify trends and cycles in time-series data
* T26.G4.12: Identify sampling bias in data collection



ID: T26.G6.14
Topic: T26 – Data Analysis & Storytelling
Skill: Create a data-driven story with multiple chapters
Description: Students build a multi-part data story: (1) "The Question" - what we wanted to know, (2) "The Data" - where it came from and limitations, (3) "The Analysis" - what we computed, (4) "The Finding" - what we discovered, (5) "The Action" - what should happen next. They use TTS to narrate each chapter.

Dependencies:
* T26.G6.11: Write structured analysis summaries (METRIC-INSIGHT-ACTION)
* T26.G4.14: Create a spoken data report using text-to-speech



ID: T26.G6.15
Topic: T26 – Data Analysis & Storytelling
Skill: Use ChatGPT to help interpret data findings
Description: Students send computed statistics to ChatGPT for interpretation: "My data shows: average=75, median=82, range=45. What might this tell us about the distribution?" They evaluate the AI's response against their own understanding and identify when AI interpretation is helpful vs when human judgment is needed.

Dependencies:
* T26.G6.11: Write structured analysis summaries (METRIC-INSIGHT-ACTION)
* T21.G6.01: Send a prompt to XO and display the response



ID: T26.G6.16
Topic: T26 – Data Analysis & Storytelling
Skill: Distinguish between correlation and causation with examples
Description: Students examine correlated variables and determine if one causes the other. Example: "Ice cream sales and drowning deaths both increase in summer—they're correlated but neither causes the other (heat is the common cause)." They practice identifying: true causation, coincidence, and common-cause scenarios. They explain why correlation alone cannot prove causation.

Dependencies:
* T26.G5.08: Explore correlation between two variables visually
* T26.G6.06: Compare two groups statistically



ID: T26.G6.17
Topic: T26 – Data Analysis & Storytelling
Skill: Create calculated columns from existing data
Description: Students add new columns computed from existing ones. They calculate Age from BirthDate, Total from Price × Quantity, or Grade from Score ranges. They use loops to iterate through rows, compute new value for each row, and add to table. They verify calculations on sample rows before processing entire dataset.

Dependencies:
* T26.G6.05: Combine related data from two tables (JOIN)
* T26.G3.02: Add rows of data to a table



ID: T26.G6.18
Topic: T26 – Data Analysis & Storytelling
Skill: Trace data lineage (where data came from and transformations applied)
Description: Students document the complete history of their dataset: original source, when collected, filters applied, columns added/removed, rows deleted, calculations performed. They create a "Data Log" showing each transformation step. They understand why lineage matters: to reproduce results and identify where errors might have occurred.

Dependencies:
* T26.G6.17: Create calculated columns from existing data
* T26.G6.10: Import external data from CSV files



ID: T26.G6.19
Topic: T26 – Data Analysis & Storytelling
Skill: Detect when AI gives incorrect statistical explanations
Description: Students verify AI-generated analysis by checking calculations manually. When ChatGPT explains statistics, they test: "AI said average is 85, let me calculate: (80+90+85)/3 = 85. Correct!" or "AI said median is 70, but when I sort [50,60,80,90], middle is between 60 and 80 = 70. Correct!" They identify AI errors and learn when to trust vs verify.

Dependencies:
* T26.G6.15: Use ChatGPT to help interpret data findings
* T26.G5.17: Use test data with known results to verify analysis code



ID: T26.G6.20
Topic: T26 – Data Analysis & Storytelling
Skill: Adapt data presentation for technical vs non-technical audiences
Description: Students create two versions of the same finding. **Technical:** "Pearson correlation coefficient: 0.73, p<0.05, n=50, suggests moderate positive relationship." **Non-technical:** "Students who study more tend to score higher—we saw this pattern in 50 students." They identify which details to include/exclude based on audience expertise.

Dependencies:
* T26.G6.11: Write structured analysis summaries (METRIC-INSIGHT-ACTION)
* T26.G6.14: Create a data-driven story with multiple chapters



ID: T26.G6.21
Topic: T26 – Data Analysis & Storytelling
Skill: Find and access public datasets (government, research)
Description: Students explore public data sources (census.gov, data.gov, school district reports) to find real datasets. They identify relevant datasets for a question, understand data dictionaries (what each column means), download CSV files, and import into CreatiCode. They compare official vs unofficial data sources.

Dependencies:
* T26.G6.10: Import external data from CSV files
* T26.G5.13: Evaluate whether a data source is credible for answering a question



ID: T26.G7.01
Topic: T26 – Data Analysis & Storytelling
Skill: Read data from Google Sheets into tables
Description: Students use 'read from google sheet: url [URL] sheet name [Sheet1] range [A1:D10] into table [data v]' to import cloud-stored data. They understand how to specify sheet name and cell range, handle shared vs private sheets, and verify data imported correctly.

Dependencies:
* T26.G6.10: Import external data from CSV files
* T06.G5.01: Broadcast a custom message and respond in another sprite



ID: T26.G7.02
Topic: T26 – Data Analysis & Storytelling
Skill: Write analysis results back to Google Sheets
Description: Students use 'write into google sheet: url [URL] sheet name [Sheet1] start cell [A1] from table [results v]' to publish findings. They create collaborative workflows where one person collects data, another analyzes it, and results appear in shared sheets automatically.

Dependencies:
* T26.G7.01: Read data from Google Sheets into tables



ID: T26.G7.03
Topic: T26 – Data Analysis & Storytelling
Skill: Build multi-chart dashboards with synchronized filters
Description: Students create dashboards with multiple charts (bar + line + pie) that respond to the same filter using shared variables and broadcasts. Changing a filter triggers all charts to redraw. They design coherent multi-view analysis interfaces.

Dependencies:
* T26.G6.08: Identify trends and cycles in time-series data
* T26.G5.07: Build a simple interactive data dashboard
* T06.G5.01: Broadcast a custom message and respond in another sprite



ID: T26.G7.04
Topic: T26 – Data Analysis & Storytelling
Skill: Extract table columns to lists for specialized analysis
Description: Students copy table column values to lists using loops because some analysis blocks require lists. They iterate through rows, adding each value to a list, preparing data for moving averages, statistical calculations, or chart blocks that only accept lists.

Dependencies:
* T26.G7.03: Build multi-chart dashboards with synchronized filters
* T10.G5.01: Use list length and item access in expressions



ID: T26.G7.05
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate moving averages to smooth noisy data
Description: Students use 'value from [simple v] moving average window [7] of list [daily_scores v]' to calculate rolling averages. They compare raw vs smoothed line charts: raw shows daily noise, smoothed reveals underlying trends. They choose appropriate window sizes (larger = smoother but less responsive).

Dependencies:
* T26.G7.04: Extract table columns to lists for specialized analysis



ID: T26.G7.06
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate and analyze prediction residuals
Description: Students compare predicted vs actual values, computing residuals (actual - predicted) for each data point. They identify patterns in errors: consistently positive residuals = under-prediction, negative = over-prediction, random = unbiased. They visualize residuals to evaluate prediction quality.

Dependencies:
* T26.G7.05: Calculate moving averages to smooth noisy data
* T09.G5.01: Model real-world quantities using variables and formulas



ID: T26.G7.07
Topic: T26 – Data Analysis & Storytelling
Skill: Automate chart regeneration when data changes
Description: Students implement scripts that redraw charts automatically when underlying data changes. They use 'when I receive [dataUpdated]' to trigger chart regeneration after imports, filters, or new records. This creates responsive dashboards that stay current without manual intervention.

Dependencies:
* T26.G7.03: Build multi-chart dashboards with synchronized filters
* T09.G6.01: Model real-world quantities using variables and formulas



ID: T26.G7.08
Topic: T26 – Data Analysis & Storytelling
Skill: Evaluate fairness by comparing outcomes across groups
Description: Students compute success rates separately for different demographic groups (e.g., accuracy by age group, completion rate by region). They identify disparities: "Group A succeeds 80% while Group B succeeds 60%." They discuss potential causes and fairness implications, connecting to AI ethics concepts.

Dependencies:
* T26.G7.06: Calculate and analyze prediction residuals
* T26.G6.06: Compare two groups statistically



ID: T26.G7.09
Topic: T26 – Data Analysis & Storytelling
Skill: Write audience-tailored data reports
Description: Students write reports with "Finding, Evidence, Recommendation" sections adapted to specific audiences. For teachers: technical details. For students: simple summaries. For parents: action items. They practice adjusting vocabulary, detail level, and emphasis for different readers.

Dependencies:
* T26.G7.08: Evaluate fairness by comparing outcomes across groups
* T26.G6.11: Write structured analysis summaries (METRIC-INSIGHT-ACTION)



ID: T26.G7.10
Topic: T26 – Data Analysis & Storytelling
Skill: Design and analyze A/B tests
Description: Students design controlled experiments: define hypothesis, split participants randomly into A/B groups, identify metrics to measure, determine sample size needed, collect data, and compare results. They conclude: "Version B improved completion by 15%, supporting our hypothesis."

Dependencies:
* T26.G6.06: Compare two groups statistically
* T26.G5.11: Formulate and test a hypothesis with data



ID: T26.G7.11
Topic: T26 – Data Analysis & Storytelling
Skill: Analyze real-time streaming data with cloud variables
Description: Students build dashboards that update automatically as cloud variables change (live game scores, sensor readings). They implement polling scripts that check for updates and refresh visualizations. They understand streaming vs batch analysis and when each is appropriate.

Dependencies:
* T26.G7.07: Automate chart regeneration when data changes
* T18.G5.01: Store and retrieve player data using cloud variables



ID: T26.G7.12
Topic: T26 – Data Analysis & Storytelling
Skill: Use AI to generate data story narratives
Description: Students send analysis summaries to ChatGPT with prompts like: "Turn these findings into a 3-paragraph news story for students: [stats]." They evaluate AI-generated narratives for accuracy, adjust tone and reading level, and combine AI-drafted text with their own charts for polished data stories.

Dependencies:
* T26.G7.09: Write audience-tailored data reports
* T26.G6.15: Use ChatGPT to help interpret data findings



ID: T26.G7.13
Topic: T26 – Data Analysis & Storytelling
Skill: Create scatter plots to visualize variable relationships
Description: Students plot two numeric variables against each other (height vs weight, study time vs score) to visualize relationships. They identify patterns: linear clusters, curved relationships, outliers, no relationship. They use scatter plots to decide if correlation exists before calculating statistics.

Dependencies:
* T26.G6.08: Identify trends and cycles in time-series data
* T26.G5.08: Explore correlation between two variables visually



ID: T26.G7.14
Topic: T26 – Data Analysis & Storytelling
Skill: Calculate and interpret standard deviation as measure of spread
Description: Students use '[standard deviation v] of column [scores] in table [data v]' to measure variability. They understand: small SD = values cluster tightly around mean, large SD = values spread widely. They compare: Class A (mean=80, SD=5, consistent) vs Class B (mean=80, SD=20, highly variable). They explain what SD reveals beyond range.

Dependencies:
* T26.G4.13: Calculate data range to measure spread
* T26.G6.06: Compare two groups statistically



ID: T26.G7.15
Topic: T26 – Data Analysis & Storytelling
Skill: Document analysis steps so others can reproduce results
Description: Students create step-by-step documentation of their complete analysis process: data source with URL/date, cleaning decisions (which rows deleted and why), filters applied, calculations performed, chart settings used. Another student should be able to follow the documentation and get identical results. This teaches reproducible research practices.

Dependencies:
* T26.G6.18: Trace data lineage (where data came from and transformations applied)
* T26.G7.09: Write audience-tailored data reports



ID: T26.G7.16
Topic: T26 – Data Analysis & Storytelling
Skill: Display data on simple maps (points by location)
Description: Students create basic geographic visualizations by placing markers/sprites on map backgrounds based on location data. Given a dataset with cities and values, they position sprites at correct map coordinates and size/color them by value magnitude. They interpret spatial patterns: "Scores are higher in northern regions."

Dependencies:
* T26.G6.07: Create pivot tables for multi-dimensional summaries
* T26.G3.10: Draw a bar chart from table data



ID: T26.G7.17
Topic: T26 – Data Analysis & Storytelling
Skill: Verify AI-generated statistics by recalculating key values manually
Description: Students receive AI analysis and systematically verify it: recalculate mean, median, percentages, and counts manually or with their own code. They document discrepancies: "AI reported 65% but actual is 68%—AI rounded." They learn which AI outputs to trust (interpretations) vs verify (calculations).

Dependencies:
* T26.G6.19: Detect when AI gives incorrect statistical explanations
* T26.G5.17: Use test data with known results to verify analysis code



ID: T26.G7.18
Topic: T26 – Data Analysis & Storytelling
Skill: Iterate on AI prompts to get more precise data analysis
Description: Students refine prompts through multiple rounds to improve AI output quality. Initial prompt: "Analyze this data" produces vague response. Revised: "Analyze this sales data: identify top 3 products, compare to last month, explain any decreases > 10%." They learn prompt engineering: be specific, provide context, request structured output, give examples.

Dependencies:
* T26.G7.12: Use AI to generate data story narratives
* T26.G6.15: Use ChatGPT to help interpret data findings



ID: T26.G8.01
Topic: T26 – Data Analysis & Storytelling
Skill: Determine if differences are statistically meaningful
Description: Students evaluate whether observed differences are real or due to chance. They compare difference magnitude to typical variation (standard deviation), use simple simulation (shuffle labels, recompute difference many times) to see if observed difference is unusual. They document assumptions and conclude with confidence levels.

Dependencies:
* T26.G7.08: Evaluate fairness by comparing outcomes across groups
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column



ID: T26.G8.02
Topic: T26 – Data Analysis & Storytelling
Skill: Automate complete report generation
Description: Students build scripts that generate full reports at button press: import latest data, compute statistics, generate charts, fill text templates with current values, and assemble into a cohesive document. They create repeatable workflows for daily/weekly reporting that run consistently without manual steps.

Dependencies:
* T26.G7.07: Automate chart regeneration when data changes
* T26.G8.01: Determine if differences are statistically meaningful
* T06.G6.01: Trace event execution paths in a multi-event program



ID: T26.G8.03
Topic: T26 – Data Analysis & Storytelling
Skill: Use AI to generate data-driven recommendations
Description: Students construct analysis-informed prompts: "Data shows: average=75, completion rate dropped 20% at level 3, users spend 2x longer on level 5. Suggest 3 specific game balance improvements." They send to ChatGPT, evaluate responses against data, and refine prompts for better recommendations.

Dependencies:
* T26.G8.02: Automate complete report generation
* T21.G6.01: Send a prompt to XO and display the response



ID: T26.G8.04
Topic: T26 – Data Analysis & Storytelling
Skill: Publish interactive data stories for audiences
Description: Students create polished data stories combining: charts with annotations, written context explaining methodology, ethical considerations about data sources and limitations, and actionable recommendations. They publish to CreatiCode sharing or export for web viewing, reaching real audiences with their analysis.

Dependencies:
* T26.G8.03: Use AI to generate data-driven recommendations
* T26.G7.09: Write audience-tailored data reports



ID: T26.G8.05
Topic: T26 – Data Analysis & Storytelling
Skill: Build simple predictive models from historical trends
Description: Students create predictive models using trend extrapolation: calculate growth rate from historical data, extend trends forward, predict future values. They state assumptions explicitly ("assuming growth continues at 5%/month"), test predictions against held-out data, and acknowledge prediction uncertainty.

Dependencies:
* T26.G7.05: Calculate moving averages to smooth noisy data
* T26.G7.06: Calculate and analyze prediction residuals



ID: T26.G8.06
Topic: T26 – Data Analysis & Storytelling
Skill: Communicate uncertainty and confidence levels in findings
Description: Students express conclusions with appropriate uncertainty: "Based on 50 samples, we estimate 70-80% success rate (95% confidence)" or "This pattern is suggestive but not conclusive—more data needed." They use confidence intervals, sample size caveats, and explicit uncertainty ranges in all conclusions.

Dependencies:
* T26.G8.01: Determine if differences are statistically meaningful
* T26.G7.10: Design and analyze A/B tests



ID: T26.G8.07
Topic: T26 – Data Analysis & Storytelling
Skill: Peer review and improve data analyses
Description: Students review sample or peer analyses and provide structured feedback: (1) Data quality issues, (2) Visualization problems, (3) Statistical reasoning gaps, (4) Communication clarity, (5) Specific improvement suggestions. They receive and respond to feedback on their own work, iterating to improve quality.

Dependencies:
* T26.G6.13: Detect and critique misleading visualizations
* T26.G8.01: Determine if differences are statistically meaningful



ID: T26.G8.08
Topic: T26 – Data Analysis & Storytelling
Skill: Consider data ethics and privacy in analysis
Description: Students evaluate ethical dimensions: Is this data collected with consent? Could analysis harm individuals (even anonymized data can be re-identified)? Is the sample representative or biased against certain groups? They document ethical considerations in reports and propose mitigations for identified risks.

Dependencies:
* T26.G8.07: Peer review and improve data analyses
* T26.G7.08: Evaluate fairness by comparing outcomes across groups



ID: T26.G8.09
Topic: T26 – Data Analysis & Storytelling
Skill: Design and execute a complete data investigation project
Description: Students independently complete a full analysis cycle: (1) formulate research question, (2) identify data needs and potential biases, (3) collect/import data, (4) clean and validate, (5) analyze with appropriate methods, (6) visualize findings, (7) interpret with uncertainty acknowledged, (8) present recommendations, (9) consider ethics. This capstone demonstrates mastery of the entire data analysis process.

Dependencies:
* T26.G8.05: Build simple predictive models from historical trends
* T26.G8.06: Communicate uncertainty and confidence levels in findings
* T26.G8.08: Consider data ethics and privacy in analysis



ID: T26.G8.10
Topic: T26 – Data Analysis & Storytelling
Skill: Create multi-modal data presentations with voice and visuals
Description: Students combine all storytelling modalities: TTS narration walks through findings, AI-generated images illustrate key concepts, interactive charts let viewers explore, widget controls allow audience to filter by their interests. They design for accessibility with multiple ways to engage with the same data story.

Dependencies:
* T26.G8.04: Publish interactive data stories for audiences
* T26.G7.12: Use AI to generate data story narratives
* T21.G6.01: Generate an image based on a text prompt using AI



ID: T26.G8.11
Topic: T26 – Data Analysis & Storytelling
Skill: Validate analysis reproducibility
Description: Students ensure their analysis can be reproduced: document all data sources, cleaning steps, analysis decisions, and assumptions. They run analysis multiple times with same inputs to verify consistent results. They provide enough detail that another student could replicate their findings.

Dependencies:
* T26.G8.09: Design and execute a complete data investigation project
* T26.G8.02: Automate complete report generation



ID: T26.G8.12
Topic: T26 – Data Analysis & Storytelling
Skill: Analyze relationships among 3+ variables using faceted charts
Description: Students create multi-panel visualizations showing how relationships vary across categories. They use faceting to display Score vs Study_Time separately for each Grade level, revealing that the correlation differs by grade. They interpret: "The study-score relationship is stronger in Grade 8 than Grade 6." This introduces multivariate analysis.

Dependencies:
* T26.G7.13: Create scatter plots to visualize variable relationships
* T26.G6.07: Create pivot tables for multi-dimensional summaries



ID: T26.G8.13
Topic: T26 – Data Analysis & Storytelling
Skill: Control for confounding variables in comparisons
Description: Students identify confounding variables that affect comparisons and control for them by filtering. Example: comparing test scores between schools, but School A has older students. Solution: filter to same age range before comparing. They explain: "We must control for age because it affects scores independently of school quality."

Dependencies:
* T26.G8.12: Analyze relationships among 3+ variables using faceted charts
* T26.G6.16: Distinguish between correlation and causation with examples



ID: T26.G8.14
Topic: T26 – Data Analysis & Storytelling
Skill: Fact-check viral data claims using original sources
Description: Students encounter viral claims ("90% of students prefer X!") and trace back to original sources. They check: sample size, date, methodology, who funded it, what question was actually asked. They compare original vs viral claim to identify exaggerations, misinterpretations, or out-of-context statistics. They document their fact-checking process.

Dependencies:
* T26.G6.21: Find and access public datasets (government, research)
* T26.G5.13: Evaluate whether a data source is credible for answering a question



ID: T26.G8.15
Topic: T26 – Data Analysis & Storytelling
Skill: Compare multiple AI-generated analyses for consistency
Description: Students send identical data/questions to AI multiple times or use different prompts, then compare outputs for consistency. They identify where AI gives stable answers (basic calculations) vs variable answers (interpretations). They synthesize multiple AI responses: "All 3 runs agreed average=75, but explanations differed—I'll combine the best parts."

Dependencies:
* T26.G7.17: Verify AI-generated statistics by recalculating key values manually
* T26.G7.18: Iterate on AI prompts to get more precise data analysis



ID: T26.G8.16
Topic: T26 – Data Analysis & Storytelling
Skill: Assign data tasks optimally between AI and human analysis
Description: Students decide which analysis tasks to delegate to AI vs do themselves: AI is good for quick summaries, pattern suggestions, draft narratives; Humans are needed for ethical judgment, context understanding, verification, final decisions. They create workflows combining both: "AI summarizes 1000 rows → I verify top findings → AI drafts report → I edit for accuracy."

Dependencies:
* T26.G8.15: Compare multiple AI-generated analyses for consistency
* T26.G8.03: Use AI to generate data-driven recommendations



# T27 - Chance & Simulations (Phase 9 Optimized - November 2025)
# Applied Phase 9 topic-focused optimizations:
# MAJOR CHANGES IN PHASE 9:
# 1. NEW K-2 Scaffolding Skills:
#    - T27.GK.00: Sort events by "always/never" using weather pictures (prerequisite to GK.01)
#    - T27.GK.01.02: Identify events that depend on nature vs choices
#    - T27.G1.00: Connect prediction to real outcomes with sticker feedback
#    - T27.G2.00: Compare two random tools and identify which has more possibilities
# 2. NEW Debugging Progression for Simulations:
#    - T27.G3.09: Debug a simulation with wrong outcome count
#    - T27.G4.04.01: Trace probability flow through if-else chains
#    - T27.G4.04.02: Fix off-by-one errors in probability calculations
#    - T27.G5.12: Validate simulation correctness using expected value
# 3. NEW Advanced Simulation Types (G6-G8):
#    - T27.G6.12: Build a waiting line (queue) simulation
#    - T27.G7.08: Simulate disease spread with infection probability
#    - T27.G7.09: Model weather using Markov chain transitions
#    - T27.G8.13: Design and validate an epidemiological simulation (capstone)
#    - T27.G8.14: Build agent-based environmental model
# 4. Split Broad Skills for Granularity:
#    - T27.G5.03 (Monte Carlo π) → G5.03.01 (setup) + G5.03.02 (calculate + visualize)
#    - T27.G6.06 → G6.06.01 (with replacement) + G6.06.02 (without replacement) + G6.06.03 (compare)
#    - T27.G8.04 → G8.04.01 (structure) + G8.04.02 (evidence) + G8.04.03 (defense)
# 5. Enhanced Real-World Applications:
#    - Environmental simulations (population dynamics, climate)
#    - Public health (epidemiology, disease spread)
#    - Civic data (voting, resource allocation)
# 6. Improved Verb Quality:
#    - "Understand" → "Trace and explain"
#    - "Know about" → "Demonstrate through simulation"
#    - All K-2 skills have detailed visual scenarios
# 7. Fixed Dependencies:
#    - All intra-topic deps verified for X-2 rule
#    - Removed redundant cross-topic deps
# Total: 99 skills (added 26 new skills for scaffolding, debugging, validation, and advanced simulation types)

ID: T27.GK.00
Topic: T27 – Chance & Simulations
Skill: Sort weather events by "always happens" and "never happens"
Description: **Student task:** Sort 6 picture cards showing weather events into two bins: "always happens" (every day) and "never happens" (impossible). **Visual scenario:** Cards show: (A) sun in sky during daytime, (B) clouds in sky, (C) rain falling from clouds—these are weather events that DO happen. Cards showing: (D) snow falling in summer at the beach, (E) rainbow at night (impossible—needs sun), (F) clouds on the ground (fog is different!)—help students identify tricky ones. **Simplified for K:** Start with just "always" and "never"—no middle category yet. **Success criteria:** Sort at least 5 of 6 correctly. **Discussion prompt:** "Can YOU make it rain? Or does weather just happen?" _Implementation note: Large picture cards with audio. Simpler than GK.01 by avoiding abstract events._

Dependencies:
(none)



ID: T27.GK.01
Topic: T27 – Chance & Simulations
Skill: Sort picture cards into "will happen" and "won't happen"
Description: **Student task:** Sort 8 illustrated picture cards into two labeled bins: "will happen" and "won't happen." **Visual scenario:** Picture cards show: (A) sun rising tomorrow, (B) dropped ball falling down, (C) ice melting in hot sun, (D) water flowing downhill—these go in "will happen." Cards showing: (E) fish flying in the sky, (F) ice staying frozen in boiling water, (G) person walking through walls, (H) cat speaking English—these go in "won't happen." **Materials:** 8 large laminated cards, 2 sorting bins. **Success criteria:** All 8 cards sorted correctly. _Implementation note: Drag-drop interface with audio support reading card descriptions. Auto-graded by final positions._

Dependencies:
* T27.GK.00: Sort weather events by "always happens" and "never happens"




ID: T27.GK.01.01
Topic: T27 – Chance & Simulations
Skill: Explain why some events always happen using picture examples
Description: **Student task:** Select the picture that shows WHY an event always happens. **Visual scenario:** Show 4 picture pairs: (A) "Ball falls" → student picks reason: "gravity pulls down" (picture of arrow pointing down), (B) "Ice melts in sun" → "sun is hot" (picture of sun with heat lines). Multiple choice for each. **Discussion prompt:** "The sun ALWAYS rises. Can anyone stop it?" (No—nature's rules). **Key concept:** Some events follow rules that never break. **Success criteria:** Match 3 of 4 events to correct reasons. _Implementation note: Matching game with picture-based reasons._

Dependencies:
* T27.GK.01: Sort picture cards into "will happen" and "won't happen"




ID: T27.GK.01.02
Topic: T27 – Chance & Simulations
Skill: Identify events that depend on nature vs events that depend on choices
Description: **Student task:** Sort 6 picture cards into "Nature decides" and "I can choose." **Visual scenario:** "Nature decides" cards: (A) rainy day picture (you can't choose weather), (B) leaves falling in autumn, (C) sun setting in evening. "I can choose" cards: (D) picking a red or blue crayon, (E) choosing to share a cookie or not, (F) deciding to walk or skip to school. **Discussion prompt:** "Can you make it stop raining? No—nature decides! But can you choose which crayon to pick? Yes!" **Key concept:** Some things are beyond our control (nature, luck), others are our choice. This builds toward understanding randomness. **Success criteria:** Sort 5 of 6 correctly. _Implementation note: Two-bin sorting with audio explanations for each card._

Dependencies:
* T27.GK.01.01: Explain why some events always happen using picture examples




ID: T27.GK.02
Topic: T27 – Chance & Simulations
Skill: Select "maybe" events and place them in the middle bin
Description: **Student task:** Given 6 new picture cards, select those showing uncertain events and place them in a "maybe" bin between "will happen" and "won't happen." **Visual scenario:** Cards show: (A) "Will it rain today?" with clouds in sky, (B) "Will I pick a red crayon?" showing hand reaching into mixed crayon box, (C) "Will the coin land heads?" showing a flipping coin, (D) "Will the spinner land on blue?" showing a 4-color spinner. The "will happen" and "won't happen" cards from GK.01 remain in their bins as anchors. **Success criteria:** Student correctly identifies 4+ cards as "maybe" events. **Discussion prompt:** "Why can't we know for sure what will happen?" _Implementation note: Three-bin sorting with audio confirmation. Auto-graded by correct placements._

Dependencies:
* T27.GK.01.02: Identify events that depend on nature vs events that depend on choices




ID: T27.GK.02.01
Topic: T27 – Chance & Simulations
Skill: Match random tools to their outcomes using picture cards
Description: **Student task:** Match 4 picture cards of random tools (coin, die, spinner, grab bag) to picture cards showing their possible results. **Visual scenario:** Tools: (A) coin → heads or tails pictures, (B) 6-sided die → numbers 1-6 dots, (C) 4-color spinner → color circles, (D) bag with mixed candies → different candy colors. **Procedure:** Drag each tool card to its matching outcome card set. **Discussion prompt:** "What makes these tools special? We don't know what will happen until we try!" **Key concept:** Random tools give different results each time. **Success criteria:** Match all 4 tools to correct outcome sets. _Implementation note: Drag-to-match interface with visual outcome cards._

Dependencies:
* T27.GK.02: Select "maybe" events and place them in the middle bin




ID: T27.GK.03
Topic: T27 – Chance & Simulations
Skill: Spin a picture spinner and compare results to hopes
Description: **Student task:** Spin a 4-color paper spinner 5 times. Before each spin, tap the color you hope to land on. After spinning, tap the color you actually landed on. **Visual scenario:** Digital spinner with 4 equal sections (red, blue, green, yellow). Screen shows two columns: "I hoped for" and "I got." After 5 spins, student sees comparison table. **Key observation:** Students notice their hopes didn't control outcomes—sometimes they got what they hoped for, sometimes not. **Discussion prompt:** "Could you make the spinner land where you wanted? Why not?" **Success criteria:** Complete 5 spins and answer reflection question. _Implementation note: Animated spinner with tap-to-select prediction before each spin. Records hope vs outcome for comparison._

Dependencies:
* T27.GK.02.01: Match random tools to their outcomes using picture cards




ID: T27.GK.04
Topic: T27 – Chance & Simulations
Skill: Count items in a picture bag and predict which color is easiest to pick
Description: **Student task:** Look at a picture of a bag with colored balls visible inside. Count each color and predict which is easiest to pick randomly. **Visual scenario:** Transparent bag shows: 5 red balls, 2 blue balls, 1 green ball. **Questions:** (1) "How many red balls?" (5), (2) "How many blue balls?" (2), (3) "If you close your eyes and pick one, which color will you PROBABLY get?" (Red—there are more red). **Discussion prompt:** "Why is red easier to pick? Because there are MORE of them!" **Key concept:** More items = easier to pick randomly. **Success criteria:** Count all colors correctly, predict most likely color. _Implementation note: Interactive counting with highlight feature._

Dependencies:
* T27.GK.03: Spin a picture spinner and compare results to hopes




ID: T27.G1.00
Topic: T27 – Chance & Simulations
Skill: Connect prediction to outcome using picture matching
Description: **Student task:** Make a prediction before a random event, then match prediction to actual outcome. **Visual scenario:** Three activities: (1) Spinner with 2 colors—student taps prediction color, watches spin, taps to match if correct. (2) Grab bag with shapes visible—predict circle or square, see what's drawn. (3) Weather forecast tomorrow—sunny or cloudy guess, return next day to compare. **Key insight:** "Did what you hoped for actually happen? Sometimes yes, sometimes no!" **Discussion prompt:** "Why can't we always be right when we guess about 'maybe' things?" **Purpose:** Bridges GK "maybe" concept to G1 formal prediction-vs-outcome recording. **Success criteria:** Complete all 3 activities, correctly identify matches. _Implementation note: Simple tap-to-predict, animate event, tap-to-match interface._

Dependencies:
* T27.GK.04: Count items in a picture bag and predict which color is easiest to pick




ID: T27.G1.01
Topic: T27 – Chance & Simulations
Skill: Predict coin flips and record outcomes with stickers
Description: **Student task:** Predict "heads" or "tails" before each of 6 coin flips, then record what actually happens. **Visual scenario:** Recording sheet with two columns labeled with pictures: coin showing heads, coin showing tails. Before each flip, student taps prediction (heads/tails picture). After flip, student places a virtual sticker in the correct column. **Procedure:** (1) Tap prediction, (2) Watch coin flip animation, (3) Place sticker under matching result. **After 6 flips:** Count stickers in each column. Answer: "How many heads? How many tails? Were your guesses mostly right or mostly wrong?" **Success criteria:** Complete 6 flips with predictions and counts recorded correctly. _Implementation note: Animated coin flip with sticker placement. Auto-graded by correct recording._

Dependencies:
* T27.G1.00: Connect prediction to outcome using picture matching




ID: T27.G1.02
Topic: T27 – Chance & Simulations
Skill: Compare spinners with different numbers of sections
Description: **Student task:** Spin two different spinners (2-section and 4-section) and compare how often each color appears. **Visual scenario:** Spinner A has 2 equal sections (red, blue). Spinner B has 4 equal sections (red, blue, green, yellow). **Procedure:** Spin each spinner 8 times, recording with tally marks on a picture chart. **Comparison questions:** (1) "Which spinner gives more color choices?" (B—4 colors), (2) "On Spinner A, how many times out of 8 did you get red?" (typically 3-5), (3) "On Spinner B, how many times out of 8 did you get red?" (typically 1-3). **Key insight:** Red appears more often on the 2-section spinner because it has fewer choices. **Success criteria:** Complete tallies and answer comparison questions correctly. _Implementation note: Two animated spinners with tally recording interface._

Dependencies:
* T27.G1.01: Predict coin flips and record outcomes with stickers




ID: T27.G1.03
Topic: T27 – Chance & Simulations
Skill: Sort picture cards by likelihood (more likely, less likely)
Description: **Student task:** Sort 6 illustrated scenario cards into "more likely" and "less likely" piles by comparing chances. **Visual scenarios:** (A) Picking a red marble from bag with 5 red, 1 blue → "more likely red", (B) Picking blue from same bag → "less likely," (C) Rolling 1-5 on a die vs rolling exactly 6, (D) Drawing a heart from 10 hearts + 2 stars, (E) Spinner landing on big section vs small section. **Reasoning required:** Student must explain using counts: "Red is more likely because there are MORE red marbles than blue." **Success criteria:** Correctly sort 5+ cards with valid reasoning for at least 2. _Implementation note: Drag-drop sorting with picture cards showing item counts. Reasoning captured via simple tap-to-select explanation options._

Dependencies:
* T27.G1.02: Compare spinners with different numbers of sections




ID: T27.G1.04
Topic: T27 – Chance & Simulations
Skill: Order events from impossible to certain on a picture line
Description: **Student task:** Place 5 event picture cards on a line from "Impossible" to "Certain." **Visual scenario:** Line has markers: Impossible (0) - Maybe (middle) - Certain (1). Event cards: (A) Sun rising tomorrow (certain), (B) Rolling a 7 on a regular die (impossible), (C) Picking a red from 3 red + 3 blue (middle-maybe), (D) Dropping a ball and it falls (certain), (E) Getting heads on a coin (middle-maybe). **Procedure:** Drag each card to its position on the line. **Discussion prompt:** "Which events go in the middle? Why can't we be SURE about them?" **Key concept:** Events have different levels of certainty—some always happen, some never, some might. **Success criteria:** Place all 5 cards in approximately correct positions. _Implementation note: Drag-to-line interface with feedback on placement._

Dependencies:
* T27.G1.03: Sort picture cards by likelihood (more likely, less likely)




ID: T27.G2.00
Topic: T27 – Chance & Simulations
Skill: Compare two random tools and count their possibilities
Description: **Student task:** Look at two random tools side by side and decide which has MORE possible outcomes. **Visual scenario:** Comparison pairs: (1) Coin (2 sides) vs die (6 sides)—which has more possibilities? (Die—6 vs 2), (2) 3-color spinner vs 5-color spinner—which has more? (5-color), (3) Bag with 2 colors vs bag with 4 colors—which? (4-color bag). **Procedure:** Count outcomes for each tool, circle the one with more. **Key concept:** More possibilities means each single outcome is less likely to happen—harder to predict! **Discussion prompt:** "If you're trying to land on blue, would you rather have a 2-color or 10-color spinner?" (2-color—better chance!). **Success criteria:** Correctly compare 3 pairs and explain why more possibilities means harder to predict. _Implementation note: Side-by-side comparison with counting interface._

Dependencies:
* T27.G1.04: Order events from impossible to certain on a picture line




ID: T27.G2.01
Topic: T27 – Chance & Simulations
Skill: Classify events as certain, possible, or impossible
Description: **Student task:** Sort 9 illustrated picture cards into three labeled bins: "Certain" (always happens), "Possible" (might happen), and "Impossible" (cannot happen). **Visual scenarios:** Certain events: (A) sun rising tomorrow, (B) dropped rock falling down, (C) January coming after December. Possible events: (D) rolling a 3 on a die, (E) picking a red marble from bag with red and blue, (F) coin landing heads. Impossible events: (G) rolling 7 on a standard die, (H) drawing blue from bag with only red marbles, (I) person jumping to the moon. **Success criteria:** Sort all 9 cards correctly. **Extension question:** "Can you think of another possible event?" _Implementation note: Three-bin sorting with visual feedback showing why each answer is correct._

Dependencies:
* T27.G2.00: Compare two random tools and count their possibilities





ID: T27.G2.02
Topic: T27 – Chance & Simulations
Skill: Run a chance experiment and tally results
Description: **Student task:** Conduct a 10-trial experiment with a spinner or bag draw, recording each result with tally marks. **Procedure:** (1) Choose tool: 4-color spinner OR bag with 3 red, 2 blue blocks, (2) Run 10 trials, (3) After each trial, add tally mark to correct column, (4) After all trials, count totals. **Recording sheet:** Picture columns for each possible outcome (colors). **Analysis questions:** "Which color appeared most often? How many times? Did any color appear exactly 0 times?" **Key insight:** Results vary—running the same experiment again might give different counts. **Success criteria:** Complete 10 trials with accurate tally recording and correct final counts. _Implementation note: Animated spinner/bag draw with tally interface. Auto-graded by matching tallies to recorded outcomes._

Dependencies:
* T27.G2.01: Classify events as certain, possible, or impossible
* T24.G1.01: Record data with tally marks





ID: T27.G2.03
Topic: T27 – Chance & Simulations
Skill: Compare spinners and decide which game is fair
Description: **Student task:** Examine two spinners and determine which would make a fair game. **Visual scenario:** Spinner A has 4 equal-sized sections (red, blue, green, yellow—each takes 1/4). Spinner B has uneven sections (red takes half the circle, blue/green/yellow split the other half). **Game rules:** Each of 4 players picks a color; whoever's color is spun wins. **Analysis questions:** (1) "On Spinner A, does each color have the same chance?" (Yes—equal slices), (2) "On Spinner B, which color has the best chance?" (Red—biggest slice), (3) "Which spinner is fairer for this game?" (Spinner A). **Key concept:** Fair = equal chances for everyone. **Success criteria:** Correctly identify fair spinner and explain why using slice sizes. _Implementation note: Side-by-side spinner comparison with tap-to-select answers._

Dependencies:
* T27.G2.02: Run a chance experiment and tally results





ID: T27.G2.04
Topic: T27 – Chance & Simulations
Skill: Test whether predictions can beat random chance
Description: **Student task:** Make predictions before 10 coin flips and track whether guessing helps. **Procedure:** (1) Before each flip, tap your prediction (heads or tails), (2) Watch the flip, (3) Record if prediction was correct (✓) or wrong (✗). **After 10 flips:** Count correct predictions. **Analysis questions:** (1) "How many did you get right out of 10?" (2) "Is that more than 5, less than 5, or about 5?" (3) "If you guess randomly, you'd expect about 5 right. Did your careful guessing do much better?" **Key insight:** Even careful predictions can't reliably beat random chance—each flip is independent. **Success criteria:** Complete 10 predictions with accurate tracking and answer analysis questions. _Implementation note: Animated coin with prediction tracking and comparison to expected 50% success rate._

Dependencies:
* T27.G2.02: Run a chance experiment and tally results





ID: T27.G2.05
Topic: T27 – Chance & Simulations
Skill: Watch a CreatiCode spinner simulation and compare to physical results
Description: **Student task:** Watch a pre-built CreatiCode spinner simulation run 20 times and compare digital results to physical spinner experience. **Procedure:** (1) Run the provided project (click green flag), (2) Watch 20 automated spins with results displayed on screen, (3) Record final counts for each color. **Comparison questions:** Think back to your physical spinner from G2.02—did you see similar variation? The computer spinner follows the same rules as a physical spinner, but runs much faster! **Analysis:** (1) "Did all colors appear the same number of times?" (No—randomness causes variation), (2) "Would you get the exact same counts if you ran it again?" (No—each run is different). **Bridge concept:** This introduces CreatiCode as a tool for running chance experiments faster than by hand. **Success criteria:** Record counts accurately and answer both questions correctly. _Implementation note: Pre-built project students observe (not edit). Shows spinning animation with live count update._

Dependencies:
* T27.G2.04: Test whether predictions can beat random chance
* T27.G2.02: Run a chance experiment and tally results




ID: T27.G2.06
Topic: T27 – Chance & Simulations
Skill: Identify unfair spinners by comparing section sizes in pictures
Description: **Student task:** Look at 4 spinner pictures and identify which ones are "fair" vs "unfair." **Visual scenario:** (A) 4 equal sections—FAIR, (B) One section takes half the circle—UNFAIR (that color has better chance), (C) 3 equal sections—FAIR, (D) 6 sections but one is twice as big—UNFAIR. **Questions for each:** "Would you want to play a game where everyone picks a color on this spinner? Why or why not?" **Key concept:** Fair means everyone has the SAME chance. If sections are different sizes, chances are different! **Discussion prompt:** "If you could pick any color on spinner B, which would you pick? Why?" (The big one—it has a better chance). **Success criteria:** Correctly classify 4 of 4 spinners as fair or unfair with reasoning. _Implementation note: Spinner pictures with interactive fair/unfair toggle and reasoning selection._

Dependencies:
* T27.G2.03: Compare spinners and decide which game is fair




ID: T27.G3.01
Topic: T27 – Chance & Simulations
Skill: Interpret bar chart results from a spinner simulation
Description: **Student task:** Run a pre-built CreatiCode spinner simulation and interpret the bar chart results. **Procedure:** (1) Click green flag to run simulation (spinner spins 20 times automatically), (2) Observe the bar chart updating as results come in, (3) After all spins, analyze the final chart. **Analysis questions:** (1) "Which color appeared most often? How many times?" (2) "Which color appeared least often?" (3) "Did all colors appear exactly 5 times each (20 spins ÷ 4 colors)?" (Probably not—randomness!). **Written response:** Write 2-3 sentences explaining: "Even though each color has an equal chance, the results weren't exactly equal because..." **Key concept:** Variability in random experiments is normal. **Success criteria:** Correctly identify most/least frequent colors and explain variability. _Implementation note: Pre-built project with automated bar chart generation._

Dependencies:
* T27.G2.05: Watch a CreatiCode spinner simulation and compare to physical results
* T26.G2.01: Read a picture graph (pictograph)





ID: T27.G3.02
Topic: T27 – Chance & Simulations
Skill: Explore the "pick random" block and predict its boundaries
Description: **Student task:** Drag the 'pick random 1 to 6' block into a 'say' block and test what values it can produce. **Exploration procedure:** (1) Click the block 10+ times and observe different numbers appearing, (2) Record the smallest and largest numbers you see. **Prediction tests:** Can this block show: (A) 0? (No—below range), (B) 7? (No—above range), (C) 3.5? (No—whole numbers only), (D) 6? (Yes—at upper boundary). Test each prediction by clicking many times. **Written summary:** "The pick random block picks a whole number from __ to __, where each number has an equal chance of being picked." **Success criteria:** Correctly predict all 4 boundary tests and write accurate summary. _Implementation note: Interactive block testing with prediction checkboxes._

Dependencies:
* T27.G3.01: Interpret bar chart results from a spinner simulation





ID: T27.G3.03
Topic: T27 – Chance & Simulations
Skill: Run a simulation loop and record results in a table
Description: **Student task:** Run a provided simulation that generates 10 random 0s and 1s, then record results in a table. **Code provided:** 'when green flag clicked → repeat 10 [set result to pick random 0 to 1, say result for 0.5 secs]'. **Procedure:** (1) Click green flag, (2) Watch each result appear, (3) Record each value (0 or 1) in your table as it appears. **After 10 trials:** Count totals—"How many 0s? How many 1s?" **Analysis question:** "If 0 and 1 have equal chances, would you expect exactly 5 of each? Did you get exactly 5?" **Key concept:** This is your first experience with code that automatically generates random data—much faster than flipping coins! **Success criteria:** Accurate recording of all 10 results and correct totals. _Implementation note: Pre-built project with step-by-step recording interface._

Dependencies:
* T27.G3.02: Explore the "pick random" block and predict its boundaries
* T07.G3.01: Use a counted repeat loop





ID: T27.G3.04
Topic: T27 – Chance & Simulations
Skill: Predict simulation outcomes and measure prediction error
Description: **Student task:** Make predictions before running a 20-trial simulation, then compare predictions to actual results. **Procedure:** (1) Before running: Write predictions—"I think red will appear ___ times, blue will appear ___ times" (out of 20 trials on a 50/50 spinner), (2) Run the simulation, (3) Record actual counts, (4) Calculate difference: |prediction - actual| for each color. **Analysis questions:** (1) "Was your prediction within 3 of the actual count?" (2) "Why is it hard to predict the exact number?" (Because randomness causes variation). **Key insight:** Even though we expect 10 red and 10 blue on average, any single run might be 12-8 or 9-11 or even 15-5. **Success criteria:** Complete predictions, run simulation, calculate errors correctly, and explain why exact prediction is difficult. _Implementation note: Prediction entry before simulation unlocks, error calculation automatic._

Dependencies:
* T27.G3.03: Run a simulation loop and record results in a table





ID: T27.G3.05
Topic: T27 – Chance & Simulations
Skill: Classify games by their random elements (dice, spinner, cards)
Description: **Student task:** Analyze 4 familiar games and identify what random element makes each game "lucky." **Games to analyze:** (A) Chutes and Ladders—uses a spinner, (B) Candy Land—draws from shuffled cards, (C) Sorry!—draws from shuffled cards + dice for movement, (D) Go Fish—shuffled cards dealt randomly. **Classification table:** For each game, fill in: (1) Random element type (dice/spinner/cards), (2) "Mostly luck" or "Luck + some skill." **Analysis question:** "Chess has no dice, spinner, or card shuffling. Is chess a luck game or skill game? Why?" (Skill—no random elements). **Key concept:** Random elements (dice, spinners, shuffled cards) create uncertainty that makes games unpredictable. **Success criteria:** Correctly identify random element for 3+ games and explain chess classification. _Implementation note: Game cards with checkboxes for random element types._

Dependencies:
* T27.G3.04: Predict simulation outcomes and measure prediction error





ID: T27.G3.06
Topic: T27 – Chance & Simulations
Skill: Modify a random generator to change its possible outcomes
Description: **Student task:** Modify a starter project to change what outcomes are possible. **Starter code:** 'if pick random 1 to 2 = 1 then say "red" else say "blue"'. **Modification choices (pick one):** (A) Change colors to "cat" and "dog", (B) Expand to 3 outcomes by changing range to 1-3 and adding 'else if = 2 then say "green"', (C) Change to show numbers "1" and "2" instead of colors. **Testing:** Click green flag 15+ times to verify: (1) All intended outcomes can appear, (2) No unintended outcomes appear. **Verification question:** "If you changed to 3 outcomes, did you see all 3 appear after 15 clicks?" **Success criteria:** Successfully modify code, test thoroughly, and confirm all outcomes are possible. _Implementation note: Starter project with side-by-side code comparison showing original and modified._

Dependencies:
* T27.G3.03: Run a simulation loop and record results in a table
* T08.G3.04: Use a simple if in a script





ID: T27.G3.07
Topic: T27 – Chance & Simulations
Skill: Build a random number generator from scratch
Description: **Student task:** Create your own random generator starting from an empty project. **Build steps:** (1) Add 'when green flag clicked' event, (2) Create a variable named 'result' using Make a Variable, (3) Add 'set result to pick random 1 to 3', (4) Add 'say result'. **Testing:** Click green flag 15+ times. Tally how often each number (1, 2, 3) appears. **Analysis questions:** (1) "Did each number appear at least once?" (Should yes after 15 tries), (2) "Did they appear exactly 5 times each?" (Probably not—that's randomness!). **Achievement:** This is your first fully self-built simulation—you created a digital die from scratch! **Extension challenge:** Change it to pick random 1 to 6 to simulate a real die. **Success criteria:** Working generator that produces values 1-3, tested 15+ times with recorded tallies. _Implementation note: Empty project with step-by-step guidance and tally recording._

Dependencies:
* T27.G3.06: Modify a random generator to change its possible outcomes
* T09.G3.01.01: Create a variable using the Make a Variable button
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T27.G3.08
Topic: T27 – Chance & Simulations
Skill: Shuffle a list randomly and observe the results
Description: **Student task:** Use CreatiCode's 'reshuffle list randomly' block to explore randomized ordering. **Build steps:** (1) Create a list with 5 items: [A, B, C, D, E], (2) Display the list, (3) Add 'reshuffle [mylist] randomly' block, (4) Display the list again. **Observation:** Run 5 times and write down each shuffled order. **Analysis questions:** (1) "Did you ever get the same order twice?" (Unlikely!), (2) "Did every letter appear in every position at least once across your 5 runs?" (Check!), (3) "Why is shuffling useful in games?" (For card dealing, random turn order, surprise elements). **Real-world connections:** Card shuffling, randomized quiz questions, music shuffle. **Key concept:** Shuffling rearranges items randomly—each possible order has equal chance. **Success criteria:** Successfully shuffle list multiple times, record different orderings. _Implementation note: Use data_reshuffle block._

Dependencies:
* T27.G3.07: Build a random number generator from scratch
* T10.G3.02: Add an item to a list




ID: T27.G3.09
Topic: T27 – Chance & Simulations
Skill: Debug a simulation that counts wrong number of outcomes
Description: **Student task:** Find and fix the bug in a simulation that doesn't count all outcomes correctly. **Buggy code provided:** A die roll counter that should count values 1-6, but only shows counts for 1-5. **Bug hunt steps:** (1) Run simulation 50 times, observe counts displayed, (2) Notice "6" count is always 0, (3) Inspect code—find 'if roll = 6' is missing from the counting logic, (4) Add the missing condition. **Debugging scaffolds:** (A) "How many different values can a die show?" (6), (B) "How many counters do you see in the code?" (5—one is missing!), (C) "Which value has no counter?" (6). **Verification:** Run again—now all 6 values have counts, total should equal 50. **Key concept:** Every possible outcome needs to be accounted for in simulation counting. **Success criteria:** Identify missing counter, fix code, verify total equals trial count. _Implementation note: Pre-built buggy project with guided hints._

Dependencies:
* T27.G3.07: Build a random number generator from scratch
* T12.G3.01: Identify a bug when output differs from expectation




ID: T27.G4.01
Topic: T27 – Chance & Simulations
Skill: Map random numbers to named outcomes using if-statements
Description: **Student task:** Extend a random generator to show meaningful words instead of raw numbers. **Build steps:** (1) Set 'roll' to pick random 1 to 4, (2) Add if-statements to convert: 'if roll = 1 then say "red"', 'else if roll = 2 then say "blue"', 'else if roll = 3 then say "green"', 'else say "yellow"'. **Testing:** Click green flag 20+ times. **Verification checklist:** □ Red appeared at least once, □ Blue appeared at least once, □ Green appeared at least once, □ Yellow appeared at least once. **Debugging scenario:** "What if you only see 3 colors after 20 tries? Is the code broken?" (Not necessarily—rare outcomes might need more tries. Try 50 times.) **Key concept:** Random numbers can drive meaningful outcomes—the number 1 BECOMES "red." **Success criteria:** All 4 colors appear within 25 tries, if-statement structure is correct. _Implementation note: Verification checklist auto-checks as outcomes appear._

Dependencies:
* T27.G3.08: Shuffle a list randomly and observe the results
* T08.G3.04: Use a simple if in a script





ID: T27.G4.02.01
Topic: T27 – Chance & Simulations
Skill: Automate data collection by logging trial results to a list
Description: **Student task:** Extend your random generator to automatically collect 50 trials in a list. **Build steps:** (1) Create a list called 'results', (2) Add 'delete all of [results]' at start (to clear old data), (3) Wrap generator in 'repeat 50' loop, (4) Inside loop, add 'add (result) to [results]' after each random pick. **After running:** Check list length—'say (length of results)' should show 50. **Verification:** (1) List has exactly 50 items, (2) Items are only valid outcomes (red/blue/green/yellow), (3) Running again gives different results. **Key advantage:** This automates data collection—50 trials in seconds instead of minutes of manual tallying! **Success criteria:** List contains exactly 50 valid outcomes after one click. _Implementation note: List display shows items accumulating during run._

Dependencies:
* T27.G4.01: Map random numbers to named outcomes using if-statements
* T07.G3.01: Use a counted repeat loop
* T10.G3.02: Add an item to a list





ID: T27.G4.02.02
Topic: T27 – Chance & Simulations
Skill: Count frequencies of each outcome from collected data
Description: **Student task:** After collecting 50 trials, count how many times each outcome appeared. **Build steps:** (1) Create counter variables: redCount, blueCount, greenCount, yellowCount, (2) Set all counters to 0, (3) Loop through results list using 'for each item in [results]', (4) Inside loop: 'if item = "red" then change redCount by 1', repeat for each color. **Display:** Show all counts on stage using 'say' or variable monitors. **Verification:** Counts should add up to 50 (redCount + blueCount + greenCount + yellowCount = 50). **Analysis question:** "Are all counts close to 12-13 (which is 50÷4)? Which color appeared most? Which least?" **Success criteria:** All 4 counts calculated correctly, total equals 50. _Implementation note: Counter variables visible on stage with final summary display._

Dependencies:
* T27.G4.02.01: Automate data collection by logging trial results to a list
* T10.G3.05: Loop through each item in a list
* T09.G3.03: Use a variable in a simple conditional (if block)





ID: T27.G4.02.03
Topic: T27 – Chance & Simulations
Skill: Calculate percentages from frequency counts
Description: **Student task:** Convert frequency counts to percentages to compare outcomes fairly. **Formula:** percentage = (count / total trials) × 100. **Example:** If red appeared 12 times out of 50: (12/50)×100 = 24%. **Code:** Create 'redPercent' variable, set it to '(redCount / 50) * 100'. **Display:** Show all 4 percentages. **Analysis questions:** (1) "Does each color appear about 25% of the time?" (For fair 4-color spinner, expect ~25% each), (2) "If red is 40% and blue is 10%, what might that mean?" (Could be random variation, or code bug making outcomes unfair), (3) "What would 'perfect fairness' look like?" (Exactly 25% each—but that rarely happens!). **Success criteria:** Calculate all 4 percentages correctly, identify whether results suggest fairness. _Implementation note: Percentage calculator with comparison to expected 25%._

Dependencies:
* T27.G4.02.02: Count frequencies of each outcome from collected data





ID: T27.G4.03
Topic: T27 – Chance & Simulations
Skill: Compare variability at different sample sizes (50 vs 500 trials)
Description: **Student task:** Run the same simulation at two sample sizes and compare how much results vary from expected. **Procedure:** (1) Run with 50 trials, record all 4 percentages, (2) Run with 500 trials, record all 4 percentages. **Comparison table:** Create side-by-side comparison—50 trials vs 500 trials. **Expected observation:** With 50 trials, percentages might be 18%, 32%, 24%, 26% (spread from 25%). With 500 trials, closer to 24%, 26%, 25%, 25% (tighter around 25%). **Key concept:** "More trials = results closer to expected percentages." This is because random variation 'averages out' over many trials. **Analysis questions:** (1) "Which run had percentages closer to 25% each?" (500 trials), (2) "Why does more data give more stable results?" **Success criteria:** Complete both runs, accurately compare variability, explain the pattern. _Implementation note: Variable for trial count that student changes; side-by-side chart generation._

Dependencies:
* T27.G4.02.03: Calculate percentages from frequency counts
* T26.G3.04: Create side-by-side bar charts for two groups





ID: T27.G4.04
Topic: T27 – Chance & Simulations
Skill: Debug an unfair simulation by finding probability bugs
Description: **Student task:** Find and fix the bug in a simulation that produces unfair results. **Buggy project:** Run the provided simulation 100 times—notice red appears ~50% instead of 25%. **Bug hunt:** Inspect the code. **Common bugs to look for:** (A) 'if roll = 1 OR roll = 2 then "red"'—red gets 2 chances out of 4, (B) 'pick random 1 to 3' but 4 outcomes mapped—one color never appears, (C) Missing 'else if' causing fall-through. **Debugging process:** (1) Trace through code with sample values (roll=1, roll=2, etc.), (2) Count how many roll values lead to each color, (3) Find the mismatch. **Fix:** Modify code so each color gets exactly 1 chance. **Verification:** Run 100 trials—percentages should now be roughly 25% each. **Success criteria:** Identify the specific bug, fix it correctly, verify with test run. _Implementation note: Pre-built buggy project with debugging hints._

Dependencies:
* T27.G4.01: Map random numbers to named outcomes using if-statements
* T12.G3.01: Identify a bug when output differs from expectation




ID: T27.G4.04.01
Topic: T27 – Chance & Simulations
Skill: Trace probability flow through nested if-else chains
Description: **Student task:** Trace through a nested if-else chain and count how many random values lead to each outcome. **Code to trace:** 'roll = pick random 1 to 8; if roll < 3 then "A", else if roll < 6 then "B", else "C"'. **Tracing table:** Create table with columns: roll value (1-8), condition check, outcome. Fill in all 8 rows. **Analysis:** Count outcomes: A gets values 1,2 (2 chances = 25%), B gets 3,4,5 (3 chances = 37.5%), C gets 6,7,8 (3 chances = 37.5%). **Discussion:** "Is this fair for a 3-player game?" (No—A has less chance than B and C). **Key concept:** Tracing helps reveal hidden unfairness in probability logic. **Verification:** Run 100 trials and compare to traced predictions. **Success criteria:** Complete trace table correctly, calculate percentages, identify fairness issue. _Implementation note: Interactive tracing table with auto-check._

Dependencies:
* T27.G4.04: Debug an unfair simulation by finding probability bugs
* T27.G4.01: Map random numbers to named outcomes using if-statements




ID: T27.G4.04.02
Topic: T27 – Chance & Simulations
Skill: Fix off-by-one errors in random range boundaries
Description: **Student task:** Find and fix off-by-one errors that cause simulation bugs. **Bug scenario 1:** 'pick random 1 to 5' but code expects 0-5 (6 values)—5 is never reached for the 6th outcome. **Bug scenario 2:** 'if roll <= 2' when you meant 'if roll < 2'—changes probability from 1/6 to 2/6. **Bug scenario 3:** 'pick random 0 to 3' for 4 outcomes, but if-conditions use 1-4—outcome "0" never triggers any action. **Debugging process:** (1) List all possible random values, (2) Trace each through conditions, (3) Find values that don't trigger expected behavior. **Fix patterns:** (A) Adjust random range to match expected values, (B) Adjust condition comparisons, (C) Add missing case handling. **Success criteria:** Fix 3 off-by-one scenarios, explain why boundaries matter. _Implementation note: Three buggy code snippets with correction interface._

Dependencies:
* T27.G4.04.01: Trace probability flow through nested if-else chains
* T27.G3.09: Debug a simulation that counts wrong number of outcomes





ID: T27.G4.05
Topic: T27 – Chance & Simulations
Skill: Generate and visualize random coordinate pairs
Description: **Student task:** Create a script that generates random x,y coordinates and visualizes them as dots. **Build steps:** (1) 'repeat 50 times', (2) 'set x to pick random -200 to 200', (3) 'set y to pick random -150 to 150', (4) 'go to x: (x) y: (y)', (5) 'stamp'. **After running:** See 50 dots scattered across the stage. **Observation questions:** (1) "Do the points clump in one area or spread out?" (Spread out fairly evenly), (2) "Are there any big empty gaps?" (Usually not, but possible by chance), (3) "Run it again—do you get the same pattern?" (No—different random coordinates each time). **Key concept:** Random 2D coordinates fill space uniformly—this is the foundation for Monte Carlo simulations! **Success criteria:** Generate 50 visible dots that appear distributed across the stage. _Implementation note: Clear stage before stamping; use small dot costume._

Dependencies:
* T27.G4.02.01: Automate data collection by logging trial results to a list
* T03.G3.01: Navigate a sprite using coordinates





ID: T27.G4.06
Topic: T27 – Chance & Simulations
Skill: Convert between probability fractions, decimals, and percentages
Description: **Student task:** Practice converting probability expressions between different forms. **Conversion examples:** (A) Fair 6-sided die: "chance of rolling 3" = 1 out of 6 = 1/6 ≈ 0.167 ≈ 16.7%, (B) 4-color spinner: "chance of red" = 1 out of 4 = 1/4 = 0.25 = 25%, (C) Bag with 3 red, 2 blue: "chance of red" = 3 out of 5 = 3/5 = 0.6 = 60%. **Practice problems:** (1) "2 out of 5 chance of rain"—what percentage? (40%), (2) "75% chance of success"—what fraction? (3/4), (3) "0.1 probability"—what percentage? (10%). **Connection to simulation:** Compare theoretical values (calculated) to experimental results (from your simulation). If theory says 25% but you got 32%, is that surprising? **Success criteria:** Convert 5+ probability expressions correctly between forms. _Implementation note: Interactive conversion practice with immediate feedback._

Dependencies:
* T27.G4.02.03: Calculate percentages from frequency counts





ID: T27.G4.07
Topic: T27 – Chance & Simulations
Skill: Generate random selections without repetition (sampling without replacement)
Description: **Student task:** Create a simulation that picks items randomly without repeats—like dealing cards or choosing team captains. **Build steps:** (1) Create list of items: ["Alice", "Bob", "Carol", "David", "Eve"], (2) 'repeat 5 times', (3) 'set index to pick random 1 to length of [names]', (4) 'say item (index) of [names]' (display the pick), (5) 'delete item (index) from [names]' (remove so it can't be picked again). **Verification:** (1) Run it—each name should appear exactly once, (2) After all picks, list should be empty, (3) No name should repeat. **Real-world connections:** Card dealing, lottery drawings, random team assignment. **Key concept:** This is "sampling without replacement"—once picked, an item is gone. **Success criteria:** All 5 names picked exactly once, list empty at end, no repeats. _Implementation note: Visual list showing items being removed as picked._

Dependencies:
* T27.G4.02.01: Automate data collection by logging trial results to a list
* T10.G3.04: Delete an item from a list





ID: T27.G4.08
Topic: T27 – Chance & Simulations
Skill: Visualize probability using area models
Description: **Student task:** Create visual area models to represent and calculate probabilities. **Build steps:** (1) Draw a square on stage (200×200 pixels), (2) Divide it into sections proportional to probabilities, (3) Color each section differently. **Example 1:** Fair die—divide square into 6 equal vertical strips. Each has area = 1/6 of total. **Example 2:** Weighted spinner (50% red, 30% blue, 20% green)—divide square: red gets half (100×200), blue gets 30% (60×200), green gets 20% (40×200). **Connection to simulation:** Generate 100 random points in the square. Count how many land in each region. Does the count match the area proportion? **Analysis question:** "If red is 50% of the area, about how many of 100 random points should land in red?" (About 50). **Success criteria:** Create accurate area model for given probabilities, verify with random point sampling. _Implementation note: Drawing tools for rectangles with proportion calculations._

Dependencies:
* T27.G4.05: Generate and visualize random coordinate pairs
* T27.G4.06: Convert between probability fractions, decimals, and percentages




ID: T27.G5.01.01
Topic: T27 – Chance & Simulations
Skill: Simulate compound events (two dice) and collect sum data
Description: **Student task:** Simulate rolling two dice 200 times and record the sum of each roll. **Build steps:** (1) Create list 'sums', (2) 'repeat 200 times', (3) 'set die1 to pick random 1 to 6', (4) 'set die2 to pick random 1 to 6', (5) 'set sum to die1 + die2', (6) 'add sum to [sums]'. **Verification:** (1) List has exactly 200 items, (2) All values are between 2 and 12 (smallest: 1+1=2, largest: 6+6=12), (3) No 1s or 13s appear (impossible sums). **Key concept:** This is a compound event—two separate random events combine to create a new outcome. The possible sums (2-12) don't all have equal chances! **Preview question:** "Do you think 7 and 2 are equally likely? We'll find out in the next skill." **Success criteria:** Collect 200 valid sums (all between 2-12). _Implementation note: Dual die visualization showing each roll before adding to list._

Dependencies:
* T27.G4.02.01: Automate data collection by logging trial results to a list
* T27.G4.06: Convert between probability fractions, decimals, and percentages





ID: T27.G5.01.02
Topic: T27 – Chance & Simulations
Skill: Analyze compound event distributions and explain why 7 is most common
Description: **Student task:** Count frequencies for each sum (2-12) from your two-dice data and explain the pattern. **Analysis steps:** (1) Create counters for each sum (2 through 12), (2) Loop through sums list counting each, (3) Create bar chart showing frequency of each sum. **Key observation:** 7 appears most often! **Explanation:** Count the ways to make each sum: Sum 2 = 1 way (1+1), Sum 7 = 6 ways (1+6, 2+5, 3+4, 4+3, 5+2, 6+1), Sum 12 = 1 way (6+6). **Fill in table:** "How many ways to make sum 3?" (2 ways: 1+2, 2+1), "How many ways to make sum 6?" (5 ways). **Key concept:** Compound events aren't equally likely even when individual events are equal—more combinations = higher probability! **Success criteria:** Create accurate frequency chart, explain why 7 is most common using combination counting. _Implementation note: Interactive combination counter alongside bar chart._

Dependencies:
* T27.G5.01.01: Simulate compound events (two dice) and collect sum data
* T27.G4.02.02: Count frequencies of each outcome from collected data
* T26.G4.01: Create a bar chart from a data table





ID: T27.G5.02
Topic: T27 – Chance & Simulations
Skill: Simulate random assignment for A/B testing
Description: **Student task:** Simulate an A/B test by randomly assigning 100 participants to two groups. **Build steps:** (1) Create list 'groups', (2) 'repeat 100 times', (3) 'if pick random 1 to 2 = 1 then add "A" to [groups] else add "B"'. **After running:** Count how many A's and B's. **Expected results:** Roughly 50 each (but rarely exactly 50-50). **Analysis questions:** (1) "Why is random assignment important for experiments?" (Ensures groups are similar, no bias in who gets which treatment), (2) "If you got 60 A's and 40 B's, is the code broken?" (Probably not—that's within normal random variation for 100 trials). **Real-world connection:** Medical trials, website testing, psychology experiments all use random assignment. **Success criteria:** Create working random assignment, verify roughly equal groups, explain importance. _Implementation note: Visual split showing two groups filling up._

Dependencies:
* T27.G4.02.02: Count frequencies of each outcome from collected data
* T27.G4.04: Debug an unfair simulation by finding probability bugs





ID: T27.G5.03
Topic: T27 – Chance & Simulations
Skill: Use Monte Carlo sampling to estimate π
Description: **Student task:** Estimate the area of a circle (and π!) using random points. **Setup:** Square from -100 to 100 (side = 200), circle with radius 100 centered at origin. **Build steps:** (1) 'repeat 1000 times', (2) 'set x to pick random -100 to 100', (3) 'set y to pick random -100 to 100', (4) 'if (x*x + y*y) < 10000 then change hits by 1' (point inside circle), (5) 'change total by 1'. **Calculation:** Circle area / Square area = π×100² / 200² = π/4. So π ≈ 4 × (hits/total). **Expected result:** With 1000 points, estimate π ≈ 3.14 (±0.1 usually). **Visualization:** Color hits green (inside circle), misses red (outside). **Key concept:** Random sampling can solve geometry problems! This is called Monte Carlo simulation. **Success criteria:** Estimate π within 0.2 of 3.14159. _Implementation note: Visual circle with dots appearing, running estimate displayed._

Dependencies:
* T27.G4.05: Generate and visualize random coordinate pairs
* T27.G4.03: Compare variability at different sample sizes (50 vs 500 trials)
* T08.G4.03: Choose actions based on user input or sensor values




ID: T27.G5.03.01
Topic: T27 – Chance & Simulations
Skill: Explain the geometry behind Monte Carlo π estimation
Description: **Student task:** Draw and label the geometric setup for Monte Carlo π estimation before coding. **Drawing task:** On graph paper or digital canvas: (1) Draw a 200×200 square centered at origin, (2) Draw inscribed circle with radius 100, (3) Shade the circle area. **Calculation preview:** (A) Square area = 200 × 200 = 40000, (B) Circle area = π × 100² = 10000π, (C) Ratio = Circle/Square = π/4 ≈ 0.785. **Prediction:** "If I drop 1000 random points in the square, about how many will land inside the circle?" (About 785—that's π/4 × 1000). **Key insight:** The ratio of hits to total points estimates π/4. Multiply by 4 to get π! **Connection:** This uses area ratios to estimate an irrational number—math meets simulation. **Success criteria:** Correct diagram, calculate areas, predict hit count within 50. _Implementation note: Interactive diagram builder with area calculator._

Dependencies:
* T27.G5.03: Use Monte Carlo sampling to estimate π




ID: T27.G5.03.02
Topic: T27 – Chance & Simulations
Skill: Visualize convergence of Monte Carlo π estimate with increasing samples
Description: **Student task:** Run π estimation at different sample sizes and graph how the estimate converges. **Experiment:** Run with n = 100, 500, 1000, 5000, 10000 points. For each, record estimate. **Visualization:** Plot sample size (x-axis) vs estimate (y-axis). Draw horizontal line at π = 3.14159. **Expected pattern:** Estimates jump around more at low n, stabilize closer to 3.14159 at high n. **Quantitative analysis:** Calculate |estimate - 3.14159| for each n. Does error decrease with more samples? (Yes!) **Discussion:** "If you needed π accurate to 2 decimal places (3.14), how many points might you need?" (Usually 1000+ works). **Key concept:** Monte Carlo accuracy improves with sample size—this is the law of large numbers applied to geometry! **Success criteria:** Complete 5 runs, create convergence plot, explain accuracy vs sample size relationship. _Implementation note: Auto-plotting of estimate vs sample size._

Dependencies:
* T27.G5.03.01: Explain the geometry behind Monte Carlo π estimation
* T27.G5.11: Demonstrate the law of large numbers through simulation





ID: T27.G5.04
Topic: T27 – Chance & Simulations
Skill: Write a 5-part simulation plan before coding
Description: **Student task:** Before building any simulation, create a written plan with 5 required parts. **Plan template:** (1) **Question:** What am I trying to find out? (e.g., "How often does rolling two dice give a sum of 7?"), (2) **Random model:** What will be random? (die roll, coin flip, coordinates, card draw?), (3) **Variables:** What will I track? (counters, lists, totals, positions?), (4) **Trials:** How many times will I run it? (justify: 100 for quick test, 1000 for accuracy), (5) **Success metric:** How will I know it worked? (expected percentage, comparison to theory, visual pattern). **Practice problem:** Write a plan for: "Estimate the probability of getting at least one 6 when rolling 4 dice." **Key benefit:** Planning prevents "just start coding" and builds design thinking—real engineers always plan first! **Success criteria:** Complete all 5 plan sections with logical, specific content. _Implementation note: Plan template with required fields before coding environment unlocks._

Dependencies:
* T27.G4.03: Compare variability at different sample sizes (50 vs 500 trials)
* T27.G4.04: Debug an unfair simulation by finding probability bugs
* T05.G4.01: Describe what a simulation should do before building





ID: T27.G5.05
Topic: T27 – Chance & Simulations
Skill: Calculate theoretical probability using the formula P = favorable/total
Description: **Student task:** Calculate probability using the formula: P(event) = favorable outcomes / total outcomes. **Examples:** (A) P(rolling a 3 on die) = 1/6 ≈ 0.167 ≈ 16.7%, (B) P(heads on coin) = 1/2 = 0.5 = 50%, (C) P(red from bag with 3 red, 2 blue) = 3/5 = 0.6 = 60%. **Practice problems:** (1) Bag with 4 red, 3 blue, 2 green marbles. P(blue) = ? (3/9 = 1/3 ≈ 33%), (2) Standard deck of 52 cards. P(ace) = ? (4/52 = 1/13 ≈ 7.7%), (3) Spinner with 5 equal sections. P(landing on any specific section) = ? (1/5 = 20%). **Key concept:** This is "theoretical" probability—calculated from logic, not experiments. It tells us what SHOULD happen in the long run. **Success criteria:** Calculate 5+ theoretical probabilities correctly and convert between fraction/decimal/percentage. _Implementation note: Interactive formula calculator with conversion tools._

Dependencies:
* T27.G4.06: Convert between probability fractions, decimals, and percentages





ID: T27.G5.06
Topic: T27 – Chance & Simulations
Skill: Compare experimental probability to theoretical probability
Description: **Student task:** Calculate theoretical probability, run a simulation, then compare. **Procedure:** (1) Calculate: P(heads) = 1/2 = 50% (theoretical), (2) Run simulation: flip coin 100 times, count heads, (3) Calculate experimental: (heads count / 100) × 100%. **Example result:** Theory = 50%, Experiment = 47 heads = 47%. **Analysis questions:** (1) "Why are they different?" (Random variation—each run is different), (2) "Will they ever match exactly?" (Rarely—randomness almost always causes some difference), (3) "What happens with more trials?" (Experimental gets closer to theoretical). **Try it:** Run with 100 trials, then 1000 trials. Which is closer to 50%? **Key concept:** Experimental probability is what we OBSERVE; theoretical is what we EXPECT. They converge with more data! **Success criteria:** Correctly compare experimental vs theoretical for 2+ scenarios. _Implementation note: Side-by-side comparison with adjustable trial count._

Dependencies:
* T27.G5.05: Calculate theoretical probability using the formula P = favorable/total
* T27.G4.03: Compare variability at different sample sizes (50 vs 500 trials)





ID: T27.G5.07
Topic: T27 – Chance & Simulations
Skill: Create and analyze frequency distributions from simulation data
Description: **Student task:** Organize simulation results into a frequency table and histogram, then analyze the distribution. **Procedure:** (1) Run 100 die rolls, (2) Create frequency table: Value | Count (1|___, 2|___, ... 6|___), (3) Create histogram/bar chart from table. **Analysis questions:** (1) "What is the mode (most common value)?" (2) "What is the range?" (1 to 6), (3) "Is the distribution 'flat' (uniform) or 'peaked'?" (Should be roughly flat for fair die). **Comparison:** For a fair die, expect each value ~16-17 times out of 100. Is your distribution close? **Shape vocabulary:** Uniform = all bars roughly equal, Peaked = one value much higher, Skewed = bars slope in one direction. **Success criteria:** Create accurate frequency table and histogram, correctly identify mode and distribution shape. _Implementation note: Interactive histogram builder with distribution shape identifier._

Dependencies:
* T27.G5.01.02: Analyze compound event distributions and explain why 7 is most common
* T26.G4.02: Create a histogram from continuous data





ID: T27.G5.07.01
Topic: T27 – Chance & Simulations
Skill: Generate batch random data using the set-random-list block
Description: **Student task:** Use CreatiCode's 'set list to N random numbers' block to efficiently generate large datasets. **Build steps:** (1) 'set [rolls] to (100) random whole numbers between (1) and (6) [allow repetition]', (2) Display the list to verify 100 values, (3) Count each outcome (1-6) from the list. **Comparison:** This single block replaces a 100-iteration loop with pick random inside! **Efficiency test:** Time how long it takes to generate 1000 values with a loop vs with this block. **Analysis:** Generate 1000 die rolls, count frequencies, compare to expected ~167 each. **Extension:** Try 'no repetition' mode—what happens if you try to generate 10 unique numbers between 1 and 6? (Works—gives all 6 in random order. What about 100 unique numbers between 1 and 6? Error—impossible!). **Success criteria:** Generate batch data, understand repetition modes, count frequencies correctly. _Implementation note: Use data_setrandomlist block._

Dependencies:
* T27.G5.07: Create and analyze frequency distributions from simulation data
* T27.G4.02.01: Automate data collection by logging trial results to a list




ID: T27.G5.08
Topic: T27 – Chance & Simulations
Skill: Build a random walker agent with state tracking
Description: **Student task:** Create a "random walker" sprite that moves based on random choices and tracks its state. **Agent state variables:** (1) x, y position, (2) direction (0=up, 90=right, 180=down, 270=left), (3) energy (starts at 50, decreases each step). **Movement logic:** Each step: (A) Set direction to pick random from [0, 90, 180, 270], (B) Move 10 pixels in that direction, (C) Change energy by -1, (D) If energy = 0, stop. **Visualization:** Leave a trail (use pen or stamp) to see the random path. **Observation questions:** (1) "Does the walker end up near where it started or far away?" (Varies—that's randomness!), (2) "Run it 5 times—do you get the same path?" (No—each run is different). **Key concept:** This is an "agent-based" simulation—the agent has state and makes probabilistic decisions. **Success criteria:** Walker completes 50 steps, trail is visible, energy depletes correctly. _Implementation note: Pen trail with energy counter display._

Dependencies:
* T27.G4.05: Generate and visualize random coordinate pairs
* T09.G4.04: Use variables to control animation or game state
* T03.G3.01: Navigate a sprite using coordinates





ID: T27.G5.09
Topic: T27 – Chance & Simulations
Skill: Calculate and verify expected value through simulation
Description: **Student task:** Calculate expected value (long-run average) and verify with simulation. **Formula:** E = Σ(outcome × probability). **Example 1:** Fair die: E = (1×1/6) + (2×1/6) + (3×1/6) + (4×1/6) + (5×1/6) + (6×1/6) = 3.5. **Example 2:** Game: 50% chance win $10, 50% chance win $0. E = (10×0.5) + (0×0.5) = $5. **Example 3:** Weighted game: 10% chance win $100, 90% chance lose $5. E = (100×0.1) + (-5×0.9) = 10 - 4.5 = $5.50. **Verification:** Run 1000 simulations, calculate average outcome. Compare to calculated E. **Key insight:** Expected value tells you what to expect ON AVERAGE over many trials—not what happens in any single trial. **Success criteria:** Calculate E for 3 scenarios, verify one with simulation (average within 10% of E). _Implementation note: Calculator for E with simulation verification tool._

Dependencies:
* T27.G5.05: Calculate theoretical probability using the formula P = favorable/total
* T27.G5.06: Compare experimental probability to theoretical probability





ID: T27.G5.10
Topic: T27 – Chance & Simulations
Skill: Identify independent events and debunk the gambler's fallacy
Description: **Student task:** Explore whether past results affect future outcomes in random events. **Simulation experiment:** (1) Run coin flip simulation that tracks streaks, (2) After getting 5 heads in a row, predict: Is tails now more likely? (3) Continue flipping 100 more times after a streak of 5 heads, (4) Count: What fraction were tails? **Key discovery:** Still ~50%! Each flip is INDEPENDENT—the coin has no memory of past flips. **Gambler's fallacy examples:** (A) "Red has come up 10 times at roulette, so black is due!" (WRONG), (B) "I've lost 5 games, so I'm due for a win!" (WRONG for random games), (C) "This lottery number hasn't won in years, it's overdue!" (WRONG). **Analysis question:** "If events ARE independent, why do we still see streaks?" (Streaks happen by chance—5 heads in a row occurs 1/32 ≈ 3% of the time). **Success criteria:** Demonstrate independence through simulation, identify 3+ gambler's fallacy scenarios. _Implementation note: Streak tracker with "after streak" analysis._

Dependencies:
* T27.G5.06: Compare experimental probability to theoretical probability





ID: T27.G5.11
Topic: T27 – Chance & Simulations
Skill: Demonstrate the law of large numbers through simulation
Description: **Student task:** Run simulations at increasing sample sizes and observe convergence to theoretical probability. **Experiment:** Run coin flip simulations with n = 10, 100, 1000, 10000 trials. Record % heads for each. **Expected pattern:** n=10: might get 30-70% (high variability), n=100: usually 40-60%, n=1000: usually 47-53%, n=10000: usually 49-51% (very close to 50%). **Visualization:** Plot percentage vs trial count on line graph. The line should stabilize around 50% as n increases. **The Law of Large Numbers:** As the number of trials increases, experimental probability approaches theoretical probability. **Discussion:** "Does this mean that after many heads, tails becomes more likely?" (NO! That's the gambler's fallacy. The law says the AVERAGE stabilizes, not that results 'even out'). **Success criteria:** Complete 4 runs at different n values, create convergence graph, explain the law correctly. _Implementation note: Running percentage display that updates during simulation._

Dependencies:
* T27.G5.06: Compare experimental probability to theoretical probability
* T27.G4.03: Compare variability at different sample sizes (50 vs 500 trials)
* T26.G4.03: Create a line graph showing change over time




ID: T27.G5.12
Topic: T27 – Chance & Simulations
Skill: Validate simulation correctness using expected value comparison
Description: **Student task:** Create a validation test to check if your simulation is working correctly. **Validation method:** (1) Calculate theoretical expected value (e.g., fair die: E = 3.5), (2) Run simulation 1000+ times, (3) Calculate average result, (4) Compare to theoretical—should be within reasonable tolerance. **Example validation:** Die roll simulation: Theory E = 3.5. If your average is 2.1, something is wrong! Debug until average is 3.4-3.6. **Tolerance rule of thumb:** With 1000 trials, average should be within ±5% of expected. With 10000 trials, within ±2%. **Common bugs this catches:** (A) Random range wrong (1-5 instead of 1-6), (B) One outcome weighted incorrectly, (C) Counting logic error. **Key concept:** Expected value comparison is a powerful validation tool—if your simulation produces wrong averages, the probabilities are wrong! **Success criteria:** Validate 2 simulations using expected value, catch and fix one intentional bug. _Implementation note: Pre-built validation checker comparing simulation mean to theoretical._

Dependencies:
* T27.G5.09: Calculate and verify expected value through simulation
* T27.G5.11: Demonstrate the law of large numbers through simulation





ID: T27.G6.01.01
Topic: T27 – Chance & Simulations
Skill: Manually test simulation parameters and log results systematically
Description: **Student task:** Test how changing a parameter affects simulation outcomes by running controlled experiments. **Example scenario:** Catch-the-falling-object game with adjustable ball speed. **Procedure:** (1) Set speed = 1, play 10 times, record wins/losses, (2) Repeat for speed = 2, 3, 4, 5. **Results table:** Speed 1 → 10/10 wins (too easy), Speed 3 → 7/10 wins (challenging), Speed 5 → 2/10 wins (too hard). **Analysis:** Identify the "sweet spot"—the parameter value where the game is challenging but fair (around 60-70% win rate). **Key concept:** Systematic parameter testing helps optimize simulations. This is how game designers balance difficulty! **Documentation:** Record hypothesis before testing, actual results, and conclusion. **Success criteria:** Test 5 parameter values, create organized results table, identify optimal range. _Implementation note: Game with adjustable parameter and results logging._

Dependencies:
* T27.G5.04: Write a 5-part simulation plan before coding
* T27.G5.06: Compare experimental probability to theoretical probability





ID: T27.G6.01.02
Topic: T27 – Chance & Simulations
Skill: Automate parameter sweeps with nested loops
Description: **Student task:** Automate the parameter testing from G6.01.01 using nested loops. **Code structure:** Outer loop: 'for speed from 1 to 5', Inner loop: 'repeat 20 times [run trial, track win/loss]'. After inner loop: log [speed, totalWins]. **Expected output:** Table like [[1, 20], [2, 18], [3, 15], [4, 10], [5, 4]]—showing wins out of 20 for each speed. **Advantages over manual testing:** (1) Faster—tests all parameters in seconds, (2) More trials—can easily run 100 instead of 10, (3) Reproducible—same code gives comparable results. **Visualization:** Create bar chart showing win rate vs parameter value. **Extension:** Test 2 parameters (speed AND size) with triple-nested loops. **Success criteria:** Automated sweep produces results table for 5+ parameter values, each with 20+ trials. _Implementation note: Progress indicator showing current parameter and trial._

Dependencies:
* T27.G6.01.01: Manually test simulation parameters and log results systematically
* T07.G5.01: Use nested loops for grid or matrix operations





ID: T27.G6.02
Topic: T27 – Chance & Simulations
Skill: Use random seeds for reproducible simulations
Description: **Student task:** Use CreatiCode's seeded random block to create reproducible simulations. **Code:** 'set [randomList] to (100) random numbers with seed (42)'. Use values from this list instead of 'pick random'. **Verification tests:** (1) Run with seed 42 twice → identical results both times, (2) Change to seed 43 → different results but still reproducible with seed 43. **Why this matters:** (A) Debugging: "I got a weird result on trial 47—can you reproduce it?" (Yes, with same seed!), (B) Fairness: "Same puzzle/challenge for all players in competition", (C) Testing: "Run same scenario to compare different algorithms." **Real-world uses:** Video game speedrunning exploits seeds, scientific simulations require reproducibility, multiplayer games use shared seeds for fairness. **Success criteria:** Demonstrate identical results with same seed, different results with different seed. _Implementation note: Side-by-side output comparison for same vs different seeds._

Dependencies:
* T27.G5.04: Write a 5-part simulation plan before coding
* T27.G6.01.02: Automate parameter sweeps with nested loops





ID: T27.G6.03
Topic: T27 – Chance & Simulations
Skill: Calculate percent error to evaluate simulation accuracy
Description: **Student task:** Calculate percent error to quantify how close simulation results are to theoretical values. **Formula:** Percent Error = |experimental - theoretical| / theoretical × 100%. **Example:** Theory: P(heads) = 50%. Experiment: 47 heads out of 100 = 47%. Error = |47-50|/50 × 100% = 6%. **Quality thresholds:** <5% error = excellent (results match theory well), 5-10% = acceptable (normal random variation), >10% = investigate (possible bug or too few trials). **Practice:** Calculate percent error for: (1) Die roll: expected 16.7% for each face, got 12% for "6" → error = ?, (2) 4-color spinner: expected 25% each, got red=32% → error = ?. **When to worry:** High error might mean: bug in code, unfair simulation, or just need more trials. **Success criteria:** Calculate percent error for 3+ scenarios, apply quality thresholds correctly. _Implementation note: Error calculator with threshold indicator (green/yellow/red)._

Dependencies:
* T27.G5.06: Compare experimental probability to theoretical probability
* T27.G5.11: Demonstrate the law of large numbers through simulation





ID: T27.G6.04
Topic: T27 – Chance & Simulations
Skill: Generate synthetic sensor data for AI testing
Description: **Student task:** Generate fake sensor data to test AI systems without real hardware. **Example: Hand detection testing.** Generate 50 fake hand positions: x = 200 + pick random -15 to 15 (adds noise), y = 150 + pick random -15 to 15, confidence = 0.8 + (pick random 0 to 20) / 100 (ranges 0.8-1.0). **Testing scenarios:** (A) High confidence readings (0.9+): AI should respond normally, (B) Low confidence readings (0.6-0.8): AI should show warning or ignore, (C) Jittery data (lots of noise): AI should smooth or filter. **Why synthetic data?** Faster than collecting real data, can create rare edge cases, reproducible for debugging, no camera needed. **Real-world use:** Self-driving car simulation, robot testing, game AI development. **Success criteria:** Generate realistic synthetic data, test AI with different noise levels, identify edge cases. _Implementation note: Synthetic data generator with adjustable noise parameters._

Dependencies:
* T27.G5.03: Use Monte Carlo sampling to estimate π
* T27.G5.04: Write a 5-part simulation plan before coding





ID: T27.G6.05
Topic: T27 – Chance & Simulations
Skill: Model an agent in a discrete grid world
Description: **Student task:** Create a grid-based agent with position and direction state. **Agent variables:** (1) gridX, gridY: integer positions (0-9), (2) direction: 0=up, 1=right, 2=down, 3=left. **Movement commands:** "forward": if direction=0, gridY += 1; if direction=1, gridX += 1; etc. "turn right": direction = (direction + 1) mod 4. **Visualization:** Convert grid to pixels: screenX = gridX × 40, screenY = gridY × 40. Draw grid lines, show agent as arrow pointing in current direction. **Test sequence:** "forward, forward, turn right, forward" starting at (0,0) facing up → should end at (1,2) facing right. **Key concept:** Grid worlds are the foundation for many AI simulations—the discrete positions make it easier to track state and test algorithms. **Success criteria:** Agent moves correctly on grid, direction changes work, visualization shows position and heading. _Implementation note: Visible grid with agent sprite that rotates based on direction._

Dependencies:
* T27.G5.08: Build a random walker agent with state tracking
* T27.G5.04: Write a 5-part simulation plan before coding





ID: T27.G6.06
Topic: T27 – Chance & Simulations
Skill: Simulate dependent events where probabilities change
Description: **Student task:** Simulate drawing marbles without replacement and observe how probabilities change. **Setup:** Bag contains 5 red, 3 blue marbles (list: [R,R,R,R,R,B,B,B]). **First draw:** P(red) = 5/8 = 62.5%. If red drawn, remove it from list. **Second draw:** Now 4 red, 3 blue remain. P(red) = 4/7 = 57.1%. **Simulation comparison:** Run 1000 trials each: (A) WITHOUT replacement (remove drawn marble), (B) WITH replacement (put marble back). **Compare results:** Track P(both red). Without replacement: (5/8)×(4/7) ≈ 35.7%. With replacement: (5/8)×(5/8) = 39.1%. **Key concept:** In dependent events, the outcome of one event changes the probabilities for the next. This is the foundation of conditional probability! **Success criteria:** Simulate both scenarios, explain why probabilities differ, calculate theoretical values. _Implementation note: Visual bag showing marbles being drawn and removed._

Dependencies:
* T27.G5.01.01: Simulate compound events (two dice) and collect sum data
* T27.G4.07: Generate random selections without repetition (sampling without replacement)




ID: T27.G6.06.01
Topic: T27 – Chance & Simulations
Skill: Trace probability changes through sequential draws without replacement
Description: **Student task:** Create a probability tree showing how probabilities change after each draw without replacement. **Setup:** Bag with 4 red, 2 blue marbles. **Tree construction:** First branch: P(red) = 4/6, P(blue) = 2/6. If red drawn first: second branch P(red) = 3/5, P(blue) = 2/5. If blue drawn first: second branch P(red) = 4/5, P(blue) = 1/5. **Calculate all paths:** P(red,red) = (4/6)×(3/5) = 12/30 = 40%, P(red,blue) = (4/6)×(2/5) = 8/30 ≈ 27%, P(blue,red) = (2/6)×(4/5) = 8/30 ≈ 27%, P(blue,blue) = (2/6)×(1/5) = 2/30 ≈ 7%. **Verification:** All probabilities sum to 100%. **Key insight:** Each path's probability is product of branches—this is the multiplication rule for dependent events. **Success criteria:** Build correct probability tree, calculate all 4 path probabilities, verify they sum to 1. _Implementation note: Interactive tree builder with probability calculator._

Dependencies:
* T27.G6.06: Simulate dependent events where probabilities change
* T27.G5.05: Calculate theoretical probability using the formula P = favorable/total




ID: T27.G6.06.02
Topic: T27 – Chance & Simulations
Skill: Compare simulation results for with vs without replacement sampling
Description: **Student task:** Run parallel simulations comparing sampling with and without replacement, analyzing the differences. **Experiment design:** Same starting bag (5 red, 3 blue), draw 3 marbles, track color sequence. Run 1000 trials of each: (A) With replacement: after each draw, put marble back, (B) Without replacement: after each draw, marble stays out. **Data collection:** For each method, count: all red, all blue, mixed combinations. **Expected differences:** With replacement: P(3 red) = (5/8)³ ≈ 24%. Without replacement: P(3 red) = (5/8)×(4/7)×(3/6) ≈ 18%. **Analysis questions:** (1) "Which method has higher P(all same color)?" (Without—once you start a streak, pool becomes more favorable), (2) "Which method gives more consistent results?" (With—probabilities stay constant). **Success criteria:** Run both simulations, compare probabilities, explain the differences. _Implementation note: Side-by-side simulation runners with comparison charts._

Dependencies:
* T27.G6.06.01: Trace probability changes through sequential draws without replacement
* T27.G6.01.02: Automate parameter sweeps with nested loops





ID: T27.G6.07
Topic: T27 – Chance & Simulations
Skill: Design a grid environment with obstacles and goals
Description: **Student task:** Extend the grid world by adding walls and a goal. **Environment elements:** (1) walls list: [[2,3], [2,4], [3,4], [4,4]] (blocked cells), (2) goal: [5,5] (target location), (3) start: [0,0]. **Movement logic update:** Before moving, check: 'if [newX, newY] in walls list, don't move (or bounce back)'. **Win detection:** 'if [gridX, gridY] = goal, say "You win!" and stop'. **Testing:** (A) Try to walk through a wall—should be blocked, (B) Reach the goal—should trigger win, (C) Create a maze configuration that has a valid path to goal. **Visualization:** Draw walls as solid blocks, goal as a star/flag, clear cells as empty. **Extension:** Make some walls only appear 50% of the time (random obstacles). **Success criteria:** Agent respects walls, reaches goal triggers win, maze is navigable. _Implementation note: Grid display with wall/goal visualization._

Dependencies:
* T27.G6.05: Model an agent in a discrete grid world
* T10.G4.01: Search for an item in a list





ID: T27.G6.08
Topic: T27 – Chance & Simulations
Skill: Implement reward functions and track agent outcomes
Description: **Student task:** Add a scoring system to the grid agent and analyze outcomes. **Reward rules:** +10 points: reach goal, -1 point: each step taken, -5 points: bump into wall. **Experiment:** Run 10 trials with random starting positions: 'startX = pick random 0 to 5, startY = pick random 0 to 5'. **Data logging:** For each trial, record [startX, startY, steps, wallBumps, finalScore]. **Analysis questions:** (1) "Which starting positions lead to higher scores?" (Closer to goal, fewer obstacles), (2) "What's the theoretical maximum score from position (4,4) if goal is (5,5)?" (+10 goal - 2 steps = +8), (3) "Why might random movement give negative scores?" (Many steps, wall bumps). **Key concept:** Reward functions define what "success" means—this is how AI learns what to optimize! **Success criteria:** Implement scoring, run 10 trials, identify patterns in results. _Implementation note: Score tracker with trial log table._

Dependencies:
* T27.G6.07: Design a grid environment with obstacles and goals
* T27.G6.01.01: Manually test simulation parameters and log results systematically





ID: T27.G6.09
Topic: T27 – Chance & Simulations
Skill: Create two-sprite interaction with chase/flee dynamics
Description: **Student task:** Create two sprites that detect and respond to each other's positions. **Sprite behaviors:** Cat (predator): moves randomly each tick (pick random direction, move 5 pixels). Mouse (prey): 'if distance to cat < 50 then glide 10 pixels away from cat, else move randomly'. **Detection methods:** (A) 'touching [cat]?' block, (B) 'distance to [cat]' < threshold, (C) Calculate manually: sqrt((catX-mouseX)² + (catY-mouseY)²). **Game loop:** Both sprites update position each tick, creating emergent chase/flee dynamics. **Analysis:** Run for 100 ticks and count: How many times did cat catch mouse? Does mouse survive longer with better flee logic? **Key concept:** Multi-agent systems create emergent behavior—the chase pattern wasn't explicitly programmed, it emerges from individual rules! **Success criteria:** Both sprites move appropriately, mouse flees when cat is near. _Implementation note: Tick counter with catch detection._

Dependencies:
* T27.G6.05: Model an agent in a discrete grid world
* T06.G5.01: Broadcast a custom message and respond in another sprite





ID: T27.G6.10
Topic: T27 – Chance & Simulations
Skill: Compare random, systematic, and stratified sampling methods
Description: **Student task:** Sample from a population using three different methods and compare results. **Population:** 100 survey responses with attributes [age, gender, score]. **Sampling methods:** (1) **Random:** Pick 20 items using pick random index, (2) **Systematic:** Take every 5th item (items 5, 10, 15, 20...), (3) **Stratified:** Ensure 10 male and 10 female in sample. **Comparison metrics:** Does sample average match population average? Does sample have similar gender ratio as population? **Discussion questions:** (1) "When might random sampling give a biased sample?" (By chance, might get mostly one group), (2) "When is stratified sampling better?" (When you need guaranteed representation of subgroups), (3) "What's the risk of systematic sampling?" (If there's a pattern in the data order, might be biased). **Success criteria:** Implement all three methods, compare representativeness, explain trade-offs. _Implementation note: Population generator with sampling tools and comparison stats._

Dependencies:
* T27.G5.02: Simulate random assignment for A/B testing
* T27.G5.11: Demonstrate the law of large numbers through simulation





ID: T27.G6.11
Topic: T27 – Chance & Simulations
Skill: Calculate and verify conditional probability through simulation
Description: **Student task:** Learn conditional probability notation and verify calculations with simulation. **Notation:** P(A|B) = "probability of A given that B occurred." **Example:** Bag has 3 red, 2 blue marbles. What is P(2nd is red | 1st was blue)? **Calculation:** After blue removed, 3 red + 1 blue remain. P(red) = 3/4 = 75%. **Simulation verification:** (1) Run 1000 two-draw trials, (2) Filter to only trials where first was blue, (3) Of those, count what fraction had red second, (4) Should be ≈75%. **Real-world examples:** (A) P(rain | cloudy) ≠ P(rain)—clouds make rain more likely, (B) P(pass test | studied) > P(pass test | didn't study), (C) P(flight delayed | winter) > P(flight delayed | summer). **Formula:** P(A|B) = P(A and B) / P(B). **Success criteria:** Calculate conditional probability for 2+ scenarios, verify one with simulation. _Implementation note: Conditional filter tool showing filtered subset analysis._

Dependencies:
* T27.G6.06: Simulate dependent events where probabilities change
* T27.G5.05: Calculate theoretical probability using the formula P = favorable/total




ID: T27.G6.12
Topic: T27 – Chance & Simulations
Skill: Build a waiting line (queue) simulation
Description: **Student task:** Simulate a service queue to analyze wait times and optimize staffing. **Scenario:** School cafeteria line—students arrive randomly, get served, leave. **Model components:** (1) Arrival: Each tick, 30% chance a new student joins queue, (2) Service: If line not empty, serve one student per tick, (3) Track: queue length, wait time for each student, max queue length. **Build steps:** (1) Create list for queue (student arrival times), (2) Each tick: maybe add student (pick random), (3) If queue not empty: remove first student, calculate wait time, (4) Log wait times to results list. **Run for 100 ticks:** Calculate average wait time, max queue length. **Optimization question:** "What if we add a second server? How does that change wait times?" (Add: if queue length > 1, serve two per tick). **Key concept:** Queue simulations help optimize real-world systems—restaurants, hospitals, airports! **Success criteria:** Working queue simulation, average wait time calculated, compare 1 vs 2 servers. _Implementation note: Visual queue display with wait time statistics._

Dependencies:
* T27.G6.08: Implement reward functions and track agent outcomes
* T27.G6.01.02: Automate parameter sweeps with nested loops





ID: T27.G7.01
Topic: T27 – Chance & Simulations
Skill: Build a predator-prey simulation with probabilistic behaviors
Description: **Student task:** Build a predator-prey simulation where agents have probabilistic decision-making. **Predator behavior:** Each step: 70% chance move toward prey (calculate direction), 30% chance random move. Has "hunger" variable that increases each step, resets to 0 when catching prey, dies if hunger > 50. **Prey behavior:** Each step: if distance to predator < 100, flee (move away); else random move. Has "energy" that decreases by 1 each step, dies if energy = 0. **Simulation metrics:** Run 100 time steps, log: number of catches, average prey lifespan, predator hunger over time. **Analysis:** (1) "Does the prey always get caught?" (No—randomness means sometimes it escapes), (2) "What if predator is 90% vs 50% likely to chase?" (Higher = more catches, but more predictable). **Key concept:** Probabilistic rules create varied, realistic behaviors. **Success criteria:** Both agents have correct probabilistic behaviors, metrics logged correctly. _Implementation note: State variables for both agents with visual tracking._

Dependencies:
* T27.G6.09: Create two-sprite interaction with chase/flee dynamics
* T27.G6.08: Implement reward functions and track agent outcomes





ID: T27.G7.02
Topic: T27 – Chance & Simulations
Skill: Trace how an agent learns from rewards over multiple trials
Description: **Student task:** Observe and trace a pre-built "learning agent" simulation to understand reinforcement learning basics. **Agent setup:** Preference table stores direction weights for each grid cell. Initially: up=25%, right=25%, down=25%, left=25%. **Learning rule:** After reaching goal, trace back the successful path. For each cell on the path, increase weight of the direction taken by 10%. Normalize so weights sum to 100%. **Trace activity:** Run 10 trials, recording for cell (2,2): Trial 1 weights, Trial 5 weights, Trial 10 weights. **Analysis questions:** (1) "How did the preference table change?" (Successful directions get higher weights), (2) "Why does the agent take fewer steps by trial 10?" (It's learned which directions lead to goal), (3) "Is this 'intelligent'?" (It's learning from experience, a basic form of AI!). **Key concept:** This is reinforcement learning—the foundation of modern AI like game-playing bots. **Success criteria:** Accurately trace weight changes, explain why performance improves. _Implementation note: Visible preference table updating after each trial._

Dependencies:
* T27.G6.08: Implement reward functions and track agent outcomes
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors





ID: T27.G7.03
Topic: T27 – Chance & Simulations
Skill: Test game fairness using synthetic player populations
Description: **Student task:** Test whether a game treats different player groups fairly using synthetic test populations. **Create synthetic players:** 50 "new players" (skill = pick random 1 to 3), 50 "experienced players" (skill = pick random 7 to 10). **Run experiment:** Each synthetic player plays the game, record their score. **Analysis:** (1) Average score for new players vs experienced players, (2) Is 3x higher for experienced fair? (Yes—skill should matter), (3) If new players score 0 and experienced score 100, is that fair? (Maybe not—game might be too punishing). **Additional test—Avatar bias:** Create players with different avatar types, same skill level. Do certain avatars get different outcomes? (If yes, that's unfair bias!). **Fairness questions:** "Should random elements affect skilled and new players equally?" "Should everyone have SOME chance to win?" **Success criteria:** Create test populations, run comparative analysis, identify fairness issues. _Implementation note: Population generator with group comparison stats._

Dependencies:
* T27.G6.04: Generate synthetic sensor data for AI testing
* T27.G6.08: Implement reward functions and track agent outcomes





ID: T27.G7.04
Topic: T27 – Chance & Simulations
Skill: Perform permutation tests to determine if differences are statistically meaningful
Description: **Student task:** Use shuffling to test whether an observed difference could happen by chance. **Scenario:** Version A scores: [85, 90, 88] (avg=87.7). Version B scores: [70, 75, 72] (avg=72.3). Real difference = 15.4 points. Is this meaningful or just random variation? **Permutation test procedure:** (1) Combine all scores into one pool: [85,90,88,70,75,72], (2) Shuffle the pool, (3) Split into fake "A" (first 3) and fake "B" (last 3), (4) Calculate fake difference in averages, (5) Repeat 200 times, (6) Count: How often is |fake difference| ≥ 15.4? **Interpretation:** If only 5 of 200 shuffles (2.5%) have difference ≥ 15.4, the real difference is unlikely to be chance. If 50 of 200 (25%) have difference ≥ 15.4, could easily be chance. **Key concept:** This is the foundation of statistical hypothesis testing—used by scientists to determine if results are "significant." **Success criteria:** Implement permutation test, interpret results correctly. _Implementation note: Shuffle animation with running count of extreme differences._

Dependencies:
* T27.G6.01.02: Automate parameter sweeps with nested loops
* T27.G6.02: Use random seeds for reproducible simulations





ID: T27.G7.05
Topic: T27 – Chance & Simulations
Skill: Write a model card documenting simulation assumptions and limitations
Description: **Student task:** Write a "model card" documenting your simulation following AI industry standards. **Model card sections:** (1) **Purpose:** What question does this simulation answer? (e.g., "Estimates how long prey survives when predator has different chase probabilities"), (2) **Assumptions:** What did we simplify? (e.g., "Agents can't see through walls," "All agents move at same speed," "Environment is 2D grid"), (3) **Limitations:** What can't it predict? (e.g., "Doesn't model fatigue," "Assumes perfect detection," "Only one predator"), (4) **Who might be affected:** Would decisions based on this simulation hurt anyone? (e.g., "If used to design a real security system, missed assumptions could create vulnerabilities"), (5) **Validation:** How did we test that it works correctly? **Why this matters:** Real AI systems require documentation so others understand limitations. Undocumented assumptions cause real-world failures! **Success criteria:** Complete all 5 sections with thoughtful, specific content. _Implementation note: Model card template with required fields._

Dependencies:
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors
* T27.G7.03: Test game fairness using synthetic player populations





ID: T27.G7.06.01
Topic: T27 – Chance & Simulations
Skill: Scale to multi-agent simulations using clones (5-10 agents)
Description: **Student task:** Scale from 2 agents to 5-10 using clone-based architecture. **Architecture:** Each clone has own state stored in lists indexed by clone ID: positions[id], speeds[id], types[id], energies[id]. **Clone-to-clone interaction:** Each frame, each clone: (1) Gets its position from list using ID, (2) Checks distance to ALL other clones, (3) Responds based on type (predator chases prey, prey flees predators, neutrals wander). **Independence test:** Delete one clone mid-simulation—others should continue working without crashing. **Common bugs:** Using sprite variables instead of list lookup (causes all clones to share state), forgetting to update list when clone state changes. **Emergent behaviors:** Watch for flocking, chasing packs, or prey grouping for safety. **Success criteria:** 5-10 agents running simultaneously with independent states, interactions work correctly. _Implementation note: Clone ID tracking with list-based state management._

Dependencies:
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors
* T11.G5.03: Create clones with different behaviors





ID: T27.G7.06.02
Topic: T27 – Chance & Simulations
Skill: Aggregate and display population-level metrics from multi-agent simulations
Description: **Student task:** Calculate population-level statistics from your multi-agent simulation and display them as a real-time dashboard. **Metrics to calculate:** (1) **Population counts:** # prey alive, # predators alive, (2) **Average position:** center of mass = (avg of all x positions, avg of all y positions), (3) **Total energy:** sum of all agents' energy levels, (4) **Clustering metric:** standard deviation of positions (low = clustered, high = spread out). **Dashboard display:** Show all metrics updating each tick. Graph population over time (line chart showing prey count vs predator count vs time). **Analysis questions:** (1) "Do prey cluster for safety?" (Check clustering metric when predator is near), (2) "Does total energy stay constant, increase, or decrease?" (Depends on your rules). **Key concept:** Population-level views reveal patterns invisible when watching individual agents. **Success criteria:** All 4 metrics calculated correctly, dashboard updates in real-time. _Implementation note: Real-time stat display with live graph._

Dependencies:
* T27.G7.06.01: Scale to multi-agent simulations using clones (5-10 agents)
* T26.G5.01: Calculate mean from a dataset






ID: T27.G7.07
Topic: T27 – Chance & Simulations
Skill: Identify and fix bias in random selection algorithms
Description: **Student task:** Investigate how "random" selection can be unfair and learn to detect/fix biases. **Example 1—Biased pool:** Random from [A,A,A,B] gives 75% A, 25% B—the pool itself is biased, not the selection. Fix: Ensure equal representation in pool. **Example 2—Flawed shuffle (Fisher-Yates bug):** Swap with ANY position (biased) vs swap with LATER positions only (correct). Test: Run 10000 shuffles of [1,2,3], count how often each permutation appears. Correct algorithm gives ~1667 each; flawed gives unequal counts. **Historical case studies:** (A) 1970 Vietnam draft lottery—capsules not mixed well, later birthdays called more, (B) Early browser random number bugs exploited by online casinos. **Fixes:** Use verified library functions, audit distributions with many trials, use stratified selection when representation matters. **Success criteria:** Identify bias in 2+ scenarios, explain why they're biased, propose corrections. _Implementation note: Shuffle tester comparing biased vs correct algorithms._

Dependencies:
* T27.G7.03: Test game fairness using synthetic player populations
* T27.G6.10: Compare random, systematic, and stratified sampling methods




ID: T27.G7.08
Topic: T27 – Chance & Simulations
Skill: Simulate disease spread with infection probability
Description: **Student task:** Build a simplified epidemic simulation showing how diseases spread through a population. **SIR Model basics:** Agents are Susceptible (S), Infected (I), or Recovered (R). **Rules:** (1) Infected agents have 20% chance to infect nearby Susceptible agents each tick, (2) Infected agents recover after 10 ticks and become immune (R), (3) Recovered agents can't be reinfected. **Setup:** 50 agents, 1 starts infected. **Metrics to track:** Peak infected count, total ever infected, time to peak, time to end. **Parameter experiments:** (A) Infection rate 10% vs 30%—how does peak change? (B) Starting with 1 vs 5 infected—how does timeline change? (C) Add "social distancing"—agents move less, lower infection rate. **Real-world connection:** This is how epidemiologists model COVID, flu, measles! **Key insight:** Small changes in infection rate cause big changes in outcomes—exponential growth is powerful. **Success criteria:** Working SIR simulation, track metrics, compare different infection rates. _Implementation note: Agents with color-coded states (green=S, red=I, blue=R)._

Dependencies:
* T27.G7.06.01: Scale to multi-agent simulations using clones (5-10 agents)
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors




ID: T27.G7.09
Topic: T27 – Chance & Simulations
Skill: Model weather transitions using Markov chain probabilities
Description: **Student task:** Build a Markov chain weather model where tomorrow's weather depends only on today's weather. **Transition matrix:** If today is Sunny: 70% tomorrow sunny, 30% rainy. If today is Rainy: 40% tomorrow sunny, 60% rainy. **Simulation:** (1) Start with random weather, (2) Each day: use today's state to pick tomorrow's state, (3) Run 100 days, track sequence. **Analysis questions:** (1) "What fraction of days are sunny in the long run?" (Calculate steady state: ~57% sunny), (2) "If it's been rainy for 3 days, is sunny more likely?" (No—Markov property means only today matters, not history!), (3) "How long are typical sunny/rainy streaks?" (Simulate and count). **Key concept:** Markov chains are "memoryless"—the future depends only on the present, not the past. Used in: weather forecasting, page rank, text generation. **Extension:** Add a third state (Cloudy) with 3×3 transition matrix. **Success criteria:** Implement transition logic, run 100-day simulation, calculate long-run percentages. _Implementation note: Transition matrix as 2D list, state visualization._

Dependencies:
* T27.G6.11: Calculate and verify conditional probability through simulation
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors





ID: T27.G8.01
Topic: T27 – Chance & Simulations
Skill: Build an automated simulation-to-dashboard pipeline
Description: **Student task:** Create a professional end-to-end pipeline from simulation to interactive dashboard. **Pipeline stages:** (1) **Data collection:** Automated parameter sweep—5 configurations × 50 trials each = 250 total runs. (2) **Storage:** Results in table with columns [configID, trialNum, outcome, score, timestamp]. (3) **Analysis:** Code calculates for each config: mean, median, range, standard deviation. (4) **Visualization:** Dashboard with bar chart comparing config means, error bars showing variability. (5) **Interactivity:** Click a config bar to see detailed histogram of that config's results. **Professional features:** Auto-refresh when new data added, export results to CSV, color-code configs by performance. **Why this matters:** This is how professional data scientists work—automating the entire pipeline from experiment to insight. **Success criteria:** Complete pipeline running, dashboard updates automatically, interactive drill-down works. _Implementation note: Integrated data collection, analysis, and visualization workflow._

Dependencies:
* T27.G6.01.02: Automate parameter sweeps with nested loops
* T27.G7.06.02: Aggregate and display population-level metrics from multi-agent simulations
* T27.G7.05: Write a model card documenting simulation assumptions and limitations





ID: T27.G8.02
Topic: T27 – Chance & Simulations
Skill: Use bootstrap sampling to estimate confidence intervals
Description: **Student task:** Learn bootstrap sampling to understand how measurements vary by chance. **Bootstrap procedure:** (1) Original data: 100 scores, (2) Draw 100 items WITH replacement (same item can be picked multiple times), (3) Calculate mean of this bootstrap sample, (4) Repeat 500 times → 500 bootstrap means. **Analysis:** Create histogram of 500 means to see the "sampling distribution." Find the middle 95%: sort means, take values at positions 13 and 488 (2.5% from each end). This range is your 95% confidence interval! **Interpretation:** "We are 95% confident the true population mean is between X and Y." **Why WITH replacement?** Simulates drawing from a population—each draw is independent. **Real-world use:** Medical studies, poll margins of error, A/B test confidence. **Success criteria:** Generate bootstrap samples, calculate 95% CI, interpret correctly. _Implementation note: Bootstrap sampler with histogram and CI visualization._

Dependencies:
* T27.G6.01.02: Automate parameter sweeps with nested loops
* T27.G7.04: Perform permutation tests to determine if differences are statistically meaningful
* T26.G6.01: Calculate statistics (mean, median, mode, range)






ID: T27.G8.03
Topic: T27 – Chance & Simulations
Skill: Integrate AI assistants into simulation analysis workflows
Description: **Student task:** Use AI assistants to help analyze simulation results and suggest next steps. **Workflow:** (1) Export simulation summary as structured text: "Config A: mean=85, sd=12. Config B: mean=72, sd=8...", (2) Prompt XO/ChatGPT: "Here are my simulation results. What patterns do you see? What parameter should I test next? Are there any outliers or anomalies?", (3) Critically evaluate AI response: Did it notice the outlier in Config C? Did it suggest something useful? Did it miss context you know? **Reflection questions:** (1) "What did the AI catch that you missed?" (2) "What did you know that the AI couldn't?" (context about your simulation design), (3) "Would you trust the AI's suggestion without verification?" **Key insight:** AI assistants are tools, not replacements—they can spot patterns but lack domain knowledge. Always verify AI suggestions! **Success criteria:** Complete AI-assisted analysis, write critical reflection comparing AI insights to your own. _Implementation note: Export tool with AI integration and reflection template._

Dependencies:
* T27.G7.05: Write a model card documenting simulation assumptions and limitations
* T27.G8.01: Build an automated simulation-to-dashboard pipeline
* T21.G6.01.01: Make a basic ChatGPT request with one parameter





ID: T27.G8.04
Topic: T27 – Chance & Simulations
Skill: Write simulation-backed policy briefs for real-world problems
Description: **Student task:** Write a 1-2 page policy brief using simulation evidence to recommend action on a real problem. **Brief structure:** (1) **Problem:** "School lunch lines average 15 minutes, students miss class time." (2) **Method:** "Simulated 3 checkout configurations with 500 students over 50 lunch periods." (3) **Findings:** "Configuration B (2 lines with mobile ordering) reduced average wait by 40% (15min → 9min)." (4) **Recommendation:** "Implement Configuration B; estimated cost $X, saves Y student-hours per week." (5) **Limitations & Ethics:** "Assumes equal walking speed; doesn't account for students with disabilities who may need priority access; mobile ordering requires smartphone access." (6) **Next Steps:** "Pilot test in one cafeteria before full rollout." **Real-world connection:** This is civic data journalism—using data to advocate for policy changes! **Success criteria:** Complete all 6 sections with specific, evidence-backed content. _Implementation note: Policy brief template with evidence linking._

Dependencies:
* T27.G8.03: Integrate AI assistants into simulation analysis workflows
* T27.G7.05: Write a model card documenting simulation assumptions and limitations
* T32.G7.07: Identify stakeholders affected by a computing solution




ID: T27.G8.04.01
Topic: T27 – Chance & Simulations
Skill: Structure a policy brief with simulation-backed evidence sections
Description: **Student task:** Learn the professional structure of a policy brief and create an outline for your simulation study. **Required sections:** (1) **Executive Summary:** 2-3 sentence overview for busy decision-makers, (2) **Problem Statement:** What issue needs solving? Who is affected? Why does it matter?, (3) **Methodology:** How did your simulation model the problem? What assumptions?, (4) **Key Findings:** What did the data show? Include specific numbers, (5) **Recommendations:** What action should be taken? What's the expected benefit?, (6) **Limitations:** What did your simulation NOT capture? What uncertainties exist?, (7) **Next Steps:** How should this be tested/validated before full implementation? **Practice:** Write an outline for: "Should our school add a traffic light at the main entrance?" **Success criteria:** Complete outline with all 7 sections, each with 2-3 bullet points. _Implementation note: Outline template with section prompts._

Dependencies:
* T27.G8.04: Write simulation-backed policy briefs for real-world problems




ID: T27.G8.04.02
Topic: T27 – Chance & Simulations
Skill: Support policy recommendations with simulation statistics and visualizations
Description: **Student task:** Create compelling evidence presentations using your simulation data. **Evidence types:** (1) **Comparative statistics:** "Configuration A: mean wait 15min, sd 4min. Configuration B: mean wait 9min, sd 2min. Difference significant (p < 0.05)." (2) **Visualizations:** Side-by-side bar charts, before/after comparison, trend lines. (3) **Confidence intervals:** "We estimate 30-50% reduction in wait times (95% CI)." **Practice problems:** Create evidence package for: (A) Comparing two traffic light timings, (B) Evaluating three cafeteria layouts, (C) Testing vaccination rates vs disease spread. **Critical evaluation:** Would a skeptic find this convincing? What counter-arguments might they raise? How would you address them? **Key concept:** Strong evidence = clear statistics + compelling visuals + acknowledgment of uncertainty. **Success criteria:** Create 3 evidence presentations with statistics, charts, and confidence measures. _Implementation note: Chart templates with statistical summary generators._

Dependencies:
* T27.G8.04.01: Structure a policy brief with simulation-backed evidence sections
* T27.G8.02: Use bootstrap sampling to estimate confidence intervals




ID: T27.G8.04.03
Topic: T27 – Chance & Simulations
Skill: Present and defend simulation-based recommendations to stakeholders
Description: **Student task:** Present your policy brief to a panel and defend your methodology and conclusions. **Presentation elements:** (1) 5-minute summary of problem, method, findings, (2) Key visualizations that communicate main message, (3) Clear "ask"—what action do you want the audience to take? **Defense preparation:** Anticipate questions: (A) "How do we know your simulation is realistic?", (B) "What if your assumptions are wrong?", (C) "What's the cost of your recommendation?", (D) "Have you considered [alternative approach]?". **Practice responses:** For each anticipated question, prepare 30-second response with evidence reference. **Peer review:** Exchange briefs with classmate, role-play as skeptical stakeholder, give feedback. **Key concept:** Simulation results only matter if you can communicate them effectively and withstand scrutiny. **Success criteria:** Complete presentation, field 3+ questions, incorporate peer feedback into revised brief. _Implementation note: Presentation template with Q&A preparation guide._

Dependencies:
* T27.G8.04.02: Support policy recommendations with simulation statistics and visualizations
* T27.G7.05: Write a model card documenting simulation assumptions and limitations





ID: T27.G8.05
Topic: T27 – Chance & Simulations
Skill: Analyze how environment design creates bias in learned agent behaviors
Description: **Student task:** Run the same learning agent in different environments and analyze how design affects what it learns. **Experiment:** **Maze A:** One clear path to goal. **Maze B:** Multiple paths—one short (hidden), one long (obvious). **Run each:** 50 learning trials per maze. **Compare results:** In Maze A, agent consistently learns the same path. In Maze B, agent might learn the LONGER path if it found reward before discovering shortcut—"good enough" prevented finding optimal! **Analysis questions:** (1) "Why might an agent learn a suboptimal solution?" (Early reward stops exploration), (2) "How is this like AI training data bias?" (AI learns patterns in its training environment, which may not generalize), (3) "How could you design the environment to encourage better learning?" (Sparse rewards, exploration bonuses). **Real-world connection:** Self-driving cars trained in sunny California struggle with snow. Hiring AI trained on historical data perpetuates past biases. **Success criteria:** Complete comparative analysis, explain bias mechanism, connect to real AI issues. _Implementation note: Dual maze comparison with path visualization._

Dependencies:
* T27.G7.02: Trace how an agent learns from rewards over multiple trials
* T27.G7.05: Write a model card documenting simulation assumptions and limitations
* T32.G7.07: Identify stakeholders affected by a computing solution





ID: T27.G8.06
Topic: T27 – Chance & Simulations
Skill: Explain pseudorandom vs true random and their appropriate uses
Description: **Student task:** Explore how computers generate "random" numbers and when different types are needed. **Demonstration:** Same seed → same "random" sequence every time. Change seed → different sequence. **How pseudorandom works:** Linear Congruential Generator: next = (a × current + c) mod m. Simple formula, deterministic, but LOOKS random. **Research topics:** (1) **Speedrunning exploits:** Video game speedrunners manipulate seeds to get "lucky" item drops—because they're predictable! (2) **Cryptography requirements:** Encryption needs TRUE randomness from hardware sources (mouse movement timing, electrical noise, radioactive decay). Using pseudorandom for crypto = hackable! **Discussion questions:** (1) "When is pseudorandom good enough?" (Games, simulations, sampling), (2) "When must you use true randomness?" (Passwords, encryption keys, lotteries with real money), (3) "Could someone predict your 'random' game if they knew the algorithm?" (Yes, if they know the seed!). **Success criteria:** Explain the difference, identify appropriate uses for each. _Implementation note: LCG visualizer showing formula generating sequence._

Dependencies:
* T27.G6.02: Use random seeds for reproducible simulations
* T27.G7.07: Identify and fix bias in random selection algorithms




ID: T27.G8.07
Topic: T27 – Chance & Simulations
Skill: Use physics simulation for probability experiments (Galton board)
Description: **Student task:** Build a virtual Galton board (bean machine) using CreatiCode's 2D physics engine to demonstrate the normal distribution. **Build steps:** (1) Initialize 2D physics world with gravity: 'initialize 2D physics world with gravity x [0] y [-100]', (2) Create rows of pegs (circles with frozen physics bodies), (3) Drop balls from top center with small random x offset, (4) Collect balls in bins at bottom, count per bin. **Physics setup:** Balls have restitution 50% (bounce), pegs have friction. **After 100+ balls:** The bin counts form a bell curve! **Analysis questions:** (1) "Why does a ball end up in the middle more often?" (Equal chance left/right at each peg → more paths to middle), (2) "How is this related to flipping coins?" (Each peg is like a coin flip—left or right). **Connection:** This is the Central Limit Theorem in physical form—many random choices sum to a normal distribution. **Success criteria:** Working Galton board, bell curve visible in bin counts. _Implementation note: Use physics engine blocks for realistic ball bouncing._

Dependencies:
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors
* T27.G5.01.02: Analyze compound event distributions and explain why 7 is most common




ID: T27.G8.08
Topic: T27 – Chance & Simulations
Skill: Apply variance reduction techniques to improve simulation efficiency
Description: **Student task:** Learn and apply techniques to get accurate simulation results with fewer trials. **Problem:** Estimating probability of rare event (1%) with standard Monte Carlo requires 10,000+ trials for accuracy. **Technique 1—Stratified sampling:** Instead of fully random, ensure proportional sampling from known subgroups. Run both methods, compare variance. **Technique 2—Antithetic variates:** For each random number R, also use 1-R. Reduces variance because R and 1-R are negatively correlated. **Experiment:** Estimate π with 500 random points vs 250 pairs of antithetic points. Compare standard deviation of estimates over 20 runs. **Analysis questions:** (1) "Why does stratified sampling reduce variance?" (Guarantees coverage of all subgroups), (2) "When is antithetic sampling helpful?" (When outcome is monotonic in the random variable). **Key concept:** Smart sampling > brute force. Professional simulations use these techniques to save computation time. **Success criteria:** Implement both techniques, demonstrate reduced variance. _Implementation note: Variance comparison across multiple runs._

Dependencies:
* T27.G8.02: Use bootstrap sampling to estimate confidence intervals
* T27.G7.04: Perform permutation tests to determine if differences are statistically meaningful




ID: T27.G8.09
Topic: T27 – Chance & Simulations
Skill: Perform sensitivity analysis on simulation parameters
Description: **Student task:** Systematically analyze how sensitive simulation outcomes are to changes in each input parameter. **Procedure:** (1) Identify all parameters: e.g., predator speed, prey speed, detection range, starting populations. (2) For each parameter, vary by ±10%, ±25%, ±50% while holding others constant. (3) Record outcome change (e.g., average prey survival time). (4) Calculate sensitivity index: (% change in output) / (% change in input). **Results table:** Parameter | Base value | Sensitivity index. **Interpretation:** High sensitivity (>1) means small input changes cause big output changes—these parameters need careful calibration! Low sensitivity (<0.1) means parameter barely matters. **Tornado diagram:** Sort parameters by sensitivity, create horizontal bar chart showing range of outcomes. **Key concept:** Sensitivity analysis identifies which assumptions matter most—crucial for model credibility. **Success criteria:** Analyze 4+ parameters, create tornado diagram, identify most sensitive parameter. _Implementation note: Automated parameter variation with tornado chart generation._

Dependencies:
* T27.G8.01: Build an automated simulation-to-dashboard pipeline
* T27.G6.01.02: Automate parameter sweeps with nested loops




ID: T27.G8.10
Topic: T27 – Chance & Simulations
Skill: Implement evolutionary optimization using random mutation and selection
Description: **Student task:** Build a simple genetic algorithm to optimize a solution through random variation and selection. **Problem:** Find the best parameters for a game AI (speed, aggression, caution) to maximize score. **Algorithm:** (1) Create population of 10 random parameter sets, (2) Run each set in simulation, record scores, (3) Select top 3 performers as "parents", (4) Create new population by copying parents with random mutations (e.g., speed ± pick random -5 to 5), (5) Repeat for 20 generations. **Visualization:** Graph best score and average score per generation—should see improvement over time! **Analysis questions:** (1) "Why do we keep top performers?" (Preserve good solutions), (2) "Why add random mutations?" (Explore new possibilities, escape local optima), (3) "How is this like biological evolution?" (Survival of fittest + variation). **Real-world use:** Neural network training, game AI, logistics optimization. **Success criteria:** Algorithm improves scores over generations, visualize improvement. _Implementation note: Population list with mutation and selection logic._

Dependencies:
* T27.G8.01: Build an automated simulation-to-dashboard pipeline
* T27.G7.01: Build a predator-prey simulation with probabilistic behaviors




ID: T27.G8.11
Topic: T27 – Chance & Simulations
Skill: Use seeded random lists for batch simulation experiments
Description: **Student task:** Leverage CreatiCode's 'set list to N random numbers with seed' block for efficient batch simulations. **Procedure:** (1) Generate 1000 random numbers with seed 42: 'set [randomList] to (1000) random numbers with seed (42)', (2) Use list values in simulation instead of calling pick random repeatedly, (3) Run same simulation on different seeds (42, 43, 44...) to create replications. **Advantages:** (A) Pre-generating is faster than per-trial generation, (B) Same seed = exact reproduction for debugging, (C) Different seeds = independent replications for statistics. **Experiment:** Run 100 trials each with seeds 1-20. Calculate mean and standard deviation of means across seeds. **The Central Limit Theorem:** Distribution of means is tighter than distribution of individual trials! **Analysis:** "Why do we run multiple seeds instead of one big run?" (Each seed is an independent experiment, giving us a sample of possible outcomes). **Success criteria:** Batch runs across 20 seeds, demonstrate mean convergence, explain CLT. _Implementation note: Use CreatiCode's seeded random list block._

Dependencies:
* T27.G6.02: Use random seeds for reproducible simulations
* T27.G8.02: Use bootstrap sampling to estimate confidence intervals




ID: T27.G8.12
Topic: T27 – Chance & Simulations
Skill: Visualize simulation results with real-time charts
Description: **Student task:** Use CreatiCode's chart widget blocks to display live simulation data as bar, line, and pie charts. **Build steps:** (1) Collect simulation data in a list during run, (2) After collection: 'draw [bar v] chart using list [results] x (0) y (0) width (200) height (150)', (3) Add line chart for time series data: 'draw [line v] chart using columns [step,value] from table [data v]'. **Chart types:** Bar for comparing categories (outcomes A vs B vs C), Line for trends over time, Pie for proportions. **Dashboard:** Create multi-chart display showing different views of same data. **Interactivity:** Update chart after each parameter change to show real-time impact. **Professional practice:** Data scientists always visualize before analyzing—patterns visible in charts might be missed in numbers. **Success criteria:** Create 3 different chart types from simulation data, dashboard updates dynamically. _Implementation note: Use widget_drawchartusinglist and widget_drawchartusingcolumn blocks._

Dependencies:
* T27.G8.01: Build an automated simulation-to-dashboard pipeline
* T27.G7.06.02: Aggregate and display population-level metrics from multi-agent simulations




ID: T27.G8.13
Topic: T27 – Chance & Simulations
Skill: Design and validate an epidemiological simulation (capstone)
Description: **Student task:** Build a comprehensive disease spread simulation with validation against known patterns. **CAPSTONE PROJECT** combining multiple simulation skills. **Full SIR model with extensions:** (1) Base SIR from G7.08, (2) Add vaccination: some agents start immune, (3) Add quarantine: infected agents removed from population temporarily, (4) Add super-spreaders: 20% of infected have 3x infection rate. **Validation:** Compare your simulation to known epidemiological patterns: (A) R0 (basic reproduction number)—calculate from your simulation, (B) Herd immunity threshold—test vaccination rates 0%, 50%, 80%, (C) Flatten the curve—test social distancing impact. **Analysis deliverables:** (1) Model card documenting assumptions, (2) Parameter sensitivity analysis, (3) Policy recommendations based on findings. **Real-world connection:** Your simulation mirrors tools used by CDC, WHO for pandemic planning. **Success criteria:** Working simulation with 3+ extensions, validation against 2+ known patterns, complete documentation. _Implementation note: Multi-agent simulation with dashboard and analysis._

Dependencies:
* T27.G7.08: Simulate disease spread with infection probability
* T27.G8.09: Perform sensitivity analysis on simulation parameters
* T27.G8.04.01: Structure a policy brief with simulation-backed evidence sections




ID: T27.G8.14
Topic: T27 – Chance & Simulations
Skill: Build an agent-based environmental model
Description: **Student task:** Create an agent-based model of an ecosystem or environmental system with interacting species and resources. **Model components:** (1) **Resources:** Grass grows with probability each tick, depletes when eaten. (2) **Herbivores:** Rabbits eat grass, reproduce when energy high, die when energy depleted. (3) **Predators:** Foxes eat rabbits, reproduce when energy high, die when hungry. **Population dynamics:** Track population counts over 500 ticks. Expected pattern: predator-prey cycles (Lotka-Volterra). **Environmental factors:** Add random events: drought (grass grows slower), disease outbreak (rabbits die faster), hunting season (foxes removed). **Analysis questions:** (1) "Do populations stabilize, oscillate, or crash?", (2) "What initial conditions lead to extinction?", (3) "How do environmental shocks affect long-term balance?" **Real-world connection:** Ecologists use similar models for wildlife management, conservation planning. **Success criteria:** 3-species model with resource dynamics, population tracking over 500 ticks, analysis of stability conditions. _Implementation note: Multi-sprite ecosystem with population graphs._

Dependencies:
* T27.G7.08: Simulate disease spread with infection probability
* T27.G8.10: Implement evolutionary optimization using random mutation and selection
* T27.G8.01: Build an automated simulation-to-dashboard pipeline




# T28 - Text Data & NLP Foundations (Phase 9 Optimized - November 2025)
# Applied Phase 9 comprehensive topic optimizations:
# MAJOR CHANGES:
# 1. Fixed Vague Verbs → Active Verbs:
#    - T28.G4.10: "Store" → "Create" text data tables with paired columns
#    - T28.G4.11: "Label" → "Classify" emotional tone
#    - T28.G8.04: "Publish" → "Document" text datasets with datasheets
#    - T28.G4.05.04: "Experiment" → "Configure" ChatGPT parameters
# 2. Expanded Truncated Descriptions:
#    - T28.G4.04.02: Full examples for includes block with case sensitivity
#    - T28.G4.04.03: Full examples for starts/ends with validation patterns
# 3. Broke Down Overly Broad Skills into Sub-Skills:
#    - T28.G8.01 → T28.G8.01, G8.01.01, G8.01.02 (pipeline design, implement, debug)
#    - T28.G8.02 → T28.G8.02, G8.02.01, G8.02.02 (confusion matrix, metrics, tradeoffs)
#    - T28.G8.11 → T28.G8.11, G8.11.01, G8.11.02 (multi-modal routing, combining, adaptive output)
# 4. Added New AI-Era Advanced Skills:
#    - T28.G7.10: Design chain-of-thought prompts for complex reasoning
#    - T28.G7.11: Analyze how semantic embeddings represent text meaning
#    - T28.G8.05.07: Build complex regex patterns with character classes
# 5. Fixed Dependency Issues:
#    - Removed irrelevant T16.G6.01 (friction) dependency from T28.G8.03
#    - Removed irrelevant T21.G6.01.01 dependency from T28.G8.04
#    - Added T28.G7.07 (RAG) dependency to T28.G8.03 for proper progression
# 6. Improved Skill Descriptions:
#    - All descriptions now use imperative verbs throughout
#    - Added concrete examples and trace-through scenarios
#    - Enhanced regex skills with detailed pattern explanations
# Total: ~117 skills (added 10 new sub-skills and skills for depth)

ID: T28.GK.01
Topic: T28 – Text Data & NLP Foundations
Skill: Sort picture cards into text vs pictures vs numbers
Description: **Student task:** Drag picture cards into three sorting bins labeled "Text," "Pictures," and "Numbers." **Visual scenario:** Picture cards show: the word "DOG" printed on paper, a photo of a dog, the number "5", a STOP sign, a smiley face drawing, the word "HELLO," price tag showing "$3," rainbow drawing. Three bins with icons. **Correct sorting:** Text bin: DOG, STOP sign text, HELLO. Pictures bin: dog photo, smiley face, rainbow. Numbers bin: 5, price tag. Audio prompt: "Text is letters that make words we can read." _Implementation note: Drag-drop sorting with 8 cards and 3 bins. Auto-graded by bin contents. CSTA: K-2-DA-07._

Dependencies:
(none)





ID: T28.GK.02
Topic: T28 – Text Data & NLP Foundations
Skill: Count letters in words using picture cards
Description: **Student task:** View word cards and tap to count letters, then drag each word to the correct "number of letters" bin. **Visual scenario:** Word cards show: CAT, DOG, SUN, FISH, BALL, HI. Bins labeled: "2 letters," "3 letters," "4 letters." Students tap each letter in a word (letters highlight as tapped), then the total count appears. Finally, drag word to correct bin. **Correct sorting:** 2 letters: HI. 3 letters: CAT, DOG, SUN. 4 letters: FISH, BALL. _Implementation note: Tap-to-count interaction followed by drag-drop sorting. Audio counts along: "One, two, three!" Auto-graded by letter counts and bin placement. CSTA: K-2-DA-07._

Dependencies:
* T28.GK.01: Sort picture cards into text vs pictures vs numbers





ID: T28.GK.03
Topic: T28 – Text Data & NLP Foundations
Skill: Match words to pictures to show text has meaning
Description: **Student task:** Draw lines to connect word cards to matching picture cards. **Visual scenario:** Left column shows word cards: CAT, TREE, APPLE, STAR, HOUSE. Right column shows shuffled pictures: cat drawing, tree drawing, apple drawing, star shape, house drawing. Students draw lines connecting each word to its picture. After matching, audio says "The word CAT means this furry animal!" for each pair. **Why it matters:** Text carries meaning—the same word always points to the same thing. _Implementation note: Line-drawing matching activity with 5 pairs; audio reinforcement on completion. Auto-graded by correct pairings. CSTA: K-2-DA-07._

Dependencies:
* T28.GK.02: Count letters in words using picture cards




ID: T28.GK.04
Topic: T28 – Text Data & NLP Foundations
Skill: Find text in everyday pictures
Description: **Student task:** View pictures of real-world scenes and tap to circle where you see text. **Visual scenario:** Scene 1: Grocery store aisle—circle "MILK" on carton, "SALE" sign, price tags. Scene 2: Street scene—circle "STOP" sign, store name "TOYS," street name sign. Scene 3: Book cover—circle title and author name. For each scene, audio asks "Where do you see words?" After circling, students tap to reveal why that text helps people (STOP tells cars to stop, price tells how much). _Implementation note: Tap-to-circle on 3 photo scenes, 2-4 text locations each. Auto-graded by circled regions. CSTA: K-2-DA-07._

Dependencies:
* T28.GK.03: Match words to pictures to show text has meaning







ID: T28.G1.01
Topic: T28 – Text Data & NLP Foundations
Skill: Sort word cards by first letter into alphabet bins
Description: **Student task:** Drag word cards into bins labeled with letters A, B, C, D. **Visual scenario:** Word cards show: APPLE, BALL, CAT, ANT, DOG, BANANA, CAKE, DUCK. Four bins with large letters A, B, C, D. Students drag each word to the bin matching its first letter. Visual hint: first letter of each word is highlighted in red. **Correct sorting:** A bin: APPLE, ANT. B bin: BALL, BANANA. C bin: CAT, CAKE. D bin: DOG, DUCK. **Why it matters:** Sorting words by first letter helps us look things up quickly, like in a dictionary! _Implementation note: Drag-drop sorting with 8 words and 4 bins. Auto-graded by bin contents. CSTA: K-2-DA-08._

Dependencies:
* T28.GK.03: Match words to pictures to show text has meaning





ID: T28.G1.02
Topic: T28 – Text Data & NLP Foundations
Skill: Count words in a sentence by tapping each word
Description: **Student task:** Tap each word in a sentence to count them, then select the correct total. **Visual scenario:** Sentence strips appear one at a time: "I SEE A CAT" (4 words), "THE DOG RUNS" (3 words), "SHE HAS A BIG RED BALL" (6 words). Students tap each word (words highlight and a counter increments: 1, 2, 3...). Then select the total from options. Key learning: spaces separate words—"I SEE" is 2 words, not 4 letters. **Why it matters:** Computers count words by finding spaces! _Implementation note: Tap-counting with 3 sentences; counter display; MCQ for total. Audio counts along. Auto-graded by final count selection. CSTA: K-2-DA-08._

Dependencies:
* T28.GK.03: Match words to pictures to show text has meaning





ID: T28.G1.03
Topic: T28 – Text Data & NLP Foundations
Skill: Sort word cards into meaning categories
Description: **Student task:** Drag word cards into category bins, then explain one grouping choice. **Visual scenario:** Word cards: DOG, RED, RUN, APPLE, CAT, BLUE, JUMP, BANANA. Four bins with picture icons: Animals (paw print), Colors (rainbow), Actions (running stick figure), Foods (plate). Students drag each word to its category bin. After sorting, audio asks "Why did DOG go in Animals?" and student selects answer: (A) because dogs are pets [correct], (B) because dogs are red. **Why it matters:** Grouping words by meaning helps computers understand language! _Implementation note: Drag-drop sorting with 8 words, 4 bins, plus 1 MCQ explanation. Auto-graded by bin contents and MCQ. CSTA: K-2-DA-08._

Dependencies:
* T28.GK.03: Match words to pictures to show text has meaning





ID: T28.G1.04
Topic: T28 – Text Data & NLP Foundations
Skill: Circle matching words across sentences
Description: **Student task:** Read sentences and tap to circle words that appear in more than one sentence. **Visual scenario:** Three sentences displayed: "THE CAT IS HAPPY." "THE DOG IS BIG." "MY CAT IS FAST." Student taps words appearing multiple times. Correct circles: THE (appears in sentences 1 & 2), CAT (appears in sentences 1 & 3), IS (appears in all 3). Matching words highlight in the same color when circled. Counter shows "Found 3 of 3 matching words!" **Why it matters:** Finding repeated words is how computers search for things in text! _Implementation note: Tap-to-circle with 3 sentences; color coding for matches. Auto-graded by identifying all repeated words. CSTA: K-2-DA-08._

Dependencies:
* T28.G1.02: Count words in a sentence by tapping each word




ID: T28.G1.05
Topic: T28 – Text Data & NLP Foundations
Skill: Predict the next word in a pattern
Description: **Student task:** Read a word pattern and select what comes next. **Visual scenario:** Pattern 1: "RED, BLUE, RED, BLUE, RED, ___" with options: BLUE [correct], GREEN, RED. Pattern 2: "I have a CAT. I have a DOG. I have a ___" with options: FISH [correct], CAT, HAVE. Pattern 3: "BIG, BIGGER, ___" with options: BIGGEST [correct], SMALL, BIG. Words in pattern are color-coded to show repeating structure. **Why it matters:** AI helpers predict the next word you might type—that's autocomplete! _Implementation note: 3 pattern-completion MCQs with visual pattern highlighting. Auto-graded by correct selections. CSTA: K-2-DA-09._

Dependencies:
* T28.G1.04: Circle matching words across sentences







ID: T28.G2.01
Topic: T28 – Text Data & NLP Foundations
Skill: Identify rhyming and repeating word patterns
Description: **Student task:** Read poems and tap words that rhyme or repeat, then label the pattern type. **Visual scenario:** Poem 1: "The CAT sat on a HAT, the RAT ran to the MAT." Tap rhyming words (CAT-HAT-RAT-MAT highlight same color). Poem 2: "I LIKE bikes. I LIKE kites. I LIKE to fly." Tap repeated phrase (I LIKE highlights). Label each: "rhyming" or "repeating." **Pattern recognition key:** Rhyming = same ending sounds, Repeating = exact same words. Counter shows "Found 4 rhymes!" or "Found 3 repeats!" **Why it matters:** Patterns help computers analyze poetry and songs! _Implementation note: Tap-to-highlight in 2 poems plus pattern labeling MCQ. Auto-graded by correct highlights and labels. CSTA: K-2-DA-09._

Dependencies:
* T28.G1.04: Circle matching words across sentences





ID: T28.G2.02
Topic: T28 – Text Data & NLP Foundations
Skill: Arrange sentences from shortest to longest by word count
Description: **Student task:** Count words in each sentence strip, then drag to arrange from shortest to longest. **Visual scenario:** Four sentence strips: "RUN" (1 word), "I LIKE DOGS" (3 words), "SHE HAS A PET" (4 words), "THE CAT" (2 words). Students tap each strip to see word count, then drag strips into order: 1st slot (shortest) → 4th slot (longest). **Correct order:** RUN (1) → THE CAT (2) → I LIKE DOGS (3) → SHE HAS A PET (4). Visual shows length bars growing taller. **Why it matters:** Measuring text length helps computers organize and compare text! _Implementation note: Tap-to-count then drag-to-order with 4 strips. Auto-graded by final ordering. CSTA: K-2-DA-08._

Dependencies:
* T28.G1.02: Count words in a sentence by tapping each word





ID: T28.G2.03
Topic: T28 – Text Data & NLP Foundations
Skill: Sort text cards into sentences vs word lists
Description: **Student task:** Drag text cards into "Sentence" bin or "Word List" bin. **Visual scenario:** Text cards: "The dog runs fast." [sentence], "cat ball red" [word list], "I like pizza!" [sentence], "jump run walk hop" [word list], "Where is my hat?" [sentence], "apple banana grape" [word list]. Two bins with icons: Sentence (complete thought bubble), Word List (scattered words). **Rules shown:** Sentence = starts with capital, ends with . or ? or !, makes sense. Word List = just words, no ending, not a complete thought. **Why it matters:** Computers need to know if text is a sentence to understand it! _Implementation note: Drag-drop sorting with 6 cards and 2 bins. Auto-graded by bin contents. CSTA: K-2-DA-08._

Dependencies:
* T28.G1.02: Count words in a sentence by tapping each word





ID: T28.G2.04
Topic: T28 – Text Data & NLP Foundations
Skill: Follow find-and-replace instructions to change words
Description: **Student task:** Read a sentence and replacement rule, then tap to swap the old word for the new word. **Visual scenario:** Rule card shows: "Find: CAT → Replace: DOG." Sentence: "THE CAT IS BIG. THE CAT IS SOFT." Student taps each CAT (it highlights), then taps the replace button. CAT transforms to DOG with animation. Final: "THE DOG IS BIG. THE DOG IS SOFT." Three rounds with different rules: (1) CAT→DOG, (2) RED→BLUE, (3) HAPPY→SAD. **Why it matters:** Find-and-replace is a super power—computers can change thousands of words instantly! _Implementation note: Interactive find-replace with 3 sentence transformations. Auto-graded by correct final sentences. CSTA: K-2-AP-13._

Dependencies:
* T28.G2.03: Sort text cards into sentences vs word lists
* T28.G1.04: Circle matching words across sentences




ID: T28.G2.05
Topic: T28 – Text Data & NLP Foundations
Skill: Execute text commands in the correct sequence
Description: **Student task:** Read command cards and drag them to a character to execute in order. **Visual scenario:** Character sprite on screen. Command cards: "JUMP" "TURN" "WAVE" "SIT." Task: "Make the character JUMP, then TURN, then WAVE." Student drags command cards to the "Run" zone in correct order. Character animates each command as it executes. If wrong order (e.g., TURN first), character does wrong action and prompt says "Oops! Read the instructions again." **Why it matters:** Computers follow text instructions exactly in order—just like you're doing! _Implementation note: Drag-to-sequence then watch animation execute. 3 different command sequences. Auto-graded by correct sequence. CSTA: K-2-AP-12._

Dependencies:
* T28.G2.03: Sort text cards into sentences vs word lists







ID: T28.G3.01
Topic: T28 – Text Data & NLP Foundations
Skill: Classify data types: text vs numbers vs images
Description: Students examine data examples and classify each as text, number, or image data type. They sort cards showing: "Hello World" (text), 42 (number), a photo (image), "3.14" (text—because it has quotes!), emoji 😀 (image), -17 (number). Key insight: the same characters can be different types—"42" in quotes is text (can't do math), 42 without quotes is a number. Students predict what happens when you try to add "5" + "3" (answer: "53" concatenation, not 8). This establishes that computers treat data differently based on type.
CSTA: 1B-DA-06

Dependencies:
* T28.G2.04: Follow find-and-replace instructions to change words





ID: T28.G3.02
Topic: T28 – Text Data & NLP Foundations
Skill: Build a word counter using variables and loops
Description: Students build a script that counts how many times a target word (e.g., "the") appears in a short paragraph. They use a counter variable initialized to 0, loop through each word in a word list, and increment the counter when a match is found. They display the final count using a variable monitor. Example: given "the cat sat on the mat," count "the" → result: 2. Students trace through the loop to predict the count before running.
CSTA: 1B-AP-10

Dependencies:
* T28.G3.01: Classify data types: text vs numbers vs images
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T28.G3.03
Topic: T28 – Text Data & NLP Foundations
Skill: Build an automated word categorizer with conditionals
Description: Students create a word categorizer that automatically sorts words into categories (emotions: happy, sad, angry; actions: run, jump, walk; places: school, park, home). Using if-then-else blocks, they check if a word is in a category list and add it to the appropriate output list. They trace through their logic to predict where "excited" would be categorized (emotion), then test. Students explain why their rules work and identify edge cases (what if a word fits two categories?).
CSTA: 1B-AP-10

Dependencies:
* T28.G3.02: Build a word counter using variables and loops





ID: T28.G3.04
Topic: T28 – Text Data & NLP Foundations
Skill: Compare messy vs clean prompts for AI helpers
Description: Students compare two prompts asking the same question: Prompt A (messy): "wat iz teh captial of farnce???" Prompt B (clean): "What is the capital of France?" They predict which prompt will get a better AI response, then test both using ChatGPT. They observe that clean text produces clearer, more accurate responses. Students then practice cleaning up 3 messy prompts by fixing spelling, capitalization, and punctuation. This builds habits for effective AI communication.
CSTA: 1B-IC-18

Dependencies:
* T28.G3.03: Build an automated word categorizer with conditionals





ID: T28.G3.05
Topic: T28 – Text Data & NLP Foundations
Skill: Test text equality using the = operator
Description: Students use the equals operator to check if two text strings match exactly. They predict then verify: Does "cat" = "cat"? (yes) Does "Cat" = "cat"? (no—case matters!) Does "cat " = "cat"? (no—trailing space!) Students build a simple password checker: set password to "secret123", ask user to type password, use = to check if input matches. They trace through cases where comparison fails and identify why (case, spaces, typos).
CSTA: 1B-AP-10

Dependencies:
* T28.G3.02: Build a word counter using variables and loops




ID: T28.G3.06
Topic: T28 – Text Data & NLP Foundations
Skill: Debug text comparison failures
Description: Students are given buggy code where text comparisons fail unexpectedly. Bug 1: Password "Secret" doesn't match user input "secret" (fix: case sensitivity). Bug 2: Keyword "hello" doesn't match " hello" from user input (fix: extra space). Bug 3: Command "stop!" doesn't match "stop" (fix: punctuation). Students trace through each comparison, identify the mismatch character-by-character, and propose fixes. They learn debugging strategies: log both strings, check length, compare character-by-character.
CSTA: 1B-AP-15

Dependencies:
* T28.G3.05: Test text equality using the = operator







ID: T28.G4.00
Topic: T28 – Text Data & NLP Foundations
Skill: Build an interactive text input/output program with ask and answer
Description: Students use the 'ask [question] and wait' block to prompt users for text input, access the response via the 'answer' variable, store it in a named variable, and display it using 'say' blocks. They build a greeting program: ask "What's your name?", store answer in 'userName', then say "Hello, [userName]!". Students trace the data flow: user types → answer holds input → variable stores it → say displays it. They extend to ask 2-3 questions and combine answers in output.
CSTA: 1B-AP-12

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T09.G3.01.01: Create a new variable with a descriptive name
* T28.G3.04: Compare messy vs clean prompts for AI helpers





ID: T28.G4.01.01
Topic: T28 – Text Data & NLP Foundations
Skill: Split text into a list of words using the split block
Description: Students use the "set [list] to split of [text] with splitter [separator]" block to break a sentence into individual words. Example: "Hello World" split by " " → list with ["Hello", "World"]. They trace through: input text → split operation → resulting list. Students access individual words using "item # of [list]" and predict what item 1 and item 2 will be. They experiment with different separators (comma, dash) and predict results before running.
CSTA: 2-AP-11

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T10.G3.03: Get the length of a list
* T28.G4.00: Build an interactive text input/output program with ask and answer





ID: T28.G4.01.02
Topic: T28 – Text Data & NLP Foundations
Skill: Combine list items into text using the join block
Description: Students use the "join [list] into text with [separator]" block to combine list items back into a single text string. Example: ["red", "blue", "green"] joined with ", " → "red, blue, green". They predict the output for different separators: space (" ") makes a sentence, newline makes a vertical list, dash ("-") makes hyphenated text. Students build a program that takes words from user, adds to list, then joins to create a sentence.
CSTA: 2-AP-11

Dependencies:
* T28.G4.01.01: Split text into a list of words using the split block





ID: T28.G4.01.03
Topic: T28 – Text Data & NLP Foundations
Skill: Extract a specific part from text using the part-of block
Description: Students use the "part [index] of [text] by [separator]" block to extract a specific segment directly without creating a full list. Example: part 2 of "apple,banana,cherry" by "," → "banana". They compare: split creates list first (good for multiple accesses), part-of gets one item directly (good for single access). Students predict outputs: part 1 of "John Smith" by " " → ? (John). They use this to extract first name, last name, or domain from email addresses.
CSTA: 2-AP-11

Dependencies:
* T28.G4.01.01: Split text into a list of words using the split block





ID: T28.G4.02
Topic: T28 – Text Data & NLP Foundations
Skill: Access individual characters by position using "letter # of"
Description: Students use Scratch's "letter # of [text]" operator to access specific characters by index (starting at 1). They predict: letter 1 of "Hello" → ? (H), letter 5 of "Hello" → ? (o). Students build a program that extracts: first letter (index 1), last letter (using length of text), middle letter (length / 2). They trace through "SCRATCH" to identify what letter 4 returns (A). This prepares for character-level text processing.
CSTA: 2-AP-11

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T28.G4.00: Build an interactive text input/output program with ask and answer





ID: T28.G4.03.01
Topic: T28 – Text Data & NLP Foundations
Skill: Count characters in text using "length of" operator
Description: Students use Scratch's "length of [text]" operator to count characters. They predict then verify: length of "Hello" → 5, length of "Hi there" → 8 (space counts!), length of "" → 0. Students build a character counter that displays "Your message has X characters." They discover that spaces and punctuation count as characters. They predict: length of "A B" (3), length of "A  B" (4—two spaces!).
CSTA: 2-AP-11

Dependencies:
* T28.G4.00: Build an interactive text input/output program with ask and answer





ID: T28.G4.03.02
Topic: T28 – Text Data & NLP Foundations
Skill: Count words by splitting text and measuring list length
Description: Students combine split and list length to count words. Process: split "The quick brown fox" by " " → list of 4 items → length of list = 4 words. They compare character count (19) vs word count (4) and explain the difference. Students predict word counts before running: "Hello World" (2), "I am here" (3), "One" (1). They build a word counter tool and discuss edge cases: what about double spaces? (would create empty items).
CSTA: 2-AP-11

Dependencies:
* T10.G3.03: Get the length of a list
* T28.G4.01.01: Split text into a list of words using the split block
* T28.G4.03.01: Count characters in text using "length of" operator





ID: T28.G4.04.01
Topic: T28 – Text Data & NLP Foundations
Skill: Convert text case using lowercase/uppercase operators
Description: Use the "[uppercase/lowercase] of text [text]" block to convert text to all lowercase or all uppercase. Build a case-insensitive password checker that accepts "SECRET", "Secret", and "secret" as valid. Predict what lowercase of "HeLLo WoRLD" returns before running ("hello world"). Trace through why case normalization matters: without it, searching for "cat" won't find "CAT" or "Cat". Create a program that normalizes user input before comparison.

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T09.G3.05: Trace code with variables to predict outcomes
* T28.G4.00: Build an interactive text input/output program with ask and answer





ID: T28.G4.04.02
Topic: T28 – Text Data & NLP Foundations
Skill: Test if text includes a substring using the includes block
Description: Use the "[text] includes [pattern] ignore case [yes/no]" block to check if a word or phrase exists within text. Build a keyword detector that responds when specific words are found in user input. Examples: "Hello World" includes "World" → true, "HELLO" includes "hello" with ignore case=yes → true. Predict outcomes before testing: Does "The cat sat" include "cat"? (yes) Does it include "dog"? (no). Build a chatbot trigger system that detects keywords like "help", "price", "hours" and responds with appropriate information. Trace through case sensitivity: without ignore case, "STOP" includes "stop" → false; with ignore case → true.
CSTA: 2-AP-11

Dependencies:
* T08.G3.04: Use a simple if in a script
* T28.G3.05: Test text equality using the = operator
* T28.G4.04.01: Convert text case using lowercase/uppercase operators





ID: T28.G4.04.03
Topic: T28 – Text Data & NLP Foundations
Skill: Test if text starts with or ends with a pattern
Description: Use the "[text] starts with [pattern]" and "[text] ends with [pattern]" blocks to check text boundaries. Validate file extensions (ends with ".txt"), check command prefixes (starts with "/"), or detect URL types (starts with "https://"). Examples: "hello.txt" ends with ".txt" → true, "/move forward" starts with "/" → true. Build a file type validator that categorizes files: ends with ".txt" → text file, ends with ".jpg" → image file, ends with ".mp3" → audio file. Create a command router that detects slash commands vs regular chat. Trace through: "report.pdf" ends with ".txt" → false, ends with ".pdf" → true.
CSTA: 2-AP-11

Dependencies:
* T08.G3.04: Use a simple if in a script
* T28.G4.04.02: Test if text includes a substring using the includes block





ID: T28.G4.05.01
Topic: T28 – Text Data & NLP Foundations
Skill: Analyze human vs AI summaries side-by-side
Description: Students read a short paragraph (5-6 sentences about a topic like "Why dogs make good pets"). They write their own 1-2 sentence summary, then view an AI-generated summary. Using a comparison table, they annotate: What did AI include that I missed? What did I include that AI missed? What's different about the wording? Students conclude that AI summaries are tools that complement human thinking, not replace it.
CSTA: 2-IC-20

Dependencies:
* T28.G3.04: Compare messy vs clean prompts for AI helpers





ID: T28.G4.05.02
Topic: T28 – Text Data & NLP Foundations
Skill: Send a ChatGPT request and store the response in a variable
Description: Students use the "OpenAI ChatGPT: request [prompt] result [variable]" block to send a simple question to ChatGPT. They trace the flow: prompt text → ChatGPT processes → response stored in variable → display with say block. Students ask "What is the capital of France?" and observe the response. They try 3 different questions and discuss: How long did it take? What format was the response? They verify the response is stored correctly by displaying the variable.
CSTA: 2-AP-16

Dependencies:
* T28.G4.05.01: Analyze human vs AI summaries side-by-side
* T08.G3.04: Use a simple if in a script
* T09.G3.05: Trace code with variables to predict outcomes





ID: T28.G4.05.03
Topic: T28 – Text Data & NLP Foundations
Skill: Craft prompts for ChatGPT to summarize text
Description: Students learn prompt engineering basics for summarization. They test prompts: (1) "Summarize this: [text]" (basic), (2) "Summarize this in 2 sentences: [text]" (length control), (3) "Summarize this for a 5th grader: [text]" (audience control). They compare outputs from each prompt style and identify which produces the best result for their needs. Students document: which prompt gave the shortest summary? Which was easiest to understand?
CSTA: 2-AP-16

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable





ID: T28.G4.05.04
Topic: T28 – Text Data & NLP Foundations
Skill: Configure ChatGPT temperature and length parameters
Description: Configure ChatGPT parameters to control response behavior: (1) Temperature: set temp=0 and ask "Write a story about a cat" twice—observe identical results! Set temp=1 and ask twice—observe different results! Explain: low temp = predictable/focused (good for facts), high temp = creative/random (good for stories). (2) Length: set max length to 50 vs 200 and compare response detail. Predict before testing: which temperature for a math answer? (0) Which for creative writing? (1). Build a configuration guide table showing [Task Type, Recommended Temperature, Recommended Length].
CSTA: 2-IC-20

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable





ID: T28.G4.06.01
Topic: T28 – Text Data & NLP Foundations
Skill: Substitute text using the replace block
Description: Students use the "replace [old] with [new] in [text]" block to transform text. Examples: replace "cat" with "dog" in "The cat sat" → "The dog sat". They predict outputs before running: replace "a" with "o" in "banana" → ? (bonono—replaces ALL occurrences!). Students build a name customizer that replaces "[NAME]" in a template with user input. They discover replace is case-sensitive: replacing "Cat" won't change "cat".
CSTA: 2-AP-11

Dependencies:
* T28.G4.00: Build an interactive text input/output program with ask and answer





ID: T28.G4.06.02
Topic: T28 – Text Data & NLP Foundations
Skill: Remove punctuation by replacing with empty text
Description: Students remove punctuation using replace with empty string: replace "." with "" in "Hello. World." → "Hello World". They chain replacements: first remove ".", then ",", then "!", then "?". Students clean the text "Hi! How are you?" by removing all punctuation. They explain why this is useful for text analysis: "Hello!" and "Hello" should be treated as the same word. They trace through a 3-step cleanup process.
CSTA: 2-AP-11

Dependencies:
* T28.G4.04.01: Convert text case using lowercase/uppercase operators
* T28.G4.06.01: Substitute text using the replace block





ID: T28.G4.07.01
Topic: T28 – Text Data & NLP Foundations
Skill: Find text position using "position of" block
Description: Students use the "position of [pattern] in [text]" block to find where a word or character first appears in text. They understand that position 1 is the first character, and 0 means "not found."

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T28.G4.02: Access individual characters by position using "letter # of"





ID: T28.G4.07.02
Topic: T28 – Text Data & NLP Foundations
Skill: Extract substrings using "substring" block
Description: Students use the "substring of [text] from position [start] to position [end]" block to extract a portion of text between two positions. They extract first 3 characters, last 5 characters, or middle portions.

Dependencies:
* T28.G4.07.01: Find text position using "position of" block





ID: T28.G4.08.01
Topic: T28 – Text Data & NLP Foundations
Skill: Check if text is a number
Description: Students use the "[text] is a number?" boolean block to validate whether text input contains a valid number. They handle cases where users enter non-numeric text when numbers are expected.

Dependencies:
* T08.G3.04: Use a simple if in a script
* T28.G4.00: Build an interactive text input/output program with ask and answer




ID: T28.G4.08.02
Topic: T28 – Text Data & NLP Foundations
Skill: Convert text to number
Description: Students use the "convert [text] to number" block to transform text input into numeric values for calculations. They handle conversion errors when text cannot be converted to numbers.

Dependencies:
* T28.G4.08.01: Check if text is a number




ID: T28.G4.10
Topic: T28 – Text Data & NLP Foundations
Skill: Create text data tables with paired columns (word/count)
Description: Create two-column tables to organize text data (e.g., 'word' and 'count' columns). Predict when tables work better than lists: paired data like word-frequency needs tables, simple sequences use lists. Build a vocabulary table storing words and their definitions. Trace through adding entries: insert new row, set word column, set count column. Students compare storing "cat:3, dog:2" as two lists vs one table and explain why the table keeps data paired correctly.

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T11.G4.01: Define and call a simple custom block (no parameters)
* T28.G4.01.01: Split text into a list of words using the split block





ID: T28.G4.11
Topic: T28 – Text Data & NLP Foundations
Skill: Classify emotional tone in sample texts as positive/negative/neutral
Description: Classify sample texts as positive, negative, or neutral by identifying sentiment-carrying words. Analyze: "I love this amazing day!" contains "love" and "amazing" → positive; "This is terrible and frustrating" contains "terrible" and "frustrating" → negative; "The sky is blue" has no sentiment words → neutral. Build a classification table with columns [text, sentiment_words_found, classification]. Predict the tone of 5 sample texts before revealing answers. Discuss edge cases: "not bad" uses negative word but means positive (context matters).

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T28.G3.03: Build automated word categorizer using conditionals and lists







ID: T28.G5.01
Topic: T28 – Text Data & NLP Foundations
Skill: Design table schemas for text data (chat logs)
Description: Students design table schemas for storing chat logs or messages, defining columns for timestamp, speaker, message text, and metadata. They sketch the structure before implementation.

Dependencies:
* T28.G4.10: Store text data in simple tables (2 columns max)
* T10.G3.05: Loop through each item in a list





ID: T28.G5.02
Topic: T28 – Text Data & NLP Foundations
Skill: Populate data tables from text using split
Description: Students implement their table schemas, using split operations to parse text data into table rows and columns. They populate tables with actual chat or message data.

Dependencies:
* T28.G5.01: Design table schemas for text data (chat logs)
* T11.G5.01: Create and populate a table
* T08.G4.07: Write scripts combining sequencing, loops, and conditionals
* T10.G3.05: Loop through each item in a list





ID: T28.G5.03.01
Topic: T28 – Text Data & NLP Foundations
Skill: Identify stop-words in word frequency results
Description: Students analyze word frequency results and identify common words (the, a, is) that dominate. They label these as 'stop-words' and explain when to remove them vs keep them for text analysis.

Dependencies:
* T28.G5.08.01: Build word frequency table





ID: T28.G5.03.02
Topic: T28 – Text Data & NLP Foundations
Skill: Build stop-word filter using tables
Description: Create a stop-word table containing common words ("the", "a", "is", "and", "to", "of"). Build a filter that loops through a word list, checks each word against the stop-word table, and removes matches. Apply the filter before running frequency counts. Compare word frequency results with and without stop-word filtering—observe how "the" dominates unfiltered results but disappears after filtering, revealing meaningful content words.

Dependencies:
* T28.G5.03.01: Identify stop-words in word frequency results
* T11.G5.01: Create and populate a table
* T10.G3.05: Loop through each item in a list





ID: T28.G5.04.01
Topic: T28 – Text Data & NLP Foundations
Skill: Create positive/negative sentiment word lists
Description: Students build tables of positive words (happy, great, love) and negative words (sad, bad, hate), preparing for simple sentiment analysis.

Dependencies:
* T28.G4.11: Label emotional tone in sample texts
* T11.G5.01: Create and populate a table
* T10.G3.05: Loop through each item in a list





ID: T28.G5.04.02
Topic: T28 – Text Data & NLP Foundations
Skill: Score text using sentiment word lists
Description: Students count matches between text and positive/negative word lists, calculate a sentiment score, and note in reflection that this heuristic approach has limits (can't detect sarcasm, context).

Dependencies:
* T28.G5.04.01: Create positive/negative sentiment word lists
* T08.G4.03: Choose actions based on user input or sensor values





ID: T28.G5.05
Topic: T28 – Text Data & NLP Foundations
Skill: Build dynamic prompts with join and concatenation
Description: Students create AI prompt templates with variable slots (placeholders) using join blocks. They fill slots with different values to generate varied prompts dynamically.

Dependencies:
* T28.G5.02: Populate data tables from text using split
* T09.G4.04: Use variables to control animation or game state





ID: T28.G5.06.01
Topic: T28 – Text Data & NLP Foundations
Skill: Use the parse sentence block to analyze grammar
Description: Students use CreatiCode's "analyze sentence [text] and write into table [table]" block to identify parts of speech (nouns, verbs, adjectives) in a sentence. They examine the resulting table to see how each word is classified.

Dependencies:
* T28.G4.01.01: Split text into a list of words using the split block
* T28.G4.10: Store text data in simple tables (2 columns max)
* T10.G3.05: Loop through each item in a list





ID: T28.G5.06.02
Topic: T28 – Text Data & NLP Foundations
Skill: Extract lemmas (word stems) from parsed sentences
Description: Students examine the lemma column in parse sentence results to understand word stems (e.g., "running" → "run", "cats" → "cat"). They use lemmas to group related words for better frequency analysis.

Dependencies:
* T28.G5.06.01: Use the parse sentence block to analyze grammar





ID: T28.G5.06.03
Topic: T28 – Text Data & NLP Foundations
Skill: Filter words by part of speech
Description: Students filter parsed sentence results to extract only nouns, only verbs, or only adjectives. They build word clouds or frequency tables for specific word types.

Dependencies:
* T28.G5.06.01: Use the parse sentence block to analyze grammar
* T28.G5.08.01: Build word frequency table





ID: T28.G5.07
Topic: T28 – Text Data & NLP Foundations
Skill: Trim whitespace from text input
Description: Students use the trim block to remove leading and trailing whitespace from user input, ensuring clean data for text processing. They discuss why this matters for text comparison.

Dependencies:
* T28.G4.04.01: Convert text case using lowercase/uppercase operators





ID: T28.G5.08.01
Topic: T28 – Text Data & NLP Foundations
Skill: Build word frequency table
Description: Students split text into words, loop through each word, and count occurrences using a table with "word" and "count" columns. They create a complete frequency table for a text sample.

Dependencies:
* T28.G4.06.02: Remove punctuation using the replace block
* T28.G4.10: Store text data in simple tables (2 columns max)
* T07.G3.03: Trace code with simple loops to predict outcomes
* T08.G3.04: Use a simple if in a script
* T09.G3.05: Trace code with variables to predict outcomes
* T10.G3.03: Add and remove items from a list





ID: T28.G5.08.02
Topic: T28 – Text Data & NLP Foundations
Skill: Find and report most frequent word
Description: Students iterate through their frequency table to find the word with highest count and display it. They handle ties and discuss what the most frequent words reveal about a text.

Dependencies:
* T28.G5.08.01: Build word frequency table
* T11.G5.01: Create and populate a table





ID: T28.G5.09
Topic: T28 – Text Data & NLP Foundations
Skill: Highlight keywords in text display
Description: Build a keyword highlighter: (1) Accept a paragraph and a list of keywords from user, (2) Split paragraph into words, (3) Loop through each word checking if it matches any keyword (case-insensitive), (4) Display matching words in red and non-matching in black. Implement using either multiple say blocks with different colors or a rich text display. Test with a news article and highlight all occurrences of specific topics. Extend: highlight different keyword categories in different colors (e.g., people=blue, places=green, actions=orange).

Dependencies:
* T28.G4.04.02: Test if text includes a substring
* T07.G3.03: Trace code with simple loops to predict outcomes
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T10.G3.05: Loop through each item in a list





ID: T28.G5.10
Topic: T28 – Text Data & NLP Foundations
Skill: Demonstrate how AI models tokenize text differently than word splitting
Description: Students compare word count vs token count for various texts. They analyze: "Hello world" (2 words, ~2 tokens), "ChatGPT" (1 word, ~2 tokens—surprise!), "running" (1 word, 1 token). Students predict then verify token estimates for 5 text samples. They calculate: if ChatGPT has a 4000 token limit and average word ≈ 1.3 tokens, approximately how many words can you send? (~3000). This practical understanding helps them write prompts that fit within limits.
CSTA: 2-DA-08

Dependencies:
* T28.G4.03.02: Count words by splitting text and measuring list length





ID: T28.G5.11
Topic: T28 – Text Data & NLP Foundations
Skill: Build a content safety checker using the moderation block
Description: Students use the "get moderation result for [text]" block to check if text contains inappropriate content. They build a content filter that: (1) takes user input, (2) runs moderation check, (3) if flagged, displays warning and blocks submission, (4) if safe, proceeds normally. Students test with various inputs (friendly message, rude message, borderline cases) and observe what gets flagged. They discuss why content moderation matters for responsible AI applications.
CSTA: 2-IC-23

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable
* T08.G4.03: Choose actions based on user input or sensor values






ID: T28.G5.12
Topic: T28 – Text Data & NLP Foundations
Skill: Find longest common substring
Description: Students use the "longest common substring of [text1] and [text2]" block to find the longest matching sequence between two texts. They use this to detect plagiarism, find similarities, or identify repeated phrases.

Dependencies:
* T28.G4.07.02: Extract substrings using "substring" block
* T28.G4.03.01: Count characters in text using "length of" operator





ID: T28.G6.01
Topic: T28 – Text Data & NLP Foundations
Skill: Analyze text metrics: characters, words, and estimated tokens
Description: Students build a text analyzer that displays multiple metrics for input text: character count (length of), word count (split and list length), estimated token count (words × 1.3), and unique word count. They create a dashboard showing all metrics. Given a sample text, they predict all four metrics before running. Students use this to check if their ChatGPT prompts are within token limits and identify verbose text that could be shortened.
CSTA: 2-DA-08

Dependencies:
* T08.G4.03: Choose actions based on user input or sensor values
* T10.G4.03: Add, remove, and access items from a list in a script
* T28.G4.03.02: Count words by splitting text and measuring list length
* T28.G5.03.02: Build stop-word filter using tables
* T28.G5.10: Demonstrate how AI models tokenize text differently than word splitting





ID: T28.G6.02
Topic: T28 – Text Data & NLP Foundations
Skill: Compute n-gram (bigram) frequencies
Description: Build a bigram frequency analyzer: (1) split text into word list, (2) loop through indices 1 to length-1, (3) for each position join word[i] + " " + word[i+1] to form bigram, (4) increment count in frequency table. Trace through "the quick brown fox" to predict bigrams: "the quick", "quick brown", "brown fox". Compare most frequent bigrams across different texts (news vs poetry) and explain what bigram patterns reveal about writing style.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T07.G4.01: Loop until a goal condition is met
* T09.G4.04: Use variables to control animation or game state
* T10.G4.03: Add, remove, and access items from a list in a script
* T11.G5.01: Create and populate a table
* T28.G5.03.02: Build stop-word filter using tables





ID: T28.G6.03
Topic: T28 – Text Data & NLP Foundations
Skill: Create autocomplete suggestions from bigrams
Description: Using bigram frequency data, students identify the top next words for a given prefix and display them using text display blocks, sprites, or list displays.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G4.01: Write scripts that respond to keyboard or mouse events
* T09.G4.04: Use variables to control animation or game state
* T10.G4.03: Add, remove, and access items from a list in a script
* T28.G6.02: Compute n-gram (bigram) frequencies





ID: T28.G6.03.01
Topic: T28 – Text Data & NLP Foundations
Skill: Use ChatGPT sessions for conversation context
Description: Students demonstrate how the session parameter ("new session" vs "continue session") affects ChatGPT conversations. They build a chatbot that remembers previous messages in the conversation.

Dependencies:
* T28.G4.05.04: Configure ChatGPT response length and temperature
* T28.G5.05: Build dynamic prompts with join and concatenation





ID: T28.G6.03.02
Topic: T28 – Text Data & NLP Foundations
Skill: Set system instructions for ChatGPT behavior
Description: Students use the "OpenAI ChatGPT: system request" block to set behavior instructions (e.g., "You are a helpful tutor" or "Respond in Spanish"). They customize AI personality and response style.

Dependencies:
* T28.G6.03.01: Use ChatGPT sessions for conversation context





ID: T28.G6.04
Topic: T28 – Text Data & NLP Foundations
Skill: Log AI prompts/responses with ratings and timestamps
Description: Build an AI interaction logger that automatically records: (1) timestamp using current time block, (2) the prompt sent to ChatGPT, (3) the response received, (4) a user rating (1-5 stars). Store each interaction as a row in a logging table with columns [timestamp, prompt, response, rating]. Implement a "view history" feature that displays past interactions. Analyze your log to identify which prompts produced the best-rated responses. This supports responsible AI practices and enables prompt improvement over time.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T07.G4.01: Loop until a goal condition is met
* T09.G4.04: Use variables to control animation or game state
* T10.G4.03: Add, remove, and access items from a list in a script
* T11.G5.01: Create and populate a table
* T28.G5.02: Populate data tables from text using split
* T28.G5.05: Build dynamic prompts with join and concatenation




ID: T28.G6.05.01
Topic: T28 – Text Data & NLP Foundations
Skill: Select AI model size for task requirements
Description: Compare small vs large AI models by testing both on the same prompts: (1) Send a simple factual question to GPT-3.5 and GPT-4, measure response time, (2) Send a complex reasoning task to both, compare answer quality, (3) Send a creative writing task to both, evaluate creativity. Document tradeoffs in a comparison table with columns [Model, Speed, Quality, Best For]. Apply this knowledge: choose GPT-3.5 for simple tasks (fast, cheap) and GPT-4 for complex tasks (accurate, slower). Build a "smart router" that auto-selects model based on prompt complexity.

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable
* T28.G6.03.01: Use ChatGPT sessions for conversation context




ID: T28.G6.05.02
Topic: T28 – Text Data & NLP Foundations
Skill: Attach image to chat for vision analysis
Description: Use the "attach costume [image] to chat" block to send images along with text prompts to vision-enabled AI models. Build an "image analyzer" that: (1) Captures or loads an image, (2) Attaches it to the chat, (3) Asks specific questions: "What objects are in this image?", "What color is the largest object?", "Describe the scene." Compare AI descriptions to your own observations. Create an "image quiz" where AI describes an image and players guess what it is. Extend: use vision AI to count objects or detect text in images.

Dependencies:
* T28.G6.05.01: Select AI model size for task requirements





ID: T28.G6.06.01
Topic: T28 – Text Data & NLP Foundations
Skill: Start and stop speech recognition with Azure
Description: Use the "start recognizing speech in [language]" and "end speech recognition" blocks to capture voice input. Build a voice recorder: (1) Display "Press SPACE to start recording", (2) On space key, call start speech recognition, (3) Display "Speak now...", (4) On space key again, call end speech recognition, (5) Display the recognized text. Trace the workflow: start → microphone activates → user speaks → stop → audio processed → text returned. Test with different languages. Handle the case where speech recognition fails (returns empty) with an error message.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T28.G5.07: Trim whitespace from text input





ID: T28.G6.06.02
Topic: T28 – Text Data & NLP Foundations
Skill: Retrieve recognized text from speech
Description: Use the "text from speech" reporter block to retrieve recognized text after speech recognition ends. Build a voice-controlled sprite: (1) Record speech, (2) Get text using "text from speech", (3) Store in variable, (4) Check if text contains "jump" → make sprite jump, "spin" → make sprite spin. Trace the data flow: speech → recognition → text variable → conditional check → action. Handle empty results by prompting "I didn't hear you, try again." Build a voice diary that appends each spoken entry to a list.

Dependencies:
* T28.G6.06.01: Start and stop speech recognition with Azure





ID: T28.G6.06.03
Topic: T28 – Text Data & NLP Foundations
Skill: Use OpenAI Whisper for speech recognition
Description: Use the "OpenAI: start recognizing speech" block for Whisper-based recognition. Build a comparison test: (1) Record the same phrase using both Azure and Whisper, (2) Compare accuracy for clear speech, accented speech, and background noise. Document findings in a comparison table: [Scenario, Azure Result, Whisper Result, Which Was Better]. Test with technical terms, names, and numbers to find edge cases. Build a fallback system that tries Azure first, then Whisper if Azure returns low-confidence results.

Dependencies:
* T28.G6.06.02: Retrieve recognized text from speech





ID: T28.G6.06.04
Topic: T28 – Text Data & NLP Foundations
Skill: Use continuous speech recognition for real-time transcription
Description: Use "start continuous speech recognition in [language] into list [list]" to stream recognized speech into a list in real-time. Build a live captioning system: (1) Start continuous recognition into a words list, (2) Use a forever loop to display the latest list items, (3) Format as scrolling captions that show the last 5 recognized phrases. Create a "voice-to-notes" app that displays transcribed text in real-time and allows user to save when done. Handle pauses in speech by detecting when no new items are added. Build a voice-controlled game where commands are recognized continuously.

Dependencies:
* T28.G6.06.02: Retrieve recognized text from speech





ID: T28.G6.07.01
Topic: T28 – Text Data & NLP Foundations
Skill: Convert text to speech using basic TTS block
Description: Use the "say [text] in [language] as [voice]" block to read text aloud using Azure TTS. Build a talking story reader: (1) Store story paragraphs in a list, (2) Loop through each paragraph, (3) Use TTS to read each aloud. Experiment with different languages (English, Spanish, French) and voice types (male/female). Create a multi-character dialogue where different sprites use different voices. Build a pronunciation guide that helps users learn new words by hearing them spoken.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T28.G4.01.02: Use the join block to combine list items into text





ID: T28.G6.07.02
Topic: T28 – Text Data & NLP Foundations
Skill: Customize TTS with speed, pitch, and volume
Description: Adjust TTS parameters to create expressive speech: (1) Speed: slow for emphasis, fast for excitement, (2) Pitch: high for questions or children's voices, low for serious tones, (3) Volume: loud for announcements, quiet for whispers. Build a "mood reader" that detects sentiment words in text and adjusts TTS parameters accordingly—happy text spoken faster and higher, sad text slower and lower. Create character voices: robot (monotone, medium pitch), excited child (fast, high pitch), wise elder (slow, low pitch). Test accessibility by creating audio for visually impaired users.

Dependencies:
* T28.G6.07.01: Convert text to speech using basic TTS block





ID: T28.G6.07.03
Topic: T28 – Text Data & NLP Foundations
Skill: Stop speech and manage TTS playback
Description: Use the "stop speaking" block to control TTS playback. Build a "skip" feature: user presses spacebar to stop current speech and move to next item. Implement an interruptible announcer: when new urgent message arrives, stop current speech and read the urgent message immediately. Create a "mute" button that stops all speech when clicked. Handle speech queue: if user triggers multiple TTS calls rapidly, stop previous and play only the latest. Build a tutorial system where users can skip long explanations by pressing any key.

Dependencies:
* T28.G6.07.01: Convert text to speech using basic TTS block





ID: T28.G6.08
Topic: T28 – Text Data & NLP Foundations
Skill: Compare text similarity using edit distance
Description: Use the "steps to change [text1] into [text2]" block to compute edit distance (minimum character operations to transform one text to another). Build a typo detector: (1) User types a word, (2) Compare to dictionary words, (3) Find closest match (lowest edit distance), (4) Suggest correction if distance ≤ 2. Trace through: "helo" to "hello" = 1 (insert l), "teh" to "the" = 2 (swap). Create a fuzzy search that finds "similar" items even with typos. Build a plagiarism detector that flags text pairs with low edit distance. Analyze: why does "cat" → "dog" have distance 3 but "cat" → "bat" has distance 1?

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T28.G4.03.01: Count characters in text using "length of" operator
* T28.G6.01: Compare characters, words, and token counts





ID: T28.G6.09
Topic: T28 – Text Data & NLP Foundations
Skill: Handle text length limits and truncation
Description: Build a text length validator for AI APIs: (1) Check character count before sending, (2) If over limit (e.g., 4000 tokens ≈ 3000 words), show warning, (3) Offer options: truncate to first N characters, or summarize first. Implement smart truncation that cuts at sentence boundaries, not mid-word. Build a "text shortener" that removes filler words to reduce length while preserving meaning. Create a live character counter that shows remaining space as user types. Handle edge cases: very long single words, text that's mostly spaces, unicode characters that count as multiple bytes.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G5.02: Use logical operators (and, or, not) in if blocks
* T28.G6.01: Compare characters, words, and token counts





ID: T28.G6.10
Topic: T28 – Text Data & NLP Foundations
Skill: Validate text input and handle errors
Description: Build a robust input validator that handles common text input problems: (1) Empty string check: if length = 0, prompt "Please enter some text", (2) Whitespace-only check: if trim result is empty, prompt "Please enter actual content", (3) Format validation: if expecting email, check for @ symbol, (4) Character validation: reject or escape special characters that could break processing. Implement default values for optional fields. Create helpful error messages that tell users exactly what to fix. Build a form validator that checks multiple fields and highlights all errors at once.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T08.G5.02: Use logical operators (and, or, not) in if blocks
* T28.G6.01: Compare characters, words, and token counts





ID: T28.G7.01.01
Topic: T28 – Text Data & NLP Foundations
Skill: Build keyword-based retrieval system
Description: Build a document retrieval system: (1) Create a knowledge base table with columns [id, content, keywords], (2) For each document, extract keywords by removing stop-words, (3) When user queries, extract query keywords, (4) Score each document by counting keyword matches, (5) Return top-scoring documents. Test with a FAQ system: store 10 Q&A pairs, let users ask natural language questions, return the most relevant answer. Implement ranking: sort by score, return top 3 matches. Debug: identify why irrelevant results appear (shared common words) and fix by refining keyword extraction.

Dependencies:
* T28.G5.03.02: Build stop-word filter using tables
* T28.G6.02: Compute n-gram (bigram) frequencies
* T28.G6.03: Create autocomplete suggestions from bigrams
* T11.G6.01: Sort a table by a column
* T09.G5.01: Trace code with variables to predict outcomes
* T10.G5.03: Add and remove items from a list





ID: T28.G7.01.02
Topic: T28 – Text Data & NLP Foundations
Skill: Use Pinecone semantic search blocks (advanced)
Description: Implement semantic search using Pinecone vector database: (1) Use "add table to Pinecone" to upload documents with embeddings, (2) Use "search from Pinecone" to find semantically similar documents. Compare results: keyword search for "happy" finds only docs with "happy", but semantic search also finds "joyful", "excited", "delighted". Build a concept-based FAQ: user asks "How do I feel better?" and semantic search returns docs about happiness, wellness, relaxation even if those exact words aren't in the query. Analyze: when does keyword search outperform semantic (exact term lookup) vs when semantic wins (concept matching)?

Dependencies:
* T28.G7.01.01: Build keyword-based retrieval system




ID: T28.G7.02.01
Topic: T28 – Text Data & NLP Foundations
Skill: Translate text between languages
Description: Use ChatGPT with system instructions to translate text: (1) Set system prompt: "You are a translator. Translate the following to [target language]:", (2) Send user text, (3) Display translation. Build a translation app that supports multiple language pairs (English↔Spanish, English↔French, Spanish↔French). Test accuracy with: simple sentences, idioms ("it's raining cats and dogs"), technical terms, and slang. Create a back-translation checker: translate to another language and back, compare to original to detect translation errors. Handle edge cases: mixed-language input, untranslatable proper nouns.

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable
* T28.G6.03.02: Set system instructions for ChatGPT behavior




ID: T28.G7.02.02
Topic: T28 – Text Data & NLP Foundations
Skill: Build multi-lingual chatbot
Description: Build a chatbot that automatically adapts to user language: (1) Detect user's language by asking ChatGPT "What language is this: [user input]?", (2) Set response language in system prompt: "Respond in [detected language]", (3) Maintain conversation in detected language. Alternatively, add a language selector dropdown that sets preferred language at start. Store language preference in a variable for the session. Handle language switching mid-conversation gracefully. Build a language learning assistant that responds in the target language but can explain grammar in the user's native language when asked.

Dependencies:
* T28.G7.02.01: Translate text between languages
* T28.G6.03.01: Use ChatGPT sessions for conversation context





ID: T28.G7.03
Topic: T28 – Text Data & NLP Foundations
Skill: Audit text datasets for bias and coverage
Description: Examine text datasets for bias and representation issues: (1) Count word frequencies for demographic terms (gender, age, nationality), (2) Analyze sentiment distribution across different topics, (3) Identify potentially harmful or stereotyping language patterns. Build a bias audit report: document which perspectives are overrepresented (e.g., 80% male pronouns), which are missing (e.g., no disability representation), and propose mitigations (e.g., add diverse examples, balance training data). Create a "bias score" that quantifies imbalance. Test your own chatbot training data for bias before deploying. This skill builds responsible AI data practices essential for ethical development.

Dependencies:
* T28.G5.04.02: Score text using sentiment word lists
* T28.G6.01: Compare characters, words, and token counts
* T28.G6.04: Log AI prompts/responses with ratings and timestamps





ID: T28.G7.04
Topic: T28 – Text Data & NLP Foundations
Skill: Critically annotate AI vs human summaries
Description: Conduct a structured comparison of human vs AI summarization: (1) Read a 3-paragraph article, (2) Write your own 2-sentence summary without AI help, (3) Generate an AI summary using ChatGPT, (4) Create an annotation table comparing both summaries across criteria: key facts included, accuracy, conciseness, readability. Identify: what AI missed (important details), what AI added (hallucinations), what AI distorted (incorrect interpretations). Calculate overlap percentage between summaries. Repeat with 5 different text types (news, story, scientific, opinion, instructions) to discover where AI summarization excels vs struggles.

Dependencies:
* T28.G5.05: Build dynamic prompts with join and concatenation
* T28.G6.03.01: Use ChatGPT sessions for conversation context
* T28.G6.04: Log AI prompts/responses with ratings and timestamps





ID: T28.G7.05.01
Topic: T28 – Text Data & NLP Foundations
Skill: Use the web search block to retrieve search results
Description: Use the "web search [query] store top [k] in table [table]" block to programmatically search the web. Build a search interface: (1) Ask user for search query, (2) Execute web search storing top 5 results, (3) Display results in a formatted list showing title and snippet. Explore the result table structure: title column, URL column, snippet column. Build a "research helper" that searches for a topic and displays key findings. Handle empty results by prompting user to try different keywords. Create a comparison tool that searches two topics and displays side-by-side results.

Dependencies:
* T28.G5.02: Populate data tables from text using split
* T11.G6.01: Sort a table by a column





ID: T28.G7.05.02
Topic: T28 – Text Data & NLP Foundations
Skill: Extract and process text from web search results
Description: Process web search results programmatically: (1) Loop through result table rows, (2) Extract snippet text from each row, (3) Apply text processing: remove HTML artifacts, extract keywords, analyze sentiment. Build a "trend analyzer" that searches a topic, extracts snippets, and identifies most common keywords across results. Create a "sentiment tracker" that searches news about a company and reports whether coverage is positive/negative. Implement result filtering: only show results whose snippets contain specific keywords. Build a citation helper that formats search results into bibliography entries.

Dependencies:
* T28.G7.05.01: Use the web search block to retrieve search results
* T28.G6.04: Log AI prompts/responses with ratings and timestamps






ID: T28.G7.06
Topic: T28 – Text Data & NLP Foundations
Skill: Display text with rich text widget
Description: Use rich text box widgets to create polished text displays: (1) Set font, size, and color for different text types (headers=large+bold, body=medium, captions=small+italic), (2) Apply semantic styling (questions=blue, answers=black, warnings=red), (3) Create dynamic content that updates based on variables. Build a chatbot UI where user messages appear right-aligned in blue and AI responses appear left-aligned in gray. Create an interactive story with formatted dialogue, narration, and sound effects text. Design a quiz interface with questions, answer choices, and feedback styled distinctly. Implement markdown-like formatting: *bold*, _italic_, headers.

Dependencies:
* T28.G5.09: Highlight keywords in text display
* T28.G6.03.01: Use ChatGPT sessions for conversation context




ID: T28.G7.07
Topic: T28 – Text Data & NLP Foundations
Skill: Build a simple RAG (Retrieval-Augmented Generation) system
Description: Implement a basic RAG pipeline that grounds AI responses in retrieved knowledge: (1) Create a knowledge base table with 10+ FAQ entries, (2) Accept user question, (3) Search knowledge base for top 3 relevant entries using keyword matching, (4) Construct prompt: "Using this context: [retrieved snippets]. Answer: [user question]", (5) Send to ChatGPT and display response. Compare accuracy: ask the same question with and without RAG. Test with questions whose answers are in the knowledge base (RAG should help) vs general knowledge questions (RAG won't help). Debug retrieval failures: if wrong answers appear, check if relevant snippets were retrieved. Extend: add "I don't know" fallback when no relevant snippets found.
CSTA: 3A-AP-17

Dependencies:
* T28.G7.01.01: Build keyword-based retrieval system
* T28.G7.05.02: Extract and process text from web search results





ID: T28.G8.01
Topic: T28 – Text Data & NLP Foundations
Skill: Design text pipeline architecture with modular stages
Description: Design a text processing pipeline with 5+ clearly defined stages: (1) Input: accept and validate text, (2) Clean: normalize whitespace and case, (3) Tokenize: split into words, (4) Filter: remove stop-words, (5) Analyze: compute metrics, (6) Output: display or store results. Create a flowchart showing data flow between stages with input/output contracts for each. Predict how text "  Hello, WORLD!  " transforms through each stage: input → "  Hello, WORLD!  " → clean → "hello world" → tokenize → ["hello", "world"] → filter → ["hello", "world"] → analyze → {hello:1, world:1}. Pipeline thinking is essential for scalable AI-era text processing.
CSTA: 3A-AP-17

Dependencies:
* T28.G7.01.01: Build keyword-based retrieval system
* T28.G7.03: Audit text datasets for bias and coverage
* T07.G6.01: Define custom blocks with inputs
* T06.G6.01: Trace event execution paths in a multi‑event program




ID: T28.G8.01.01
Topic: T28 – Text Data & NLP Foundations
Skill: Implement pipeline stages as reusable custom blocks
Description: Implement each pipeline stage as a custom block with descriptive names and clear parameters. Build: clean_text(input) → returns trimmed, lowercased text; tokenize(text, delimiter) → returns word list; filter_stopwords(wordList, stopwordTable) → returns filtered list; count_frequency(wordList) → returns frequency table. Test each block independently with sample inputs before integration. Verify: clean_text("  HELLO  ") returns "hello", tokenize("a b c", " ") returns ["a","b","c"]. Document each block's expected input format and output type.
CSTA: 3A-AP-17

Dependencies:
* T28.G8.01: Design text pipeline architecture with modular stages
* T07.G6.01: Define custom blocks with inputs
* T11.G6.01: Sort a table by a column




ID: T28.G8.01.02
Topic: T28 – Text Data & NLP Foundations
Skill: Debug pipeline failures by isolating stages
Description: Debug a broken pipeline by isolating which stage produces unexpected output. Technique: log intermediate outputs after each stage by storing in variables or displaying. When pipeline output is wrong, compare actual vs expected at each stage to find the first mismatch. Example: pipeline returns empty frequency table → check analyze stage output (empty) → check filter stage output (empty!) → filter removed all words because stop-word table was too aggressive. Fix the broken stage without affecting others. Test with edge cases: empty input, very long text, text with only stop-words.
CSTA: 3A-AP-15

Dependencies:
* T28.G8.01.01: Implement pipeline stages as reusable custom blocks
* T06.G6.01: Trace event execution paths in a multi‑event program





ID: T28.G8.02
Topic: T28 – Text Data & NLP Foundations
Skill: Build confusion matrix for classifier evaluation
Description: Build an evaluation framework for text classifiers. Create a test dataset table with columns [text, actual_label, predicted_label]. Count: true positives (predicted=actual=positive), true negatives (predicted=actual=negative), false positives (predicted positive, actual negative), false negatives (predicted negative, actual positive). Visualize as a 2×2 confusion matrix table. Trace through a spam detector with 10 test cases: 6 spam correctly identified (TP), 2 legitimate correctly identified (TN), 1 legitimate marked as spam (FP), 1 spam missed (FN). Explain what each quadrant means for real users.
CSTA: 3A-DA-11

Dependencies:
* T28.G8.06: Engineer text features for ML classifiers
* T28.G7.03: Audit text datasets for bias and coverage
* T21.G7.01: Evaluate ML model performance with test data
* T10.G6.01: Sort a table by a column




ID: T28.G8.02.01
Topic: T28 – Text Data & NLP Foundations
Skill: Compute precision, recall, and F1 scores from confusion matrix
Description: Calculate evaluation metrics from confusion matrix counts: precision = TP/(TP+FP) (of all predicted positive, how many were correct?), recall = TP/(TP+FN) (of all actual positive, how many were found?), F1 = 2×precision×recall/(precision+recall) (balanced score). Trace through spam detector example: TP=6, FP=1, FN=1 → precision = 6/7 = 0.86, recall = 6/7 = 0.86, F1 = 0.86. Compare classifiers: Classifier A (precision=0.9, recall=0.5) vs Classifier B (precision=0.6, recall=0.9)—which is better depends on use case.
CSTA: 3A-DA-11

Dependencies:
* T28.G8.02: Build confusion matrix for classifier evaluation
* T09.G6.01: Model real-world quantities using variables and formulas
* T09.G6.02: Apply operator precedence rules (PEMDAS) in expressions




ID: T28.G8.02.02
Topic: T28 – Text Data & NLP Foundations
Skill: Analyze precision vs recall tradeoffs for different applications
Description: Analyze when to optimize for precision vs recall based on application requirements. High precision priority (minimize false positives): spam filtering (don't accidentally delete important emails), content recommendation (don't recommend irrelevant items). High recall priority (minimize false negatives): fraud detection (don't miss any fraud), disease screening (don't miss any sick patients). Test a classifier with different thresholds: strict threshold → high precision, low recall; lenient threshold → low precision, high recall. Build a threshold selector that lets users adjust based on their priorities.
CSTA: 3A-IC-24

Dependencies:
* T28.G8.02.01: Compute precision, recall, and F1 scores from confusion matrix





ID: T28.G8.03
Topic: T28 – Text Data & NLP Foundations
Skill: Integrate text analytics into AI prompt engineering
Description: Embed text analytics results (top keywords, sentiment scores, entity extraction) into AI prompt templates and evaluate whether augmented prompts produce better AI responses. Build a RAG-style enhancement system: (1) Extract keywords from user query, (2) Retrieve relevant context using keyword matching, (3) Construct prompt: "Context: [keywords/entities]. Question: [user query]", (4) Send to ChatGPT and compare response quality to non-augmented prompt. Trace through an example: query "What is photosynthesis?" → extract "photosynthesis" → retrieve science context → augmented prompt produces more accurate response. Measure improvement using response relevance scoring.
CSTA: 3A-AP-17

Dependencies:
* T28.G7.01.01: Build keyword-based retrieval system
* T28.G7.03: Audit text datasets for bias and coverage
* T28.G7.07: Build a simple RAG (Retrieval-Augmented Generation) system
* T06.G6.01: Trace event execution paths in a multi‑event program
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column





ID: T28.G8.04
Topic: T28 – Text Data & NLP Foundations
Skill: Document text datasets with datasheets (source, bias, limitations)
Description: Author "datasheet" documentation for text datasets following responsible AI practices. Create a structured document covering: (1) Source: where did the data come from? (2) Collection process: how was it gathered? (3) Known limitations: what's missing or underrepresented? (4) Bias analysis: which perspectives dominate or are absent? (5) Intended uses: what is this data appropriate for? (6) Maintenance: how will it be updated? Build a datasheet template with sections for each area. Document your own chatbot training data and identify at least 3 limitations. Compare your datasheet to professional examples (like ImageNet or GPT documentation).
CSTA: 3A-IC-24

Dependencies:
* T28.G7.03: Audit text datasets for bias and coverage
* T28.G7.04: Critically annotate AI vs human summaries
* T06.G6.01: Trace event execution paths in a multi‑event program
* T09.G6.01: Model real-world quantities using variables and formulas
* T10.G6.01: Sort a table by a column
* T07.G6.01: Trace nested loops with variable bounds





ID: T28.G8.05.01
Topic: T28 – Text Data & NLP Foundations
Skill: Apply basic regex pattern syntax
Description: Students apply basic regex syntax: literal characters match themselves, "." matches any character, "*" means "zero or more", "+" means "one or more". They test simple patterns using the "regex [pattern] test [text]" block.

Dependencies:
* T28.G6.08: Compare text similarity using edit distance
* T06.G6.01: Trace event execution paths in a multi‑event program





ID: T28.G8.05.02
Topic: T28 – Text Data & NLP Foundations
Skill: Use regex test block for pattern validation
Description: Students use the "regex [pattern] test [text]" boolean block to check if text matches a pattern. They validate formats like email addresses, phone numbers, or dates using regex patterns.

Dependencies:
* T28.G8.05.01: Apply basic regex pattern syntax





ID: T28.G8.05.03
Topic: T28 – Text Data & NLP Foundations
Skill: Use regex match to extract patterns
Description: Students use the "regex [pattern] flag [g] match [text] into list [list]" block to find all occurrences of a pattern and store them in a list. They extract all numbers, all capitalized words, or all @mentions from text.

Dependencies:
* T28.G8.05.02: Use regex test block for pattern validation





ID: T28.G8.05.04
Topic: T28 – Text Data & NLP Foundations
Skill: Use regex search to find pattern positions
Description: Students use the "regex [pattern] search [text]" block to find the starting position of a pattern in text. They locate where specific patterns occur within larger documents.

Dependencies:
* T28.G8.05.02: Use regex test block for pattern validation





ID: T28.G8.05.05
Topic: T28 – Text Data & NLP Foundations
Skill: Use regex replace for advanced text transformation
Description: Students use the "regex [pattern] flag [g] replace [text] with [replacement]" block to replace all matches of a pattern. They redact phone numbers, standardize date formats, or clean up text with multiple spaces.

Dependencies:
* T28.G8.05.03: Use regex match to extract patterns





ID: T28.G8.05.06
Topic: T28 – Text Data & NLP Foundations
Skill: Use regex split for flexible tokenization
Description: Use the "regex [pattern] flag [g] split [text] into list [list]" block to split text using regex patterns as delimiters. Split on multiple delimiters: `[,;:]` splits on comma OR semicolon OR colon. Split on patterns: `\s+` splits on one or more whitespace characters (handles double spaces). Build a flexible parser that splits "name: John; age: 25, city: NYC" into meaningful parts. Compare regex split vs simple split: simple split handles one delimiter, regex handles complex patterns.
CSTA: 3A-DA-11

Dependencies:
* T28.G8.05.03: Use regex match to extract patterns



ID: T28.G8.05.07
Topic: T28 – Text Data & NLP Foundations
Skill: Build complex regex patterns with character classes and quantifiers
Description: Combine regex features to create powerful patterns for real-world validation: `[0-9]{3}-[0-9]{4}` matches phone numbers like "555-1234", `[A-Z][a-z]+` matches capitalized words, `\w+@\w+\.\w+` matches simple email format. Build a pattern library for common formats: dates (MM/DD/YYYY), URLs (http://...), usernames (alphanumeric, 3-16 chars). Test patterns with edge cases: "555-12345" should NOT match phone pattern (too many digits), "test@" should NOT match email (missing domain). Debug patterns that match too much or too little by testing incrementally.
CSTA: 3A-DA-11

Dependencies:
* T28.G8.05.06: Use regex split for flexible tokenization
* T28.G8.05.05: Use regex replace for advanced text transformation





ID: T28.G8.06
Topic: T28 – Text Data & NLP Foundations
Skill: Engineer text features for ML classifiers
Description: Design and implement a feature extraction pipeline for text classification: (1) Compute basic features: character count, word count, average word length, (2) Add content features: keyword presence (count of specific words), sentiment score, punctuation ratio, (3) Add structural features: number of sentences, capital letter ratio, digit ratio. Build a feature table where each row is a text sample and columns are features. Train a classifier to distinguish spam from legitimate messages using your features. Iterate: add or remove features to improve accuracy. Document which features had the most predictive power.

Dependencies:
* T28.G5.04.02: Score text using sentiment word lists
* T28.G6.01: Compare characters, words, and token counts
* T28.G6.04: Log AI prompts/responses with ratings and timestamps
* T21.G6.01: Train a simple ML model (supervised learning)
* T10.G6.01: Sort a table by a column




ID: T28.G8.07
Topic: T28 – Text Data & NLP Foundations
Skill: Extract structured output from LLM
Description: Design prompts that instruct ChatGPT to return structured data: (1) Request JSON format with specific keys: "Extract the following as JSON: {name: string, age: number, interests: array}", (2) Request CSV format for tabular data: "List 5 countries with columns: name, capital, population", (3) Request numbered lists with consistent formatting. Parse the structured response using split operations to populate tables or lists. Build a "data extractor" that takes unstructured text (e.g., a paragraph about a person) and outputs a structured profile table. Handle cases where AI returns malformed output by validating structure before parsing.

Dependencies:
* T28.G7.07: Build a simple RAG (Retrieval-Augmented Generation) system
* T28.G6.03.02: Set system instructions for ChatGPT behavior
* T28.G5.02: Populate data tables from text using split




ID: T28.G7.08
Topic: T28 – Text Data & NLP Foundations
Skill: Build multi-step AI agent pipeline
Description: Design and implement an AI agent that orchestrates multiple ChatGPT calls in sequence: (1) First call analyzes user intent from input, (2) Second call retrieves relevant context based on intent, (3) Third call generates response using context. Build a "research assistant" that: asks user for a topic → calls AI to generate 3 search queries → calls AI to synthesize findings into a summary. Trace the data flow between steps using variables. Handle failures at any step with appropriate fallbacks. Compare single-call vs multi-step approaches for complex tasks.
CSTA: 3A-AP-17

Dependencies:
* T28.G6.03.01: Use ChatGPT sessions for conversation context
* T28.G6.03.02: Set system instructions for ChatGPT behavior
* T28.G5.05: Build dynamic prompts with join and concatenation




ID: T28.G7.09
Topic: T28 – Text Data & NLP Foundations
Skill: Design prompt templates with few-shot examples
Description: Create reusable prompt templates that include few-shot examples to guide AI behavior: (1) Define a task with clear instructions, (2) Provide 2-3 input/output examples showing desired format, (3) Add the actual query. Build a "sentiment classifier" prompt with examples: "Classify as positive/negative/neutral. Examples: 'I love this!' → positive, 'This is terrible' → negative, 'The sky is blue' → neutral. Now classify: [user input]". Compare accuracy with vs without examples. Create a library of prompt templates for different tasks (summarization, translation, extraction) and test each with 5 diverse inputs.
CSTA: 2-AP-16

Dependencies:
* T28.G4.05.03: Craft prompts for ChatGPT to summarize text
* T28.G5.05: Build dynamic prompts with join and concatenation




ID: T28.G7.10
Topic: T28 – Text Data & NLP Foundations
Skill: Design chain-of-thought prompts for complex reasoning
Description: Build prompts that guide AI through step-by-step reasoning for complex problems. Structure: "Let's solve this step by step: 1) First identify the key information, 2) Then analyze the relationships, 3) Finally draw a conclusion." Test chain-of-thought (CoT) vs direct prompts on: math word problems, logic puzzles, multi-step questions. Compare accuracy: direct prompt "What is 15% of 240?" vs CoT prompt "What is 15% of 240? Think step by step: first convert percentage to decimal, then multiply." Document when CoT improves accuracy (complex reasoning) vs when unnecessary (simple facts). Build a prompt selector that auto-adds CoT for complex queries.
CSTA: 3A-AP-17

Dependencies:
* T28.G7.09: Design prompt templates with few-shot examples
* T28.G4.05.03: Craft prompts for ChatGPT to summarize text




ID: T28.G7.11
Topic: T28 – Text Data & NLP Foundations
Skill: Analyze how semantic embeddings represent text meaning
Description: Explore how AI represents text meaning as numbers (embeddings). Concept: similar meanings → numerically close embeddings, different meanings → distant embeddings. Use Pinecone semantic search to observe: "happy", "joyful", "glad" cluster together while "sad" is distant. Compare keyword matching (exact word required) vs semantic matching (similar meaning works). Predict which texts would have similar embeddings: "The cat sat on the mat" vs "A feline rested on the rug" (similar!) vs "The dog ran in the park" (different). Build a "concept finder" that retrieves semantically related documents even without exact keyword matches.
CSTA: 2-DA-08

Dependencies:
* T28.G7.01.02: Use Pinecone semantic search blocks (advanced)
* T28.G6.02: Compute n-gram (bigram) frequencies




ID: T28.G8.08
Topic: T28 – Text Data & NLP Foundations
Skill: Implement AI function calling with structured parameters
Description: Build an AI-powered command system where ChatGPT interprets user intent and returns structured function calls: (1) Define available functions with parameter schemas (e.g., "set_timer(minutes: number, label: string)", "search(query: string, max_results: number)"), (2) Prompt AI to interpret user request and return the function name + parameters, (3) Parse AI response and execute the corresponding action. Build a "voice command processor" that converts natural language ("set a timer for 5 minutes called pizza") into structured calls. Handle ambiguous requests by asking for clarification. This skill prepares for real-world AI agent development.
CSTA: 3A-AP-17

Dependencies:
* T28.G8.07: Extract structured output from LLM
* T28.G7.08: Build multi-step AI agent pipeline




ID: T28.G8.09
Topic: T28 – Text Data & NLP Foundations
Skill: Build conversational memory system for chatbots
Description: Implement a chatbot with persistent memory across sessions: (1) Store conversation history in a table with columns [session_id, timestamp, role, message], (2) On each new message, retrieve relevant past context using keyword matching or recency, (3) Include context summary in the ChatGPT prompt. Build a "personal tutor bot" that remembers topics discussed, questions asked, and concepts the user struggled with. Implement memory pruning to stay within token limits—keep recent messages + important milestones. Compare chatbot helpfulness with vs without memory. Implement "forget me" feature that clears user history.
CSTA: 3A-AP-17

Dependencies:
* T28.G6.03.01: Use ChatGPT sessions for conversation context
* T28.G6.04: Log AI prompts/responses with ratings and timestamps
* T28.G7.01.01: Build keyword-based retrieval system




ID: T28.G8.10
Topic: T28 – Text Data & NLP Foundations
Skill: Design text preprocessing pipeline with error recovery
Description: Architect a robust text preprocessing pipeline that handles real-world messy input: (1) Input validation: check for empty strings, excessive length, binary data, (2) Normalization: trim whitespace, normalize unicode, convert case, (3) Cleaning: remove or replace invalid characters, fix common encoding issues, (4) Tokenization: split with error handling for edge cases. Implement error recovery at each stage—don't crash on bad input, instead log the error, attempt repair, or skip gracefully. Build a "file processor" that reads text files, applies the pipeline, and reports which files had issues and what was done to fix them. Test with intentionally malformed inputs.
CSTA: 3A-AP-17

Dependencies:
* T28.G6.09: Handle text length limits and truncation
* T28.G6.10: Validate text input and handle errors
* T28.G5.07: Trim whitespace from text input




ID: T28.G8.11
Topic: T28 – Text Data & NLP Foundations
Skill: Route inputs by modality type (text/voice/image)
Description: Build an input router that detects modality type and directs to appropriate processor. Detect input source: text input (ask block) → direct text processing; voice input (speech recognition active) → transcribe first, then text processing; image input (vision analysis requested) → extract description first, then text processing. Create a mode selector variable that tracks current input type. Build a "universal assistant" that accepts any input type and normalizes to text for unified processing. Test with each modality independently before combining.
CSTA: 3A-AP-18

Dependencies:
* T28.G6.06.02: Retrieve recognized text from speech
* T28.G6.05.02: Attach image to chat for vision analysis
* T28.G4.00: Build an interactive text input/output program with ask and answer




ID: T28.G8.11.01
Topic: T28 – Text Data & NLP Foundations
Skill: Combine multi-modal inputs for unified processing
Description: Process multiple input modalities simultaneously and merge for unified understanding. Build a system where user can: (1) Show an image and type a question about it, (2) Speak a question while pointing at screen elements, (3) Provide context via text and ask for voice response. Create an input merger that combines extracted text from all modalities into a single context string. Handle cases where inputs conflict (spoken "yes" but typed "no") or complement each other (image of dog + text "what breed?"). Test with real multi-modal scenarios.
CSTA: 3A-AP-18

Dependencies:
* T28.G8.11: Route inputs by modality type (text/voice/image)




ID: T28.G8.11.02
Topic: T28 – Text Data & NLP Foundations
Skill: Design adaptive output based on input modality
Description: Match output modality to user input preference for natural interaction. Voice input → voice output using TTS; text input → text output; image input → visual + text output. Build response mode selector that tracks how user prefers to receive responses. Create accessibility features: if user can't see screen, auto-select voice output; if user can't hear, auto-select text output. Test the "universal assistant" adapting its communication style: respond in same language/modality as input, adjust verbosity based on input complexity.
CSTA: 3A-AP-18

Dependencies:
* T28.G8.11.01: Combine multi-modal inputs for unified processing
* T28.G6.07.01: Convert text to speech using basic TTS block




ID: T28.G5.13
Topic: T28 – Text Data & NLP Foundations
Skill: Validate AI response quality
Description: Build a response validator that checks AI outputs before displaying to users: (1) Length check: is response too short (likely error) or too long (likely rambling)?, (2) Format check: does response match expected structure?, (3) Content check: does response contain prohibited content or off-topic material?, (4) Relevance check: does response address the original question? Implement a "response quality gate" that scores each ChatGPT response 1-5 on these criteria and flags low-quality responses for retry or human review. Test with intentionally bad prompts to see what low-quality responses look like. Build automatic retry logic for failed responses.
CSTA: 2-IC-23

Dependencies:
* T28.G4.05.02: Send a ChatGPT request and store the response in a variable
* T28.G5.11: Build a content safety checker using the moderation block
* T28.G4.03.01: Count characters in text using "length of" operator




ID: T28.G6.11
Topic: T28 – Text Data & NLP Foundations
Skill: Chain multiple text operations into a workflow
Description: Build a text transformation workflow that chains multiple operations: (1) Create a list of operations to perform in order (e.g., [lowercase, remove_punctuation, split_words, filter_stopwords]), (2) Loop through operations, applying each to the result of the previous, (3) Display intermediate results at each step. Build a "text recipe" system where users can select and reorder operations. Trace through "Hello, World!" with operations [lowercase, remove_punctuation] to predict output. Extend: save workflows as reusable presets. Debug: identify which step in a chain produces unexpected output.
CSTA: 2-AP-17

Dependencies:
* T28.G5.07: Trim whitespace from text input
* T28.G4.04.01: Convert text case using lowercase/uppercase operators
* T28.G4.06.02: Remove punctuation by replacing with empty text





# T29 - Devices & Hardware Systems (Phase 9 Major Overhaul - November 2025)
# Applied Phase 9 comprehensive restructuring with MAJOR BOLD IMPROVEMENTS:
#
# NEW CONCEPT AREAS ADDED:
# 1. POWER & SUSTAINABILITY PROGRESSION:
#    - GK.04: Sequence device setup steps with power awareness
#    - GK.05: Circle devices that need power sources
#    - G1.04: Sort devices by power type (battery vs plug-in)
#    - G2.09: Match devices to battery types
#    - G4.10: Analyze power management in CreatiCode projects
#    - G8.14: Evaluate hardware lifecycle and e-waste impacts
#    - G8.15: Design adaptive sensor sampling for power efficiency
#
# 2. SENSOR CALIBRATION PROGRESSION:
#    - G2.10: Sequence calibration steps (unplugged)
#    - G3.09: Calibrate sensor thresholds through experimentation
#    - G6.13: Design sensor calibration procedures for users
#
# 3. EARLY DEBUGGING & TROUBLESHOOTING:
#    - G1.05: Match device problems to solutions (picture-based)
#    - G3.10: Diagnose sensor issues using checklist
#    - G4.11: Implement sensor fallback when primary fails
#    - G5.20: Implement hardware capability detection
#
# 4. SENSOR FUSION INTRODUCED EARLIER:
#    - G4.12: Connect multiple input devices in single project
#    - G5.16: Combine two sensors for enhanced detection
#    - G6.11: Implement multi-device sensor fusion for AR
#    - G8.13: Design sensor fusion algorithm for gesture recognition
#
# 5. HARDWARE SECURITY & SAFETY:
#    - G6.14: Implement hardware safety warnings
#    - G7.11: Analyze hardware security vulnerabilities
#    - G8.16: Implement hardware security best practices
#
# 6. DEVICE FLEET & SYSTEM MANAGEMENT:
#    - G5.21: Design peripheral device chain/hub configuration
#    - G7.12: Design device fleet management for classroom
#    - G7.13: Implement hardware abstraction for cross-platform
#    - G8.11: Implement simplified hardware abstraction layer (HAL)
#    - G8.12: Analyze real-time OS concepts for sensor processing
#    - G8.17: Design device fleet telemetry system
#
# 7. EXPANDED K-2 WITH DIVERSE ASSESSMENTS:
#    - Added sequencing, circling, prediction activities
#    - Earlier safety and power awareness
#    - More diverse assessment types beyond matching/sorting
#
# 8. PROFESSIONAL-LEVEL SKILLS (G7-G8):
#    - Hardware abstraction layer concepts
#    - Real-time OS principles simplified
#    - Security hardening for AI sensors
#    - Fleet management and telemetry
#
# SKILL SPLITS FOR BETTER GRANULARITY:
#    - T29.G5.14 split into 3 sub-skills (access, calculate, detect patterns)
#    - T29.G7.10 split into 3 sub-skills (collect, train, deploy)
#    - T29.G8.08 split into 4 sub-skills (design, prepare, train, evaluate)
#
# Previous optimizations preserved with enhanced progressions:
# - Camera: G3.05 → G4.06.01 → G5.05 → G6.05.01 → G7.09
# - Speech: G3.06 → G4.07 → G6.05 → G6.05.02 → G6.05.03
# - Body tracking: G5.06 → G6.06 → G6.06.01 → G6.06.03
# - NEW Power: GK.05 → G1.04 → G2.09 → G4.10 → G8.14 → G8.15
# - NEW Calibration: G2.10 → G3.09 → G6.13
# - NEW Security: G7.11 → G8.16
# - NEW System: G5.21 → G7.12 → G7.13 → G8.11 → G8.17
#
# Total: ~127 skills (added 35 new skills, 4 splits into 13 sub-skills)

ID: T29.GK.01
Topic: T29 – Devices & Hardware Systems
Skill: Identify everyday computing devices using picture cards
Description: **Student task:** View picture cards showing various objects and tap all the ones that are computers. **Visual scenario:** Picture cards show: tablet, smart speaker, traffic light controller, laptop, game console, toaster, clock, toy robot. **Correct answers:** tablet, smart speaker, traffic light controller, laptop, game console. Students then match each computing device to its job using a drag-and-drop activity. _Implementation note: Multi-select tap activity with 8 picture cards; audio prompt "Which ones are computers?" Auto-graded by correct selections. CSTA: K-2-CS-01._






ID: T29.GK.02
Topic: T29 – Devices & Hardware Systems
Skill: Match device pictures to their actions
Description: **Student task:** Drag device picture cards to match their action descriptions. **Visual scenario:** Left side shows devices: camera, speaker, automatic door, tablet, microphone. Right side shows action labels: "takes pictures," "plays sound," "opens when someone walks up," "shows games," "listens to voice." **Correct matches:** camera→takes pictures, speaker→plays sound, automatic door→opens when someone walks up, tablet→shows games, microphone→listens to voice. _Implementation note: Drag-and-drop matching with 5 pairs; audio reads labels on hover. Auto-graded by correct pairings. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.01: Identify everyday computing devices using picture cards







ID: T29.GK.03
Topic: T29 – Devices & Hardware Systems
Skill: Sort input and output devices using picture cards
Description: **Student task:** Drag device picture cards into two sorting bins labeled "Sends Info IN" (input) and "Sends Info OUT" (output). **Visual scenario:** Picture cards show: microphone, light bulb, button, screen, keyboard, speaker. Two large bins with icons (arrow pointing into computer = input, arrow pointing out of computer = output). **Correct sorting:** Input bin: microphone, button, keyboard. Output bin: light bulb, screen, speaker. _Implementation note: Drag-drop sorting with 6 cards and 2 bins; visual feedback shows green check for correct placement. Auto-graded by final bin contents. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.02: Match device pictures to their actions




ID: T29.GK.04
Topic: T29 – Devices & Hardware Systems
Skill: Sequence device setup steps using picture cards
Description: **Student task:** Arrange picture cards showing the steps to set up a simple device in the correct order. **Visual scenario:** Picture cards show: (1) take tablet out of box, (2) find the charging cable, (3) plug in the cable, (4) press the power button, (5) tablet turns on and shows home screen. Students drag cards to arrange in order. Follow-up: "What happens if you skip step 3?" (Answer: tablet might not have battery power). _Implementation note: Drag-to-sequence activity with 5 cards; audio confirmation of correct order. Auto-graded by sequence accuracy. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.01: Identify everyday computing devices using picture cards




ID: T29.GK.05
Topic: T29 – Devices & Hardware Systems
Skill: Circle devices that need power sources using picture cards
Description: **Student task:** View picture cards of various objects and circle the ones that need batteries or plugs to work. **Visual scenario:** Picture cards show: tablet (needs power), teddy bear (no power), smart speaker (needs power), bouncy ball (no power), robot toy (needs power), wooden blocks (no power), laptop (needs power), book (no power). Students tap to circle devices needing power. Follow-up matching: match each powered device to its power source icon (battery or plug). _Implementation note: Tap-to-circle activity with 8 cards; audio asks "Which ones need power to work?" Auto-graded by correct selections. CSTA: K-2-CS-01._

Dependencies:
* T29.GK.01: Identify everyday computing devices using picture cards




ID: T29.GK.06
Topic: T29 – Devices & Hardware Systems
Skill: Predict device behavior from visual indicator cues
Description: **Student task:** View pictures of devices showing visual indicators and predict what each indicator means. **Visual scenario 1:** Tablet with red battery icon → predict: "battery almost empty, needs charging." **Scenario 2:** Phone with lightning bolt on screen → predict: "device is charging." **Scenario 3:** Laptop with glowing power button → predict: "laptop is turned on." **Scenario 4:** Speaker with blinking blue light → predict: "waiting to connect to another device." Students match indicators to meanings. _Implementation note: Picture-to-meaning matching with 4 scenarios; audio reads predictions aloud. Auto-graded by correct matches. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.02: Match device pictures to their actions
* T29.GK.05: Circle devices that need power sources using picture cards







ID: T29.G1.01
Topic: T29 – Devices & Hardware Systems
Skill: Label basic computer parts on a diagram
Description: **Student task:** Drag name labels onto a computer diagram to label each part, then tap each part to hear its job. **Visual scenario:** Large diagram shows laptop with numbered arrows pointing to: (1) screen, (2) keyboard, (3) touchpad, (4) power button, (5) speakers, (6) camera. Label bank: "Screen," "Keyboard," "Touchpad," "Power Button," "Speakers," "Camera." After labeling, tapping each part reveals audio: "The screen shows pictures and words," "The keyboard types letters," etc. _Implementation note: Drag-drop labeling with 6 parts; audio feedback on tap. Auto-graded by label placement. CSTA: K-2-CS-01._

Dependencies:
* T29.GK.01: Identify everyday computing devices using picture cards




ID: T29.G1.02
Topic: T29 – Devices & Hardware Systems
Skill: Sort hardware vs software using picture cards
Description: **Student task:** Drag picture cards into two sorting bins: "Hardware" (things you can touch) and "Software" (programs that run). **Visual scenario:** Picture cards show: keyboard, game app icon, robot arm, drawing program icon, mouse, video player icon, headphones, calculator app icon. Two bins with labels and icons (hand touching = hardware, screen with play button = software). **Correct sorting:** Hardware: keyboard, robot arm, mouse, headphones. Software: game app icon, drawing program icon, video player icon, calculator app icon. _Implementation note: Drag-drop sorting with 8 cards; audio explains "Hardware is something you can touch and hold." Auto-graded by bin contents. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram





ID: T29.G1.03
Topic: T29 – Devices & Hardware Systems
Skill: Identify sensors in everyday places using picture scenarios
Description: **Student task:** View picture scenarios and tap to circle the hidden sensor, then select what it detects from options. **Visual scenario 1:** Automatic door at grocery store - circle the motion sensor above the door, select "movement." **Visual scenario 2:** Touchless faucet in bathroom - circle the infrared sensor below the spout, select "hands." **Visual scenario 3:** Smart toy that responds to voice - circle the microphone inside, select "voice." _Implementation note: 3 picture scenarios with tap-to-circle and MCQ selection; audio reads scenario descriptions. Auto-graded by correct sensor identification and detection type. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram




ID: T29.G1.04
Topic: T29 – Devices & Hardware Systems
Skill: Sort devices by where they get power (battery vs plug-in)
Description: **Student task:** Drag device picture cards into two sorting bins: "Uses Batteries" (portable power) and "Plugs Into Wall" (needs outlet). **Visual scenario:** Picture cards show: game controller (batteries), smart speaker (plug-in), tablet (rechargeable battery), desktop computer (plug-in), wireless mouse (batteries), TV (plug-in), flashlight (batteries), lamp (plug-in). Students sort and then answer: "Why can you carry a tablet around but not a desktop computer?" (Answer: tablet has battery, desktop needs wall power). _Implementation note: Drag-drop sorting with 8 cards; audio explains portability concept. Auto-graded by bin contents. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.05: Circle devices that need power sources using picture cards




ID: T29.G1.05
Topic: T29 – Devices & Hardware Systems
Skill: Match device problems to solutions using picture pairs
Description: **Student task:** Match picture cards showing device problems to picture cards showing solutions. **Visual scenario:** Problem cards: (1) tablet screen is black, (2) headphones have no sound, (3) camera shows blurry picture, (4) mouse won't move cursor. Solution cards: (A) charge the battery, (B) check if plugged in, (C) clean the lens, (D) plug in USB or check batteries. **Correct matches:** 1→A, 2→B, 3→C, 4→D. Audio explains each solution: "If the tablet won't turn on, it might need charging!" _Implementation note: Drag-drop matching with 4 pairs; introduces basic troubleshooting. Auto-graded by correct pairings. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram




ID: T29.G1.06
Topic: T29 – Devices & Hardware Systems
Skill: Sequence what happens when a button is pressed
Description: **Student task:** Arrange picture cards showing what happens when you press a power button, from start to finish. **Visual scenario:** Picture cards show: (1) finger reaches for power button, (2) finger presses button down, (3) electricity flows to computer parts, (4) computer wakes up inside, (5) screen lights up with home screen. Students arrange cards in order. Follow-up question: "What step happens that you can't see?" (Answer: electricity flowing inside). _Implementation note: 5-card sequencing activity; builds cause-effect understanding. Auto-graded by sequence order. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram
* T29.GK.04: Sequence device setup steps using picture cards




ID: T29.G1.07
Topic: T29 – Devices & Hardware Systems
Skill: Circle safe vs unsafe device handling in picture scenarios
Description: **Student task:** View picture scenarios and circle the SAFE device handling (green circle) or UNSAFE handling (red X). **Visual scenario 1:** Child carrying laptop with two hands (SAFE) vs carrying by screen only (UNSAFE). **Scenario 2:** Device on stable table (SAFE) vs on edge about to fall (UNSAFE). **Scenario 3:** Clean dry hands using tablet (SAFE) vs sticky fingers on screen (UNSAFE). **Scenario 4:** Keeping drinks away (SAFE) vs drink next to computer (UNSAFE). Students mark each and hear explanation. _Implementation note: 4 paired scenarios with tap-to-mark; audio explains safety reasons. Auto-graded by correct marks. CSTA: K-2-IC-20._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram





ID: T29.G2.01
Topic: T29 – Devices & Hardware Systems
Skill: Match internal computer parts to everyday analogies using picture cards
Description: **Student task:** Drag picture cards to match computer parts to everyday analogy cards, then explain each part's job. **Visual scenario:** Left column shows computer parts: CPU chip, RAM stick, hard drive. Right column shows analogy pictures: brain thinking, sticky note (short-term memory), backpack storing books. **Correct matches:** CPU→brain ("does the thinking"), RAM→sticky note ("remembers things while working"), Hard drive→backpack ("stores things for later"). After matching, students tap each pair to hear explanation. _Implementation note: Drag-drop matching with 3 pairs; audio explains analogies. Auto-graded by correct pairings. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram
* T29.G1.02: Sort hardware vs software using picture cards
* T01.G1.01: Put pictures in order to plant a seed





ID: T29.G2.02
Topic: T29 – Devices & Hardware Systems
Skill: Trace input-process-output flow using visual diagrams
Description: **Student task:** Drag picture cards and arrows to build a flow diagram showing input→process→output. **Visual scenario:** Three labeled boxes: "INPUT" (green), "PROCESS" (yellow), "OUTPUT" (blue). Picture cards: keyboard with finger pressing "A", CPU chip with gear icon, screen showing letter "A". Arrow cards to connect them. **Correct sequence:** Keyboard (input) → Arrow → CPU (process) → Arrow → Screen (output). Students drag cards into boxes and connect with arrows. _Implementation note: Drag-drop sequencing with 3 stages and 2 arrows; visual highlight confirms correct flow. Auto-graded by sequence order. CSTA: K-2-CS-02._

Dependencies:
* T29.GK.03: Sort input and output devices using picture cards
* T29.G1.01: Label basic computer parts on a diagram
* T01.G1.01: Put pictures in order to plant a seed





ID: T29.G2.03
Topic: T29 – Devices & Hardware Systems
Skill: Sort wired vs wireless connections using picture scenarios
Description: **Student task:** Drag device picture cards into "Wired" or "Wireless" sorting bins, then answer why each connection type is useful. **Visual scenario:** Picture cards show: HDMI cable connecting laptop to TV, USB printer with cable, Bluetooth headphones with wave icon, Wi-Fi tablet with signal bars, ethernet cable to computer, wireless mouse with receiver. Two bins: "Wired" (cable icon) and "Wireless" (wave icon). **Correct sorting:** Wired: HDMI cable, USB printer, ethernet cable. Wireless: Bluetooth headphones, Wi-Fi tablet, wireless mouse. Follow-up MCQ: "Why use wireless?" Options: (A) can move around freely [correct], (B) always faster, (C) doesn't need batteries. _Implementation note: Drag-drop sorting with 6 cards plus follow-up MCQ. Auto-graded by bin contents and MCQ. CSTA: K-2-NI-04._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram
* T01.G1.07: Decide if two algorithms finish with the same result





ID: T29.G2.04
Topic: T29 – Devices & Hardware Systems
Skill: Sort device care habits into good vs bad using picture scenarios
Description: **Student task:** Drag picture scenarios into "Good Care" or "Bad Care" sorting bins. **Visual scenario:** Picture cards show: (1) child carrying laptop with two hands, (2) child with clean hands before touching tablet, (3) gently plugging in charger, (4) dropping tablet on floor, (5) eating chips while using keyboard, (6) putting drink next to laptop. **Correct sorting:** Good care: two hands, clean hands, gentle plug. Bad care: dropping, eating chips, drink nearby. _Implementation note: Drag-drop sorting with 6 scenarios; visual feedback with happy/sad device faces. Auto-graded by bin contents. CSTA: K-2-IC-20._

Dependencies:
* T29.G1.01: Label basic computer parts on a diagram
* T01.G1.01: Put pictures in order to plant a seed





ID: T29.G2.05
Topic: T29 – Devices & Hardware Systems
Skill: Match sensors to what they detect using picture cards
Description: **Student task:** Drag sensor picture cards to match what they detect. **Visual scenario:** Left column shows sensors: camera lens, microphone, touch screen with finger, motion sensor, temperature sensor. Right column shows detection types with icons: light/images (sun and photo), sound/voices (sound waves), finger touches (hand icon), movement (running person), hot/cold (thermometer). **Correct matches:** camera→light/images, microphone→sound/voices, touch screen→finger touches, motion sensor→movement, temperature sensor→hot/cold. _Implementation note: Drag-drop matching with 5 pairs; audio describes each sensor's function on completion. Auto-graded by correct pairings. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.03: Identify sensors in everyday places using picture scenarios
* T29.GK.03: Sort input and output devices using picture cards




ID: T29.G2.06
Topic: T29 – Devices & Hardware Systems
Skill: Predict what happens when a device connection breaks using picture scenarios
Description: **Student task:** View a picture scenario of a working system, then predict what happens when a connection breaks. **Visual scenario 1:** Bluetooth headphones connected to tablet playing music → headphones disconnected → select outcome: (A) music stops in headphones [correct], (B) tablet turns off, (C) music gets louder. **Visual scenario 2:** USB mouse connected to computer → mouse unplugged → select outcome: (A) screen goes blank, (B) can't move cursor [correct], (C) keyboard stops working. **Visual scenario 3:** Wi-Fi router connected → router unplugged → select outcome: (A) can't load websites [correct], (B) computer turns off, (C) games saved disappear. _Implementation note: 3 scenarios with before/after pictures and MCQ; builds prediction skills. Auto-graded by MCQ selections. CSTA: K-2-CS-02._

Dependencies:
* T29.G2.03: Sort wired vs wireless connections using picture scenarios
* T29.G2.02: Trace input-process-output flow using visual diagrams




ID: T29.G2.07
Topic: T29 – Devices & Hardware Systems
Skill: Sort sensors by what they sense (sight, sound, touch, location)
Description: **Student task:** Drag sensor picture cards into category bins: "Sees" (sight), "Hears" (sound), "Feels" (touch), "Finds Location." **Visual scenario:** Picture cards show: camera (sees), microphone (hears), touchscreen (feels), GPS chip (location), motion detector (sees movement), voice recorder (hears), pressure button (feels), compass (finds direction). Four bins with eye, ear, hand, and map icons. Students explain why each sensor belongs in its category. _Implementation note: Multi-category sorting with 8 cards and 4 bins; builds sensor classification. Auto-graded by bin contents. CSTA: K-2-CS-02._

Dependencies:
* T29.G2.05: Match sensors to what they detect using picture cards




ID: T29.G2.08
Topic: T29 – Devices & Hardware Systems
Skill: Predict sensor behavior in different conditions using picture scenarios
Description: **Student task:** View scenarios showing sensors in different conditions and predict how well they will work. **Visual scenario 1:** Camera in bright room (works well) vs camera in dark closet (can't see much). **Scenario 2:** Microphone in quiet library (hears clearly) vs at loud concert (hears too much noise). **Scenario 3:** Touch screen with dry fingers (works) vs with wet gloves (might not work). Students match conditions to predictions: "works great," "has trouble," "won't work." _Implementation note: 3 scenarios with condition variations and prediction matching. Auto-graded by correct predictions. CSTA: K-2-CS-02._

Dependencies:
* T29.G2.05: Match sensors to what they detect using picture cards
* T29.G2.06: Predict what happens when a device connection breaks using picture scenarios




ID: T29.G2.09
Topic: T29 – Devices & Hardware Systems
Skill: Match devices to their battery types using picture cards
Description: **Student task:** Match device pictures to battery type pictures. **Visual scenario:** Devices: TV remote, laptop, game controller, tablet, wireless mouse, smartwatch. Battery types: small round button battery, rechargeable built-in battery, AA/AAA batteries. **Correct matches:** remote→AA batteries, laptop→rechargeable built-in, controller→AA batteries, tablet→rechargeable built-in, mouse→AA batteries, smartwatch→button battery. Follow-up: "Which devices do you plug in to charge vs replace batteries?" _Implementation note: Matching with 6 devices and 3 battery types; builds power awareness. Auto-graded by correct pairings. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.04: Sort devices by where they get power (battery vs plug-in)




ID: T29.G2.10
Topic: T29 – Devices & Hardware Systems
Skill: Sequence device calibration steps using picture cards
Description: **Student task:** Arrange picture cards showing how to calibrate a touchscreen in the correct order. **Visual scenario:** Picture cards show: (1) open settings menu, (2) find "calibrate screen" option, (3) tap the dot in top-left corner, (4) tap the dot in top-right corner, (5) tap the dot in bottom corners, (6) press "done" button. Follow-up question: "Why do we calibrate? So the screen knows exactly where your finger touches!" _Implementation note: 6-card sequencing activity introducing calibration concept. Auto-graded by sequence order. CSTA: K-2-CS-02._

Dependencies:
* T29.G1.06: Sequence what happens when a button is pressed




ID: T29.G2.11
Topic: T29 – Devices & Hardware Systems
Skill: Sort device sharing scenarios into fair and unfair
Description: **Student task:** View picture scenarios of students sharing devices and sort into "Fair Sharing" and "Unfair Sharing" bins. **Visual scenarios:** (1) Two students taking turns with timer (FAIR), (2) One student hogging tablet while others wait (UNFAIR), (3) Student helping another learn to use device (FAIR), (4) Student grabbing device from someone's hands (UNFAIR), (5) Students working together on one project (FAIR), (6) Student hiding device so no one else can use it (UNFAIR). Students explain why each scenario is fair or unfair. _Implementation note: Ethical sorting with 6 scenarios; digital citizenship focus. Auto-graded by bin contents. CSTA: K-2-IC-20._

Dependencies:
* T29.G1.07: Circle safe vs unsafe device handling in picture scenarios





ID: T29.G3.01
Topic: T29 – Devices & Hardware Systems
Skill: Map project ideas to required sensors in CreatiCode
Description: Analyze CreatiCode project ideas (voice assistant, gesture game, face tracking app, drawing program) and select the required hardware inputs for each. Identify which sensors are needed (microphone for voice, camera for face/gesture, keyboard for typing, mouse for drawing) and explain how the sensor data enables the project's functionality. Match 4 projects to their sensor requirements and write one sentence explaining each connection.

Dependencies:
* T29.G2.01: Match internal computer parts to everyday analogies using picture cards
* T29.G2.02: Trace input-process-output flow using visual diagrams





ID: T29.G3.02
Topic: T29 – Devices & Hardware Systems
Skill: Select appropriate input types for CreatiCode project scenarios
Description: Analyze CreatiCode project scenarios and select the best input type for each. Given scenarios (platformer game, painting app, voice-controlled story, fitness tracker), choose between keyboard keys, mouse clicks/movement, camera feed, or microphone audio. Justify each selection by explaining why that input type fits the user experience (keyboard for precise control, mouse for freeform drawing, camera for motion, microphone for hands-free).

Dependencies:
* T29.G2.02: Trace input-process-output flow using visual diagrams
* T29.G2.05: Match sensors to what they detect using picture cards





ID: T29.G3.03
Topic: T29 – Devices & Hardware Systems
Skill: Analyze cloud save vs local export trade-offs in CreatiCode
Description: Analyze scenarios requiring project storage decisions and select the best option. Given scenarios (sharing with friend, working offline at home, backing up important project, accessing from school and home), choose between CreatiCode cloud save (accessible anywhere with internet, auto-saves, easy sharing link) and local export (works offline, creates backup file, portable via USB). Complete a decision table listing pros/cons of each method.

Dependencies:
* T29.G2.01: Match internal computer parts to everyday analogies using picture cards





ID: T29.G3.04
Topic: T29 – Devices & Hardware Systems
Skill: Trace how sensors provide data to CreatiCode programs
Description: Trace the data path from physical sensors to program actions. Given a CreatiCode project (face filter app), diagram the flow: (1) camera captures light → (2) converts to image data (pixels) → (3) program analyzes image → (4) sprite responds. Complete similar traces for microphone (sound waves → audio data → speech text → sprite speaks) and motion sensor (movement → position values → character moves). Practice: fill-in-the-blank data flow diagrams.

Dependencies:
* T29.G2.05: Match sensors to what they detect using picture cards
* T29.G2.02: Trace input-process-output flow using visual diagrams





ID: T29.G3.05
Topic: T29 – Devices & Hardware Systems
Skill: Enable and display camera feed in CreatiCode projects
Description: Students create a CreatiCode project that accesses the device camera and displays the feed on stage. Tasks: (1) use the camera permission block to request access, (2) display live camera feed using appropriate blocks, (3) handle the case when permission is denied by showing a message. Students explain why camera access requires user permission (privacy protection) and identify appropriate uses (face filters, motion games) vs inappropriate uses (recording without consent).

Dependencies:
* T29.G2.05: Match sensors to what they detect using picture cards
* T29.G2.02: Trace input-process-output flow using visual diagrams





ID: T29.G3.06
Topic: T29 – Devices & Hardware Systems
Skill: Enable and capture audio using device microphone in CreatiCode
Description: Students create a CreatiCode project that accesses the device microphone and captures audio input. Tasks: (1) use microphone permission block to request access, (2) detect when audio input is present (sound level sensing), (3) create a visual indicator (sprite grows when loud, shrinks when quiet). Students explain why microphone access requires permission and identify appropriate uses (voice commands, sound-reactive art) vs privacy concerns (always-listening without consent).

Dependencies:
* T29.G2.05: Match sensors to what they detect using picture cards
* T29.G2.02: Trace input-process-output flow using visual diagrams




ID: T29.G3.07
Topic: T29 – Devices & Hardware Systems
Skill: Test different input methods for the same CreatiCode action
Description: Students program a sprite to perform the same action (move right) using three different input methods: (1) keyboard arrow key press, (2) mouse click on right side of stage, (3) touch/drag on touchscreen (if available). Compare: Which input feels most natural for a racing game? For a drawing app? For a quiz game? Students document their findings in a comparison table: Input Type | Best For | Why.

Dependencies:
* T29.G3.02: Select appropriate input types for CreatiCode project scenarios




ID: T29.G3.08
Topic: T29 – Devices & Hardware Systems
Skill: Create a sensor tester project in CreatiCode
Description: Students build a diagnostic project that displays live readings from multiple sensors on screen. Dashboard shows: (1) Mouse X/Y position as numbers, (2) Current keyboard key pressed (or "none"), (3) Microphone loudness level as a meter bar, (4) Camera status indicator (available/unavailable). Each sensor has a labeled display area. Students test by moving mouse, pressing keys, making sounds, and observe real-time updates.

Dependencies:
* T29.G3.05: Enable and display camera feed in CreatiCode projects
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode




ID: T29.G3.09
Topic: T29 – Devices & Hardware Systems
Skill: Calibrate sensor thresholds through experimentation
Description: Students create a sound-activated animation and experiment to find the best loudness threshold. Tasks: (1) Start with threshold at 50 - test if animation triggers reliably, (2) If too sensitive (triggers from background noise), increase to 70, (3) If not sensitive enough (misses normal speaking), decrease to 30, (4) Document the "sweet spot" threshold that works best. Students learn that calibration means adjusting settings until something works just right for the environment.

Dependencies:
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode
* T29.G2.10: Sequence device calibration steps using picture cards




ID: T29.G3.10
Topic: T29 – Devices & Hardware Systems
Skill: Diagnose sensor issues using a troubleshooting checklist
Description: Students use a step-by-step checklist to fix broken sensor projects. Checklist for "Camera not working": (1) Did browser ask for permission? (Check) (2) Did you click "Allow"? (Check) (3) Is camera being used by another app? (Check) (4) Is the camera block in your code? (Check) (5) Is another sprite blocking the camera display? (Check). Students practice with 3 broken projects, following the checklist to identify and fix each issue.

Dependencies:
* T29.G3.05: Enable and display camera feed in CreatiCode projects
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode





ID: T29.G4.01
Topic: T29 – Devices & Hardware Systems
Skill: Diagram data flow in CreatiCode AI-powered projects
Description: Students create data flow diagrams for CreatiCode AI projects, identifying each stage from sensor to action. Given a project (face detection game), students diagram: Camera (input) → Face Detection AI (processing) → Face position data → Sprite follows face (output). Students complete 3 diagrams for different AI features: (1) camera→face detection→sprite action, (2) microphone→speech recognition→text display, (3) camera→hand detection→gesture control. Practice: label each stage as INPUT, AI PROCESSING, DATA, or OUTPUT.

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G2.02: Trace input-process-output flow using visual diagrams
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G4.02
Topic: T29 – Devices & Hardware Systems
Skill: Predict how device performance affects CreatiCode project responsiveness
Description: Students analyze how different device capabilities affect CreatiCode project performance. Given scenarios (simple animation on old tablet vs multi-sprite AI game on fast computer), students predict: frame rate differences, AI processing delays, and user experience impacts. Students complete a comparison table: Project Type | Slow Device Result | Fast Device Result. Practice: identify which project features (many sprites, AI detection, high-res camera) demand more processing power and predict performance on low-end devices.

Dependencies:
* T06.G2.03: Design a simple "if-then" game rule
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G4.03
Topic: T29 – Devices & Hardware Systems
Skill: Trace latency vs bandwidth effects in online CreatiCode projects
Description: Students distinguish latency (delay time) from bandwidth (data amount) using concrete examples. Latency analogy: time for a single ping-pong ball to travel across room. Bandwidth analogy: how many ping-pong balls can travel at once. Students analyze scenarios: (1) Online game with high latency → delayed player movements [latency issue]. (2) Video call that freezes but eventually loads → insufficient bandwidth. (3) Multiplayer CreatiCode project with laggy responses → identify which metric is the bottleneck. Practice: match 4 problem scenarios to latency or bandwidth causes.

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G2.03: Sort wired vs wireless connections using picture scenarios





ID: T29.G4.04
Topic: T29 – Devices & Hardware Systems
Skill: Select between 2D camera widgets and 3D webcam backgrounds in CreatiCode
Description: Students analyze project requirements and select the appropriate camera display method. 2D camera widgets: display camera in a window overlay on the stage (good for video chat apps, photo booths). 3D webcam backgrounds: use live camera as the background for 3D scenes (good for AR games, virtual try-on). Given 4 project scenarios, students select the appropriate method and justify: (1) Photo booth app → 2D widget, (2) AR furniture placement → 3D background, (3) Video message recorder → 2D widget, (4) Dance game with 3D character overlay → 3D background.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G3.05: Enable and display camera feed in CreatiCode projects





ID: T29.G4.05
Topic: T29 – Devices & Hardware Systems
Skill: Identify accessibility hardware types and their purposes
Description: Students analyze adaptive input devices and match them to user needs. Given devices (switch button, eye tracker, screen reader software, joystick controller, voice recognition), students: (1) identify which disability each addresses (motor impairment, vision impairment, limited hand mobility), (2) explain how the device connects to the computer (USB, Bluetooth, software), (3) describe one CreatiCode project feature that could benefit from each device. Practice: match 4 adaptive devices to 4 user scenarios.

Dependencies:
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G4.06
Topic: T29 – Devices & Hardware Systems
Skill: Create keyboard-controlled interactions in CreatiCode
Description: Students program sprites to respond to keyboard events using CreatiCode blocks. Tasks: (1) use "when [key] pressed" hat block to trigger actions, (2) use "when [key] released" to stop actions, (3) use "key [key] pressed?" reporter in conditionals for continuous checking, (4) create a simple game with WASD movement controls. Students debug common issues: key not responding (wrong key name), action continues after release (missing release handler), multiple keys conflict.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.04: Use a simple if in a script
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G4.06.01
Topic: T29 – Devices & Hardware Systems
Skill: Add and configure camera preview widgets in CreatiCode
Description: Students add camera widgets to display live camera feeds in CreatiCode projects. Tasks: (1) use "add camera window" block to create a camera preview, (2) configure front/back camera selection, (3) set flip modes (normal, mirror), (4) use "save picture from camera" to capture snapshots. Students create a photo booth project with: camera preview widget, capture button that saves photo, and display of captured image. Debug: camera not showing (permissions), wrong camera selected.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T29.G3.05: Enable and display camera feed in CreatiCode projects
* T29.G4.04: Select between 2D camera widgets and 3D webcam backgrounds in CreatiCode





ID: T29.G4.06.02
Topic: T29 – Devices & Hardware Systems
Skill: Create mouse-controlled interactions in CreatiCode
Description: Students program sprites to respond to mouse button events. Tasks: (1) use "when left mouse button pressed" to trigger actions, (2) use mouse x/y position reporters to track cursor location, (3) create a sprite that follows the mouse cursor, (4) differentiate left vs right click actions. Students create a drawing app where: left-click draws, right-click erases, sprite follows mouse position. Debug: clicks not registering (wrong event), sprite position updating incorrectly.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.04: Use a simple if in a script
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G4.06.03
Topic: T29 – Devices & Hardware Systems
Skill: Create drag and scroll interactions in CreatiCode
Description: Students program sprites to respond to mouse drag and wheel events. Tasks: (1) use "when mouse pointer dragged" to track drag movements, (2) use mouse wheel events to zoom or scroll content, (3) calculate drag distance using start/end positions. Students create a map viewer with: drag to pan the view, scroll wheel to zoom in/out. Debug: drag not smooth (missing position updates), scroll direction inverted.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.04: Use a simple if in a script
* T29.G4.06.02: Create mouse-controlled interactions in CreatiCode





ID: T29.G4.06.04
Topic: T29 – Devices & Hardware Systems
Skill: Create draggable sprite interactions in CreatiCode
Description: Students program sprites to be draggable using sprite-specific drag events. Tasks: (1) enable sprite dragging mode, (2) use "when dragging starts" to initialize drag state, (3) use "when being dragged" to update position continuously, (4) use "when dragging stops" to finalize placement. Students create a puzzle game where: pieces can be dragged, pieces snap to grid when dropped, incorrect placement bounces back. Debug: sprite not draggable (mode not enabled), position jumps on drag start.

Dependencies:
* T06.G2.01: Create a simple cause-and-effect chain with picture cards
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T08.G3.04: Use a simple if in a script
* T29.G4.06.02: Create mouse-controlled interactions in CreatiCode





ID: T29.G4.07
Topic: T29 – Devices & Hardware Systems
Skill: Create audio-reactive visualizations in CreatiCode
Description: Students create projects that respond to microphone audio levels in real-time. Tasks: (1) use audio level reporter to get current sound volume, (2) map audio levels to sprite properties (size, position, color), (3) create a sound visualizer with bars that bounce to music. Students analyze the audio sampling rate and explain why rapid updates create smooth visualizations. This skill bridges basic microphone access to advanced speech recognition by building comfort with real-time audio data.

Dependencies:
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode
* T07.G2.01: Identify when to use "repeat" vs "do once"
* T09.G3.03: Use a variable in a calculation




ID: T29.G4.08
Topic: T29 – Devices & Hardware Systems
Skill: Trace data flow in connected device systems
Description: Trace how data flows between multiple connected devices in IoT-style systems. Tasks: (1) diagram data flow from sensor device → network → cloud server → user device, (2) identify where data is processed at each stage (edge vs cloud), (3) predict latency at each hop. Analyze a smart home scenario: temperature sensor → Wi-Fi router → cloud service → phone app displays temperature. Questions: Where does the sensor reading become a number? What happens if Wi-Fi disconnects? How long does the full path take? Match 4 IoT scenarios to their data flow diagrams.

Dependencies:
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T29.G2.06: Predict what happens when a device connection breaks using picture scenarios
* T29.G4.03: Trace latency vs bandwidth effects in online CreatiCode projects




ID: T29.G4.09
Topic: T29 – Devices & Hardware Systems
Skill: Interpret sensor data in table format
Description: Read and interpret sensor data stored in CreatiCode table variables. Tasks: (1) examine face detection table output (rows for each facial feature, columns for x/y position), (2) examine hand detection table output (21 rows per hand with finger positions), (3) locate specific data points (e.g., "find the nose y-position in row 5"). Understand that AI sensors output structured data in tables, not single values. Practice: given a face detection table, answer questions like "Is the face tilted left or right?" by comparing left/right eye x-positions.

Dependencies:
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T29.G3.04: Trace how sensors provide data to CreatiCode programs
* T10.G3.01: Create and populate a table




ID: T29.G4.10
Topic: T29 – Devices & Hardware Systems
Skill: Analyze power management in CreatiCode projects
Description: Students analyze how different CreatiCode project features affect device battery consumption. Create comparison: (1) Simple sprite animation = low power usage, (2) Camera continuously active = medium power, (3) AI face detection running = high power, (4) Multiple AI features + camera + audio = very high power. Students design a "power budget" for a 30-minute classroom project: which features can run continuously, which should be turned off when not needed? Practice: modify a battery-draining project to be more efficient by adding start/stop controls for heavy features.

Dependencies:
* T29.G4.02: Predict how device performance affects CreatiCode project responsiveness
* T29.G2.09: Match devices to their battery types using picture cards




ID: T29.G4.11
Topic: T29 – Devices & Hardware Systems
Skill: Implement sensor fallback when primary input fails
Description: Students create a CreatiCode game with backup controls when camera fails. Tasks: (1) Try to start face tracking for character control, (2) If camera permission denied, detect the failure, (3) Show message "Camera unavailable - using keyboard controls", (4) Switch to arrow key controls instead. Students test both paths: grant permission (face tracking works), deny permission (keyboard fallback works). This builds robust design habits.

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G3.10: Diagnose sensor issues using a troubleshooting checklist




ID: T29.G4.12
Topic: T29 – Devices & Hardware Systems
Skill: Connect multiple input devices in a single project
Description: Students build a CreatiCode project that uses three input types simultaneously. Design: (1) Keyboard WASD for movement, (2) Mouse for aiming/clicking, (3) Microphone loudness for special power activation (shout to jump high!). Each input controls a different aspect of the game. Students document how inputs work together without conflicting. Challenge: add a fourth input (camera-based gesture) for a secret action.

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G4.06.02: Create mouse-controlled interactions in CreatiCode
* T29.G3.07: Test different input methods for the same CreatiCode action




ID: T29.G4.13
Topic: T29 – Devices & Hardware Systems
Skill: Trace sensor data from hardware to program variable
Description: Students diagram the complete path of sensor data from physical hardware to program use. Example path for camera: (1) Camera lens → captures light photons, (2) Sensor chip → converts to digital pixels, (3) Device driver → makes data available to browser, (4) CreatiCode block → reads pixel data, (5) AI processing → extracts face position, (6) Variable → stores x,y coordinates, (7) Sprite → moves to position. Students complete similar traces for microphone and keyboard. Label each step with: HARDWARE, DRIVER, API, BLOCK, VARIABLE.

Dependencies:
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T29.G4.09: Interpret sensor data in table format




ID: T29.G4.14
Topic: T29 – Devices & Hardware Systems
Skill: Compare project behavior across multiple devices
Description: Students load the same CreatiCode project on two different devices (e.g., school Chromebook and personal tablet) and document differences. Comparison table: Device | Screen Size | Available Sensors | Performance (FPS) | Differences Noticed. Observations: Does face tracking work on both? Is one slower? Does the layout look different? Students identify which differences are caused by hardware vs browser vs settings.

Dependencies:
* T29.G4.02: Predict how device performance affects CreatiCode project responsiveness
* T29.G4.03: Trace latency vs bandwidth effects in online CreatiCode projects




ID: T29.G5.01
Topic: T29 – Devices & Hardware Systems
Skill: Analyze device requirements for CreatiCode AI features
Description: Analyze CreatiCode AI projects and create device requirement specifications. Given projects (voice assistant, pose game, face detection app, multiplayer game), list: (1) required hardware (camera resolution, microphone quality, processor speed), (2) required connectivity (internet for cloud APIs, bandwidth for real-time features), (3) optional enhancements (GPU for faster AI, higher frame rate camera). Complete a requirements matrix for 4 different AI project types.

Dependencies:
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T29.G4.02: Predict how device performance affects CreatiCode project responsiveness
* T09.G3.03: Use a variable in a calculation





ID: T29.G5.02
Topic: T29 – Devices & Hardware Systems
Skill: Design device-handling procedures for classroom projects
Description: Create device handling checklists for group project work. Checklist items include: (1) pre-use inspection (check cables, test camera/microphone, log battery level), (2) during-use care (clean hands, stable surface, proper ventilation), (3) post-use procedures (save work, log out, sanitize shared devices, report issues). Analyze scenarios where poor device handling causes project failures and propose preventive measures.

Dependencies:
* T29.G4.05: Identify accessibility hardware types and their purposes
* T29.G3.01: Map project ideas to required sensors in CreatiCode
* T11.G3.06: Identify personal information that should stay private online
* T11.G4.19: Explain why software updates matter for security





ID: T29.G5.03
Topic: T29 – Devices & Hardware Systems
Skill: Analyze sensor data types and sampling rates for CreatiCode projects
Description: Analyze how different sensors collect data at different rates and formats. Comparison table: Camera (30-60 fps, image frames), Microphone (44100 samples/sec, audio waveform), Motion sensor (60-120 Hz, position values). Explain: (1) why higher frame rates improve face tracking smoothness, (2) why audio sample rate affects speech recognition accuracy, (3) why polling rate matters for responsive gesture control. Match 4 project types to minimum sensor specifications.

Dependencies:
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T29.G4.02: Predict how device performance affects CreatiCode project responsiveness
* T09.G3.03: Use a variable in a calculation





ID: T29.G5.04
Topic: T29 – Devices & Hardware Systems
Skill: Evaluate hardware configurations for accessibility outcomes
Description: Analyze device setups and recommend configurations for users with different abilities. Given scenarios: (1) User with limited hand mobility needs to play a CreatiCode game → recommend switch interface + voice control, (2) User with visual impairment needs to create a project → recommend screen reader + audio feedback, (3) User with hearing impairment needs speech recognition → recommend visual captions + vibration feedback. Justify hardware choices based on user needs and CreatiCode feature compatibility.

Dependencies:
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G4.05: Identify accessibility hardware types and their purposes





ID: T29.G5.05
Topic: T29 – Devices & Hardware Systems
Skill: Configure orbit cameras for 3D CreatiCode scenes
Description: Students add and configure orbit cameras for 3D CreatiCode projects. Tasks: (1) use "add orbit camera" block with target position, (2) set camera distance and angle limits, (3) configure keyboard controls for rotation (arrow keys), (4) configure mouse controls for zoom (scroll wheel). Students create a 3D product viewer where users can rotate around an object and zoom in/out. Debug: camera clips through objects (distance too close), rotation feels wrong (inverted controls).

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G3.01: Map project ideas to required sensors in CreatiCode





ID: T29.G5.05.01
Topic: T29 – Devices & Hardware Systems
Skill: Enable mouse picking and hovering for 3D objects in CreatiCode
Description: Students enable mouse interactions for 3D objects. Tasks: (1) use "turn on picking" to enable click detection on 3D objects, (2) use "turn on hovering" to detect mouse hover, (3) create "when this 3D object is picked" event handlers, (4) use reporter blocks (picked point x/y/z, hovered object name) for precise interaction. Students create an interactive 3D museum where: clicking objects shows info popup, hovering highlights the object. Debug: clicks not detected (picking not enabled), wrong object responds (layering issues).

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence





ID: T29.G5.05.02
Topic: T29 – Devices & Hardware Systems
Skill: Configure follow cameras for 3D CreatiCode games
Description: Students add follow cameras that track moving objects in 3D scenes. Tasks: (1) use "add follow camera" block attached to player sprite, (2) configure direction lock (none for free look, 2-axis for side-scroller, 4-axis for top-down), (3) set see-through percentage to prevent camera obstruction, (4) adjust follow distance and smoothing. Students create a 3D racing game where camera follows the car with smooth transitions. Debug: camera jitters (smoothing too low), camera goes through walls (collision not configured).

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G3.01: Map project ideas to required sensors in CreatiCode
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes





ID: T29.G5.05.03
Topic: T29 – Devices & Hardware Systems
Skill: Configure advanced 3D camera limits and viewport settings
Description: Students configure advanced 3D camera settings for polished experiences. Tasks: (1) set radius min/max to prevent extreme zoom, (2) configure visible range to optimize rendering, (3) set vertical angle limits to prevent disorienting views, (4) adjust pan/zoom/tilt speed ratios for user comfort, (5) position camera viewport for split-screen or picture-in-picture. Students create a 3D architecture walkthrough with comfortable navigation limits. Debug: camera gets stuck (limits too restrictive), performance issues (visible range too large).

Dependencies:
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G3.01: Map project ideas to required sensors in CreatiCode
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes





ID: T29.G5.06
Topic: T29 – Devices & Hardware Systems
Skill: Create face-tracking interactions in CreatiCode projects
Description: Students use face detection blocks to create interactive projects. Tasks: (1) enable face detection with "run face detection" block, (2) read face position (x, y) and size to track user, (3) create a sprite that follows the user's face, (4) detect multiple faces for multiplayer games. Students create a face-following pet game where a character tracks the player's face. Privacy discussion: explain when face detection is appropriate (games, filters) vs concerning (surveillance without consent).

Dependencies:
* T29.G3.05: Enable and display camera feed in CreatiCode projects
* T29.G4.01: Diagram data flow in CreatiCode AI-powered projects
* T09.G3.03: Use a variable in a calculation





ID: T29.G5.06.01
Topic: T29 – Devices & Hardware Systems
Skill: Justify sensor selection for CreatiCode project requirements
Description: Students analyze project requirements and justify sensor choices. Given 5 project types: (1) Quiz game → keyboard (precise text input), (2) Drawing app → mouse (smooth cursor tracking), (3) Fitness tracker → camera (body pose detection), (4) Voice assistant → microphone (speech recognition), (5) AR furniture preview → camera + gyroscope (spatial tracking). Students complete a decision matrix: Project | Primary Sensor | Why | Alternative | Trade-off. Practice: propose sensor configurations for 2 new project ideas with justification.

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G4.04: Select between 2D camera widgets and 3D webcam backgrounds in CreatiCode
* T09.G3.03: Use a variable in a calculation





ID: T29.G5.07
Topic: T29 – Devices & Hardware Systems
Skill: Debug sensor input issues systematically in CreatiCode
Description: Students apply systematic debugging to sensor-related problems. Common issues and fixes: (1) Camera not working → check permissions, verify camera selection, test with simple display first, (2) Microphone silent → check volume levels, verify browser permissions, test with audio level meter, (3) Keyboard not responding → verify focus on stage, check event hat block spelling, test with console log. Students debug 3 broken projects by: identifying symptoms, hypothesizing causes, testing fixes, documenting solutions.

Dependencies:
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G4.07: Create audio-reactive visualizations in CreatiCode




ID: T29.G5.08
Topic: T29 – Devices & Hardware Systems
Skill: Add and configure virtual joysticks for mobile 3D controls
Description: Program virtual joystick widgets for touch-based 3D game controls. Tasks: (1) use "add [left/right] joystick" block to create on-screen touch controllers, (2) customize joystick colors and scale for visibility, (3) read joystick properties (x, y displacement, pressed state, direction) to control character movement, (4) combine left joystick for movement + right joystick for camera rotation in a 3D game. Debug: joystick not responding (wrong side selected), movement inverted (x/y axis confusion), joystick obscures gameplay (scale too large).

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode




ID: T29.G5.09
Topic: T29 – Devices & Hardware Systems
Skill: Embed and control video content in CreatiCode projects
Description: Add video widgets to play embedded video content within CreatiCode projects. Tasks: (1) use "add youtube video" block with URL, position, and size parameters, (2) control playback with start/pause/stop/mute commands, (3) use "seek to time" to jump to specific moments, (4) trigger events using "when video time is [seconds]" hat blocks for synchronized interactions. Create an interactive tutorial where video pauses at key moments for user input. Debug: video not loading (URL format), audio conflicts (multiple videos), timing issues (seeking while playing).

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode




ID: T29.G5.10
Topic: T29 – Devices & Hardware Systems
Skill: Implement device geolocation in CreatiCode projects
Description: Access device GPS/location data in CreatiCode projects. Tasks: (1) use "latitude" and "longitude" reporter blocks to get current position, (2) display coordinates on screen as text labels, (3) handle permission requests for location access, (4) create a simple "You Are Here" marker. Understand that location requires user permission for privacy. Create a project that shows current coordinates and updates when the device moves. Debug: location returns 0 (permissions denied), location inaccurate (indoor GPS limitations), slow updates (GPS acquisition time).

Dependencies:
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G4.09: Interpret sensor data in table format
* T29.G3.04: Trace how sensors provide data to CreatiCode programs




ID: T29.G5.11
Topic: T29 – Devices & Hardware Systems
Skill: Configure 3D distance sensors for obstacle detection
Description: Configure virtual distance sensors in 3D CreatiCode scenes for obstacle detection. Tasks: (1) use "configure sensor of [object] in [direction] with max [distance]" to set up distance rays, (2) configure multiple directions (front, back, left, right, up, down), (3) choose between single ray vs five-ray configurations, (4) read sensor data to detect obstacles and measure distances. Create a 3D car that stops before hitting walls using front distance sensor. Debug: sensor not detecting (wrong direction), detecting wrong objects (max distance too large), sensor rays visible (debugging vs production mode).

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G4.08: Trace data flow in connected device systems
* T08.G4.03: Nest an if inside a loop




ID: T29.G5.12
Topic: T29 – Devices & Hardware Systems
Skill: Design device-to-cloud data pipelines
Description: Design data pipelines that move sensor data from device to cloud storage. Tasks: (1) identify data source (camera, microphone, GPS), (2) determine data format (image, audio, coordinates), (3) choose transmission method (HTTP fetch, cloud variables), (4) select cloud destination (Google Sheets, cloud database). Design a pipeline for a weather station: temperature sensor → CreatiCode program → Google Sheets. Consider: data frequency (how often to send), batching (send multiple readings at once), error handling (retry on failure). Diagram 3 different sensor-to-cloud pipelines.

Dependencies:
* T29.G4.08: Trace data flow in connected device systems
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T10.G4.01: Import data from an external source




ID: T29.G5.13
Topic: T29 – Devices & Hardware Systems
Skill: Understand AR camera modes and their hardware requirements
Description: Analyze different AR camera modes and their device requirements. AR modes: (1) AR World Camera: uses back camera + motion sensors to estimate 3D position (requires gyroscope, accelerometer), (2) AR Face Camera: uses front camera for face mesh tracking (requires front camera with depth or AI processing), (3) AR Image Tracking: detects printed markers (requires camera with sufficient resolution), (4) Webcam Background: simple camera overlay (basic camera only). Match 4 AR project types to minimum device requirements. Explain why some AR features work on phones but not Chromebooks.

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G4.04: Select between 2D camera widgets and 3D webcam backgrounds in CreatiCode




ID: T29.G5.14
Topic: T29 – Devices & Hardware Systems
Skill: Process multi-dimensional sensor data arrays
Description: Work with complex sensor data that has multiple dimensions. Tasks: (1) process hand detection table with 47 rows of finger positions/angles, (2) process body tracking table with 33 body part positions in x/y/z, (3) calculate derived values (e.g., arm length from shoulder to wrist positions), (4) detect patterns in multi-dimensional data (all fingers curled = fist). Create a project that classifies hand poses by analyzing finger curl values from the hand detection table. Practice: given body tracking data, calculate if the user's arms are raised above their head.

Dependencies:
* T29.G4.09: Interpret sensor data in table format
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects
* T10.G4.04: Filter or search within a table




ID: T29.G5.15
Topic: T29 – Devices & Hardware Systems
Skill: Debug hardware connectivity issues systematically
Description: Apply systematic debugging to hardware-related problems. Debug flowchart: (1) Check permissions → granted? If no, request or show message. (2) Check hardware exists → camera/mic available? If no, show "device not found." (3) Check hardware works → test with simple display/meter. (4) Check integration → sensor data reaching program? Use console logging. Create a diagnostic project that tests: camera (show feed), microphone (show level meter), GPS (show coordinates), and reports status of each. Document 5 common hardware issues and their systematic fixes.

Dependencies:
* T29.G5.07: Debug sensor input issues systematically in CreatiCode
* T29.G5.10: Implement device geolocation in CreatiCode projects
* T11.G4.17: Practice binary search debugging in CreatiCode




ID: T29.G5.16
Topic: T29 – Devices & Hardware Systems
Skill: Combine two sensors for enhanced detection
Description: Students create a project that combines two sensor inputs for richer interaction. Project: Character control using BOTH face position AND microphone volume. (1) Face X-position controls character's horizontal movement (left-right), (2) Microphone volume controls character's vertical movement (quiet = low, loud = high). Students experience how combining sensors creates more natural interaction than single sensor. Discussion: Why is this better than just using face tracking? (Answer: adds another dimension of control without needing hands).

Dependencies:
* T29.G5.06: Create face-tracking interactions in CreatiCode projects
* T29.G4.07: Create audio-reactive visualizations in CreatiCode
* T29.G4.12: Connect multiple input devices in a single project




ID: T29.G5.17
Topic: T29 – Devices & Hardware Systems
Skill: Implement device-specific adaptations
Description: Students modify a project to work well on both desktop and mobile. Tasks: (1) Detect device type (desktop vs mobile), (2) On desktop: use keyboard arrows for movement, (3) On mobile: add virtual joystick for movement, (4) On mobile: make buttons larger for touch. Students test on both device types and document how each version works. Key insight: same project, different controls, same gameplay.

Dependencies:
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G4.14: Compare project behavior across multiple devices




ID: T29.G5.18
Topic: T29 – Devices & Hardware Systems
Skill: Debug sensor timing and synchronization issues
Description: Students diagnose and fix timing problems when using multiple sensors. Scenario: Camera updates at 30 fps but mouse updates at 60+ times per second. Problems that can occur: (1) Character jitters because sensors update at different rates, (2) Audio reaction seems delayed compared to visual feedback. Solutions: (1) Use frame-rate limiting to synchronize updates, (2) Buffer sensor data and process at consistent intervals. Students implement a smooth multi-sensor project.

Dependencies:
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects
* T29.G5.07: Debug sensor input issues systematically in CreatiCode




ID: T29.G5.19
Topic: T29 – Devices & Hardware Systems
Skill: Measure and optimize sensor polling frequency
Description: Students experiment with how often to check sensor values. Tasks: (1) Check face position every frame (60 fps) - very responsive but uses more CPU, (2) Check every 5 frames (12 fps) - less responsive but more efficient, (3) Check every 10 frames (6 fps) - noticeable lag. Students find the balance: responsive enough for good gameplay, efficient enough to run smoothly. Create a slider that lets users adjust polling rate and see the tradeoff.

Dependencies:
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects
* T29.G5.07: Debug sensor input issues systematically in CreatiCode




ID: T29.G5.20
Topic: T29 – Devices & Hardware Systems
Skill: Implement hardware capability detection and graceful degradation
Description: Students build a project that detects available hardware and adapts accordingly. Detection checklist: (1) Is camera available? Yes→enable face features, No→hide face features, (2) Is microphone available? Yes→enable voice features, No→show text input instead, (3) Is geolocation available? Yes→show location features, No→ask for manual location. Students create a "feature availability" display and test on devices with different capabilities.

Dependencies:
* T29.G5.15: Debug hardware connectivity issues systematically
* T29.G4.11: Implement sensor fallback when primary input fails




ID: T29.G5.21
Topic: T29 – Devices & Hardware Systems
Skill: Design peripheral device topology diagrams
Description: Students diagram how multiple devices connect through hubs and networks. Example topology: Computer USB port → USB Hub → Mouse + Keyboard + Webcam + External Storage. Students draw diagrams for: (1) Simple setup (one device directly connected), (2) Hub setup (multiple devices through hub), (3) Network setup (devices connected through Wi-Fi router). Predict: what happens if the USB hub is unplugged? (All 4 devices stop working). What if just the webcam is unplugged? (Only webcam stops).

Dependencies:
* T29.G4.08: Trace data flow in connected device systems
* T29.G2.03: Sort wired vs wireless connections using picture scenarios




ID: T29.G6.01
Topic: T29 – Devices & Hardware Systems
Skill: Interpret sensor specifications for CreatiCode project planning
Description: Students read simplified spec sheets and determine which specifications matter for their projects. Given specs (camera: 720p vs 1080p, 30fps vs 60fps; microphone: 16kHz vs 44kHz sample rate), students analyze: (1) Face detection needs → minimum 720p, 30fps sufficient, (2) Speech recognition → 16kHz adequate for voice, (3) Music visualization → 44kHz for accurate audio representation. Students complete a requirements specification document matching project needs to minimum hardware specs.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects





ID: T29.G6.02
Topic: T29 – Devices & Hardware Systems
Skill: Select storage strategies for CreatiCode project requirements
Description: Students analyze project requirements and select appropriate storage strategies. Comparison: (1) Cloud save: accessible anywhere, auto-sync, requires internet, limited by account storage, (2) Local browser storage: fast access, works offline, cleared if browser data wiped, device-specific, (3) Export to file: permanent backup, portable, manual process, version management needed. Students create a storage decision flowchart and apply it to 4 scenarios: school project, home project, shared collaboration, offline presentation.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G3.03: Analyze cloud save vs local export trade-offs in CreatiCode
* T29.G5.01: Analyze device requirements for CreatiCode AI features





ID: T29.G6.03
Topic: T29 – Devices & Hardware Systems
Skill: Analyze privacy implications of camera and microphone permissions
Description: Students analyze the privacy protection model for device access. Topics: (1) Why browsers require explicit permission (prevent unauthorized surveillance), (2) How CreatiCode requests access (permission prompts, user consent), (3) What happens when denied (graceful fallback, alternative input), (4) Privacy risks of always-on sensors (background recording, data exfiltration). Students evaluate 4 app permission requests and rate them: necessary, optional, or suspicious. Practice: design permission request dialogs that clearly explain why access is needed.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G3.05: Enable and display camera feed in CreatiCode projects
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode
* T29.G5.02: Design device-handling procedures for classroom projects





ID: T29.G6.04
Topic: T29 – Devices & Hardware Systems
Skill: Create device compatibility checklists for CreatiCode AI projects
Description: Students create comprehensive device compatibility checklists. Checklist categories: (1) Minimum requirements (camera resolution, microphone presence, browser version), (2) Recommended specs (higher frame rate, faster processor), (3) Connectivity requirements (internet speed for cloud APIs, latency for real-time features), (4) Fallback options (what works if feature unavailable). Students create checklists for 3 different AI project types and test them against device profiles (old tablet, Chromebook, gaming laptop).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects





ID: T29.G6.05
Topic: T29 – Devices & Hardware Systems
Skill: Implement one-shot speech recognition in CreatiCode projects
Description: Students implement speech-to-text for single utterances. Tasks: (1) use "start recognizing speech" to begin capture, (2) use "end speech recognition" to stop and process, (3) read "text from speech" reporter for recognized text, (4) use "clear speech text" to reset for next input. Students create a voice-controlled quiz where speaking an answer triggers checking. Configuration options: language selection, API choice (Azure, Whisper). Debug: recognition fails (microphone permissions), wrong language detected.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode
* T29.G4.07: Create audio-reactive visualizations in CreatiCode
* T29.G5.01: Analyze device requirements for CreatiCode AI features





ID: T29.G6.05.01
Topic: T29 – Devices & Hardware Systems
Skill: Create AR effects with webcam backgrounds in CreatiCode
Description: Students overlay 3D objects on live camera feeds for augmented reality effects. Tasks: (1) use "turn on webcam background" to show camera as scene background, (2) select front/back camera based on use case (selfie vs world-facing), (3) configure flip modes for natural mirror behavior, (4) position 3D objects to appear grounded in real space. Students create an AR pet that sits on their desk visible through the camera. Debug: objects appear behind camera feed (layering), mirrored text on selfie camera.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects





ID: T29.G6.05.02
Topic: T29 – Devices & Hardware Systems
Skill: Implement continuous speech recognition for real-time voice input
Description: Students implement always-listening speech recognition for real-time voice control. Tasks: (1) use "start continuous speech recognition into list" to begin streaming, (2) monitor the recognition list for new utterances, (3) process each recognized phrase as it arrives, (4) use "stop continuous speech recognition" when done. Students create a voice-controlled game where continuous commands control character movement ("jump", "duck", "run"). Debug: recognition list grows unbounded (not clearing), missed utterances (processing too slow).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G3.06: Enable and capture audio using device microphone in CreatiCode
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G6.05: Implement one-shot speech recognition in CreatiCode projects





ID: T29.G6.05.03
Topic: T29 – Devices & Hardware Systems
Skill: Implement text-to-speech audio output in CreatiCode projects
Description: Students implement text-to-speech for audio feedback. Tasks: (1) use "say in language" block with text and language selection, (2) configure voice type (Male/Female/Boy/Girl), (3) adjust speed, pitch, and volume for natural delivery, (4) use "stop speaking" to interrupt ongoing speech. Students create a talking story narrator that reads text aloud with character voices. Debug: speech cuts off (text too long), wrong pronunciation (language mismatch), overlapping audio (not waiting for completion).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G5.01: Analyze device requirements for CreatiCode AI features
* T29.G6.05: Implement one-shot speech recognition in CreatiCode projects





ID: T29.G6.06
Topic: T29 – Devices & Hardware Systems
Skill: Create gesture-controlled games with hand detection in CreatiCode
Description: Students use hand detection to recognize gestures and control games. Tasks: (1) use "run hand detection" to start tracking, (2) read finger curl values (0-1) for each finger, (3) read finger direction values for pointing detection, (4) combine values to recognize gestures (fist: all curled, pointing: index extended, thumbs up: thumb extended). Students create a rock-paper-scissors game using hand gestures. Camera requirements: good lighting, hand visible in frame, appropriate distance. Debug: detection unstable (poor lighting), wrong gesture recognized (threshold tuning).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G5.06: Create face-tracking interactions in CreatiCode projects





ID: T29.G6.06.01
Topic: T29 – Devices & Hardware Systems
Skill: Implement 3D pose detection for depth-aware body tracking
Description: Students implement 3D pose detection for depth-aware interactions. Tasks: (1) enable 3D pose mode to get x/y/z coordinates for body parts, (2) track shoulder/wrist/knee positions in 3D space, (3) calculate distances between body parts for gesture recognition, (4) compare 2D vs 3D detection trade-offs. Students create a virtual boxing game where punch depth matters (close vs far punches). Analysis: when does 3D improve interactions (depth games, VR-like), when is 2D sufficient (side-scrollers, simple gestures).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode





ID: T29.G6.06.02
Topic: T29 – Devices & Hardware Systems
Skill: Create draggable 3D object interactions in CreatiCode
Description: Students configure 3D objects to be draggable with constrained movement. Tasks: (1) use "set dragging mode" with direction constraints (free, horizontal only, vertical only), (2) create "when this 3D object starts dragging" handler for initialization, (3) use "when this 3D object is dragged" for continuous updates, (4) use "dragged 3D object name" reporter to identify which object. Students create a 3D room decorator where furniture can be dragged into position. Debug: object moves unexpectedly (wrong constraint mode), drag feels unnatural (missing position updates).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G5.05.01: Enable mouse picking and hovering for 3D objects in CreatiCode





ID: T29.G6.06.03
Topic: T29 – Devices & Hardware Systems
Skill: Create full-body gesture games with 2D body tracking
Description: Students use 2D body part recognition for full-body interactions. Tasks: (1) enable body tracking in single or multiple person modes, (2) read body part positions (head, shoulders, elbows, wrists, hips, knees, ankles), (3) calculate arm/leg curl values for pose detection, (4) track multiple people for multiplayer games. Students create a dance game where players match on-screen poses. Comparison: hand-only (precise finger control, close range) vs full-body (gross motor movements, active games). Debug: tracking loses player (person exits frame), wrong person tracked (multiple people).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T29.G4.06: Create keyboard-controlled interactions in CreatiCode
* T29.G5.06: Create face-tracking interactions in CreatiCode projects
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode





ID: T29.G6.07
Topic: T29 – Devices & Hardware Systems
Skill: Implement AR image tracking with anchor objects in CreatiCode
Description: Create augmented reality experiences that track physical images as anchors. Tasks: (1) use "switch to AR LOGO camera" block to enable image tracking mode, (2) configure camera selection (front/back) and scale settings, (3) position 3D objects relative to the detected image anchor, (4) handle marker visibility (show/hide tracking indicator). Create an AR business card that displays 3D content when the CreatiCode logo is detected. Compare image tracking vs world tracking: image anchoring is more stable but requires printed markers; world tracking works anywhere but may drift. Debug: image not detected (lighting, angle), objects misaligned (scale mismatch).

Dependencies:
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes
* T29.G6.05.01: Create AR effects with webcam backgrounds in CreatiCode
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects




ID: T29.G6.08
Topic: T29 – Devices & Hardware Systems
Skill: Create location-aware applications with geo info
Description: Build applications that use geographic context from device location. Tasks: (1) get latitude/longitude using reporter blocks, (2) use "get geo info" block to convert coordinates to place information (city, country, state), (3) display location context in UI (e.g., "You are in [city], [country]"), (4) change app behavior based on location (show local content, adjust language). Create a "World Explorer" app that shows facts about the user's current location. Privacy consideration: explain when apps should request location vs work without it. Debug: geo info returns empty (coordinates outside database coverage), slow lookup (network latency).

Dependencies:
* T29.G5.10: Implement device geolocation in CreatiCode projects
* T29.G6.03: Analyze privacy implications of camera and microphone permissions
* T29.G5.12: Design device-to-cloud data pipelines




ID: T29.G6.09
Topic: T29 – Devices & Hardware Systems
Skill: Create autonomous navigation using distance sensors
Description: Implement autonomous object movement using distance sensors for navigation. Tasks: (1) configure distance sensors in multiple directions (front, left, right), (2) implement obstacle avoidance logic (if obstacle ahead, turn), (3) create wall-following behavior (keep constant distance from wall), (4) implement path planning for simple mazes. Create a 3D robot that navigates through a maze autonomously using only distance sensor readings. Compare with real robotics: similarities (sensor-driven behavior) and differences (perfect sensors vs noise). Debug: robot gets stuck (corner cases), oscillating movement (threshold tuning).

Dependencies:
* T29.G5.11: Configure 3D distance sensors for obstacle detection
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode
* T08.G5.02: Combine conditionals with Boolean operators




ID: T29.G6.10
Topic: T29 – Devices & Hardware Systems
Skill: Profile sensor performance and diagnose failures
Description: Profile sensor performance to identify issues before they affect users. Tasks: (1) measure sensor latency (time from event to data available), (2) measure update frequency (readings per second), (3) identify dropped frames or missed data, (4) correlate performance with device load. Create a sensor benchmark tool that measures: camera fps, audio sample rate, face detection latency, GPS update speed. Establish baseline performance metrics. Diagnose: why does face detection slow down when background sprites are animating? How does battery level affect GPS accuracy?

Dependencies:
* T29.G5.15: Debug hardware connectivity issues systematically
* T29.G5.14: Process multi-dimensional sensor data arrays
* T29.G6.01: Interpret sensor specifications for CreatiCode project planning




ID: T29.G6.11
Topic: T29 – Devices & Hardware Systems
Skill: Implement multi-device sensor fusion for AR
Description: Students create an AR project that combines multiple sensor types for stable object placement. Fusion approach: (1) Camera provides visual anchoring (where is the marker?), (2) Motion sensors provide orientation (device tilt/rotation), (3) Combination creates stable AR objects that don't drift. Compare: AR with camera only (objects float/drift) vs AR with camera + motion sensors (objects stay anchored). Students implement and test both versions to experience the improvement from sensor fusion.

Dependencies:
* T29.G5.16: Combine two sensors for enhanced detection
* T29.G6.05.01: Create AR effects with webcam backgrounds in CreatiCode
* T29.G6.07: Implement AR image tracking with anchor objects in CreatiCode




ID: T29.G6.12
Topic: T29 – Devices & Hardware Systems
Skill: Analyze hardware versioning and backward compatibility
Description: Students research how CreatiCode features work differently on older vs newer devices. Compatibility research: (1) Older tablets (2018) may not support AR mode - why? (Missing gyroscope), (2) Some Chromebooks lack cameras - what features break?, (3) Older browsers may not support speech recognition API. Students create a device generation compatibility matrix and recommend minimum device specs for different project types.

Dependencies:
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects
* T29.G5.13: Understand AR camera modes and their hardware requirements




ID: T29.G6.13
Topic: T29 – Devices & Hardware Systems
Skill: Design sensor calibration procedures for users
Description: Students create user-friendly calibration workflows for sensor-based projects. Example calibration flow for body tracking game: (1) "Stand in front of camera", (2) "Raise both arms above your head", (3) "System is learning your arm length", (4) "Move left and right", (5) "Calibration complete!" Students design and test calibration with peers, iterating based on feedback. Key insight: good calibration instructions make projects work for many different users.

Dependencies:
* T29.G5.06: Create face-tracking interactions in CreatiCode projects
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode
* T29.G3.09: Calibrate sensor thresholds through experimentation




ID: T29.G6.14
Topic: T29 – Devices & Hardware Systems
Skill: Implement hardware safety warnings in CreatiCode projects
Description: Students add safety features to projects that use intensive hardware. Safety warnings: (1) AI processing: "Your device may get warm during extended use", (2) Long AR sessions: "Take a break for your eyes every 20 minutes", (3) High volume audio: "Lower volume to protect your hearing", (4) Flash effects: "Warning: this game contains flashing lights." Students add appropriate warnings to a project and implement "do not show again" checkbox for repeat users.

Dependencies:
* T29.G6.03: Analyze privacy implications of camera and microphone permissions
* T29.G5.02: Design device-handling procedures for classroom projects




ID: T29.G6.15
Topic: T29 – Devices & Hardware Systems
Skill: Compare edge AI vs cloud AI with actual measurements
Description: Students implement the same AI task using local processing vs cloud API and measure differences. Comparison experiment: (1) Local face detection (runs in browser) - measure: latency, works offline, (2) Cloud image analysis (API call) - measure: latency, needs internet, better accuracy. Create comparison table: Method | Latency (ms) | Works Offline | Privacy | Cost. Students determine when to use each approach based on project requirements.

Dependencies:
* T29.G5.12: Design device-to-cloud data pipelines
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects




ID: T29.G7.01
Topic: T29 – Devices & Hardware Systems
Skill: Profile and optimize CreatiCode project performance
Description: Use performance monitoring tools to identify and fix bottlenecks. Tasks: (1) use browser developer tools to monitor frame rate and CPU usage, (2) identify performance bottlenecks (too many sprites, AI processing frequency, large assets), (3) apply optimizations (reduce sprite count, lower AI update rate, compress images), (4) measure improvement quantitatively. Optimize a laggy project from 15fps to 60fps. Optimization strategies: sprite pooling, delayed AI updates, level-of-detail for distant objects. Document before/after metrics.

Dependencies:
* T29.G6.01: Interpret sensor specifications for CreatiCode project planning
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects





ID: T29.G7.02
Topic: T29 – Devices & Hardware Systems
Skill: Design sensor redundancy and fail-safe systems for CreatiCode
Description: Students design redundancy plans for when sensors fail. Tasks: (1) identify critical sensors for each feature, (2) design primary + backup input methods (camera → keyboard, voice → text input), (3) implement detection of sensor failure (permission denied, no data, timeout), (4) create automatic fallback switching. Students design a fail-safe system for a gesture game: primary (hand detection) → backup (keyboard) → emergency (mouse clicks). Document failure scenarios and recovery procedures.

Dependencies:
* T29.G6.01: Interpret sensor specifications for CreatiCode project planning
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects





ID: T29.G7.03
Topic: T29 – Devices & Hardware Systems
Skill: Implement graceful degradation for AI feature failures
Description: Students implement user-friendly degradation when AI features fail. Tasks: (1) design degradation levels (full AI → simplified AI → manual control), (2) implement smooth transitions between modes (no jarring changes), (3) provide clear user feedback about current mode and why, (4) maintain core functionality at all levels. Students implement degradation for a face-tracking game: Level 1 (face tracking) → Level 2 (mouse follow) → Level 3 (keyboard WASD). User messaging: "Camera unavailable - using mouse control instead."

Dependencies:
* T29.G7.02: Design sensor redundancy and fail-safe systems for CreatiCode
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects





ID: T29.G7.04
Topic: T29 – Devices & Hardware Systems
Skill: Analyze cloud vs edge processing trade-offs in CreatiCode AI
Description: Students analyze which AI tasks run locally (edge) vs in the cloud and justify placement decisions. Local/edge processing: camera feed display, basic motion detection, real-time sprite movement (low latency, works offline, private). Cloud processing: image generation, ChatGPT inference, advanced speech recognition (powerful AI, requires internet, usage costs). Students create a decision matrix for a voice assistant project: speech capture (edge), recognition (cloud), response generation (cloud), TTS output (edge). Analyze latency, privacy, cost, and offline implications.

Dependencies:
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects
* T29.G6.01: Interpret sensor specifications for CreatiCode project planning





ID: T29.G7.05
Topic: T29 – Devices & Hardware Systems
Skill: Evaluate privacy implications of AI-powered sensor systems
Description: Students evaluate privacy scenarios and propose ethical guidelines. Scenarios: (1) Voice assistant always listening for wake word - what data is captured? Where stored? Who can access? (2) Classroom face detection for attendance - consent issues, data retention, potential misuse. (3) Hand tracking in games - is gesture data personal information? Students develop a privacy checklist: when to request permission, what to disclose, how long to retain data, when to delete, who can access. Apply checklist to evaluate 3 CreatiCode AI project designs.

Dependencies:
* T29.G6.03: Analyze privacy implications of camera and microphone permissions
* T29.G5.03: Analyze sensor data types and sampling rates for CreatiCode projects





ID: T29.G7.06
Topic: T29 – Devices & Hardware Systems
Skill: Design responsive CreatiCode projects for mobile and desktop
Description: Students design projects that adapt to different device capabilities. Considerations: (1) Screen size: adjust UI layout, button sizes for touch vs mouse, (2) Input methods: touch gestures vs mouse clicks, virtual joystick vs keyboard, (3) Processing power: reduce AI frequency on mobile, lower quality on slow devices, (4) Camera position: selfie camera typical on mobile, webcam position varies on desktop. Students modify a desktop game to work well on mobile: add touch controls, optimize performance, adjust camera expectations. Test and document cross-device compatibility.

Dependencies:
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects
* T29.G5.05: Configure orbit cameras for 3D CreatiCode scenes





ID: T29.G7.07
Topic: T29 – Devices & Hardware Systems
Skill: Implement permission error handling for device access in CreatiCode
Description: Students implement robust error handling for permission denials. Tasks: (1) detect permission denied state vs timeout vs hardware missing, (2) display clear error messages explaining why permission is needed, (3) provide retry option for users who want to grant permission, (4) implement fallback functionality for users who decline. Students create a permission handling module: request → denied → explain why needed → offer alternative → user can retry or continue with fallback. Test with different denial scenarios.

Dependencies:
* T29.G7.03: Implement graceful degradation for AI feature failures





ID: T29.G7.08
Topic: T29 – Devices & Hardware Systems
Skill: Profile and diagnose AI processing bottlenecks in CreatiCode
Description: Profile AI-heavy projects to identify processing bottlenecks. Tasks: (1) measure time for each AI operation (face detection, speech recognition, image generation), (2) identify which operations block the main thread, (3) analyze cumulative processing load, (4) propose optimizations (reduce AI frequency, cache results, precompute). Profile a project using multiple AI features and create a bottleneck report: Operation | Time | Frequency | Optimization. Apply optimizations and measure improvement.

Dependencies:
* T29.G7.01: Profile and optimize CreatiCode project performance
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode




ID: T29.G7.09
Topic: T29 – Devices & Hardware Systems
Skill: Design AR face tracking experiences with mesh overlays in CreatiCode
Description: Create advanced AR face experiences using face mesh tracking. Tasks: (1) use "switch to AR face camera" block with mesh configuration options (face, eyes, mouth, lips), (2) enable face mesh overlay to visualize tracking points, (3) attach 3D objects to face mesh positions for filters/masks, (4) use face data table for detailed tracking (landmarks, expressions). Create a face filter app with glasses, hats, or masks that track facial movements. Compare face mesh AR vs simple face detection: mesh provides richer data but requires more processing. Debug: mesh flickering (low light), objects offset (wrong attachment point).

Dependencies:
* T29.G6.07: Implement AR image tracking with anchor objects in CreatiCode
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode
* T29.G5.06: Create face-tracking interactions in CreatiCode projects




ID: T29.G7.10
Topic: T29 – Devices & Hardware Systems
Skill: Train and deploy KNN classifiers with sensor data
Description: Train machine learning classifiers using live sensor data in CreatiCode. Tasks: (1) collect training data from sensors (hand positions, face landmarks, body poses), (2) label data with classification categories (gestures, expressions, poses), (3) use "create KNN classifier" block to train model, (4) use trained classifier to recognize new inputs in real-time. Create a custom gesture recognizer: collect 10 examples each of 3 hand gestures, train classifier, test recognition accuracy. Analyze: how does training data quality affect recognition accuracy? What happens with ambiguous gestures between classes?

Dependencies:
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode
* T29.G6.10: Profile sensor performance and diagnose failures
* T29.G5.14: Process multi-dimensional sensor data arrays




ID: T29.G7.11
Topic: T29 – Devices & Hardware Systems
Skill: Analyze hardware security vulnerabilities
Description: Students research common hardware security risks and propose mitigations. Vulnerabilities: (1) Camera/microphone unauthorized access - apps secretly recording, (2) Sensor spoofing - fake GPS location, manipulated sensor data, (3) Side-channel attacks - timing analysis, power consumption patterns, (4) USB device attacks - malicious devices pretending to be keyboards. Students evaluate: which vulnerabilities apply to CreatiCode projects? How do browser permissions help? What additional protections are needed for sensitive applications?

Dependencies:
* T29.G7.05: Evaluate privacy implications of AI-powered sensor systems
* T29.G7.07: Implement permission error handling for device access in CreatiCode




ID: T29.G7.12
Topic: T29 – Devices & Hardware Systems
Skill: Design device fleet management for classroom deployment
Description: Students plan how to deploy and maintain CreatiCode projects across a classroom of 30 devices. Fleet management tasks: (1) How to distribute project updates to all devices efficiently, (2) How to configure device settings uniformly, (3) How to monitor which devices have issues, (4) How to troubleshoot remotely. Students create a classroom deployment playbook: pre-class setup checklist, during-class monitoring plan, post-class cleanup procedures.

Dependencies:
* T29.G7.06: Design responsive CreatiCode projects for mobile and desktop
* T29.G6.04: Create device compatibility checklists for CreatiCode AI projects




ID: T29.G7.13
Topic: T29 – Devices & Hardware Systems
Skill: Implement hardware abstraction for cross-platform compatibility
Description: Students create an abstraction layer that hides device differences. Abstraction functions: (1) getPosition() - returns position from mouse on desktop, touch on mobile, joystick if connected, (2) playSound() - uses best available audio method, (3) showCamera() - handles permission request, fallback, error display. Students implement these abstractions and test on multiple device types. Key insight: abstraction makes code portable without rewriting for each device.

Dependencies:
* T29.G7.06: Design responsive CreatiCode projects for mobile and desktop
* T29.G5.17: Implement device-specific adaptations




ID: T29.G7.14
Topic: T29 – Devices & Hardware Systems
Skill: Analyze real-time processing requirements
Description: Students identify which CreatiCode features require real-time response and design latency budgets. Real-time requirements: (1) Game input response: <16ms for 60fps feel, (2) Audio synchronization: <50ms for perceived sync, (3) AI feedback: <200ms for responsive feel, (4) Network updates: <100ms for smooth multiplayer. Students create latency budgets for a multi-feature project: Total budget: 16ms. Allocation: Input (2ms) + Physics (3ms) + AI (5ms) + Render (6ms). Identify bottlenecks and propose optimizations.

Dependencies:
* T29.G7.01: Profile and optimize CreatiCode project performance
* T29.G5.18: Debug sensor timing and synchronization issues




ID: T29.G7.15
Topic: T29 – Devices & Hardware Systems
Skill: Design sensor redundancy for critical applications
Description: Students design redundant sensor systems for high-reliability projects. Redundancy levels: (1) Primary: hand gesture detection, (2) Secondary: keyboard shortcuts, (3) Tertiary: on-screen buttons. Implementation: each control method performs the same action, system auto-switches if one fails. Students implement a robust accessibility game that works even if camera breaks, keyboard malfunctions, or mouse disconnects. Test by disabling each input method.

Dependencies:
* T29.G7.02: Design sensor redundancy and fail-safe systems for CreatiCode
* T29.G7.03: Implement graceful degradation for AI feature failures




ID: T29.G7.16
Topic: T29 – Devices & Hardware Systems
Skill: Implement hardware performance profiling dashboard
Description: Students create a comprehensive performance monitoring tool. Dashboard displays: (1) Current FPS with color indicator (green >30, yellow 15-30, red <15), (2) Sensor update rates for each active sensor, (3) Memory usage estimate, (4) Time spent in each processing phase. Students use dashboard to identify performance problems: "Face detection taking 40ms causing frame drops." Implement recommendations: reduce AI frequency, optimize sprite count.

Dependencies:
* T29.G7.01: Profile and optimize CreatiCode project performance
* T29.G7.08: Profile and diagnose AI processing bottlenecks in CreatiCode
* T29.G6.10: Profile sensor performance and diagnose failures




ID: T29.G8.01
Topic: T29 – Devices & Hardware Systems
Skill: Design comprehensive device-cloud architecture for AI projects
Description: Design architecture diagrams balancing local and cloud processing. Architecture layers: (1) Device layer: sensors, display, local storage, (2) Processing layer: what runs locally vs cloud, (3) Communication layer: API calls, data formats, error handling, (4) Cloud layer: AI services, costs, rate limits. Design architecture for a comprehensive AI assistant: camera (local), face detection (local), ChatGPT reasoning (cloud), image generation (cloud), TTS (local). Optimize for: latency-critical paths, privacy-sensitive data, offline functionality, cost efficiency.

Dependencies:
* T29.G7.04: Analyze cloud vs edge processing trade-offs in CreatiCode AI
* T29.G7.01: Profile and optimize CreatiCode project performance
* T03.G6.01: Propose a module hierarchy for a medium project
* T04.G6.01: Group snippets by underlying algorithm pattern
* T09.G6.01: Model real-world quantities using variables and formulas





ID: T29.G8.02
Topic: T29 – Devices & Hardware Systems
Skill: Evaluate device sustainability and lifecycle impacts
Description: Research and evaluate the environmental impact of computing devices. Topics: (1) Energy consumption: device power usage, cloud processing energy cost, (2) E-waste: device lifespan, recycling options, toxic materials, (3) Supply chain: rare earth minerals, manufacturing conditions, transport emissions. Create a sustainability report for classroom devices: energy audit, lifespan estimate, recycling plan, sustainable alternatives. Propose 3 practices to reduce environmental impact while maintaining educational value.

Dependencies:
* T29.G7.01: Profile and optimize CreatiCode project performance
* T29.G7.04: Analyze cloud vs edge processing trade-offs in CreatiCode AI
* T10.G6.01: Sort a table by a column





ID: T29.G8.03
Topic: T29 – Devices & Hardware Systems
Skill: Create comprehensive hardware integration test plans
Description: Create test plans ensuring software works across diverse hardware configurations. Test dimensions: (1) Device types: desktop, laptop, tablet, phone, (2) OS/Browser versions: Chrome, Safari, Firefox across versions, (3) Peripherals: different cameras, microphones, input devices, (4) Edge cases: permissions denied, hardware disconnected, low battery. Create a test matrix: Device | Browser | Camera | Microphone | Expected Result | Actual Result. Execute tests and document compatibility findings with recommended minimum specs.

Dependencies:
* T29.G7.02: Design sensor redundancy and fail-safe systems for CreatiCode
* T29.G7.03: Implement graceful degradation for AI feature failures
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T31.G6.01: Identify common malware types
* T34.G6.01: Analyze hardware computing eras (mainframe → PC → mobile)





ID: T29.G8.04
Topic: T29 – Devices & Hardware Systems
Skill: Author hardware requirement playbooks for team projects
Description: Write comprehensive hardware playbooks for team replication. Playbook sections: (1) Hardware requirements: minimum and recommended specs, (2) Setup guide: step-by-step configuration with screenshots, (3) Troubleshooting: common issues and solutions, (4) Accessibility: alternative input options, accommodations, (5) Testing checklist: verification steps before deployment. Create a playbook for a complex CreatiCode AI project, test it with a peer who follows instructions, and iterate based on feedback. Final playbook enables anyone to replicate the setup.

Dependencies:
* T29.G8.03: Create comprehensive hardware integration test plans
* T29.G7.02: Design sensor redundancy and fail-safe systems for CreatiCode
* T04.G6.01: Group snippets by underlying algorithm pattern
* T07.G6.01: Trace nested loops with variable bounds
* T25.G6.01: Map stakeholder questions to data requirements




ID: T29.G8.05
Topic: T29 – Devices & Hardware Systems
Skill: Design multi-modal input systems combining multiple sensors
Description: Design systems that combine multiple input sensors for robust interaction. Multi-modal approaches: (1) Voice + gesture: speak command + point to target, (2) Face + hand: face for identity + hand for control, (3) Keyboard + camera: type for precision + camera for coarse control. Design a multi-modal interface for an accessibility-focused game: primary input (gesture), secondary input (voice), fallback (keyboard). Analyze benefits: redundancy, natural interaction, accessibility. Challenges: synchronization, conflict resolution, increased complexity.

Dependencies:
* T29.G7.08: Profile and diagnose AI processing bottlenecks in CreatiCode
* T29.G6.06: Create gesture-controlled games with hand detection in CreatiCode
* T29.G6.05.02: Implement continuous speech recognition for real-time voice input




ID: T29.G8.06
Topic: T29 – Devices & Hardware Systems
Skill: Evaluate sensor fusion architectures for enhanced AI interactions
Description: Evaluate architectures that fuse data from multiple sensors for enhanced accuracy. Sensor fusion concepts: (1) Complementary: sensors cover different aspects (camera + microphone for video call), (2) Redundant: same data from multiple sources (face position from face detection + body tracking), (3) Cooperative: sensors work together (camera identifies speaker + microphone captures their voice). Design and implement a sensor fusion system: combine face tracking + hand detection for a "point and click" interface. Measure accuracy improvement over single-sensor approach.

Dependencies:
* T29.G8.05: Design multi-modal input systems combining multiple sensors
* T29.G7.04: Analyze cloud vs edge processing trade-offs in CreatiCode AI
* T29.G6.06.03: Create full-body gesture games with 2D body tracking





ID: T29.G8.07
Topic: T29 – Devices & Hardware Systems
Skill: Design adaptive hardware interfaces using AI-assisted input prediction
Description: Design AI-enhanced interfaces that adapt to user behavior and preferences. Adaptive approaches: (1) Input prediction: AI predicts next action based on patterns (auto-complete gestures, anticipate menu selections), (2) Personalization: interface adapts to user's motor abilities (larger buttons for tremor, slower response for deliberate users), (3) Context awareness: switch input modes based on detected context (voice when hands busy, touch when quiet). Create an adaptive game controller that learns user preferences: track input patterns, adjust sensitivity/timing thresholds, offer personalized shortcuts. Evaluate: when does adaptation help vs confuse users? Design A/B test to measure effectiveness.

Dependencies:
* T29.G8.06: Evaluate sensor fusion architectures for enhanced AI interactions
* T29.G8.05: Design multi-modal input systems combining multiple sensors
* T29.G7.08: Profile and diagnose AI processing bottlenecks in CreatiCode




ID: T29.G8.08
Topic: T29 – Devices & Hardware Systems
Skill: Create neural network models for sensor classification
Description: Build and train neural network models using CreatiCode's TensorFlow blocks for sensor data classification. Tasks: (1) use "create NN model" to define network architecture (input layer matching sensor dimensions, hidden layers, output classes), (2) prepare training data from sensor readings (normalize, split train/test), (3) train model using "fit model" with appropriate epochs and batch sizes, (4) deploy trained model for real-time inference. Create a pose classifier: collect body tracking data for 5 different poses, train neural network, achieve >90% accuracy on test set. Compare KNN vs neural network: accuracy, training time, inference speed. Debug: model won't converge (learning rate), overfitting (too few examples).

Dependencies:
* T29.G7.10: Train and deploy KNN classifiers with sensor data
* T29.G8.05: Design multi-modal input systems combining multiple sensors
* T10.G7.01: Clean and preprocess data for analysis




ID: T29.G8.09
Topic: T29 – Devices & Hardware Systems
Skill: Design real-time systems with latency budgets
Description: Design hardware systems with explicit latency requirements and budgets. Real-time analysis: (1) identify latency-critical paths (user input to visual feedback), (2) measure latency at each stage (sensor capture, processing, rendering), (3) allocate latency budgets (sensor: 20ms, AI: 30ms, render: 16ms = 66ms total for 15fps), (4) optimize stages that exceed budget. Create a rhythm game requiring <100ms input latency: measure actual latency, identify bottlenecks, apply optimizations until target met. Compare soft real-time (games, interactive) vs hard real-time (safety systems). Document: latency requirements, measurement methodology, optimization strategies.

Dependencies:
* T29.G8.01: Design comprehensive device-cloud architecture for AI projects
* T29.G7.08: Profile and diagnose AI processing bottlenecks in CreatiCode
* T29.G6.10: Profile sensor performance and diagnose failures




ID: T29.G8.10
Topic: T29 – Devices & Hardware Systems
Skill: Implement edge AI deployment strategies
Description: Design and implement strategies for deploying AI models to edge devices. Edge deployment considerations: (1) model size constraints (memory limits on mobile), (2) inference speed requirements (real-time vs batch), (3) fallback strategies (cloud backup when edge fails), (4) model updates (versioning, hot-swapping). Implement a hybrid system: simple gesture recognition runs locally (fast, offline), complex natural language runs in cloud (powerful, requires connection). Compare edge-only vs cloud-only vs hybrid: latency, reliability, cost, privacy. Create deployment checklist: device compatibility, model optimization, offline testing, performance benchmarks.

Dependencies:
* T29.G8.08: Create neural network models for sensor classification
* T29.G8.01: Design comprehensive device-cloud architecture for AI projects
* T29.G7.04: Analyze cloud vs edge processing trade-offs in CreatiCode AI




ID: T29.G8.11
Topic: T29 – Devices & Hardware Systems
Skill: Implement simplified hardware abstraction layer (HAL)
Description: Students design and implement a hardware abstraction layer that provides uniform interface to different hardware. HAL components: (1) InputManager - abstracts keyboard, mouse, touch, gamepad into unified input events, (2) SensorManager - abstracts camera, microphone, GPS into unified sensor data streams, (3) OutputManager - abstracts screen, speakers into unified output channels. Students implement HAL for a game and test on multiple device types without changing game code. Discussion: how do real operating systems (Windows, iOS, Android) use HALs?

Dependencies:
* T29.G7.13: Implement hardware abstraction for cross-platform compatibility
* T29.G7.06: Design responsive CreatiCode projects for mobile and desktop




ID: T29.G8.12
Topic: T29 – Devices & Hardware Systems
Skill: Analyze real-time operating system concepts for sensor processing
Description: Students study simplified RTOS concepts and apply them to sensor data processing. RTOS principles: (1) Task priority - AI detection is high priority, logging is low priority, (2) Preemption - urgent sensor data can interrupt less important tasks, (3) Scheduling - ensure time-critical tasks get CPU time, (4) Interrupts - how hardware signals availability of new data. Students design a task schedule for a multi-sensor project that ensures smooth gameplay while running background AI. Compare RTOS approach to simple polling.

Dependencies:
* T29.G8.09: Design real-time systems with latency budgets
* T29.G7.14: Analyze real-time processing requirements




ID: T29.G8.13
Topic: T29 – Devices & Hardware Systems
Skill: Design sensor fusion algorithm for gesture recognition
Description: Students design a sophisticated gesture recognition system using multiple sensors. Fusion algorithm: (1) Camera hand tracking provides hand shape, (2) Microphone detects clap/snap sounds, (3) Device orientation (if available) adds context. Combined: "open palm + clap + device tilted forward" = specific command. Students implement and train the multi-sensor recognizer, compare accuracy to single-sensor approach. Document fusion algorithm decisions: which sensors contribute which information? How to handle conflicting signals?

Dependencies:
* T29.G8.08: Create neural network models for sensor classification
* T29.G8.06: Evaluate sensor fusion architectures for enhanced AI interactions
* T29.G6.11: Implement multi-device sensor fusion for AR




ID: T29.G8.14
Topic: T29 – Devices & Hardware Systems
Skill: Evaluate hardware lifecycle and e-waste impacts
Description: Students analyze the complete lifecycle of computing devices and propose sustainable practices. Lifecycle phases: (1) Manufacturing - raw materials, energy, factory conditions, (2) Distribution - shipping carbon footprint, (3) Usage - electricity consumption, upgrade cycles, (4) End-of-life - e-waste, recycling, toxic materials. Students create sustainability report for their classroom devices: estimate carbon footprint, identify recycling options, propose 3 changes to reduce environmental impact. Discussion: how do hardware choices affect our planet?

Dependencies:
* T29.G8.02: Evaluate device sustainability and lifecycle impacts
* T29.G4.10: Analyze power management in CreatiCode projects




ID: T29.G8.15
Topic: T29 – Devices & Hardware Systems
Skill: Design adaptive sensor sampling based on context
Description: Students implement intelligent sensor sampling that adapts to context. Adaptive strategies: (1) During active gameplay: high-frequency sensor updates (60 fps), (2) During menus/pauses: low-frequency updates (10 fps), (3) When app backgrounded: sensor shutdown to save battery, (4) When battery low: reduce AI update frequency. Students implement context-aware sampling and measure battery impact. Compare: naive always-on vs adaptive sampling for a 30-minute session.

Dependencies:
* T29.G8.09: Design real-time systems with latency budgets
* T29.G5.19: Measure and optimize sensor polling frequency
* T29.G4.10: Analyze power management in CreatiCode projects




ID: T29.G8.16
Topic: T29 – Devices & Hardware Systems
Skill: Implement hardware security best practices
Description: Students apply security principles to hardware-using projects. Security practices: (1) Minimal permissions - only request sensors actually needed, (2) Data protection - don't store sensitive sensor data longer than necessary, (3) Input validation - sanitize sensor inputs before processing, (4) Secure transmission - encrypt data sent to cloud, (5) Audit logging - track when sensors are accessed. Students perform security audit of existing project and implement improvements. Create security checklist for future hardware projects.

Dependencies:
* T29.G7.11: Analyze hardware security vulnerabilities
* T29.G8.10: Implement edge AI deployment strategies




ID: T29.G8.17
Topic: T29 – Devices & Hardware Systems
Skill: Design device fleet telemetry and analytics system
Description: Students design a telemetry system to collect performance data from deployed projects. Telemetry data: (1) Performance metrics - FPS, sensor latency, error rates, (2) Usage patterns - which features used most, session lengths, (3) Hardware info - device types, browser versions, available sensors. Analytics dashboard: aggregate data from 30 devices, identify trends, detect problems early. Students design telemetry for a classroom project: what to collect, how to visualize, how to use data to improve the project. Privacy consideration: anonymize device identification.

Dependencies:
* T29.G7.12: Design device fleet management for classroom deployment
* T29.G8.01: Design comprehensive device-cloud architecture for AI projects




ID: T30.GK.01
Topic: T30 – Internet & Cloud: Kindergarten
Skill: Sort devices into "connects to internet" vs "works alone" categories (picture-based)
Description: Students drag picture cards of devices (tablet showing video call, laptop with web browser, smart speaker, game console with multiplayer game, smart watch, alarm clock, flashlight) into two bins: "Uses Internet" and "Works Alone." Audio narration helps non-readers. They tap to hear what each device does.
CSTA: EK-SAS-NW-02

Dependencies:



ID: T30.GK.02
Topic: T30 – Internet & Cloud: Kindergarten
Skill: Match internet activities to devices (picture-based)
Description: Students see pictures of activities (watching videos, playing online games, video calling family) and match them to devices that can do those activities. They learn that different devices can connect to the same online services.
CSTA: EK-SAS-NW-02

Dependencies:
* T30.GK.01: Sort devices into "connects to internet" vs "works alone" categories (picture-based)



ID: T30.GK.03
Topic: T30 – Internet & Cloud: Kindergarten
Skill: Identify waiting signs for internet loading (picture-based)
Description: Students identify visual indicators of waiting for internet (spinning circles, loading bars, hourglass icons) in pictures and understand these mean "the internet is working to bring you something." They match loading icons to activities like watching videos or loading games.
CSTA: EK-SAS-NW-02

Dependencies:
* T30.GK.01: Sort devices into "connects to internet" vs "works alone" categories (picture-based)



ID: T30.GK.04
Topic: T30 – Internet & Cloud: Kindergarten
Skill: Recognize when things come from the internet vs the device (picture-based)
Description: Students view scenarios showing content from the internet (streaming a song, viewing a website) vs content stored on the device (photos in gallery, offline drawing app). They sort picture cards into "comes through internet" and "already on my device" categories.
CSTA: EK-SAS-NW-02

Dependencies:
* T30.GK.02: Match internet activities to devices (picture-based)



ID: T30.GK.05
Topic: T30 – Internet & Cloud: Kindergarten
Skill: Trace a message traveling between two devices (picture-based)
Description: Students arrange 3-4 picture cards in order showing: child taps "send" → message floats through the air/wires → grandma's tablet lights up → grandma reads message. They understand messages don't teleport instantly but travel through connections.
CSTA: EK-SAS-NW-02

Dependencies:
* T30.GK.03: Identify waiting signs for internet loading (picture-based)



ID: T30.G1.01
Topic: T30 – Internet & Cloud: Grade 1
Skill: Identify when a device is connected or disconnected (picture-based)
Description: Students examine pictures showing connectivity indicators (Wi-Fi symbol, "no connection" icon, loading spinner) and match them to scenarios like "playing an online game" vs "drawing offline." They predict what will work without internet.
CSTA: E1-SAS-NW-02

Dependencies:
* T30.GK.04: Recognize when things come from the internet vs the device (picture-based)



ID: T30.G1.02
Topic: T30 – Internet & Cloud: Grade 1
Skill: Sort activities by "needs internet" vs "works offline" (picture-based)
Description: Students sort picture cards of activities (playing music from device, streaming video, drawing pictures, playing online games with friends) into categories based on whether they need internet to work. They explain their reasoning using simple language.
CSTA: E1-SAS-NW-02

Dependencies:
* T30.G1.01: Identify when a device is connected or disconnected (picture-based)



ID: T30.G1.03
Topic: T30 – Internet & Cloud: Grade 1
Skill: Trace a simple message path with pictures (picture-based)
Description: Students arrange picture cards showing a message traveling: child sends message → message goes through air/wires → reaches another device → friend reads message. They understand messages travel from one place to another and need internet to get there. This expands on the simpler sequencing from Kindergarten.
CSTA: E1-SAS-NW-02

Dependencies:
* T30.GK.05: Trace a message traveling between two devices (picture-based)
* T30.G1.01: Identify when a device is connected or disconnected (picture-based)



ID: T30.G1.04
Topic: T30 – Internet & Cloud: Grade 1
Skill: Predict what happens when internet is slow or missing (picture-based)
Description: Students view scenarios and predict outcomes when internet is slow (video pauses and buffers, message takes longer to send) or missing (can't load new videos, can't send messages). They match scenarios to appropriate outcomes.
CSTA: E1-SAS-NW-02

Dependencies:
* T30.G1.02: Sort activities by "needs internet" vs "works offline" (picture-based)
* T30.G1.03: Trace a simple message path with pictures (picture-based)



ID: T30.G1.05
Topic: T30 – Internet & Cloud: Grade 1
Skill: Compare fast vs slow internet connections (picture-based)
Description: Students compare picture scenarios showing fast internet (video plays smoothly, game responds quickly) vs slow internet (spinner keeps spinning, video stops to "think"). They use a simple scale to match connection speed to user experience outcomes.
CSTA: E1-SAS-NW-02

Dependencies:
* T30.G1.04: Predict what happens when internet is slow or missing (picture-based)



ID: T30.G2.01
Topic: T30 – Internet & Cloud: Grade 2
Skill: Explain how the internet connects many computers (picture-based)
Description: Students view diagrams showing how computers, tablets, and phones connect through routers and cables to form a network. They identify components in simple network pictures and explain how devices communicate through connections.
CSTA: E2-SAS-NW-02

Dependencies:
* T30.G1.03: Trace a simple message path with pictures (picture-based)



ID: T30.G2.02
Topic: T30 – Internet & Cloud: Grade 2
Skill: Distinguish local storage vs cloud storage (picture-based)
Description: Students compare pictures showing data stored on a device (files in a folder on tablet) vs data stored in the cloud (files that appear on multiple devices). They sort examples into "only on this device" vs "saved in the cloud" and explain the difference.
CSTA: E2-SAS-NW-02

Dependencies:
* T30.G2.01: Explain how the internet connects many computers (picture-based)



ID: T30.G2.03
Topic: T30 – Internet & Cloud: Grade 2
Skill: Identify what information to keep private online (picture-based)
Description: Students discuss scenarios about keeping personal information private online. They identify which information should not be shared (full name, address, password, phone number) vs what is safe to share (favorite color, age-appropriate username, game scores). They explain why privacy matters.
CSTA: E2-SAS-SC-02

Dependencies:
* T30.G2.01: Explain how the internet connects many computers (picture-based)



ID: T30.G2.04
Topic: T30 – Internet & Cloud: Grade 2
Skill: Predict what happens when internet disconnects (picture-based)
Description: Students view scenarios (streaming video, typing in a cloud document, playing an offline game, saving to the cloud) and predict what happens if the internet suddenly stops. They match scenarios to outcomes (video stops, document can't save, game keeps working, save fails).
CSTA: E2-SAS-NW-02

Dependencies:
* T30.G2.01: Explain how the internet connects many computers (picture-based)
* T30.G1.05: Compare fast vs slow internet connections (picture-based)



ID: T30.G2.05
Topic: T30 – Internet & Cloud: Grade 2
Skill: Trace how sharing works over the internet (picture-based)
Description: Students arrange picture cards showing: student creates drawing → saves to cloud → friend opens on their device → both see the same drawing. They understand that the cloud stores things in the middle so multiple people can access them.
CSTA: E2-SAS-NW-02

Dependencies:
* T30.G2.02: Distinguish local storage vs cloud storage (picture-based)
* T30.G1.03: Trace a simple message path with pictures (picture-based)



ID: T30.G2.06
Topic: T30 – Internet & Cloud: Grade 2
Skill: Identify roles in online communication (picture-based)
Description: Students identify who is "sending" and who is "receiving" in communication scenarios (email, video call, multiplayer game). They understand that both sides need working internet and that communication requires a sender and receiver who take turns.
CSTA: E2-SAS-NW-02

Dependencies:
* T30.G2.05: Trace how sharing works over the internet (picture-based)



ID: T30.G3.01
Topic: T30 – Internet & Cloud: Grade 3
Skill: Trace a path from device to website through network components
Description: Students follow a visual diagram showing: device → router → internet service provider → internet backbone → server → back to device. They explain each step in simple terms and understand why each component is needed for web browsing to work.
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G2.01: Explain how the internet connects many computers (picture-based)



ID: T30.G3.02
Topic: T30 – Internet & Cloud: Grade 3
Skill: Label parts of URLs and explain how web addresses work
Description: Students examine URLs and label their parts (https://, domain name like "creaticode.com", path like "/projects"). They compare URLs to street addresses: domain name = city, path = street and house number. They predict which URLs lead to the same website based on matching domain names.
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G3.01: Trace a path from device to website through network components



ID: T30.G3.02.01
Topic: T30 – Internet & Cloud: Grade 3
Skill: Explain how domain names translate to computer addresses
Description: Students learn that computers use numerical addresses (IP addresses like 192.168.1.1) but people use friendly names (like creaticode.com). They understand DNS as a "phone book" that looks up the computer's address when you type a website name. They match domain names to their purpose (name-to-number lookup).
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G3.02: Label parts of URLs and explain how web addresses work



ID: T30.G3.03
Topic: T30 – Internet & Cloud: Grade 3
Skill: Categorize real-time vs delayed online communication
Description: Students categorize activities (email, video call, online multiplayer game, shared document, text message, forum post) by whether they need real-time internet connection or can work with delays. They explain why video calls need constant connection but emails can be sent and read at different times.
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G2.06: Identify roles in online communication (picture-based)
* T30.G3.01: Trace a path from device to website through network components



ID: T30.G3.04
Topic: T30 – Internet & Cloud: Grade 3
Skill: Compare saving locally vs saving to the cloud in CreatiCode
Description: Students observe how CreatiCode projects can be saved locally (download) vs saved to the cloud (publish/share). They explain the difference and when each is useful (cloud for sharing and accessing from multiple devices, local for backup and offline access).
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G2.02: Distinguish local storage vs cloud storage (picture-based)
* T30.G3.01: Trace a path from device to website through network components



ID: T30.G3.05
Topic: T30 – Internet & Cloud: Grade 3
Skill: Predict network behavior in different scenarios
Description: Students analyze scenarios (slow internet, disconnected Wi-Fi, server down, wrong URL) and predict what will happen (page loads slowly, error message appears, nothing loads, "not found" message). They match scenarios to appropriate outcomes and explain their reasoning.
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G3.01: Trace a path from device to website through network components
* T30.G2.04: Predict what happens when internet disconnects (picture-based)



ID: T30.G3.06
Topic: T30 – Internet & Cloud: Grade 3
Skill: Identify client and server roles in web communication
Description: Students learn that your device (client) asks for things and another computer (server) provides them. They label diagrams showing: client sends request → server processes request → server sends response → client displays result. They identify which computer is the client and which is the server in everyday scenarios.
CSTA: E3-SAS-NW-02

Dependencies:
* T30.G3.03: Categorize real-time vs delayed online communication



ID: T30.G4.01
Topic: T30 – Internet & Cloud: Grade 4
Skill: Explain how data travels across the internet in packets
Description: Students learn that data is broken into packets, sent separately across the internet, and reassembled at the destination. They simulate this by writing a message, splitting it into numbered pieces, having pieces travel different paths on a diagram, then reassembling in order.
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G3.01: Trace a path from device to website through network components
* T30.G3.06: Identify client and server roles in web communication



ID: T30.G4.02
Topic: T30 – Internet & Cloud: Grade 4
Skill: Identify secure vs insecure websites using HTTPS indicators
Description: Students recognize indicators of secure websites (https://, lock icon in browser) vs insecure websites (http://, no lock or warning). They understand why security matters when entering passwords or personal information online and practice identifying secure sites.
CSTA: E4-SAS-SC-03

Dependencies:
* T30.G3.02: Label parts of URLs and explain how web addresses work
* T30.G4.01: Explain how data travels across the internet in packets



ID: T30.G4.03
Topic: T30 – Internet & Cloud: Grade 4
Skill: Compare server storage vs device storage trade-offs
Description: Students compare what data is stored on servers (cloud saves, shared documents, online game progress) vs locally (downloaded files, offline games, cached data). They explain benefits of each (servers: accessible anywhere, sync across devices; local: works offline, private, faster access).
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G3.04: Compare saving locally vs saving to the cloud in CreatiCode
* T30.G4.01: Explain how data travels across the internet in packets



ID: T30.G4.04
Topic: T30 – Internet & Cloud: Grade 4
Skill: Trace what happens when sharing a CreatiCode project
Description: Students trace the steps when sharing a project: project data is sent → CreatiCode servers receive and store it → friend accesses URL → servers send project to friend's browser → friend sees and can remix. They explain why both users need internet and how the server acts as a middleman.
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G3.04: Compare saving locally vs saving to the cloud in CreatiCode
* T30.G4.01: Explain how data travels across the internet in packets



ID: T30.G4.05
Topic: T30 – Internet & Cloud: Grade 4
Skill: Debug common connectivity issues using scenario analysis
Description: Students analyze scenarios with connectivity problems (wrong Wi-Fi network, weak signal, incorrect URL, server maintenance) and identify the issue based on clues (error messages, symptoms, context). They propose solutions (check connection, try again later, verify URL, switch networks).
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G3.05: Predict network behavior in different scenarios
* T30.G4.01: Explain how data travels across the internet in packets



ID: T30.G4.06
Topic: T30 – Internet & Cloud: Grade 4
Skill: Predict behavior with slow or lost connections
Description: Students predict what happens in different scenarios when connections are slow (videos buffer, pages load partially, games lag) or lost completely (ongoing actions fail, cached content still works, reconnection attempts). They explain why some activities handle poor connections better than others.
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G4.01: Explain how data travels across the internet in packets
* T30.G3.03: Categorize real-time vs delayed online communication



ID: T30.G4.07
Topic: T30 – Internet & Cloud: Grade 4
Skill: Explain how multiple devices share one internet connection
Description: Students trace how multiple devices in a home or classroom share one internet connection through a router. They understand the router as a traffic director that sends each device's requests out and delivers responses back to the correct device. They predict what happens when too many devices use the same connection.
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G4.01: Explain how data travels across the internet in packets
* T30.G3.02.01: Explain how domain names translate to computer addresses



ID: T30.G4.08
Topic: T30 – Internet & Cloud: Grade 4
Skill: Compare different types of internet connections
Description: Students learn about different ways to connect to the internet (Wi-Fi, ethernet cable, cellular/mobile data) and compare their characteristics (speed, reliability, mobility, cost). They predict which connection type is best for different scenarios (gaming, travel, school).
CSTA: E4-SAS-NW-02

Dependencies:
* T30.G4.06: Predict behavior with slow or lost connections



ID: T30.G5.01
Topic: T30 – Internet & Cloud: Grade 5
Skill: Diagram and trace the request-response cycle in network communication
Description: Students diagram the request-response pattern: user action → client sends request → server processes → server sends response → client displays result. They trace real examples (loading a webpage, fetching game data) and predict what happens at each step. They identify latency as time between request and response.
CSTA: E5-SAS-NW-02

Dependencies:
* T30.G4.01: Explain how data travels across the internet in packets
* T30.G4.04: Trace what happens when sharing a CreatiCode project



ID: T30.G5.01.01
Topic: T30 – Internet & Cloud: Grade 5
Skill: Explain what happens during an HTTP request
Description: Students learn that HTTP is the language browsers and servers use to communicate. They identify the parts of a simple request (GET/POST method, URL, headers) and response (status code like 200 OK or 404 Not Found, data). They match common status codes to their meanings and predict what response a server might return.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.01: Diagram and trace the request-response cycle in network communication



ID: T30.G5.02
Topic: T30 – Internet & Cloud: Grade 5
Skill: Evaluate when apps need internet vs work offline
Description: Students evaluate scenarios (watching a downloaded movie, editing a shared doc, joining a multiplayer match, viewing cached news) and determine whether each requires connectivity. They justify their reasoning based on whether the task requires sending/receiving data from servers in real-time.
CSTA: MS-SAS-HW-02

Dependencies:
* T30.G5.01: Diagram and trace the request-response cycle in network communication
* T30.G4.03: Compare server storage vs device storage trade-offs



ID: T30.G5.03
Topic: T30 – Internet & Cloud: Grade 5
Skill: Fetch and display web content using "fetch web page as markdown" block
Description: Students use CreatiCode's "fetch web page as markdown from URL" block to retrieve content from a URL and display it. They trace the request-response cycle, predict what data will return, and debug issues when the fetch fails (wrong URL, network timeout, page not found).
CSTA: MS-SAS-NW-06

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T30.G5.01.01: Explain what happens during an HTTP request



ID: T30.G5.04
Topic: T30 – Internet & Cloud: Grade 5
Skill: Access user identity using "username", "user id", and "user avatar" blocks
Description: Students use CreatiCode's user identity reporter blocks ("username", "user id", "user avatar") to personalize their projects. They greet users by name, display avatars, and understand how servers identify different users through unique IDs.
CSTA: MS-SAS-NW-06

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T30.G5.01: Diagram and trace the request-response cycle in network communication



ID: T30.G5.05
Topic: T30 – Internet & Cloud: Grade 5
Skill: Create a multiplayer game session using "create game named" block
Description: Students use CreatiCode's "create game named [NAME] password [PWD] my name [HOST] role [ROLE] server [LOC] capacity (N) world width (W) height (H)" block to create a multiplayer game session. They understand the host creates a session on a server that others can join.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.04: Access user identity using "username", "user id", and "user avatar" blocks
* T06.G3.01: Build a green-flag script that runs a 3-5 block sequence



ID: T30.G5.06
Topic: T30 – Internet & Cloud: Grade 5
Skill: Join a multiplayer game using "join multiplayer game" block
Description: Students use CreatiCode's "join multiplayer game named [NAME] by host [HOST] from server [LOC] with password [PWD] my name [NAME] role [ROLE]" block to join an existing game session. They understand how the client connects to the host's session through the server acting as coordinator.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.05: Create a multiplayer game session using "create game named" block



ID: T30.G5.07
Topic: T30 – Internet & Cloud: Grade 5
Skill: List available multiplayer games using "list multiplayer games" block
Description: Students use CreatiCode's "list multiplayer games in server [LOC] in table [TABLE]" block to display all available games on the server, showing game names and host information to help users discover and join active game sessions.
CSTA: MS-SAS-NW-06

Dependencies:
* T10.G3.05: Loop through each item in a list
* T30.G5.05: Create a multiplayer game session using "create game named" block



ID: T30.G5.08
Topic: T30 – Internet & Cloud: Grade 5
Skill: Check multiplayer connection status using "connected to game" block
Description: Students use CreatiCode's "connected to game" boolean reporter block to check if they are connected to a multiplayer game and display appropriate messages (connecting, connected, disconnected) to guide users through the connection process.
CSTA: MS-SAS-HW-03

Dependencies:
* T08.G3.04: Use a simple if in a script
* T30.G5.06: Join a multiplayer game using "join multiplayer game" block



ID: T30.G5.09
Topic: T30 – Internet & Cloud: Grade 5
Skill: Debug multiplayer connection failures
Description: Students identify common multiplayer connection issues (wrong game name, incorrect password, server location mismatch, game at capacity) by examining error symptoms. They use the "connected to game" block to check status and systematically test different fixes.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.08: Check multiplayer connection status using "connected to game" block
* T30.G4.05: Debug common connectivity issues using scenario analysis



ID: T30.G5.10
Topic: T30 – Internet & Cloud: Grade 5
Skill: Trace data flow in multiplayer scenarios
Description: Students diagram how data flows in multiplayer games: player 1 action → client 1 sends to server → server broadcasts to all clients → other clients update. They label each step, identify which parts happen on clients vs server, and explain why the server is needed as a coordinator.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.06: Join a multiplayer game using "join multiplayer game" block
* T30.G5.01: Diagram and trace the request-response cycle in network communication



ID: T30.G5.11
Topic: T30 – Internet & Cloud: Grade 5
Skill: Explain why servers are needed for online features
Description: Students compare what a single device can do alone vs what requires a server (single player game vs multiplayer, local files vs cloud storage, offline app vs web app). They explain why servers enable sharing, persistence, and coordination between users, and identify which online features rely on servers.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.10: Trace data flow in multiplayer scenarios
* T30.G5.02: Evaluate when apps need internet vs work offline



ID: T30.G6.01
Topic: T30 – Internet & Cloud: Grade 6
Skill: Trace the steps of an HTTP/HTTPS request with encryption
Description: Students identify the sequence: client sends request → server processes → server sends response → client renders. For HTTPS, they explain that encryption protects data in transit from eavesdropping, like sealing a letter in an envelope. They identify this pattern in their fetch and multiplayer code.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.01.01: Explain what happens during an HTTP request
* T30.G5.03: Fetch and display web content using "fetch web page as markdown" block



ID: T30.G6.02
Topic: T30 – Internet & Cloud: Grade 6
Skill: Read and write data to Google Sheets from CreatiCode
Description: Students use CreatiCode's Google Sheets blocks to read data ("read from google sheet: url [URL] sheet name [SHEET] range [RANGE] into table [TABLE]") and write data ("write into google sheet: url [URL] sheet name [SHEET] start cell [CELL] from table [TABLE]"). They create a simple app that loads questions from a spreadsheet and saves user responses back, tracing the data flow from cloud to local and back.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption
* T09.G5.01: Create and use lists to organize data



ID: T30.G6.02.01
Topic: T30 – Internet & Cloud: Grade 6
Skill: Debug cloud data connection failures
Description: Students debug issues when data doesn't load from Google Sheets or cloud storage by systematically checking: URL correctness, sheet/key name spelling, sharing permissions, range format. They create a troubleshooting checklist and test each potential issue.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.02: Read and write data to Google Sheets from CreatiCode



ID: T30.G6.03
Topic: T30 – Internet & Cloud: Grade 6
Skill: Use cell-level Google Sheets operations for targeted updates
Description: Students use CreatiCode's cell-specific blocks ("set value to [VALUE] at row/column", "value at row/column", "append row") for precise data manipulation without overwriting entire ranges. They build a score tracker that reads a player's current best and updates only if a new high score is achieved.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.02: Read and write data to Google Sheets from CreatiCode



ID: T30.G6.04
Topic: T30 – Internet & Cloud: Grade 6
Skill: Manage cloud spreadsheet structure programmatically
Description: Students use CreatiCode's structural blocks (list/add/remove sheets, insert/remove rows and columns, clear sheet) to dynamically manage spreadsheet organization. They create a project that organizes data into separate sheets by category or creates new sheets on demand.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.03: Use cell-level Google Sheets operations for targeted updates



ID: T30.G6.05
Topic: T30 – Internet & Cloud: Grade 6
Skill: Measure and compare network latency effects
Description: Students use timer blocks to measure network latency when making cloud requests (fetch, multiplayer, cloud data). They record response times in a table, compare results across different request types, and propose strategies for handling slow responses (loading indicators, timeouts, cached data).
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption
* T30.G5.11: Explain why servers are needed for online features



ID: T30.G6.05.01
Topic: T30 – Internet & Cloud: Grade 6
Skill: Implement loading indicators for slow responses
Description: Students build loading indicators (progress bars, spinner animations, status messages) that display while waiting for cloud responses. They use the "connected to game" block or timer-based logic to show/hide indicators, improving user experience during network delays.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.05: Measure and compare network latency effects
* T08.G3.04: Use a simple if in a script



ID: T30.G6.06
Topic: T30 – Internet & Cloud: Grade 6
Skill: Classify data privacy risks when sharing cloud data
Description: Students review types of data that could be shared via cloud (usernames, game scores, chat messages, personal info, location data). They classify each by privacy risk level (low/medium/high) and explain which data should be public vs private. They apply this understanding when deciding between public and private options in cloud data blocks.
CSTA: MS-SAS-SC-09

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption
* T30.G4.02: Identify secure vs insecure websites using HTTPS indicators



ID: T30.G6.07
Topic: T30 – Internet & Cloud: Grade 6
Skill: Add and remove sprites in multiplayer games
Description: Students use CreatiCode's multiplayer sprite blocks ("add this sprite to game as [Dynamic/Static] [Rectangle/Circle]", "remove this sprite from game") to manage game objects in the shared world. They understand how sprites synchronize across players through the server and when to add/remove sprites.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.06: Join a multiplayer game using "join multiplayer game" block
* T30.G5.08: Check multiplayer connection status using "connected to game" block



ID: T30.G6.08
Topic: T30 – Internet & Cloud: Grade 6
Skill: Use "when added to game" event to initialize multiplayer sprites
Description: Students use CreatiCode's "when added to game" event hat block to execute initialization code when a sprite is successfully added to the multiplayer game world. They set up initial positions, costumes, or variables, understanding this event fires after successful server synchronization.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.07: Add and remove sprites in multiplayer games



ID: T30.G6.09
Topic: T30 – Internet & Cloud: Grade 6
Skill: List players in multiplayer game using "list players in game" block
Description: Students use CreatiCode's "list players in game [NAME] hosted by [HOST] from server [LOC] in table [TABLE]" block to display all players currently in a game session, useful for showing player lists, managing teams, or checking game state.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.07: List available multiplayer games using "list multiplayer games" block



ID: T30.G6.10
Topic: T30 – Internet & Cloud: Grade 6
Skill: Create and join cloud sessions for shared data
Description: Students use CreatiCode's cloud session blocks ("create cloud session [SESSION]", "join cloud session [SESSION]") to establish named sessions for storing and sharing data. They understand sessions allow multiple users to access the same cloud data space.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption
* T30.G5.04: Access user identity using "username", "user id", and "user avatar" blocks



ID: T30.G6.11
Topic: T30 – Internet & Cloud: Grade 6
Skill: Save and load cloud data with public/private visibility
Description: Students use CreatiCode's "save [public/private] data [VALUE] with name [KEY]" and "load data named [KEY]" blocks to store and retrieve data. They implement user preferences (private) vs shared leaderboards (public) and explain the difference between visibility options.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.10: Create and join cloud sessions for shared data
* T30.G6.06: Classify data privacy risks when sharing cloud data



ID: T30.G6.12
Topic: T30 – Internet & Cloud: Grade 6
Skill: Access Google Drive folder contents using "list content" block
Description: Students use CreatiCode's "list content of Google Drive folder [URL] in table [TABLE]" block to list files and folders from Google Drive, integrating cloud storage into their applications for accessing shared resources and user files.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.02: Read and write data to Google Sheets from CreatiCode



ID: T30.G6.13
Topic: T30 – Internet & Cloud: Grade 6
Skill: Read URL parameters to customize project behavior
Description: Students use CreatiCode's "read URL parameter [NAME]" reporter block to read parameters passed in the project URL (e.g., ?level=3&name=Alex), enabling customization through URL parameters. They build a project that changes behavior based on URL inputs.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption
* T30.G3.02: Label parts of URLs and explain how web addresses work



ID: T30.G6.14
Topic: T30 – Internet & Cloud: Grade 6
Skill: Design cloud-connected user interfaces with status feedback
Description: Students design interfaces that clearly show cloud connection status (connected/disconnected), loading states (fetching data), and data freshness (last updated). They apply UX principles to help users understand what's happening during cloud operations.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.05.01: Implement loading indicators for slow responses
* T30.G5.08: Check multiplayer connection status using "connected to game" block



ID: T30.G6.15
Topic: T30 – Internet & Cloud: Grade 6
Skill: Handle asynchronous cloud responses gracefully
Description: Students understand that cloud requests don't complete instantly. They implement patterns to handle async responses: display loading states, prevent duplicate requests (disable buttons while loading), show success/error messages, and ensure the UI remains responsive during network operations.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.05: Measure and compare network latency effects
* T30.G6.05.01: Implement loading indicators for slow responses



ID: T30.G6.16
Topic: T30 – Internet & Cloud: Grade 6
Skill: Explain the difference between synchronous and asynchronous operations
Description: Students contrast synchronous operations (program waits for result before continuing) with asynchronous operations (program continues while waiting, handles result when ready). They identify which cloud operations are async and explain why this matters for user experience and program design.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.15: Handle asynchronous cloud responses gracefully



ID: T30.G6.17
Topic: T30 – Internet & Cloud: Grade 6
Skill: Compare real-time vs polling data synchronization approaches
Description: Students compare two ways to keep data synchronized: polling (repeatedly checking for updates at intervals) vs real-time push (server notifies clients of changes). They identify trade-offs (polling: simpler but slower; real-time: faster but more complex) and choose appropriate approaches for different scenarios.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.15: Handle asynchronous cloud responses gracefully
* T30.G5.10: Trace data flow in multiplayer scenarios



ID: T30.G7.01
Topic: T30 – Internet & Cloud: Grade 7
Skill: Diagram client-server communication for multiplayer games
Description: Students create diagrams showing how a central server receives updates from each client and broadcasts them back. They label timing constraints, message ordering, and identify potential synchronization issues (what happens if two players act at the same time, or if messages arrive out of order).
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G6.07: Add and remove sprites in multiplayer games
* T30.G6.05: Measure and compare network latency effects



ID: T30.G7.02
Topic: T30 – Internet & Cloud: Grade 7
Skill: Synchronize sprite movement using "synchronously set speed" blocks
Description: Students use CreatiCode's "synchronously set speed x (X) y (Y)" and "synchronously set speed (SPEED) dir (DIR)" blocks to synchronize sprite positions across all players in a multiplayer game. They understand how movement data is transmitted in real-time and why synchronization prevents sprites from appearing in different places for different players.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.07: Add and remove sprites in multiplayer games



ID: T30.G7.03
Topic: T30 – Internet & Cloud: Grade 7
Skill: Broadcast multiplayer messages using "broadcast with parameter" block
Description: Students use CreatiCode's "broadcast [MSG] with parameter [PARAM] mode [MODE]" block to send messages with parameters to all players in a game session, enabling communication and game state updates across the network. They trace how messages propagate through the server to all clients.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.02: Synchronize sprite movement using "synchronously set speed" blocks



ID: T30.G7.04
Topic: T30 – Internet & Cloud: Grade 7
Skill: Handle sprite collisions using "when touching will trigger" block
Description: Students use CreatiCode's "when touching [SPRITE] will [stop/delete/continue] and trigger [MSG] with parameter [PARAM]" block to set up collision handlers for multiplayer sprites with different collision modes, enabling interactive multiplayer game mechanics that work consistently across all players.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.02: Synchronize sprite movement using "synchronously set speed" blocks



ID: T30.G7.05
Topic: T30 – Internet & Cloud: Grade 7
Skill: Reset multiplayer game world using "reset game world" block
Description: Students use CreatiCode's "reset game world" block to clear all sprites and reset the multiplayer game state, useful for starting new rounds or clearing the game between sessions. They understand this affects all connected clients.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.07: Add and remove sprites in multiplayer games



ID: T30.G7.05.01
Topic: T30 – Internet & Cloud: Grade 7
Skill: Build a complete multiplayer game loop
Description: Students combine multiplayer skills to build a complete game loop: create/join game → add sprites → synchronize movement → handle collisions → broadcast game events → reset for new rounds. They test with multiple players and trace the full data flow through the server.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.03: Broadcast multiplayer messages using "broadcast with parameter" block
* T30.G7.04: Handle sprite collisions using "when touching will trigger" block
* T30.G7.05: Reset multiplayer game world using "reset game world" block



ID: T30.G7.06
Topic: T30 – Internet & Cloud: Grade 7
Skill: Insert data into database collection using "insert from table" block
Description: Students use CreatiCode's "insert from table [TABLE] row from (START) to (END) into collection [COLLECTION]" block to insert rows from a table into a cloud database collection. They understand this stores data persistently that can be queried later, unlike session data which is temporary.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.11: Save and load cloud data with public/private visibility
* T09.G5.01: Create and use lists to organize data



ID: T30.G7.07
Topic: T30 – Internet & Cloud: Grade 7
Skill: Query and retrieve data from database collections
Description: Students use CreatiCode's "fetch from collection" block to retrieve filtered, sorted, and limited subsets of data. They design queries to answer questions like "find top 10 highest scores" or "list all players who joined today." They predict query results before running and debug when results don't match expectations.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.06: Insert data into database collection using "insert from table" block



ID: T30.G7.07.01
Topic: T30 – Internet & Cloud: Grade 7
Skill: Debug database query issues
Description: Students debug database queries that return unexpected results by checking: collection name spelling, query condition logic, field names, sort order, and limit values. They compare expected vs actual results and systematically isolate the issue.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.07: Query and retrieve data from database collections



ID: T30.G7.08
Topic: T30 – Internet & Cloud: Grade 7
Skill: Build database query conditions using comparison operator blocks
Description: Students use CreatiCode's database query condition blocks ("<cond [INPUT1] [COMPARATOR] [INPUT2]>") with operators (equals, not equals, greater than, less than, greater/less or equal) to build precise where clauses for fetching specific subsets of data from collections.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.07: Query and retrieve data from database collections



ID: T30.G7.09
Topic: T30 – Internet & Cloud: Grade 7
Skill: Build database query conditions using text search and logical operators
Description: Students use CreatiCode's database query blocks for text search ("<cond (field [NAME]) contains [TEXT]?>") and logical operators ("<cond <> and <>>" "<cond <> or <>>" "<cond not <>>") to build complex query conditions combining multiple criteria for sophisticated data filtering.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.08: Build database query conditions using comparison operator blocks



ID: T30.G7.09.01
Topic: T30 – Internet & Cloud: Grade 7
Skill: Design efficient queries to avoid over-fetching
Description: Students analyze data needs and design queries that fetch only required data by using specific field selections, appropriate limits, and precise conditions. They compare over-fetching (getting all data then filtering) vs efficient querying (filtering server-side) and measure performance differences.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.09: Build database query conditions using text search and logical operators
* T30.G6.05: Measure and compare network latency effects



ID: T30.G7.10
Topic: T30 – Internet & Cloud: Grade 7
Skill: Update database records using "update collection" blocks
Description: Students use CreatiCode's database update blocks ("update collection [COLLECTION] from table [TABLE]" and "update collection [COLLECTION] in-place where <COND> set (F1) to (V1) set (F2) to (V2)...") to modify existing documents with new values, managing persistent cloud data lifecycle.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.07: Query and retrieve data from database collections



ID: T30.G7.11
Topic: T30 – Internet & Cloud: Grade 7
Skill: Remove database records using "remove all documents" block
Description: Students use CreatiCode's "remove all documents from collection [COLLECTION] where <COND>" block to delete documents from collections based on query conditions, completing the full CRUD (Create, Read, Update, Delete) cycle. They understand the importance of careful condition checking before deletion.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.10: Update database records using "update collection" blocks



ID: T30.G7.11.01
Topic: T30 – Internet & Cloud: Grade 7
Skill: Explain the CRUD pattern for database operations
Description: Students identify and explain the four basic database operations: Create (insert), Read (query/fetch), Update (modify), Delete (remove). They map each CreatiCode database block to its CRUD category and explain when to use each operation in application design.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.11: Remove database records using "remove all documents" block



ID: T30.G7.12
Topic: T30 – Internet & Cloud: Grade 7
Skill: Handle concurrent database updates
Description: Students explore what happens when multiple users update the same database record simultaneously. They identify race conditions and implement strategies to handle conflicts: read-modify-write with version checking, or timestamp-based conflict detection. They test with multiple browser windows.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.10: Update database records using "update collection" blocks
* T30.G7.01: Diagram client-server communication for multiplayer games



ID: T30.G7.13
Topic: T30 – Internet & Cloud: Grade 7
Skill: Use database field and collection name reporter blocks
Description: Students use CreatiCode's reporter blocks ("field [NAME]" and "collection [NAME]") to dynamically reference database fields and collections in their queries, enabling more flexible and reusable database code that can work with different collections or fields.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.07: Query and retrieve data from database collections



ID: T30.G7.14
Topic: T30 – Internet & Cloud: Grade 7
Skill: Record and display game leaderboards
Description: Students use CreatiCode's leaderboard blocks ("record player score", "show game leaderboard [highest/lowest] rows [N]") to build competitive game features. They trace how scores flow from client to server database to display, and understand how the server maintains score rankings across all players.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G5.04: Access user identity using "username", "user id", and "user avatar" blocks
* T30.G7.07: Query and retrieve data from database collections



ID: T30.G7.15
Topic: T30 – Internet & Cloud: Grade 7
Skill: Manage leaderboard data using "hide", "clear", and "remove" blocks
Description: Students use CreatiCode's leaderboard management blocks ("hide game leaderboard", "clear scores for [my scores/all users]", "remove player score for [NAME] with score between [LOW] and [HIGH]") to control leaderboard visibility and data, implementing features like score reset or cheater removal.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.14: Record and display game leaderboards



ID: T30.G7.16
Topic: T30 – Internet & Cloud: Grade 7
Skill: Store and read user data using "store user data" and "read user data" blocks
Description: Students use CreatiCode's "store user data key [KEY] value [VALUE]" and "read user data key [KEY]" blocks to save and retrieve user-specific data (preferences, settings, progress) that persists across sessions and is private to each user. They compare this to public cloud data.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G6.11: Save and load cloud data with public/private visibility



ID: T30.G7.17
Topic: T30 – Internet & Cloud: Grade 7
Skill: Analyze trade-offs between network topologies
Description: Students diagram physical and logical network topologies (star, mesh, and peer-to-peer), labeling how nodes are arranged and connected. They create a comparison table evaluating trade-offs in latency, resilience, and implementation complexity for each topology type. They explain when each topology is appropriate.
CSTA: MS-SAS-NW-04

Dependencies:
* T30.G6.01: Trace the steps of an HTTP/HTTPS request with encryption



ID: T30.G7.18
Topic: T30 – Internet & Cloud: Grade 7
Skill: Differentiate client-server from peer-to-peer architecture
Description: Students diagram the architectural differences between centralized client-server models (like CreatiCode's multiplayer system) and peer-to-peer approaches. They create a comparison chart analyzing trade-offs including latency, trust/authority, scalability, and ease of implementation.
CSTA: MS-SAS-NW-04

Dependencies:
* T30.G7.17: Analyze trade-offs between network topologies



ID: T30.G7.19
Topic: T30 – Internet & Cloud: Grade 7
Skill: Analyze societal impacts of networked systems
Description: Students research societal impacts of networked tools: (1) Benefits like enabling collaboration, expanding access to information, and connecting communities; (2) Harms like privacy loss, misinformation spread, and digital divide. They provide real examples and propose mitigation strategies for negative impacts.
CSTA: MS-SAS-IM-11

Dependencies:
* T30.G6.06: Classify data privacy risks when sharing cloud data
* T30.G7.18: Differentiate client-server from peer-to-peer architecture



ID: T30.G7.20
Topic: T30 – Internet & Cloud: Grade 7
Skill: Explain cloud computing service models (IaaS, PaaS, SaaS)
Description: Students compare cloud service models: Infrastructure as a Service (rent servers/storage), Platform as a Service (rent development environment), Software as a Service (use web apps). They classify real examples (AWS EC2, Heroku, Google Docs) and identify which model CreatiCode's cloud features most resemble.
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G7.18: Differentiate client-server from peer-to-peer architecture
* T30.G6.11: Save and load cloud data with public/private visibility



ID: T30.G8.01
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design edge vs cloud processing pipelines
Description: Students diagram which computations should happen locally/edge (fast response, privacy-sensitive) vs in the cloud (resource-intensive, shared data). They apply this to real scenarios: image recognition (edge for privacy), leaderboards (cloud for sharing), game physics (edge for speed), AI processing (cloud for power).
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G7.18: Differentiate client-server from peer-to-peer architecture
* T30.G7.19: Analyze societal impacts of networked systems
* T30.G6.05: Measure and compare network latency effects



ID: T30.G8.02
Topic: T30 – Internet & Cloud: Grade 8
Skill: Analyze bandwidth and latency requirements for cloud applications
Description: Students estimate bandwidth and latency needs for different cloud features (real-time multiplayer: low latency/medium bandwidth; file upload: high bandwidth/moderate latency; chat: low both; video streaming: high bandwidth/low latency). They document requirements and explain how network constraints affect design choices.
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G8.01: Design edge vs cloud processing pipelines
* T30.G7.01: Diagram client-server communication for multiplayer games



ID: T30.G8.03
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design security measures for cloud data handling
Description: Students outline security measures for cloud applications: authentication (who can access), authorization (what they can do), encryption (protecting data in transit and at rest), and input validation (preventing malicious data). They apply these to multiplayer games, leaderboards, and cloud storage scenarios.
CSTA: MS-SAS-SC-09

Dependencies:
* T30.G7.19: Analyze societal impacts of networked systems
* T30.G8.02: Analyze bandwidth and latency requirements for cloud applications
* T30.G6.06: Classify data privacy risks when sharing cloud data



ID: T30.G8.04
Topic: T30 – Internet & Cloud: Grade 8
Skill: Implement data anonymization for cloud storage
Description: Students implement techniques to protect user privacy when storing cloud data: removing personally identifiable information, using hashed user IDs instead of names, aggregating data before sharing. They apply these to leaderboards and usage statistics, balancing functionality with privacy.
CSTA: MS-SAS-SC-09

Dependencies:
* T30.G8.03: Design security measures for cloud data handling
* T30.G7.16: Store and read user data using "store user data" and "read user data" blocks



ID: T30.G8.05
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design fallback strategies for cloud service failures
Description: Students identify failure scenarios for cloud dependencies (server downtime, slow network, disconnection, API rate limits) and implement graceful degradation strategies. They code fallback behaviors: showing cached data when offline, displaying loading states, and providing manual alternatives when cloud features fail.
CSTA: MS-SAS-HW-03

Dependencies:
* T30.G8.02: Analyze bandwidth and latency requirements for cloud applications
* T30.G6.11: Save and load cloud data with public/private visibility
* T08.G6.01: Use if/else conditionals in different contexts



ID: T30.G8.06
Topic: T30 – Internet & Cloud: Grade 8
Skill: Build cloud service monitoring dashboards
Description: Students create monitoring dashboards that track cloud service usage (request counts, response times, error rates, data storage size). They use variables and UI widgets to display metrics and implement alerts when thresholds are exceeded. They explain how monitoring helps maintain reliable cloud applications.
CSTA: MS-SAS-IM-11

Dependencies:
* T30.G8.04: Implement data anonymization for cloud storage
* T30.G8.05: Design fallback strategies for cloud service failures
* T30.G6.05: Measure and compare network latency effects



ID: T30.G8.07
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design API request patterns for efficient data access
Description: Students analyze different API request patterns (polling vs event-driven updates, batching vs individual requests, caching strategies). They implement a project that minimizes cloud calls by caching data locally, batching multiple updates, and refreshing only when necessary. They measure and compare request counts and response times for different approaches.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.02: Analyze bandwidth and latency requirements for cloud applications
* T30.G6.17: Compare real-time vs polling data synchronization approaches



ID: T30.G8.08
Topic: T30 – Internet & Cloud: Grade 8
Skill: Implement data synchronization conflict resolution
Description: Students identify scenarios where multiple users edit the same data simultaneously (collaborative documents, multiplayer game state). They implement conflict resolution strategies: last-write-wins, merge changes, or reject conflicts with user notification. They test their implementation by simulating concurrent edits from multiple browser windows.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.12: Handle concurrent database updates
* T30.G7.10: Update database records using "update collection" blocks



ID: T30.G8.09
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design scalable data structures for cloud storage
Description: Students compare flat vs hierarchical data organization for different use cases (user profiles: flat, comment threads: hierarchical, game inventories: nested lists). They implement both approaches for a sample application and analyze trade-offs in query complexity, storage efficiency, and ease of updates.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.06: Insert data into database collection using "insert from table" block
* T30.G7.11.01: Explain the CRUD pattern for database operations



ID: T30.G8.10
Topic: T30 – Internet & Cloud: Grade 8
Skill: Analyze rate limiting and quota management for cloud services
Description: Students explain why cloud services implement rate limits (preventing abuse, ensuring fair access, managing server load). They implement request tracking in their projects, display remaining quota, and handle rate limit responses gracefully by queuing requests or displaying user-friendly wait messages.
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G8.07: Design API request patterns for efficient data access
* T30.G8.05: Design fallback strategies for cloud service failures



ID: T30.G8.11
Topic: T30 – Internet & Cloud: Grade 8
Skill: Compare cloud deployment regions and their trade-offs
Description: Students analyze how server location affects latency for users in different geographic regions. They measure response times to different server locations (or simulate with timers), create a visualization of latency differences, and explain when to choose specific regions (user proximity, data residency requirements, redundancy for reliability).
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G8.02: Analyze bandwidth and latency requirements for cloud applications
* T30.G7.17: Analyze trade-offs between network topologies



ID: T30.G8.12
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design event-driven cloud architectures
Description: Students diagram event-driven patterns where actions trigger cloud responses (user action → event → cloud processing → notification to other users). They implement a project using cloud broadcasts and data change events to create reactive applications where multiple components respond to shared state changes automatically.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.03: Broadcast multiplayer messages using "broadcast with parameter" block
* T30.G6.11: Save and load cloud data with public/private visibility



ID: T30.G8.13
Topic: T30 – Internet & Cloud: Grade 8
Skill: Design cloud-first application architectures
Description: Students design complete applications that leverage cloud capabilities from the start: data storage in cloud databases, user authentication, real-time multiplayer features, and cloud-based AI. They create architecture diagrams showing which components run on client vs server, data flow patterns, and explain architectural decisions.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.01: Design edge vs cloud processing pipelines
* T30.G8.12: Design event-driven cloud architectures



ID: T30.G8.14
Topic: T30 – Internet & Cloud: Grade 8
Skill: Analyze real-world cloud service trade-offs
Description: Students research real cloud services (AWS, Google Cloud, Azure, CDNs) and analyze their trade-offs: cost vs performance, latency vs geographic coverage, ease of use vs customization, vendor lock-in vs integration. They propose which service to use for specific scenarios and justify their reasoning.
CSTA: MS-SAS-NW-05

Dependencies:
* T30.G8.11: Compare cloud deployment regions and their trade-offs
* T30.G7.20: Explain cloud computing service models (IaaS, PaaS, SaaS)



ID: T30.G8.15
Topic: T30 – Internet & Cloud: Grade 8
Skill: Implement retry logic with exponential backoff
Description: Students implement retry strategies for failed cloud requests: retry failed requests with increasing delays (exponential backoff), limit retry attempts, distinguish transient failures (retry) from permanent failures (show error). They test by simulating network failures and measure retry behavior.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.05: Design fallback strategies for cloud service failures
* T30.G8.10: Analyze rate limiting and quota management for cloud services



ID: T30.G8.16
Topic: T30 – Internet & Cloud: Grade 8
Skill: Debug complex multi-user scenarios
Description: Students debug issues that only occur with multiple concurrent users: race conditions, data inconsistencies, synchronization bugs, message ordering problems. They use logging, state inspection, and multiple browser windows to reproduce and diagnose issues. They implement fixes and verify with multi-user testing.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.08: Implement data synchronization conflict resolution
* T30.G7.01: Diagram client-server communication for multiplayer games



ID: T30.G8.17
Topic: T30 – Internet & Cloud: Grade 8
Skill: Create semantic database using "create semantic database from table" block
Description: Students use CreatiCode's "create semantic database from table [TABLE]" block to create a semantic database from a table of text content, enabling AI-powered search capabilities. They understand this creates vector embeddings that capture meaning for similarity-based search rather than exact matches.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G7.06: Insert data into database collection using "insert from table" block
* T30.G8.09: Design scalable data structures for cloud storage



ID: T30.G8.18
Topic: T30 – Internet & Cloud: Grade 8
Skill: Search semantic database for AI-powered content retrieval
Description: Students use CreatiCode's semantic search blocks ("search semantic database with [QUERY]", "search with where [CONDITION]") to find content by meaning rather than exact text matches. They compare semantic search results to traditional queries and explain when AI-powered search provides better results.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.17: Create semantic database using "create semantic database from table" block



ID: T30.G8.19
Topic: T30 – Internet & Cloud: Grade 8
Skill: Build a complete cloud-backed application
Description: Students design and implement a complete cloud-backed application combining multiple T30 skills: cloud data storage, database queries, user identity, multiplayer features or shared data, proper error handling, and user feedback. They document their architecture decisions and test with multiple users.
CSTA: MS-SAS-NW-06

Dependencies:
* T30.G8.13: Design cloud-first application architectures
* T30.G8.16: Debug complex multi-user scenarios
* T30.G8.15: Implement retry logic with exponential backoff


## Topic T31 - Cybersecurity & Digital Safety

ID: T31.GK.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Sort information into safe-to-share vs keep-private categories
Description: Students sort illustrated cards showing different types of information (favorite color, favorite food, pet's name vs home address, phone number, parents' names) into "OK to share with friends" and "Keep private" bins. They practice the phrase "Ask a trusted adult first" when unsure. Focus is on recognizing that some information is special and needs protection.




ID: T31.GK.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify when to stop and tell an adult online
Description: Students hear short audio-narrated scenario stories with picture scenes (stranger in chat asking for photo, pop-up with scary message, someone asking where they live) and select the correct response: stop using the device and tell a trusted adult.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.GK.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare short vs long passwords using visual length
Description: Students compare visual representations of passwords using picture-based length comparisons. They see a short password shown as "cat" (3 boxes) vs a longer password shown with 8+ boxes containing mixed symbols (letters, numbers, special characters). They point to which password is harder to guess based on visual length and variety.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.GK.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Sort activities into online vs offline categories and identify consequences
Description: Students drag picture cards showing activities (playing outside, watching videos on tablet, reading a paper book, video calling grandma, drawing with crayons, playing a phone game) into "Uses Internet" and "No Internet Needed" boxes. They count how many activities in each category. They match consequence pictures (talking to strangers online, screen hurting eyes, losing game progress) to online activities to build awareness of online activity implications.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.GK.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Match devices to lock symbols
Description: Students see pictures of devices (phone, tablet, computer, game console) and match each to a "lock" picture to show that devices need protection. They discuss why we lock devices like we lock doors to our home.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.GK.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify pictures that are safe vs unsafe to share online
Description: Students sort picture cards showing different types of images (drawing they made, photo of their pet, photo showing their house number, picture with their school name visible, family photo with faces, picture of their favorite toy) into "Safe to share" and "Ask adult first" bins. They learn that pictures can accidentally reveal private information.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.GK.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Sort pictures of AI helpers vs regular computer programs
Description: Students look at illustrated cards showing different types of computer helpers (calculator app, voice assistant like Siri, game character following set rules, chatbot that answers questions) and sort them into "AI Helper - Can Learn" vs "Regular Program - Same Every Time" categories. They use picture clues (brain symbol for AI, gear symbol for regular programs). This builds foundation for understanding AI as a distinct technology.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.G1.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain why some personal information must stay private
Description: Students drag information cards into two columns: "Private - Don't Share Online" (full name, address, phone number, birthday, school name, family photos) vs "OK to Share" (favorite color, favorite animal, hobby). They match each private item to a consequence picture card showing what could go wrong if shared (stranger finds home, identity stolen, unsafe situation). Focus on understanding WHY information needs protection, not just which information.

Dependencies:
* T31.GK.01: Sort information into safe-to-share vs keep-private categories




ID: T31.G1.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify trusted vs unknown contacts in chat scenarios
Description: Students view illustrated chat message scenarios with visual cues (green border = known friend/family, red border = stranger/unknown). For each scenario, they select the correct action: "Reply" (for trusted contacts) or "Don't reply and tell adult" (for unknowns). Audio narration supports non-readers.

Dependencies:
* T31.G1.01: Explain why some personal information must stay private
* T31.GK.02: Identify when to stop and tell an adult online




ID: T31.G1.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Select correct password behaviors from picture scenarios
Description: Students see illustrated scenarios showing password behaviors and mark each as safe (checkmark) or unsafe (X): sharing password with friend (X), typing password when alone (check), writing password on sticky note on screen (X), telling only parent (check). They sequence picture cards showing consequences of password sharing.

Dependencies:
* T31.G1.01: Explain why some personal information must stay private
* T31.GK.03: Compare short vs long passwords using visual length




ID: T31.G1.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Label pop-up messages as real or scam using visual clues
Description: Students see illustrated pop-up windows with exaggerated visual red flags and drag them to "Real" or "Scam" boxes. Scam indicators include: giant flashy prize images, cartoon money bags, excessive exclamation marks, "YOU WON!" in bright colors. Real messages show calm icons and simple text. Focus on visual pattern recognition, not reading.

Dependencies:
* T31.G1.01: Explain why some personal information must stay private
* T31.GK.02: Identify when to stop and tell an adult online




ID: T31.G1.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace what happens when sharing private information
Description: Students follow a simple visual story sequence: Child shares home address online → Stranger now knows where they live → Consequence (worried family). They put picture cards in order showing cause and effect of sharing private information, then identify the mistake in the sequence.

Dependencies:
* T31.G1.01: Explain why some personal information must stay private




ID: T31.G1.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify when apps ask for permission using picture cards
Description: Students look at illustrated permission request screens (app wants camera, app wants location, app wants contacts) and sort them into "Ask adult first" vs "Probably OK" categories. They practice saying "Let me ask a grown-up" when seeing permission requests. Focus on recognizing that apps asking for things is a signal to pause and check.

Dependencies:
* T31.G1.01: Explain why some personal information must stay private
* T31.GK.02: Identify when to stop and tell an adult online




ID: T31.G1.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Recognize that AI assistants can make mistakes using picture scenarios
Description: Students view illustrated scenarios showing AI assistants giving both correct and incorrect answers (AI correctly names an animal in a photo vs AI thinking a dog is a cat, AI giving good homework help vs AI making up a wrong fact). They sort scenarios into "AI Got It Right" vs "AI Made a Mistake" categories. They learn that AI helpers are not always correct and should ask adults when unsure. Visual indicators show confused AI with question marks for mistakes.

Dependencies:
* T31.GK.07: Sort pictures of AI helpers vs regular computer programs
* T31.GK.02: Identify when to stop and tell an adult online




ID: T31.G2.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a stronger password using a template
Description: Students use a guided word-building template to create a practice password: pick an animal (dog) + add a number (7) + add a symbol (!). They compare their result (dog7!) to weak passwords (dog, 123) and count how many more characters and variety their password has. They draw a memory picture to help remember their password pattern.

Dependencies:
* T31.G1.03: Select correct password behaviors from picture scenarios




ID: T31.G2.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Sequence the steps to log off a shared device
Description: Students arrange picture cards in correct order showing logout steps: (1) Save work, (2) Click user icon, (3) Select "Log Out", (4) Verify logged out. They explain what could happen if they skip logout (next person sees their account, can change their work, can pretend to be them).

Dependencies:
* T31.G1.01: Explain why some personal information must stay private
* T31.GK.05: Match devices to lock symbols




ID: T31.G2.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Choose kind vs unkind responses to online messages
Description: Students see illustrated chat scenarios with mean or hurtful messages and select the best response from picture options: ignore the message, tell a trusted adult, report the message, or send a kind reply. They mark responses that make things worse (arguing back, sharing the message widely) with X.

Dependencies:
* T31.G1.02: Identify trusted vs unknown contacts in chat scenarios




ID: T31.G2.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Match device care actions to safety reasons
Description: Students draw lines connecting device care pictures (keeping password hidden, not leaving tablet unattended, using device near adults, keeping screen clean) to matching "why it helps" cards (stops others from seeing password, prevents theft, adult can help if something bad happens). They sort actions into "keeps me safe" vs "doesn't help safety."

Dependencies:
* T31.G2.02: Sequence the steps to log off a shared device




ID: T31.G2.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Predict consequences of clicking suspicious links
Description: Students view illustrated "What happens next?" scenarios: a character sees a flashing "Click here for free prize!" link. They sequence picture cards showing consequences (fake website appears, asks for password, account gets stolen). They identify warning signs before clicking and select "Don't click - ask adult first."

Dependencies:
* T31.G1.04: Label pop-up messages as real or scam using visual clues




ID: T31.G2.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare usernames vs passwords using analogy pictures
Description: Students match analogy pictures: username = name badge you wear (others can see) vs password = secret handshake (only you know). They categorize example items as "like a username" (can share) or "like a password" (keep secret). They identify which part of "Player1 / abc123" is the username vs password.

Dependencies:
* T31.G2.01: Build a stronger password using a template




ID: T31.G2.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify safe vs unsafe websites using visual clues
Description: Students look at simplified browser screenshots and point to safety clues: padlock icon (safe), "https" at start (safe), misspelled website name (unsafe), no padlock (be careful). They sort website screenshots into "looks safe" and "ask adult first" categories.

Dependencies:
* T31.G2.05: Predict consequences of clicking suspicious links




ID: T31.G2.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Match app permission types to what they can access
Description: Students connect picture cards of permission types (camera icon, location pin, microphone icon, contact book icon) to what the app could see or do (take photos, know where you are, hear what you say, see your friends list). They sort permissions into "This app needs it" vs "Why would it need this?" for sample apps (photo app wants camera = makes sense, flashlight app wants contacts = suspicious).

Dependencies:
* T31.G1.06: Identify when apps ask for permission using picture cards
* T31.G2.04: Match device care actions to safety reasons




ID: T31.G2.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify healthy vs unhealthy screen time habits using picture scenarios
Description: Students sort illustrated scenario cards into "Healthy Screen Time" vs "Unhealthy Screen Time" categories: playing outside before screen time (healthy), using tablet for 4 hours without breaks (unhealthy), doing homework first (healthy), staying up late on phone (unhealthy), watching videos with family (healthy), ignoring friends to play games (unhealthy). They count scenarios in each category and discuss why balance matters. Picture cards show visual cues like tired eyes, happy outdoor play, family together.

Dependencies:
* T31.GK.04: Sort activities into online vs offline categories and identify consequences
* T31.G2.04: Match device care actions to safety reasons




ID: T31.G3.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Label parts of URLs and email addresses
Description: Students examine URLs (https://www.school.edu/games) and email addresses (teacher@school.edu) and label each part by dragging labels: protocol (https://), domain name (school.edu), path (/games), username (teacher), @ symbol, email domain. They circle suspicious elements in fake URLs (misspellings like "g00gle", extra words like "login-secure-bank") and explain why each is a warning sign.

Dependencies:
* T31.G2.06: Compare usernames vs passwords using analogy pictures
* T31.G2.07: Identify safe vs unsafe websites using visual clues




ID: T31.G3.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain two-factor authentication using door lock analogy and student examples
Description: Students compare login security using door analogies: one lock (password only) vs two locks (password + phone code). They match scenarios to security levels: "Someone steals your password" → "Can they get in with 1 lock? (yes) With 2 locks? (no, need phone too)". They list two things needed for 2FA (something you know + something you have). They identify concrete 2FA examples students encounter: gaming accounts (password + email code), school accounts (password + parent verification), tablet unlock (passcode + fingerprint).

Dependencies:
* T31.G2.06: Compare usernames vs passwords using analogy pictures




ID: T31.G3.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze browser address bars for safety indicators
Description: Students examine screenshots of browser address bars and check off safety indicators found: padlock icon present (yes/no), starts with https (yes/no), domain name spelled correctly (yes/no), no extra suspicious words in URL (yes/no). They rate each website as "Safe," "Suspicious," or "Dangerous" based on indicator count and explain their reasoning.

Dependencies:
* T31.G3.01: Label parts of URLs and email addresses




ID: T31.G3.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Apply privacy settings to control who sees your projects
Description: Students practice project privacy in CreatiCode: (1) Open sharing panel for their project, (2) Set project to Private, verify classmate cannot view it, (3) Share with specific classmate, verify they can now view, (4) Set to Public, discuss what "anyone can see" means. They create a decision chart: "When should I use Private vs Shared vs Public?" and apply it to 3 scenarios (school project, personal game, collaboration).

_Implementation note: Uses CreatiCode platform sharing UI, not programming blocks._

Dependencies:
* T31.G2.04: Match device care actions to safety reasons
* T31.G3.03: Analyze browser address bars for safety indicators




ID: T31.G3.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Apply checklist to identify phishing messages
Description: Students examine sample suspicious emails/texts and apply a 4-point checklist: (1) Unknown sender? (2) Urgent/scary language? (3) Spelling/grammar mistakes? (4) Suspicious link or request for password? They tally red flags found (0-4) and select the correct response based on score: 0 flags = probably safe, 1-2 = be cautious, 3-4 = definitely phishing, delete/report.

Dependencies:
* T31.G3.03: Analyze browser address bars for safety indicators
* T31.G2.05: Predict consequences of clicking suspicious links




ID: T31.G3.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a personal information protection plan
Description: Students create a simple "My Safety Plan" by selecting from options: "I will keep private: ___" (select 3+ items), "I will ask an adult before: ___" (select 2+ items), "If something scary happens online, I will: ___" (select steps). They test their plan by applying it to 3 scenarios and checking if their plan covers each situation.

Dependencies:
* T31.G3.01: Label parts of URLs and email addresses
* T31.G3.02: Explain two-factor authentication using door lock analogy and student examples




ID: T31.G3.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify safe vs risky behaviors in online games
Description: Students evaluate online gaming scenarios for safety: (1) Stranger in game asks to be friends on another platform (risky - don't share contact info), (2) Game asks for birthday to give gift (risky - verify with adult), (3) Player uses mean words in chat (risky - mute/report, don't engage), (4) Friend from school invites to play (safe). They apply the "stranger in game = stranger in real life" rule and list 3 safe responses to risky situations. They explain why in-game currency scams target young players.

Dependencies:
* T31.G2.03: Choose kind vs unkind responses to online messages
* T31.G3.05: Apply checklist to identify phishing messages




ID: T31.G3.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Evaluate app permission requests for reasonableness
Description: Students examine permission request scenarios for 5 different apps and decide if each permission makes sense: (1) Map app wants location (reasonable), (2) Calculator app wants camera (suspicious), (3) Voice recorder wants microphone (reasonable), (4) Game wants access to all photos (suspicious). They create a "Permission Checker" checklist: Does the app need this to work? What could go wrong if I say yes? They practice saying "No" or "Ask adult" for suspicious requests.

Dependencies:
* T31.G2.08: Match app permission types to what they can access
* T31.G3.03: Analyze browser address bars for safety indicators




ID: T31.G3.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain why software updates protect security
Description: Students learn about software updates through simple scenarios: (1) Match illustrated "security holes" (cracks in a wall) to "patches" (repairs) showing how updates fix problems, (2) Sort update types into "Security Fix" (protects from hackers), "Bug Fix" (fixes crashes), and "New Feature" (adds cool things), (3) Sequence a story showing what happens when updates are skipped (device gets slower, apps stop working, hackers can get in). They explain why "Update Now" helps keep devices safe.

Dependencies:
* T31.G3.03: Analyze browser address bars for safety indicators
* T31.G2.04: Match device care actions to safety reasons




ID: T31.G3.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify bystander actions to stop cyberbullying
Description: Students examine illustrated cyberbullying scenarios and identify helpful bystander actions: (1) Someone posts a mean comment about a classmate - bystander can report the comment, tell a trusted adult, send a kind message to the target, not like or share the mean post, (2) Group chat excludes someone on purpose - invite them to a different activity, talk to the group about including others. They sort bystander responses into "Helps Stop It" vs "Makes It Worse" vs "Does Nothing". They practice saying "That's not OK" and role-play supporting the target.

Dependencies:
* T31.G2.03: Choose kind vs unkind responses to online messages
* T31.G3.07: Identify safe vs risky behaviors in online games




ID: T31.G4.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Classify digital citizenship rules by who they protect
Description: Students review a digital citizenship agreement with 10+ rules and categorize each rule into three buckets: (1) Rules that protect MY data (e.g., "Don't share passwords"), (2) Rules that protect OTHERS (e.g., "Be kind in comments"), (3) Rules that protect EVERYONE (e.g., "Report bad content"). They tally rules in each category and discuss which category has the most rules. They propose one new rule for each category based on their experiences.

Dependencies:
* T31.G3.02: Explain two-factor authentication using door lock analogy and student examples
* T31.G3.06: Build a personal information protection plan




ID: T31.G4.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare password manager benefits, risks, and trustworthiness
Description: Students examine a password manager demonstration (teacher-led, no real passwords) and complete a T-chart listing benefits (unique password for each site, don't need to memorize, auto-fills forms) vs risks (master password stolen = all passwords lost, service gets hacked, locked out if forget master). They decide: "When would a password manager help most?" (many accounts, hard-to-remember passwords). They evaluate trustworthiness factors: is it from a known company? does it have good reviews? does it encrypt passwords? They compare free vs paid password managers and identify which features matter for security.

Dependencies:
* T31.G3.02: Explain two-factor authentication using door lock analogy and student examples
* T31.G3.03: Analyze browser address bars for safety indicators




ID: T31.G4.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze a data breach story and list protective actions
Description: Students read an age-appropriate news summary about a data breach (company X leaked user passwords). They answer: What information was stolen? How did attackers get it? They list 3 protective actions for affected users (change password, enable 2FA, check for suspicious activity) and 2 things the company should have done differently (encrypt passwords, limit data collection).

Dependencies:
* T31.G4.01: Classify digital citizenship rules by who they protect
* T31.G4.02: Compare password manager benefits, risks, and trustworthiness




ID: T31.G4.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace how 2FA blocks stolen password attacks
Description: Students trace through attack scenarios step-by-step: (1) Attacker gets password from phishing email, (2) Attacker tries to log in, (3) System asks for phone code, (4) Attacker doesn't have victim's phone, (5) Login blocked. They compare outcomes with vs without 2FA enabled and circle where 2FA stopped the attack.

Dependencies:
* T31.G3.02: Explain two-factor authentication using door lock analogy and student examples
* T31.G4.03: Analyze a data breach story and list protective actions




ID: T31.G4.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Rate app and website trustworthiness using multiple indicators
Description: Students examine app store listings and websites and rate trustworthiness (1-5 stars) using a checklist: verified badge present? reasonable permission requests? padlock icon? professional appearance? many positive reviews? privacy policy available? They justify ratings by citing specific indicators found or missing.

Dependencies:
* T31.G3.03: Analyze browser address bars for safety indicators
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G4.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Select correct responses to suspicious message scenarios
Description: Students read 5 suspicious message scenarios (urgent bank alert, prize winner notification, friend asking for password, unknown game invite, fake tech support) and select the best response from 4 options each. Correct answers include: tell trusted adult, report message, verify through official channel, delete without clicking. They explain why other options (click link, reply with info) are dangerous.

Dependencies:
* T31.G3.05: Apply checklist to identify phishing messages
* T31.G4.04: Trace how 2FA blocks stolen password attacks




ID: T31.G4.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Design a password strength scoring rubric
Description: Students design a password strength rubric with point values: length (1 pt per char over 6), uppercase letters (1 pt), numbers (1 pt), symbols (2 pts), not a dictionary word (2 pts). They score 5 example passwords using their rubric and rank them from weakest to strongest. They test if their rubric matches expert ratings.

Dependencies:
* T31.G4.02: Compare password manager benefits, risks, and trustworthiness
* T31.G3.02: Explain two-factor authentication using door lock analogy and student examples




ID: T31.G4.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Evaluate QR code safety before scanning
Description: Students learn QR code risks: (1) Examine how QR codes can link to malicious websites without showing the URL, (2) Identify suspicious QR code placements (stickers over official codes, random flyers), (3) Practice safe scanning: use phone's built-in preview feature to see URL before opening, check if URL matches expected destination. They sort 5 QR code scenarios into "Safe to scan" vs "Ask adult first" and explain their reasoning for each.

Dependencies:
* T31.G3.01: Label parts of URLs and email addresses
* T31.G4.05: Rate app and website trustworthiness using multiple indicators




ID: T31.G4.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify social media privacy settings and their effects
Description: Students examine simplified social media privacy settings and predict who can see content with each setting: Public (everyone including strangers), Friends Only (approved contacts), Private (only you). They match posting scenarios to appropriate settings: "Photo of my art project" → Friends/Public OK, "Photo showing my house" → Private or don't post. They explain why default settings are often less private than people think.

Dependencies:
* T31.G3.04: Apply privacy settings to control who sees your projects
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G4.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Recognize in-app purchase and subscription traps
Description: Students examine screenshots of common in-app purchase tactics: (1) "Free trial" that auto-charges after 3 days, (2) Premium currency that obscures real cost, (3) Timed offers creating false urgency, (4) "Unlock all" buttons that charge real money. They calculate real costs (100 gems = $5, sword costs 500 gems = $25) and identify which purchases need adult permission. They create a decision flowchart for in-app purchases.

Dependencies:
* T31.G4.05: Rate app and website trustworthiness using multiple indicators
* T31.G3.07: Identify safe vs risky behaviors in online games




ID: T31.G4.11
Topic: T31 – Cybersecurity & Digital Safety
Skill: Create a balanced screen time plan
Description: Students design a personal daily screen time plan using a template: (1) List all screen activities (school work, games, videos, social media) with estimated times, (2) Add non-screen activities (homework, sports, family time, sleep), (3) Create a daily schedule showing when each happens, (4) Apply the 20-20-20 rule (every 20 minutes, look 20 feet away for 20 seconds), (5) Set screen-free times (meals, before bed). They calculate total screen time and compare to recommended guidelines. They test their plan for one week and adjust based on what works.

Dependencies:
* T31.G2.09: Identify healthy vs unhealthy screen time habits using picture scenarios
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G4.12
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify safe vs risky activities on public WiFi
Description: Students examine scenarios and categorize activities by risk level on public WiFi: (1) Checking school website (low risk - public info), (2) Logging into email (medium risk - use HTTPS), (3) Online shopping with credit card (high risk - avoid on public WiFi), (4) Playing offline games (no risk), (5) Banking (very high risk - never on public WiFi). They explain why public WiFi is less secure (anyone nearby can see data). They identify safer alternatives: wait for home WiFi, use cellular data, use VPN (introduce concept briefly).

Dependencies:
* T31.G3.03: Analyze browser address bars for safety indicators
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G4.13
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain the 3-2-1 backup rule
Description: Students learn the 3-2-1 backup rule for protecting important files: 3 copies of data (original + 2 backups), 2 different storage types (computer + external drive, or cloud + USB), 1 copy stored off-site (cloud or at different location). They apply this to a scenario: student has important project on school computer - where should backups go? They explain why multiple backups protect against different disasters (fire destroys computer and nearby drive, but cloud backup survives; computer breaks, but external drive backup works). They identify which of their own files need backing up.

Dependencies:
* T31.G3.04: Apply privacy settings to control who sees your projects
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G4.14
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace your digital footprint and its permanence
Description: Students map their own digital footprint: (1) List online accounts they have (games, school sites, video platforms), (2) Identify what data each account stores about them (username, age, game scores, comments posted), (3) Draw a "footprint map" showing how their data is spread across sites, (4) Examine what happens when they "delete" something (often still stored, may be cached, others may have copied it). They discuss permanence: "Even if I delete it, is it really gone?" They practice the "grandma test": would I be OK if grandma saw this in 10 years?

Dependencies:
* T31.G4.01: Classify digital citizenship rules by who they protect
* T31.G4.09: Identify social media privacy settings and their effects




ID: T31.G4.15
Topic: T31 – Cybersecurity & Digital Safety
Skill: Practice secure email habits
Description: Students learn and practice safe email habits through scenarios: (1) Verify sender before opening attachments (check email address matches expected sender), (2) Hover over links to see destination before clicking, (3) Identify suspicious subject lines ("URGENT ACTION REQUIRED!!!"), (4) Use BCC for group emails to protect everyone's addresses, (5) Don't include sensitive info in email body (passwords, credit cards). They analyze 5 sample emails and mark safe practices vs red flags. They write a "good email" and "phishing email" and peer-review to see if classmates can tell the difference.

Dependencies:
* T31.G3.05: Apply checklist to identify phishing messages
* T31.G4.06: Select correct responses to suspicious message scenarios




ID: T31.G5.01a
Topic: T31 – Cybersecurity & Digital Safety
Skill: Define social engineering and explain why attacks target humans
Description: Students learn that social engineering attacks target people, not computers: (1) Define social engineering as "tricking people into giving information or access," (2) Compare to technical hacking (finding holes in code vs finding holes in trust), (3) Analyze why humans are the "weakest link" (can be rushed, want to be helpful, make mistakes under pressure), (4) List psychological tactics attackers use: urgency ("Act now!"), authority ("I'm from IT"), fear ("Your account will close"), curiosity ("See who viewed your profile"). They explain why even good security systems fail if users are tricked.

Dependencies:
* T31.G3.05: Apply checklist to identify phishing messages
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G5.01b
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify phishing attacks across multiple formats
Description: Students examine phishing across different platforms: (1) Email phishing (fake bank alerts, package delivery scams), (2) SMS/text phishing "smishing" (fake verification codes, prize notifications), (3) Voice phishing "vishing" (calls claiming to be tech support), (4) Social media phishing (fake friend requests, malicious links in DMs). They apply detection techniques to each format: check sender identity, look for urgency/threats, verify independently before responding. They create a cross-platform detection guide.

Dependencies:
* T31.G5.01a: Define social engineering and explain why attacks target humans
* T31.G3.05: Apply checklist to identify phishing messages




ID: T31.G5.01c
Topic: T31 – Cybersecurity & Digital Safety
Skill: Recognize pretexting and authority impersonation
Description: Students analyze pretexting scenarios where attackers create believable stories: (1) Caller claims to be from school needing to verify emergency contact info, (2) Email appears from principal asking for student data, (3) Person at door says they're IT and need to "fix" computer, (4) Online message claims to be friend who lost their phone and needs help. They identify pretext elements (fabricated scenario, sense of authority or urgency, requests information or access). They practice verification: "How can I confirm you are who you say?" They role-play saying "Let me verify with my teacher/parent first."

Dependencies:
* T31.G5.01a: Define social engineering and explain why attacks target humans
* T31.G5.01b: Identify phishing attacks across multiple formats




ID: T31.G5.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify physical security risks and countermeasures
Description: Students match physical security risks to their countermeasures: shoulder surfing → shield screen when typing passwords, tailgating → don't hold door for strangers, unattended device → lock screen before leaving, visible passwords → use password manager or memorize. They role-play scenarios and explain how physical access leads to digital compromise.

Dependencies:
* T31.G5.01a: Define social engineering and explain why attacks target humans




ID: T31.G5.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare app privacy policies using a data collection chart
Description: Students examine simplified privacy policy summaries for two apps and complete a comparison chart: Data collected (name, email, location, usage)? Who sees it (company only, advertisers, everyone)? Can you delete it (yes/no)? They score each app's privacy friendliness (1-5) and justify their ratings. They identify which app they'd recommend to a friend and why.

Dependencies:
* T31.G3.04: Apply privacy settings to control who sees your projects
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G5.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify PII in project data and categorize by sensitivity
Description: Students review sample project data (chat logs, input prompts, saved images) and highlight personal information: names (high sensitivity), locations (high), birthdates (high), faces in images (high), generic preferences (low). They sort highlighted items into categories: "Must remove before sharing," "Should anonymize," and "OK to share." They count PII items found and calculate a privacy risk score.

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G5.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Apply redaction techniques to protect PII
Description: Students practice redaction techniques on sample data: replace names with "User A/B/C," replace specific locations with "[City]," blur or crop faces in images, remove exact dates but keep month/year if needed. They redact a sample project and verify that no PII remains visible while the content still makes sense for sharing.

Dependencies:
* T31.G5.04: Identify PII in project data and categorize by sensitivity




ID: T31.G5.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Design a data collection consent notice
Description: Students create a consent notice for a hypothetical app that explains: what data is collected, why it's needed, who can see it, how long it's kept, and how to delete it. They evaluate 3 sample consent notices (one too vague, one too long, one well-designed) and rank them. They write a consent message for their own CreatiCode project that would collect user names.

Dependencies:
* T31.G5.04: Identify PII in project data and categorize by sensitivity




ID: T31.G5.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Execute and verify a project backup procedure
Description: Students follow backup steps for their CreatiCode project: (1) File → Download to save project file, (2) Name file with date (MyProject_2024-01-15), (3) Save to designated backup folder, (4) Test restore by uploading file to new project. They verify the restored project works identically. They create a backup schedule checklist (backup before major changes, weekly backup).

_Implementation note: Uses CreatiCode File menu, not programming blocks._

Dependencies:
* T31.G3.04: Apply privacy settings to control who sees your projects




ID: T31.G5.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement consent prompts in CreatiCode projects using widgets
Description: Students add a consent screen to their CreatiCode project using UI widgets: display text explaining data collection, add Yes/No buttons, use conditionals to only proceed if user clicks Yes, store consent in a variable. They test that the project respects user choice and doesn't proceed without consent.

Dependencies:
* T31.G5.06: Design a data collection consent notice
* T15.G3.01: Create a simple UI with text and button widgets




ID: T31.G5.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Encode and decode messages using substitution cipher (unplugged)
Description: Students learn encryption through hands-on cipher activity: (1) Create a shift-3 cipher key (A→D, B→E, etc.), (2) Encode "HELLO" as "KHOOR," (3) Decode classmate's message using the key, (4) Try to decode without knowing the shift (brute force). They connect to browser padlock icon showing encryption in use and explain why intercepted encrypted data is useless to attackers.

Dependencies:
* T31.G3.03: Analyze browser address bars for safety indicators
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G5.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Rank passwords by strength using established criteria
Description: Students apply password strength criteria to rank 6 passwords from weakest to strongest: length (longer = stronger), character variety (letters + numbers + symbols), unpredictability (no dictionary words, no patterns like "123"). They score each password (0-10 pts) using a rubric and justify rankings. They identify which weak password would be cracked first and why.

Dependencies:
* T31.G4.07: Design a password strength scoring rubric
* T31.G4.04: Trace how 2FA blocks stolen password attacks




ID: T31.G5.11
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace data flow in a simple app and identify collection points
Description: Students examine a flowchart showing how data moves through an app: user input → app processes → saved to database → shared with third parties. They label each step with what data is collected and who can access it. They identify the riskiest point (where most data leaves user control) and suggest privacy improvements for each step.

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G5.04: Identify PII in project data and categorize by sensitivity




ID: T31.G5.12
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify security risks in multiplayer game scenarios
Description: Students analyze multiplayer game scenarios for security risks: (1) Sharing game room password publicly (anyone can join), (2) Using real name as display name (reveals identity), (3) Storing player scores in cloud variables that anyone can modify (cheating), (4) Chat messages visible to all players (privacy concern). For each scenario, they identify the risk, explain potential consequences, and propose a safer alternative. They connect these to real online gaming safety practices.

Dependencies:
* T31.G4.09: Identify social media privacy settings and their effects
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G5.13
Topic: T31 – Cybersecurity & Digital Safety
Skill: Evaluate AI assistant interactions for information safety and understand AI limitations
Description: Students examine scenarios of people using AI assistants (chatbots like ChatGPT, voice assistants): (1) Asking AI for homework help (generally safe), (2) Telling AI your address to find nearby stores (risky - AI logs data), (3) Sharing personal problems with AI (risky - may be stored/reviewed), (4) Using AI to write stories (safe). They categorize each scenario by risk level and explain why AI conversations may not be private. They list 3 types of information never to share with AI assistants. They identify AI capabilities (can generate text, answer questions, help with ideas) and limitations (may give wrong answers, doesn't truly understand context, can't verify facts, has no common sense). They explain why AI should be a helper, not a replacement for learning.

Dependencies:
* T31.G5.04: Identify PII in project data and categorize by sensitivity
* T31.G5.06: Design a data collection consent notice




ID: T31.G5.14
Topic: T31 – Cybersecurity & Digital Safety
Skill: Configure basic browser privacy settings
Description: Students practice adjusting browser privacy settings (teacher-guided demonstration or practice accounts): (1) Block third-party cookies (prevent tracking across websites), (2) Clear browsing history and cache, (3) Enable "Do Not Track" requests, (4) Review and remove website permissions (location, camera, notifications), (5) Set search engine to privacy-focused option if available. They explain what each setting does and why it improves privacy. They create a "privacy checkup" routine to review settings monthly.

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G4.09: Identify social media privacy settings and their effects




ID: T31.G5.15
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify security risks in smart home devices (IoT)
Description: Students examine Internet of Things (IoT) security risks through scenarios: (1) Smart speaker always listening (privacy risk - may record private conversations), (2) Smart doorbell camera storing video in cloud (who can access?), (3) Smart toy connecting to internet without password (hacker can access), (4) Smart thermostat tracking when family is home (reveals routines). They categorize risks: privacy invasion, unauthorized access, data collection. For each device, they identify: What data does it collect? Who can access it? What's the worst that could happen? They propose security improvements: change default passwords, disable features not needed, check who can access data.

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G5.04: Identify PII in project data and categorize by sensitivity




ID: T31.G5.16
Topic: T31 – Cybersecurity & Digital Safety
Skill: Report security incidents using proper channels
Description: Students learn when and how to report security incidents: (1) Identify what counts as a security incident (account hacked, phishing email received, suspicious activity, data breach notification, inappropriate content, cyberbullying), (2) Match each incident type to proper reporting channel (tell teacher, tell parent, report to platform, contact school IT), (3) Practice writing clear incident reports: What happened? When? What did you do? What needs to be fixed?, (4) Understand why reporting matters (stops harm from spreading, helps others stay safe, improves security). They role-play reporting scenarios with appropriate language and channels.

Dependencies:
* T31.G5.01b: Identify phishing attacks across multiple formats
* T31.G4.01: Classify digital citizenship rules by who they protect




ID: T31.G5.17
Topic: T31 – Cybersecurity & Digital Safety
Skill: Configure gaming platform security and parental controls
Description: Students learn about gaming platform security features: (1) Privacy settings (who can see profile, who can send messages, who can join games), (2) Communication controls (text chat, voice chat, video), (3) Purchase restrictions (require password for purchases, disable in-app purchases), (4) Time limits and play schedules, (5) Content filters (age-appropriate games only). They examine sample parental control panels and configure appropriate settings for different age scenarios (8-year-old vs 13-year-old). They explain why each control exists and how it protects players. They create a "gaming safety checklist" for setting up new accounts.

Dependencies:
* T31.G4.09: Identify social media privacy settings and their effects
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G6.01.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain how viruses and worms spread through systems
Description: Students analyze self-replicating malware behavior: (1) Trace how a virus attaches to files and spreads when files are shared, (2) Diagram how worms travel through network connections without user action, (3) List warning signs (system slowdown, unknown processes, files appearing/changing), (4) Match each malware type to its primary defense (antivirus for viruses, firewall for worms). They compare one real-world example of each type and explain why worms can spread faster than viruses.

Dependencies:
* T31.G4.03: Analyze a data breach story and list protective actions
* T31.G5.01a: Define social engineering and explain why attacks target humans




ID: T31.G6.01.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace how ransomware encrypts files and demands payment
Description: Students analyze ransomware attack chains: (1) Trace the infection path (phishing email → user clicks → malware downloads → files encrypted), (2) Explain what encryption does to make files inaccessible without a key, (3) Analyze why attackers demand cryptocurrency (hard to trace, irreversible). They debate why paying ransom is discouraged (funds criminals, no guarantee of recovery, may be targeted again) and demonstrate why regular backups defeat ransomware by restoring files without paying.

Dependencies:
* T31.G6.01.01: Explain how viruses and worms spread through systems
* T31.G5.09: Encode and decode messages using substitution cipher (unplugged)




ID: T31.G6.01.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify how spyware secretly collects personal data
Description: Students analyze spyware behavior: (1) List what spyware collects (keystrokes revealing passwords, browsing history, screenshots, webcam/microphone access), (2) Trace how it arrives (bundled with "free" software, malicious ads, fake browser updates), (3) Identify warning signs in their own devices (homepage changed, new toolbars, slow performance, battery draining fast). They examine app permission requests and identify suspicious ones (flashlight app requesting microphone access). They list 3 personal items spyware could steal from them specifically.

Dependencies:
* T31.G6.01.01: Explain how viruses and worms spread through systems




ID: T31.G6.01.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze how trojans disguise themselves as legitimate software
Description: Students examine trojan deception techniques: (1) Compare legitimate vs trojan versions of the same app (official website vs suspicious download site), (2) List common disguises (cracked games, free movie downloads, "system optimizer" tools), (3) Trace what happens after installation (backdoor opens, data stolen, device joins botnet). They analyze 3 scenarios and identify which downloads are trojans based on red flags (too-good-to-be-true offers, unusual file sources, missing digital signatures). They explain why "if it's free, you might be the product."

Dependencies:
* T31.G6.01.01: Explain how viruses and worms spread through systems




ID: T31.G6.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze phishing emails using advanced detection techniques
Description: Students examine 5 sanitized phishing email examples and apply advanced analysis: check sender domain (legitimate vs lookalike), hover over links to see actual destination (without clicking), examine urgency tactics and threats, identify impersonation attempts, check for personalization (or generic "Dear Customer"). They score each email's sophistication level and write detection rules.

Dependencies:
* T31.G5.01a: Define social engineering and explain why attacks target humans
* T31.G6.01.01: Explain how viruses and worms spread through systems




ID: T31.G6.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Diagram network attacks (DoS and MitM)
Description: Students draw diagrams showing how network attacks work: DoS attack (many requests overwhelming server until legitimate users can't connect) and Man-in-the-Middle (attacker intercepts communication between user and server). They label attack components, explain why HTTPS prevents MitM (encryption), and list how organizations defend against DoS (rate limiting, traffic filtering).

Dependencies:
* T31.G5.09: Encode and decode messages using substitution cipher (unplugged)
* T31.G6.01.01: Explain how viruses and worms spread through systems




ID: T31.G6.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Trace how malicious input can manipulate systems
Description: Students learn conceptually how attackers use unexpected input to cause harm: entering very long text to overflow fields, typing special characters that confuse the system, or crafting input that changes how commands execute. Using non-code examples, they trace how a login form might be tricked if it doesn't validate input properly. They list 3 rules for safe input handling (limit length, filter special chars, treat all input as untrusted).

Dependencies:
* T31.G6.01.04: Analyze how trojans disguise themselves as legitimate software
* T31.G5.11: Trace data flow in a simple app and identify collection points




ID: T31.G6.05.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a login form with password length validation
Description: Students create a CreatiCode login form using widgets (text input for username, text input for password, login button). They add validation using string length blocks: if password length < 8, display error "Password must be at least 8 characters" and prevent login. They test with passwords of 5, 8, and 12 characters and verify correct behavior. They explain why minimum length improves security against guessing.

Dependencies:
* T08.G4.03: Read and trace a script with if-else
* T10.G4.01: Concatenate strings to build messages
* T15.G4.01: Build a quiz with text input widgets
* T31.G5.10: Rank passwords by strength using established criteria




ID: T31.G6.05.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement password display masking with asterisks
Description: Students enhance their login form with password masking: create a visible label showing asterisks, store actual password in hidden variable, for each character typed add one asterisk to display while storing real character in password variable. They use string length and repeat blocks to generate asterisk string. They test that displayed text shows "****" while variable contains "test" and explain how this prevents shoulder surfing.

Dependencies:
* T31.G6.05.01: Build a login form with password length validation




ID: T31.G6.05.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement login attempt tracking and account lockout
Description: Students add brute-force protection to their login form: create failedAttempts counter variable, increment on wrong password, after 3 failures disable login button and show "Account locked - wait 30 seconds". They implement countdown timer using wait and variable blocks to auto-unlock. They test by entering wrong passwords and verify lockout triggers. They explain how this prevents attackers from trying thousands of passwords.

Dependencies:
* T31.G6.05.01: Build a login form with password length validation
* T07.G4.01: Trace loop execution with a variable counter




ID: T31.G6.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify AI-specific security threats in projects
Description: Students analyze AI features and identify three threat categories: (1) Prompt injection - inputs that trick AI into ignoring instructions, (2) Bias amplification - AI outputs that treat groups unfairly, (3) Inappropriate content - AI generating harmful/offensive outputs. They examine example scenarios for each threat type, identify which threat applies, and propose one mitigation for each (input filtering, diverse training, content moderation).

Dependencies:
* T31.G5.01a: Define social engineering and explain why attacks target humans
* T31.G6.01.01: Explain how viruses and worms spread through systems




ID: T31.G6.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare ethical vs malicious hacking through case studies
Description: Students read 2 simplified case studies: one ethical (security researcher finds bug, reports responsibly, gets rewarded) and one malicious (attacker finds same bug, exploits it for profit). They complete a comparison chart: permission obtained (yes/no), goal (help/harm), outcome (fixed/damage), legal status. They explain why the same technical skills can be used for good or bad and discuss bug bounty programs.

Dependencies:
* T31.G6.01.01: Explain how viruses and worms spread through systems
* T31.G4.03: Analyze a data breach story and list protective actions




ID: T31.G6.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a Caesar cipher encoder using string position lookup
Description: Students implement encryption in CreatiCode: (1) Create alphabet variable "ABCDEFGHIJKLMNOPQRSTUVWXYZ", (2) Get input message and shift value, (3) Loop through each character, find its position in alphabet using string contains/position blocks, (4) Calculate new position (original + shift), handle wrap-around with mod, (5) Get letter at new position using substring, (6) Join all shifted letters. They encode "HELLO" with shift=3 to get "KHOOR" and test decoding by using negative shift.

Dependencies:
* T10.G4.01: Concatenate strings to build messages
* T31.G5.09: Encode and decode messages using substitution cipher (unplugged)
* T07.G4.01: Trace loop execution with a variable counter




ID: T31.G6.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement password complexity validation with multiple rules
Description: Students enhance their login form to check multiple password requirements: (1) At least 8 characters (string length), (2) Contains at least one number (check if string contains 0-9), (3) Contains at least one uppercase (check A-Z). They display specific error messages for each failed rule. They test passwords against all rules and discuss why complexity requirements exist alongside length requirements.

Dependencies:
* T31.G6.05.01: Build a login form with password length validation
* T10.G5.01: Use the "contains" block to search within strings




ID: T31.G6.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement password-protected multiplayer game rooms
Description: Students create a multiplayer CreatiCode project with password protection: (1) Create game using "create game" block with password parameter, (2) Store the password in a variable that only the host sets, (3) Display room code but not password, (4) Test that players cannot join without correct password, (5) Add feedback for wrong password attempts. They explain why game rooms need passwords (prevent unwanted players, griefing, unauthorized access) and compare to real-world password use cases.

Dependencies:
* T31.G5.12: Identify security risks in multiplayer game scenarios
* T31.G6.05.01: Build a login form with password length validation




ID: T31.G6.11
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement display name sanitization for multiplayer games
Description: Students add name safety to their multiplayer projects: (1) Create text input for player display name, (2) Implement length limit (max 15 characters) using string length check, (3) Filter out obvious bad words using contains check against a small blocklist, (4) Replace or reject names that fail checks, (5) Store sanitized name in player variable. They test with various inputs and explain why allowing any name is risky (impersonation, offensive content, code injection).

Dependencies:
* T31.G6.10: Implement password-protected multiplayer game rooms
* T31.G6.04: Trace how malicious input can manipulate systems




ID: T31.G6.12
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build an AI-powered project with content filtering
Description: Students create a CreatiCode project using ChatGPT blocks with basic safety measures: (1) Add a system prompt instructing the AI to be helpful and appropriate, (2) Check user input length before sending to AI (reject very long inputs), (3) Display AI response in a widget, (4) Add a "report inappropriate response" button that logs the incident. They test with various prompts and discuss why AI outputs need monitoring even with good system prompts.

Dependencies:
* T31.G5.13: Evaluate AI assistant interactions for information safety and understand AI limitations
* T31.G6.06: Identify AI-specific security threats in projects




ID: T31.G6.13
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze persuasive design patterns that increase screen time
Description: Students identify and analyze persuasive design techniques used in apps and games: (1) Infinite scroll (content never ends, keeps you watching), (2) Autoplay next video (removes stopping point), (3) Streaks and daily rewards (fear of missing out), (4) Push notifications (constant reminders to return), (5) Social validation (likes, hearts, view counts create dopamine loop). They examine screenshots of popular apps and identify which techniques are used. They discuss: Why do companies want more screen time? (More ads, more data collected). They design an app feature that respects users' time instead of maximizing it.

Dependencies:
* T31.G4.11: Create a balanced screen time plan
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G6.14
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain how cookies and trackers collect data
Description: Students learn about web tracking: (1) Define cookies as small data files websites store on your device, (2) Distinguish types: first-party cookies (help website remember you) vs third-party cookies (track you across websites), (3) Explain tracking pixels (invisible images that report when you view content), (4) Trace data collection: visit website → cookie stored → visit another site → tracker sees you were on first site → profile built about interests. They examine cookie consent popups and identify deceptive patterns (accept button bigger than reject, pre-checked boxes). They explain how tracking enables targeted advertising and why some people want privacy.

Dependencies:
* T31.G5.14: Configure basic browser privacy settings
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G6.15
Topic: T31 – Cybersecurity & Digital Safety
Skill: Use a password manager to store and generate passwords
Description: Students practice using a password manager (teacher demonstration or educational version): (1) Create master password (strong, memorable, unique - this is the ONE password to remember), (2) Add entry for practice account (website, username, password), (3) Use password generator to create strong random password (16+ chars, mixed types), (4) Practice auto-fill feature, (5) Organize passwords into categories (school, games, other). They compare passwords they created manually vs generated ones and see the difference in strength. They explain the tradeoff: convenience + security vs single point of failure. They discuss why the master password must be extremely strong and never shared.

Dependencies:
* T31.G4.02: Compare password manager benefits, risks, and trustworthiness
* T31.G5.10: Rank passwords by strength using established criteria




ID: T31.G6.16
Topic: T31 – Cybersecurity & Digital Safety
Skill: Apply lateral reading to verify news sources
Description: Students learn lateral reading to verify online information: (1) Don't just read the article - open new tabs to research the source, (2) Search "[source name] + credibility" or "[source name] + bias", (3) Check who wrote it (search author name, are they real/qualified?), (4) Find original source if article cites data or quotes, (5) Cross-check claims with multiple reputable sources. They practice with 3 articles (one credible, one biased, one fake) and use lateral reading to evaluate each. They create a "verification checklist" and explain why this matters for AI-generated content too (AI can confidently state false information).

Dependencies:
* T31.G5.13: Evaluate AI assistant interactions for information safety and understand AI limitations
* T31.G4.05: Rate app and website trustworthiness using multiple indicators




ID: T31.G7.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Extend Caesar cipher with wrap-around and case handling
Description: Students enhance their G6 cipher to handle edge cases: (1) Wrap around alphabet end (Z+3 = C using mod operator), (2) Preserve lowercase by checking case before and after encryption, (3) Pass through non-letters unchanged (spaces, punctuation). They test with "Hello, World!" ensuring output preserves spacing and punctuation. They explain why simple ciphers are vulnerable to frequency analysis and list 3 features of modern encryption algorithms.

Dependencies:
* T31.G6.08: Build a Caesar cipher encoder using string position lookup
* T09.G5.01: Use multiple variables together in a single expression




ID: T31.G7.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Calculate and compare password cracking times
Description: Students build or use a calculator to compare password strength: given 26 lowercase letters and 1000 guesses/second, calculate time to crack 4-char (26^4 / 1000 = 456 seconds), 8-char (26^8 / 1000 = 66 years), 12-char passwords. They add numbers and symbols to see how possibilities multiply. They graph cracking time vs length and write class password guidelines based on findings (minimum 12 chars, mixed character types).

Dependencies:
* T31.G6.05.03: Implement login attempt tracking and account lockout
* T31.G6.09: Implement password complexity validation with multiple rules




ID: T31.G7.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a security event logging system using tables
Description: Students create a logging system in CreatiCode using table variables: (1) Create log table with columns [timestamp, userID, action, result], (2) Add "log event" custom block that appends row to table, (3) Call log block after login attempts, button clicks, data saves, (4) Display log viewer showing recent entries, (5) Add basic anomaly detection (flag if 5+ failed logins in 1 minute). They explain why logs must not contain passwords and how logs help detect attacks.

Dependencies:
* T11.G5.03: Use table variables to store multi-row data
* T31.G5.07: Execute and verify a project backup procedure
* T31.G6.05.03: Implement login attempt tracking and account lockout




ID: T31.G7.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Debate facial recognition benefits and risks using structured arguments
Description: Students research facial recognition AI and prepare structured arguments for a class debate. Benefits side: finding missing children, convenient phone unlock, airport security efficiency. Risks side: tracking without consent, bias against certain demographics (document error rate disparities), enabling surveillance state. They cite specific examples/statistics and propose 3 ethical guidelines balancing benefits and risks.

Dependencies:
* T31.G5.04: Identify PII in project data and categorize by sensitivity
* T31.G6.06: Identify AI-specific security threats in projects




ID: T31.G7.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Evaluate emotion detection AI accuracy and ethical concerns
Description: Students examine AI emotion detection claims: analyze study data showing accuracy rates (often 60-70%, not 99% as marketed), identify cultural bias (facial expressions mean different things across cultures), list privacy concerns (continuous monitoring, data storage, consent). They create a decision framework for evaluating when emotion AI use is acceptable (opt-in only, clear purpose, accuracy disclosed, right to refuse).

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G7.04: Debate facial recognition benefits and risks using structured arguments




ID: T31.G7.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement input sanitization to prevent manipulation
Description: Students add input sanitization to their CreatiCode projects: (1) Limit text input length to prevent overflow (max 100 chars), (2) Filter dangerous characters by replacing or removing <, >, &, quotation marks, (3) Validate numeric inputs are actually numbers before using them, (4) Display sanitized input back to user to show what was cleaned. They test with attack-like inputs and verify sanitization works.

Dependencies:
* T31.G6.04: Trace how malicious input can manipulate systems
* T31.G6.05.01: Build a login form with password length validation




ID: T31.G7.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement secure cloud variable usage for multiplayer data
Description: Students create a multiplayer project using cloud variables securely: (1) Use cloud variables only for data that should be shared (scores, game state), (2) Avoid storing PII in cloud variables, (3) Implement server-side validation by checking if incoming values are in valid range, (4) Add rate limiting by tracking how often a player updates cloud data (reject rapid updates), (5) Log suspicious activity to a table variable. They test by attempting to send invalid data and verify it's rejected.

Dependencies:
* T31.G6.10: Implement password-protected multiplayer game rooms
* T31.G7.03: Build a security event logging system using tables




ID: T31.G7.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a chat moderation system for multiplayer projects
Description: Students implement basic chat moderation in a multiplayer CreatiCode project: (1) Create chat message input and display using widgets, (2) Check messages against a blocklist of inappropriate words before sending, (3) Replace blocked words with asterisks or reject message, (4) Log moderated messages to a table (without showing blocked content), (5) Add rate limiting (max 1 message per 2 seconds) to prevent spam. They test the system and discuss why automated moderation is imperfect but necessary.

Dependencies:
* T31.G6.11: Implement display name sanitization for multiplayer games
* T31.G7.06: Implement input sanitization to prevent manipulation




ID: T31.G7.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze AI-generated misinformation and apply broader media literacy
Description: Students examine real-world examples of AI-generated misinformation and connect to general media literacy: (1) Fake news articles written by AI (analyze writing patterns), (2) AI-generated "expert" quotes that don't exist, (3) Synthetic data and statistics, (4) AI-manipulated images with altered details. They develop detection strategies that work for both AI and human-created misinformation: check multiple sources, verify quotes by searching for them, look for inconsistencies, use reverse image search, consider source credibility and bias, identify emotional manipulation tactics. They apply strategies to 5 sample items (mix of AI-generated, human-created misinformation, and credible content) and identify which are trustworthy.

Dependencies:
* T31.G6.12: Build an AI-powered project with content filtering
* T31.G7.07: Detect deepfake videos and AI-generated images using verification techniques
* T31.G6.16: Apply lateral reading to verify news sources




ID: T31.G7.11
Topic: T31 – Cybersecurity & Digital Safety
Skill: Explain VPN basics using tunnel analogy
Description: Students learn Virtual Private Network (VPN) concepts through analogy: (1) Regular internet = sending postcards (anyone can read them), (2) VPN = sealed envelope in a tunnel (encrypted, private), (3) Draw how VPN works: your device → encrypted tunnel → VPN server → destination website, (4) Explain what VPN hides (your real IP address/location, your activity from WiFi provider) and what it doesn't hide (activity from VPN company, destination websites still see your actions). They identify when VPN is useful (public WiFi, bypassing school blocks, privacy from ISP) vs when it's not needed (home WiFi with trusted family). They discuss VPN trustworthiness (free VPNs may sell data, need to trust VPN provider).

Dependencies:
* T31.G5.09: Encode and decode messages using substitution cipher (unplugged)
* T31.G4.12: Identify safe vs risky activities on public WiFi




ID: T31.G7.12
Topic: T31 – Cybersecurity & Digital Safety
Skill: Identify key children's online privacy rights (COPPA)
Description: Students learn their privacy rights under COPPA (Children's Online Privacy Protection Act): (1) Websites must get parent permission before collecting data from users under 13, (2) Parents can review what data was collected and request deletion, (3) Websites must protect children's information, (4) Children can't be required to share more information than necessary. They examine 3 website scenarios and identify COPPA violations (game collects email from 10-year-old without parent consent, app requires full address for no reason). They discuss why age restrictions exist (13+ for many platforms) and why lying about age removes protections. They identify which rights apply to them and practice exercising rights (asking parent to review data, requesting account deletion).

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G5.06: Design a data collection consent notice




ID: T31.G7.13
Topic: T31 – Cybersecurity & Digital Safety
Skill: Configure smart device privacy settings
Description: Students practice configuring privacy settings on smart devices (teacher demonstration with sample accounts/devices): (1) Voice assistant: review voice recording history, disable always-listening mode when not needed, delete stored recordings, (2) Smart TV: disable ACR (automatic content recognition) that tracks what you watch, turn off personalized ads, (3) Fitness tracker: limit what health data is shared, turn off location history, (4) Gaming console: restrict data collection, disable personalized ads. They create a "new device setup checklist" covering privacy settings to configure before regular use. They explain why default settings prioritize company data collection over user privacy.

Dependencies:
* T31.G5.15: Identify security risks in smart home devices (IoT)
* T31.G5.14: Configure basic browser privacy settings




ID: T31.G8.01.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test text input fields with boundary and injection cases
Description: Students perform security testing on their CreatiCode projects following an ethical testing checklist: (1) Test very long inputs (100+, 1000+ chars), document if app crashes or truncates, (2) Test special characters (<>'"&;) and document behavior, (3) Test empty input and whitespace-only input, (4) Rate each finding by severity (Critical: crash/data loss, High: unexpected behavior, Medium: poor error handling, Low: cosmetic). They fix at least 2 high/critical issues found.

Dependencies:
* T31.G6.07: Compare ethical vs malicious hacking through case studies
* T31.G7.06: Implement input sanitization to prevent manipulation




ID: T31.G8.01.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test numeric inputs with edge cases and invalid types
Description: Students test numeric input handling in their projects: (1) Negative numbers where positive expected (score = -100), (2) Very large numbers (999999999) to check overflow, (3) Decimals where integers expected (3.5 lives), (4) Zero in division, (5) Text where numbers expected. They document each test case, expected behavior, actual behavior, and whether it's a vulnerability. They implement type checking and range validation to fix issues.

Dependencies:
* T31.G8.01.01: Test text input fields with boundary and injection cases




ID: T31.G8.01.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test authentication systems for common weaknesses
Description: Students security-test login systems they built: (1) Try common weak passwords from a list (password, 123456, qwerty), (2) Test empty password and spaces-only password, (3) Test username enumeration (different messages for "wrong user" vs "wrong password"), (4) Test bypass attempts (manipulating variables directly if possible). They document which weaknesses exist and implement fixes: password blacklist, consistent error messages, server-side validation.

Dependencies:
* T31.G8.01.01: Test text input fields with boundary and injection cases
* T31.G6.05.03: Implement login attempt tracking and account lockout




ID: T31.G8.01.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Write professional security test reports with severity ratings
Description: Students compile findings from all security tests into a formal report with standard sections: (1) Executive Summary (critical issues count, overall risk), (2) Methodology (what was tested, how), (3) Findings table (issue, reproduction steps, impact, severity, fix recommendation), (4) Risk matrix (severity vs likelihood). They prioritize fixes by severity × likelihood score and create a remediation timeline. They present top 3 findings to class.

Dependencies:
* T31.G8.01.01: Test text input fields with boundary and injection cases
* T31.G8.01.02: Test numeric inputs with edge cases and invalid types
* T31.G8.01.03: Test authentication systems for common weaknesses





ID: T31.G8.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement role-based access control in CreatiCode projects
Description: Students build an access control system with two roles: (1) Create userRole variable (admin or player), (2) Create permission-checking custom block that returns true/false based on role, (3) Gate admin features (edit content, view all data) behind role checks, (4) Gate player features (view content, submit answers) appropriately, (5) Test by logging in as each role and verifying access. Example: Quiz app where admins create questions, players answer them.

Dependencies:
* T31.G6.05.01: Build a login form with password length validation
* T31.G6.05.03: Implement login attempt tracking and account lockout
* T31.G7.03: Build a security event logging system using tables
* T08.G6.01: Refactor code using conditionals to reduce duplication






ID: T31.G8.03.01
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test chatbots for prompt injection vulnerabilities
Description: Students perform prompt injection security testing on AI chatbots: (1) Try "Ignore previous instructions and..." attacks, (2) Attempt to reveal system prompts ("What are your rules?"), (3) Test jailbreak patterns from documented examples, (4) Try to make AI produce content outside its intended scope. They document successful and blocked attempts, implement input filtering (reject messages containing "ignore instructions"), and strengthen system prompts with explicit boundaries.

Dependencies:
* T31.G6.06: Identify AI-specific security threats in projects
* T31.G7.06: Implement input sanitization to prevent manipulation
* T21.G6.01: Build a simple chatbot with ChatGPT blocks




ID: T31.G8.03.02
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test image generation for content filter bypasses
Description: Students ethically test image generation safety: (1) Document what content filters exist, (2) Test edge cases with indirect descriptions, euphemisms, or misspellings that might bypass filters, (3) Identify prompt patterns that produce unexpected outputs, (4) Document filter weaknesses. They implement additional safeguards: keyword blocklist, output review before display, user reporting mechanism. They compare their filters to industry-standard content moderation approaches.

Dependencies:
* T31.G8.03.01: Test chatbots for prompt injection vulnerabilities
* T20.G6.02: Write structured prompts to get specific image styles




ID: T31.G8.03.03
Topic: T31 – Cybersecurity & Digital Safety
Skill: Audit sensor-based projects for privacy vulnerabilities
Description: Students conduct privacy audits on projects using cameras, microphones, or other sensors: (1) Inventory what data is collected (faces, voices, locations), (2) Check where data is stored and who can access it, (3) Verify consent prompts exist before data collection, (4) Check for PII in logs or saved data, (5) Test data deletion works properly. They implement missing privacy controls and create a data handling policy document for their project.

Dependencies:
* T31.G8.03.01: Test chatbots for prompt injection vulnerabilities
* T31.G7.04: Debate facial recognition benefits and risks using structured arguments




ID: T31.G8.03.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compile AI security audit report with risk ratings
Description: Students create a comprehensive AI security audit report combining all findings: (1) Executive summary with critical issue count, (2) AI-specific vulnerability section (prompt injection, content bypass, privacy leaks), (3) Risk matrix mapping each vulnerability to impact and likelihood, (4) Prioritized remediation plan with timeline, (5) Recommendations for ongoing monitoring. They present report to class and implement top-priority fixes.

Dependencies:
* T31.G8.01.04: Write professional security test reports with severity ratings
* T31.G8.03.01: Test chatbots for prompt injection vulnerabilities
* T31.G8.03.02: Test image generation for content filter bypasses
* T31.G8.03.03: Audit sensor-based projects for privacy vulnerabilities





ID: T31.G8.04
Topic: T31 – Cybersecurity & Digital Safety
Skill: Conduct ethics audit of AI projects using structured framework
Description: Students audit their AI projects for ethical concerns using a checklist: (1) Fairness - test if AI treats different users/inputs equally, document any bias found, (2) Content safety - assess inappropriate output risks, (3) Consent - verify data collection has user agreement, (4) Transparency - check if users know they're interacting with AI and its limitations. They write an ethics report with findings, connect to broader AI ethics principles, and propose mitigations (diverse testing, content filters, clear disclosures).

Dependencies:
* T31.G8.03.04: Compile AI security audit report with risk ratings
* T31.G7.04: Debate facial recognition benefits and risks using structured arguments
* T31.G7.05: Evaluate emotion detection AI accuracy and ethical concerns





ID: T31.G8.05
Topic: T31 – Cybersecurity & Digital Safety
Skill: Design AI incident response plans with step-by-step procedures
Description: Students create incident response plans for AI system failures. Given scenario: "Chatbot gave harmful advice to a student." They write step-by-step response: (1) Immediate containment - disable AI feature, (2) Notification - alert teacher/admin, (3) Investigation - review logs to find cause, (4) Documentation - record what happened and why, (5) Remediation - update filters/prompts/training, (6) Testing - verify fix before re-enabling, (7) Prevention - add monitoring to detect similar issues. They compare AI incidents to traditional security incidents (AI has unpredictable outputs).

Dependencies:
* T31.G7.03: Build a security event logging system using tables
* T31.G8.03.04: Compile AI security audit report with risk ratings
* T31.G8.04: Conduct ethics audit of AI projects using structured framework




ID: T31.G8.06
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement secure session management in multi-user projects
Description: Students build session security for multiplayer/multi-user CreatiCode projects: (1) Generate unique session IDs on login, (2) Store session ID with user data, (3) Validate session on each action, (4) Implement session timeout (auto-logout after inactivity), (5) Secure logout that clears session data. They test that one user cannot access another's session and that expired sessions properly deny access.

Dependencies:
* T31.G8.02: Implement role-based access control in CreatiCode projects
* T31.G7.03: Build a security event logging system using tables




ID: T31.G8.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build a comprehensive security checklist for project review
Description: Students create a reusable security checklist for reviewing CreatiCode projects, covering all learned topics: input validation (length, type, characters), authentication (password strength, lockout, session management), authorization (role checks, permission gates), privacy (PII handling, consent, data retention), AI safety (prompt injection, content filters, bias). They apply checklist to peer projects, identify gaps, and provide remediation recommendations.

Dependencies:
* T31.G8.01.04: Write professional security test reports with severity ratings
* T31.G8.02: Implement role-based access control in CreatiCode projects
* T31.G8.03.04: Compile AI security audit report with risk ratings




ID: T31.G7.07
Topic: T31 – Cybersecurity & Digital Safety
Skill: Detect deepfake videos and AI-generated images using verification techniques
Description: Students learn to identify AI-generated media: (1) Examine sample deepfake videos for artifacts (unnatural blinking, blurred edges, inconsistent lighting, audio-lip sync issues), (2) Use reverse image search to find original sources, (3) Check metadata for signs of manipulation, (4) Apply the SIFT method (Stop, Investigate source, Find better coverage, Trace original). They analyze 5 media samples and correctly classify real vs AI-generated. They discuss how deepfakes threaten trust and list 3 situations where deepfakes could cause harm.

Dependencies:
* T31.G5.03: Compare app privacy policies using a data collection chart
* T31.G6.06: Identify AI-specific security threats in projects




ID: T31.G8.08
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze AI-enhanced phishing attacks and their detection
Description: Students examine how AI makes attacks more dangerous: (1) Compare traditional phishing (generic text, spelling errors) vs AI-generated phishing (personalized, perfect grammar, mimics writing style), (2) Analyze voice phishing (vishing) using AI voice cloning, (3) Identify new detection challenges when AI removes obvious red flags. They develop updated detection strategies: verify through separate channels, use code words with family, question urgency. They create a "trust but verify" protocol for suspicious communications.

Dependencies:
* T31.G6.02: Analyze phishing emails using advanced detection techniques
* T31.G7.07: Detect deepfake videos and AI-generated images using verification techniques




ID: T31.G8.09
Topic: T31 – Cybersecurity & Digital Safety
Skill: Apply zero-trust security principles to project design
Description: Students learn zero-trust architecture: "never trust, always verify." They apply principles: (1) Verify every request regardless of source (check permissions even for logged-in users), (2) Use least-privilege access (give minimum permissions needed), (3) Assume breach (design as if attackers are already inside). They redesign a sample project with zero-trust principles: add verification at each step, remove implicit trust in internal components, log all access attempts. They compare before/after security posture.

Dependencies:
* T31.G8.02: Implement role-based access control in CreatiCode projects
* T31.G8.06: Implement secure session management in multi-user projects




ID: T31.G8.10
Topic: T31 – Cybersecurity & Digital Safety
Skill: Debug security vulnerabilities using systematic testing
Description: Students practice structured security debugging: (1) Given a project with intentional security flaws, systematically test each input/feature, (2) Document each vulnerability found with reproduction steps, (3) Prioritize by severity (data exposure > functionality break > cosmetic), (4) Fix vulnerabilities one at a time and verify each fix doesn't break functionality, (5) Re-test to confirm vulnerabilities are closed. They debug a sample project with 5 planted vulnerabilities and successfully find and fix at least 4.

Dependencies:
* T31.G8.01.04: Write professional security test reports with severity ratings
* T31.G7.06: Implement input sanitization to prevent manipulation




ID: T31.G8.11
Topic: T31 – Cybersecurity & Digital Safety
Skill: Build comprehensive multiplayer game security with anti-cheat measures
Description: Students implement multiple security layers in a multiplayer CreatiCode game: (1) Password-protected rooms, (2) Sanitized display names, (3) Server-validated scoring (check if score increases are plausible based on game rules), (4) Rate-limited actions (prevent impossible action speeds), (5) Secure game state synchronization using cloud variables. They implement a "suspicious activity" detection system that flags players for manual review. They test by attempting common cheating methods and verify detection.

Dependencies:
* T31.G7.08: Implement secure cloud variable usage for multiplayer data
* T31.G7.09: Build a chat moderation system for multiplayer projects
* T31.G8.02: Implement role-based access control in CreatiCode projects




ID: T31.G8.12
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement data encryption for sensitive cloud storage
Description: Students implement basic data protection for cloud-stored data in CreatiCode: (1) Use their Caesar cipher (or a simple substitution) to encrypt sensitive data before storing in cloud variables, (2) Decrypt data when reading from cloud, (3) Store the encryption key separately (not in cloud variables), (4) Test that encrypted data is unreadable without the key. They discuss limitations of simple encryption and why real applications use stronger methods. They list 3 types of data that should always be encrypted.

Dependencies:
* T31.G7.01: Extend Caesar cipher with wrap-around and case handling
* T31.G7.08: Implement secure cloud variable usage for multiplayer data




ID: T31.G8.13
Topic: T31 – Cybersecurity & Digital Safety
Skill: Test AI systems for adversarial input vulnerabilities
Description: Students systematically test AI components in their projects for adversarial inputs: (1) Test prompt injection with "ignore all previous instructions" variants, (2) Test input that tries to leak system prompts, (3) Test edge cases (empty input, very long input, special characters), (4) Test inputs designed to produce harmful outputs, (5) Document each test case, expected behavior, actual behavior, and severity. They implement fixes for discovered vulnerabilities and create an "AI security test suite" they can reuse.

Dependencies:
* T31.G8.03.01: Test chatbots for prompt injection vulnerabilities
* T31.G8.01.04: Write professional security test reports with severity ratings




ID: T31.G8.14
Topic: T31 – Cybersecurity & Digital Safety
Skill: Implement privacy-preserving camera/microphone consent in projects
Description: Students build robust consent systems for sensor-using projects: (1) Display clear consent prompt before activating camera/microphone, (2) Store consent choice in variable and respect it throughout session, (3) Add visible indicator (colored dot/icon) when camera/mic is active, (4) Implement "revoke consent" button that stops recording immediately, (5) Add timeout that auto-stops recording after set time. They test that the system cannot be bypassed and create a "sensor privacy checklist" for reviewing similar projects.

Dependencies:
* T31.G5.08: Implement consent prompts in CreatiCode projects using widgets
* T31.G8.03.03: Audit sensor-based projects for privacy vulnerabilities




ID: T31.G8.15
Topic: T31 – Cybersecurity & Digital Safety
Skill: Conduct penetration testing on peer projects using ethical methodology
Description: Students perform ethical security testing on classmate projects (with permission): (1) Define scope and get written consent, (2) Test authentication systems for bypasses, (3) Test input fields for injection vulnerabilities, (4) Test for unauthorized data access, (5) Test AI components for prompt injection, (6) Document all findings professionally. They present findings privately to project owner, suggest fixes without exploiting vulnerabilities, and help verify fixes are effective. They reflect on the ethical responsibilities of security testing.

Dependencies:
* T31.G8.10: Debug security vulnerabilities using systematic testing
* T31.G8.07: Build a comprehensive security checklist for project review
* T31.G6.07: Compare ethical vs malicious hacking through case studies




ID: T31.G8.16
Topic: T31 – Cybersecurity & Digital Safety
Skill: Design a security-first project architecture from scratch
Description: Students design and document a secure architecture before building: (1) Identify all user inputs and data flows, (2) List security requirements for each (validation, sanitization, encryption), (3) Design authentication and authorization systems, (4) Plan logging and monitoring, (5) Create threat model listing potential attacks and defenses, (6) Document privacy protections and consent mechanisms. They peer-review architecture documents and implement a project following their secure design, then verify security through testing.

Dependencies:
* T31.G8.07: Build a comprehensive security checklist for project review
* T31.G8.09: Apply zero-trust security principles to project design
* T31.G8.11: Build comprehensive multiplayer game security with anti-cheat measures




ID: T31.G8.17
Topic: T31 – Cybersecurity & Digital Safety
Skill: Compare privacy regulations (COPPA, GDPR, CCPA)
Description: Students compare major privacy regulations and understand their rights: (1) COPPA (Children's Online Privacy Protection Act) - protects under-13 users in US, requires parental consent for data collection, (2) GDPR (General Data Protection Regulation) - EU law giving users control over personal data, right to access, delete, and port data, (3) CCPA (California Consumer Privacy Act) - California law with similar rights to GDPR. They create a comparison chart: What region? Who is protected? What rights? What data needs consent? They identify which laws apply to them and practice exercising rights (data access request, account deletion). They discuss why global companies often apply strictest law to everyone.

Dependencies:
* T31.G7.12: Identify key children's online privacy rights (COPPA)
* T31.G5.03: Compare app privacy policies using a data collection chart




ID: T31.G8.18
Topic: T31 – Cybersecurity & Digital Safety
Skill: Analyze cryptocurrency and NFT scams targeting youth
Description: Students learn to identify crypto/NFT scams common in youth spaces: (1) "Get rich quick" schemes (promise guaranteed profits, require upfront payment), (2) Fake giveaways (celebrity impersonation, "send 1 coin get 2 back"), (3) Pump and dump (influencers promote coin then sell), (4) NFT rug pulls (project disappears after collecting money), (5) Phishing for wallet credentials. They analyze 5 real-world examples and identify red flags: unrealistic promises, urgency, celebrity endorsement, requires seed phrase/private key. They explain why these target young people (FOMO, peer pressure, unfamiliarity) and list protective actions (research before investing, never share wallet keys, be skeptical of guaranteed returns).

Dependencies:
* T31.G5.01b: Identify phishing attacks across multiple formats
* T31.G4.10: Recognize in-app purchase and subscription traps




ID: T32.GK.01
Topic: T32 – Digital Citizenship
Skill: Sort pictures of technology helping people into categories
Description: Students sort picture cards showing technology use into two piles: "technology helping" (video calling grandma, using a drawing app for homework, watching an educational video) and "not helping right now" (screen time during dinner, ignoring a friend to play games). For each "helping" card, students point to who is being helped and say one word about how (e.g., "learning," "talking," "making"). This builds foundational understanding that technology is a tool with purposes.





ID: T32.GK.02
Topic: T32 – Digital Citizenship
Skill: Match screen time scenarios to feeling cards
Description: Students look at picture cards showing different screen time scenarios (tired eyes after long game session, missing outdoor play with friends, feeling energetic after a break). They drag each scenario card to a matching feeling card (tired face, sad face, happy face, healthy face). Students explain their matches by saying phrases like "too much screen makes tired" or "taking breaks helps feel good." They sequence three picture cards showing a healthy pattern: play, break, play.

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.GK.03
Topic: T32 – Digital Citizenship
Skill: Sort device sharing behaviors into kind and not-kind categories
Description: Students sort picture cards showing device sharing behaviors into two labeled boxes: "kind sharing" (waiting your turn, asking "may I please use it?", offering to share, setting a timer) and "not kind" (grabbing device, pushing, saying "it's mine!", not letting others try). For each card sorted, students act out saying the kind words or show what the kind action looks like. They practice the phrase "May I have a turn?" and "Your turn next!"

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.GK.04
Topic: T32 – Digital Citizenship
Skill: Choose yes or no cards for safe sharing scenarios
Description: Students view picture scenarios where a cartoon character asks for information (What's your name? Where do you live? What's your favorite color? Can I see your photo?). For each scenario, students hold up a green "yes, safe to share" or red "no, keep private" card. After each choice, they explain why: "Favorite color is okay because strangers can't find me with it" vs "My address is private because strangers shouldn't know where I live." Students practice the safety phrase: "I need to ask a grown-up first."

Dependencies:
* T32.GK.01: Sort pictures of technology helping people into categories





ID: T32.GK.05
Topic: T32 – Digital Citizenship
Skill: Match community helpers to digital tools using picture cards
Description: Students drag picture cards of workers (teacher, doctor, farmer, artist) onto picture cards of the digital tools they use (tablet, scanner, drone, camera). For each match, students point to the worker and say one way the tool helps that worker do their job better (e.g., "The doctor uses the tablet to see patient pictures").

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.GK.06
Topic: T32 – Digital Citizenship
Skill: Select kind responses for device sharing using picture cards
Description: Students view picture cards showing scenarios where two children want to use the same tablet. They select the picture card showing the kind response (sharing, taking turns, using a timer) from a set of options. Students explain why the kind choice helps everyone by pointing to consequence picture cards (happy faces, task completed together).

Dependencies:
* T32.GK.03: Sort device sharing behaviors into kind and not-kind categories





ID: T32.GK.07
Topic: T32 – Digital Citizenship
Skill: Explain what a digital tool helps someone do using picture cards
Description: Given a picture card of someone using a tool (drawing on a tablet, having a video call, taking a photo), students point to and name the task it helps with. Students select from picture cards showing different purposes (learning, talking, making, playing) and match them to the tool picture. They say one sentence explaining the match (e.g., "The video call helps grandma talk to us").

Dependencies:
* T32.GK.05: Match community helpers to digital tools using picture cards





ID: T32.GK.08
Topic: T32 – Digital Citizenship
Skill: Describe ways people work together using picture cards
Description: Students look at picture cards showing teams working together (doctors and nurses, teachers and students, builders) and point to examples of people helping each other. Students describe one way the team members help each other using the picture cards as prompts.

Dependencies:
* T32.GK.06: Take turns using a device to complete a task together





ID: T32.G1.01
Topic: T32 – Digital Citizenship
Skill: Sort good vs not-so-good choices and explain why
Description: Students categorize technology behaviors (pausing game to eat vs ignoring responsibilities) into "good for me"/"not good for me" using picture cards, then explain their reasoning by connecting each choice to a consequence picture (e.g., "Pausing to eat is good because it keeps me healthy").

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.G1.02
Topic: T32 – Digital Citizenship
Skill: Match feelings to technology experiences
Description: Students match pictures of emotions (happy, sad, frustrated, excited) to technology scenarios (winning a game, losing progress, video calling family, waiting for slow loading) to understand emotional impacts of tech use.

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.G1.03
Topic: T32 – Digital Citizenship
Skill: Circle design choices made by app creators
Description: Students look at picture cards showing app screens and circle design choices made by creators (characters, colors, sounds). They match circled elements to "someone chose this" labels to understand that people make technology choices.

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed





ID: T32.G1.04
Topic: T32 – Digital Citizenship
Skill: Match uncomfortable scenarios to trusted adults using picture cards
Description: Students use picture cards showing uncomfortable technology scenarios (mean message, scary image, stranger asking questions) and match them with picture cards of trusted adults who can help (parent, teacher, librarian).

Dependencies:
* T32.G1.02: Match feelings to technology experiences





ID: T32.G1.05
Topic: T32 – Digital Citizenship
Skill: Sort picture cards of jobs that use computers
Description: Students sort picture cards showing different professions (scientist, musician, builder, nurse, chef) into piles: "uses computers" and "does not use computers." For each job placed in the "uses computers" pile, students point to a picture card showing how that worker uses a digital tool.

Dependencies:
* T32.GK.07: Describe what a digital tool helps someone do





ID: T32.G1.06
Topic: T32 – Digital Citizenship
Skill: Sort technology scenarios into helps vs causes problems categories
Description: Students sort picture cards showing technology scenarios (video chat with grandma, staying up too late playing games, learning with educational videos, eyes hurting from too much screen) into two labeled boxes: "helps me" and "causes problems." For each card, students complete the sentence: "This [helps/causes problems] because ___." Students identify that the same technology (like games) can sometimes help (learning game) and sometimes cause problems (playing too long).

Dependencies:
* T32.G1.05: Sort picture cards of jobs that use computers





ID: T32.G1.07
Topic: T32 – Digital Citizenship
Skill: Select picture cards showing good listening behaviors
Description: Students select picture cards showing good listening behaviors (eyes on speaker, waiting to talk, nodding) from a set that also includes poor listening (interrupting, looking away). Students sort cards into "good listener" and "not listening" piles and explain why teams need good listeners.

Dependencies:
* T03.GK.01: Tap picture cards to identify parts of a whole object





ID: T32.G1.08
Topic: T32 – Digital Citizenship
Skill: Match picture cards of digital creators to their creations
Description: Students use picture cards showing people who make digital things (game designer, app builder, animator, music producer). They drag each creator card to match with a picture card of what they create (a game, an app on a phone, a cartoon character, a song). For each match, students say one thing that creator needs to know how to do (e.g., "game designer needs to know what makes games fun").

Dependencies:
* T32.G1.05: Sort picture cards of jobs that use computers





ID: T32.G2.01
Topic: T32 – Digital Citizenship
Skill: Compare benefits and harms of a tech tool
Description: Students create simple pros/cons charts for tools like video sharing or messaging apps. They list at least 2 positives and 2 negatives for each tool, then draw or place pictures showing examples of each benefit and harm to create a visual comparison chart.

Dependencies:
* T01.G1.07: Decide if two algorithms finish with the same result





ID: T32.G2.02
Topic: T32 – Digital Citizenship
Skill: Plan balanced tech schedules
Description: Learners design a simple daily routine that includes device time, outdoor play, meals, and sleep using picture cards and timers.

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed
* T03.G1.03: List steps for a simple classroom routine





ID: T32.G2.03
Topic: T32 – Digital Citizenship
Skill: Practice online kindness scripts
Description: Students role-play responses to unkind messages (ignore, block, tell adult) and practice writing positive messages. They use picture cards showing scenarios and speech bubbles to practice kind communication strategies.

Dependencies:
* T01.G1.01: Put pictures in order to plant a seed





ID: T32.G2.04
Topic: T32 – Digital Citizenship
Skill: Distinguish public vs. private information
Description: Students sort information cards (name, favorite color, home address, birthday, pet's name) into 'okay to share online' and 'keep private' piles. For each card, they explain WHY the information is private or safe to share (e.g., "Home address is private because strangers could find where you live" or "Favorite color is safe because it doesn't help anyone locate you").

Dependencies:
* T32.G2.01: Compare benefits and harms of a tech tool





ID: T32.G2.05
Topic: T32 – Digital Citizenship
Skill: Match project roles to tasks using picture cards
Description: Students use picture cards to match roles (story planner, builder, tester) to task cards in a project. For example, the "builder" card matches to "puts blocks together," the "tester" card matches to "tries it out," and the "planner" card matches to "decides what to make."

Dependencies:
* T32.G1.05: List jobs that rely on computers





ID: T32.G2.06
Topic: T32 – Digital Citizenship
Skill: Build a picture schedule balancing screen time with other activities
Description: Students build a picture schedule using activity cards showing how screen/device time fits alongside other activities (reading, outside play, meals, sleep). They arrange cards to create a balanced day and explain why balancing tech use with other activities keeps us healthy.

Dependencies:
* T32.G2.02: Plan balanced tech schedules
* T03.G1.03: List steps for a simple classroom routine





ID: T32.G2.07
Topic: T32 – Digital Citizenship
Skill: Draw or describe teammates' different strengths
Description: Students draw or write about how classmates contribute different skills to a project using picture prompts. One friend might be good at drawing, another at building, another at telling stories. Students explain why having different strengths makes a team better.

Dependencies:
* T32.G2.05: Identify project roles in simple terms





ID: T32.G2.08
Topic: T32 – Digital Citizenship
Skill: Name jobs where people create digital things
Description: Students identify careers where people create digital content (game designer, animator, app builder) through picture sorting. Students describe what each job creates and one tool they might use.

Dependencies:
* T32.G1.05: List jobs that rely on computers
* T32.GK.07: Describe what a digital tool helps someone do





ID: T32.G2.09
Topic: T32 – Digital Citizenship
Skill: Practice polite communication using scenario cards
Description: Students use picture scenario cards showing group work situations. They practice using kind words when working together ("please," "thank you," "great idea!") by selecting speech bubble cards with polite phrases to match each scenario. Students role-play asking for help, offering help, or giving a compliment.

Dependencies:
* T32.GK.06: Take turns using a device to complete a task together
* T32.G1.07: Select picture cards showing good listening behaviors





ID: T32.G2.10
Topic: T32 – Digital Citizenship
Skill: Sort information sources into trustworthy and not-sure categories
Description: Students sort picture cards showing information sources into two piles: "trustworthy" (teacher showing a book, parent explaining, library website, school news) and "not sure" (random person online, pop-up ad, message from stranger, flashy website with no author). For each card, students explain their sorting using simple criteria: "Do I know who said this?" and "Would a grown-up I trust agree?" This builds foundational information literacy for later source evaluation skills.

Dependencies:
* T32.G2.01: Compare benefits and harms of a tech tool
* T32.G1.04: Match uncomfortable scenarios to trusted adults using picture cards




ID: T32.G3.01
Topic: T32 – Digital Citizenship
Skill: Build digital footprint checker with warning labels
Description: Students create a project where typing a sample post (text input widget) displays a warning label if it contains common personal information keywords. Using if-blocks, they check for words like 'address', 'phone', 'school', 'live at' and display different warning messages (label widgets) for each type. Students test by categorizing 5 sample posts as 'safe to share' or 'reveals too much' based on which warnings appear.

Dependencies:
* T32.G2.01: Compare benefits and harms of a tech tool
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T15.G3.01: Add a label widget to display text
* T08.G3.04: Use a simple if in a script





ID: T32.G3.02
Topic: T32 – Digital Citizenship
Skill: Build a recommendation simulator to analyze how algorithms influence content
Description: Students build a simple recommendation simulator using variables, conditionals, and data visualization. They create a project where clicking different content types (sports, music, gaming) increments counters in a table variable. Using if-blocks and comparison operators, the program displays different "recommended content" labels based on which counters are highest, demonstrating how algorithms track behavior to shape recommendations. Students document patterns they observe and explain how this shapes viewing habits.

Dependencies:
* T32.G3.01: Build digital footprint checker with warning labels
* T08.G3.04: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage using the variable monitor





ID: T32.G3.03
Topic: T32 – Digital Citizenship
Skill: Build an AI-moderated chat room with class communication guidelines
Description: Students build a simple moderated chat room using widget blocks (text input, labels, buttons) and AI moderation. They create a chat interface where users type messages into a text input widget. Before displaying messages in a label widget, the program uses ChatGPT AI moderation blocks to check for inappropriate content (spam, unkindness, PII). If content violates guidelines, a warning label appears instead. Students collaboratively write the guidelines that inform the AI moderation prompts, then test with sample messages.

Dependencies:
* T32.G3.01: Build digital footprint checker with warning labels
* T08.G3.04: Use a simple if in a script
* T15.G3.01: Add a label widget to display text
* T21.G3.01: Use ChatGPT blocks for simple queries





ID: T32.G3.04
Topic: T32 – Digital Citizenship
Skill: Build an app that shows what data it collects
Description: Students build a simple app (quiz or game) that collects data using variables and widgets. They create visible indicators showing what's being collected: labels that update to show "You've answered 5 questions" (counter variable), "Your high score: 100" (performance data), "You clicked on: Animals" (preference tracking). Students then explain what the app "knows" about users and whether users can see what's collected.

Dependencies:
* T32.G3.01: Evaluate digital footprints
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T15.G3.01: Add a label widget to display text





ID: T32.G3.05
Topic: T32 – Digital Citizenship
Skill: Interview classmates to understand project needs
Description: Students interview a classmate or family member about what they would like in a simple app or game. Students write down at least two ideas they learned from their interview and practice asking follow-up questions.

Dependencies:
* T32.G2.05: Match project roles to tasks using picture cards





ID: T32.G3.06
Topic: T32 – Digital Citizenship
Skill: Draft simple team agreements
Description: Students fill out a team charter listing: team member names, each person's role (builder, tester, planner), the project goal, and one rule for working together (like "listen when others talk"). Teams discuss and agree on their charter.

Dependencies:
* T32.G3.05: Ask classmates simple questions to understand project needs





ID: T32.G3.07
Topic: T32 – Digital Citizenship
Skill: Reflect on collaboration habits
Description: After a group activity, students answer: "What did our team do well?" and "What could we do better next time?" Students write or say one specific thing they will try differently.

Dependencies:
* T32.G3.06: Draft simple team agreements





ID: T32.G3.08
Topic: T32 – Digital Citizenship
Skill: Identify what coders and digital designers do
Description: Students watch a short video or look at pictures of programmers and digital designers at work. Students describe one thing these workers do (like write code or draw characters) and one tool they use (like a computer or drawing tablet).

Dependencies:
* T32.G2.08: Name jobs where people create digital things





ID: T32.G3.09
Topic: T32 – Digital Citizenship
Skill: Practice giving and receiving helpful feedback
Description: Students practice giving kind and specific feedback on a classmate's work ("I like how you used bright colors" or "Maybe add a sound effect"). Students also practice saying "thank you" when receiving feedback, even if they disagree.

Dependencies:
* T32.G2.09: Practice polite communication in group work
* T32.G3.07: Reflect on collaboration habits





ID: T32.G4.01
Topic: T32 – Digital Citizenship
Skill: Read and categorize tech impact case studies
Description: Students read provided case studies (drones delivering meds vs drones invading privacy, social media connecting vs isolating people) and organize them into a table variable with columns: technology, benefits, harms, affected community. They identify which communities are helped vs. harmed in each scenario.

Dependencies:
* T04.G2.01: Identify the repeating unit in a longer pattern
* T04.G2.02: Spot repeated step sequences in everyday algorithms
* T32.G3.01: Evaluate digital footprints





ID: T32.G4.02
Topic: T32 – Digital Citizenship
Skill: Build interactive case study viewer with widgets
Description: Students build an interactive case study viewer using widget blocks: buttons to select different case studies, and labels to display benefits/harms for each case. The viewer reads from the table variable created in T32.G4.01 and displays the organized information clearly.

Dependencies:
* T32.G4.01: Read and categorize tech impact case studies
* T07.G3.01: Use repeat blocks to simplify code
* T15.G4.01: Style widget text properties





ID: T32.G4.03
Topic: T32 – Digital Citizenship
Skill: Analyze technology impact tradeoffs
Description: Using the case study viewer, students analyze each scenario to identify tradeoffs: What is gained? What is lost? Who benefits? Who is harmed? They document at least 2 tradeoffs per case study and explain why the same technology can have different impacts on different groups.

Dependencies:
* T32.G4.02: Build interactive case study viewer with widgets





ID: T32.G4.04
Topic: T32 – Digital Citizenship
Skill: Compare persuasive vs informative design patterns
Description: Students analyze actual CreatiCode community projects to identify persuasive design patterns (bright colors for "buy" buttons, countdown timers, celebrity endorsements in sprites). They create a project that demonstrates persuasive vs. informative design: two versions of the same app (e.g., a game invitation) where one uses persuasive tactics (flashing sprites, urgent language in labels) and one is neutral. Using widget blocks, they build both interfaces and have peers compare them, documenting which tactics they notice.

Dependencies:
* T04.G3.01: Use pattern recognition to simplify algorithms
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use repeat blocks to simplify code
* T15.G4.01: Style widget text properties
* T32.G3.02: Discuss how algorithms influence what we see





ID: T32.G4.05
Topic: T32 – Digital Citizenship
Skill: Test game for audio accessibility
Description: Students test a CreatiCode game for audio accessibility by muting sound and attempting to play. They document: (1) Can game objectives be understood without audio? (2) Are there visual alternatives for sound effects (sprite flashes, text pop-ups)? (3) Can players know when important events happen without hearing? Students rate the game as "audio independent," "partially accessible," or "requires audio" and list specific audio-dependent elements that need visual alternatives.

Dependencies:
* T05.G3.01: Put human‑centered design steps in order
* T12.G3.01: Test and trace simple block-based scripts

ID: T32.G4.05.01
Topic: T32 – Digital Citizenship
Skill: Test game for visual accessibility
Description: Students test a CreatiCode game for visual accessibility. They evaluate: (1) Are sprites large enough to see clearly? (2) Is there sufficient color contrast between game elements and background? (3) Is text readable (size, font clarity)? (4) Can colorblind users distinguish important elements? Students document findings in a checklist and rate each aspect as accessible/needs improvement/inaccessible.

Dependencies:
* T32.G4.05: Test game for audio accessibility

ID: T32.G4.05.02
Topic: T32 – Digital Citizenship
Skill: Test game for input accessibility
Description: Students test a CreatiCode game for input accessibility by trying to play using only keyboard (no mouse) and documenting results. They check: (1) Can all actions be performed with keyboard? (2) Are there multiple control options? (3) Is the timing requirement reasonable for players with motor differences? Students list which controls work and which don't, proposing keyboard alternatives for mouse-only actions.

Dependencies:
* T32.G4.05.01: Test game for visual accessibility

ID: T32.G4.05.03
Topic: T32 – Digital Citizenship
Skill: Create accessibility testing checklist tool
Description: Students combine their audio, visual, and input accessibility testing knowledge to build a widget-based testing form. The form includes: checkboxes for each accessibility criterion, dropdown menus for ratings (accessible/needs improvement/inaccessible), text input fields for documenting specific issues. Results are stored in a table variable for comparison across games. Students test their tool on 2-3 different games to verify it captures meaningful accessibility data.

Dependencies:
* T32.G4.05.02: Test game for input accessibility
* T15.G4.01: Style widget text properties





ID: T32.G4.06
Topic: T32 – Digital Citizenship
Skill: Implement keyboard controls for accessibility
Description: Based on input accessibility barriers identified in T32.G4.05.02, students implement keyboard controls to make a mouse-dependent game accessible. They: (1) identify all mouse-only actions in the game, (2) add "when key pressed" blocks for each action (arrow keys for movement, space for select, etc.), (3) create a visible key mapping guide using label widgets showing "Press SPACE to jump" style instructions, (4) test with peers who use keyboard only. Students document which keys they chose and why, reflecting on how this change enables more players to enjoy the game.

Dependencies:
* T32.G4.05.03: Create accessibility testing checklist tool
* T15.G4.01: Style widget text properties

ID: T32.G4.06.01
Topic: T32 – Digital Citizenship
Skill: Add visual alternatives for audio cues
Description: Students identify audio-dependent elements in a game and add visual alternatives. For each sound effect (jump sound, collision, success/failure), they: (1) add a visual indicator (sprite flash, color change, text popup), (2) ensure the visual appears at the same time as the sound, (3) test by muting and verifying the game is still playable. Students create a comparison showing before (audio-only) and after (audio + visual) versions.

Dependencies:
* T32.G4.06: Implement keyboard controls for accessibility

ID: T32.G4.06.02
Topic: T32 – Digital Citizenship
Skill: Build accessibility settings menu
Description: Students create an in-game accessibility settings menu using widgets. The menu includes toggle buttons for: (1) high contrast mode (changes background/sprite colors), (2) larger text option, (3) sound on/off with visual cue option. When toggled, these settings immediately update the game display. Students use variables to store user preferences and apply them throughout the game, demonstrating user control over their experience.

Dependencies:
* T32.G4.06.01: Add visual alternatives for audio cues





ID: T32.G4.07
Topic: T32 – Digital Citizenship
Skill: Create a digital citizen pledge project
Description: Students use block coding to build an interactive pledge where users click to commit to positive online behaviors (be kind, protect privacy, ask before sharing) and see encouraging responses. The project uses button widgets for each pledge and displays affirmations when clicked.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T07.G3.01: Use repeat blocks to simplify code
* T32.G3.01: Evaluate digital footprints
* T32.G3.03: Develop class guidelines for respectful communication





ID: T32.G4.08
Topic: T32 – Digital Citizenship
Skill: Identify diverse tech careers via profiles and videos
Description: Students watch videos or read profiles about different technologists (UX designer, robotics technician, accessibility advocate). For each career, students write down: (1) what the person does daily, (2) what tools they use, and (3) one interesting fact.

Dependencies:
* T32.G3.05: Interview classmates to understand project needs
* T32.G3.08: Identify what coders and digital designers do





ID: T32.G4.09
Topic: T32 – Digital Citizenship
Skill: Track work with a shared checklist
Description: Teams create a simple three-column chart (To Do / Doing / Done) on paper or whiteboard. They list tasks for a project, assign each task to a team member, and update the chart at least twice as they work.

Dependencies:
* T05.G3.01: Put human‑centered design steps in order
* T05.G3.02: Identify user needs from a short interview transcript
* T32.G2.07: Draw or describe teammates' different strengths
* T32.G3.06: Draft simple team agreements





ID: T32.G4.10
Topic: T32 – Digital Citizenship
Skill: Role-play resolving disagreements in a coding or design project
Description: Students act out scenarios where teammates disagree about a project decision (color scheme, character choice, which feature to add first). Students practice: (1) listening to both sides, (2) asking what the user needs, and (3) finding a fair solution together.

Dependencies:
* T32.G3.06: Draft simple team agreements
* T32.G3.07: Reflect on collaboration habits





ID: T32.G4.11
Topic: T32 – Digital Citizenship
Skill: Categorize tech jobs by what they create
Description: Students sort tech career cards into categories: (1) people who make games, (2) people who build apps, (3) people who analyze data, (4) people who design how things look. Students give one example job for each category.

Dependencies:
* T32.G2.08: Name jobs where people create digital things
* T32.G4.08: Identify diverse tech careers via profiles and videos





ID: T32.G4.12
Topic: T32 – Digital Citizenship
Skill: Match skills to tech job requirements
Description: Students match skills (drawing, math, writing, problem-solving, talking to people) to different tech jobs. Students explain why a game designer needs creativity or why a data analyst needs math skills.

Dependencies:
* T32.G4.08: Identify diverse tech careers via profiles and videos
* T32.G4.11: Categorize tech jobs by what they create




ID: T32.G4.13
Topic: T32 – Digital Citizenship
Skill: Ask basic AI fairness questions about CreatiCode projects
Description: Students practice asking simple AI ethics questions when evaluating CreatiCode projects that use AI features (ChatGPT, image generation). They ask: (1) Does this AI feature help the user? How? (2) Could this AI feature make mistakes? What happens then? (3) Does everyone get the same quality results? Students test AI features with different inputs (simple vs complex prompts, different topics) and document whether results seem fair and helpful. This scaffolds the formal ethics frameworks introduced in G5-G6.

Dependencies:
* T32.G3.03: Develop class guidelines for respectful communication
* T32.G4.03: Analyze technology impact tradeoffs





ID: T32.G5.01
Topic: T32 – Digital Citizenship
Skill: Document technology impacts in one community with evidence
Description: Students research a specific technology (e.g., mobile banking, telemedicine, agricultural drones) and document its benefits and challenges in one specific community. They gather evidence from at least 3 sources, evaluate source credibility, and create a summary chart with citations showing specific impacts (number of people affected, percentage changes, before/after comparisons).

Dependencies:
* T32.G4.03: Analyze technology impact tradeoffs





ID: T32.G5.02
Topic: T32 – Digital Citizenship
Skill: Compare impacts across two communities
Description: Building on T32.G5.01, students research the same technology in a second, different community (urban vs. rural, developed vs. developing nation, high vs. low income). They create a comparison chart showing how benefits and challenges differ between the two communities.

Dependencies:
* T32.G5.01: Research technology impacts in one community





ID: T32.G5.03
Topic: T32 – Digital Citizenship
Skill: Explain why technology impacts differ across contexts
Description: Students analyze their comparison from T32.G5.02 to explain WHY the same technology has different impacts in different communities. They consider factors like infrastructure, resources, culture, education, and existing inequalities. They present their analysis with specific evidence from their research.

Dependencies:
* T32.G5.02: Compare impacts across two communities





ID: T32.G5.04
Topic: T32 – Digital Citizenship
Skill: Argue positions on digital well-being policies with evidence
Description: Students debate policy scenarios (device-free times, notifications settings, screen time limits) using evidence from research on focus, sleep, and mental health. They reference specific studies or data and use structured debate formats (claim, evidence, reasoning) to support their positions. Each student must argue both sides to understand multiple perspectives.

Dependencies:
* T32.G4.03: Analyze technology impact tradeoffs
* T32.G4.05: Test game for audio accessibility





ID: T32.G5.05
Topic: T32 – Digital Citizenship
Skill: Analyze AI's differential impacts on workers and communities
Description: Learners research how AI affects different communities unequally: which jobs are most at risk, how impacts vary by education/income level, geographic disparities in AI adoption, and how T20-T23 AI tools might worsen or improve equity. They propose reskilling and policy solutions with social justice focus.

Dependencies:
* T32.G4.03: Identify tradeoffs in technology impacts
* T32.G4.04: Understand advertising/persuasion online
* T09.G4.01: Create and update a variable with meaningful names





ID: T32.G5.06
Topic: T32 – Digital Citizenship
Skill: Explain Consent for AI Data Collection
Description: Students research a technology's impact on different stakeholders (e.g., AI chatbots impact: students, teachers, tutors, textbook companies). They collect impact data via widget-based surveys (rating scales 1-5: How much does this help/harm you?). Responses are stored in Google Sheets using cloud blocks. Students create data visualizations using table variables showing which groups benefit most/least, then discuss equity implications.

Dependencies:
* T32.G5.05: Analyze AI's differential impacts on workers and communities
* T18.G5.01: Store data in a Google Sheet using blocks
* T15.G5.01: Build a simple survey using widgets





ID: T32.G5.07
Topic: T32 – Digital Citizenship
Skill: Apply simple ethics questions to technology decisions
Description: Students learn to ask basic ethics questions when evaluating technologies: (1) Does it help people? Who benefits most?, (2) Is it fair? Can everyone use it?, (3) Do users have control and choice? They practice applying these questions to familiar technologies (apps, games, school tools) and document their evaluations. This scaffolds the formal ethics frameworks in G6.

Dependencies:
* T32.G5.03: Explain why technology impacts differ across contexts
* T32.G5.04: Debate digital well-being scenarios





ID: T32.G5.08
Topic: T32 – Digital Citizenship
Skill: Evaluate online sources using credibility criteria
Description: Students evaluate online information sources by checking: (1) Author/organization credentials, (2) Publication date and currency, (3) Evidence and citations provided, (4) Bias and purpose (inform vs. persuade vs. sell), (5) Corroboration with other sources. They rate sources as high/medium/low credibility and explain their reasoning.

Dependencies:
* T32.G5.01: Research technology impacts in one community





ID: T32.G5.09
Topic: T32 – Digital Citizenship
Skill: Audit and reduce digital footprints using a checklist tool
Description: Students audit their own digital footprint by searching their name, reviewing app permissions, and checking what information they've shared online. They build a project using widgets that demonstrates footprint reduction strategies: a checklist tool showing steps to limit data collection, adjust privacy settings, and review permissions. Students create a "before/after" comparison of their digital exposure with specific metrics (number of apps with location access, public posts found, etc.).

Dependencies:
* T32.G3.01: Build digital footprint checker with warning labels
* T32.G4.03: Analyze technology impact tradeoffs
* T15.G5.01: Build a simple survey using widgets




ID: T32.G5.10
Topic: T32 – Digital Citizenship
Skill: Map personal interests to tech pathways
Description: Students list their hobbies and strengths (music, storytelling, sports, helping people, art). Then they match each interest to a tech role that uses it (sound designer, narrative designer, sports data analyst, civic technologist, graphic designer). Students explain why each match makes sense.

Dependencies:
* T32.G4.11: Categorize tech jobs by what they create
* T32.G4.08: Identify diverse tech careers via profiles and videos





ID: T32.G5.10a
Topic: T32 – Digital Citizenship
Skill: Execute a plan-build-feedback iteration cycle
Description: Teams complete one iteration cycle: (1) plan a small CreatiCode feature together documenting requirements, (2) build it using blocks, (3) have another student test it and provide specific, written feedback, (4) document what to improve with action items. Students demonstrate understanding of iterative development by comparing their first version to the revised version and explaining how feedback improved the project.

Dependencies:
* T32.G4.09: Track work with a shared checklist
* T32.G3.07: Reflect on collaboration habits





ID: T32.G5.11
Topic: T32 – Digital Citizenship
Skill: Evaluate representation and inclusion in tech career stories
Description: Students review tech marketing materials, career profiles, or news images. They identify: (1) who is shown (age, gender, background), (2) who might be missing, and (3) why diverse representation matters. Students sketch or describe a more inclusive alternative.

Dependencies:
* T32.G4.08: Identify diverse tech careers via profiles and videos
* T32.G3.05: Interview classmates to understand project needs





ID: T32.G5.12
Topic: T32 – Digital Citizenship
Skill: Lead a team check-in meeting
Description: Students take turns leading a 5-minute team check-in where each member shares: (1) what they finished, (2) what they're working on, and (3) if they need help. The leader makes sure everyone gets a turn and writes down any blockers.

Dependencies:
* T32.G4.09: Track work with a shared checklist
* T32.G4.10: Role-play resolving disagreements in a coding or design project





ID: T32.G5.13
Topic: T32 – Digital Citizenship
Skill: Identify tech careers that help others
Description: Students research tech jobs that focus on helping people: accessibility engineer (making tech usable for everyone), civic technologist (improving government services), health tech specialist (helping doctors and patients). Students describe how each job makes a positive difference.

Dependencies:
* T32.G5.09: Map personal interests to tech pathways
* T32.G5.11: Evaluate representation and inclusion in tech career stories





ID: T32.G6.01
Topic: T32 – Digital Citizenship
Skill: Test AI image generation for bias
Description: Students test CreatiCode's T20 image generation blocks for bias. They generate 10+ images with prompts like "doctor," "nurse," "CEO," "teacher," "engineer," "artist" and document demographic representation patterns using a table variable (columns: Prompt, Gender Observed, Race Observed, Age Observed, Stereotype Present?). They analyze patterns in the results.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T20.G6.01: Generate images with AI (DALL-E blocks)
* T32.G5.15: Create an accessibility testing checklist for projects
* T32.G5.05: Analyze AI's differential impacts on workers and communities





ID: T32.G6.02
Topic: T32 – Digital Citizenship
Skill: Test AI chatbots for accuracy and inclusivity
Description: Students test T21 ChatGPT blocks for accuracy and inclusivity by checking: (1) Does it cite training data sources?, (2) Does it generate verifiable misinformation? (test factual claims), (3) Does it understand different English dialects? (test with AAVE, Indian English, etc.). They log findings to a table variable with columns: Test Type, Input, Output, Issues Found, Accuracy Rating.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T21.G6.01: Use ChatGPT for complex conversations
* T32.G5.05: Analyze AI's differential impacts on workers and communities
* T32.G5.08: Evaluate online sources using credibility criteria





ID: T32.G6.03
Topic: T32 – Digital Citizenship
Skill: Build AI testing dashboard combining image and chatbot tests
Description: Students create a comprehensive testing dashboard using widgets that combines image generation and chatbot testing. The dashboard includes: dropdown to select AI tool (Image/Chat), text input for test prompt, buttons to record observations (Biased/Fair, Accurate/Inaccurate, Inclusive/Exclusive), and table display showing all logged test results. This consolidates data from T32.G6.01 and T32.G6.02.

Dependencies:
* T32.G6.01: Test AI image generation for bias
* T32.G6.02: Test AI chatbots for accuracy and inclusivity
* T15.G6.01: Create forms with multiple widget types





ID: T32.G6.04
Topic: T32 – Digital Citizenship
Skill: Apply beneficence lens (does it help? who benefits?)
Description: Students apply the beneficence ethics lens to CreatiCode projects by asking: Does this help people? Who benefits most? Who might be harmed? They use ChatGPT blocks to analyze project purpose and document their evaluation in a table variable.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T21.G6.01: Use ChatGPT for analysis tasks
* T32.G5.07: Apply simple ethics questions to technology decisions





ID: T32.G6.05
Topic: T32 – Digital Citizenship
Skill: Apply fairness lens (equal access and impact?)
Description: Students apply the fairness ethics lens to CreatiCode projects by asking: Can everyone use this equally? Are there accessibility barriers? Does it treat all users fairly? They test projects with accessibility features like text-to-speech and document barriers or inequities found.

Dependencies:
* T32.G6.04: Apply beneficence lens (does it help? who benefits?)
* T15.G6.01: Create forms with multiple widget types
* T32.G4.06: Implement accessibility improvements





ID: T32.G6.06
Topic: T32 – Digital Citizenship
Skill: Apply autonomy lens (user control and choice?)
Description: Students apply the autonomy ethics lens to CreatiCode projects by asking: Do users have control? Can they make informed choices? Is consent obtained? They check for consent mechanisms using widget buttons and evaluate whether users understand what data is collected and how it's used.

Dependencies:
* T32.G6.05: Apply fairness lens (equal access and impact?)
* T15.G6.01: Create forms with multiple widget types





ID: T32.G6.07
Topic: T32 – Digital Citizenship
Skill: Build ethics evaluation tool combining all lenses
Description: Students build a comprehensive ethics evaluation tool using widgets that combines all three lenses (beneficence, fairness, autonomy). The tool includes: dropdown menu to select lens, text input for project URL/name, and labels to display evaluation questions for each lens. They document findings in a table variable with columns: Project, Lens, Evidence, Rating. Students use the tool to evaluate their own and community projects.

Dependencies:
* T32.G6.06: Apply autonomy lens (user control and choice?)
* T32.G5.03: Explain why technology impacts differ across contexts





ID: T32.G6.08
Topic: T32 – Digital Citizenship
Skill: Analyze data privacy tradeoffs
Description: Students build an interactive privacy policy demonstrator using widgets and cloud data blocks. They create a sample app (e.g., a quiz or game) that collects data points (name, age, score, location). Using widget blocks, they build: (1) A consent interface with checkboxes (buttons) for each data type, (2) Labels showing what each data type enables ("Location → Show local leaderboard"), (3) A "Submit" button that only saves checked data to a cloud table variable. Students compare full-data vs. minimal-data versions to analyze which features truly need which data. They write privacy statements justifying each data collection.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T15.G6.01: Create forms with multiple widget types
* T18.G6.01: Store and retrieve data from cloud tables
* T32.G4.04: Compare persuasive vs informative design patterns
* T32.G5.03: Explain why technology impacts differ across contexts





ID: T32.G6.09
Topic: T32 – Digital Citizenship
Skill: Synthesize comprehensive AI ethics guidelines
Description: Using findings from T32.G6.03 testing dashboard, students synthesize comprehensive ethics guidelines for AI content generation (T20-T21). They: (1) Analyze test data using table variable operations to identify patterns (e.g., "80% of 'CEO' images showed men"), (2) Create an interactive ethics guidelines document using widgets: buttons to select AI type (Image/Chat), dropdown for ethical concern category (Bias, Misinformation, Inclusivity, Citation), labels displaying specific guidelines and evidence, (3) Develop decision frameworks: When is bias acceptable? How to write inclusive prompts? How to verify AI outputs? (4) Include concrete examples: "Good prompt: 'diverse group of doctors' vs Biased prompt: 'doctor'". Students present guidelines as a widget-based reference tool that other students can use when working with T21-T22 AI blocks.

Dependencies:
* T32.G6.03: Build AI testing dashboard combining image and chatbot tests
* T15.G6.01: Create forms with multiple widget types





ID: T32.G6.10
Topic: T32 – Digital Citizenship
Skill: Develop ethics guidelines for AI perception and assistance
Description: Students actively test AI perception and assistance tools to develop evidence-based guidelines. For perception: Test hand/body tracking with different skin tones and lighting, documenting accuracy variations. For coding assistants: Test AI coding help with different question types and English proficiency levels. Students build a testing demo using widgets that displays test results (table variables showing: test case, demographic/condition, accuracy rating, ethical concerns). Using findings, they create comprehensive guidelines addressing consent, surveillance concerns, equity in recognition accuracy, academic integrity, proper citation, and avoiding over-dependency.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T22.G6.01: Use AI perception tools (hand/body tracking)
* T32.G5.05: Analyze AI's differential impacts on workers and communities
* T32.G6.09: Synthesize comprehensive AI ethics guidelines





ID: T32.G6.11
Topic: T32 – Digital Citizenship
Skill: Analyze digital divide data
Description: Students interpret data charts and graphs showing digital divide indicators (broadband availability by region/income, device ownership by demographic, internet speeds, digital literacy rates). They identify patterns and disparities, then propose specific, actionable community interventions to address access gaps (community wifi hotspots, device lending programs, digital literacy classes).

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T32.G5.03: Explain why technology impacts differ across contexts
* T32.G5.05: Analyze AI's differential impacts on workers and communities





ID: T32.G6.12
Topic: T32 – Digital Citizenship
Skill: Build consent form and data collection system
Description: Students build a consent-based data collection system using widgets and conditional logic. They create: (1) A clear consent form with checkboxes (button widgets) for each data type (name, age, location, usage stats), (2) Explanatory labels for each data type showing why it's needed and how it will be used (e.g., "Location → Show local leaderboard and connect you with nearby users"), (3) Conditional data collection logic: Use if-blocks to check consent checkboxes before saving each data type to cloud tables, (4) Visual feedback: Labels showing which data was collected based on consent choices. Students test with different consent combinations to verify only consented data is stored.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T15.G6.01: Create forms with multiple widget types
* T18.G6.01: Store and retrieve data from cloud tables
* T32.G6.08: Analyze data privacy tradeoffs





ID: T32.G6.13
Topic: T32 – Digital Citizenship
Skill: Implement data viewing and deletion controls
Description: Building on T32.G6.12, students implement user data control features that demonstrate data ownership principles. They add: (1) "View my data" button that retrieves user's stored records from cloud tables and displays them in organized table widgets (showing what data exists, when it was collected, how it's being used), (2) "Delete my data" button that removes user records from cloud storage with confirmation dialog (button widget: "Are you sure?"), (3) "Update my consent" feature allowing users to revoke/grant permissions and delete previously collected data for changed permissions, (4) Export feature: Download data as text/table. Students test with peers and reflect on what makes consent "informed" (clear language, granular choices, revocable, transparency about data use).

Dependencies:
* T32.G6.12: Build consent form and data collection system
* T15.G6.01: Create forms with multiple widget types
* T18.G6.01: Store and retrieve data from cloud tables





ID: T32.G6.14
Topic: T32 – Digital Citizenship
Skill: Research and compare computing career clusters
Description: Students research four computing career clusters: (1) Software Development (software engineer, web developer), (2) Hardware Engineering (chip designer, robotics engineer), (3) Data Science (data analyst, business intelligence analyst), (4) AI/Machine Learning (ML engineer, AI researcher). For each cluster, they identify key skills and typical tools. Students create a comparison chart showing similarities/differences and identify which cluster best matches their interests.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T32.G5.09: Map personal interests to tech pathways
* T32.G5.13: Identify tech careers that help others





ID: T32.G6.15
Topic: T32 – Digital Citizenship
Skill: Analyze representation and barriers in computing careers
Description: Students research demographics in computing fields using publicly available data. They identify underrepresented groups and discuss at least 3 barriers to entry (accessibility, geographic, socioeconomic, cultural factors). Students propose one way to improve representation and explain why diverse teams build better products.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T32.G5.11: Evaluate representation and inclusion in tech career stories
* T32.G6.14: Research and compare computing career clusters





ID: T32.G6.16
Topic: T32 – Digital Citizenship
Skill: Map CreatiCode AI skills to real-world career applications
Description: Students create a detailed mapping connecting AI skills learned in CreatiCode (image generation, chatbots, voice recognition, body tracking) to real-world AI career roles. For each CreatiCode feature: (1) identify 2-3 careers that use similar technology (e.g., ChatGPT blocks → prompt engineer, content moderator; image generation → AI artist, marketing designer), (2) list specific additional skills needed for those careers (e.g., Python programming, statistics, domain expertise), (3) create a career pathway document showing how to bridge from CreatiCode experience to professional roles. Students present their mappings explaining why certain skills transfer and what gaps exist.

Dependencies:
* T32.G6.14: Research and compare computing career clusters
* T32.G5.10: Map personal interests to tech pathways





ID: T32.G6.17
Topic: T32 – Digital Citizenship
Skill: Build and explain algorithmic filter bubble simulator
Description: Students analyze how recommendation algorithms determine what content users see by building a functional simulator. They create a project where: (1) users select interests via button widgets, (2) the system uses conditionals to filter and prioritize "recommended content" based on selections, (3) repeated choices narrow recommendations further (demonstrating filter bubble effect). Students research real-world filter bubbles and echo chambers, test their simulator with different selection patterns, and write an analysis explaining how algorithms can limit exposure to diverse perspectives and what users can do to burst filter bubbles.

Dependencies:
* T32.G6.14: Research and compare computing career clusters
* T32.G4.04: Compare persuasive vs informative design patterns
* T32.G3.02: Discuss how algorithms influence what we see





ID: T32.G6.18
Topic: T32 – Digital Citizenship
Skill: Analyze AI content attribution and copyright
Description: Students examine AI-generated content ownership questions: Who owns AI-generated images/text? Should AI training data sources be credited? Students research copyright law basics and create guidelines for crediting AI-generated work. They build a project that tracks and displays AI prompt history alongside outputs to demonstrate attribution practices.

Dependencies:
* T05.G5.01: Write clear user needs and requirements for a small app
* T06.G5.01: Identify standard event patterns in a small game
* T08.G5.02: Design multi-branch decision logic
* T32.G6.17: Explain how algorithms shape online experiences
* T20.G6.01: Generate images with AI (DALL-E blocks)





ID: T32.G6.19
Topic: T32 – Digital Citizenship
Skill: Analyze representation gaps in computing workforce
Description: Students research demographics in computing fields using publicly available data and visualizations. They: (1) collect data on gender, race, and geographic representation in different tech roles, (2) identify underrepresented groups and calculate disparity ratios, (3) investigate at least 3 barriers to entry (pipeline issues, workplace culture, geographic access, economic factors), (4) connect barriers to potential solutions (mentorship programs, alternative pathways, remote work, scholarships), (5) explain why diverse teams build better products with specific examples of products that failed due to lack of diversity in design teams. Students create a presentation with data visualizations and actionable recommendations.

Dependencies:
* T32.G6.15: Analyze representation and barriers in computing careers
* T32.G5.11: Evaluate representation and inclusion in tech career stories





ID: T32.G6.20
Topic: T32 – Digital Citizenship
Skill: Create AI career pathway portfolio entry
Description: Students create a detailed portfolio entry demonstrating their AI skills journey. They: (1) document each AI feature they've used in CreatiCode (image generation, chatbots, voice recognition, body tracking) with screenshots and code samples, (2) for each feature, write how they solved a problem or created something novel, (3) research and list 2-3 professional careers for each AI skill with salary ranges and job growth data, (4) identify skill gaps between their current abilities and professional requirements, (5) create a learning roadmap showing next steps (courses, certifications, projects) to bridge those gaps. The portfolio entry becomes part of their career planning document.

Dependencies:
* T32.G6.16: Map CreatiCode AI skills to real-world career applications
* T32.G5.10: Map personal interests to tech pathways





ID: T32.G6.21
Topic: T32 – Digital Citizenship
Skill: Facilitate effective stand-up meetings with blockers resolution
Description: Teams practice running daily stand-up check-ins with structured facilitation. Each member shares: (1) what they completed since last check-in, (2) what they plan to work on next, (3) any blockers preventing progress. The facilitator (rotating role): (a) keeps meeting under 10 minutes using a timer, (b) takes notes on blockers in a shared document, (c) assigns follow-up owners for each blocker, (d) checks previous blockers were resolved. After the meeting, facilitator sends summary to team. Students evaluate meeting effectiveness and propose improvements.

Dependencies:
* T32.G5.10a: Execute a plan-build-feedback iteration cycle
* T32.G5.12: Lead a team check-in meeting





ID: T32.G6.22
Topic: T32 – Digital Citizenship
Skill: Maintain a team task board with workflow states
Description: Teams create and maintain a digital or physical task board with columns (Backlog, To Do, In Progress, Review, Done). Students practice: (1) writing clear task cards with acceptance criteria, (2) moving tasks through workflow states as they progress, (3) limiting work-in-progress to prevent overload, (4) keeping the board updated throughout a project. Students reflect on how visual task management improves team coordination and identifies bottlenecks.

Dependencies:
* T32.G4.09: Track work with a shared checklist
* T32.G6.21: Facilitate effective stand-up meetings with blockers resolution





ID: T32.G6.23
Topic: T32 – Digital Citizenship
Skill: Conduct sprint reviews with structured feedback
Description: At the end of a project phase, teams hold a sprint review meeting where they: (1) demonstrate completed features to stakeholders, (2) collect structured feedback using a "what worked / what didn't / what to try next" format, (3) identify specific improvement actions with owners, (4) update the backlog based on feedback. Students practice giving specific, constructive feedback (not just "good job" but "the button placement made it easy to navigate") and receiving feedback gracefully.

Dependencies:
* T32.G5.10a: Execute a plan-build-feedback iteration cycle
* T32.G6.21: Facilitate effective stand-up meetings with blockers resolution





ID: T32.G6.24
Topic: T32 – Digital Citizenship
Skill: Analyze job descriptions for technical skills
Description: Students read simplified job postings for tech roles. They highlight and list: (1) technical skills mentioned (programming languages, tools, platforms), (2) experience requirements, and (3) education preferences. Students identify which skills they already have and which they need to learn.

Dependencies:
* T32.G4.11: Categorize tech jobs by what they create
* T32.G5.10: Map personal interests to tech pathways
* T32.G6.14: Research and compare computing career clusters





ID: T32.G6.25
Topic: T32 – Digital Citizenship
Skill: Analyze job descriptions for soft skills and values
Description: Students read the same job postings and identify: (1) collaboration and communication traits mentioned (teamwork, problem-solving, communication), (2) company values (accessibility, ethics, diversity, user focus), and (3) work style preferences (remote, team-based, independent). Students explain why these non-technical requirements matter.

Dependencies:
* T32.G6.24: Analyze job descriptions for technical skills





ID: T32.G6.26
Topic: T32 – Digital Citizenship
Skill: Add ethics clauses to team charters
Description: Students amend their team charters with specific commitments about: (1) responsible AI use (checking for bias, citing AI assistance), (2) crediting sources and collaborators properly, (3) protecting user data and privacy (minimal collection, consent), (4) ensuring accessibility for all users. Teams discuss why each commitment matters and how they will hold each other accountable to these standards.

Dependencies:
* T32.G5.10a: Execute a plan-build-feedback iteration cycle
* T32.G6.07: Build ethics evaluation tool combining all lenses





ID: T32.G6.27
Topic: T32 – Digital Citizenship
Skill: Document project contributions for a portfolio
Description: Students write a structured portfolio entry (1-2 paragraphs) for a CreatiCode project including: (1) project name and what it does, (2) their specific role and contributions (I designed the UI, I wrote the game logic, I tested for bugs), (3) technical skills demonstrated (conditionals, loops, variables, widgets), (4) soft skills used (collaboration, problem-solving), (5) what they learned and would do differently. Portfolio entries should use active verbs ("I built," "I debugged," "I collaborated").

Dependencies:
* T32.G5.10: Map personal interests to tech pathways
* T32.G5.10a: Execute a plan-build-feedback iteration cycle
* T32.G6.23: Conduct sprint reviews with structured feedback





ID: T32.G7.01
Topic: T32 – Digital Citizenship
Skill: Build systematic testing framework for AI perception bias
Description: Students create a comprehensive testing framework to audit AI perception tools (hand tracking, body pose detection) for bias. They build a test suite using widgets with: (1) dropdown menus to select test conditions (skin tone: light/medium/dark, lighting: bright/dim/mixed, body type variations), (2) automated data collection that logs results to table variables (columns: Tool Type, Test Condition, Accuracy Score, Error Type, Timestamp), (3) test execution interface with start/stop buttons, (4) result summary display. This framework enables systematic bias detection before deploying AI perception in projects.

Dependencies:
* T32.G6.10: Develop ethics guidelines for AI perception and assistance (T22-T23)
* T32.G6.03: Build AI testing dashboard combining image and chatbot tests





ID: T32.G7.02
Topic: T32 – Digital Citizenship
Skill: Analyze audit data and identify disparities
Description: Building on T32.G7.01, students analyze the collected test data using table variable operations to calculate accuracy rates by demographic group and identify disparities (e.g., "T23 hand tracking: 95% accurate for light skin, 78% for dark skin"). They create visualizations (bar charts) showing disparity patterns clearly.

Dependencies:
* T32.G7.01: Build systematic testing framework for AI perception
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.03
Topic: T32 – Digital Citizenship
Skill: Propose solutions for detected bias
Description: Using the disparity analysis from T32.G7.02, students propose both technical solutions (better training data, adjustable sensitivity settings) and policy solutions (required bias testing before deployment, transparency requirements, regular audits). They present evidence-based recommendations with specific implementation steps.

Dependencies:
* T32.G7.02: Analyze audit data and identify disparities





ID: T32.G7.04
Topic: T32 – Digital Citizenship
Skill: Generate and analyze AI art in different styles
Description: Students use T21 (DALL-E) blocks to generate art "in the style of" famous artists (e.g., "landscape in Van Gogh style," "portrait in Picasso style," "photograph in Ansel Adams style"). They document quality and similarity to original artists' work in a table variable with columns: Artist Style, Prompt, Quality Rating (1-5), Similarity to Original, Ethical Concerns.

Dependencies:
* T32.G6.03: Build AI testing dashboard combining image and chatbot tests
* T32.G5.05: Analyze AI's differential impacts on workers and communities
* T20.G7.01: Generate complex images with AI





ID: T32.G7.05
Topic: T32 – Digital Citizenship
Skill: Create AI-generated commercial assets
Description: Students generate commercial assets using T21 blocks (logos for fictional companies, product images, stock photos of diverse scenarios). They create a comparison table logging: Prompt, Time to generate, Quality rating (1-5), Could this replace human work? (Yes/No/Partial), Ethical concerns noted. They conduct a time comparison study: Generate 10 images with AI (seconds) vs. estimate human creation time for similar work (hours/days).

Dependencies:
* T32.G7.04: Generate and analyze AI art in different styles
* T20.G7.01: Generate complex images with AI





ID: T32.G7.06
Topic: T32 – Digital Citizenship
Skill: Build AI art gallery with comparison data
Description: Students build an interactive gallery widget display showing AI-generated works with metadata (artist style referenced, generation time, prompt used, quality ratings, replacement potential). The gallery allows users to browse through generated images and view associated data. Students document patterns in what AI does well vs. poorly, and where human creativity remains essential.

Dependencies:
* T32.G7.05: Create AI-generated commercial assets
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.07
Topic: T32 – Digital Citizenship
Skill: Conduct bias audits for AI content generation (T20-T21)
Description: Students systematically audit T20 image generation for representation across demographics and T21 chatbots for response quality by dialect/topic. They measure disparities, analyze root causes, and propose mitigation strategies. Students use table variables to log results (columns: Prompt, Demographic, Quality Rating) and create data visualizations showing disparity patterns.

Dependencies:
* T32.G6.03: Build AI testing dashboard combining image and chatbot tests
* T32.G5.05: Analyze AI's differential impacts on workers and communities





ID: T32.G7.08
Topic: T32 – Digital Citizenship
Skill: Identify unintended consequences of new tech
Description: Students select a technology (delivery drones, facial recognition, social media algorithms) and create a detailed storyboard showing both intended use and unforeseen impacts. They identify at least 3 unintended consequences (privacy invasion, job displacement, environmental impact, social isolation, etc.) and propose specific mitigations for each. Storyboards can be digital or paper-based.

Dependencies:
* T32.G6.07: Build ethics evaluation tool combining all lenses





ID: T32.G7.09
Topic: T32 – Digital Citizenship
Skill: Build transparency vs. security tradeoff simulator
Description: Students build an interactive demo simulating transparency vs. security tradeoffs for AI tools. They create: (1) A hypothetical AI system (e.g., content moderation bot, facial recognition for school safety), (2) Transparency controls using widgets: sliders to adjust transparency levels (from "fully open source" to "completely proprietary"), (3) Consequence simulation: As transparency changes, labels display changing outcomes (High transparency → "Public can audit for bias, but bad actors can game the system"; Low transparency → "Harder to exploit, but community can't verify fairness").

Dependencies:
* T32.G6.08: Analyze data privacy tradeoffs
* T32.G5.04: Debate digital well-being scenarios





ID: T32.G7.10
Topic: T32 – Digital Citizenship
Skill: Analyze stakeholder impacts at different transparency levels
Description: Building on the simulator from T32.G7.09, students add a stakeholder impact display showing how different groups (users, developers, regulators, potential attackers) are affected by each transparency level. They use table widgets to show benefits and risks for each stakeholder at different transparency settings.

Dependencies:
* T32.G7.09: Build transparency vs. security tradeoff simulator
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.11
Topic: T32 – Digital Citizenship
Skill: Justify transparency recommendations with evidence
Description: Students test different transparency scenarios using their simulator, weigh tradeoffs across stakeholders, and justify a specific transparency recommendation with evidence from their simulation. They write a policy brief explaining their recommendation and addressing counterarguments.

Dependencies:
* T32.G7.10: Analyze stakeholder impacts at different transparency levels





ID: T32.G7.12
Topic: T32 – Digital Citizenship
Skill: Build AI perception surveillance simulator
Description: Students use CreatiCode's T22 perception blocks (hand detection, body pose tracking) to build a surveillance simulator demonstrating how AI perception can be used for monitoring. They create a project that: (1) Uses hand detection to count people entering/exiting a "virtual space" (tracking when hands appear/disappear, maintaining entry/exit counters using variables), (2) Uses body pose detection to classify movements (e.g., walking vs. running based on joint distance changes, standing vs. sitting based on body position), (3) Logs all detections to a table variable with detailed data (timestamp, movement type, duration, body position data), (4) Creates a monitoring dashboard using widgets: labels showing live counts, table display of detection log, buttons to start/stop/clear monitoring. Students experience first-hand what data AI perception systems can capture.

Dependencies:
* T32.G6.08: Analyze data privacy tradeoffs
* T32.G6.10: Develop ethics guidelines for AI perception and assistance (T22-T23)
* T22.G7.01: Use hand and body tracking for interactive projects





ID: T32.G7.13
Topic: T32 – Digital Citizenship
Skill: Analyze privacy and safety impacts
Description: Using the surveillance simulator built in T32.G7.12, students analyze their own collected data as a case study in AI perception ethics. They: (1) Review the logged data table and identify what privacy-sensitive information was captured (movement patterns, time spent in areas, behavioral classifications), (2) Analyze potential discrimination: Could the system treat people with different abilities unfairly? (e.g., mobility device users flagged as "suspicious," different walking gaits misclassified), (3) Research real-world AI surveillance cases (school monitoring, public safety, retail analytics) and compare to their simulator, (4) Conduct a structured debate using a widget-based debate tool (buttons for "Pro Safety" vs "Pro Privacy" positions, text displays for arguments/evidence), (5) Write evidence-based ethical guidelines for when such systems are justified, including required safeguards (transparency, consent, bias testing, data minimization, human oversight).

Dependencies:
* T32.G7.12: Build AI perception surveillance simulator
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.14
Topic: T32 – Digital Citizenship
Skill: Debate ethics and propose policies
Description: Using findings from T32.G7.06 AI art gallery experiments, students research stakeholder perspectives and engage in structured debates about AI media generation ethics. They: (1) Research perspectives through interviews/articles: Artists' concerns about devaluation of work and copyright, Educators' views on AI in creative learning, Business perspectives on efficiency and cost, Consumers' views on AI disclosure, (2) Build an interactive debate tool using widgets: Buttons to select debate topics (AI art copyright, Training data attribution, Disclosure requirements, Artist compensation), Dropdown for stakeholder perspective (Artist, Business, Consumer, Educator, AI Researcher), Text display of arguments and counter-arguments for each position, (3) Conduct classroom debates using evidence from research and experiments, (4) Draft policy proposals addressing: Should AI art be copyrightable?, Should training data sources be credited/compensated?, When must AI generation be disclosed?, How can artists adapt/benefit? Students present proposals with specific, actionable recommendations grounded in their experimental evidence and stakeholder research.

Dependencies:
* T32.G7.06: Build AI art gallery with comparison data
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.15
Topic: T32 – Digital Citizenship
Skill: Facilitate community discussions on AI-powered tech policy
Description: Students design and conduct structured interviews with 3+ stakeholders (teachers, parents, students) about a local AI policy question (e.g., Should schools use AI proctoring? Should the school allow AI writing assistants?). They create interview protocols with at least 5 open-ended questions, document responses, and create a summary report identifying areas of agreement and disagreement on AI governance, connecting to AI applications.

Dependencies:
* T32.G6.11: Analyze digital divide data
* T32.G5.04: Debate digital well-being scenarios





ID: T32.G7.16
Topic: T32 – Digital Citizenship
Skill: Compare honest vs. misleading data visualizations
Description: Students analyze how data presentation affects interpretation. Given the same dataset (e.g., test scores over time, digital divide statistics), they create two visualizations using table variables and sprite graphics: (1) Honest version: Appropriate scale, full context, clear labels, complete data, (2) Misleading version: Truncated y-axis, cherry-picked time range, or misleading colors. Using widget buttons, users can toggle between versions. Students document how design choices change perception and write guidelines for ethical data visualization.

Dependencies:
* T32.G6.11: Analyze digital divide data
* T18.G7.01: Create data visualizations using table variables
* T15.G7.01: Build interactive data displays with widgets





ID: T32.G7.17
Topic: T32 – Digital Citizenship
Skill: Analyze deepfakes and synthetic media detection
Description: Students learn about deepfakes and synthetic media by examining examples and learning detection techniques. They identify warning signs (unnatural blinking, lighting inconsistencies, audio-visual mismatches, facial distortions). They build a checklist tool using widgets for evaluating media authenticity and practice applying it to sample videos/images. Students discuss implications for misinformation, consent, and trust in digital media.

Dependencies:
* T32.G7.06: Build AI art gallery with comparison data
* T32.G5.08: Evaluate online sources using credibility criteria





ID: T32.G7.18
Topic: T32 – Digital Citizenship
Skill: Prepare interview questions for tech professionals
Description: Students prepare at least 5 thoughtful questions to ask a tech professional, covering: career journey, daily work, challenges faced, skills needed, and advice for students. Questions should be open-ended and specific to the professional's field.

Dependencies:
* T32.G6.18: Compare computing career clusters
* T32.G5.11: Evaluate representation and inclusion in tech career stories





ID: T32.G7.19
Topic: T32 – Digital Citizenship
Skill: Conduct and summarize a career interview
Description: Students interview a tech professional (in person, virtually, or via recorded profile) using their prepared questions. They create a written summary or presentation of key findings including: the professional's pathway, daily work, and recommendations for students.

Dependencies:
* T32.G7.18: Prepare interview questions for tech professionals





ID: T32.G7.20
Topic: T32 – Digital Citizenship
Skill: Research emerging tech careers and required skills
Description: Students research new and emerging tech career paths (AI ethics specialist, sustainability technologist, accessibility engineer, VR/AR developer). For each career, students identify: the skills, education, and experiences needed to pursue them, and why these careers are growing.

Dependencies:
* T32.G6.18: Compare computing career clusters





ID: T32.G7.21
Topic: T32 – Digital Citizenship
Skill: Discuss AI ethics and equity with tech professionals
Description: Students explore AI ethics, fairness, and responsible AI through case studies or conversations with professionals. They learn about: bias in AI systems, strategies for ensuring AI serves all communities equitably, and the role of AI ethics specialists.

Dependencies:
* T32.G6.19: Analyze representation in computing careers





ID: T32.G7.22
Topic: T32 – Digital Citizenship
Skill: Design cross-functional team diagrams
Description: Students create a diagram showing how different roles collaborate on a large project: design (UX/UI), engineering (front-end, back-end), QA (testing), and ethics/accessibility review. Students draw arrows showing how work flows between roles and identify potential communication challenges.

Dependencies:
* T32.G6.23: Conduct sprint reviews
* T32.G6.18: Compare computing career clusters





ID: T32.G7.23
Topic: T32 – Digital Citizenship
Skill: Facilitate inclusive collaboration
Description: Students analyze scenarios of exclusive behavior (interrupting, taking credit for others' work, ignoring quieter teammates) and inclusive behavior (making sure everyone speaks, giving credit, welcoming different perspectives). Students propose specific improvements for exclusive scenarios and practice facilitating discussions where everyone participates.

Dependencies:
* T32.G5.10: Complete a plan-build-feedback cycle
* T32.G5.11: Evaluate representation and inclusion in tech career stories
* T32.G5.12: Lead a team check-in meeting





ID: T32.G7.24
Topic: T32 – Digital Citizenship
Skill: Plan a lesson for younger coders
Description: Students plan a short lesson (10-15 minutes) to teach younger students a coding concept or tech safety topic (debugging basics, AI safety, online privacy). The plan includes: learning objective, step-by-step instructions, an activity, and how to check understanding.

Dependencies:
* T32.G6.26: Add ethics clauses to team charters
* T32.G5.11: Evaluate representation and inclusion in tech career stories





ID: T32.G7.25
Topic: T32 – Digital Citizenship
Skill: Deliver a lesson to younger coders
Description: Students deliver their planned lesson to younger students. After teaching, they reflect on: what went well, what was challenging, how they adapted to student questions, and what they would change next time. Students develop leadership and communication skills.

Dependencies:
* T32.G7.24: Plan a lesson for younger coders





ID: T32.G7.26
Topic: T32 – Digital Citizenship
Skill: Use shared documents for team collaboration
Description: Students practice using shared documents (Google Docs, shared notes) for team projects. They learn to: (1) write in the same document without conflicts, (2) use comments to give feedback, (3) track changes and version history, and (4) resolve editing conflicts respectfully.

Dependencies:
* T32.G6.22: Maintain a team task board





ID: T32.G7.27
Topic: T32 – Digital Citizenship
Skill: Use project tracking tools for team coordination
Description: Students practice using basic project tracking tools (task lists, shared checklists, simple project boards) to coordinate team work. They learn to: assign tasks, set deadlines, track progress, and communicate about blockers asynchronously.

Dependencies:
* T32.G7.26: Use shared documents for team collaboration
* T32.G6.27: Document project contributions for a portfolio





ID: T32.G8.01
Topic: T32 – Digital Citizenship
Skill: Build accessibility and privacy assessment modules
Description: Students build the first two modules of an impact assessment tool using widgets. (1) Accessibility module: Checklist items for text-to-speech, keyboard controls, color contrast, instruction clarity - each with Yes/No/Partial/NA radio buttons and evidence text fields, (2) Privacy module: Checklist items for data collection, user consent, secure storage, data retention policy - with same rating structure. Each module calculates a score (1-5 scale) and stores results in a table variable.

Dependencies:
* T32.G7.08: Identify unintended consequences of new tech
* T32.G6.07: Build ethics evaluation tool combining all lenses
* T15.G8.01: Build complex multi-widget applications
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T06.G6.01: Trace event execution paths in a multi‑event program
* T07.G6.01: Trace nested loops with variable bounds





ID: T32.G8.02
Topic: T32 – Digital Citizenship
Skill: Build wellbeing and cultural sensitivity modules
Description: Building on T32.G8.01, students add two more assessment modules: (3) Wellbeing module: Checklist items for time limits, addictive patterns avoided, breaks encouraged, age-appropriate content, (4) Cultural sensitivity module: Checklist items for inclusive representation, stereotypes avoided, multiple perspectives, respectful content. Each follows the same rating structure (Yes/No/Partial/NA, evidence notes, 1-5 scoring).

Dependencies:
* T32.G8.01: Build accessibility and privacy assessment modules
* T15.G8.01: Build complex multi-widget applications





ID: T32.G8.03
Topic: T32 – Digital Citizenship
Skill: Integrate scoring and generate recommendations
Description: Students integrate all four assessment modules into one comprehensive tool. They add: (1) Navigation buttons to move between assessment categories, (2) Overall project score calculation (average across all four categories), (3) ChatGPT integration that analyzes the assessment data and generates specific, actionable recommendations (e.g., "Project scored 2/5 on accessibility. Lacks keyboard controls - consider adding when key pressed blocks. Missing text-to-speech - add AI Speaker blocks"). Students test their complete tool on sample projects to ensure scoring is consistent and recommendations are useful.

Dependencies:
* T32.G8.02: Build wellbeing and cultural sensitivity modules
* T21.G8.01: Use ChatGPT for advanced analysis






ID: T32.G8.04.01
Topic: T32 – Digital Citizenship
Skill: Design workshop curriculum for responsible tech
Description: Students plan a short lesson (10-15 minutes) to teach younger students a coding concept or tech safety topic (debugging basics, AI safety, online privacy). The plan includes: learning objective, step-by-step instructions, an activity, and how to check understanding. They select the workshop topic (screen balance, kindness, privacy, AI ethics).

Dependencies:
* T32.G7.07: Conduct bias audits for AI content generation (T20-T21)
* T32.G6.07: Build ethics evaluation tool combining all lenses
* T02.G6.01: Use the pseudocode generation block
* T07.G6.01: Trace nested loops with variable bounds
* T09.G6.01: Model real-world quantities using variables and formulas

ID: T32.G8.04.02
Topic: T32 – Digital Citizenship
Skill: Build interactive workshop tools
Description: Students design and build interactive teaching tools using widgets and blocks for their workshop. Examples: timer widget for screen balance, scenario simulator for kindness, sorting game for privacy, or bias demo for AI ethics. They also create an assessment component (quiz) to check understanding.

Dependencies:
* T32.G8.04.01: Design workshop curriculum for responsible tech
* T16.G8.01: Build complex multi-widget applications

ID: T32.G8.04.03
Topic: T32 – Digital Citizenship
Skill: Deliver workshop and iterate
Description: Students pilot their workshops with younger grades, delivering the lesson and using their interactive tools. They collect feedback using widget-based surveys and iterate on their tools and lesson plan based on what worked and what didn't.

Dependencies:
* T32.G8.04.02: Build interactive workshop tools
ID: T32.G8.05
Topic: T32 – Digital Citizenship
Skill: Evaluate real proposals using the tool
Description: Students evaluate real proposals (predictive policing, emotion AI in schools, personalized education platforms, facial recognition for attendance) using the impact assessment tool built in T32.G8.03. They systematically assess each proposal across all frameworks, gathering evidence from research and documenting where frameworks agree or conflict.

Dependencies:
* T32.G8.03: Integrate scoring and generate recommendations
* T15.G8.01: Build complex multi-widget applications





ID: T32.G8.06
Topic: T32 – Digital Citizenship
Skill: Resolve conflicts between ethical frameworks
Description: When frameworks conflict (e.g., beneficence supports surveillance for safety but autonomy opposes it), students must justify which framework should take priority for each specific case. They write reasoned arguments considering context, stakeholder impacts, and values, and present their decisions with supporting evidence.

Dependencies:
* T32.G8.05: Evaluate real proposals using the tool





ID: T32.G8.07
Topic: T32 – Digital Citizenship
Skill: Analyze AI chatbots' impact on information literacy (Pairing with T22)
Description: Following T21 chatbot projects, students analyze how AI-generated answers affect research habits, critical thinking, misinformation spread, and educational equity. They examine differential impacts on students with varying digital literacy levels and propose guidelines for responsible chatbot use in academic settings.

Dependencies:
* T32.G8.06: Resolve conflicts between ethical frameworks
* T32.G7.07: Conduct bias audits for AI content generation (T20-T21)
* T07.G6.01: Trace nested loops with variable bounds
* T10.G6.01: Sort a table by a column
* T12.G6.01: Trace complex code with multiple variables





ID: T32.G8.08
Topic: T32 – Digital Citizenship
Skill: Draft equity-focused policy briefs for AI in education
Description: Students create data-driven policy briefs with integrated visualizations. They: (1) Research and collect data on AI equity issues: survey students about AI tool access, analyze AI output bias from their T32.G7.01 audits, review privacy policies from education AI tools, (2) Build data visualizations using table variables and sprite graphics: bar charts showing access disparities by demographic, pie charts of bias audit results, timeline of privacy incidents, (3) Draft one-page policy brief with embedded visualizations addressing differential access, bias in AI outputs, and privacy protection, (4) Create interactive brief using widgets: buttons to toggle between data views, clickable recommendations that expand to show supporting evidence and action steps. Students present briefs with specific, measurable action items grounded in their visualized data.

Dependencies:
* T32.G7.15: Facilitate community discussions on AI-powered tech policy
* T32.G6.11: Analyze digital divide data
* T02.G6.01: Use the pseudocode generation block
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds





ID: T32.G8.09
Topic: T32 – Digital Citizenship
Skill: Apply tool to evaluate AI projects
Description: Using the impact assessment tool built in T32.G8.03, students conduct comprehensive evaluations of real CreatiCode community projects. They: (1) Select 3+ diverse community projects for evaluation (at least one using AI blocks T20-T23, at least one game, at least one educational tool), (2) Systematically assess each project using the tool, gathering evidence for each category: Test accessibility features, Review data collection practices, Analyze potential wellbeing impacts, Evaluate cultural representation, (3) Generate assessment reports: Use the tool's scoring output, Review ChatGPT-generated recommendations, Add their own observations and suggestions, (4) Create a comparative analysis using table variables: Which categories had lowest scores across projects? What common issues emerged? Which projects demonstrated best practices?, (5) Present findings to project creators with constructive, evidence-based recommendations. Students reflect on assessment challenges: How to score subjective categories consistently? When are tradeoffs acceptable? How to balance thoroughness with practicality?

Dependencies:
* T32.G8.03: Integrate scoring and generate recommendations
* T15.G8.01: Build complex multi-widget applications
* T05.G6.01: Apply empathy, needs, and accessibility checklist to a design
* T07.G6.01: Trace nested loops with variable bounds
* T08.G6.01: Use conditionals in physics simulations





ID: T32.G8.10
Topic: T32 – Digital Citizenship
Skill: Lead peer workshops on responsible tech use
Description: Students design and build interactive workshop tools for teaching younger students about responsible tech use. They create: (1) Workshop topic selection: Choose from screen balance, online kindness, privacy awareness, or AI ethics, (2) Interactive teaching tool using widgets and blocks: For screen balance (timer widget showing healthy tech time limits, activity tracker), For online kindness (scenario simulator with multiple choice responses and consequence feedback), For privacy (information sorting game using drag-drop widgets), For AI ethics (bias demonstration tool using AI image generation blocks), (3) Assessment component: Quiz using widgets to check understanding, results stored in table variable, (4) Take-home materials: Printable guidelines generated from workshop data. Students pilot workshops with younger grades, collect feedback using widget-based surveys, and iterate on their tools based on what worked.

Dependencies:
* T32.G7.15: Facilitate community discussions on AI-powered tech policy
* T32.G7.24: Plan a lesson for younger coders
* T32.G7.25: Deliver a lesson to younger coders
* T03.G6.01: Propose a module hierarchy for a medium project
* T07.G6.01: Trace nested loops with variable bounds





ID: T32.G8.11
Topic: T32 – Digital Citizenship
Skill: Identify high school courses for tech careers
Description: Students research which high school courses support different tech career paths. For their target career (AI researcher, UX engineer, data scientist), they identify: (1) math courses needed (algebra, statistics, calculus), (2) science courses (computer science, physics), and (3) other relevant courses (art, communication, business).

Dependencies:
* T32.G7.20: Research emerging tech careers and required skills
* T32.G6.20: Create AI career pathway portfolio entry





ID: T32.G8.12
Topic: T32 – Digital Citizenship
Skill: Plan extracurriculars and portfolio goals
Description: Students identify extracurricular activities that build skills for their target career: coding clubs, robotics teams, hackathons, internships, online courses. They set 3-5 specific portfolio goals (projects to complete, skills to demonstrate) for the next 2-3 years.

Dependencies:
* T32.G8.11: Identify high school courses for tech careers





ID: T32.G8.13
Topic: T32 – Digital Citizenship
Skill: Build a multi-year career roadmap
Description: Students combine their course plan and extracurricular goals into a complete multi-year roadmap for their target career. The roadmap includes: year-by-year milestones, skills to develop, projects to complete, and people/communities to connect with.

Dependencies:
* T32.G8.12: Plan extracurriculars and portfolio goals





ID: T32.G8.14
Topic: T32 – Digital Citizenship
Skill: Assemble a project portfolio
Description: Students select 3-5 of their best CreatiCode projects and organize them into a portfolio. For each project, they include: project name, description, their role, skills demonstrated, and a screenshot or link. Students arrange projects to show growth and variety.

Dependencies:
* T32.G6.27: Document project contributions for a portfolio
* T32.G6.24: Analyze job descriptions for technical skills





ID: T32.G8.15
Topic: T32 – Digital Citizenship
Skill: Write a student resume
Description: Students write a one-page resume including: contact information, objective/summary, skills (technical and soft skills), relevant projects/experience, and education. They tailor the resume to highlight skills mentioned in job descriptions they've analyzed.

Dependencies:
* T32.G8.14: Assemble a project portfolio
* T32.G6.25: Analyze job descriptions for soft skills and values





ID: T32.G8.16
Topic: T32 – Digital Citizenship
Skill: Practice interview skills
Description: Students conduct mock interviews with peers or mentors. They practice: answering common questions (tell me about yourself, describe a project, how do you handle challenges), asking good questions, and following up professionally. Students give and receive feedback on interview performance.

Dependencies:
* T32.G8.15: Write a student resume
* T32.G7.25: Deliver a lesson to younger coders





ID: T32.G8.17
Topic: T32 – Digital Citizenship
Skill: Analyze AI impact on workforce: displacement vs augmentation
Description: Students research how AI affects different job categories: (1) Jobs at risk of displacement (repetitive tasks, pattern recognition, data processing), (2) Jobs augmented by AI (creativity, judgment, relationships enhanced by AI tools). They create a comparison chart identifying patterns, analyze which skills remain valuable, and propose strategies for AI-augmented careers. Students examine how impacts vary by education level, income, and geographic location.

Dependencies:
* T32.G6.20: Connect AI skills to career pathways
* T32.G7.21: Discuss AI ethics and equity with tech professionals
* T03.G6.01: Propose a module hierarchy for a medium project
* T10.G6.01: Sort a table by a column





ID: T32.G8.18
Topic: T32 – Digital Citizenship
Skill: Identify jobs augmented vs displaced by AI
Description: Students categorize jobs into three groups: (1) jobs likely to be displaced by AI (repetitive, pattern-based tasks with low human judgment), (2) jobs augmented by AI (human creativity/judgment enhanced by AI tools), (3) new jobs created by AI (AI trainers, prompt engineers, AI ethics specialists). For each category, students identify specific examples with evidence, analyze what makes a job more resilient to AI displacement (creativity, empathy, physical dexterity, complex reasoning), and discuss how workers in at-risk jobs might transition to augmented or new roles.

Dependencies:
* T32.G8.17: Analyze AI impact on workforce: displacement vs augmentation





ID: T32.G8.19
Topic: T32 – Digital Citizenship
Skill: Analyze patterns in AI workforce disruption
Description: Using the job categorizations from T32.G8.18, students identify patterns in AI workforce disruption. They analyze: (1) which industries are most affected and why, (2) which skill types are most resilient (creative, interpersonal, physical, analytical), (3) how education level correlates with displacement risk, (4) geographic patterns in AI job impact, (5) timeline predictions for different job categories. Students create data visualizations showing these patterns and write recommendations for individual career planning based on the patterns identified.

Dependencies:
* T32.G8.18: Identify jobs augmented vs displaced by AI





ID: T32.G8.20
Topic: T32 – Digital Citizenship
Skill: Analyze how AI impacts vary by community
Description: Students examine how AI's workplace effects differ across communities. They research and analyze: (1) education level correlations - how does formal education affect AI vulnerability/opportunity, (2) income disparities - do wealthier communities have better AI access/training, (3) geographic factors - urban vs rural AI job availability, (4) access to technology training - who can afford reskilling programs. Students create case studies of specific communities, interview community members if possible, and identify which groups face the greatest challenges. They propose targeted interventions for each vulnerable community type with evidence-based reasoning.

Dependencies:
* T32.G8.19: Analyze patterns in AI workforce disruption
* T32.G6.19: Analyze representation gaps in computing workforce





ID: T32.G8.21
Topic: T32 – Digital Citizenship
Skill: Design a proposal for equitable AI use
Description: Students create a proposal for how AI tools could be deployed equitably in their school or community. The proposal includes: (1) specific AI tools and their benefits, (2) training programs needed, (3) access initiatives for underserved groups, and (4) safeguards against bias. Students present their proposal and gather feedback.

Dependencies:
* T32.G8.20: Analyze how AI impacts vary by community
* T32.G7.15: Facilitate community discussions on AI-powered tech policy
* T32.G6.07: Build ethics evaluation tool combining all lenses





ID: T32.G8.22
Topic: T32 – Digital Citizenship
Skill: Plan a capstone retrospective
Description: Students plan a retrospective meeting for their final project, including: agenda (demo, what went well, improvements, lessons learned), who to invite (peers, teachers, mentors), feedback collection method (forms, discussion), and how to document outcomes for future teams.

Dependencies:
* T32.G7.22: Design cross-functional team diagrams
* T32.G7.23: Facilitate inclusive collaboration
* T32.G6.23: Conduct sprint reviews





ID: T32.G8.23
Topic: T32 – Digital Citizenship
Skill: Facilitate a capstone retrospective with stakeholders
Description: Students run their planned retrospective meeting, facilitating discussion among peers and teachers. They: demonstrate their project, guide reflection discussions, collect feedback professionally, and publish documented action items and lessons learned for future teams.

Dependencies:
* T32.G8.22: Plan a capstone retrospective
* T08.G6.01: Use conditionals in physics simulations
* T34.G6.01: Analyze hardware computing eras (mainframe → PC → mobile)




ID: T33.GK.01
Topic: T33 – Connected Services
Skill: Sort picture cards of apps into online and offline groups
Description: Using illustrated picture cards showing familiar apps (weather app, calculator, video chat, camera, maps, clock), students sort them into two boxes: "needs internet helpers" and "works alone." They explain their choices using simple language like "this one asks the cloud for help" and identify the cloud/wifi symbols that indicate internet connectivity.




ID: T33.GK.02
Topic: T33 – Connected Services
Skill: Match cloud services to what they provide
Description: Using illustrated picture cards, students match cloud service icons (message bubble, music note, photo icon, video play button) to the content they provide (chat messages, songs, pictures, videos). They understand that the internet brings different types of content from faraway computers to their device.

Dependencies:
* T33.GK.01: Sort picture cards of apps into online and offline groups




ID: T33.GK.03
Topic: T33 – Connected Services
Skill: Identify which devices need internet helpers in picture scenes
Description: Using illustrated picture cards showing a child's day (asking voice assistant for weather, playing offline game, video calling grandma, using calculator), students point to which activities need internet helpers. They circle the wifi or cloud symbol on devices that "talk to faraway computers."

Dependencies:
* T33.GK.02: Match cloud services to what they provide






ID: T33.G1.01
Topic: T33 – Connected Services
Skill: Sequence picture cards showing app waiting for internet response
Description: Using illustrated picture cards, students arrange a sequence showing: (1) user taps app button, (2) app shows loading spinner, (3) cloud/server processes request, (4) answer returns to app, (5) app displays result. They explain that internet helpers need time to respond and identify the loading spinner as the "waiting" signal.

Dependencies:
* T33.GK.03: Identify which devices need internet helpers in picture scenes




ID: T33.G1.02
Topic: T33 – Connected Services
Skill: Identify when people share through cloud services
Description: Using illustrated picture cards showing scenarios (sending a photo to grandma, watching a video a friend shared, playing a game with someone far away), students identify which activities involve sharing through the cloud. They understand that cloud services help people share things even when they are not in the same place.

Dependencies:
* T33.G1.01: Sequence picture cards showing app waiting for internet response




ID: T33.G1.03
Topic: T33 – Connected Services
Skill: Match sending and receiving in cloud sharing scenarios
Description: Using illustrated picture cards, students match pairs showing sending and receiving: child sends drawing → grandma sees drawing on her tablet; dad takes photo → photo appears on mom's phone. They trace the "path" of content through the cloud by drawing a line between sender and receiver cards.

Dependencies:
* T33.G1.02: Identify when people share through cloud services





ID: T33.G2.01
Topic: T33 – Connected Services
Skill: Predict what happens when app loses internet connection
Description: Using illustrated picture cards showing scenarios (video call freezing, map not loading, game pausing), students predict and match what happens when an app loses internet: "video freezes," "shows error," "uses old data." They sort cards into "will still work" versus "will stop working" based on whether the feature needs continuous internet.

Dependencies:
* T33.G1.03: Match sending and receiving in cloud sharing scenarios




ID: T33.G2.02
Topic: T33 – Connected Services
Skill: Sort picture cards of fast vs slow cloud responses
Description: Using illustrated picture cards, students sort cloud activities by response time: "fast" (sending a short message, checking weather) versus "slow" (downloading a movie, uploading many photos). They explain why bigger content takes longer and identify the progress bar as a signal for slow transfers.

Dependencies:
* T33.G2.01: Predict what happens when app loses internet connection




ID: T33.G2.03
Topic: T33 – Connected Services
Skill: Match cloud storage icons to what gets saved
Description: Using illustrated picture cards, students match cloud storage icons (camera roll cloud, document cloud, game cloud) to what gets saved (photos, homework files, game progress). They understand that cloud storage keeps things safe even if the device breaks or gets lost.

Dependencies:
* T33.G2.02: Sort picture cards of fast vs slow cloud responses




ID: T33.G2.04
Topic: T33 – Connected Services
Skill: Sequence picture cards showing cloud backup and restore
Description: Using illustrated picture cards, students arrange a sequence: (1) child saves game progress, (2) progress goes to cloud, (3) tablet breaks, (4) new tablet connects to cloud, (5) game progress returns. They explain that cloud storage "remembers" even when devices change.

Dependencies:
* T33.G2.03: Match cloud storage icons to what gets saved





ID: T33.G3.01
Topic: T33 – Connected Services
Skill: Trace data flow from app to cloud and back in diagram
Description: Students examine illustrated diagrams showing data flow: user types question → app sends to cloud → cloud processes → cloud sends answer → app displays. They label each step and trace the path with their finger or cursor. They identify which step is happening when they see a loading spinner and explain why each step is needed.

Dependencies:
* T33.G2.04: Sequence picture cards showing cloud backup and restore
* T01.G3.01: Trace execution through sequential blocks




ID: T33.G3.02
Topic: T33 – Connected Services
Skill: Identify request and response in cloud communication diagrams
Description: Students examine diagrams showing cloud communication and label the "request" (question going to cloud) and "response" (answer coming back). They identify examples of requests (asking for weather, searching for a video) and responses (temperature number, list of videos). They understand every cloud interaction has a request-response pair.

Dependencies:
* T33.G3.01: Trace data flow from app to cloud and back in diagram




ID: T33.G3.03
Topic: T33 – Connected Services
Skill: Predict which cloud service provides each type of answer
Description: Students match questions to cloud services: "What's the weather?" goes to weather service, "Translate this word" goes to translation service, "Find a video about cats" goes to video service. They understand that different cloud services specialize in different types of information.

Dependencies:
* T33.G3.02: Identify request and response in cloud communication diagrams




ID: T33.G3.04
Topic: T33 – Connected Services
Skill: Predict service response times in request-response diagrams
Description: Students examine diagrams of different cloud requests and predict relative response times: asking "What is 2+2?" is fast, asking "Generate an image of a cat" is slow. They order service types by typical response time and explain that complex tasks take longer for the cloud to process.

Dependencies:
* T33.G3.03: Predict which cloud service provides each type of answer




ID: T33.G4.01
Topic: T33 – Connected Services
Skill: Explain difference between saving locally and saving to cloud
Description: Students compare two scenarios: saving a drawing on "this device only" versus saving to "the cloud." They trace what happens in each case using diagrams and explain tradeoffs: local saves are faster but only on one device; cloud saves work everywhere but need internet. They predict which save method to use for different situations (homework vs quick note).

Dependencies:
* T33.G3.04: Predict service response times in request-response diagrams
* T30.G4.01: Explain how data travels across the internet




ID: T33.G4.02
Topic: T33 – Connected Services
Skill: Trace how login connects user to their cloud data
Description: Students trace diagrams showing: user enters username/password → app sends credentials to cloud → cloud finds user's saved data → data is sent back to app. They explain why each person needs their own login to access their own cloud storage, and why sharing passwords lets others access your data.

Dependencies:
* T33.G4.01: Explain difference between saving locally and saving to cloud
* T32.G4.01: Identify personal information that should stay private




ID: T33.G4.03
Topic: T33 – Connected Services
Skill: Categorize cloud services by what they store or provide
Description: Students sort cloud service examples into categories: storage services (save files, photos, backups), information services (weather, news, search), communication services (email, chat, video calls), and entertainment services (streaming music, videos, games). They explain what distinguishes each category.

Dependencies:
* T33.G4.02: Trace how login connects user to their cloud data




ID: T33.G4.04
Topic: T33 – Connected Services
Skill: Debug service timeout scenarios in diagrams
Description: Students examine diagrams showing cloud service problems: request sent but no response arrives, loading spinner keeps spinning, error message appears. They predict causes (slow internet, server busy, service down) and identify the timeout step where the app gives up waiting. They explain why apps need timeouts to avoid waiting forever.

Dependencies:
* T33.G4.03: Categorize cloud services by what they store or provide




ID: T33.G5.01
Topic: T33 – Connected Services
Skill: Distinguish real-time sync from one-time fetch in app scenarios
Description: Students compare two types of cloud connections: real-time sync (shared whiteboard where everyone sees changes instantly, multiplayer game positions) versus one-time fetch (checking weather once, loading a webpage). They categorize familiar apps by connection type and explain why games need real-time sync but news apps use one-time fetch.

Dependencies:
* T33.G4.04: Debug service timeout scenarios in diagrams
* T30.G5.01: Trace how a device reaches an online service





ID: T33.G5.02
Topic: T33 – Connected Services
Skill: Identify what data is safe to share in URLs versus private
Description: Students examine example URLs containing data (search queries, usernames, file IDs) and identify what information becomes visible when sharing a URL. They sort data into "safe to share" (test data, public facts, fictional names) versus "keep private" (real names, addresses, passwords). They create example "safe" test data for a hypothetical project.

Dependencies:
* T33.G5.01: Distinguish real-time sync from one-time fetch in app scenarios
* T32.G4.01: Identify personal information that should stay private





ID: T33.G5.03
Topic: T33 – Connected Services
Skill: Predict which Cloud blocks need internet by examining block categories
Description: Students examine CreatiCode's Cloud category blocks (Google Sheets, fetch URL, cloud sessions) and predict which ones require internet connectivity. They test their predictions by running projects offline and observing which blocks fail. They create a simple reference chart categorizing blocks as "needs internet" or "works offline."

Dependencies:
* T33.G5.02: Identify what data is safe to share in URLs versus private
* T30.G5.01: Trace how a device reaches an online service




ID: T33.G5.04
Topic: T33 – Connected Services
Skill: Explain how APIs let programs talk to cloud services
Description: Students learn that API (Application Programming Interface) is how programs ask cloud services for help. They trace examples: a weather app uses a weather API to get temperature, a translation app uses a translation API to convert words. They understand that APIs define what questions a program can ask and what format the answers come in.

Dependencies:
* T33.G5.03: Predict which Cloud blocks need internet by examining block categories




ID: T33.G5.05
Topic: T33 – Connected Services
Skill: Identify parameters and return values in API requests
Description: Students examine simple API request diagrams and identify: the service being called (weather API), the parameters being sent (city name), and the return value received (temperature). They practice reading block descriptions to find what inputs (parameters) a cloud block needs and what output (return value) it provides.

Dependencies:
* T33.G5.04: Explain how APIs let programs talk to cloud services




ID: T33.G5.06
Topic: T33 – Connected Services
Skill: Run a simple cloud block and observe request-response timing
Description: Students run a provided CreatiCode project that uses a simple cloud block (like fetch URL or save data). They use the console panel to observe when the request is sent and when the response arrives. They measure the delay with a timer variable and compare response times for different services. This bridges conceptual understanding to hands-on coding.

Dependencies:
* T33.G5.05: Identify parameters and return values in API requests




ID: T33.G6.01
Topic: T33 – Connected Services
Skill: Fetch web content using the fetch URL block and display it
Description: Students use the `fetch web page as markdown from URL` block to retrieve content from a provided public URL and display it using say or text blocks. They observe that the fetch takes time to complete and that the content appears after the network request finishes. They test with different URLs to see different content returned.

Dependencies:
* T33.G5.06: Run a simple cloud block and observe request-response timing
* T08.G4.03: Use if-else to choose between two outcomes

Note: For AI blocks, see Topic T32. For Multiplayer game blocks, see Topic T19.





ID: T33.G6.02
Topic: T33 – Connected Services
Skill: Read data range from Google Sheets into a table variable
Description: Students use the `read from google sheet` block to load data from a shared Google Sheet into a CreatiCode table variable. They specify the sheet URL, sheet name, range (e.g., A1:D10), and target table name. They verify the data loaded correctly by displaying table contents using loops or table display blocks.

Dependencies:
* T33.G6.01: Fetch web content using the fetch URL block and display it
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.03
Topic: T33 – Connected Services
Skill: Write table data to Google Sheets from starting cell
Description: Students use the `write into google sheet` block to export a CreatiCode table to a Google Sheet. They specify the sheet URL, sheet name, starting cell address, and source table. They verify successful writes by checking the Google Sheet in a browser to confirm data appears in correct cells.

Dependencies:
* T33.G6.02: Read data range from Google Sheets into a table variable
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.04
Topic: T33 – Connected Services
Skill: Get and set individual cell values in Google Sheets
Description: Students use `value at row (ROW) column (COL) of sheet [SHEETNAME]` to read individual cells and `set value to [VALUE] at row (ROW) column (COL)` to write individual cells. They build projects that check or update specific values (high score, status flag, counter) efficiently without loading/writing entire tables.

Dependencies:
* T33.G6.03: Write table data to Google Sheets from starting cell
* T08.G4.03: Use if-else to choose between two outcomes





ID: T33.G6.05
Topic: T33 – Connected Services
Skill: Clear sheet contents and append rows to Google Sheets
Description: Students use `clear sheet` to remove all content from a sheet while preserving the sheet itself, and `append row from table` to add new rows at the bottom of existing data. They implement a "reset and reload" pattern: clear old data, then append fresh entries one at a time.

Dependencies:
* T33.G6.04: Get and set individual cell values in Google Sheets
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.06
Topic: T33 – Connected Services
Skill: Display loading message while waiting for cloud service response
Description: Students create programs that show a "Loading..." message or spinner costume before calling a Cloud block, then hide it after the response arrives. They observe that network operations take time and user feedback prevents confusion during waits.

Dependencies:
* T33.G6.02: Read data range from Google Sheets into a table variable
* T02.G4.01: Create animation using costume switching





ID: T33.G6.07
Topic: T33 – Connected Services
Skill: Detect and handle empty or error responses from cloud services
Description: Students create programs that check if fetched data is empty or contains error indicators before using it. They use if-else to display "No data found" or "Error occurred" messages instead of showing blank content or crashing. They test with invalid URLs or empty sheet ranges to observe error states.

Dependencies:
* T33.G6.06: Display loading message while waiting for cloud service response
* T08.G4.03: Use if-else to choose between two outcomes





ID: T33.G6.08
Topic: T33 – Connected Services
Skill: List, add, and remove sheets in a Google Spreadsheet
Description: Students use `list all sheets` to discover available sheet names, `add sheet` to create new sheets programmatically, and `remove sheet` to delete sheets. They build a project that checks if a sheet exists before adding (to avoid duplicates) or removing (to avoid errors).

Dependencies:
* T33.G6.05: Clear sheet contents and append rows to Google Sheets
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.09
Topic: T33 – Connected Services
Skill: Insert table rows into a cloud database collection
Description: Students use `insert from table [TABLENAME] row from (START) to (END) into collection [COLLECTION]` to save table data to CreatiCode's cloud database. They create a simple score-logging project that saves game results to persistent cloud storage. They verify data was saved by fetching it back.

Dependencies:
* T33.G6.03: Write table data to Google Sheets from starting cell
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.10
Topic: T33 – Connected Services
Skill: Fetch all documents from a cloud database collection into a table
Description: Students use `fetch from collection [COLLECTION] into table [TABLE]` (without WHERE conditions) to retrieve all records from a collection. They build projects that load previously saved scores or settings from cloud storage and display them. They understand that fetched data populates a table for processing.

Dependencies:
* T33.G6.09: Insert table rows into a cloud database collection
* T10.G4.01: Create a list and populate it with items





ID: T33.G6.11
Topic: T33 – Connected Services
Skill: List Google Drive folder contents
Description: Students use `list content of Google Drive folder` to retrieve file names, IDs, and types from a shared folder. They parse the returned table to display file names in a loop. They understand that the block returns metadata (filename, file ID, MIME type) that can be used to access specific files.

Dependencies:
* T33.G6.02: Read data range from Google Sheets into a table variable
* T10.G4.01: Create a list and populate it with items




ID: T33.G6.12
Topic: T33 – Connected Services
Skill: Save and load simple data to CreatiCode server
Description: Students use `save data [VALUE] with name [KEY]` to store a value on the CreatiCode server and `load data named [KEY]` to retrieve it. They build a project that remembers a user's high score or preference across sessions. They understand the difference between public (shared) and private (personal) data visibility.

Dependencies:
* T33.G6.02: Read data range from Google Sheets into a table variable
* T09.G5.01: Use multiple variables together in a single expression




ID: T33.G6.13
Topic: T33 – Connected Services
Skill: Save and load table data to CreatiCode server
Description: Students use `save table [TABLE] to server as [DATANAME]` to persist entire tables and `load [DATANAME] from server into table [TABLE]` to retrieve them. They build projects that save game state, inventory lists, or collected data that persists between play sessions.

Dependencies:
* T33.G6.12: Save and load simple data to CreatiCode server
* T10.G4.01: Create a list and populate it with items




ID: T33.G6.14
Topic: T33 – Connected Services
Skill: Add costume from URL to load external images
Description: Students use `add costume named [NAME] from URL [URL] max width (W) max height (H)` to load images from web addresses into their project. They understand that the image downloads from the internet and becomes a costume. They test with different image URLs and observe scaling based on max dimensions.

Dependencies:
* T33.G6.01: Fetch web content using the fetch URL block and display it
* T02.G4.01: Create animation using costume switching




ID: T33.G6.15
Topic: T33 – Connected Services
Skill: Display images from URL using widget blocks
Description: Students use `add image from URL [URL] at x (X) y (Y)` to display web images as widgets on the stage. They position and size images using coordinates and dimensions. They understand widgets appear on top of sprites and can be used for UI elements like backgrounds or icons.

Dependencies:
* T33.G6.14: Add costume from URL to load external images
* T08.G4.03: Use if-else to choose between two outcomes





ID: T33.G6.16
Topic: T33 – Connected Services
Skill: Record player scores to game leaderboard
Description: Students use `record player score (VALUE)` to save a score to the CreatiCode server leaderboard for the current project. They understand that scores are associated with the logged-in user. They test by recording different scores and observing how the leaderboard updates.

Dependencies:
* T33.G6.12: Save and load simple data to CreatiCode server
* T09.G5.01: Use multiple variables together in a single expression




ID: T33.G6.17
Topic: T33 – Connected Services
Skill: Display and customize game leaderboard
Description: Students use `show game leaderboard [SORT] rows [ROWS] header [COLOR] background [COLOR]` to display a ranked list of top players. They customize the leaderboard with sort order (highest/lowest first), number of rows shown, and colors. They use `hide game leaderboard` to remove it when not needed.

Dependencies:
* T33.G6.16: Record player scores to game leaderboard
* T08.G4.03: Use if-else to choose between two outcomes




ID: T33.G6.18
Topic: T33 – Connected Services
Skill: Store and retrieve user-specific data with keys
Description: Students use `store user data key [KEY] value [VALUE]` to save personalized settings and `read user data key [KEY]` to retrieve them. They build projects that remember user preferences (difficulty level, avatar choice, sound settings) tied to the logged-in user.

Dependencies:
* T33.G6.12: Save and load simple data to CreatiCode server
* T09.G5.01: Use multiple variables together in a single expression




ID: T33.G6.19
Topic: T33 – Connected Services
Skill: Debug timing issues when cloud response arrives after next block runs
Description: Students observe bugs where code runs before cloud data arrives (variable is empty when used). They use console logging to trace execution order and identify the race condition. They fix the bug by ensuring dependent code runs only after the cloud response arrives, learning that cloud blocks complete before the next block runs (blocking behavior).

Dependencies:
* T33.G6.07: Detect and handle empty or error responses from cloud services
* T33.G6.12: Save and load simple data to CreatiCode server




ID: T33.G7.01
Topic: T33 – Connected Services
Skill: Query cloud collection with simple WHERE condition using comparison operators
Description: Students use `fetch from collection [COLLECTION] into table [TABLE] where <CONDITION>` with the `<cond [INPUT1] [COMPARATOR] [INPUT2]>` block to filter records. They build queries like "score > 100" or "level = 5" using the `field [FIELDNAME]` block. They compare query results to full fetch results to verify filtering works correctly.

Dependencies:
* T33.G6.10: Fetch all documents from a cloud database collection into a table
* T08.G5.02: Use nested conditionals for multi-branch decisions





ID: T33.G7.02
Topic: T33 – Connected Services
Skill: Query cloud collection with AND/OR compound conditions
Description: Students combine multiple conditions using `<cond <> and <>>` and `<cond <> or <>>` blocks to create compound queries. They build filters like "score > 100 AND level = 5" or "status = 'active' OR priority = 'high'". They trace query logic to predict which records will be returned.

Dependencies:
* T33.G7.01: Query cloud collection with simple WHERE condition using comparison operators
* T08.G5.02: Use nested conditionals for multi-branch decisions





ID: T33.G7.03
Topic: T33 – Connected Services
Skill: Query cloud collection with NOT and CONTAINS conditions
Description: Students use `<cond not <>>` to negate conditions and `<cond (field [FIELDNAME]) contains [TEXT]>` for text substring matching. They build queries like "NOT (status = 'deleted')" or "name contains 'Team'". They combine these with AND/OR for sophisticated filters.

Dependencies:
* T33.G7.02: Query cloud collection with AND/OR compound conditions
* T11.G5.01: Extract and combine parts of strings





ID: T33.G7.04
Topic: T33 – Connected Services
Skill: Sort and limit cloud collection query results
Description: Students use SORT BY parameter with field name and order (1 for ascending, -1 for descending) and LIMIT parameter to control result count. They build leaderboards showing top 10 scores sorted descending, or paginated views showing 20 records at a time. They understand sorting and limiting happen server-side for efficiency.

Dependencies:
* T33.G7.01: Query cloud collection with simple WHERE condition using comparison operators
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T33.G7.05
Topic: T33 – Connected Services
Skill: Update cloud collection documents using table-based updates
Description: Students use `update collection [COLLECTION] from table [TABLE]` to modify existing records. They implement the fetch-modify-write pattern: fetch documents into a table, change values using table operations, then write the modified table back. They build features that edit user profiles or update game settings.

Dependencies:
* T33.G7.01: Query cloud collection with simple WHERE condition using comparison operators
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T33.G7.06
Topic: T33 – Connected Services
Skill: Update cloud collection fields in-place with WHERE conditions
Description: Students use `update collection [COLLECTION] in-place where <CONDITION> set (FIELD) to (VALUE)` to change specific fields without loading data first. They build features that increment scores, change statuses, or update timestamps for matching records efficiently. They compare in-place updates to table-based updates and choose appropriately.

Dependencies:
* T33.G7.05: Update cloud collection documents using table-based updates
* T33.G7.02: Query cloud collection with AND/OR compound conditions





ID: T33.G7.07
Topic: T33 – Connected Services
Skill: Remove documents from cloud collections with WHERE conditions
Description: Students use `remove all documents from collection [COLLECTION] where <CONDITION>` to delete specific records matching criteria. They understand removal is permanent and cannot be undone. They implement confirmation checks and test with sample data before removing production data.

Dependencies:
* T33.G7.02: Query cloud collection with AND/OR compound conditions
* T08.G5.02: Use nested conditionals for multi-branch decisions





ID: T33.G7.08
Topic: T33 – Connected Services
Skill: Create a cloud session for real-time variable sharing
Description: Students use `create cloud session [SESSION]` to establish a named session that enables real-time sharing of cloud variables. They understand the session creator becomes the "host." Each session requires a unique ID (room name), and the creator shares this ID with collaborators. Only cloud variables (not regular variables) synchronize across sessions.

Dependencies:
* T33.G5.01: Distinguish real-time sync from one-time fetch in app scenarios
* T09.G5.01: Use multiple variables together in a single expression





ID: T33.G7.09
Topic: T33 – Connected Services
Skill: Join a cloud session and synchronize variables with others
Description: Students use `join cloud session [SESSION]` to connect to an existing session. They build collaborative features where cloud variable changes appear instantly for all users: synchronized counters, shared text displays, collaborative drawing. They test isolation by using different vs same session IDs.

Dependencies:
* T33.G7.08: Create a cloud session for real-time variable sharing
* T09.G5.01: Use multiple variables together in a single expression

Note: Cloud sessions synchronize cloud variables only. For full multiplayer games with sprite replication, see Topic T19.





ID: T33.G7.10
Topic: T33 – Connected Services
Skill: Insert and remove rows dynamically in Google Sheets
Description: Students use `insert [COUNT] rows at row [START]` to add empty rows at a specific position, and `remove rows [FROM] to [TO]` to delete row ranges. They understand that inserting shifts existing rows down and removing shifts rows up. They build data management systems that expand or archive data dynamically.

Dependencies:
* T33.G6.08: List, add, and remove sheets in a Google Spreadsheet
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T33.G7.11
Topic: T33 – Connected Services
Skill: Insert and remove columns dynamically in Google Sheets
Description: Students use `insert [COUNT] columns at column [START]` to add empty columns, and `remove columns [FROM] to [TO]` to delete column ranges. They understand that inserting shifts existing columns right and removing shifts columns left. They build data structures that dynamically expand for new data fields.

Dependencies:
* T33.G7.10: Insert and remove rows dynamically in Google Sheets
* T10.G5.01: Understand table structure (rows, columns, cells)





ID: T33.G7.12
Topic: T33 – Connected Services
Skill: Build workflows that combine multiple cloud services sequentially
Description: Students orchestrate multi-service workflows: fetch web content → process with AI → store results in Google Sheets, or read settings from Sheets → generate AI content → display. They use variables to pass data between service calls and ensure each step completes before the next begins.

Dependencies:
* T33.G6.02: Read data range from Google Sheets into a table variable
* T33.G6.03: Write table data to Google Sheets from starting cell
* T33.G6.01: Fetch web content using the fetch URL block and display it





ID: T33.G7.13
Topic: T33 – Connected Services
Skill: Implement rate limiting with cooldown timers for service calls
Description: Students implement counters and cooldown timers so projects don't spam external service blocks. They create a call counter that prevents additional requests until a timer expires. They understand that excessive calls may be blocked and learn to respect service rate limits.

Dependencies:
* T33.G6.07: Detect and handle empty or error responses from cloud services
* T07.G5.01: Use timer blocks to control timing in programs




ID: T33.G7.14
Topic: T33 – Connected Services
Skill: Read URL parameters to customize project behavior
Description: Students use `read URL parameter [PARAMETER]` to get values passed in the project URL (e.g., ?mode=easy&level=3). They build projects that change behavior based on URL parameters: different starting levels, color themes, or preset configurations. They understand this enables sharing customized project links.

Dependencies:
* T33.G5.02: Identify what data is safe to share in URLs versus private
* T09.G5.01: Use multiple variables together in a single expression




ID: T33.G7.15
Topic: T33 – Connected Services
Skill: Use AI moderation to check text content
Description: Students use `get moderation result for [TEXT]` to check if user-generated text is appropriate, receiving "Pass" or "Fail" results. They build projects with user input that filter inappropriate content before displaying or storing it. They understand moderation helps maintain safe online spaces.

Dependencies:
* T33.G6.07: Detect and handle empty or error responses from cloud services
* T32.G5.01: Identify online communication that needs adult help




ID: T33.G7.16
Topic: T33 – Connected Services
Skill: Use AI moderation to check images
Description: Students use `get moderation result for image at URL [URL]` or `get moderation result for costume named [NAME]` to check if images are appropriate. They build projects that validate user-uploaded images before adding them to shared galleries or displays.

Dependencies:
* T33.G7.15: Use AI moderation to check text content
* T33.G6.14: Add costume from URL to load external images




ID: T33.G7.17
Topic: T33 – Connected Services
Skill: Open external URLs from project
Description: Students use `open URL [URL] in new browser tab` to link their project to external resources (documentation, related content, source websites). They build projects with help buttons, "learn more" links, or external resource navigation. They understand security implications of linking to external sites.

Dependencies:
* T33.G6.01: Fetch web content using the fetch URL block and display it
* T32.G5.04: Verify information from multiple sources




ID: T33.G7.18
Topic: T33 – Connected Services
Skill: Add YouTube videos as widgets
Description: Students use `add youtube video [URL] at X (X) Y (Y) width (WIDTH) height (HEIGHT)` to embed YouTube videos in their projects. They control video positioning and sizing. They build educational projects that include instructional videos or multimedia presentations.

Dependencies:
* T33.G6.15: Display images from URL using widget blocks
* T33.G7.17: Open external URLs from project




ID: T33.G7.19
Topic: T33 – Connected Services
Skill: Design table schemas for cloud database collections
Description: Students plan table structures before inserting data: choosing field names, deciding data types (text vs number), and considering which fields will be queried frequently. They implement a schema for a game (player name, score, level, timestamp) and explain why good schema design makes querying easier and more efficient.

Dependencies:
* T33.G7.04: Sort and limit cloud collection query results
* T33.G7.05: Update cloud collection documents using table-based updates




ID: T33.G7.20
Topic: T33 – Connected Services
Skill: Implement data synchronization between local and cloud storage
Description: Students build projects that work offline using local storage and sync to cloud when connected. They implement a sync strategy: save locally first for speed, then push to cloud for persistence. They handle sync conflicts when local and cloud data differ, choosing "last write wins" or "merge" strategies.

Dependencies:
* T33.G7.19: Design table schemas for cloud database collections
* T33.G6.13: Save and load table data to CreatiCode server




ID: T33.G8.01
Topic: T33 – Connected Services
Skill: Cache service responses locally to reduce redundant API calls
Description: Students implement a caching pattern: before calling an external service, check if the same request was made recently by looking up a local table. If found, use the cached response; otherwise, make the call and store the result. They implement simple cache expiration using timestamps. This reduces service calls and improves performance.

Dependencies:
* T33.G7.12: Build workflows that combine multiple cloud services sequentially
* T10.G6.01: Sort a table by a column





ID: T33.G8.02
Topic: T33 – Connected Services
Skill: Validate and sanitize data received from external services
Description: Students create validation logic for external service data: checking data types from Google Sheets imports, confirming web fetch results are non-empty and correctly formatted. They implement logging of validation failures and create user-friendly error messages when data doesn't meet expectations.

Dependencies:
* T33.G7.12: Build workflows that combine multiple cloud services sequentially
* T10.G6.02: Filter table rows based on a condition





ID: T33.G8.03
Topic: T33 – Connected Services
Skill: Design fallback strategies for service outages
Description: Students design and implement fallback experiences for when Cloud services are unavailable: use cached data, switch to manual input alternatives, or gracefully degrade functionality. They test their fallback strategies by simulating offline conditions and document recovery procedures.

Dependencies:
* T33.G8.01: Cache service responses locally to reduce redundant API calls
* T33.G6.07: Detect and handle empty or error responses from cloud services





ID: T33.G8.04
Topic: T33 – Connected Services
Skill: Compare cloud-based and local implementations through hands-on testing
Description: Students implement the same feature twice—once using a Cloud service block and once using local data—then compare tradeoffs: internet dependency, response time, data persistence, and offline reliability. They document measured differences and create a decision framework for when each approach is better.

Dependencies:
* T33.G8.02: Validate and sanitize data received from external services
* T33.G8.03: Design fallback strategies for service outages





ID: T33.G8.05
Topic: T33 – Connected Services
Skill: Build a cloud-integrated data pipeline capstone project
Description: Students build a complete data pipeline as a capstone: fetch external data → process and transform → store in Google Sheets or cloud database → display results. They handle errors at each stage, implement validation, and create a dashboard showing pipeline status. This integrates skills from G6 through G8.

Dependencies:
* T33.G8.04: Compare cloud-based and local implementations through hands-on testing
* T33.G7.12: Build workflows that combine multiple cloud services sequentially




ID: T33.G8.06
Topic: T33 – Connected Services
Skill: Create a semantic database from table data
Description: Students use `create semantic database from table [TABLE]` to build a searchable knowledge base. They understand that the semantic database converts text into embeddings that allow meaning-based search rather than exact keyword matching. They populate a table with Q&A pairs or knowledge facts, then create the database for later querying.

Dependencies:
* T33.G6.10: Fetch all documents from a cloud database collection into a table
* T10.G6.01: Sort a table by a column




ID: T33.G8.07
Topic: T33 – Connected Services
Skill: Query semantic database for meaning-based search
Description: Students use `search semantic database with [QUERY] store top (K) in table [TABLE]` to find relevant entries by meaning rather than exact text match. They observe how "What's your phone number?" matches entries about "contact information." They use the top-K results to build smart Q&A bots or knowledge assistants.

Dependencies:
* T33.G8.06: Create a semantic database from table data
* T33.G7.01: Query cloud collection with simple WHERE condition using comparison operators




ID: T33.G8.08
Topic: T33 – Connected Services
Skill: Filter semantic search results with WHERE conditions
Description: Students use `search semantic database with [QUERY] where [CONDITION] store top (K) in table [TABLE]` to combine meaning-based search with structured filters. They build queries like "find relevant entries WHERE category = 'science'" to narrow results by metadata while still using semantic matching for the main search.

Dependencies:
* T33.G8.07: Query semantic database for meaning-based search
* T33.G7.02: Query cloud collection with AND/OR compound conditions




ID: T33.G8.09
Topic: T33 – Connected Services
Skill: Perform web search and process results programmatically
Description: Students use `web search [QUERY] store top (K) in table [TABLE]` to search the web from their project. They understand results include title, link, and snippet columns. They build projects that search for current information, parse the results, and display summaries or follow links for more detail.

Dependencies:
* T33.G8.02: Validate and sanitize data received from external services
* T33.G7.12: Build workflows that combine multiple cloud services sequentially




ID: T33.G8.10
Topic: T33 – Connected Services
Skill: Design retry logic for unreliable service calls
Description: Students implement retry patterns for cloud service calls that might fail: try the call, if it fails wait and try again, after N failures give up gracefully. They use loops with counters and delays to implement exponential backoff. They understand that network calls can fail temporarily and retries often succeed.

Dependencies:
* T33.G8.03: Design fallback strategies for service outages
* T33.G7.13: Implement rate limiting with cooldown timers for service calls




ID: T33.G8.11
Topic: T33 – Connected Services
Skill: Build a multi-service integration dashboard
Description: Students create a dashboard that displays live data from multiple cloud sources: leaderboard from game server, data summary from Google Sheets, status from database collection. They implement refresh intervals, loading states for each data source, and error handling that doesn't crash the whole dashboard if one service fails.

Dependencies:
* T33.G8.05: Build a cloud-integrated data pipeline capstone project
* T33.G8.10: Design retry logic for unreliable service calls




ID: T33.G8.12
Topic: T33 – Connected Services
Skill: Analyze cloud service costs and optimize usage
Description: Students analyze which cloud operations are "expensive" (slow, rate-limited, or use credits) versus "cheap" (fast, unlimited). They redesign projects to minimize expensive calls: batch operations instead of single-item calls, cache frequently-needed data, use local processing when possible. They create a cost-benefit analysis for cloud vs local approaches.

Dependencies:
* T33.G8.04: Compare cloud-based and local implementations through hands-on testing
* T33.G8.01: Cache service responses locally to reduce redundant API calls




ID: T33.G8.13
Topic: T33 – Connected Services
Skill: Architect a service composition pattern for complex applications
Description: Students design and document multi-service architectures where different cloud services work together: AI service provides text → TTS converts to speech → storage saves the audio. They create data flow diagrams showing service dependencies, identify single points of failure, and propose redundancy strategies. This develops systems thinking for distributed applications.

Dependencies:
* T33.G8.11: Build a multi-service integration dashboard
* T33.G8.12: Analyze cloud service costs and optimize usage




ID: T33.G8.14
Topic: T33 – Connected Services
Skill: Design event-driven service coordination patterns
Description: Students implement event-driven patterns where one service triggers another: when new data arrives in the database, fetch related content from web; when moderation fails, notify user and log the event. They use the "when variable changed" event to coordinate services without tight coupling, creating more maintainable and flexible architectures.

Dependencies:
* T33.G8.13: Architect a service composition pattern for complex applications
* T33.G7.09: Join a cloud session and synchronize variables with others




ID: T33.G8.15
Topic: T33 – Connected Services
Skill: Evaluate tradeoffs in service selection for real-world scenarios
Description: Students analyze real-world scenarios (building a collaborative document editor, creating a live trivia game, designing a content moderation system) and evaluate which combination of cloud services best fits each use case. They consider factors like latency requirements, data consistency needs, cost constraints, and offline capabilities to make informed architectural decisions.

Dependencies:
* T33.G8.14: Design event-driven service coordination patterns
* T33.G8.12: Analyze cloud service costs and optimize usage




ID: T34.GK.01
Topic: T34 – Computing History
Skill: Locate computing tools in picture scenes
Description: Using illustrated picture cards showing familiar places (home, school, store), students tap on computing devices (tablet, smart speaker, checkout scanner) and drag each to a card showing one job it performs (play music, show a recipe, count items).



ID: T34.GK.01.01
Topic: T34 – Computing History
Skill: Tap computing devices in home scenes
Description: Using picture cards showing a home (kitchen, living room), students tap on computing devices (tablet, smart speaker, microwave with buttons) and drag each to a matching job card (play videos, answer questions, heat food).



ID: T34.GK.01.02
Topic: T34 – Computing History
Skill: Tap computing devices in school and store scenes
Description: Using picture cards showing school and store scenes, students tap on computing devices (classroom tablets, checkout scanners, library computers) and drag each to a matching job card (learn math, add up prices, find books).

Dependencies:
* T34.GK.01.01: Tap computing devices in home scenes




ID: T34.GK.02
Topic: T34 – Computing History
Skill: Match old and new technology in picture pairs
Description: Using picture cards showing paired images (rotary phone vs smartphone, bulky PC vs tablet), students drag old and new versions together and select a label showing that technology changes over time.



ID: T34.GK.02.01
Topic: T34 – Computing History
Skill: Match old and new communication tools in pictures
Description: Using picture cards (rotary phone vs smartphone, letter vs email icon), students drag matching pairs together and tap which is old and which is new.



ID: T34.GK.02.02
Topic: T34 – Computing History
Skill: Match old and new computing machines in pictures
Description: Using picture cards (typewriter vs laptop, room-sized computer vs tablet), students drag matching pairs together and select a label showing computers got smaller over time.

Dependencies:
* T34.GK.02.01: Match old and new communication tools in pictures




ID: T34.GK.03
Topic: T34 – Computing History
Skill: Match workers to their computing tools in pictures
Description: Using picture cards showing everyday workers (teacher, nurse, mechanic), students drag lines to connect each person to the computing tool they use (laptop, tablet, diagnostic computer).



ID: T34.GK.04
Topic: T34 – Computing History
Skill: Classify robots and smart devices in picture scenes
Description: Using picture cards showing robots (vacuum robots, assembly-line robots) and smart devices (voice assistants, smart watches), students drag each into a "Robot" or "Smart Device" bin and then match it to a job card (clean floors, build cars, play music, show time).

Dependencies:
* T34.GK.01: Locate computing tools in picture scenes


ID: T34.GK.05
Topic: T34 – Computing History
Skill: Sort computing devices by what they help with
Description: Using picture cards of computing devices (calculator, tablet, robot arm), students drag each into bins labeled "Helps with Numbers," "Helps with Words and Pictures," or "Helps with Moving Things."

Dependencies:
* T34.GK.01: Locate computing tools in picture scenes
* T34.GK.04: Classify robots and smart devices in picture scenes


ID: T34.GK.06
Topic: T34 – Computing History
Skill: Identify which device is newer in picture comparisons
Description: Using side-by-side picture cards showing two versions of similar technology (old flip phone vs smartphone, CRT monitor vs flat screen), students tap the newer device and drag a "newer" star onto it.

Dependencies:
* T34.GK.02: Match old and new technology in picture pairs




ID: T34.G1.01
Topic: T34 – Computing History
Skill: Compare life before and after a technology using picture stories
Description: Using illustrated picture cards showing "before" and "after" scenes (writing letters vs video chat, paper maps vs GPS), students drag difference labels onto pictures and select which version is faster or easier.

Dependencies:
* T34.GK.02: Match old and new technology in picture pairs


ID: T34.G1.01.01
Topic: T34 – Computing History
Skill: Identify how one task changed with picture cards
Description: Using picture cards showing one task (sending messages: letter vs text), students drag a "faster" or "easier" label onto the new way and select one reason from a list (no waiting, no stamps, can send to many people).

Dependencies:
* T34.GK.02: Match old and new technology in picture pairs


ID: T34.G1.01.02
Topic: T34 – Computing History
Skill: Compare multiple tasks in before/after picture stories
Description: Using picture cards showing multiple tasks (maps vs GPS, encyclopedia vs internet search), students drag "before" and "after" labels onto each pair and sort them by how much time each new way saves.

Dependencies:
* T34.G1.01.01: Identify how one task changed with picture cards




ID: T34.G1.02
Topic: T34 – Computing History
Skill: Recognize computing pioneers in picture cards
Description: Using illustrated picture cards showing diverse pioneers (Ada Lovelace who wrote the first program, Charles Babbage who designed early computers, Grace Hopper who found the first "bug"), students match each person's picture to a card showing their contribution.

Dependencies:
* T34.GK.03: Match workers to their computing tools in pictures


ID: T34.G1.02.01
Topic: T34 – Computing History
Skill: Match pioneer pictures to their inventions
Description: Using picture cards of computing pioneers and their inventions, students draw lines connecting each person (Ada Lovelace, Alan Turing, Grace Hopper) to the invention or idea they are known for (first program, code-breaking computer, first compiler).

Dependencies:
* T34.G1.02: Recognize computing pioneers in picture cards


ID: T34.G1.03
Topic: T34 – Computing History
Skill: Sort computing tool pictures by era
Description: Using picture cards of computing tools (abacus, calculator, bulky computer, laptop, smartphone), students drag each card into "very old," "old," or "new" bins and select a statement explaining that tools became smaller and more powerful over time.

Dependencies:
* T34.GK.02: Match old and new technology in picture pairs


ID: T34.G1.04
Topic: T34 – Computing History
Skill: Sort picture cards of computing tools by size
Description: Using picture cards showing computing tools (room-sized mainframe, desktop computer, laptop, smartphone, smartwatch), students drag cards from biggest to smallest and select a label showing that computers got smaller over time.

Dependencies:
* T34.GK.02: Match old and new technology in picture pairs
* T34.G1.03: Sort computing tool pictures by era


ID: T34.G1.05
Topic: T34 – Computing History
Skill: Predict what a future computing tool might do
Description: Using picture cards showing today's technology (smartphone, smart speaker), students select from a list what new things a future device might do (talk like a friend, help with homework, drive a car) and drag their prediction onto a "Future Computer" card.

Dependencies:
* T34.G1.01: Compare life before and after a technology using picture stories
* T34.G1.03: Sort computing tool pictures by era


ID: T34.G1.06
Topic: T34 – Computing History
Skill: Identify computing helpers in community picture cards
Description: Using picture cards showing community helpers using technology (doctor with X-ray computer, librarian with catalog system, firefighter with radio), students match each helper to their computing tool and select how it helps them do their job better.

Dependencies:
* T34.GK.03: Match workers to their computing tools in pictures
* T34.G1.01: Compare life before and after a technology using picture stories




ID: T34.G2.01
Topic: T34 – Computing History
Skill: Complete "then vs now" comparison charts using picture cards
Description: Using picture cards showing tasks (taking photos, shopping, banking), students drag images into a two-column chart ("Then" and "Now") and connect each pair with an arrow showing how computers changed that task.

Dependencies:
* T34.G1.01: Compare life before and after a technology using picture stories
* T01.G1.01: Put pictures in order to plant a seed




ID: T34.G2.02
Topic: T34 – Computing History
Skill: Sort picture cards showing who inventions helped
Description: Using picture cards showing people using computing inventions (screen readers, online maps, smartphones), students drag cards into "helped many people" and "helped fewer people" bins and select one reason why some people were left out (cost, where they lived, language).

Dependencies:
* T34.G1.01: Compare life before and after a technology using picture stories
* T34.G1.02: Recognize computing pioneers in picture cards


ID: T34.G2.02.01
Topic: T34 – Computing History
Skill: Identify barriers to technology access in pictures
Description: Using picture cards showing different communities (rural areas, cities, different countries), students sort cards showing who can easily use computers and who cannot, then select reasons from a list (no internet, too expensive, needs electricity).

Dependencies:
* T34.G2.02: Sort picture cards showing who inventions helped


ID: T34.G2.03
Topic: T34 – Computing History
Skill: Complete mini-biography picture templates of computing helpers
Description: Using illustrated templates with picture cards, students drag icons showing facts (birthplace, invention, how they helped) onto a mini-bio poster about a person who uses tech to help others.

Dependencies:
* T34.G1.02: Recognize computing pioneers in picture cards


ID: T34.G2.04
Topic: T34 – Computing History
Skill: Sequence computing tool pictures from oldest to newest
Description: Using picture cards showing computing tools from different eras (abacus, mechanical calculator, early computer, modern laptop, smartphone), students drag them in order from oldest to newest and select one fact about each from a list.

Dependencies:
* T34.G1.03: Sort computing tool pictures by era
* T34.G1.04: Sort picture cards of computing tools by size


ID: T34.G2.05
Topic: T34 – Computing History
Skill: Classify what computers can and cannot do in picture scenarios
Description: Using picture cards showing tasks (hugging a friend, tasting food, feeling emotions, doing math, drawing pictures), students drag each into "Computers Can Do" or "Computers Cannot Do" bins and select one reason for each choice (needs a body, needs feelings, just follows rules).

Dependencies:
* T34.G1.01: Compare life before and after a technology using picture stories
* T34.G1.05: Predict what a future computing tool might do


ID: T34.G2.06
Topic: T34 – Computing History
Skill: Match computing tools to the problems they solved
Description: Using picture cards showing problems (slow calculations, lost letters, distant family) and solutions (calculators, email, video chat), students draw lines connecting each problem to the computing tool that solved it.

Dependencies:
* T34.G2.01: Complete "then vs now" comparison charts using picture cards
* T34.G2.04: Sequence computing tool pictures from oldest to newest




ID: T34.G3.01
Topic: T34 – Computing History
Skill: Sequence computing milestones on a timeline
Description: Students drag milestone cards (first programmable loom 1801, ENIAC 1945, Apple II 1977, iPhone 2007) onto a timeline and label each with its decade, selecting what each milestone made possible from a list.

Dependencies:
* T34.G2.01: Complete "then vs now" comparison charts using picture cards
* T34.G2.04: Sequence computing tool pictures from oldest to newest




ID: T34.G3.01.01
Topic: T34 – Computing History
Skill: Place three computing milestones on a simple timeline
Description: Students drag three milestone cards (ENIAC 1945, first video game 1958, first smartphone 2007) onto a timeline with decade markers and select one word describing what each made possible (calculate, play, connect).

Dependencies:
* T34.G2.04: Sequence computing tool pictures from oldest to newest


ID: T34.G3.01.02
Topic: T34 – Computing History
Skill: Sequence five or more milestones with decade labels
Description: Students drag five or more milestone cards onto a timeline, label each with its decade, and write one sentence describing how each milestone changed what computers could do.

Dependencies:
* T34.G3.01.01: Place three computing milestones on a simple timeline


ID: T34.G3.02
Topic: T34 – Computing History
Skill: Connect computing milestones to everyday activities
Description: Students select a computing milestone from a list and write 2-3 sentences explaining how it changed something they do daily (word processors for typing assignments, internet for homework research, smartphones for texting friends).

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline




ID: T34.G3.03
Topic: T34 – Computing History
Skill: Create profile cards for diverse computing pioneers
Description: Students research pioneers from diverse backgrounds (Mark Dean, Fei-Fei Li, Katherine Johnson) and create profile cards listing: name, era, country, invention or contribution, and one sentence about how their work changed computing.

Dependencies:
* T34.G2.03: Complete mini-biography picture templates of computing helpers


ID: T34.G3.03.01
Topic: T34 – Computing History
Skill: Identify key facts about a computing pioneer
Description: Given information about a computing pioneer (Katherine Johnson), students select correct answers about their contribution (space mission calculations), era (1960s), and why their work mattered (helped astronauts reach the moon).

Dependencies:
* T34.G3.03: Create profile cards for diverse computing pioneers


ID: T34.G3.04
Topic: T34 – Computing History
Skill: Trace software interface evolution from text to visual
Description: Students sequence major software interface developments (punch cards, text commands, windows/menus, touchscreen apps, voice assistants) and write one sentence for each step explaining what changed for users (easier to learn, no typing needed).

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline




ID: T34.G3.05
Topic: T34 – Computing History
Skill: Sequence gaming platform evolution
Description: Students order gaming platforms chronologically (arcade games 1970s, home consoles 1980s, handheld games 1990s, PC games 2000s, mobile games 2010s, VR 2020s) and write one example game type each platform made popular.

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G3.04: Trace software interface evolution from text to visual


ID: T34.G3.06
Topic: T34 – Computing History
Skill: Explain why early computers were room-sized
Description: Students examine images of early computers (ENIAC, room-sized mainframes) and complete a cause-effect diagram explaining why they were huge (vacuum tubes, cooling systems, miles of wiring) and why modern computers fit in pockets (transistors, microchips, miniaturization).

Dependencies:
* T34.G2.04: Sequence computing tool pictures from oldest to newest
* T34.G3.01: Sequence computing milestones on a timeline


ID: T34.G3.07
Topic: T34 – Computing History
Skill: Trace how computing tools changed a specific job
Description: Students select one job (librarian, cashier, pilot) and create a mini-timeline showing how computing tools changed that job over 50 years, listing at least 3 specific changes with approximate dates (card catalogs to computer databases to online search).

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G3.02: Connect computing milestones to everyday activities


ID: T34.G3.08
Topic: T34 – Computing History
Skill: Compare computing tools across generations in a family
Description: Students interview a family member about what computing tools they used at the student's age (typewriters, calculators, early computers) and create a comparison chart showing "Then" vs "Now" tools for the same tasks (writing, calculating, playing games).

Dependencies:
* T34.G3.02: Connect computing milestones to everyday activities
* T34.G3.07: Trace how computing tools changed a specific job


ID: T34.G3.09
Topic: T34 – Computing History
Skill: Identify the first "bug" story and its meaning
Description: Students read the story of Grace Hopper finding an actual moth in the Mark II computer (1947) and explain why we call computer problems "bugs" and fixing them "debugging."

Dependencies:
* T34.G3.03: Create profile cards for diverse computing pioneers
* T34.G3.06: Explain why early computers were room-sized




ID: T34.G4.01
Topic: T34 – Computing History
Skill: Construct cause-effect chains in computing history
Description: Students trace how one invention (the transistor) enabled subsequent technologies (microchips, PCs, mobile devices) by creating a cause-effect diagram with at least 4 linked steps, labeling each arrow with the enabling factor (smaller, cheaper, faster).

Dependencies:
* T12.G3.01: Test and trace simple block-based scripts
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G3.02: Connect computing milestones to everyday activities



ID: T34.G4.01.01
Topic: T34 – Computing History
Skill: Identify a single cause-effect link between two inventions
Description: Students select two related computing inventions from a list (vacuum tube to transistor, transistor to microchip) and write one sentence explaining how the first invention's limitations led to the second invention (too hot led to cooler, too big led to smaller).

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G3.02: Connect computing milestones to everyday activities



ID: T34.G4.01.02
Topic: T34 – Computing History
Skill: Construct a multi-step cause-effect chain diagram
Description: Students build a diagram with at least three linked inventions showing cascading effects (transistor to microchip to personal computer to smartphone) and label each arrow with the enabling factor.

Dependencies:
* T34.G4.01.01: Identify a single cause-effect link between two inventions




ID: T34.G4.02
Topic: T34 – Computing History
Skill: Compare regional computing adoption
Description: Students research how two different regions (US vs Japan, Europe vs Asia) adopted computers and create a chart noting similarities and differences in timing and usage.

Dependencies:
* T34.G3.02: Connect computing milestones to everyday activities
* T34.G3.03: Create profile cards for diverse computing pioneers




ID: T34.G4.03
Topic: T34 – Computing History
Skill: Trace data storage evolution
Description: Students create a timeline of data storage methods (punch cards, magnetic tape, floppy disks, hard drives, USB drives, cloud storage) with capacity estimates for each era, explaining why each advance mattered (more data, faster access, easier sharing).

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G4.01: Construct cause-effect chains in computing history




ID: T34.G4.04
Topic: T34 – Computing History
Skill: Sequence internet evolution milestones
Description: Students create a timeline of internet development (ARPANET 1969, World Wide Web 1991, search engines 1998, social media 2004, streaming 2010s, AI assistants 2020s) and write one sentence for each explaining how it changed information access.

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G4.01: Construct cause-effect chains in computing history


ID: T34.G4.04.01
Topic: T34 – Computing History
Skill: Identify key internet milestones and their dates
Description: Students match internet milestones (ARPANET, WWW, first search engine, first social network) to their approximate dates and select one sentence describing what each made possible.

Dependencies:
* T34.G4.04: Sequence internet evolution milestones




ID: T34.G4.05
Topic: T34 – Computing History
Skill: Document an innovator's journey from idea to impact
Description: Students research a computing innovator (inventor or entrepreneur) and document key milestones in their journey including the original idea, challenges faced, and eventual impact.

Dependencies:
* T34.G3.03: Create profile cards for diverse computing pioneers
* T34.G4.01: Construct cause-effect chains in computing history


ID: T34.G4.06
Topic: T34 – Computing History
Skill: Compare how the same task was programmed across eras
Description: Students compare how a simple task (sorting numbers, displaying text) was done across computing eras: punch cards, typed commands, visual programming (Scratch/CreatiCode), explaining what changed for programmers.

Dependencies:
* T34.G3.04: Trace software interface evolution from text to visual
* T34.G4.01: Construct cause-effect chains in computing history


ID: T34.G4.07
Topic: T34 – Computing History
Skill: Explain Moore's Law using historical data
Description: Students examine processor data from different decades (1970s: thousands of transistors, 2020s: billions), create a simple chart showing transistor growth, and explain Moore's Law (doubling every 2 years) and predict what it means for future computing power.

Dependencies:
* T34.G3.06: Explain why early computers were room-sized
* T34.G4.01: Construct cause-effect chains in computing history


ID: T34.G4.08
Topic: T34 – Computing History
Skill: Trace the evolution of programming from binary to blocks
Description: Students create a visual showing how programming evolved (binary codes 1950s, assembly language 1960s, text languages 1970s-90s, visual blocks 2000s, AI-assisted 2020s) and explain how each step made programming accessible to more people.

Dependencies:
* T34.G3.04: Trace software interface evolution from text to visual
* T34.G4.06: Compare how the same task was programmed across eras


ID: T34.G4.09
Topic: T34 – Computing History
Skill: Build a simple computing history quiz in CreatiCode
Description: Students create a CreatiCode project with at least 5 multiple-choice questions about computing history milestones, using ask blocks and if-then conditions to check answers and display feedback.

Dependencies:
* T34.G4.01: Construct cause-effect chains in computing history
* T34.G4.04: Sequence internet evolution milestones




ID: T34.G5.01
Topic: T34 – Computing History
Skill: Investigate a social movement where computing played a key role
Description: Students research one social movement where computing was significant (accessibility advocacy with screen readers, open-source movement, or educational technology for underserved communities) and present findings with evidence.

Dependencies:
* T34.G4.01: Construct cause-effect chains in computing history
* T34.G4.02: Compare regional computing adoption




ID: T34.G5.02
Topic: T34 – Computing History
Skill: Compare invention timelines across industries
Description: Students create parallel timelines showing computing milestones alongside another domain (medicine, music, transportation) to identify cross-industry influence and co-evolution.

Dependencies:
* T34.G3.01: Sequence computing milestones on a timeline
* T34.G4.02: Compare regional computing adoption




ID: T34.G5.03
Topic: T34 – Computing History
Skill: Conduct interviews about technology changes
Description: Students interview family or community members about how technology changed their work or daily life over time, prepare 5 structured questions, record key responses, and write a 1-paragraph summary comparing their experiences to current technology use.

Dependencies:
* T34.G3.03: Create profile cards for diverse computing pioneers
* T34.G4.05: Document an innovator's journey from idea to impact




ID: T34.G5.04
Topic: T34 – Computing History
Skill: Analyze how internet changed communication
Description: Students compare pre-internet and post-internet communication methods (letters to email, libraries to search engines, stores to e-commerce) and explain social and economic impacts of each change.

Dependencies:
* T34.G4.04: Sequence internet evolution milestones
* T34.G5.01: Investigate a social movement where computing played a key role




ID: T34.G5.05
Topic: T34 – Computing History
Skill: Link hardware evolution to modern programming features
Description: Students trace how specific hardware innovations (GPU development, increased processing power, network bandwidth) made modern programming features possible (3D graphics, real-time AI, multiplayer games) and explain why these features could not exist on 1990s computers.

Dependencies:
* T34.G4.01: Construct cause-effect chains in computing history
* T34.G4.03: Trace data storage evolution
* T12.G3.01: Test and trace simple block-based scripts


ID: T34.G5.06
Topic: T34 – Computing History
Skill: Trace the evolution of programming languages
Description: Students create a timeline of programming language evolution (machine code to assembly to FORTRAN/COBOL to C to Python/JavaScript to visual programming) and explain how each generation made programming more accessible.

Dependencies:
* T34.G4.06: Compare how the same task was programmed across eras
* T34.G5.02: Compare invention timelines across industries


ID: T34.G5.07
Topic: T34 – Computing History
Skill: Investigate the history of computer bugs and debugging
Description: Students research famous bugs (first actual bug 1947, Y2K 1999, Ariane 5 1996) and create a timeline showing how debugging tools evolved from print statements to modern debuggers, explaining what each generation of tools added.

Dependencies:
* T34.G4.01: Construct cause-effect chains in computing history
* T34.G4.06: Compare how the same task was programmed across eras


ID: T34.G5.08
Topic: T34 – Computing History
Skill: Trace the history of computing accessibility
Description: Students research how computing became accessible to people with disabilities (screen readers 1980s, voice control 2000s, eye tracking 2010s) and create a timeline showing both technological advances and remaining challenges.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G5.04: Analyze how internet changed communication


ID: T34.G5.09
Topic: T34 – Computing History
Skill: Build a CreatiCode timeline explorer with clickable eras
Description: Students create an interactive CreatiCode project where users click on different computing eras (1940s, 1970s, 2000s) to see information about key inventions, using sprite costumes and broadcast messages for navigation.

Dependencies:
* T34.G4.09: Build a simple computing history quiz in CreatiCode
* T34.G5.02: Compare invention timelines across industries


ID: T34.G5.10
Topic: T34 – Computing History
Skill: Compare the first programmers to modern programmers
Description: Students research early programmers (Ada Lovelace, ENIAC women, Grace Hopper) and compare their tools, challenges, and methods to modern programmers using IDEs and AI assistants, identifying what has changed and what remains the same.

Dependencies:
* T34.G4.08: Trace the evolution of programming from binary to blocks
* T34.G5.06: Trace the evolution of programming languages




ID: T34.G6.01
Topic: T34 – Computing History
Skill: Analyze hardware computing eras (mainframe to PC to mobile)
Description: Students compare mainframe (1950s-1970s), personal computer (1980s-2000s), and mobile computing (2010s-present) eras using a comparison chart showing size, cost, typical users, and what each era made possible for everyday people.

Dependencies:
* T34.G4.01: Construct cause-effect chains in computing history
* T34.G5.02: Compare invention timelines across industries
* T34.G5.05: Link hardware evolution to modern programming features




ID: T34.G6.02
Topic: T34 – Computing History
Skill: Analyze network computing eras (standalone to internet to cloud)
Description: Students compare standalone computing, internet-connected computing, and cloud computing eras, identifying what became possible in each phase and what limitations remained.

Dependencies:
* T34.G5.04: Analyze how internet changed communication
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)




ID: T34.G6.03
Topic: T34 – Computing History
Skill: Evaluate who had access to computing in different eras
Description: Students examine who gained or lacked access to computing historically (by cost, geography, language, disability) using a multi-era comparison chart, connecting historical patterns to current access barriers and proposed solutions.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G4.02: Compare regional computing adoption
* T34.G5.08: Trace the history of computing accessibility




ID: T34.G6.04
Topic: T34 – Computing History
Skill: Analyze how user interface evolution expanded access
Description: Students trace UI evolution (command line to GUI to touchscreen to voice) and explain how each advance made computers accessible to new user groups (children, non-English speakers, people with motor disabilities).

Dependencies:
* T34.G5.08: Trace the history of computing accessibility
* T34.G6.03: Evaluate who had access to computing in different eras




ID: T34.G6.05
Topic: T34 – Computing History
Skill: Analyze a historical computing failure and its lessons
Description: Students study one famous software bug or system failure (Y2K problem, Therac-25, Ariane 5 rocket) and write a case study explaining: what happened, why it happened, what it cost, and what lessons it taught the computing industry about testing, safety, and design.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G5.07: Investigate the history of computer bugs and debugging


ID: T34.G6.06
Topic: T34 – Computing History
Skill: Compare open-source vs proprietary software history
Description: Students trace the history of open-source software (GNU, Linux, Apache) versus proprietary software, analyzing the motivations, business models, and impact of each approach on computing.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G5.06: Trace the evolution of programming languages


ID: T34.G6.07
Topic: T34 – Computing History
Skill: Analyze the history of computer graphics and visualization
Description: Students trace the evolution of computer graphics (text to 2D graphics to 3D to VR/AR) and explain how each advance changed what computers could communicate to users.

Dependencies:
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)
* T34.G6.04: Analyze how user interface evolution expanded access


ID: T34.G6.08
Topic: T34 – Computing History
Skill: Build an interactive pioneer biography in CreatiCode
Description: Students create a CreatiCode project presenting a computing pioneer's life story with multiple clickable scenes, text-to-speech narration for key facts, and quiz elements testing the viewer's knowledge.

Dependencies:
* T34.G5.09: Build a CreatiCode timeline explorer with clickable eras
* T34.G6.03: Evaluate who had access to computing in different eras


ID: T34.G6.09
Topic: T34 – Computing History
Skill: Trace the history of AI from Turing to ChatGPT
Description: Students create a timeline of AI development from Alan Turing's 1950 paper through expert systems, neural networks, deep learning, and large language models, identifying the key breakthrough and limitation of each era.

Dependencies:
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)
* T34.G6.02: Analyze network computing eras (standalone to internet to cloud)




ID: T34.G7.01
Topic: T34 – Computing History
Skill: Construct a comprehensive AI history timeline
Description: Students create a timeline of major AI breakthroughs (Turing test, expert systems, deep learning, large language models) and analyze how each changed human-computer interaction and what enabled the breakthrough.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G5.02: Compare invention timelines across industries
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)



ID: T34.G7.01.01
Topic: T34 – Computing History
Skill: Sequence early AI milestones (1950s-1980s)
Description: Students place early AI milestones (Turing test proposal, first expert systems, early chatbots like ELIZA) on a timeline and explain the limitations of each era.

Dependencies:
* T34.G5.02: Compare invention timelines across industries
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)



ID: T34.G7.01.02
Topic: T34 – Computing History
Skill: Trace modern AI breakthroughs (1990s-present)
Description: Students create a timeline of modern AI developments (machine learning, deep learning, large language models) and identify what hardware or data advances enabled each breakthrough.

Dependencies:
* T34.G7.01.01: Sequence early AI milestones (1950s-1980s)




ID: T34.G7.02
Topic: T34 – Computing History
Skill: Evaluate how technology policies evolved over time
Description: Students examine how one technology policy evolved historically (COPPA, early computer misuse acts, or privacy regulations) and analyze its motivations, implementation challenges, and outcomes.

Dependencies:
* T34.G5.01: Investigate a social movement where computing played a key role
* T34.G6.03: Evaluate who had access to computing in different eras




ID: T34.G7.03
Topic: T34 – Computing History
Skill: Design a museum-style exhibit about a computing pioneer
Description: Students plan a museum exhibit highlighting a computing pioneer including: biography panel, 3-5 key artifacts from their era with descriptions, interactive element design, and a "modern relevance" section connecting their work to today's technology.

Dependencies:
* T34.G5.03: Conduct interviews about technology changes
* T34.G6.05: Analyze a historical computing failure and its lessons




ID: T34.G7.04
Topic: T34 – Computing History
Skill: Identify and explain patterns of technological change
Description: Students identify patterns in computing history (miniaturization, cost reduction, increased access, faster adoption rates) and explain each pattern with 2-3 historical examples and predict future implications.

Dependencies:
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)
* T34.G6.02: Analyze network computing eras (standalone to internet to cloud)


ID: T34.G7.05
Topic: T34 – Computing History
Skill: Trace the history of cybersecurity and hacking
Description: Students research the evolution of cybersecurity (early viruses, worms, cyberattacks, modern threats) and explain how security practices evolved in response to each generation of threats.

Dependencies:
* T34.G6.05: Analyze a historical computing failure and its lessons
* T34.G7.02: Evaluate how technology policies evolved over time


ID: T34.G7.06
Topic: T34 – Computing History
Skill: Compare AI winters and AI booms historically
Description: Students analyze the cycles of AI optimism and disappointment (1960s-70s boom, first AI winter, expert systems boom, second winter, modern deep learning boom) and identify factors that caused each phase.

Dependencies:
* T34.G7.01: Construct a comprehensive AI history timeline
* T34.G7.04: Identify and explain patterns of technological change


ID: T34.G7.07
Topic: T34 – Computing History
Skill: Analyze the history of human-computer interaction
Description: Students trace the evolution of HCI (batch processing to command line to GUI to touch to voice to gesture to brain-computer interfaces) and explain how each paradigm changed who could use computers and for what purposes, predicting the next major interaction paradigm.

Dependencies:
* T34.G6.04: Analyze how user interface evolution expanded access
* T34.G6.07: Analyze the history of computer graphics and visualization


ID: T34.G7.08
Topic: T34 – Computing History
Skill: Trace the history of AI assistants in programming
Description: Students research the evolution of programming assistance tools (syntax highlighting to autocomplete to IntelliSense to AI code completion to AI pair programming) and analyze how each generation changed programmer productivity and required skills.

Dependencies:
* T34.G7.01: Construct a comprehensive AI history timeline
* T34.G7.04: Identify and explain patterns of technological change


ID: T34.G7.09
Topic: T34 – Computing History
Skill: Compare computing revolutions and their adoption patterns
Description: Students analyze how different computing revolutions (mainframes, PCs, internet, smartphones, AI) were adopted, comparing initial skepticism, breakthrough moments, and mass adoption timelines to identify patterns that might predict future technology adoption.

Dependencies:
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)
* T34.G7.04: Identify and explain patterns of technological change


ID: T34.G7.10
Topic: T34 – Computing History
Skill: Build a "talk to a pioneer" chatbot in CreatiCode
Description: Students use CreatiCode's ChatGPT blocks to create an interactive chatbot that responds as a computing pioneer (Ada Lovelace, Alan Turing, Grace Hopper), incorporating historical facts about their life, era, and contributions.

Dependencies:
* T34.G6.08: Build an interactive pioneer biography in CreatiCode
* T34.G7.01: Construct a comprehensive AI history timeline


ID: T34.G7.11
Topic: T34 – Computing History
Skill: Analyze how computing changed one field historically
Description: Students select one field (medicine, music, science, education) and create a detailed analysis of how computing transformed it over 50 years, including specific technologies, key turning points, and remaining challenges.

Dependencies:
* T34.G7.04: Identify and explain patterns of technological change
* T34.G7.09: Compare computing revolutions and their adoption patterns




ID: T34.G8.01
Topic: T34 – Computing History
Skill: Write evidence-based technology forecasts with supporting data
Description: Students analyze historical patterns (processor speeds, adoption curves, AI progress) and write evidence-based forecasts for one future technology (AI tutors, AR classrooms, or quantum computing), citing specific historical data points.

Dependencies:
* T34.G7.01: Construct a comprehensive AI history timeline
* T34.G7.04: Identify and explain patterns of technological change
* T03.G6.01: Propose a module hierarchy for a medium project
* T21.G6.01.01: Make a basic ChatGPT request with one parameter




ID: T34.G8.02
Topic: T34 – Computing History
Skill: Analyze a cross-cultural innovation ecosystem with historical context
Description: Students investigate how policies, education, and industry shaped computing in one region (Kenya's mobile payment innovation or Estonia's e-government) and link findings to historical roots, explaining why innovation happened there rather than elsewhere.

Dependencies:
* T34.G6.01: Analyze hardware computing eras (mainframe to PC to mobile)
* T34.G7.02: Evaluate how technology policies evolved over time
* T10.G6.01: Sort a table by a column




ID: T34.G8.03
Topic: T34 – Computing History
Skill: Gather primary sources for computing history research
Description: Students gather primary sources (oral histories, historical documents, archival photos) about a computing history topic and organize them with proper citations.

Dependencies:
* T34.G6.03: Evaluate who had access to computing in different eras
* T34.G7.03: Design a museum-style exhibit about a computing pioneer




ID: T34.G8.04
Topic: T34 – Computing History
Skill: Build an interactive CreatiCode exhibit about computing history
Description: Students build an interactive CreatiCode scene presenting their computing history research, including clickable elements, multiple information panels, text-to-speech narration, and navigation between topics.

Dependencies:
* T34.G7.03: Design a museum-style exhibit about a computing pioneer
* T34.G8.03: Gather primary sources for computing history research
* T11.G6.14: Analyze a program's structure using a checklist and suggest specific improvements
* T32.G6.14: Compare computing career clusters (software, hardware, data, AI)


ID: T34.G8.05
Topic: T34 – Computing History
Skill: Analyze how AI is changing the history of programming
Description: Students analyze how AI tools (code completion, AI assistants, natural language to code) are changing programming, comparing current changes to historical paradigm shifts and predicting future developments.

Dependencies:
* T34.G7.01: Construct a comprehensive AI history timeline
* T34.G7.06: Compare AI winters and AI booms historically


ID: T34.G8.06
Topic: T34 – Computing History
Skill: Debate ethical dilemmas from computing history
Description: Students research a historical computing ethics debate (nuclear targeting systems, surveillance technology, early AI safety concerns) and construct arguments from multiple perspectives, connecting to current ethical discussions.

Dependencies:
* T34.G7.02: Evaluate how technology policies evolved over time
* T34.G7.05: Trace the history of cybersecurity and hacking


ID: T34.G8.07
Topic: T34 – Computing History
Skill: Create a computing history documentary script
Description: Students write a detailed documentary script about a computing history topic, including narration, interview questions, visual sequences, and primary source citations.

Dependencies:
* T34.G8.03: Gather primary sources for computing history research
* T34.G8.01: Write evidence-based technology forecasts with supporting data


ID: T34.G8.08
Topic: T34 – Computing History
Skill: Analyze how computing changed scientific discovery
Description: Students investigate how computing transformed one scientific field (genomics, climate modeling, particle physics, astronomy) and explain what discoveries would have been impossible without computers, including the role of AI in recent breakthroughs.

Dependencies:
* T34.G7.04: Identify and explain patterns of technological change
* T34.G8.02: Analyze a cross-cultural innovation ecosystem with historical context


ID: T34.G8.09
Topic: T34 – Computing History
Skill: Predict the future of programming with AI
Description: Students analyze historical programming paradigm shifts and current AI capabilities to write an evidence-based prediction about how programming might change in 10-20 years, considering what skills will remain valuable and what new skills may be needed.

Dependencies:
* T34.G7.08: Trace the history of AI assistants in programming
* T34.G8.05: Analyze how AI is changing the history of programming


ID: T34.G8.10
Topic: T34 – Computing History
Skill: Create an interactive timeline of computing history
Description: Students build an interactive CreatiCode project presenting computing history with clickable eras, pop-up information panels, embedded images, and quiz elements that test users' knowledge of key milestones and pioneers.

Dependencies:
* T34.G8.04: Build an interactive CreatiCode exhibit about computing history
* T34.G8.07: Create a computing history documentary script


ID: T34.G8.11
Topic: T34 – Computing History
Skill: Synthesize lessons from computing history for future decisions
Description: Students write a synthesis essay connecting multiple computing history lessons (failed predictions, unintended consequences, access barriers) to a current technology decision (AI regulation, social media rules, privacy laws), using historical evidence to support recommendations.

Dependencies:
* T34.G8.01: Write evidence-based technology forecasts with supporting data
* T34.G8.06: Debate ethical dilemmas from computing history


ID: T34.G8.12
Topic: T34 – Computing History
Skill: Build a multi-era computing comparison tool in CreatiCode
Description: Students create a CreatiCode project where users can compare any two computing eras side-by-side, using widgets for era selection and dynamically displaying data about speed, cost, size, and capabilities for each era.

Dependencies:
* T34.G8.04: Build an interactive CreatiCode exhibit about computing history
* T34.G8.10: Create an interactive timeline of computing history


ID: T34.G8.13
Topic: T34 – Computing History
Skill: Analyze the evolution of computing education
Description: Students research how computing education evolved from specialized university courses (1960s) through Logo and BASIC (1980s) to visual programming and AI-assisted learning (2020s), analyzing what made each approach more or less accessible.

Dependencies:
* T34.G7.07: Analyze the history of human-computer interaction
* T34.G8.05: Analyze how AI is changing the history of programming


ID: T34.G8.14
Topic: T34 – Computing History
Skill: Create an AI-narrated history presentation in CreatiCode
Description: Students build a CreatiCode project that uses ChatGPT blocks to generate dynamic narration about computing history events based on user selections, combined with text-to-speech to create an immersive audio-visual history experience.

Dependencies:
* T34.G7.10: Build a "talk to a pioneer" chatbot in CreatiCode
* T34.G8.10: Create an interactive timeline of computing history




