ID: T13.GK.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Spot a missing or wrong action in an animation
Description: Students watch a short picture story or animation and compare what happens to what was supposed to happen (e.g., the character should jump but doesn't, or moves the wrong direction). They simply point to or circle the moment something went wrong without explaining why or fixing it.



ID: T13.GK.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Retry after noticing something went wrong
Description: Students follow a simple set of picture steps for a task (e.g., stacking blocks, moving a character on a board), notice when the result is not what was intended, and try the steps again from the beginning. They experience the "try, check, retry" cycle without changing the steps themselves.

Dependencies:
* T13.GK.01: Spot a missing or wrong action




ID: T13.GK.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Fix a single wrong direction or action in steps
Description: Students "play computer" by acting out or watching a character follow a short list of picture steps to reach a fun goal (like a treasure or door). When the character ends up in the wrong place or does something silly, they identify which one movement is wrong (e.g., an arrow pointing left instead of right, or "sit down" too early) and swap it for a better step so the routine works.

Dependencies:
* T01.GK.03: Find the first and last pictures
* T13.GK.01: Spot a missing or wrong action


ID: T13.G1.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Identify which step causes a problem and explain why
Description: Students look at a set of picture-based steps that, when "played out" as a story, clearly go wrong (e.g., "jump before moving" when the intent is move-then-jump). They select or highlight the specific step that causes the problem AND explain in simple words why that step is wrong (e.g., "This step happens too early").

Dependencies:
* T01.GK.03: Find the first and last pictures


ID: T13.G1.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Fix a sequence error in steps
Description: Students reorder picture or word cards in a step list to fix a sequencing error that made a story or game behave strangely (for example, moving "say hello" so it happens after "walk to friend," or moving a "wait" picture to the correct position).

Dependencies:
* T01.GK.02: Put pictures in order for coming to class


ID: T13.G1.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Change a number to fix a repeated action
Description: Students modify a number in picture‑based instructions (e.g., change "jump 10 times" to "jump 3 times" so the movement matches a picture, or change a count of claps) to correct unexpected behavior in a routine.

Dependencies:
* T04.GK.02: Extend a repeating pattern by one tile


ID: T13.G1.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Demonstrate steps physically and identify the error
Description: Students act out a set of picture steps (e.g., pretend to follow a recipe, walk through a maze path) and identify where something goes wrong. They explain the error verbally or by pointing (e.g., "We forgot to open the paint before painting" or "I went left instead of right here").

Dependencies:
* T01.GK.01: Put pictures in order for getting ready for bed


ID: T13.G2.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Fix steps that use the wrong signal
Description: Students examine instructions where a character is supposed to act on a certain signal (e.g., clap, whistle, or card color) but the written or picture steps mention the wrong signal. They identify and fix the signal in the instructions so the behavior matches the story.

Dependencies:
* T01.G1.06: Fix a routine with one wrong step


ID: T13.G2.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Trace a set of steps and predict behavior
Description: Students "walk through" a simple set of instructions step by step, predicting what each step does and what the character or object will look like or where it will end up at the end. This mental tracing helps them spot logic errors before acting it out.

Dependencies:
* T01.G1.05: Find the missing step in an algorithm
* T03.G1.03: List steps for a simple classroom routine


ID: T13.G2.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Fix a repeated step that happens too many or too few times
Description: Students modify instructions where an action repeats the wrong number of times (e.g., clap 2 times instead of 5, or march too many steps). They change the number of repeats so the behavior matches a picture or description.

Dependencies:
* T04.G2.01: Identify the repeating unit in a longer pattern
* T01.G2.01: Find actions that repeat in everyday tasks


ID: T13.G2.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Add a simple check to see if steps worked
Description: Students add a small "check" card or picture (e.g., a thumbs‑up or scoreboard picture) at a key point in a set of steps to show that something important has happened (like reaching a goal or using all the cards). This helps them see what is going on inside a longer routine.

Dependencies:
* T03.G1.03: List steps for a simple classroom routine
* T01.G1.09: Match an algorithm to its goal


ID: T13.G3.00
Topic: T13 – Testing, Debugging & Error Handling
Skill: Recognize when a CreatiCode script has errors
Description: Students learn to identify common error indicators in CreatiCode before attempting to debug: (1) blocks that turn red or orange when clicked (indicating an error in that block), (2) scripts that don't run when the green flag is clicked (nothing happens), (3) sprites that freeze or stop responding during execution. They practice spotting these visual cues and understanding that they signal something needs to be fixed. This prepares them for actual debugging by teaching them to notice when something is wrong.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence


ID: T13.G3.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Test and trace simple block-based scripts
Description: Students perform two key debugging skills: (1) TRACE - Look at a simple 3-5 block script without running it and predict what each block will do in sequence (sprite's final position, appearance, or speech), then (2) TEST - Run the script in CreatiCode, observe the actual behavior, and compare it to their prediction. If behavior doesn't match expectation (e.g., "should move 50 steps right, then say Hello"), they identify which specific block produced unexpected results by checking one block at a time. This combines mental tracing with actual testing.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T13.G2.02: Trace a set of steps and predict behavior
* T13.G3.00: Recognize when a CreatiCode script has errors


ID: T13.G3.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Fix a wrong block in a sequence
Description: Students identify and replace a single incorrect block in a short script (e.g., "move 10 steps" should be "move 50 steps," or "turn right" should be "turn left") to make the program work correctly.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T13.G2.03: Fix a repeated step that happens too many or too few times


ID: T13.G3.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug a script with a missing block
Description: Students identify where a block is missing in a script (e.g., forgot to add "point in direction" before moving, or missing a "say" block) and add it in the correct position.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T13.G2.02: Trace a set of steps and predict behavior


ID: T13.G3.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Practice the debugging cycle: run, observe, change, test again
Description: Students practice the iterative debugging cycle: (1) run the program, (2) observe what went wrong (sprite moves wrong direction, says wrong message, etc.), (3) make ONE specific change to a block (change a number, swap a block, reorder blocks), and (4) test again. They repeat this cycle 2-3 times, experiencing iteration as normal rather than expecting perfection on first try. This teaches that debugging is a process, not a single action.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T13.G2.04: Add a simple check to see if steps worked


ID: T13.G3.05
Topic: T13 – Testing, Debugging & Error Handling
Skill: Identify and explain which block causes unexpected behavior
Description: Students run a script that produces wrong output and identify which specific block is causing the problem by mentally stepping through the code and comparing expected behavior to actual behavior at each step. They not only point to the problematic block but also explain WHY it's wrong (e.g., "This says 'turn right 90' but it should be 'turn left 90' to face the target"). This skill builds on T13.G3.01 by requiring explanation of the error, not just identification.

Dependencies:
* T13.G3.01: Test and trace simple block-based scripts


ID: T13.G4.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug a conditional inside a loop
Description: Students debug a simple program with a single conditional check inside a counted loop (e.g., repeat 10 times with one if statement inside). The bug might be a wrong condition value, a missing action inside the if-block, or incorrect block placement. This introduces the concept of debugging nested structures at the simplest level.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.01: Use a simple if in a script
* T13.G3.02: Fix a wrong block in a sequence


ID: T13.G4.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Identify and manually test edge cases
Description: Students learn what an "edge case" is: an unusual or extreme input that might cause problems (e.g., score is exactly 0, sprite is at the very edge of the stage at x=240 or y=180, countdown timer reaches 0). Given a program with a conditional, they brainstorm 2-3 edge cases (extreme values, boundary positions, zero/negative numbers) and manually test each one, recording whether the program handles it correctly or fails.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G3.01: Test a simple block-based script


ID: T13.G4.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Design an alternative approach and compare results
Description: Given a working program, students redesign it to accomplish the same task using a different approach (e.g., using a different loop structure, rearranging conditions, or using a wait instead of repeat). They test both versions with the same inputs, compare results, and verify both produce correct output.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.01: Use a simple if in a script
* T13.G3.04: Practice the debugging cycle: run, observe, change, test again


ID: T13.G4.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Identify and fix an infinite loop or program hang
Description: Students recognize that a `forever` or `repeat until` loop is stuck (never exits) and diagnose why (e.g., the condition never becomes true, or the update is missing). They fix the condition or add a stopping mechanism.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.01: Use a simple if in a script
* T13.G3.02: Fix a wrong block in a sequence


ID: T13.G4.05.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Create a simple test plan with documented test cases
Description: Students write a simple test plan using a template with three columns: (1) Input/Action, (2) Expected Result, (3) Pass/Fail (left blank). They document 3-5 different test cases before running the program (e.g., "Input: score = 10, Expected: sprite says 'Good job!'"). This introduces systematic testing by documenting expectations before testing, distinguishing it from exploratory trial-and-error.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T13.G3.01: Test a simple block-based script


ID: T13.G4.05.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Run tests and record results
Description: Students follow their test plan, run the program with each test case, and record whether each test passed (result matched expectation) or failed (result didn't match). They identify which cases need fixing.

Dependencies:
* T13.G4.05.01: Create a simple test plan with test cases


ID: T13.G4.06
Topic: T13 – Testing, Debugging & Error Handling
Skill: Compare two programs solving the same task
Description: Students examine two different programs that both accomplish the same goal but may have different structure, efficiency, or robustness. They decide which version would be easier to test, debug, and reuse (e.g., clearer structure, fewer special‑case bugs, helpful messages) and explain why.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T13.G4.03: Design an alternative approach and compare results


ID: T13.G4.07
Topic: T13 – Testing, Debugging & Error Handling
Skill: Record what went wrong and how you fixed it
Description: After finding and fixing a bug, students write a simple note or fill in a template describing: (1) what was wrong (the symptom they saw), and (2) what they changed to fix it (which block they modified, added, or removed). This introduces basic debugging documentation without requiring formal hypothesis-testing methodology.

Dependencies:
* T13.G3.04: Practice the debugging cycle: run, observe, change, test again


ID: T13.G4.08
Topic: T13 – Testing, Debugging & Error Handling
Skill: Distinguish between different types of bugs
Description: Students learn to categorize bugs into four types: (1) sequence errors (blocks in wrong order), (2) value errors (wrong numbers, text, or choices in blocks), (3) logic errors (wrong conditions, operators like > instead of <), and (4) missing blocks (forgot to add a necessary block). Given 4-5 broken programs, they identify which category each bug belongs to, explaining their reasoning before attempting fixes.

Dependencies:
* T06.G3.01: Build a green-flag script that runs a 3–5 block sequence
* T13.G3.02: Fix a wrong block in a sequence
* T13.G4.01: Debug a conditional inside a loop


ID: T13.G4.09
Topic: T13 – Testing, Debugging & Error Handling
Skill: Use debug print blocks to trace program execution
Description: Students add `print [message] in [console v]` or `print [message] in [alert v]` blocks at key points in their program to see which parts of code are running and in what order. They use simple messages like "loop started", "reached this point", or print variable values like "score is now [score]" to understand program flow. After finding the bug, they remove the debug blocks. This introduces systematic tracing using CreatiCode's built-in debug features.

Dependencies:
* T13.G3.04: Practice the debugging cycle: run, observe, change, test again
* T13.G4.07: Record what went wrong and how you fixed it


ID: T13.G5.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug programs using advanced tracing and logging
Description: Students build on basic debug print blocks to use more advanced debugging techniques: (1) `say [message]` blocks to show which part of code is running, (2) `say [variable]` blocks to display variable values, (3) variable monitors (check the box to display variable on stage), or (4) label widgets to show multiple values simultaneously. They systematically trace execution flow and variable changes to locate complex bugs (e.g., "loop only ran 3 times instead of 5" or "score variable never changed"). This extends the debug print technique with multiple output methods.

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G4.08: Distinguish between different types of bugs
* T13.G4.09: Use debug print blocks to trace program execution


ID: T13.G5.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Add input validation to handle invalid entries
Description: Students design a program that accepts user input and add conditional checks to reject or handle invalid entries gracefully (e.g., if a player enters a negative number when a positive is required, the program asks again or defaults safely). This builds on edge case awareness by actively preventing problems.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T13.G4.02: Identify and manually test edge cases


ID: T13.G5.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Create and follow a comprehensive test plan with multiple input types
Description: Students design a comprehensive test plan covering three categories of inputs: (1) normal/typical cases (expected use), (2) boundary cases (minimum, maximum, zero, edge of screen), and (3) invalid inputs (negative when positive expected, empty values). They create 8-10 test cases total across all three categories, run each systematically, record pass/fail results, and summarize which categories had the most failures.

Dependencies:
* T13.G4.05.02: Run tests and record results


ID: T13.G5.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Make a fragile program more robust with defensive improvements
Description: Students take a working but fragile program (one that handles only happy-path cases) and make it more robust by adding at least three improvements from this list: (1) add condition checks before risky operations (e.g., "if list length > 0" before accessing item 1), (2) handle boundary values (score = 0, stage edge at x=240), (3) add input validation (reject negative when positive required), (4) add descriptive error messages when problems occur, or (5) remove duplicate code that could cause inconsistent behavior. They document each improvement explaining WHAT was fragile and HOW the fix makes it more robust, then test with cases that previously would have failed.

Dependencies:
* T13.G4.01: Debug a conditional inside a loop
* T13.G4.06: Compare two programs solving the same task
* T13.G5.02: Add input validation to handle invalid entries


ID: T13.G5.05
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug complex two-level nested structures
Description: Students debug a program with complex two-level nesting: loops inside loops, conditionals with if-else branches inside loops, or multiple conditionals in sequence within a loop. They systematically identify which level (outer loop, inner structure, or specific condition) has the bug and fix it. This builds on simpler single-conditional-in-loop debugging from G4.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.01: Use a simple if in a script
* T13.G4.01: Debug a conditional inside a loop


ID: T13.G5.06
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug deeply nested structures (three+ levels)
Description: Students debug a program with three or more levels of nesting (e.g., a loop inside a loop with a conditional inside that, or nested conditionals inside nested loops). They trace through multiple levels systematically to identify which level is causing incorrect behavior and fix it. This is more complex than two-level nesting.

Dependencies:
* T07.G3.01: Use a counted repeat loop
* T08.G3.01: Use a simple if in a script
* T13.G5.05: Debug complex two-level nested structures


ID: T13.G5.07
Topic: T13 – Testing, Debugging & Error Handling
Skill: Read and interpret error indicators
Description: Students learn to identify when CreatiCode indicates a problem: a block that turns red/orange when clicked (indicating an error in that block), unexpected sprite behavior, or frozen scripts. They practice reading the symptoms, identifying which block or sequence is problematic, and using those clues to locate bugs. This introduces systematic observation of error signals before debugging.

Dependencies:
* T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
* T13.G4.07: Record what went wrong and how you fixed it
* T13.G5.01: Debug programs using advanced tracing and logging


ID: T13.G5.08
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug a program with limited changes allowed
Description: Students are given a broken program with a constraint: "Fix the bug by changing only numbers/values in blocks" or "Fix by reordering blocks, not adding or removing any." This develops precision in identifying exactly what's wrong and forces systematic thinking (can't just try random additions). They must identify the minimal change needed.

Dependencies:
* T13.G4.07: Record what went wrong and how you fixed it
* T13.G5.01: Debug programs using advanced tracing and logging


ID: T13.G5.09
Topic: T13 – Testing, Debugging & Error Handling
Skill: Use breakpoint blocks to stop execution at specific points
Description: Students insert `breakpoint` blocks at strategic locations in their program, then run it using the blue arrow (Debug Mode) instead of the green flag. When execution pauses at a breakpoint, they examine sprite positions, variable values (using monitors), and stage state to understand exactly what's happening at that moment. They step through the program section by section, moving the breakpoint block to different locations to isolate problems. This allows precise inspection of program state and is especially useful for debugging timing issues and complex loops.

Dependencies:
* T13.G5.01: Debug programs using advanced tracing and logging
* T13.G5.07: Read and interpret error indicators


ID: T13.G5.10
Topic: T13 – Testing, Debugging & Error Handling
Skill: Interpret console output and error messages
Description: Students learn to read and understand messages that appear in the CreatiCode console window, including: (1) debug print output showing program flow and variable values, (2) error messages indicating what went wrong (e.g., "cannot read property of undefined"), (3) warning messages about potential problems. They practice connecting console messages to specific blocks or code sections, using the information to locate and fix bugs. This skill bridges visual debugging and text-based error interpretation.

Dependencies:
* T13.G4.09: Use debug print blocks to trace program execution
* T13.G5.07: Read and interpret error indicators


ID: T13.G6.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Trace complex code with multiple variables
Description: Students step through a program with multiple variables and complex logic, tracking how each variable changes at each step. They use a table or mental model to predict the final state and verify correctness.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G5.01: Debug programs using advanced tracing and logging
* T13.G5.06: Debug deeply nested structures (three+ levels)


ID: T13.G6.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Use a systematic debugging process (hypothesis-driven)
Description: Students apply a 4-step debugging method: (1) observe and describe the symptom (what goes wrong and when), (2) form a hypothesis about which block or logic causes it (e.g., "I think the repeat count is too low"), (3) test the hypothesis by adding `say` blocks to check that value or temporarily changing the block, and (4) verify the fix by running all previous test cases. They document this process for 2-3 bugs, distinguishing it from random trial-and-error.

Dependencies:
* T08.G3.01: Use a simple if in a script
* T13.G5.01: Debug programs using advanced tracing and logging


ID: T13.G6.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Design systematic boundary tests using a matrix
Description: Students design a systematic boundary test matrix for a program with numeric inputs. For each input variable, they identify 5 test values: (1) minimum valid, (2) just below minimum (invalid), (3) typical middle value, (4) maximum valid, (5) just above maximum (invalid). They create a test matrix documenting expected vs. actual results for each value, ensuring comprehensive coverage of edge conditions and invalid inputs.

Dependencies:
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G5.02: Add input validation to handle invalid entries


ID: T13.G6.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Document known limitations and potential bugs
Description: Students examine their program and document cases or inputs it doesn't handle correctly, potential future bugs, or design limitations. This self-aware documentation reflects mature debugging thinking.

Dependencies:
* T13.G4.07: Record what went wrong and how you fixed it
* T13.G5.04: Make a fragile program more robust with defensive improvements


ID: T13.G6.05
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug a peer's program using systematic observation
Description: Students are given a classmate's broken program (without seeing the fix). They use systematic observation: (1) run the program and observe symptoms, (2) add `say` blocks or monitors to trace variable values, (3) form a hypothesis about the bug, (4) discuss their hypothesis with the author (without immediately revealing it), and (5) help guide the author to discover the fix themselves. This introduces collaborative debugging and explaining bugs to others.

Dependencies:
* T13.G5.01: Debug programs using advanced tracing and logging
* T13.G6.02: Use a systematic debugging process


ID: T13.G7.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Write comprehensive test cases for an algorithm
Description: Students analyze an algorithm (e.g., finding maximum in a list, calculating average, checking if number is prime, or searching for an item) and write a test suite of 10-15 test cases covering: (1) normal cases (typical inputs), (2) edge cases (empty list, single item, all items equal, very large numbers), (3) boundary values (minimum, maximum valid inputs), and (4) invalid inputs. They run all tests, record pass/fail for each, and calculate coverage percentage (how many cases passed).

Dependencies:
* T08.G5.01: Design multi-branch decision logic
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G6.03: Design systematic boundary tests


ID: T13.G7.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug logic errors in complex programs
Description: Students identify and correct logic errors in a program (bugs that don't crash the program but produce wrong results, such as off-by-one errors, incorrect operators, or wrong variable assignments). These are harder to spot than syntax errors.

Dependencies:
* T08.G5.01: Design multi-branch decision logic
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G6.01: Trace complex code with multiple variables


ID: T13.G7.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Simplify complex code to make it easier to understand and test
Description: Students identify a complex section of code (long script with 20+ blocks, deep nesting, or repeated blocks) and simplify it using at least two techniques: (1) break large scripts into smaller custom blocks with clear names, (2) replace repeated code blocks with a loop or custom block, (3) rename variables to be more descriptive (e.g., "playerScore" instead of "s"), or (4) add comment blocks to explain what each section does. They verify the refactored version produces identical results using test cases from earlier work. This makes code easier to debug and maintain.

Dependencies:
* T08.G5.01: Design multi-branch decision logic
* T09.G3.01.04: Display variable value on stage using the variable monitor
* T13.G6.04: Document known limitations and potential bugs


ID: T13.G7.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Compare reliability of different program designs
Description: Students examine two or more designs for the same task, evaluate their handling of edge cases and error conditions, and argue which is more reliable and why. This builds on earlier comparison skills by focusing specifically on reliability and error-handling quality.

Dependencies:
* T08.G5.01: Design multi-branch decision logic
* T13.G6.02: Use a systematic debugging process
* T13.G6.04: Document known limitations and potential bugs


ID: T13.G7.05
Topic: T13 – Testing, Debugging & Error Handling
Skill: Anticipate runtime errors and add defensive checks
Description: Students identify 3-5 operations in their program that could fail at runtime: (1) division (check if divisor ≠ 0 before dividing), (2) list access (check if list length > index before accessing), (3) user input (check if answer is a valid number before using), (4) position boundaries (check if x/y within stage bounds), or (5) countdown timers (check if timer > 0 before decrementing). They add defensive `if` checks before each risky operation, providing fallback values (e.g., set score to 0) or user-friendly `say` messages when problems occur.

Dependencies:
* T08.G5.01: Design multi-branch decision logic
* T13.G5.02: Add input validation to handle invalid entries
* T13.G6.03: Design systematic boundary tests


ID: T13.G7.06
Topic: T13 – Testing, Debugging & Error Handling
Skill: Test programs in different contexts and identify context-dependent bugs
Description: Students test a program under different conditions: different sprite starting positions, different backdrop sizes, different variable initial values, or different player counts in multiplayer mode. They identify bugs that only appear in certain contexts (e.g., "collision detection fails when sprite starts at x < 0" or "multiplayer sync breaks with 3+ players"). They document context-dependent bugs and explain why the bug doesn't always appear.

Dependencies:
* T13.G6.02: Use a systematic debugging process
* T13.G6.03: Design systematic boundary tests


ID: T13.G8.01
Topic: T13 – Testing, Debugging & Error Handling
Skill: Design and execute a rigorous test suite
Description: Students design a test suite that explicitly covers all code paths and critical scenarios, run the tests systematically, and document coverage (e.g., how many branches were tested, how many edge cases). They track which tests pass and fail.

Dependencies:
* T09.G6.01: Model real-world quantities using variables and formulas
* T13.G6.01: Trace complex code with multiple variables
* T13.G7.01: Write comprehensive test cases for an algorithm


ID: T13.G8.02
Topic: T13 – Testing, Debugging & Error Handling
Skill: Debug for correctness against specifications
Description: Given a formal (or semi-formal) specification of a program's expected behavior, students test the implementation against it, identify discrepancies, and fix bugs until the program matches the specification.

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T08.G6.01: Use conditionals to control simulation steps
* T13.G6.01: Trace complex code with multiple variables


ID: T13.G8.03
Topic: T13 – Testing, Debugging & Error Handling
Skill: Handle errors gracefully with defensive programming patterns
Description: Students add comprehensive error-handling logic using conditional checks, fallback behaviors, and error reporting to make a program robust. They anticipate multiple failure points (invalid input, missing data, edge cases), add defensive if-checks before risky operations, provide fallback values or alternative paths, and display user-friendly error messages. This creates a complete error-handling strategy that prevents crashes and ensures graceful degradation.

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T08.G6.01: Use conditionals to control simulation steps
* T13.G7.05: Anticipate runtime errors and add defensive checks


ID: T13.G8.04
Topic: T13 – Testing, Debugging & Error Handling
Skill: Evaluate code correctness, edge case coverage, and assumptions
Description: Students critically review code (their own or AI-generated) using a 4-question framework: (1) Does it correctly solve the stated problem for all normal inputs? (2) What edge cases does it miss (empty data, zero values, maximum limits, negative numbers)? (3) What assumptions does it make (e.g., "assumes user always enters a number," "assumes list always has items")? (4) What are potential failure modes (where could it crash or give wrong results)? They write a review document answering all four questions with specific examples, then propose 2-3 improvements to make the code more robust.

Dependencies:
* T06.G6.01: Trace event execution paths in a multi‑event program
* T09.G6.01: Model real-world quantities using variables and formulas
* T13.G7.02: Debug logic errors in complex programs


ID: T13.G8.05
Topic: T13 – Testing, Debugging & Error Handling
Skill: Trace error propagation through custom blocks
Description: Students debug a program with custom blocks (procedures) where an error in a deeply nested custom block causes incorrect behavior in the main script. They trace the call chain: main script calls custom block A, which calls custom block B, which has the bug. They identify which block in the chain contains the error and explain how the error propagated up to cause visible symptoms. This introduces the concept of call stacks and error propagation.

Dependencies:
* T11.G5.01: Create a custom block with parameters
* T13.G6.01: Trace complex code with multiple variables
* T13.G7.02: Debug logic errors in complex programs


