# T35 – Impacts & Ethics: K–8 Skill List (Draft v2)

Topic reference: `T35 Impacts & Ethics` in `domains_topics_overview.md`
Domain: Computing & Society (D5) · CSTA focus: CAS‑ET (Emerging Technologies) with links to CAS‑HC, CAS‑CE

Each skill below has:

- a **stable ID** (`T35.G<grade>.<nn>`),
- an **IXL-style short name**,
- a **description** (what understanding/behavior it targets),
- a **challenge format** (the typical problem type to assess it).

Where relevant, a primary **CSTA code** is noted.

**Role and scope in v3:** T35 helps students reason about the benefits, harms, and responsibilities tied to computing. K–2 concentrate on healthy habits and simple cause/effect (“helpful vs harmful”). Grades 3–5 examine real scenarios (screen balance, online kindness, digital footprints). Grades 6–8 analyze ethical frameworks (fairness, privacy, inclusion), debate emerging tech (AI, biometrics), and produce policies that tie into T21–T24 AI blocks, T23 perception hardware, and T32 cybersecurity. The topic scaffolds from personal decisions to community-level impacts.

---

## Grade K (PreK–K)

### T35.GK.01 – Identify a helpful use of technology

- **Short name:** How does tech help?
- **Description:** Students pick pictures showing technology helping someone (video call grandma, drawing app for homework).
- **Challenge format:** Picture matching. Auto-grading checks selections.
- **CSTA:** EK‑CAS‑ET‑02.

### T35.GK.02 – Recognize signs of too much screen time

- **Short name:** How do you feel after playing all day?
- **Description:** Learners connect long screen sessions with feeling tired or missing other activities.
- **Challenge format:** Scenario question. Auto-grading checks responses referencing rest/balance.
- **CSTA:** EK‑CAS‑ET‑02.

### T35.GK.03 – Practice device sharing etiquette

- **Short name:** Take turns with tech
- **Description:** Students role-play sharing tablets or taking turns, reinforcing respectful use.
- **Challenge format:** Concept reflection. Auto-grading confirms learners mention sharing/asking politely.
- **CSTA:** EK‑CAS‑ET‑02.

---

## Grade 1

### T35.G1.01 – Sort good vs not-so-good choices

- **Short name:** Tech choices chart
- **Description:** Learners categorize behaviors (pausing game to eat vs ignoring responsibilities) into “good for me”/“not good for me.”
- **Challenge format:** Sorting cards. Auto-grading checks placement.
- **CSTA:** E1‑CAS‑ET‑02.

### T35.G1.02 – Describe how technology makes people feel

- **Short name:** Happy or frustrated?
- **Description:** Students discuss how apps/games can make them excited, calm, or upset, introducing emotional impacts.
- **Challenge format:** Picture prompt + sentence. Auto-grading ensures feelings/reasons are mentioned.
- **CSTA:** E1‑CAS‑ET‑02.

### T35.G1.03 – Recognize that people make technology choices

- **Short name:** Someone designed this button
- **Description:** Learners note that each app/game is made by people who choose characters, colors, and rules.
- **Challenge format:** Concept Q&A. Auto-grading checks mention of creators.
- **CSTA:** E1‑CAS‑ET‑02.

---

## Grade 2

### T35.G2.01 – Compare benefits and harms of a tech tool

- **Short name:** Two-column pros/cons
- **Description:** Students list positives and negatives for tools like video sharing or messaging apps.
- **Challenge format:** T-chart fill-in. Auto-grading checks both columns.
- **CSTA:** E2‑CAS‑ET‑02.

### T35.G2.02 – Plan balanced tech schedules

- **Short name:** Mix screen and non-screen time
- **Description:** Learners design a simple daily routine that includes device time, outdoor play, meals, and sleep.
- **Challenge format:** Timeline creation. Auto-grading checks inclusion of multiple activity types.
- **CSTA:** E2‑CAS‑ET‑02.

### T35.G2.03 – Practice online kindness scripts

- **Short name:** What do you say when someone is mean online?
- **Description:** Students role-play responses (ignore, block, tell adult) and positive messages.
- **Challenge format:** Scenario responses. Auto-grading ensures replies include respectful language and reporting.
- **CSTA:** E2‑CAS‑ET‑02.

---

## Grade 3

### T35.G3.01 – Evaluate digital footprints

- **Short name:** What does this post say about you?
- **Description:** Learners analyze sample posts (photos, comments) to determine what others might learn and whether it’s safe to share.
- **Challenge format:** Concept Q&A. Auto-grading checks identification of PII and judgement statements.
- **CSTA:** E3‑CAS‑ET‑02, T32 dependency.

### T35.G3.02 – Discuss how algorithms influence what we see

- **Short name:** Why does this video keep showing up?
- **Description:** Students learn that apps recommend content based on prior activity and reflect on how this shapes their time.
- **Challenge format:** Short reflection referencing cause/effect. Auto-grading ensures mention of recommendations.
- **CSTA:** E3‑CAS‑ET‑02.

### T35.G3.03 – Develop class guidelines for respectful communication

- **Short name:** Create a chat code of conduct
- **Description:** Learners write simple rules (no spam, be kind, no PII) for classroom collaboration tools.
- **Challenge format:** Group document summary. Rubric checks inclusion of kindness, privacy, consequences.
- **CSTA:** E3‑CAS‑ET‑02.

---

## Grade 4

### T35.G4.01 – Analyze case studies of tech helping/harming communities

- **Short name:** Tech impact case cards
- **Description:** Students read short case studies (drones delivering meds vs drones invading privacy) and discuss tradeoffs.
- **Challenge format:** Case discussion worksheet. Auto-grading ensures mention of both benefits and harms.
- **CSTA:** E4‑CAS‑ET‑02.

### T35.G4.02 – Understand advertising/persuasion online

- **Short name:** Spot sponsored content
- **Description:** Learners identify ads, influencer promotions, and persuasive design patterns in sample apps.
- **Challenge format:** Screenshot annotation. Auto-grading checks labels and explanation.
- **CSTA:** E4‑CAS‑ET‑02.

### T35.G4.03 – Reflect on accessibility/inclusion in games

- **Short name:** Who can/can’t play this game?
- **Description:** Students review a game for accessibility (color contrast, controls) and propose improvements.
- **Challenge format:** Review sheet. Auto-grading rubric checks mention of barriers + solutions.
- **CSTA:** E4‑CAS‑ET‑02, CAS‑HC.

---

## Grade 5

### T35.G5.01 – Examine global impacts of technology

- **Short name:** Technology in different communities
- **Description:** Learners study how a technology (mobile banking, telemedicine) affects people in two regions differently and why.
- **Challenge format:** Comparative chart + paragraph. Auto-grading checks mention of benefits/constraints per region.
- **CSTA:** E5‑CAS‑ET‑02, CAS‑HC.

### T35.G5.02 – Debate digital well-being scenarios

- **Short name:** Should we allow phones at lunch?
- **Description:** Students debate policy scenarios (device-free times, notifications) referencing evidence on focus and health.
- **Challenge format:** Structured debate notes. Rubric checks claims, evidence, and respectful counterpoints.
- **CSTA:** E5‑CAS‑ET‑02.

### T35.G5.03 – Analyze AI's differential impacts on workers and communities

- **Short name:** AI job impacts across different communities
- **Description:** Learners research how AI affects different communities unequally: which jobs are most at risk, how impacts vary by education/income level, geographic disparities in AI adoption, and how T21-T24 AI tools might worsen or improve equity. They propose reskilling and policy solutions with social justice focus.
- **Challenge format:** Equity-focused AI impact analysis. Auto-grading requires demographic analysis, disparity identification, and community-centered solutions connecting to T21-T24.
- **CSTA:** E5‑CAS‑ET‑02.
- **AI4K12:** E2 Societal Impacts; D2 Bias and Fairness.

---

## Grade 6

### T35.G6.01 – Apply ethics lenses (beneficence, fairness, autonomy)

- **Short name:** Use an ethics checklist for apps
- **Description:** Students evaluate a CreatiCode project using simple ethics lenses and document findings.
- **Challenge format:** Checklist + reflection. Auto-grading checks each lens includes evidence.
- **CSTA:** MS‑CAS‑ET‑05.

### T35.G6.02 – Analyze data privacy tradeoffs

- **Short name:** What data does this app collect and why?
- **Description:** Learners read mock privacy statements and decide whether the data collection is justified for the feature.
- **Challenge format:** Decision chart. Auto-grading checks references to stated purposes.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G6.03 – Develop comprehensive AI ethics guidelines for T21-T24 applications

- **Short name:** Complete AI ethics framework for class projects
- **Description:** Students create comprehensive ethical guidelines covering all T21-T24 AI applications: T21 image generation (bias, consent, cultural representation), T22 chatbots (privacy, misinformation, accessibility), T23 perception (consent, surveillance concerns, equity), and T24 XO assistance (academic integrity, citation, dependency). They connect guidelines to social justice principles and equity outcomes.
- **Challenge format:** Multi-application ethics framework. Rubric evaluates comprehensive coverage of all AI applications, social justice integration, and practical implementation guidance.
- **CSTA:** MS‑CAS‑ET‑06.
- **AI4K12:** D1 Ethical Design; D2 Bias and Fairness; E2 Societal Impacts.

### T35.G6.04 – Examine digital divide data

- **Short name:** Who still lacks access?
- **Description:** Learners interpret charts (broadband availability, device ownership) and propose community actions.
- **Challenge format:** Data analysis + action plan. Auto-grading ensures evidence is cited.
- **CSTA:** MS‑CAS‑HC‑03.

---

## Grade 7

### T35.G7.01 – Conduct comprehensive bias audits across T21-T24 AI features

- **Short name:** Systematic AI fairness testing across applications
- **Description:** Students systematically audit T21 image generation (representation across demographics), T22 chatbots (response quality by dialect/topic), T23 perception (accuracy by skin tone/lighting), and T24 XO assistance (help quality by English proficiency). They measure disparities, analyze root causes, and propose both technical and policy solutions.
- **Challenge format:** Multi-application bias audit. Auto-grading checks systematic testing across T21-T24, quantitative disparity measurement, and comprehensive mitigation plans.
- **CSTA:** MS‑CAS‑ET‑05, DAA‑DI.
- **AI4K12:** D2 Bias and Fairness; E2 Societal Impacts.

### T35.G7.02 – Explore unintended consequences of new tech

- **Short name:** Side effects storyboard
- **Description:** Learners storyboard a technology (delivery drones, facial recognition) showing both intended use and unforeseen impact, then propose mitigations.
- **Challenge format:** Storyboard. Rubric checks for multiple perspectives and solutions.
- **CSTA:** MS‑CAS‑ET‑05.

### T35.G7.03 – Evaluate transparency vs security tensions

- **Short name:** Should we open-source this tool?
- **Description:** Students weigh openness (auditability) against misuse risks for a hypothetical AI tool and justify a recommendation.
- **Challenge format:** Position paper referencing pros/cons. Auto-grading ensures arguments cite concrete risks/benefits.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G7.04 – Analyze societal impacts of AI perception technologies (Pairing with T23)

- **Short name:** AI surveillance: community safety vs privacy
- **Description:** Following T23 perception projects, students analyze real-world case studies of AI surveillance (facial recognition in schools, emotion detection at work, gesture tracking in public). They debate tradeoffs between security and privacy, examine disproportionate impacts on marginalized communities, and propose ethical guidelines.
- **Challenge format:** Case study debate with equity focus. Rubric checks stakeholder analysis, community impact assessment, and ethical framework application.
- **CSTA:** MS‑CAS‑ET‑05.
- **AI4K12:** E2 Societal Impacts; D2 Bias and Fairness.

### T35.G7.05 – Debate ethical implications of AI media generation (Pairing with T21)

- **Short name:** AI-generated content and creative professions
- **Description:** Following T21 AI media projects, students hold structured debates on AI's impact on artists, photographers, and designers. They examine issues of copyright, style imitation, job displacement, cultural representation in training data, and propose frameworks for ethical AI media use.
- **Challenge format:** Structured debate + policy proposal. Rubric checks multiple perspective inclusion, equity analysis, and actionable recommendations.
- **CSTA:** MS‑CAS‑ET‑05.
- **AI4K12:** E2 Societal Impacts; D1 Ethical Design.

### T35.G7.06 – Facilitate community discussions on AI-powered tech policy

- **Short name:** Host AI ethics town halls
- **Description:** Learners prepare questions about AI policy (chatbot use in schools, AI hiring tools, automated content moderation), gather diverse stakeholder input, and summarize consensus on local AI governance needs, connecting to T21-T24 applications.
- **Challenge format:** AI-focused facilitation plan + summary. Rubric checks stakeholder inclusion, AI-specific policy understanding, and equity-centered outcomes.
- **CSTA:** MS‑CAS‑HC‑03.
- **AI4K12:** A1 Human-AI Collaboration; E2 Societal Impacts.

---

## Grade 8

### T35.G8.01 – Apply ethical frameworks to real proposals

- **Short name:** Use consequentialist vs deontological reasoning
- **Description:** Students evaluate a computing project (predictive policing, emotion AI) through multiple ethical lenses and compare conclusions.
- **Challenge format:** Comparative essay. Rubric checks lens definitions and application.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G8.01 – Analyze AI chatbots' impact on information literacy (Pairing with T22)

- **Short name:** AI chatbots and the future of learning
- **Description:** Following T22 chatbot projects, students analyze how AI-generated answers affect research habits, critical thinking, misinformation spread, and educational equity. They examine differential impacts on students with varying digital literacy levels and propose guidelines for responsible chatbot use in academic settings.
- **Challenge format:** Impact analysis + policy recommendations. Rubric checks equity analysis, evidence synthesis, and practical guidelines connecting to T22 experiences.
- **CSTA:** MS‑CAS‑ET‑06.
- **AI4K12:** E2 Societal Impacts; A1 Human-AI Collaboration.

### T35.G8.02 – Draft equity-focused policy briefs for AI in education

- **Short name:** AI policy with social justice lens
- **Description:** Learners synthesize evidence and stakeholder input into policy briefs that center equity in AI use for schools. They address differential access to T21-T24 tools, bias in AI outputs, privacy protection for vulnerable students, and culturally responsive AI implementation.
- **Challenge format:** Equity-centered policy document. Rubric evaluates social justice framing, community voice inclusion, and systemic inequality analysis.
- **CSTA:** MS‑CAS‑ET‑06, CAS‑HC‑02.
- **AI4K12:** D2 Bias and Fairness; E2 Societal Impacts.

### T35.G8.03 – Design impact assessments for CreatiCode projects

- **Short name:** Pre-launch impact checklist
- **Description:** Students create rubrics assessing accessibility, privacy, wellbeing, and cultural sensitivity before publishing games/apps.
- **Challenge format:** Checklist + sample application. Auto-grading checks categories and evidence fields.
- **CSTA:** MS‑PRO‑PM‑03, CAS‑ET.

### T35.G8.04 – Lead peer workshops on responsible tech use

- **Short name:** Teach younger students about digital wellbeing
- **Description:** Learners develop workshops/demos for younger grades on topics like screen balance, online kindness, or AI use.
- **Challenge format:** Lesson plan + reflection. Rubric checks objectives, activities, and adjustments based on feedback.
- **CSTA:** MS‑CAS‑CE‑08, CAS‑ET‑06.

---
