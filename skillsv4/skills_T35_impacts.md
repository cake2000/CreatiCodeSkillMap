# T35 – Impacts & Ethics: K–8 Skill List (Draft v2)

Topic reference: `T35 Impacts & Ethics` in `domains_topics_overview.md`
Domain: Computing & Society (D5) · CSTA focus: CAS‑ET (Emerging Technologies) with links to CAS‑HC, CAS‑CE

Each skill below has:

- a **stable ID** (`T35.G<grade>.<nn>`),
- an **IXL-style short name**,
- a **description** (what understanding/behavior it targets),
- a **challenge format** (the typical problem type to assess it).

Where relevant, a primary **CSTA code** is noted.

**Role and scope in v3:** T35 helps students reason about the benefits, harms, and responsibilities tied to computing. K–2 concentrate on healthy habits and simple cause/effect (“helpful vs harmful”). Grades 3–5 examine real scenarios (screen balance, online kindness, digital footprints). Grades 6–8 analyze ethical frameworks (fairness, privacy, inclusion), debate emerging tech (AI, biometrics), and produce policies that tie into T21–T24 AI blocks, T23 perception hardware, and T32 cybersecurity. The topic scaffolds from personal decisions to community-level impacts.

---

## Grade K (PreK–K)

### T35.GK.01 – Identify a helpful use of technology

- **Short name:** How does tech help?
- **Description:** Students pick pictures showing technology helping someone (video call grandma, drawing app for homework).
- **Challenge format:** Picture matching. Auto-grading checks selections.
- **CSTA:** EK‑CAS‑ET‑02.

### T35.GK.02 – Recognize signs of too much screen time

_Dependency:_
  * T01.GK.01: Put pictures in order for getting ready for bed


- **Short name:** How do you feel after playing all day?
- **Description:** Learners connect long screen sessions with feeling tired or missing other activities.
- **Challenge format:** Scenario question. Auto-grading checks responses referencing rest/balance.
- **CSTA:** EK‑CAS‑ET‑02.

### T35.GK.03 – Practice device sharing etiquette

_Dependency:_
  * T01.GK.01: Put pictures in order for getting ready for bed


- **Short name:** Take turns with tech
- **Description:** Students sort picture cards showing sharing behaviors (waiting your turn, asking nicely, grabbing) into "kind" and "not kind" categories to learn respectful device use.
- **Challenge format:** Picture sorting. Auto-grading checks correct categorization of behaviors.
- **CSTA:** EK‑CAS‑ET‑02.

---

## Grade 1

### T35.G1.01 – Sort good vs not-so-good choices

_Dependency:_
  * T01.GK.01: Put pictures in order for getting ready for bed


- **Short name:** Tech choices chart
- **Description:** Learners categorize behaviors (pausing game to eat vs ignoring responsibilities) into “good for me”/“not good for me.”
- **Challenge format:** Sorting cards. Auto-grading checks placement.
- **CSTA:** E1‑CAS‑ET‑02.

### T35.G1.02 – Match feelings to technology experiences

_Dependency:_
  * T01.GK.01: Put pictures in order for getting ready for bed


- **Short name:** Happy or frustrated?
- **Description:** Students match pictures of emotions (happy, sad, frustrated, excited) to technology scenarios (winning a game, losing progress, video calling family, waiting for slow loading) to understand emotional impacts of tech use.
- **Challenge format:** Picture matching. Auto-grading checks correct emotion-to-scenario matches.
- **CSTA:** E1‑CAS‑ET‑02.

### T35.G1.03 – Recognize that people make technology choices

_Dependency:_
  * T01.GK.01: Put pictures in order for getting ready for bed


- **Short name:** Someone designed this button
- **Description:** Students look at app screenshots and identify choices made by creators (characters, colors, sounds) by circling elements and matching them to "someone chose this" labels.
- **Challenge format:** Picture annotation. Auto-grading checks correct identification of design choices.
- **CSTA:** E1‑CAS‑ET‑02.

---

## Grade 2

### T35.G2.01 – Compare benefits and harms of a tech tool

_Dependency:_
  * T01.G1.07: Decide if two algorithms finish with the same result


- **Short name:** Two-column pros/cons
- **Description:** Students list positives and negatives for tools like video sharing or messaging apps.
- **Challenge format:** T-chart fill-in. Auto-grading checks both columns.
- **CSTA:** E2‑CAS‑ET‑02.

### T35.G2.02 – Plan balanced tech schedules

_Dependency:_
  * T01.G1.01: Put pictures in order to plant a seed
  * T03.G1.03: List steps for a simple classroom routine


- **Short name:** Mix screen and non-screen time
- **Description:** Learners design a simple daily routine that includes device time, outdoor play, meals, and sleep.
- **Challenge format:** Timeline creation. Auto-grading checks inclusion of multiple activity types.
- **CSTA:** E2‑CAS‑ET‑02.

### T35.G2.03 – Practice online kindness scripts

_Dependency:_
  * T01.G1.01: Put pictures in order to plant a seed


- **Short name:** What do you say when someone is mean online?
- **Description:** Students role-play responses (ignore, block, tell adult) and positive messages.
- **Challenge format:** Scenario responses. Auto-grading ensures replies include respectful language and reporting.
- **CSTA:** E2‑CAS‑ET‑02.

---

## Grade 3

### T35.G3.01 – Evaluate digital footprints

_Dependency:_
  * T35.G2.01: Compare benefits and harms of a tech tool
  * T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
  * T07.G3.01: Use a counted repeat loop


- **Short name:** What does this post say about you?
- **Description:** Learners analyze sample posts (photos, comments) to determine what others might learn and whether it’s safe to share.
- **Challenge format:** Concept Q&A. Auto-grading checks identification of PII and judgement statements.
- **CSTA:** E3‑CAS‑ET‑02, T32 dependency.

### T35.G3.02 – Discuss how algorithms influence what we see

_Dependency:_
  * T35.G3.01: Evaluate digital footprints
  * T08.G3.01: Use a simple if in a script
  * T09.G3.01: Create and use a numeric variable for score or count


- **Short name:** Why does this video keep showing up?
- **Description:** Students learn that apps recommend content based on prior activity and reflect on how this shapes their time.
- **Challenge format:** Short reflection referencing cause/effect. Auto-grading ensures mention of recommendations.
- **CSTA:** E3‑CAS‑ET‑02.

### T35.G3.03 – Develop class guidelines for respectful communication

_Dependency:_
  * T35.G3.02: Discuss how algorithms influence what we see
  * T08.G3.01: Use a simple if in a script
  * T09.G3.01: Create and use a numeric variable for score or count


- **Short name:** Create a chat code of conduct
- **Description:** Learners write simple rules (no spam, be kind, no PII) for classroom collaboration tools.
- **Challenge format:** Group document summary. Rubric checks inclusion of kindness, privacy, consequences.
- **CSTA:** E3‑CAS‑ET‑02.

---

## Grade 4

### T35.G4.01 – Analyze case studies of tech helping/harming communities

_Dependency:_
  * T35.G3.01: Evaluate digital footprints


- **Short name:** Tech impact case cards
- **Description:** Students read short case studies (drones delivering meds vs drones invading privacy) and discuss tradeoffs.
- **Challenge format:** Case discussion worksheet. Auto-grading ensures mention of both benefits and harms.
- **CSTA:** E4‑CAS‑ET‑02.

### T35.G4.02 – Understand advertising/persuasion online

_Dependency:_
  * T04.G2.01: Identify the repeating unit in a longer pattern
  * T35.G3.02: Discuss how algorithms influence what we see


- **Short name:** Spot sponsored content
- **Description:** Learners identify ads, influencer promotions, and persuasive design patterns in sample apps.
- **Challenge format:** Screenshot annotation. Auto-grading checks labels and explanation.
- **CSTA:** E4‑CAS‑ET‑02.

### T35.G4.03 – Reflect on accessibility/inclusion in games

_Dependency:_
  * T35.G3.03: Develop class guidelines for respectful communication


- **Short name:** Who can/can't play this game?
- **Description:** Students review a game for accessibility (color contrast, controls) and propose improvements.
- **Challenge format:** Review sheet. Auto-grading rubric checks mention of barriers + solutions.
- **CSTA:** E4‑CAS‑ET‑02, CAS‑HC.

---

## Grade 5

### T35.G5.01 – Examine global impacts of technology

_Dependency:_
  * T35.G4.01: Analyze case studies of tech helping/harming communities


- **Short name:** Technology in different communities
- **Description:** Learners study how a technology (mobile banking, telemedicine) affects people in two regions differently and why.
- **Challenge format:** Comparative chart + paragraph. Auto-grading checks mention of benefits/constraints per region.
- **CSTA:** E5‑CAS‑ET‑02, CAS‑HC.

### T35.G5.02 – Debate digital well-being scenarios

_Dependency:_
  * T35.G4.01: Analyze case studies of tech helping/harming communities
  * T35.G4.03: Reflect on accessibility/inclusion in games


- **Short name:** Should we allow phones at lunch?
- **Description:** Students debate policy scenarios (device-free times, notifications) referencing evidence on focus and health.
- **Challenge format:** Structured debate notes. Rubric checks claims, evidence, and respectful counterpoints.
- **CSTA:** E5‑CAS‑ET‑02.

### T35.G5.03 – Analyze AI's differential impacts on workers and communities

_Dependency:_
  * T04.G2.01: Identify the repeating unit in a longer pattern
  * T35.G4.01: Analyze case studies of tech helping/harming communities
  * T35.G4.02: Understand advertising/persuasion online


- **Short name:** AI job impacts across different communities
- **Description:** Learners research how AI affects different communities unequally: which jobs are most at risk, how impacts vary by education/income level, geographic disparities in AI adoption, and how T21-T24 AI tools might worsen or improve equity. They propose reskilling and policy solutions with social justice focus.
- **Challenge format:** Equity-focused AI impact analysis. Auto-grading requires demographic analysis, disparity identification, and community-centered solutions connecting to T21-T24.
- **CSTA:** E5‑CAS‑ET‑02.
- **AI4K12:** E2 Societal Impacts; D2 Bias and Fairness.

---

## Grade 6

### T35.G6.01 – Apply ethics lenses (beneficence, fairness, autonomy)

_Dependency:_
  * T06.G3.01: Build a green‑flag script that runs a 3–5 block sequence
  * T09.G3.01: Create and use a numeric variable for score or count
  * T35.G5.01: Examine global impacts of technology
  * T35.G4.01: Analyze case studies of tech helping/harming communities


- **Short name:** Use an ethics checklist for apps
- **Description:** Students evaluate a CreatiCode project using simple ethics lenses and document findings.
- **Challenge format:** Checklist + reflection. Auto-grading checks each lens includes evidence.
- **CSTA:** MS‑CAS‑ET‑05.

### T35.G6.02 – Analyze data privacy tradeoffs

_Dependency:_
  * T35.G5.01: Examine global impacts of technology
  * T35.G4.02: Understand advertising/persuasion online


- **Short name:** What data does this app collect and why?
- **Description:** Learners read mock privacy statements and decide whether the data collection is justified for the feature.
- **Challenge format:** Decision chart. Auto-grading checks references to stated purposes.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G6.03 – Develop ethics guidelines for AI content generation (T21-T22)

_Dependency:_
  * T35.G5.03: Analyze AI's differential impacts on workers and communities
  * T35.G4.03: Reflect on accessibility/inclusion in games


- **Short name:** AI content generation ethics
- **Description:** Students create ethical guidelines for AI image generation (T21) addressing bias in outputs, consent for training data, and cultural representation, and for AI chatbots (T22) addressing privacy, misinformation risks, and accessibility concerns.
- **Challenge format:** Ethics guideline document for generative AI. Rubric evaluates coverage of bias, consent, and misinformation issues.
- **CSTA:** MS‑CAS‑ET‑06.
- **AI4K12:** D1 Ethical Design; D2 Bias and Fairness.

### T35.G6.03.01 – Develop ethics guidelines for AI perception and assistance (T23-T24)

_Dependency:_
  * T35.G6.03: Develop ethics guidelines for AI content generation (T21-T22)
  * T35.G5.03: Analyze AI's differential impacts on workers and communities


- **Short name:** AI perception/assistance ethics
- **Description:** Students create ethical guidelines for AI perception tools (T23) addressing consent, surveillance concerns, and equity in recognition accuracy, and for AI coding assistants (T24) addressing academic integrity, proper citation, and avoiding over-dependency.
- **Challenge format:** Ethics guideline document for perception/assistance AI. Rubric evaluates coverage of surveillance, consent, and academic integrity issues.
- **CSTA:** MS‑CAS‑ET‑06.
- **AI4K12:** D1 Ethical Design; E2 Societal Impacts.

### T35.G6.04 – Examine digital divide data

_Dependency:_
  * T35.G5.01: Examine global impacts of technology
  * T35.G4.01: Analyze case studies of tech helping/harming communities


- **Short name:** Who still lacks access?
- **Description:** Learners interpret charts (broadband availability, device ownership) and propose community actions.
- **Challenge format:** Data analysis + action plan. Auto-grading ensures evidence is cited.
- **CSTA:** MS‑CAS‑HC‑03.

---

## Grade 7

### T35.G7.01 – Conduct bias audits for AI content generation (T21-T22)

_Dependency:_
  * T35.G6.03: Develop ethics guidelines for AI content generation (T21-T22)
  * T35.G5.03: Analyze AI's differential impacts on workers and communities


- **Short name:** AI content generation fairness testing
- **Description:** Students systematically audit T21 image generation for representation across demographics and T22 chatbots for response quality by dialect/topic. They measure disparities, analyze root causes, and propose mitigation strategies.
- **Challenge format:** Bias audit for generative AI. Auto-grading checks systematic testing, disparity measurement, and mitigation proposals.
- **CSTA:** MS‑CAS‑ET‑05, DAA‑DI.
- **AI4K12:** D2 Bias and Fairness; E2 Societal Impacts.

### T35.G7.01.01 – Conduct bias audits for AI perception and assistance (T23-T24)

_Dependency:_
  * T35.G7.01: Conduct bias audits for AI content generation (T21-T22)
  * T35.G6.03.01: Develop ethics guidelines for AI perception and assistance (T23-T24)


- **Short name:** AI perception/assistance fairness testing
- **Description:** Students systematically audit T23 perception tools for accuracy across skin tones and lighting conditions, and T24 coding assistants for help quality by English proficiency. They document disparities and propose both technical and policy solutions.
- **Challenge format:** Bias audit for perception/assistance AI. Auto-grading checks systematic testing, disparity documentation, and solution proposals.
- **CSTA:** MS‑CAS‑ET‑05, DAA‑DI.
- **AI4K12:** D2 Bias and Fairness; E2 Societal Impacts.

### T35.G7.02 – Explore unintended consequences of new tech

_Dependency:_
  * T35.G6.01: Apply ethics lenses (beneficence, fairness, autonomy)
  * T35.G5.01: Examine global impacts of technology


- **Short name:** Side effects storyboard
- **Description:** Learners storyboard a technology (delivery drones, facial recognition) showing both intended use and unforeseen impact, then propose mitigations.
- **Challenge format:** Storyboard. Rubric checks for multiple perspectives and solutions.
- **CSTA:** MS‑CAS‑ET‑05.

### T35.G7.03 – Evaluate transparency vs security tensions

_Dependency:_
  * T35.G6.02: Analyze data privacy tradeoffs
  * T35.G5.02: Debate digital well-being scenarios


- **Short name:** Should we open-source this tool?
- **Description:** Students weigh openness (auditability) against misuse risks for a hypothetical AI tool and justify a recommendation.
- **Challenge format:** Position paper referencing pros/cons. Auto-grading ensures arguments cite concrete risks/benefits.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G7.04 – Analyze societal impacts of AI perception technologies (Pairing with T23)

_Dependency:_
  * T35.G6.02: Analyze data privacy tradeoffs
  * T35.G6.03.01: Develop ethics guidelines for AI perception and assistance (T23-T24)


- **Short name:** AI surveillance: community safety vs privacy
- **Description:** Following T23 perception projects, students analyze real-world case studies of AI surveillance (facial recognition in schools, emotion detection at work, gesture tracking in public). They debate tradeoffs between security and privacy, examine disproportionate impacts on marginalized communities, and propose ethical guidelines.
- **Challenge format:** Case study debate with equity focus. Rubric checks stakeholder analysis, community impact assessment, and ethical framework application.
- **CSTA:** MS‑CAS‑ET‑05.
- **AI4K12:** E2 Societal Impacts; D2 Bias and Fairness.

### T35.G7.05 – Debate ethical implications of AI media generation (Pairing with T21)

_Dependency:_
  * T35.G6.03: Develop ethics guidelines for AI content generation (T21-T22)
  * T35.G5.03: Analyze AI's differential impacts on workers and communities


- **Short name:** AI-generated content and creative professions
- **Description:** Following T21 AI media projects, students hold structured debates on AI's impact on artists, photographers, and designers. They examine issues of copyright, style imitation, job displacement, cultural representation in training data, and propose frameworks for ethical AI media use.
- **Challenge format:** Structured debate + policy proposal. Rubric checks multiple perspective inclusion, equity analysis, and actionable recommendations.
- **CSTA:** MS‑CAS‑ET‑05.
- **AI4K12:** E2 Societal Impacts; D1 Ethical Design.

### T35.G7.06 – Facilitate community discussions on AI-powered tech policy

_Dependency:_
  * T35.G6.04: Examine digital divide data
  * T35.G5.02: Debate digital well-being scenarios


- **Short name:** Host AI ethics town halls
- **Description:** Learners prepare questions about AI policy (chatbot use in schools, AI hiring tools, automated content moderation), gather diverse stakeholder input, and summarize consensus on local AI governance needs, connecting to T21-T24 applications.
- **Challenge format:** AI-focused facilitation plan + summary. Rubric checks stakeholder inclusion, AI-specific policy understanding, and equity-centered outcomes.
- **CSTA:** MS‑CAS‑HC‑03.
- **AI4K12:** A1 Human-AI Collaboration; E2 Societal Impacts.

---

## Grade 8

### T35.G8.01 – Apply ethical frameworks to real proposals

_Dependency:_
  * T04.G2.01: Identify the repeating unit in a longer pattern
  * T35.G7.01: Conduct bias audits for AI content generation (T21-T22)
  * T35.G6.01: Apply ethics lenses (beneficence, fairness, autonomy)


- **Short name:** Use consequentialist vs deontological reasoning
- **Description:** Students evaluate a computing project (predictive policing, emotion AI) through multiple ethical lenses and compare conclusions.
- **Challenge format:** Comparative essay. Rubric checks lens definitions and application.
- **CSTA:** MS‑CAS‑ET‑06.

### T35.G8.01.01 – Analyze AI chatbots' impact on information literacy (Pairing with T22)

_Dependency:_
  * T35.G8.01: Apply ethical frameworks to real proposals
  * T35.G7.01: Conduct bias audits for AI content generation (T21-T22)


- **Short name:** AI chatbots and the future of learning
- **Description:** Following T22 chatbot projects, students analyze how AI-generated answers affect research habits, critical thinking, misinformation spread, and educational equity. They examine differential impacts on students with varying digital literacy levels and propose guidelines for responsible chatbot use in academic settings.
- **Challenge format:** Impact analysis + policy recommendations. Rubric checks equity analysis, evidence synthesis, and practical guidelines connecting to T22 experiences.
- **CSTA:** MS‑CAS‑ET‑06.
- **AI4K12:** E2 Societal Impacts; A1 Human-AI Collaboration.

### T35.G8.02 – Draft equity-focused policy briefs for AI in education

_Dependency:_
  * T35.G7.06: Facilitate community discussions on AI-powered tech policy
  * T35.G6.04: Examine digital divide data


- **Short name:** AI policy with social justice lens
- **Description:** Learners synthesize evidence and stakeholder input into policy briefs that center equity in AI use for schools. They address differential access to T21-T24 tools, bias in AI outputs, privacy protection for vulnerable students, and culturally responsive AI implementation.
- **Challenge format:** Equity-centered policy document. Rubric evaluates social justice framing, community voice inclusion, and systemic inequality analysis.
- **CSTA:** MS‑CAS‑ET‑06, CAS‑HC‑02.
- **AI4K12:** D2 Bias and Fairness; E2 Societal Impacts.

### T35.G8.03 – Design impact assessments for CreatiCode projects

_Dependency:_
  * T35.G7.02: Explore unintended consequences of new tech
  * T35.G6.01: Apply ethics lenses (beneficence, fairness, autonomy)


- **Short name:** Pre-launch impact checklist
- **Description:** Students create rubrics assessing accessibility, privacy, wellbeing, and cultural sensitivity before publishing games/apps.
- **Challenge format:** Checklist + sample application. Auto-grading checks categories and evidence fields.
- **CSTA:** MS‑PRO‑PM‑03, CAS‑ET.

### T35.G8.04 – Lead peer workshops on responsible tech use

_Dependency:_
  * T35.G7.06: Facilitate community discussions on AI-powered tech policy
  * T35.G6.04: Examine digital divide data


- **Short name:** Teach younger students about digital wellbeing
- **Description:** Learners develop workshops/demos for younger grades on topics like screen balance, online kindness, or AI use.
- **Challenge format:** Lesson plan + reflection. Rubric checks objectives, activities, and adjustments based on feedback.
- **CSTA:** MS‑CAS‑CE‑08, CAS‑ET‑06.

---
