# T21 - Chatbots & Prompting - PART 2 (Grades 3-4)
# ============================================================================
# GRADE 3-4 SKILLS: RCTF Framework & Structured Prompting
# ============================================================================
#
# This section focuses on:
# - Transitioning from picture-based to text-based prompting
# - Introducing RCTF (Role, Context, Task, Format) framework
# - Building multi-turn conversational chatbots
# - Debugging and iterating on prompts
# - Testing chatbot behavior systematically
# - Understanding audience and tone in AI communication
#
# ============================================================================

---

## GRADE 3 SKILLS




ID: T21.G3.01
Topic: T21 – Chatbots & Prompting
Skill: Trace how a simple text prompt flows through a chatbot system diagram
Description: **Student task:** Examine a visual flowchart showing how a chatbot processes prompts: [User enters prompt] → [Prompt sent to AI model] → [AI generates response] → [Response displayed to user]. Students label each step and trace what happens when they ask "What is the capital of France?" They identify where the input goes, where processing happens, and where output appears. They answer questions: "Where does the AI's answer come from?" (generated by model, not from a database), "Will the same prompt always give the exact same answer?" (no, slight variations). **Key insight:** Understanding the chatbot pipeline helps debug problems and set realistic expectations. _Implementation note: Interactive diagram with drag-to-label components and trace-path activity. Builds on G2.06's system understanding. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G2.06: Identify when a robot helper might make mistakes using picture scenarios




ID: T21.G3.02
Topic: T21 – Chatbots & Prompting
Skill: Create a one-sentence text prompt with Role and Task components
Description: **Student task:** Write 3 simple one-sentence prompts that include WHO (Role) and WHAT (Task). **Scenario 1:** "I want help writing a story about space." Student writes: "You are a storyteller. Write a story about space." **Scenario 2:** "I need math help with fractions." Student writes: "You are a math teacher. Explain fractions." **Scenario 3:** "I want to learn about animals." Student writes: "You are a scientist. Tell me about animals." System checks that each prompt has both Role ("You are a...") and Task (action verb + subject). **Key insight:** Starting with Role + Task creates clear, focused prompts. _Implementation note: Text entry with template guidance; auto-check verifies presence of role statement and task verb. Provides feedback if components missing. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G2.01: Decompose picture prompts into Role, Task, and Format components
* T21.G2.02: Build complete picture prompts using Role, Task, Format cards




ID: T21.G3.03
Topic: T21 – Chatbots & Prompting
Skill: Add Context and Format components to expand a basic prompt
Description: **Student task:** Take 3 basic Role+Task prompts and expand them by adding Context (why/what situation) and Format (how to present answer). **Example:** Basic prompt: "You are a chef. Explain how to make cookies." Student adds: **Context:** "I'm 8 years old and want to help my parents bake." **Format:** "Give me 5 simple steps." **Final prompt:** "You are a chef. I'm 8 years old and want to help my parents bake cookies. Explain how to make cookies. Give me 5 simple steps." Students create 3 expanded prompts, each building from Role+Task to full RCTF. **Key insight:** Context and Format make responses more relevant and useful. _Implementation note: Guided prompt builder with four text fields (R, C, T, F); shows before/after comparison. Auto-graded by presence of all components. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.02: Create a one-sentence text prompt with Role and Task components




ID: T21.G3.03.01
Topic: T21 – Chatbots & Prompting
Skill: Identify which RCTF component is missing in incomplete prompts
Description: **Student task:** Read 6 incomplete prompts and identify which RCTF component (Role, Context, Task, or Format) is missing. **Example 1:** "I'm working on a science project about volcanoes [Context]. Explain volcanoes [Task]. Use bullet points [Format]." **Missing:** Role. **Example 2:** "You are a history expert [Role]. Explain the American Revolution [Task]. Use simple words [Format]." **Missing:** Context. Students drag each prompt into the correct "Missing ___" box. After sorting, they add the missing component to complete each prompt. **Key insight:** Recognizing gaps in prompts helps improve them systematically. _Implementation note: Sorting activity with 6 prompts (2 per missing component type); follow-up asks students to fill in missing parts. Auto-graded. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G3.04
Topic: T21 – Chatbots & Prompting
Skill: Create a simple chatbot that responds to one specific keyword
Description: **Student task:** Build a basic chatbot script in CreatiCode using if-then logic. Chatbot detects ONE keyword and responds accordingly. **Example:** User asks "help" → Chatbot says "I'm here to help! What do you need?" Students use blocks: `when green flag clicked` → `ask [Type your message] and wait` → `if <(answer) contains [help]> then` → `say [I'm here to help!]`. Students test with multiple inputs to see when chatbot responds vs. stays silent. **Key insight:** Simple chatbots use pattern matching, not true understanding. _Implementation note: Block-based coding activity using conditional logic; introduces keyword detection. Students must test with 3+ inputs. CSTA: E3-AP-AF-01, E3-IC-SV-01._

Dependencies:
* T21.G3.01: Trace how a simple text prompt flows through a chatbot system diagram




ID: T21.G3.05
Topic: T21 – Chatbots & Prompting
Skill: Predict chatbot response for 3-4 different user inputs to same bot
Description: **Student task:** Given a chatbot with defined behavior, predict how it will respond to different inputs. **Scenario:** Chatbot programmed to: if input contains "hello" → say "Hi there!"; if input contains "help" → say "What do you need?"; otherwise → say "I don't understand." Students predict responses for: (1) "hello friend", (2) "I need help", (3) "what's the weather?", (4) "hello, I need help". **Correct predictions:** (1) "Hi there!", (2) "What do you need?", (3) "I don't understand", (4) depends on which condition is checked first. **Key insight:** Understanding chatbot logic helps predict behavior and find edge cases. _Implementation note: MCQ prediction activity with 4 inputs; reveals importance of condition order and overlapping patterns. CSTA: E3-AP-AF-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword




ID: T21.G3.06
Topic: T21 – Chatbots & Prompting
Skill: Trace a 3-turn conversation showing how context is preserved
Description: **Student task:** Examine a conversation transcript and trace how information from early turns is used in later responses. **Conversation:** Turn 1: User: "My favorite animal is a dolphin." Bot: "Dolphins are amazing! They're very intelligent." Turn 2: User: "Where do they live?" Bot: "Dolphins live in oceans around the world." Turn 3: User: "What do they eat?" Bot: "Dolphins eat fish and squid." Students highlight pronouns ("they") and draw arrows showing what each refers to (dolphins). They identify that context is maintained across all 3 turns without re-stating "dolphins." **Key insight:** Conversational AI maintains context by remembering previous exchanges. _Implementation note: Visual annotation activity with conversation transcript; students mark context references. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.05: Predict chatbot response for 3-4 different user inputs to same bot




ID: T21.G3.07
Topic: T21 – Chatbots & Prompting
Skill: Build a 2-turn chatbot conversation with context from turn 1 used in turn 2
Description: **Student task:** Create a chatbot that asks for information in turn 1, then uses that information in turn 2. **Example script:** Turn 1: Bot asks "What's your favorite color?" → stores answer in variable `favoriteColor`. Turn 2: Bot says: `join [My favorite color is also] (favoriteColor)!`. Students build this using blocks: `ask [What's your favorite color?] and wait` → `set [favoriteColor] to (answer)` → `say (join [My favorite color is also ] (favoriteColor)!)`. They test with different inputs to verify context carries over. **Key insight:** Variables store context between conversation turns. _Implementation note: Block-based coding with variables; introduces state management in conversations. CSTA: E3-AP-AF-01, E3-AP-V-01._

Dependencies:
* T21.G3.06: Trace a 3-turn conversation showing how context is preserved




ID: T21.G3.08
Topic: T21 – Chatbots & Prompting
Skill: Compare expected vs actual chatbot output to identify prompt problems
Description: **Student task:** Students are given 3 scenarios where desired output doesn't match actual output. They identify what went wrong in each prompt. **Scenario 1:** Desired: "Three rhyming words about cats." Actual: Long paragraph about cat history. **Problem:** Prompt didn't specify Format (3 words). **Scenario 2:** Desired: "Funny story for kids." Actual: Serious scientific explanation. **Problem:** Prompt didn't specify Role (comedian/storyteller) or Context (for kids). **Scenario 3:** Desired: "Recipe with exact measurements." Actual: Vague cooking instructions. **Problem:** Prompt didn't specify Format (include measurements). Students select the problem from multiple choices and rewrite the prompt to fix it. **Key insight:** Debugging prompts requires comparing intent vs. result. _Implementation note: Three debugging scenarios with MCQ problem identification + prompt rewriting. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.05: Predict chatbot response for 3-4 different user inputs to same bot




ID: T21.G3.09
Topic: T21 – Chatbots & Prompting
Skill: Fix a broken prompt by adding missing details or correcting vague language
Description: **Student task:** Students receive 4 broken prompts and fix each one by adding specificity or correcting vague language. **Broken Prompt 1:** "Tell me about it." **Problem:** No subject specified. **Fixed:** "You are a science teacher. Tell me about photosynthesis. Use simple language for a 3rd grader." **Broken Prompt 2:** "Write something good." **Problem:** Too vague. **Fixed:** "You are a poet. Write a short, happy poem about sunshine. Use 4 lines with rhyming words." Students identify the vague parts (highlighted) and rewrite with specific details. After fixing, they test both versions with AI and compare results. **Key insight:** Specific details transform vague prompts into effective ones. _Implementation note: Prompt editing activity with before/after testing; highlights improvements in output quality. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.08: Compare expected vs actual chatbot output to identify prompt problems




ID: T21.G3.10
Topic: T21 – Chatbots & Prompting
Skill: Create chatbot responses for 3 different user moods (happy, sad, confused)
Description: **Student task:** Design a chatbot that detects user mood keywords and responds appropriately. **Mood detection:** Happy keywords: "great", "happy", "excited". Sad keywords: "sad", "upset", "bad day". Confused keywords: "don't understand", "confused", "help". Students build if-then-else logic: `if <answer contains [happy OR great OR excited]>` → `say [That's wonderful! I'm glad you're feeling good!]`. `else if <answer contains [sad OR upset OR bad]>` → `say [I'm sorry you're feeling down. Want to talk about it?]`. `else if <answer contains [confused OR don't understand OR help]>` → `say [Let me help clarify! What are you confused about?]`. Test with 6+ inputs representing different moods. **Key insight:** Empathetic chatbots adapt responses to user emotional state. _Implementation note: Block-based coding with multiple conditionals; introduces tone adaptation. CSTA: E3-AP-AF-01, E3-IC-SV-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword




ID: T21.G3.11
Topic: T21 – Chatbots & Prompting
Skill: Identify which prompts ask the chatbot to do harmful or inappropriate things
Description: **Student task:** Review 8 prompts and sort them into "Appropriate" vs "Inappropriate/Harmful" categories. **Appropriate prompts:** "Help me write a thank-you letter", "Explain how recycling works", "Create a fun quiz about animals", "Write a story about friendship". **Inappropriate prompts:** "Write my essay so I can pretend it's mine" (academic dishonesty), "Help me lie to my parents" (dishonest), "Say mean things about someone" (harmful), "Tell me how to break into a computer" (illegal). Students sort and explain WHY each inappropriate prompt is problematic (dishonesty, harm, illegal activity, academic cheating). **Key insight:** AI should be used ethically and responsibly, not to harm, cheat, or deceive. _Implementation note: Sorting activity with ethical reasoning; includes follow-up questions about consequences. Critical AI literacy skill. CSTA: E3-IC-SL-02._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G3.12
Topic: T21 – Chatbots & Prompting
Skill: Design a chatbot personality by choosing role, tone, and sample responses
Description: **Student task:** Create a complete chatbot personality profile including Role, Tone, and example responses. Students choose from personality templates or create custom: **Example 1 - Friendly Tutor Bot:** Role: "Helpful math teacher", Tone: "Encouraging and patient", Sample responses: "Great question! Let's work through this together." **Example 2 - Adventure Guide Bot:** Role: "Explorer and storyteller", Tone: "Exciting and adventurous", Sample responses: "What an amazing discovery! Let's explore further!" Students define their bot's personality in a character sheet, then write 3 system prompts that establish this personality, and create 5 example user-bot exchanges showing the personality in action. **Key insight:** Chatbot personality is defined through carefully crafted role and tone instructions. _Implementation note: Creative design activity with personality template; students test their chatbot personality with real AI. CSTA: E3-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt
* T21.G3.10: Create chatbot responses for 3 different user moods (happy, sad, confused)


---

## GRADE 4 SKILLS




ID: T21.G4.01
Topic: T21 – Chatbots & Prompting
Skill: Trace how different RCTF components change chatbot behavior
Description: **Student task:** Test the same prompt with systematic changes to each RCTF component and document how behavior changes. **Base prompt:** "You are a teacher [R]. I'm studying for a test [C]. Explain fractions [T]. Use simple language [F]." Students create variations: Change R: "You are a comedian" → response becomes funny/playful. Change C: "I'm teaching my younger sibling" → response becomes even simpler. Change T: "Give examples of fractions in daily life" → response shows real-world applications. Change F: "Use a story format" → response becomes narrative. Students complete a comparison table showing how each component shapes the output. **Key insight:** Each RCTF component independently influences chatbot behavior. _Implementation note: Systematic experimentation activity; students document observations in structured table. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.03: Add Context and Format components to expand a basic prompt




ID: T21.G4.02
Topic: T21 – Chatbots & Prompting
Skill: Build prompts using RCTF framework for 3 different scenarios
Description: **Student task:** Apply RCTF framework to create complete prompts for three distinct scenarios. **Scenario 1 - Homework Help:** R: "You are a patient science tutor", C: "I'm a 4th grader working on my homework about the water cycle", T: "Explain the water cycle", F: "Use 4-5 simple sentences with an example I can relate to". **Scenario 2 - Creative Writing:** R: "You are a creative writing coach", C: "I want to write a story for my class assignment about adventure", T: "Help me brainstorm story ideas", F: "Give me 3 different story concepts as bullet points". **Scenario 3 - Learning New Skill:** R: "You are a coding instructor", C: "I'm learning to code and want to make a simple game", T: "Explain what a variable is", F: "Use a real-world analogy that a 10-year-old would understand". Students write all RCTF components for each scenario and test with AI. **Key insight:** RCTF provides a systematic approach to prompt construction for any purpose. _Implementation note: Structured prompt-writing activity with template; students test and compare outputs. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.01: Trace how different RCTF components change chatbot behavior




ID: T21.G4.02.01
Topic: T21 – Chatbots & Prompting
Skill: Optimize each RCTF component to improve prompt clarity
Description: **Student task:** Take 3 poorly-written prompts and optimize each RCTF component for clarity and effectiveness. **Poor Prompt 1:** "You are someone who knows stuff [R - too vague]. I need information [C - unclear]. Tell me things [T - no specific task]. Make it good [F - meaningless]." **Optimized:** "You are a marine biologist [R - specific expertise]. I'm preparing a presentation for my class about ocean conservation [C - clear purpose]. Explain why coral reefs are important [T - focused task]. Give me 3 main reasons with one example for each [F - concrete format]." Students optimize 3 prompts by: 1) Making Role specific and relevant, 2) Adding meaningful Context, 3) Creating focused Task, 4) Defining clear Format. They compare outputs from original vs. optimized prompts. **Key insight:** Optimization means making each component specific, relevant, and measurable. _Implementation note: Prompt refinement activity; side-by-side comparison shows quality improvement. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios




ID: T21.G4.03
Topic: T21 – Chatbots & Prompting
Skill: Create a chatbot with 4-5 different response patterns using if-then logic
Description: **Student task:** Build a more sophisticated chatbot that can handle 4-5 different user intents using nested if-then-else logic. **Example - Homework Helper Bot:** Detects: (1) Math keywords → "I can help with math! What's the problem?", (2) Science keywords → "Science is fascinating! What topic?", (3) Writing keywords → "Let's work on your writing! What are you writing about?", (4) "I don't know" → "That's okay! Let's figure out what you need help with.", (5) None of above → "I help with math, science, and writing. Which subject?". Students implement using nested conditionals, test with 10+ varied inputs, and document which inputs trigger which patterns. **Key insight:** Complex chatbots use decision trees with multiple branches. _Implementation note: Block-based coding with nested conditionals; students create comprehensive test plan. CSTA: E4-AP-AF-01, E4-IC-SV-01._

Dependencies:
* T21.G3.04: Create a simple chatbot that responds to one specific keyword
* T21.G3.10: Create chatbot responses for 3 different user moods (happy, sad, confused)




ID: T21.G4.04
Topic: T21 – Chatbots & Prompting
Skill: Test chatbot with 5+ diverse inputs and document which ones fail
Description: **Student task:** Create a systematic test plan for a chatbot, execute tests, and document failures. Students design test cases covering: (1) Normal inputs (expected keywords), (2) Edge cases (typos, capitalization, extra words), (3) Out-of-scope inputs (unrelated topics), (4) Boundary cases (multiple keywords in one input), (5) Empty/minimal inputs. **Example test table:** Input: "help me with math please" | Expected: Math response | Actual: Math response | Pass/Fail: Pass. Input: "HELP MATH" | Expected: Math response | Actual: No response | Pass/Fail: Fail (case-sensitive). Students document at least 5 failures, categorize failure types (case sensitivity, missing keywords, unexpected format), and propose fixes. **Key insight:** Systematic testing reveals chatbot limitations and improvement opportunities. _Implementation note: Test documentation activity with pass/fail tracking; introduces QA methodology. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G4.03: Create a chatbot with 4-5 different response patterns using if-then logic




ID: T21.G4.05
Topic: T21 – Chatbots & Prompting
Skill: Parse user input to extract key information (name, number, topic)
Description: **Student task:** Build a chatbot that extracts specific information from user input and uses it in responses. **Scenario 1 - Name extraction:** User: "My name is Alex" → Bot extracts "Alex" → Stores in variable → Says "Nice to meet you, Alex!" **Scenario 2 - Number extraction:** User: "I have 3 cats" → Bot extracts "3" → Says "Wow, 3 cats! That's a lot!" **Scenario 3 - Topic extraction:** User: "I want to learn about dinosaurs" → Bot extracts "dinosaurs" → Says "Dinosaurs are fascinating! What do you want to know about dinosaurs?" Students use string manipulation blocks (`letter () of ()`, `join`, `contains`) to locate and extract information. They test extraction with varied sentence structures. **Key insight:** Information extraction allows personalized, context-aware responses. _Implementation note: Block-based coding with string manipulation; introduces basic NLP concepts. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G4.03: Create a chatbot with 4-5 different response patterns using if-then logic




ID: T21.G4.06
Topic: T21 – Chatbots & Prompting
Skill: Build a 3-turn conversation where bot remembers 2 pieces of information
Description: **Student task:** Create a stateful chatbot conversation that gathers and uses multiple pieces of information across turns. **Conversation flow:** Turn 1: Bot: "What's your name?" → User: "Emma" → Store in `userName`. Bot: "Nice to meet you, Emma! What's your favorite subject?" Turn 2: User: "Science" → Store in `favoriteSubject`. Bot: "Science is great, Emma! What science topic interests you most?" Turn 3: User: "Space" → Store in `scienceTopic`. Bot: "Emma, I can tell you love science, especially space! Here's a fun fact about space: ..." Students implement using variables to maintain state, ensure pronouns and names are used correctly to show context, and test that information persists throughout the conversation. **Key insight:** Multi-variable state management enables natural, contextual conversations. _Implementation note: Block-based coding with multiple variables and sequential dialogue; introduces conversation state complexity. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G3.07: Build a 2-turn chatbot conversation with context from turn 1 used in turn 2
* T21.G4.05: Parse user input to extract key information (name, number, topic)




ID: T21.G4.07
Topic: T21 – Chatbots & Prompting
Skill: Trace conversation flow through a 4-turn branching dialogue tree
Description: **Student task:** Examine a complex branching dialogue tree with 4 turns and multiple paths. Students trace different conversation paths based on user choices. **Dialogue tree:** Turn 1: Bot: "Do you want help with homework or want to play a game?" Turn 2a (if homework): Bot: "What subject?" → branches to math/science/writing. Turn 2b (if game): Bot: "What type of game?" → branches to trivia/word game/story. Turn 3: Further specialization based on Turn 2 choice. Turn 4: Final response tailored to path. Students trace 3 different complete paths, identify decision points, and document how context from each turn influences subsequent options. They draw arrows showing valid and invalid transitions. **Key insight:** Branching conversations create decision trees with multiple valid paths. _Implementation note: Visual tree diagram tracing with annotation; prepares for implementing branching logic. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G3.06: Trace a 3-turn conversation showing how context is preserved




ID: T21.G4.08
Topic: T21 – Chatbots & Prompting
Skill: Implement a branching conversation with 2 choice points
Description: **Student task:** Build a chatbot with a branching conversation structure featuring 2 decision points. **Implementation example - Story Game Bot:** Turn 1: "Do you want a scary story or a funny story?" → Store choice. Turn 2 (if scary): "Do you want ghosts or monsters?" → Branch A: ghosts, Branch B: monsters. Turn 2 (if funny): "Do you want animals or silly people?" → Branch C: animals, Branch D: silly people. Turn 3: Tell appropriate story based on path taken. Students use nested if-then-else structures, track which path user is on using variables, and create 4 different story endings (one per path). They test all 4 paths and verify correct story is told. **Key insight:** Branching logic creates interactive, personalized experiences. _Implementation note: Block-based coding with nested conditionals and state tracking; students create flowchart before coding. CSTA: E4-AP-AF-01, E4-AP-V-01._

Dependencies:
* T21.G4.07: Trace conversation flow through a 4-turn branching dialogue tree




ID: T21.G4.09
Topic: T21 – Chatbots & Prompting
Skill: Debug a prompt by testing one RCTF component change at a time
Description: **Student task:** Use systematic debugging to fix a prompt that produces poor output. Students follow scientific method: (1) Identify the problem with current output, (2) Form hypothesis about which RCTF component is causing issue, (3) Test by changing ONLY that component, (4) Observe if output improves, (5) Iterate. **Example:** Prompt: "You are a helper [R - vague]. I need information [C - unclear]. Tell me about dogs [T]. Make it interesting [F - vague]." **Problem:** Output is too technical and long. **Hypothesis 1:** Role is too vague. **Test:** Change R to "You are a friendly pet expert for kids" → Output improves slightly. **Hypothesis 2:** Format is vague. **Test:** Add F: "Use 3-4 simple sentences" → Output much better! Students debug 3 prompts, documenting each hypothesis and test result. **Key insight:** Systematic debugging isolates which components need improvement. _Implementation note: Structured debugging worksheet with hypothesis-test-result tracking. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.09: Fix a broken prompt by adding missing details or correcting vague language
* T21.G4.01: Trace how different RCTF components change chatbot behavior




ID: T21.G4.10
Topic: T21 – Chatbots & Prompting
Skill: Create test cases for chatbot covering normal, edge, and error inputs
Description: **Student task:** Design comprehensive test suite with three categories of test cases. **Normal cases:** Expected inputs that should work perfectly. **Edge cases:** Unusual but valid inputs (typos, mixed case, extra punctuation, very short/long inputs). **Error cases:** Invalid or out-of-scope inputs that should be handled gracefully. **Example test suite for Math Helper Bot:** Normal: "help with addition", "I need math help", "solve 2+2". Edge: "HELP", "m a t h", "help???", "can you maybe possibly help with math please". Error: "cook a recipe", "12345", "", "asdfghjkl". Students create 15+ test cases (5 per category), predict expected behavior, run tests, and document which cases fail. They propose error handling for failed cases. **Key insight:** Comprehensive testing ensures robust chatbot performance across all input types. _Implementation note: Test suite design activity with categorization and prediction; introduces software testing principles. CSTA: E4-AP-AF-01._

Dependencies:
* T21.G4.04: Test chatbot with 5+ diverse inputs and document which ones fail




ID: T21.G4.11
Topic: T21 – Chatbots & Prompting
Skill: Compare two different prompts for the same task and evaluate quality
Description: **Student task:** Evaluate and compare two prompts designed for the same goal using quality criteria. Students receive rubric: (1) Clarity - Are instructions clear? (2) Completeness - Are all RCTF components present? (3) Specificity - Is language precise? (4) Output quality - Does it produce desired result? **Example comparison:** Goal: "Get help writing a poem about nature." **Prompt A:** "Write a nature poem." **Prompt B:** "You are a creative poetry teacher [R]. I'm a 4th grade student working on a class project about appreciating nature [C]. Help me write a short poem celebrating trees and forests [T]. Use 4 lines with simple rhymes that paint a visual picture [F]." Students score each prompt (1-5) on each criterion, test both prompts, compare outputs, and write a justification for which is better and why. They complete this for 3 different prompt pairs. **Key insight:** Systematic evaluation reveals what makes prompts effective. _Implementation note: Comparison activity with scoring rubric; students analyze quality factors. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios




ID: T21.G4.12
Topic: T21 – Chatbots & Prompting
Skill: Identify when chatbot output contains incorrect or made-up information
Description: **Student task:** Learn to spot AI hallucinations and factual errors. Students receive 8 chatbot responses and verify accuracy using trusted sources. **Example responses to check:** (1) "The capital of France is Paris" (correct), (2) "Penguins live in the Arctic" (incorrect - they live in Antarctica), (3) "George Washington was the 3rd president" (incorrect - he was 1st), (4) "The fastest land animal is the cheetah" (correct), (5) [Made-up fact about invented animal], (6) [Plausible-sounding but false historical claim]. Students categorize each as: Correct, Factually wrong, or Made-up (hallucination). For incorrect/made-up items, they find the correct information and explain why AI might have made the error. **Key insight:** AI can confidently state incorrect information; always verify important facts. _Implementation note: Fact-checking activity with research component; critical AI literacy skill. CSTA: E4-IC-SV-01, E4-IC-SL-02._

Dependencies:
* T21.G4.04: Test chatbot with 5+ diverse inputs and document which ones fail




ID: T21.G4.13
Topic: T21 – Chatbots & Prompting
Skill: Design a chatbot for a specific audience (young children, teenagers, adults)
Description: **Student task:** Create three versions of the same chatbot optimized for different age groups. Students adapt vocabulary, tone, complexity, and examples for each audience. **Task:** Create a chatbot that explains "what is gravity" for: **Audience 1 - Young children (ages 5-7):** R: "You are a friendly teacher for young kids", C: "Explain to a 6-year-old", T: "Explain gravity", F: "Use 2-3 very simple sentences with an example like dropping a ball". Sample output: "Gravity is like an invisible force that pulls things down. When you drop a ball, gravity makes it fall to the ground!" **Audience 2 - Preteens (ages 10-12):** More detailed explanation with scientific terms. **Audience 3 - Teenagers (ages 14-16):** Include physics concepts, formulas, and real-world applications. Students write RCTF prompts for all three audiences, test outputs, and analyze how vocabulary, sentence structure, and examples differ. **Key insight:** Effective communication adapts to audience knowledge and needs. _Implementation note: Audience-adaptation activity; students compare outputs across age groups. CSTA: E4-IC-SV-01._

Dependencies:
* T21.G3.12: Design a chatbot personality by choosing role, tone, and sample responses
* T21.G4.02: Build prompts using RCTF framework for 3 different scenarios


---

## END OF GRADE 4 SKILLS
