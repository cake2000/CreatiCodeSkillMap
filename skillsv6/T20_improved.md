## TOPIC: T20 – AI Media (Phase 9 Optimized - December 2025)
# Phase 9 MAJOR RESTRUCTURING - Focus on AI Media Generation & Perception
#
# TOPIC CLARIFICATION (Phase 9):
# T20 focuses on AI MEDIA - generation and perception of images, audio, and video/vision
# T21 focuses on CHATBOTS & PROMPTING - text-based AI conversations and prompt engineering
# ChatGPT skills remain in T20 ONLY when directly supporting media workflows (image description, etc.)
#
# CORE SKILL PATHWAYS (Phase 9):
# 1. AI IMAGE GENERATION: DALL-E image creation, prompt refinement, quality evaluation, deepfake detection
# 2. AI AUDIO: Text-to-speech synthesis, speech recognition, voice interfaces
# 3. AI VISION/PERCEPTION: Face detection, body tracking, hand detection, gesture recognition
# 4. NEURAL NETWORKS & ML: Building/training models, KNN classification, pattern recognition
# 5. SEMANTIC SEARCH: Vector databases, similarity search, knowledge retrieval
# 6. AI MEDIA ETHICS: Bias detection, hallucination detection, deepfake awareness, accessibility, responsible AI
#
# PHASE 9 KEY IMPROVEMENTS:
# 1. FIXED G3 DEPENDENCIES - Added proper K-2 dependencies to create progressive learning path
# 2. NEURAL NETWORK SUB-SKILLS - Added T20.G7.11.01, .02, .03 for detailed NN training concepts
# 3. AI HALLUCINATIONS - New detection skills at G5, G7, G8 for identifying fabricated content
# 4. DEEPFAKE DETECTION - Added authenticity verification at G6, G7, G8
# 5. REDUCED G8 OVERLOAD - Consolidated from 28 to 26 skills through merging related concepts
# 6. STRONGER INTERNAL DEPENDENCIES - Enhanced X-2 rule compliance within T20 progression
# 7. ACTIVE VERBS - Replaced all "understand/identify" with "trace/debug/evaluate/predict/detect"
# 8. CREATICODE BLOCKS - Explicit references to CreatiCode ML extensions where applicable
#
# SKILL DISTRIBUTION (Phase 9):
# - GK: 8 skills (picture sorting, matching, basic AI media concepts)
# - G1: 8 skills (comparing AI/real media, sequencing, safety)
# - G2: 8 skills (training data analysis, bias awareness, sharing rules)
# - G3: 10 skills (pre-coding: pipelines, templates, evaluation) - NOW with K-2 dependencies
# - G4: 12 skills (advanced analysis: complexity, safety, iteration strategies)
# - G5: 16 skills (first coding: DALL-E, TTS, parameter adjustment, hallucination detection)
# - G6: 20 skills (face/body detection, speech recognition, moderation, deepfake awareness)
# - G7: 24 skills (hand detection, neural networks with sub-skills, KNN, multi-modal, hallucination analysis)
# - G8: 26 skills (deep learning, semantic search, production systems, accessibility, deepfake verification)
#
# Total: 132 skills (GK-G8) - focused on AI media generation, perception, evaluation, and authenticity

Focus: AI-generated images and audio, computer vision (face/body/hand detection), neural networks, semantic search, hallucination detection, deepfake awareness, and AI media evaluation

## GRADE K (8 skills)




ID: T20.GK.01
Topic: T20 – AI Media
Skill: Sort picture cards by real photos vs computer-made images
Description: **Student task:** Sort 12 picture cards into two piles: photos taken by cameras and pictures made by computers. **Visual scenario:** Cards show simple objects (apple, dog, car) with obvious differences—photos have natural backgrounds and lighting, computer images have flat colors and perfect shapes. Cards have visual hints like camera icons or computer icons on the back for self-checking. **Key insight:** Computers can make pictures that look different from real photos.
Activity Type: Unplugged sorting
Estimated Time: 3-4 minutes
CSTA: 1A-CS-01

Dependencies: None




ID: T20.GK.02
Topic: T20 – AI Media
Skill: Match word cards to AI-generated pictures
Description: **Student task:** Match 6 word cards (cat, tree, house, sun, flower, car) to corresponding computer-generated pictures. **Visual scenario:** Word cards have simple text and icons, picture cards show colorful AI-generated images of each word. Students place word card next to matching picture card on a mat. **Key insight:** Computers can make pictures from words we give them.
Activity Type: Unplugged matching
Estimated Time: 2-3 minutes
CSTA: 1A-AP-10

Dependencies: None




ID: T20.GK.03
Topic: T20 – AI Media
Skill: Sort things AI can draw vs things AI cannot draw
Description: **Student task:** Sort 10 cards into two groups: things AI can draw (dog, car, flower, house, rainbow) and things AI cannot draw yet (love, friendship, hunger, being tired, feeling scared). **Visual scenario:** Physical cards show concrete objects on one set and abstract emotion icons on another. Students use sorting mat with "AI Can Draw" and "AI Cannot Draw Yet" headers. **Key insight:** AI can draw things we see but struggles with feelings and ideas.
Activity Type: Unplugged sorting
Estimated Time: 3-4 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.01: Sort picture cards by real photos vs computer-made images




ID: T20.GK.04
Topic: T20 – AI Media
Skill: Match computer voices to different helper devices
Description: **Student task:** Listen to 5 short voice clips and match each to picture cards of devices (phone, tablet, robot toy, smart speaker, talking GPS). **Visual scenario:** Teacher plays audio clips of AI voices saying simple phrases. Students place numbered tokens on picture cards showing which device made which sound. Audio clips demonstrate different voice styles (friendly, robotic, helpful). **Key insight:** Computers can talk using different voices to help us.
Activity Type: Audio matching
Estimated Time: 3-4 minutes
CSTA: 1A-CS-01

Dependencies: None




ID: T20.GK.05
Topic: T20 – AI Media
Skill: Sort activities by human-only vs AI-can-help
Description: **Student task:** Sort 12 activity cards into two piles: things only people can do (hug someone, taste food, feel happy, play with friends) and things AI can help with (draw pictures, make sounds, answer questions, play music). **Visual scenario:** Cards show illustrated scenarios of activities. Students use a sorting mat with two columns and discuss their choices with a partner. **Key insight:** Some things need real people, but AI can help us with other tasks.
Activity Type: Unplugged sorting
Estimated Time: 4-5 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.03: Sort things AI can draw vs things AI cannot draw




ID: T20.GK.06
Topic: T20 – AI Media
Skill: Debug AI picture mistakes by finding wrong details
Description: **Student task:** Find 3 mistakes in each of 4 AI-generated pictures (dog with 5 legs, car with square wheels, person with hand on wrong arm, house with upside-down door). **Visual scenario:** Large picture cards show AI-generated images with obvious errors. Students use red dot stickers to mark mistakes and explain what's wrong. Answer cards show correct versions. **Key insight:** AI sometimes makes mistakes when creating pictures, and people need to check them.
Activity Type: Error detection
Estimated Time: 4-5 minutes
CSTA: 1A-AP-14

Dependencies:
* T20.GK.01: Sort picture cards by real photos vs computer-made images
* T20.GK.02: Match word cards to AI-generated pictures




ID: T20.GK.07
Topic: T20 – AI Media
Skill: Match safe-sharing symbols to AI picture scenarios
Description: **Student task:** Match 6 safe-sharing symbol cards (checkmark for OK, X for not OK) to scenarios showing kids sharing AI pictures (show to teacher=OK, post online alone=not OK, share with parent=OK, send to strangers=not OK). **Visual scenario:** Scenario cards show illustrated situations of children with AI-generated content. Students place green checkmarks or red X cards on each scenario. **Key insight:** We need grown-up permission before sharing AI pictures outside our classroom.
Activity Type: Safety sorting
Estimated Time: 3-4 minutes
CSTA: 1A-IC-18

Dependencies:
* T20.GK.01: Sort picture cards by real photos vs computer-made images




ID: T20.GK.08
Topic: T20 – AI Media
Skill: Predict what picture AI will make from simple word combinations
Description: **Student task:** Look at 2-word combination cards (blue dog, big tree, small car, happy sun) and choose from 3 picture options what the AI would create. **Visual scenario:** Word cards show simple adjective-noun combinations. Students see 3 picture choices and circle the most likely AI output based on the words given. Self-checking answer key on card backs. **Key insight:** AI follows the words we give it to make pictures.
Activity Type: Prediction
Estimated Time: 3-4 minutes
CSTA: 1A-AP-10

Dependencies:
* T20.GK.02: Match word cards to AI-generated pictures


## GRADE 1 (8 skills)




ID: T20.G1.01
Topic: T20 – AI Media
Skill: Compare photo elements vs AI-generated image elements
Description: **Student task:** Examine 6 paired cards (real photo next to AI version of same subject) and find 3 differences in each pair using observation checklist (lighting, shadows, background detail, texture). **Visual scenario:** Large paired cards show side-by-side comparisons (real cat photo vs AI cat, real park vs AI park). Students mark differences on printed checklist with provided categories. **Key insight:** AI images and real photos have different qualities we can learn to notice.
Activity Type: Comparison analysis
Estimated Time: 4-5 minutes
CSTA: 1A-CS-01

Dependencies:
* T20.GK.01: Sort picture cards by real photos vs computer-made images




ID: T20.G1.02
Topic: T20 – AI Media
Skill: Sequence word cards to create specific AI picture instructions
Description: **Student task:** Arrange 4-5 word cards in order to create clear instructions for AI (color + size + object + location). **Visual scenario:** Students have word card sets (red, small, dog, park) and arrange them in sequence boxes numbered 1-4. They compare their sequence to example AI outputs showing what happens with different word orders. Includes 5 different scenarios to practice. **Key insight:** The order and choice of words affects what picture AI creates.
Activity Type: Sequencing
Estimated Time: 4-5 minutes
CSTA: 1A-AP-11

Dependencies:
* T20.GK.02: Match word cards to AI-generated pictures
* T20.GK.08: Predict what picture AI will make from simple word combinations




ID: T20.G1.03
Topic: T20 – AI Media
Skill: Detect AI-generated image errors in realistic scenarios
Description: **Student task:** Examine 5 AI-generated images of everyday scenes and mark errors using error type cards (wrong body parts, impossible physics, mixed-up objects, incorrect counting). **Visual scenario:** Cards show AI images with subtle mistakes (person with extra fingers, reflection that doesn't match, bicycle with uneven wheels). Students place error-type labels on detected problems. **Key insight:** AI can make realistic-looking pictures that have mistakes we need to spot.
Activity Type: Error detection
Estimated Time: 5 minutes
CSTA: 1A-AP-14

Dependencies:
* T20.GK.06: Debug AI picture mistakes by finding wrong details




ID: T20.G1.04
Topic: T20 – AI Media
Skill: Explain why detected AI image errors happened
Description: **Student task:** For 4 AI images with marked errors, match explanation cards describing why the error occurred (AI doesn't understand hands, AI mixed training images, AI doesn't know real physics). **Visual scenario:** Building on detected errors from previous skill, students now select from explanation cards showing simple reasons for each type of mistake. Uses same error images but focuses on the "why" rather than detection. **Key insight:** AI makes predictable types of mistakes because of how it learns from pictures.
Activity Type: Explanation matching
Estimated Time: 4-5 minutes
CSTA: 1A-AP-14

Dependencies:
* T20.G1.03: Detect AI-generated image errors in realistic scenarios




ID: T20.G1.05
Topic: T20 – AI Media
Skill: Distinguish human voices from AI-generated voices
Description: **Student task:** Listen to 10 short audio clips (5 human, 5 AI) and sort numbered tokens into "Human Voice" or "AI Voice" categories based on voice qualities. **Visual scenario:** Teacher plays audio clips of people and AI saying the same sentences. Students listen for clues (breathing sounds, natural pauses, emotion variation, slight imperfections) and place tokens on sorting mat. Includes discussion guide for checking answers. **Key insight:** AI voices sound almost real but have small differences we can learn to hear.
Activity Type: Audio sorting
Estimated Time: 5 minutes
CSTA: 1A-CS-01

Dependencies:
* T20.GK.04: Match computer voices to different helper devices




ID: T20.G1.06
Topic: T20 – AI Media
Skill: Match emotion words to tasks only humans can do
Description: **Student task:** Connect 8 emotion/creativity cards (feeling proud, caring for someone, being creative, making a friend laugh) to 8 task cards showing why humans are needed (art needs feeling, helping needs caring, jokes need understanding). **Visual scenario:** Students draw lines or place strings connecting emotion cards to specific task examples. Each task card shows an illustrated scenario requiring human qualities. Includes self-checking answer guide. **Key insight:** Creative and emotional tasks need real human feelings that AI doesn't have.
Activity Type: Matching
Estimated Time: 4-5 minutes
CSTA: 1A-IC-16

Dependencies:
* T20.GK.03: Sort things AI can draw vs things AI cannot draw
* T20.GK.05: Sort activities by human-only vs AI-can-help




ID: T20.G1.07
Topic: T20 – AI Media
Skill: Find private information in AI-generated content before sharing
Description: **Student task:** Review 6 AI-generated images showing classroom scenarios and mark with red dots any private information visible (names, faces, addresses, school names). **Visual scenario:** Picture cards show AI images that students might create (class photo, birthday invitation, house drawing). Students use red sticker dots to cover private details and green checkmarks for safe content. Includes privacy checklist card. **Key insight:** Even AI-generated pictures can show private information we shouldn't share.
Activity Type: Privacy check
Estimated Time: 5 minutes
CSTA: 1A-IC-18

Dependencies:
* T20.GK.07: Match safe-sharing symbols to AI picture scenarios




ID: T20.G1.08
Topic: T20 – AI Media
Skill: Sort sharing scenarios by permission level needed
Description: **Student task:** Sort 10 scenario cards into 3 permission categories (no permission needed, ask teacher, ask parent/guardian) based on what's being shared and where. **Visual scenario:** Cards show specific situations (showing AI picture to classmate, posting AI video online, printing AI image for home, emailing AI creation to grandparent). Students place cards in 3 zones on sorting mat and explain reasoning. **Key insight:** Different ways of sharing AI content need different levels of permission from adults.
Activity Type: Permission sorting
Estimated Time: 5 minutes
CSTA: 1A-IC-18

Dependencies:
* T20.G1.07: Find private information in AI-generated content before sharing
* T20.GK.07: Match safe-sharing symbols to AI picture scenarios


## GRADE 2 (8 skills)




ID: T20.G2.01
Topic: T20 – AI Media
Skill: Analyze training data to predict AI image output
Description: **Student task:** Examine 8 training image cards showing what AI learned from (all dogs are golden retrievers, all cars are red, all trees have leaves) and predict what the AI will create when asked for "dog", "car", or "tree". **Visual scenario:** Students see sets of training images grouped by category, then choose from 3 possible output predictions. Includes explanation cards showing how limited training creates limited outputs. 4 different scenarios to analyze. **Key insight:** AI creates images based on patterns in pictures it learned from, so training data affects outputs.
Activity Type: Prediction analysis
Estimated Time: 5 minutes
CSTA: 1B-AP-10

Dependencies:
* T20.G1.01: Compare photo elements vs AI-generated image elements
* T20.G1.02: Sequence word cards to create specific AI picture instructions




ID: T20.G2.02
Topic: T20 – AI Media
Skill: Create detailed word sequences for complex AI images
Description: **Student task:** Build 6-8 word instruction sequences using provided word cards (adjectives, nouns, actions, locations, styles) to create specific complex images. **Visual scenario:** Students have expanded word card sets organized by category (colors, sizes, objects, places, art styles). They arrange cards in sequence frames to build detailed prompts like "large blue robot dancing in city park cartoon style". Includes 4 target images to recreate through word sequencing. **Key insight:** More detailed and specific word instructions help AI create images closer to what we want.
Activity Type: Prompt building
Estimated Time: 5 minutes
CSTA: 1B-AP-11

Dependencies:
* T20.G1.02: Sequence word cards to create specific AI picture instructions




ID: T20.G2.03
Topic: T20 – AI Media
Skill: Debug word sequences when AI output doesn't match intent
Description: **Student task:** Given 5 word sequences and their unexpected AI outputs, identify which words caused the problem and suggest replacement words. **Visual scenario:** Cards show original word sequence, the AI's output image, and the intended output image. Students circle problematic words and select better word choices from provided options. Includes common issues like ambiguous words, conflicting descriptions, or missing key details. **Key insight:** When AI creates wrong images, we can fix our word instructions to get better results.
Activity Type: Debugging
Estimated Time: 5 minutes
CSTA: 1B-AP-14

Dependencies:
* T20.G2.02: Create detailed word sequences for complex AI images




ID: T20.G2.04
Topic: T20 – AI Media
Skill: Compare AI voice qualities across different applications
Description: **Student task:** Listen to 6 different AI voices (GPS navigation, audiobook reader, voice assistant, character voice, translation voice, accessibility reader) and match each to its best use case card. **Visual scenario:** Teacher plays audio samples of different AI voice types. Students have application cards showing when each voice type works best and match voices to uses. Includes characteristic cards (clear/fast, expressive/slow, friendly/helpful) to describe each voice. **Key insight:** Different AI voices are designed for different purposes and have different strengths.
Activity Type: Audio analysis
Estimated Time: 5 minutes
CSTA: 1B-CS-01

Dependencies:
* T20.G1.05: Distinguish human voices from AI-generated voices




ID: T20.G2.05
Topic: T20 – AI Media
Skill: Sort tasks requiring human creativity vs AI assistance
Description: **Student task:** Sort 12 creative task cards into 3 categories: needs human creativity, AI can assist humans, AI can do independently. **Visual scenario:** Task cards show activities (write a poem about friendship, resize a photo, choose a birthday gift for friend, remove photo background, paint feelings, generate stock image). Students place cards in 3-column sorting mat and justify choices using reasoning cards. **Key insight:** Some creative tasks need human feelings and choices, while AI can help with technical parts.
Activity Type: Creativity sorting
Estimated Time: 5 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G1.06: Match emotion words to tasks only humans can do




ID: T20.G2.06
Topic: T20 – AI Media
Skill: Predict consequences of sharing AI content in different contexts
Description: **Student task:** Given 8 sharing scenario cards, predict and match consequence cards (positive, neutral, negative outcomes) explaining what might happen. **Visual scenario:** Scenario cards show situations like posting AI art claiming it's hand-drawn, sharing AI images without labeling them as AI-made, using AI voice for school project without permission. Students match to outcome cards and discuss reasoning. **Key insight:** How we share and label AI content affects trust and follows rules about honesty.
Activity Type: Consequence prediction
Estimated Time: 5 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G1.08: Sort sharing scenarios by permission level needed




ID: T20.G2.07
Topic: T20 – AI Media
Skill: Evaluate AI-generated images for bias in representation
Description: **Student task:** Examine 6 sets of AI-generated images for common subjects (doctors, teachers, engineers, nurses, chefs, scientists) and identify if all images show diversity or show bias patterns. **Visual scenario:** Each set has 4 AI images for same profession. Students use diversity checklist cards (gender, age, race, ability) to mark whether images show variety or patterns. Includes comparison cards showing balanced vs biased sets. **Key insight:** AI sometimes creates biased images based on biased training data, and we should notice these patterns.
Activity Type: Bias detection
Estimated Time: 5 minutes
CSTA: 1B-IC-20

Dependencies:
* T20.G2.01: Analyze training data to predict AI image output
* T20.G1.01: Compare photo elements vs AI-generated image elements




ID: T20.G2.08
Topic: T20 – AI Media
Skill: Create sharing permission checklist for AI media projects
Description: **Student task:** Build a decision flowchart using 10 question cards to determine if AI content is ready to share (Is it labeled as AI? Does it show private info? Do you have permission? Is it appropriate? Is it honest?). **Visual scenario:** Students arrange question cards in logical order on a flowchart mat with yes/no paths leading to "OK to share," "Ask adult first," or "Don't share" endpoints. Test flowchart with 5 example scenarios. **Key insight:** Following a checklist helps us make safe and responsible decisions about sharing AI content.
Activity Type: Checklist creation
Estimated Time: 5 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G2.06: Predict consequences of sharing AI content in different contexts
* T20.G1.07: Find private information in AI-generated content before sharing


## GRADE 3 (10 skills)




ID: T20.G3.01
Topic: T20 – AI Media
Skill: Distinguish AI-generated images from human-created images using visual clues
Description: Students examine pairs of images (one AI-generated, one human-created) and identify which is which based on observable characteristics. They list specific visual clues such as distorted hands, unusual textures, impossible reflections, or unnatural lighting. Students categorize these clues into categories like "anatomy errors," "lighting problems," and "background inconsistencies." This foundational skill builds critical evaluation abilities needed for analyzing AI media outputs.
Activity Type: Analysis
Estimated Time: 15-20 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G1.01: Compare photo elements vs AI-generated image elements
* T20.G1.03: Detect AI-generated image errors in realistic scenarios




ID: T20.G3.02
Topic: T20 – AI Media
Skill: Label components of an AI image generation pipeline
Description: Students receive a visual diagram showing the basic pipeline of text-to-image AI systems with unlabeled boxes and arrows. They label each component: "text prompt input," "AI processing," "image output," and "feedback/revision." Students match simple explanations to each stage, such as "where you type what you want" or "where the AI creates the picture." They trace the flow from start to finish using arrows to show how information moves through the system.
Activity Type: Diagram
Estimated Time: 10-15 minutes
CSTA: 1B-AP-08

Dependencies:
* T20.G2.01: Analyze training data to predict AI image output




ID: T20.G3.03
Topic: T20 – AI Media
Skill: Complete template-based prompts for AI image generation
Description: Students use pre-designed prompt templates with fill-in-the-blank sections to create complete image generation prompts. Templates provide structure like "[subject] in [location] during [time of day] with [mood/style]." Students select appropriate words from provided word banks to fill each blank, ensuring the completed prompt makes logical sense. They compare how different word choices create different mental images and predict what the AI might generate from their completed prompts.
Activity Type: Template completion
Estimated Time: 15-20 minutes
CSTA: 1B-AP-11

Dependencies:
* T20.G2.02: Create detailed word sequences for complex AI images
* T20.G3.02: Label components of an AI image generation pipeline




ID: T20.G3.04
Topic: T20 – AI Media
Skill: Predict which text-to-image prompts will produce better results
Description: Students examine pairs of prompts for the same general idea (e.g., "a dog" vs. "a golden retriever puppy playing in a sunny park") and predict which will produce a better AI image. They justify their predictions by identifying specific, descriptive words versus vague, general words. Students create a checklist of "good prompt qualities" including specificity, clear descriptions, and concrete details. They apply this checklist to evaluate and rank additional prompts from best to worst.
Activity Type: Prediction
Estimated Time: 15-20 minutes
CSTA: 1B-AP-14

Dependencies:
* T20.G3.03: Complete template-based prompts for AI image generation
* T20.G2.03: Debug word sequences when AI output doesn't match intent




ID: T20.G3.05
Topic: T20 – AI Media
Skill: Categorize AI media types by input and output
Description: Students sort different AI media tools into categories based on what they take as input and what they produce as output. Categories include text-to-image, text-to-audio, image-to-text, and audio-to-text. They receive cards describing various AI tools and place them in a grid organized by input type (columns) and output type (rows). Students identify patterns such as "AI can transform between different media types" and discuss real-world applications for each category.
Activity Type: Categorization
Estimated Time: 15-20 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G3.02: Label components of an AI image generation pipeline
* T20.G2.04: Compare AI voice qualities across different applications




ID: T20.G3.06
Topic: T20 – AI Media
Skill: Flag unsafe information in AI media prompts
Description: Students review example prompts for AI image and audio generation and flag those containing private information, inappropriate content, or personally identifiable details. They use a simple safety checklist covering categories like "full names," "addresses," "private photos," and "inappropriate requests." Students rewrite flagged prompts to remove unsafe elements while maintaining the creative intent. They discuss why protecting privacy matters when using AI tools and create a classroom "safe prompting" poster.
Activity Type: Safety analysis
Estimated Time: 20-25 minutes
CSTA: 1B-IC-21

Dependencies:
* T20.G2.08: Create sharing permission checklist for AI media projects
* T20.G3.03: Complete template-based prompts for AI image generation




ID: T20.G3.07
Topic: T20 – AI Media
Skill: Trace the text-to-speech generation pipeline step-by-step
Description: Students follow a simplified diagram of text-to-speech AI systems and trace each step from text input to audio output. They label stages including "text analysis," "pronunciation selection," "voice synthesis," and "audio output." For each stage, students describe in simple terms what happens (e.g., "the AI breaks words into sounds" or "the AI chooses how to say each word"). They identify where human choices matter, such as selecting voice characteristics or adjusting speed.
Activity Type: Diagram tracing
Estimated Time: 15-20 minutes
CSTA: 1B-AP-08

Dependencies:
* T20.G3.02: Label components of an AI image generation pipeline
* T20.G2.04: Compare AI voice qualities across different applications




ID: T20.G3.08
Topic: T20 – AI Media
Skill: Evaluate AI-generated images for quality and accuracy
Description: Students assess AI-generated images using a simple rubric with criteria such as "matches the prompt," "realistic details," "no obvious errors," and "appropriate composition." They rate each image on a 1-3 scale for each criterion and calculate a total quality score. Students identify specific strengths (e.g., "beautiful colors," "correct number of objects") and weaknesses (e.g., "distorted fingers," "blurry background"). They discuss how evaluation helps users decide whether to accept, revise, or regenerate AI outputs.
Activity Type: Rubric evaluation
Estimated Time: 20-25 minutes
CSTA: 1B-IC-18

Dependencies:
* T20.G3.01: Distinguish AI-generated images from human-created images using visual clues
* T20.G3.04: Predict which text-to-image prompts will produce better results
* T20.G2.07: Evaluate AI-generated images for bias in representation




ID: T20.G3.09
Topic: T20 – AI Media
Skill: Match prompt modifications to expected changes in AI images
Description: Students receive a base prompt and several modified versions with one change each (e.g., changing time of day, adding weather, switching location). They predict how each modification will change the resulting AI image by drawing or describing the expected difference. Students match "before and after" image pairs showing actual AI outputs to the corresponding prompt modifications. They identify which types of prompt changes create dramatic visual differences versus subtle adjustments.
Activity Type: Prediction matching
Estimated Time: 20-25 minutes
CSTA: 1B-AP-14

Dependencies:
* T20.G3.04: Predict which text-to-image prompts will produce better results
* T20.G3.08: Evaluate AI-generated images for quality and accuracy




ID: T20.G3.10
Topic: T20 – AI Media
Skill: Construct multi-stage improvement plans for failed AI image outputs
Description: Students analyze AI-generated images that failed to match their prompts and create step-by-step improvement plans. They identify the specific problems (e.g., "missing object," "wrong color," "incorrect setting"), prioritize which to fix first, and write revised prompts addressing each issue. Students organize their plans using numbered steps showing the progression from original prompt to first revision to final revision. They explain why each revision should improve the output and predict the cumulative effect of all changes.
Activity Type: Revision planning
Estimated Time: 25-30 minutes
CSTA: 1B-AP-11

Dependencies:
* T20.G3.08: Evaluate AI-generated images for quality and accuracy
* T20.G3.09: Match prompt modifications to expected changes in AI images


## GRADE 4 (12 skills)




ID: T20.G4.01
Topic: T20 – AI Media
Skill: Analyze how prompt specificity affects AI image generation accuracy
Description: Students conduct structured comparisons of AI outputs from prompts with varying levels of specificity. They create a spectrum from "vague" to "highly specific" and place example prompts along this spectrum, then examine corresponding AI outputs. Students quantify specificity by counting descriptive adjectives, concrete nouns, and contextual details in each prompt. They graph the relationship between specificity score and output quality score, identifying the threshold where additional details stop improving results. Students document patterns such as "more details usually helps, but too many can confuse the AI."
Activity Type: Comparative analysis
Estimated Time: 25-30 minutes
CSTA: 2-AP-10

Dependencies:
* T20.G3.04: Predict which text-to-image prompts will produce better results
* T20.G3.08: Evaluate AI-generated images for quality and accuracy




ID: T20.G4.02
Topic: T20 – AI Media
Skill: Trace the flow of data through multi-stage AI media pipelines
Description: Students follow complex AI media workflows involving multiple processing stages, such as text-to-image-to-description-to-revised-image. They create flowcharts showing each transformation step, labeling what type of data enters and exits each stage (text, image, audio, structured data). Students identify feedback loops where outputs become new inputs. They analyze how errors or quality issues at early stages propagate through the pipeline and discuss checkpoint strategies for quality control at each stage.
Activity Type: Data flow tracing
Estimated Time: 25-30 minutes
CSTA: 2-AP-12

Dependencies:
* T20.G3.02: Label components of an AI image generation pipeline
* T20.G3.07: Trace the text-to-speech generation pipeline step-by-step




ID: T20.G4.03
Topic: T20 – AI Media
Skill: Debug prompts by isolating problematic components
Description: Students receive complex multi-element prompts that produce unexpected results and systematically isolate which components cause problems. They use a binary search debugging strategy: test the prompt with half the elements, then narrow down further based on results. Students document their debugging process showing which elements were tested in each iteration and how they identified the problematic component. They explain why each problematic element created issues (ambiguity, conflict with other elements, impossible request).
Activity Type: Systematic debugging
Estimated Time: 30-35 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G3.10: Construct multi-stage improvement plans for failed AI image outputs
* T20.G3.04: Predict which text-to-image prompts will produce better results




ID: T20.G4.04
Topic: T20 – AI Media
Skill: Evaluate safety implications of AI-generated media in context
Description: Students analyze case studies where AI-generated media could create safety, privacy, or ethical concerns. For each scenario, they identify potential risks (misidentification, misinformation, privacy violations, bias reinforcement), assess severity, and propose mitigation strategies. Students distinguish between technical safeguards (content filters, watermarks) and social safeguards (policies, education, oversight). They create decision trees for determining when AI-generated media requires additional review or should not be created.
Activity Type: Case study analysis
Estimated Time: 30-35 minutes
CSTA: 2-IC-21

Dependencies:
* T20.G3.06: Flag unsafe information in AI media prompts
* T20.G3.08: Evaluate AI-generated images for quality and accuracy




ID: T20.G4.05
Topic: T20 – AI Media
Skill: Compare training data diversity to output representation
Description: Students examine training datasets for AI image generators and correlate dataset characteristics with bias patterns in outputs. They quantify representation in training data (counting examples by category) and compare to output distributions when generating similar content. Students graph these relationships and identify underrepresented categories that lead to poor or biased results. They propose specific training data additions that would improve representation and predict how outputs would change.
Activity Type: Data analysis
Estimated Time: 30-35 minutes
CSTA: 2-DA-08

Dependencies:
* T20.G3.01: Distinguish AI-generated images from human-created images using visual clues
* T20.G2.07: Evaluate AI-generated images for bias in representation




ID: T20.G4.06
Topic: T20 – AI Media
Skill: Predict resource requirements for AI media generation tasks
Description: Students compare different AI media generation tasks and predict which will require more computational resources and time. They consider factors like output resolution, prompt complexity, number of generation steps, and media type. Students rank tasks from least to most resource-intensive and match tasks to appropriate use cases (quick draft, final production, real-time application). They explain trade-offs between quality, speed, and computational cost.
Activity Type: Prediction and comparison
Estimated Time: 20-25 minutes
CSTA: 2-AP-11

Dependencies:
* T20.G3.05: Categorize AI media types by input and output
* T20.G4.01: Analyze how prompt specificity affects AI image generation accuracy




ID: T20.G4.07
Topic: T20 – AI Media
Skill: Evaluate prompt strategies across multiple generation attempts
Description: Students test different prompting strategies (adding style keywords, using negation, specifying perspective, adding quality modifiers) across multiple generation attempts for the same goal. They document results systematically, noting which strategies improve consistency, which reduce errors, and which have unpredictable effects. Students calculate success rates for each strategy and create evidence-based recommendations for when to use each approach. They distinguish between strategies that improve average quality versus those that improve consistency.
Activity Type: Experimental evaluation
Estimated Time: 35-40 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G4.01: Analyze how prompt specificity affects AI image generation accuracy
* T20.G3.09: Match prompt modifications to expected changes in AI images




ID: T20.G4.08
Topic: T20 – AI Media
Skill: Design accessibility improvements for AI-generated media
Description: Students evaluate AI-generated images, audio, and video for accessibility barriers and propose improvements. They apply accessibility criteria such as color contrast, alt text availability, caption accuracy, and screen reader compatibility. Students redesign prompts to generate more accessible content from the start (requesting high contrast, clear composition, simple layouts). They create accessibility checklists specific to AI-generated media and explain how AI tools can both help and hinder accessibility goals.
Activity Type: Design and evaluation
Estimated Time: 30-35 minutes
CSTA: 2-IC-22

Dependencies:
* T20.G4.04: Evaluate safety implications of AI-generated media in context
* T20.G3.08: Evaluate AI-generated images for quality and accuracy




ID: T20.G4.09
Topic: T20 – AI Media
Skill: Construct iterative refinement workflows for complex AI outputs
Description: Students design multi-step workflows for creating complex AI media that requires iterative refinement. They map out decision points where human evaluation determines next steps (regenerate, adjust prompt, accept and refine, start over). Students create flowcharts showing different paths through the refinement process based on evaluation results. They specify evaluation criteria at each checkpoint and define "done" conditions. Students test their workflows with actual AI generation tasks and refine the workflow based on results.
Activity Type: Workflow design
Estimated Time: 35-40 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G4.07: Evaluate prompt strategies across multiple generation attempts
* T20.G4.02: Trace the flow of data through multi-stage AI media pipelines




ID: T20.G4.10
Topic: T20 – AI Media
Skill: Detect bias patterns in AI media across demographic categories
Description: Students systematically test AI image generators for bias by creating matched prompts across demographic categories (varying gender, race, age, ability) for professional roles, activities, and settings. They document patterns in representation, quality, and stereotyping. Students quantify bias by counting occurrences and rating stereotype intensity. They compare bias patterns across different AI tools and explain how training data and design choices create these patterns. Students propose specific prompting strategies to counteract identified biases.
Activity Type: Bias detection
Estimated Time: 35-40 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G4.05: Compare training data diversity to output representation
* T20.G2.07: Evaluate AI-generated images for bias in representation




ID: T20.G4.11
Topic: T20 – AI Media
Skill: Analyze failure modes in AI voice synthesis
Description: Students examine cases where text-to-speech AI produces poor results and categorize failure modes (pronunciation errors, unnatural rhythm, wrong emphasis, emotional mismatch, accent issues). They identify patterns in what types of text cause problems (technical terms, names, multiple languages, punctuation-heavy text). Students design input text modifications that work around identified limitations. They compare different TTS systems and document which failure modes each system handles better or worse.
Activity Type: Failure analysis
Estimated Time: 25-30 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G3.07: Trace the text-to-speech generation pipeline step-by-step
* T20.G4.03: Debug prompts by isolating problematic components




ID: T20.G4.12
Topic: T20 – AI Media
Skill: Evaluate trade-offs in AI media generation parameter choices
Description: Students experiment with AI generation parameters (creativity/temperature, quality/steps, style strength, guidance scale) and document how each affects outputs. They create comparison matrices showing parameter settings versus outcome characteristics (creativity, consistency, quality, generation time). Students identify parameter combinations suitable for different use cases (exploration vs. production, speed vs. quality, consistency vs. variety). They explain the computational and practical trade-offs involved in different parameter choices.
Activity Type: Parameter evaluation
Estimated Time: 30-35 minutes
CSTA: 2-AP-11

Dependencies:
* T20.G4.06: Predict resource requirements for AI media generation tasks
* T20.G4.07: Evaluate prompt strategies across multiple generation attempts


## GRADE 5 (16 skills)




ID: T20.G5.01
Topic: T20 – AI Media
Skill: Generate images using CreatiCode DALL-E blocks with text prompts
Description: Students use CreatiCode's "generate image from [text]" block to create AI images from text descriptions. They write prompts in the block, trigger image generation, and observe results displayed in their project. Students experiment with different prompt phrasings for the same concept and compare outputs. They document how word choice affects generation results. Students create a gallery project showcasing 5-8 AI-generated images with their corresponding prompts displayed as captions.
Activity Type: Block-based coding
Estimated Time: 35-40 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G4.01: Analyze how prompt specificity affects AI image generation accuracy
* T20.G3.03: Complete template-based prompts for AI image generation
* T03.G5.04: Coordinate sprite positioning relative to stage boundaries




ID: T20.G5.02
Topic: T20 – AI Media
Skill: Debug image generation failures using error message analysis
Description: Students encounter and resolve common DALL-E generation errors in CreatiCode (content policy violations, network timeouts, unclear prompts, size limitations). They read error messages, identify the problem category, and apply appropriate fixes. Students create an error troubleshooting guide documenting each error type, its likely cause, and solution strategies. They test edge cases deliberately to trigger different errors and practice systematic debugging. Students explain how error messages guide the debugging process.
Activity Type: Debugging
Estimated Time: 30-35 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T20.G4.03: Debug prompts by isolating problematic components




ID: T20.G5.03
Topic: T20 – AI Media
Skill: Implement parameter-based prompt variations in loops
Description: Students use CreatiCode loops with join blocks to generate multiple AI images from systematically varied prompts. They create variables for prompt components (subject, setting, style) and use join blocks to combine them with fixed text. Students nest loops to explore combinations (e.g., each subject in each setting). They collect generated images in a list and display them in a grid layout. Students analyze which parameter variations create the most significant visual changes.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-11

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T03.G5.07: Debug sprite cloning logic errors in interactive applications
* T01.G5.02: Debug complex nested loops with multiple variables




ID: T20.G5.04
Topic: T20 – AI Media
Skill: Create voice output using text-to-speech blocks with parameter control
Description: Students use CreatiCode's text-to-speech blocks to convert text to spoken audio. They experiment with voice parameters (voice type, speed, pitch) and observe how each affects output quality and character. Students create interactive projects where sprites speak using TTS, such as character dialogue or narrated stories. They synchronize TTS timing with sprite animations using wait blocks. Students compare TTS voices for different use cases (narrator, character, instructions).
Activity Type: Block-based coding
Estimated Time: 35-40 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G4.11: Analyze failure modes in AI voice synthesis
* T03.G5.03: Synchronize sprite animations with sound playback timing




ID: T20.G5.05
Topic: T20 – AI Media
Skill: Implement user-input-driven prompt generation systems
Description: Students create projects where users input parameters via ask blocks, and the program constructs AI image prompts from these inputs. They use join blocks to combine user inputs with template text, validate inputs for appropriateness, and generate images based on the constructed prompts. Students add error handling for inappropriate or nonsensical inputs. They create user interfaces with clear instructions and display both the constructed prompt and resulting image. Students test with various user inputs to ensure robustness.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G5.03: Implement parameter-based prompt variations in loops
* T02.G5.04: Validate user inputs to prevent runtime errors
* T01.G5.05: Implement complex conditional logic with multiple AND/OR conditions




ID: T20.G5.06
Topic: T20 – AI Media
Skill: Detect AI-generated content hallucinations in image descriptions
Description: Students generate AI images from prompts, then use AI image-description tools to describe the generated images back to text. They compare the original prompt with the AI-generated description to identify "hallucinations" (details in the description that weren't in the prompt or aren't in the image). Students categorize hallucination types (added objects, incorrect attributes, fabricated relationships, misidentified elements). They document patterns in what types of hallucinations occur frequently and discuss implications for trusting AI-generated descriptions.
Activity Type: Analysis
Estimated Time: 30-35 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T20.G4.01: Analyze how prompt specificity affects AI image generation accuracy




ID: T20.G5.07
Topic: T20 – AI Media
Skill: Evaluate AI image quality using multi-criteria rubrics
Description: Students create and apply detailed rubrics for evaluating AI-generated images across criteria: prompt alignment, technical quality, composition, realism/style appropriateness, and usability for intended purpose. They assign scores for each criterion and calculate overall ratings. Students compare ratings across multiple generation attempts for the same prompt and identify which criteria show most variation. They use rubric results to decide whether to accept, regenerate, or refine prompts. Students explain how systematic evaluation improves decision-making.
Activity Type: Rubric evaluation
Estimated Time: 35-40 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T20.G4.07: Evaluate prompt strategies across multiple generation attempts
* T20.G3.08: Evaluate AI-generated images for quality and accuracy




ID: T20.G5.08
Topic: T20 – AI Media
Skill: Implement content moderation checks for user-generated prompts
Description: Students create projects with user-driven AI image generation that include content moderation. They build filter systems checking for inappropriate keywords, validate input length and format, and provide clear feedback when prompts are rejected. Students use conditional logic to categorize prompts as safe, questionable, or unsafe. They design user-friendly error messages explaining why prompts were rejected without revealing the complete filter logic. Students test filter effectiveness and adjust for false positives and false negatives.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G5.05: Implement user-input-driven prompt generation systems
* T20.G4.04: Evaluate safety implications of AI-generated media in context
* T02.G5.04: Validate user inputs to prevent runtime errors




ID: T20.G5.09
Topic: T20 – AI Media
Skill: Create comparative galleries showing prompt iteration effects
Description: Students build projects that generate and display multiple images showing the evolution of a prompt through iterations. They use lists to store both prompts and generated images, create grid layouts to display images side-by-side, and add text labels showing how each prompt differs from the previous version. Students implement navigation controls to browse through iteration sequences. They document which types of changes (style words, detail additions, composition instructions) produce visible improvements versus negligible changes.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-12

Dependencies:
* T20.G5.03: Implement parameter-based prompt variations in loops
* T04.G5.06: Manipulate lists with insert, delete, and replace operations
* T03.G5.04: Coordinate sprite positioning relative to stage boundaries




ID: T20.G5.10
Topic: T20 – AI Media
Skill: Trace data transformations in text-to-speech-to-text pipelines
Description: Students create projects that convert text to speech using TTS blocks, then use speech recognition to convert the audio back to text. They compare original text with the final transcribed text to identify information loss or errors. Students document where errors occur (pronunciation issues, recognition failures, ambiguous phonetics) and quantify accuracy rates. They experiment with text modifications (punctuation, formatting, word choice) to improve round-trip accuracy. Students explain why some information cannot survive the transformation cycle.
Activity Type: Data transformation analysis
Estimated Time: 35-40 minutes
CSTA: 2-AP-12

Dependencies:
* T20.G5.04: Create voice output using text-to-speech blocks with parameter control
* T20.G4.02: Trace the flow of data through multi-stage AI media pipelines




ID: T20.G5.11
Topic: T20 – AI Media
Skill: Implement adaptive prompting based on generation feedback
Description: Students create projects that automatically adjust prompts based on generation results. They use image description blocks to analyze generated images, extract key features, and modify prompts to correct missing or incorrect elements. Students implement feedback loops where each generation attempt informs the next prompt. They set iteration limits and define success criteria for stopping the refinement loop. Students document how many iterations are typically needed for different prompt types and explain why some prompts converge faster than others.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G5.06: Detect AI-generated content hallucinations in image descriptions
* T20.G5.03: Implement parameter-based prompt variations in loops
* T01.G5.08: Design custom blocks with parameters and return values




ID: T20.G5.12
Topic: T20 – AI Media
Skill: Debug timing issues in multi-media AI generation sequences
Description: Students create projects combining image generation, text-to-speech, and other AI media blocks in sequences. They encounter and resolve timing problems where operations complete at different speeds, causing synchronization issues. Students implement wait blocks with appropriate durations, use wait-until conditions for blocking operations, and add status indicators showing what's currently processing. They measure actual completion times for different operations and build timing models. Students explain why AI operations have variable completion times.
Activity Type: Debugging
Estimated Time: 35-40 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G5.04: Create voice output using text-to-speech blocks with parameter control
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T03.G5.03: Synchronize sprite animations with sound playback timing




ID: T20.G5.13
Topic: T20 – AI Media
Skill: Evaluate bias in AI-generated character representations
Description: Students systematically generate AI images of people in various roles and contexts, varying demographic descriptors (gender, race, age, profession). They document representation patterns, identify biases, and quantify disparities. Students create comparison charts showing how often different demographics appear in different roles. They test whether neutral prompts (not specifying demographics) produce diverse results or default to stereotypes. Students propose prompt modifications that counteract identified biases and test their effectiveness.
Activity Type: Bias analysis
Estimated Time: 40-45 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T20.G4.10: Detect bias patterns in AI media across demographic categories




ID: T20.G5.14
Topic: T20 – AI Media
Skill: Create accessible AI media projects with alternative content
Description: Students build AI media projects with built-in accessibility features. They add text descriptions for generated images using sprites with visible text or speech output, provide captions for any audio content, and ensure interactive elements work with keyboard controls. Students test their projects under accessibility constraints (no sound, no images) to verify alternative content works. They document which accessibility features are built into the AI tools versus what they must add manually.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-IC-22

Dependencies:
* T20.G5.04: Create voice output using text-to-speech blocks with parameter control
* T20.G4.08: Design accessibility improvements for AI-generated media
* T03.G5.06: Implement keyboard controls for sprite movement




ID: T20.G5.15
Topic: T20 – AI Media
Skill: Design prompt templates for consistent visual style across images
Description: Students create reusable prompt templates that maintain consistent visual style across multiple AI-generated images. They identify which prompt elements control style (art medium, artist reference, color palette, composition style) versus content (subject, setting, objects). Students use variables for content elements while keeping style elements constant. They generate image sets with consistent style but varying content, then evaluate style consistency using visual comparison. Students document which style descriptors produce most consistent results.
Activity Type: Template design
Estimated Time: 40-45 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G5.03: Implement parameter-based prompt variations in loops
* T20.G5.07: Evaluate AI image quality using multi-criteria rubrics




ID: T20.G5.16
Topic: T20 – AI Media
Skill: Implement retry logic for failed AI media operations
Description: Students create robust AI media projects with error handling and retry mechanisms. They use try-catch patterns (if-then blocks checking for errors) to detect generation failures, implement exponential backoff for retries (waiting longer between each attempt), and set maximum retry limits to prevent infinite loops. Students add user feedback showing retry status and allow manual cancellation. They test retry logic by deliberately triggering failures and verify appropriate behavior. Students explain when retry logic helps versus when it wastes resources.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G5.02: Debug image generation failures using error message analysis
* T20.G5.12: Debug timing issues in multi-media AI generation sequences
* T02.G5.06: Implement error handling and recovery strategies in programs


## GRADE 6 (20 skills)




ID: T20.G6.01
Topic: T20 – AI Media
Skill: Implement face detection using CreatiCode ML face blocks
Description: Students use CreatiCode's "detect faces in stage" block to identify faces in images or video. They extract face position data (x, y coordinates, width, height) and use this to draw rectangles highlighting detected faces. Students create projects that respond to the number of faces detected, track face positions as people move, and display face count. They test with various images to understand detection capabilities and limitations (angles, lighting, occlusion). Students explain how face detection differs from face recognition.
Activity Type: Block-based coding
Estimated Time: 35-40 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G5.01: Generate images using CreatiCode DALL-E blocks with text prompts
* T03.G6.05: Implement sprite pen drawing with dynamic color and size changes




ID: T20.G6.02
Topic: T20 – AI Media
Skill: Create interactive applications using body pose detection
Description: Students use CreatiCode's body tracking blocks to detect body poses and track key point positions (head, shoulders, elbows, wrists, hips, knees, ankles). They create interactive projects that respond to body movements, such as controlling sprites with arm positions, triggering actions based on poses, or creating movement-based games. Students implement position smoothing to reduce jitter and calibrate detection for different users. They document which poses detect most reliably and which are challenging.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T03.G6.03: Implement sprite following behaviors based on mouse or sprite positions




ID: T20.G6.03
Topic: T20 – AI Media
Skill: Debug edge cases in face detection applications
Description: Students systematically test face detection with challenging scenarios: multiple faces, partial faces, extreme angles, poor lighting, obstructions (glasses, masks, hands), and non-face images. They document detection success rates for each category and identify patterns in failures. Students modify their applications to handle edge cases gracefully (displaying appropriate messages, using last-known positions, adjusting sensitivity). They explain technical reasons why certain scenarios cause detection failures and propose application design strategies that work within detection limitations.
Activity Type: Debugging
Estimated Time: 40-45 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T20.G5.02: Debug image generation failures using error message analysis




ID: T20.G6.04
Topic: T20 – AI Media
Skill: Implement speech recognition for voice-controlled applications
Description: Students use CreatiCode speech recognition blocks to convert spoken words to text and create voice-controlled projects. They implement wake words or activation buttons, display recognized text in real-time, and use conditional logic to trigger actions based on spoken commands. Students handle recognition errors and ambiguities, implement timeout behaviors for no speech detected, and provide audio or visual feedback confirming recognition. They test recognition accuracy with different speakers, accents, and background noise levels.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G5.10: Trace data transformations in text-to-speech-to-text pipelines
* T20.G5.04: Create voice output using text-to-speech blocks with parameter control




ID: T20.G6.05
Topic: T20 – AI Media
Skill: Create multi-modal interfaces combining vision and voice AI
Description: Students build projects that use both computer vision (face/body detection) and voice AI (speech recognition/TTS) together. They create applications where users interact through multiple modalities, such as gesture-and-voice-controlled games or accessible interfaces offering visual and audio options. Students implement mode switching between input types, ensure consistency across modalities, and handle conflicts when multiple inputs occur simultaneously. They test which task types benefit most from multi-modal interfaces.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.04: Implement speech recognition for voice-controlled applications
* T20.G6.02: Create interactive applications using body pose detection




ID: T20.G6.06
Topic: T20 – AI Media
Skill: Evaluate generated images for deepfake warning signs
Description: Students examine AI-generated images of people to identify potential deepfake indicators: unnatural facial features, inconsistent lighting, artifacts around edges, mismatched reflections, impossible anatomy, background inconsistencies, and unusual texture patterns. They create a deepfake detection checklist and apply it to sample images. Students compare obviously fake images with subtle deepfakes and practice distinguishing quality issues from deliberate manipulation. They discuss why deepfake detection matters for media literacy and trust.
Activity Type: Analysis
Estimated Time: 35-40 minutes
CSTA: 2-IC-21

Dependencies:
* T20.G5.07: Evaluate AI image quality using multi-criteria rubrics
* T20.G4.10: Detect bias patterns in AI media across demographic categories
* T20.G3.01: Distinguish AI-generated images from human-created images using visual clues




ID: T20.G6.07
Topic: T20 – AI Media
Skill: Implement confidence threshold filtering for face detection
Description: Students add confidence score checking to face detection applications to filter unreliable detections. They access confidence values from detection results, set threshold values experimentally, and only process detections above the threshold. Students create UI showing both all detections and high-confidence-only views for comparison. They graph confidence distributions across different image types and choose appropriate thresholds for different use cases (high recall vs. high precision). Students explain the precision-recall trade-off in threshold selection.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-AP-11

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T20.G6.03: Debug edge cases in face detection applications




ID: T20.G6.08
Topic: T20 – AI Media
Skill: Create data visualizations for body tracking over time
Description: Students use body tracking data to create visualizations showing movement patterns over time. They record key point positions across frames in lists, use pen blocks to draw motion trails, create heatmaps showing most frequent positions, and graph position data over time. Students implement playback controls to review recorded movements and overlay visualizations on video. They analyze patterns in movement data and identify characteristic motion signatures for different activities (walking, jumping, dancing).
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-DA-08

Dependencies:
* T20.G6.02: Create interactive applications using body pose detection
* T04.G6.06: Build data aggregation systems using nested list structures
* T03.G6.05: Implement sprite pen drawing with dynamic color and size changes




ID: T20.G6.09
Topic: T20 – AI Media
Skill: Debug speech recognition accuracy issues in noisy environments
Description: Students investigate how background noise, multiple speakers, and acoustic conditions affect speech recognition accuracy. They test recognition in various acoustic scenarios, measure word error rates, and implement noise mitigation strategies (asking users to repeat, using confirmation dialogs, offering visual alternatives). Students experiment with recognition parameters if available and document which types of speech (length, complexity, vocabulary) recognize most accurately. They design applications that degrade gracefully when recognition quality drops.
Activity Type: Debugging
Estimated Time: 40-45 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G6.04: Implement speech recognition for voice-controlled applications
* T20.G5.12: Debug timing issues in multi-media AI generation sequences




ID: T20.G6.10
Topic: T20 – AI Media
Skill: Implement privacy protections in face detection applications
Description: Students design face detection applications with privacy safeguards: blurring detected faces, not storing facial images, processing locally without cloud upload, providing clear privacy notices, and allowing users to opt out. They implement face blurring by drawing filled rectangles over detected face regions and explain when face detection without recognition is appropriate. Students create privacy policy explanations for their projects and discuss ethical considerations in deploying face detection technology.
Activity Type: Block-based coding
Estimated Time: 40-45 minutes
CSTA: 2-IC-23

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T20.G5.08: Implement content moderation checks for user-generated prompts




ID: T20.G6.11
Topic: T20 – AI Media
Skill: Create adaptive image generation systems based on quality feedback
Description: Students build systems that generate multiple AI images and automatically select the best one based on quality criteria. They generate several variations of the same prompt, analyze each using image description or quality detection blocks, score images on defined criteria, and select the highest-scoring result. Students implement parallel generation if possible or sequential with early stopping. They document how often the first generation is best versus how often refinement improves results.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G5.11: Implement adaptive prompting based on generation feedback
* T20.G5.07: Evaluate AI image quality using multi-criteria rubrics




ID: T20.G6.12
Topic: T20 – AI Media
Skill: Evaluate voice synthesis quality across languages and accents
Description: Students test text-to-speech systems with content in multiple languages and various accents within languages. They assess pronunciation accuracy, natural prosody, comprehensibility, and accent authenticity. Students document which languages and accents are well-supported versus poorly rendered. They create comparison matrices showing TTS quality across language/accent combinations and discuss why quality varies. Students explain how training data diversity affects TTS quality and representation.
Activity Type: Comparative evaluation
Estimated Time: 35-40 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G5.04: Create voice output using text-to-speech blocks with parameter control
* T20.G5.13: Evaluate bias in AI-generated character representations




ID: T20.G6.13
Topic: T20 – AI Media
Skill: Implement gesture-based controls using body tracking
Description: Students create applications that recognize specific gestures from body tracking data and map them to controls. They define gesture patterns (arms raised, jumping, leaning, specific poses), implement pattern matching logic to detect these gestures, and trigger appropriate responses. Students handle gesture ambiguity and false positives, implement gesture hold times to confirm intent, and provide feedback when gestures are recognized. They test gesture recognition across different users and refine definitions for robustness.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G6.02: Create interactive applications using body pose detection
* T20.G6.08: Create data visualizations for body tracking over time




ID: T20.G6.14
Topic: T20 – AI Media
Skill: Create content moderation systems for generated images
Description: Students implement content moderation for AI-generated images in user-facing applications. They use image analysis blocks to detect inappropriate content, flag problematic images before display, log moderation decisions, and provide user feedback about why content was rejected. Students calibrate sensitivity thresholds balancing over-blocking versus under-blocking. They test with boundary cases and implement appeal/review mechanisms. Students discuss limitations of automated moderation and when human review is needed.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-IC-21

Dependencies:
* T20.G5.08: Implement content moderation checks for user-generated prompts
* T20.G6.11: Create adaptive image generation systems based on quality feedback




ID: T20.G6.15
Topic: T20 – AI Media
Skill: Debug synchronization issues in vision-based interactive applications
Description: Students identify and resolve timing problems in applications using real-time computer vision (face/body detection). They encounter frame rate mismatches, detection latency, and update synchronization issues. Students implement frame skipping strategies, add prediction/interpolation for smooth tracking, use double buffering for display, and optimize detection frequency. They measure actual latency and frame rates, identify bottlenecks, and implement appropriate solutions. Students explain trade-offs between accuracy, smoothness, and responsiveness.
Activity Type: Debugging
Estimated Time: 45-50 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G6.02: Create interactive applications using body pose detection
* T20.G5.12: Debug timing issues in multi-media AI generation sequences




ID: T20.G6.16
Topic: T20 – AI Media
Skill: Implement fallback strategies for AI component failures
Description: Students design applications that gracefully handle AI component failures (API unavailable, detection failure, generation timeout). They implement fallback behaviors such as using cached results, degrading to simpler alternatives, switching to manual controls, or providing informative error messages. Students create status monitoring systems that detect degraded performance and automatically activate fallbacks. They test applications under failure conditions and verify appropriate fallback activation. Students explain when fallbacks adequately serve users versus when failure should halt the application.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G5.16: Implement retry logic for failed AI media operations
* T20.G6.03: Debug edge cases in face detection applications




ID: T20.G6.17
Topic: T20 – AI Media
Skill: Evaluate accessibility of vision-based interaction systems
Description: Students analyze computer vision-based applications for accessibility barriers affecting users with mobility differences, visual impairments, or equipment limitations. They identify which interactions require specific physical capabilities, design alternative input methods (voice, keyboard, switch controls), and test their applications with accessibility constraints. Students document which vision-based features have accessible alternatives versus which are inherently inaccessible. They propose design patterns for inclusive vision-based interactions.
Activity Type: Accessibility evaluation
Estimated Time: 40-45 minutes
CSTA: 2-IC-22

Dependencies:
* T20.G6.02: Create interactive applications using body pose detection
* T20.G5.14: Create accessible AI media projects with alternative content




ID: T20.G6.18
Topic: T20 – AI Media
Skill: Create comparative analysis of AI media quality across tools
Description: Students systematically compare different AI media tools (different image generators, TTS engines, detection models) on consistent tasks. They define evaluation criteria, run identical tests across tools, document results in comparison matrices, and calculate aggregate quality scores. Students identify which tools excel at which tasks and explain differences based on tool design and training. They create recommendation guides matching tools to use cases and discuss why multiple tools exist rather than one universal solution.
Activity Type: Comparative analysis
Estimated Time: 50-55 minutes
CSTA: 2-AP-19

Dependencies:
* T20.G5.07: Evaluate AI image quality using multi-criteria rubrics
* T20.G6.12: Evaluate voice synthesis quality across languages and accents




ID: T20.G6.19
Topic: T20 – AI Media
Skill: Implement prompt security filters for adversarial inputs
Description: Students create robust prompt filtering systems protecting against adversarial inputs (jailbreaks, prompt injection, encoded inappropriate requests, attempts to extract training data). They analyze known attack patterns, implement multiple detection layers, use both keyword matching and semantic analysis, and log attempted violations. Students test their filters against provided adversarial examples and refine based on results. They explain the cat-and-mouse nature of prompt security and why perfect filtering is impossible.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-IC-21

Dependencies:
* T20.G5.08: Implement content moderation checks for user-generated prompts
* T20.G6.14: Create content moderation systems for generated images




ID: T20.G6.20
Topic: T20 – AI Media
Skill: Design ethical guidelines for AI media projects
Description: Students create comprehensive ethical guidelines for their AI media applications covering privacy, consent, transparency, bias mitigation, accessibility, and appropriate use. They analyze their projects against these guidelines, identify ethical concerns, and implement technical and policy solutions. Students create user-facing documentation explaining how their project handles ethical considerations and what data it uses or stores. They present their ethical framework and justify design choices balancing functionality with responsibility.
Activity Type: Ethical design
Estimated Time: 45-50 minutes
CSTA: 2-IC-23

Dependencies:
* T20.G6.10: Implement privacy protections in face detection applications
* T20.G5.13: Evaluate bias in AI-generated character representations
* T20.G5.14: Create accessible AI media projects with alternative content


## GRADE 7 (24 skills)




ID: T20.G7.01
Topic: T20 – AI Media
Skill: Implement hand detection using CreatiCode ML hand tracking blocks
Description: Students use CreatiCode's hand detection blocks to identify hands and track hand landmark positions (fingertips, joints, palm center, wrist). They create applications that visualize hand skeletons by drawing lines connecting landmarks, detect hand poses (open palm, fist, pointing), and track finger positions for interaction. Students implement both single-hand and multi-hand tracking, handle detection failures gracefully, and optimize detection frequency for performance. They document detection accuracy for different hand orientations and gestures.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T20.G6.02: Create interactive applications using body pose detection




ID: T20.G7.02
Topic: T20 – AI Media
Skill: Create gesture recognition systems from hand tracking data
Description: Students build gesture recognition using hand landmark data. They define gestures through landmark relationships (finger spacing, hand orientation, movement patterns), implement pattern matching algorithms comparing current hand state to gesture definitions, and create gesture vocabulary for their applications. Students handle temporal gestures requiring movement over time, use state machines to track gesture progress, and implement confidence scoring for ambiguous gestures. They test gesture recognition across users and refine definitions for consistency.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G7.01: Implement hand detection using CreatiCode ML hand tracking blocks
* T20.G6.13: Implement gesture-based controls using body tracking




ID: T20.G7.03
Topic: T20 – AI Media
Skill: Debug latency and performance in real-time hand tracking
Description: Students identify and resolve performance issues in hand tracking applications. They measure detection latency, frame processing time, and update rates, then optimize by adjusting detection frequency, implementing frame skipping, using prediction for smoother movement, and reducing processing per frame. Students profile their applications to identify bottlenecks, implement selective processing (only when hands present), and balance accuracy with responsiveness. They document the relationship between performance parameters and user experience quality.
Activity Type: Debugging
Estimated Time: 45-50 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G7.01: Implement hand detection using CreatiCode ML hand tracking blocks
* T20.G6.15: Debug synchronization issues in vision-based interactive applications




ID: T20.G7.04
Topic: T20 – AI Media
Skill: Implement advanced prompt engineering with negative prompts and weights
Description: Students use advanced prompt techniques including negative prompts (specifying what not to include), element weighting (emphasizing certain parts), and prompt composition (combining multiple concepts). They experiment with syntax for weights and negatives in CreatiCode or other tools, document how different weight values affect outputs, and create complex prompts balancing multiple objectives. Students build applications that construct weighted prompts from user inputs and explain when advanced techniques improve results versus adding unnecessary complexity.
Activity Type: Block-based coding
Estimated Time: 45-50 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G5.15: Design prompt templates for consistent visual style across images
* T20.G5.03: Implement parameter-based prompt variations in loops




ID: T20.G7.05
Topic: T20 – AI Media
Skill: Create style transfer applications combining AI generation with vision
Description: Students build applications that analyze existing images using computer vision, extract style characteristics, and use this information to guide new AI image generation. They might use image description to understand content, color detection to extract palettes, or composition analysis to guide layout, then incorporate these into generation prompts. Students create before-and-after galleries showing style transfer results and evaluate how well styles transferred. They explain technical challenges in automated style transfer.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.11: Create adaptive image generation systems based on quality feedback
* T20.G5.11: Implement adaptive prompting based on generation feedback




ID: T20.G7.06
Topic: T20 – AI Media
Skill: Evaluate and detect AI hallucinations in multi-modal outputs
Description: Students investigate AI hallucinations across modalities: fabricated details in image descriptions, invented facts in image-to-text, false associations in multi-modal analysis. They create systematic tests generating AI outputs and checking for hallucinated content against ground truth. Students categorize hallucination types (added objects, fabricated relationships, incorrect attributes, made-up text content), measure hallucination rates, and identify which contexts produce more hallucinations. They design verification strategies users can employ to detect hallucinations.
Activity Type: Analysis
Estimated Time: 45-50 minutes
CSTA: 2-DA-08

Dependencies:
* T20.G5.06: Detect AI-generated content hallucinations in image descriptions
* T20.G6.11: Create adaptive image generation systems based on quality feedback




ID: T20.G7.07
Topic: T20 – AI Media
Skill: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
Description: Students use CreatiCode's KNN blocks to build custom classifiers. They collect training data by associating inputs (images, sounds, sensor values) with labels, train KNN models on this data, and use the model to classify new inputs. Students experiment with different K values, visualize how classification confidence changes with K, and test classifier accuracy with separate test data. They create interactive applications where users can add training examples and immediately see classification results update.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-13

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T04.G7.06: Implement multi-dimensional data processing and analysis




ID: T20.G7.08
Topic: T20 – AI Media
Skill: Debug classification errors in custom KNN models
Description: Students systematically investigate why their KNN classifiers make mistakes. They examine misclassified examples, visualize decision boundaries if possible, check for class imbalance in training data, and identify ambiguous cases near class boundaries. Students experiment with different K values to see effects on errors, add more training examples in problematic regions, and remove outliers that confuse the classifier. They document common error patterns and create guidelines for improving training data quality.
Activity Type: Debugging
Estimated Time: 45-50 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G6.03: Debug edge cases in face detection applications




ID: T20.G7.09
Topic: T20 – AI Media
Skill: Create interactive training interfaces for machine learning models
Description: Students build user-friendly interfaces for training custom ML models. They implement data collection workflows (capture training examples with labels), provide visual feedback showing training data distribution across classes, allow users to review and delete bad examples, and display real-time classification results as training progresses. Students add features like save/load for training data, bulk import/export, and training data visualization. They test their interfaces with real users and refine based on usability feedback.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G5.05: Implement user-input-driven prompt generation systems




ID: T20.G7.10
Topic: T20 – AI Media
Skill: Evaluate training data requirements for classification accuracy
Description: Students experimentally determine how much training data is needed for good classification. They train models with varying amounts of data per class (5, 10, 20, 50 examples), measure accuracy for each, and graph the relationship between training size and performance. Students identify the point of diminishing returns where more data doesn't significantly improve accuracy. They compare data requirements across different classification tasks (simple vs. complex) and explain why some problems need more training data than others.
Activity Type: Experimental evaluation
Estimated Time: 50-55 minutes
CSTA: 2-DA-08

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G7.08: Debug classification errors in custom KNN models




ID: T20.G7.11
Topic: T20 – AI Media
Skill: Trace neural network architecture from input to output
Description: Students examine simplified neural network diagrams showing input layer, hidden layers, and output layer. They trace how data flows through the network, label each layer's purpose, and describe transformations at each stage. Students use visual representations with weighted connections and activation functions, trace example inputs through the network step-by-step, and predict outputs based on network structure. They explain how network depth and width affect capacity and identify which architectures suit which problems.
Activity Type: Diagram analysis
Estimated Time: 40-45 minutes
CSTA: 2-AP-12

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G4.02: Trace the flow of data through multi-stage AI media pipelines




ID: T20.G7.11.01
Topic: T20 – AI Media
Skill: Trace forward propagation through a simple neural network layer
Description: Students follow data through individual neural network layers by calculating weighted sums and applying activation functions. They work with small examples (3-5 neurons) using provided weights, manually compute activation values for each neuron, and trace how inputs transform to outputs. Students visualize the computation as a data flow graph, identify which neurons activate strongly for which inputs, and explain how weights determine neuron behavior. They compare linear versus non-linear activations and explain why activation functions matter.
Activity Type: Mathematical tracing
Estimated Time: 35-40 minutes
CSTA: 2-AP-12

Dependencies:
* T20.G7.11: Trace neural network architecture from input to output




ID: T20.G7.11.02
Topic: T20 – AI Media
Skill: Predict how weight adjustments affect neural network outputs
Description: Students experiment with changing individual weights in small neural networks and predict resulting output changes. They identify which weights have most influence on specific outputs, trace how weight changes propagate through layers, and explain the relationship between weight magnitude and output sensitivity. Students work with interactive network visualizations if available or manual calculations for small networks. They connect weight adjustment concepts to training and explain how learning algorithms find good weights.
Activity Type: Prediction and analysis
Estimated Time: 40-45 minutes
CSTA: 2-AP-11

Dependencies:
* T20.G7.11.01: Trace forward propagation through a simple neural network layer




ID: T20.G7.11.03
Topic: T20 – AI Media
Skill: Evaluate how training data quality affects neural network learning
Description: Students train simple neural networks (or use pre-trained models with controlled training data) with varying quality training sets: clean data, noisy data, biased data, insufficient data, and redundant data. They measure resulting model performance, identify which data quality issues cause which problems, and explain how bad training data leads to poor models. Students create guidelines for training data quality including diversity, accuracy, quantity, and balance. They explain why "garbage in, garbage out" applies to neural networks.
Activity Type: Experimental evaluation
Estimated Time: 45-50 minutes
CSTA: 2-DA-08

Dependencies:
* T20.G7.11.01: Trace forward propagation through a simple neural network layer
* T20.G7.10: Evaluate training data requirements for classification accuracy




ID: T20.G7.12
Topic: T20 – AI Media
Skill: Implement transfer learning by combining pre-trained and custom models
Description: Students use pre-trained AI models (image classification, object detection) as components in larger custom applications. They feed pre-trained model outputs as inputs to custom classifiers, combine multiple pre-trained models for multi-modal applications, and fine-tune behavior through prompt engineering or post-processing. Students explain advantages of transfer learning (leveraging existing training, less data needed) versus training from scratch. They document which pre-trained components they use and how they integrate them.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G7.11: Trace neural network architecture from input to output




ID: T20.G7.13
Topic: T20 – AI Media
Skill: Create deepfake detection systems using multi-factor analysis
Description: Students build applications that analyze images/videos for deepfake indicators using multiple detection methods: visual artifact detection, consistency checking (lighting, shadows, reflections), temporal consistency in videos, and metadata analysis. They combine evidence from multiple sources, implement scoring systems aggregating different factors, and set detection thresholds. Students test with known real and fake media, measure detection accuracy, and document which detection methods work best for which deepfake types.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.06: Evaluate generated images for deepfake warning signs
* T20.G7.06: Evaluate and detect AI hallucinations in multi-modal outputs




ID: T20.G7.14
Topic: T20 – AI Media
Skill: Debug overfitting in custom-trained classification models
Description: Students encounter and resolve overfitting where models perform well on training data but poorly on new data. They split data into training and test sets, measure accuracy on both, and identify overfitting when test accuracy lags significantly. Students implement solutions including collecting more diverse training data, reducing model complexity, and adding regularization through simpler models. They document the training/test accuracy gap and explain why models that memorize training examples fail to generalize.
Activity Type: Debugging
Estimated Time: 45-50 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G7.08: Debug classification errors in custom KNN models
* T20.G7.10: Evaluate training data requirements for classification accuracy




ID: T20.G7.15
Topic: T20 – AI Media
Skill: Implement attention-based interaction using gaze tracking
Description: Students create applications that track where users look (using face detection and eye position estimation if available, or simpler proxy methods like head orientation). They implement gaze-based interfaces highlighting elements users look at, selecting items with dwell time, and providing gaze-based feedback. Students calibrate gaze tracking for individual users, handle inaccuracies gracefully, and design interfaces accounting for gaze tracking limitations. They evaluate when gaze interaction improves usability versus when it's frustrating.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.01: Implement face detection using CreatiCode ML face blocks
* T20.G7.02: Create gesture recognition systems from hand tracking data




ID: T20.G7.16
Topic: T20 – AI Media
Skill: Create automated image quality assessment systems
Description: Students build systems that automatically assess AI-generated image quality using multiple metrics: technical quality (resolution, artifacts, noise), composition (balance, focal point), prompt alignment (checking if key elements present), and aesthetic qualities. They implement scoring algorithms combining multiple factors, calibrate weights for different criteria, and validate automated scores against human ratings. Students use these systems to automatically filter or rank generated images and document correlation between automated scores and human preferences.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 2-AP-14

Dependencies:
* T20.G6.11: Create adaptive image generation systems based on quality feedback
* T20.G5.07: Evaluate AI image quality using multi-criteria rubrics




ID: T20.G7.17
Topic: T20 – AI Media
Skill: Implement real-time performance optimization for ML-intensive applications
Description: Students optimize applications using computationally expensive ML operations (detection, classification, generation) to maintain acceptable performance. They implement strategies including processing every Nth frame, using lower-resolution inputs, caching results when inputs don't change, running detection asynchronously, and gracefully degrading quality when performance drops. Students measure frame rates and latency, identify performance bottlenecks using timing analysis, and document trade-offs between accuracy, latency, and completeness.
Activity Type: Optimization
Estimated Time: 50-55 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G7.03: Debug latency and performance in real-time hand tracking
* T20.G6.15: Debug synchronization issues in vision-based interactive applications




ID: T20.G7.18
Topic: T20 – AI Media
Skill: Evaluate bias in custom-trained classification models
Description: Students systematically test their custom classifiers for bias across different subgroups. They collect test data representing different demographics or categories, measure accuracy for each subgroup separately, and identify disparities. Students trace bias to training data imbalance, ambiguous labeling, or inappropriate features. They implement bias mitigation strategies including balancing training data, removing biased features, and adjusting decision thresholds per group. Students document bias testing methodology and results.
Activity Type: Bias analysis
Estimated Time: 50-55 minutes
CSTA: 2-IC-20

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G5.13: Evaluate bias in AI-generated character representations




ID: T20.G7.19
Topic: T20 – AI Media
Skill: Create multi-stage AI pipelines with quality gates
Description: Students build complex AI pipelines with multiple stages (generation, analysis, refinement, validation) and quality checkpoints between stages. They implement decision logic at each gate determining whether to proceed, retry with modifications, or fail, use intermediate results to guide subsequent stages, and track success/failure rates at each gate. Students visualize pipeline flow showing where items pass or fail, optimize gate thresholds balancing quality versus throughput, and document pipeline efficiency.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G6.11: Create adaptive image generation systems based on quality feedback
* T20.G4.09: Construct iterative refinement workflows for complex AI outputs




ID: T20.G7.20
Topic: T20 – AI Media
Skill: Debug cross-modal consistency issues in multi-modal AI systems
Description: Students identify and resolve inconsistencies when combining multiple AI modalities (image generation + description, speech-to-text + text-to-speech, vision + language). They detect when different modalities provide contradictory information, implement consistency checking comparing outputs across modalities, and create resolution strategies when conflicts arise. Students measure consistency rates, identify which modality combinations produce most conflicts, and design systems that handle inconsistency gracefully.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 2-AP-17

Dependencies:
* T20.G6.05: Create multi-modal interfaces combining vision and voice AI
* T20.G7.06: Evaluate and detect AI hallucinations in multi-modal outputs




ID: T20.G7.21
Topic: T20 – AI Media
Skill: Implement explainable AI techniques for classification decisions
Description: Students create transparency features showing why their classifiers make specific decisions. They visualize which features most influenced decisions, display nearest neighbors in KNN classification, show confidence scores for different classes, and generate explanations in user-friendly language. Students implement feature importance analysis, create visual explanations highlighting relevant input regions, and design UI showing decision reasoning. They evaluate whether explanations help users trust or debug the system.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 2-AP-16

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G7.09: Create interactive training interfaces for machine learning models




ID: T20.G7.22
Topic: T20 – AI Media
Skill: Create accessibility-first AI interaction systems
Description: Students design AI-powered applications with accessibility as a primary design constraint rather than an afterthought. They provide multiple interaction modalities (voice, vision, touch, keyboard), ensure all AI outputs have accessible alternatives (descriptions for images, captions for audio), support assistive technologies, and test with accessibility tools. Students document accessibility features in their design documentation, conduct accessibility audits, and iterate based on findings.
Activity Type: Accessible design
Estimated Time: 55-60 minutes
CSTA: 2-IC-22

Dependencies:
* T20.G6.17: Evaluate accessibility of vision-based interaction systems
* T20.G6.05: Create multi-modal interfaces combining vision and voice AI




ID: T20.G7.23
Topic: T20 – AI Media
Skill: Evaluate computational ethics in AI media deployment
Description: Students analyze ethical implications of deploying their AI media applications considering privacy, consent, transparency, bias, accessibility, dual use, and environmental impact. They conduct ethical impact assessments, identify potential harms, propose mitigation strategies, and create ethical use policies. Students consider stakeholder perspectives beyond end users (those depicted in training data, affected communities, environment). They document ethical decisions in their project and justify trade-offs.
Activity Type: Ethical analysis
Estimated Time: 50-55 minutes
CSTA: 2-IC-23

Dependencies:
* T20.G6.20: Design ethical guidelines for AI media projects
* T20.G7.18: Evaluate bias in custom-trained classification models




ID: T20.G7.24
Topic: T20 – AI Media
Skill: Create comparative benchmarks for AI media model performance
Description: Students design comprehensive benchmarks comparing different AI models (image generators, classifiers, detectors) on consistent tasks. They define standardized test sets, establish evaluation metrics, automate testing across models, collect performance data, and analyze results statistically. Students create visualization dashboards showing model comparisons, identify performance trade-offs (accuracy vs. speed, quality vs. cost), and make evidence-based model selection recommendations for different use cases.
Activity Type: Benchmarking
Estimated Time: 60 minutes
CSTA: 2-DA-09

Dependencies:
* T20.G6.18: Create comparative analysis of AI media quality across tools
* T20.G7.10: Evaluate training data requirements for classification accuracy


## GRADE 8 (26 skills)




ID: T20.G8.01
Topic: T20 – AI Media
Skill: Implement semantic search using vector embeddings in CreatiCode
Description: Students use CreatiCode's semantic search blocks to create searchable collections of images, text, or multi-modal content using vector embeddings. They add items to vector databases with associated metadata, perform similarity searches finding semantically related items, and tune search parameters for precision/recall balance. Students compare semantic search with keyword search, explain how embeddings capture meaning beyond exact matches, and create applications like visual search engines or recommendation systems using embedding similarity.
Activity Type: Block-based coding
Estimated Time: 50-55 minutes
CSTA: 3A-AP-13

Dependencies:
* T20.G7.07: Implement K-Nearest Neighbors classification using CreatiCode ML blocks
* T20.G7.05: Create style transfer applications combining AI generation with vision




ID: T20.G8.02
Topic: T20 – AI Media
Skill: Debug semantic drift in vector-based retrieval systems
Description: Students investigate why semantic search sometimes returns unexpected results. They examine cases where semantically different items rank highly, identify ambiguous queries matching unintended concepts, and detect when embedding models lack domain-specific knowledge. Students implement query refinement strategies, add negative examples to exclude concepts, use metadata filters to constrain results, and re-rank results with additional criteria. They document common semantic drift patterns and create guidelines for writing effective semantic queries.
Activity Type: Debugging
Estimated Time: 45-50 minutes
CSTA: 3A-AP-17

Dependencies:
* T20.G8.01: Implement semantic search using vector embeddings in CreatiCode
* T20.G7.08: Debug classification errors in custom KNN models




ID: T20.G8.03
Topic: T20 – AI Media
Skill: Create hybrid retrieval systems combining multiple search strategies
Description: Students build advanced search systems combining semantic search, keyword search, and metadata filtering. They implement scoring algorithms that weight different search methods, create unified ranking combining diverse results, and allow users to adjust search strategy emphasis. Students compare pure semantic, pure keyword, and hybrid approaches on test queries, measure precision and recall for each, and identify which queries benefit from hybrid approaches. They explain trade-offs between search methods.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-AP-16

Dependencies:
* T20.G8.01: Implement semantic search using vector embeddings in CreatiCode
* T20.G8.02: Debug semantic drift in vector-based retrieval systems




ID: T20.G8.04
Topic: T20 – AI Media
Skill: Implement neural network training for custom image classification
Description: Students train custom neural network image classifiers using transfer learning in CreatiCode or similar platforms. They collect and label training images, select base models appropriate for their task, configure training parameters (learning rate, epochs, batch size), monitor training progress, and evaluate model performance. Students implement data augmentation to expand training sets, use validation sets to prevent overfitting, and export trained models for deployment. They document training process and compare final model performance to baseline approaches.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-AP-13

Dependencies:
* T20.G7.11.03: Evaluate how training data quality affects neural network learning
* T20.G7.12: Implement transfer learning by combining pre-trained and custom models




ID: T20.G8.05
Topic: T20 – AI Media
Skill: Debug training failures in custom neural networks
Description: Students troubleshoot neural network training problems including non-convergence, overfitting, underfitting, vanishing gradients, and excessive training time. They analyze training curves showing loss and accuracy over epochs, identify problem signatures, and apply appropriate solutions (adjusting learning rate, adding data, changing architecture, using regularization). Students implement early stopping to prevent overfitting, use learning rate schedules, and diagnose data quality issues causing training problems. They create debugging guides for common training failures.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 3A-AP-17

Dependencies:
* T20.G8.04: Implement neural network training for custom image classification
* T20.G7.14: Debug overfitting in custom-trained classification models




ID: T20.G8.06
Topic: T20 – AI Media
Skill: Create production-ready AI media systems with monitoring and logging
Description: Students transform prototype AI applications into production systems with robust monitoring, logging, error handling, and performance tracking. They implement usage analytics tracking request patterns, log errors with sufficient context for debugging, monitor performance metrics (latency, throughput, error rates), and create alerting for anomalies. Students design dashboards visualizing system health, implement rate limiting and resource management, and create maintenance documentation. They explain differences between prototype and production system requirements.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-AP-16

Dependencies:
* T20.G7.19: Create multi-stage AI pipelines with quality gates
* T20.G6.16: Implement fallback strategies for AI component failures




ID: T20.G8.07
Topic: T20 – AI Media
Skill: Evaluate energy and computational costs of AI media operations
Description: Students measure and analyze computational costs of different AI operations including generation time, memory usage, API calls, and energy consumption estimates. They create cost models estimating resources for different operation types and volumes, identify most expensive operations, and design cost-optimization strategies. Students compare cloud versus local processing costs, evaluate sustainability implications of AI media systems, and make informed decisions balancing functionality versus resource consumption. They document cost analysis in their project planning.
Activity Type: Analysis
Estimated Time: 45-50 minutes
CSTA: 3A-IC-24

Dependencies:
* T20.G7.17: Implement real-time performance optimization for ML-intensive applications
* T20.G4.06: Predict resource requirements for AI media generation tasks




ID: T20.G8.08
Topic: T20 – AI Media
Skill: Implement A/B testing frameworks for AI model comparison
Description: Students create systems for rigorous A/B testing comparing different AI models or prompting strategies. They implement random assignment of users/requests to different conditions, collect performance data for each condition, calculate statistical significance of differences, and draw valid conclusions. Students design tests controlling for confounding variables, determine appropriate sample sizes, and visualize results with confidence intervals. They explain when observed differences are meaningful versus noise and make data-driven model selection decisions.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-DA-09

Dependencies:
* T20.G7.24: Create comparative benchmarks for AI media model performance
* T20.G4.07: Evaluate prompt strategies across multiple generation attempts




ID: T20.G8.09
Topic: T20 – AI Media
Skill: Create deepfake verification systems with authenticity scoring
Description: Students build comprehensive deepfake detection systems combining multiple verification methods: technical analysis (artifacts, consistency, metadata), provenance checking (source verification, digital signatures), cross-reference verification (checking against known authentic media), and behavioral analysis. They implement scoring systems aggregating evidence, calibrate thresholds for different confidence levels (verified authentic, likely authentic, uncertain, likely fake, verified fake), and provide detailed explanations of verification results. Students test with diverse deepfakes and measure detection accuracy.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-AP-16

Dependencies:
* T20.G7.13: Create deepfake detection systems using multi-factor analysis
* T20.G6.06: Evaluate generated images for deepfake warning signs




ID: T20.G8.10
Topic: T20 – AI Media
Skill: Debug adversarial attacks on AI media classifiers
Description: Students investigate adversarial examples designed to fool AI classifiers through imperceptible input modifications. They generate or test with adversarial examples, analyze how small perturbations cause misclassification, and implement defensive strategies (input validation, adversarial training, ensemble methods, confidence thresholds). Students measure classifier robustness to adversarial attacks, identify which types of perturbations are most effective, and explain fundamental limits of classifier robustness. They document security implications for deployed AI systems.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 3A-AP-17

Dependencies:
* T20.G8.04: Implement neural network training for custom image classification
* T20.G7.08: Debug classification errors in custom KNN models




ID: T20.G8.11
Topic: T20 – AI Media
Skill: Implement differential privacy in AI media applications
Description: Students add privacy protections to AI systems that process personal data. They implement techniques like adding noise to outputs, aggregating data before processing, limiting query specificity, and using synthetic data for testing. Students balance privacy protection strength versus utility, measure privacy budgets, and explain privacy-utility trade-offs. They create privacy guarantees documentation, test that individual data cannot be recovered from outputs, and design systems assuming data will be sensitive.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-IC-30

Dependencies:
* T20.G6.10: Implement privacy protections in face detection applications
* T20.G7.23: Evaluate computational ethics in AI media deployment




ID: T20.G8.12
Topic: T20 – AI Media
Skill: Create sophisticated hallucination detection and verification systems
Description: Students build multi-layered systems detecting AI hallucinations in generated content through cross-verification, fact-checking, consistency analysis, and confidence calibration. They implement verification pipelines checking generated content against ground truth sources, use multiple AI models to cross-verify facts, detect inconsistencies between different parts of generated content, and flag low-confidence outputs for review. Students measure hallucination rates, categorize hallucination types, and create user interfaces clearly indicating verification status.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-AP-16

Dependencies:
* T20.G7.06: Evaluate and detect AI hallucinations in multi-modal outputs
* T20.G5.06: Detect AI-generated content hallucinations in image descriptions




ID: T20.G8.13
Topic: T20 – AI Media
Skill: Implement model versioning and rollback systems
Description: Students create infrastructure for managing multiple versions of AI models in production. They implement version tracking for models and training data, create deployment pipelines supporting gradual rollout, monitor performance of new versions, and implement automatic rollback when performance degrades. Students design A/B testing comparing versions, maintain compatibility between versions, and document version changes. They explain why model versioning matters and when to retire old versions versus maintaining multiple versions.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-AP-18

Dependencies:
* T20.G8.06: Create production-ready AI media systems with monitoring and logging
* T20.G8.08: Implement A/B testing frameworks for AI model comparison




ID: T20.G8.14
Topic: T20 – AI Media
Skill: Evaluate fairness metrics across protected groups
Description: Students conduct comprehensive fairness evaluations of AI systems measuring multiple fairness metrics (demographic parity, equal opportunity, equalized odds, predictive parity) across protected groups. They collect disaggregated performance data, calculate metrics for each group, identify fairness violations, and implement mitigation strategies. Students explain tensions between different fairness definitions, document which fairness criteria their system prioritizes, and justify these choices based on use case. They create fairness report cards for their AI systems.
Activity Type: Fairness analysis
Estimated Time: 55-60 minutes
CSTA: 3A-IC-29

Dependencies:
* T20.G7.18: Evaluate bias in custom-trained classification models
* T20.G5.13: Evaluate bias in AI-generated character representations




ID: T20.G8.15
Topic: T20 – AI Media
Skill: Create explainable AI systems with counterfactual explanations
Description: Students implement advanced explainability features including counterfactual explanations ("your image would be classified differently if..."), feature importance visualizations, decision boundary visualizations, and natural language explanations of model decisions. They generate multiple explanation types for different audiences (end users, domain experts, developers), validate that explanations accurately reflect model behavior, and test whether explanations improve user understanding and trust. Students evaluate trade-offs between explanation completeness and comprehensibility.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-AP-16

Dependencies:
* T20.G7.21: Implement explainable AI techniques for classification decisions
* T20.G8.04: Implement neural network training for custom image classification




ID: T20.G8.16
Topic: T20 – AI Media
Skill: Debug model performance degradation in production
Description: Students investigate why AI models that perform well in testing degrade in production. They identify causes including data drift (input distribution changes), concept drift (relationships between inputs and outputs change), feedback loops, adversarial usage, and infrastructure issues. Students implement monitoring detecting drift, create automated alerts for performance degradation, design systems for continuous evaluation with production data, and implement model retraining pipelines. They document degradation patterns and prevention strategies.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 3A-AP-17

Dependencies:
* T20.G8.06: Create production-ready AI media systems with monitoring and logging
* T20.G8.05: Debug training failures in custom neural networks




ID: T20.G8.17
Topic: T20 – AI Media
Skill: Implement multi-objective optimization in AI media generation
Description: Students create systems optimizing multiple competing objectives simultaneously (quality, speed, cost, diversity, fairness). They implement Pareto optimization finding solutions balancing multiple objectives, create visualizations showing trade-off frontiers, and design interfaces allowing users to specify objective priorities. Students explain why optimizing one objective often degrades others, implement weighted scoring combining objectives, and document trade-off decisions in their systems.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-AP-15

Dependencies:
* T20.G8.06: Create production-ready AI media systems with monitoring and logging
* T20.G4.12: Evaluate trade-offs in AI media generation parameter choices




ID: T20.G8.18
Topic: T20 – AI Media
Skill: Create accessibility compliance frameworks for AI media
Description: Students develop comprehensive accessibility frameworks for AI media applications meeting WCAG standards and disability rights requirements. They implement automated accessibility testing, create accessibility checklists covering all AI components, provide multiple interaction modalities, ensure compatibility with assistive technologies, and conduct accessibility audits. Students document accessibility features, create compliance reports, test with diverse users including those with disabilities, and iterate based on feedback. They explain legal and ethical imperatives for accessibility.
Activity Type: Accessibility framework
Estimated Time: 60 minutes
CSTA: 3A-IC-24

Dependencies:
* T20.G7.22: Create accessibility-first AI interaction systems
* T20.G6.17: Evaluate accessibility of vision-based interaction systems




ID: T20.G8.19
Topic: T20 – AI Media
Skill: Implement content authenticity verification with digital watermarking
Description: Students create systems embedding and verifying digital watermarks in AI-generated content to establish authenticity and provenance. They implement watermarking during generation, create verification systems detecting watermarks, test watermark robustness to modifications (compression, cropping, filters), and design user interfaces showing verification results. Students explain limitations of watermarking, document what watermarks can and cannot prove, and discuss role of technical measures in establishing content authenticity.
Activity Type: Block-based coding
Estimated Time: 55-60 minutes
CSTA: 3A-IC-28

Dependencies:
* T20.G8.09: Create deepfake verification systems with authenticity scoring
* T20.G7.13: Create deepfake detection systems using multi-factor analysis




ID: T20.G8.20
Topic: T20 – AI Media
Skill: Debug bias amplification in iterative AI systems
Description: Students investigate how bias amplifies when AI systems are used iteratively (outputs become training data for next iteration). They create simulations showing bias amplification over iterations, identify feedback loops creating runaway bias, and implement interventions breaking amplification cycles. Students measure bias growth rates, test mitigation strategies (diverse data injection, debiasing algorithms, human oversight), and design systems resistant to bias amplification. They explain why deployed AI systems can make bias worse over time.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 3A-IC-29

Dependencies:
* T20.G8.14: Evaluate fairness metrics across protected groups
* T20.G7.18: Evaluate bias in custom-trained classification models




ID: T20.G8.21
Topic: T20 – AI Media
Skill: Create responsible AI impact assessments
Description: Students conduct comprehensive impact assessments for AI media systems evaluating technical, social, ethical, environmental, and economic impacts. They identify stakeholders affected by their systems, assess potential harms and benefits for each group, propose mitigation strategies for identified harms, and create accountability mechanisms. Students document impact assessments, update them as systems evolve, and use findings to guide design decisions. They explain why impact assessment should be ongoing throughout system lifecycle, not just initial deployment.
Activity Type: Impact assessment
Estimated Time: 60 minutes
CSTA: 3A-IC-29

Dependencies:
* T20.G7.23: Evaluate computational ethics in AI media deployment
* T20.G8.14: Evaluate fairness metrics across protected groups




ID: T20.G8.22
Topic: T20 – AI Media
Skill: Implement federated learning for privacy-preserving model training
Description: Students explore federated learning concepts where models train on distributed data without centralizing it. They implement simplified federated learning simulations, compare centralized versus federated approaches, analyze privacy benefits and technical challenges, and evaluate when federated learning is appropriate. Students measure communication costs, handle heterogeneous data distributions, and implement aggregation strategies combining distributed model updates. They explain how federated learning enables collaborative learning while preserving privacy.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-IC-30

Dependencies:
* T20.G8.11: Implement differential privacy in AI media applications
* T20.G8.04: Implement neural network training for custom image classification




ID: T20.G8.23
Topic: T20 – AI Media
Skill: Debug hallucination amplification in multi-agent AI systems
Description: Students investigate how hallucinations amplify when multiple AI systems interact (one AI's hallucinated output becomes another's input). They create multi-agent simulations showing hallucination propagation, identify architectural patterns causing amplification, and implement verification checkpoints preventing hallucination spread. Students measure hallucination rates in multi-agent versus single-agent systems, design robust architectures resistant to hallucination cascades, and create isolation strategies preventing contamination between agents.
Activity Type: Debugging
Estimated Time: 50-55 minutes
CSTA: 3A-AP-17

Dependencies:
* T20.G8.12: Create sophisticated hallucination detection and verification systems
* T20.G7.20: Debug cross-modal consistency issues in multi-modal AI systems




ID: T20.G8.24
Topic: T20 – AI Media
Skill: Create comprehensive AI system documentation and disclosure
Description: Students create complete documentation for AI systems including model cards, data sheets, system architecture documentation, known limitations, evaluation results, intended use cases, and inappropriate uses. They write documentation for multiple audiences (end users, developers, regulators, researchers), implement in-app disclosure mechanisms informing users about AI capabilities and limitations, and create transparency reports. Students explain legal and ethical requirements for AI disclosure and design documentation supporting accountability.
Activity Type: Documentation
Estimated Time: 55-60 minutes
CSTA: 3A-IC-28

Dependencies:
* T20.G8.06: Create production-ready AI media systems with monitoring and logging
* T20.G8.21: Create responsible AI impact assessments




ID: T20.G8.25
Topic: T20 – AI Media
Skill: Implement continuous evaluation pipelines for deployed AI systems
Description: Students create automated evaluation systems continuously monitoring deployed AI performance on quality, fairness, safety, and efficiency metrics. They implement automated test suites running on schedules, create dashboards visualizing trends over time, set up alerting for metric degradation, and design human review workflows for flagged issues. Students integrate evaluation with deployment pipelines (preventing deployment of degraded models), maintain evaluation datasets representing real usage, and document evaluation methodology.
Activity Type: Block-based coding
Estimated Time: 60 minutes
CSTA: 3A-AP-18

Dependencies:
* T20.G8.06: Create production-ready AI media systems with monitoring and logging
* T20.G8.16: Debug model performance degradation in production




ID: T20.G8.26
Topic: T20 – AI Media
Skill: Design AI governance frameworks for organizational deployment
Description: Students create governance frameworks for organizations deploying AI media systems including approval workflows, risk assessment procedures, ongoing monitoring requirements, incident response plans, and accountability structures. They define roles and responsibilities, create decision criteria for AI adoption, design review processes for high-risk applications, and establish mechanisms for stakeholder input. Students document governance frameworks, explain how governance balances innovation with responsibility, and justify framework design choices based on organizational context and risk tolerance.
Activity Type: Governance design
Estimated Time: 60 minutes
CSTA: 3A-IC-29

Dependencies:
* T20.G8.21: Create responsible AI impact assessments
* T20.G8.24: Create comprehensive AI system documentation and disclosure
